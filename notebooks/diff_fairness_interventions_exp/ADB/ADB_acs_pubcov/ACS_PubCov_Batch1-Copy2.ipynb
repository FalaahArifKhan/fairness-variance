{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfdf046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb27a77e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd456fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2626a3df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855b9875",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92af387b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147d79f",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609f837a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSPublicCoverageDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440ab89",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f23e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_pubcov'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_CA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f4a15e",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c44176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8989a617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3d934f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bf843ff8-62e9-4aac-83bc-d805e3299fdc\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4f7f5",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c711d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>ESR</th>\n",
       "      <th>ST</th>\n",
       "      <th>FER</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL MAR SEX DIS ESP CIT MIG MIL ANC NATIVITY DEAR DEYE DREM ESR ST FER  \\\n",
       "0   19   5   1   2   0   1   3   4   1        1    2    2    2   6  6   0   \n",
       "1   16   5   1   2   0   3   3   4   4        1    2    2    2   1  6   0   \n",
       "2   13   5   2   2   1   1   1   0   2        1    2    2    2   6  6   2   \n",
       "3   20   1   2   2   0   4   1   4   1        2    2    2    2   6  6   2   \n",
       "4   16   1   2   2   0   4   1   4   1        2    2    2    2   6  6   0   \n",
       "\n",
       "  RAC1P  AGEP   PINCP  \n",
       "0     1    21  3150.0  \n",
       "1     9    18  1600.0  \n",
       "2     1    16     0.0  \n",
       "3     8    43     0.0  \n",
       "4     6    54     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSPublicCoverageDataset(state=['CA'], year=2018, with_nulls=False,\n",
    "                                       subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4fd8e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f78ef",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81bf52",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2c8b917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c3054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': '84eeb5f0-4ebe-4d9f-94ef-53ae302c2264'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0774252fc3d84263b3f1952d6646e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb71fcf4f547769fec45358ef2d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81e93a7c9ca4b759124ebae6b6a39d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2024-01-08 14:47:02.022905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706076; batch adversarial loss: 0.692046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528616; batch adversarial loss: 0.690824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437058; batch adversarial loss: 0.641205\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374626; batch adversarial loss: 0.591401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.578531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.540871\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253209; batch adversarial loss: 0.536458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249384; batch adversarial loss: 0.510654\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222574; batch adversarial loss: 0.526174\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231929; batch adversarial loss: 0.544187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269365; batch adversarial loss: 0.530938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.269131; batch adversarial loss: 0.499622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209271; batch adversarial loss: 0.500838\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232830; batch adversarial loss: 0.522906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200820; batch adversarial loss: 0.444583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175221; batch adversarial loss: 0.468809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195260; batch adversarial loss: 0.487876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.108377; batch adversarial loss: 0.462686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.154744; batch adversarial loss: 0.465643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.114956; batch adversarial loss: 0.518928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185771; batch adversarial loss: 0.457848\n",
      "epoch 21; iter: 0; batch classifier loss: 0.114915; batch adversarial loss: 0.514133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.135782; batch adversarial loss: 0.513373\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134654; batch adversarial loss: 0.569677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175153; batch adversarial loss: 0.454520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180932; batch adversarial loss: 0.524089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194350; batch adversarial loss: 0.554577\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175350; batch adversarial loss: 0.572550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203875; batch adversarial loss: 0.621340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.584977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192389; batch adversarial loss: 0.494302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166049; batch adversarial loss: 0.488495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181273; batch adversarial loss: 0.477612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197128; batch adversarial loss: 0.508084\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233774; batch adversarial loss: 0.480641\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171880; batch adversarial loss: 0.430034\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272469; batch adversarial loss: 0.529935\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227646; batch adversarial loss: 0.448445\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163945; batch adversarial loss: 0.406804\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079406; batch adversarial loss: 0.448137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091811; batch adversarial loss: 0.446052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.067578; batch adversarial loss: 0.525227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.059282; batch adversarial loss: 0.496629\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104444; batch adversarial loss: 0.455580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119299; batch adversarial loss: 0.454710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076554; batch adversarial loss: 0.489845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086420; batch adversarial loss: 0.475786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067454; batch adversarial loss: 0.383989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099616; batch adversarial loss: 0.504962\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129307; batch adversarial loss: 0.369170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074693; batch adversarial loss: 0.344991\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073794; batch adversarial loss: 0.533122\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101932; batch adversarial loss: 0.551938\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079983; batch adversarial loss: 0.460136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074297; batch adversarial loss: 0.473660\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119616; batch adversarial loss: 0.417397\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096468; batch adversarial loss: 0.344682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112178; batch adversarial loss: 0.483005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097981; batch adversarial loss: 0.495853\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082937; batch adversarial loss: 0.485810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061327; batch adversarial loss: 0.522080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090307; batch adversarial loss: 0.448743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047843; batch adversarial loss: 0.452977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065588; batch adversarial loss: 0.387373\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098521; batch adversarial loss: 0.422866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058718; batch adversarial loss: 0.489143\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089657; batch adversarial loss: 0.364338\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069073; batch adversarial loss: 0.508808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079268; batch adversarial loss: 0.435710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075794; batch adversarial loss: 0.451353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103014; batch adversarial loss: 0.524944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079265; batch adversarial loss: 0.458990\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054589; batch adversarial loss: 0.416570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.571959\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075297; batch adversarial loss: 0.431452\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071271; batch adversarial loss: 0.468172\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070982; batch adversarial loss: 0.451261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076285; batch adversarial loss: 0.433854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062035; batch adversarial loss: 0.504788\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075761; batch adversarial loss: 0.467174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098143; batch adversarial loss: 0.505237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084273; batch adversarial loss: 0.357909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071487; batch adversarial loss: 0.473864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121158; batch adversarial loss: 0.486395\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.409071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065818; batch adversarial loss: 0.503372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082517; batch adversarial loss: 0.587905\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.466063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.564533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089993; batch adversarial loss: 0.390280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082860; batch adversarial loss: 0.463198\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047112; batch adversarial loss: 0.537224\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101391; batch adversarial loss: 0.538014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.131220; batch adversarial loss: 0.459360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.109573; batch adversarial loss: 0.465781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054340; batch adversarial loss: 0.397680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.495775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062126; batch adversarial loss: 0.498909\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.431311\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102993; batch adversarial loss: 0.376494\n",
      "epoch 100; iter: 0; batch classifier loss: 0.102044; batch adversarial loss: 0.357074\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054333; batch adversarial loss: 0.467210\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054543; batch adversarial loss: 0.427762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.450090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065666; batch adversarial loss: 0.440686\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081424; batch adversarial loss: 0.314604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067678; batch adversarial loss: 0.510275\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063083; batch adversarial loss: 0.474941\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019212; batch adversarial loss: 0.407522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034522; batch adversarial loss: 0.409571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058404; batch adversarial loss: 0.502819\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040291; batch adversarial loss: 0.444476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042527; batch adversarial loss: 0.447824\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.419865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054878; batch adversarial loss: 0.463392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053708; batch adversarial loss: 0.508642\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035963; batch adversarial loss: 0.455745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072132; batch adversarial loss: 0.499220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043367; batch adversarial loss: 0.420356\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048310; batch adversarial loss: 0.492525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074792; batch adversarial loss: 0.405318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.584632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066402; batch adversarial loss: 0.514826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.436852\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040002; batch adversarial loss: 0.377582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017416; batch adversarial loss: 0.497774\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071384; batch adversarial loss: 0.499982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037890; batch adversarial loss: 0.466903\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.433337\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043349; batch adversarial loss: 0.491828\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017410; batch adversarial loss: 0.436271\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050517; batch adversarial loss: 0.450991\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047536; batch adversarial loss: 0.512238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013396; batch adversarial loss: 0.419450\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069495; batch adversarial loss: 0.453873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.442644\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.452397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046000; batch adversarial loss: 0.442586\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029759; batch adversarial loss: 0.361690\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037082; batch adversarial loss: 0.530520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061619; batch adversarial loss: 0.476281\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027611; batch adversarial loss: 0.463160\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.430123\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.542561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.402583\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.458558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052981; batch adversarial loss: 0.499904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052879; batch adversarial loss: 0.468605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.437735\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013094; batch adversarial loss: 0.392392\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054930; batch adversarial loss: 0.392228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033070; batch adversarial loss: 0.429573\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013686; batch adversarial loss: 0.480302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025517; batch adversarial loss: 0.474301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026941; batch adversarial loss: 0.397288\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021937; batch adversarial loss: 0.382238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.386828\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029149; batch adversarial loss: 0.362087\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032100; batch adversarial loss: 0.514566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026255; batch adversarial loss: 0.514117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030920; batch adversarial loss: 0.367334\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015507; batch adversarial loss: 0.385345\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041188; batch adversarial loss: 0.557631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038723; batch adversarial loss: 0.467234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.458803\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.389683\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.340316\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030933; batch adversarial loss: 0.488713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.493203\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040985; batch adversarial loss: 0.462638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028517; batch adversarial loss: 0.418939\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026486; batch adversarial loss: 0.536990\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020521; batch adversarial loss: 0.486689\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030953; batch adversarial loss: 0.454736\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006511; batch adversarial loss: 0.437390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016025; batch adversarial loss: 0.431013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.506947\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.402723\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.441069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010429; batch adversarial loss: 0.496293\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.415183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021063; batch adversarial loss: 0.424210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.479177\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011231; batch adversarial loss: 0.444569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027491; batch adversarial loss: 0.465693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033915; batch adversarial loss: 0.559489\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023120; batch adversarial loss: 0.453808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012470; batch adversarial loss: 0.402795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.427348\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041508; batch adversarial loss: 0.460209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.323445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039655; batch adversarial loss: 0.390811\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015852; batch adversarial loss: 0.466843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035564; batch adversarial loss: 0.504015\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008910; batch adversarial loss: 0.485968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056930; batch adversarial loss: 0.580673\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.370200\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.446720\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041652; batch adversarial loss: 0.417590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012187; batch adversarial loss: 0.526439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:38.105341: W tensorflow/c/c_api.cc:304] Operation '{name:'04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:784 op device:{requested: '', assigned: ''} def:{{{node 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706066; batch adversarial loss: 0.736104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530403; batch adversarial loss: 0.678148\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459406; batch adversarial loss: 0.631632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.603996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406459; batch adversarial loss: 0.622275\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.592824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326480; batch adversarial loss: 0.557714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264814; batch adversarial loss: 0.563979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309007; batch adversarial loss: 0.561000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337536; batch adversarial loss: 0.511946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.497081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326900; batch adversarial loss: 0.521918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282505; batch adversarial loss: 0.507427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.319482; batch adversarial loss: 0.490685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297245; batch adversarial loss: 0.530186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348114; batch adversarial loss: 0.492884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315601; batch adversarial loss: 0.543774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353514; batch adversarial loss: 0.479612\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284691; batch adversarial loss: 0.557426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321636; batch adversarial loss: 0.461743\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313884; batch adversarial loss: 0.535758\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.452499\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307755; batch adversarial loss: 0.462012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.481600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280347; batch adversarial loss: 0.487124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349690; batch adversarial loss: 0.456283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296061; batch adversarial loss: 0.497201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.333900; batch adversarial loss: 0.465661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244060; batch adversarial loss: 0.450193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281684; batch adversarial loss: 0.416492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234843; batch adversarial loss: 0.482024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302185; batch adversarial loss: 0.407197\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187466; batch adversarial loss: 0.474231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230678; batch adversarial loss: 0.523563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241098; batch adversarial loss: 0.496128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299920; batch adversarial loss: 0.424774\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261082; batch adversarial loss: 0.428908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260111; batch adversarial loss: 0.474318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284937; batch adversarial loss: 0.372036\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288252; batch adversarial loss: 0.389466\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252943; batch adversarial loss: 0.422020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203067; batch adversarial loss: 0.377419\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247434; batch adversarial loss: 0.503243\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251894; batch adversarial loss: 0.407028\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323468; batch adversarial loss: 0.434153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277021; batch adversarial loss: 0.421189\n",
      "epoch 46; iter: 0; batch classifier loss: 0.304496; batch adversarial loss: 0.501504\n",
      "epoch 47; iter: 0; batch classifier loss: 0.246984; batch adversarial loss: 0.447492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231022; batch adversarial loss: 0.519735\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179348; batch adversarial loss: 0.410107\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257322; batch adversarial loss: 0.496071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267536; batch adversarial loss: 0.423316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.341285; batch adversarial loss: 0.459359\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095520; batch adversarial loss: 0.458750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.434297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125691; batch adversarial loss: 0.351374\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099187; batch adversarial loss: 0.398515\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078252; batch adversarial loss: 0.323342\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138991; batch adversarial loss: 0.535808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090362; batch adversarial loss: 0.529794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081609; batch adversarial loss: 0.375216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.478639\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108687; batch adversarial loss: 0.408623\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104107; batch adversarial loss: 0.481544\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044141; batch adversarial loss: 0.368196\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082003; batch adversarial loss: 0.465862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105736; batch adversarial loss: 0.443595\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073735; batch adversarial loss: 0.489333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060975; batch adversarial loss: 0.436080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.429296\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049926; batch adversarial loss: 0.365259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083830; batch adversarial loss: 0.494927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074709; batch adversarial loss: 0.461633\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111192; batch adversarial loss: 0.433871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039334; batch adversarial loss: 0.515788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071055; batch adversarial loss: 0.406289\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082684; batch adversarial loss: 0.357580\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067315; batch adversarial loss: 0.511623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069397; batch adversarial loss: 0.385906\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075082; batch adversarial loss: 0.456910\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048823; batch adversarial loss: 0.406157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081523; batch adversarial loss: 0.411017\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091294; batch adversarial loss: 0.499160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064026; batch adversarial loss: 0.350682\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042356; batch adversarial loss: 0.517212\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.350081\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035308; batch adversarial loss: 0.443477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.374428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.407967\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102669; batch adversarial loss: 0.389595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099464; batch adversarial loss: 0.437800\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056865; batch adversarial loss: 0.437627\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.460328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036856; batch adversarial loss: 0.436436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.363280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105770; batch adversarial loss: 0.378147\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056142; batch adversarial loss: 0.399404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037050; batch adversarial loss: 0.386856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067514; batch adversarial loss: 0.414906\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097396; batch adversarial loss: 0.436210\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066562; batch adversarial loss: 0.466013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042754; batch adversarial loss: 0.375284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046262; batch adversarial loss: 0.387627\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060422; batch adversarial loss: 0.400367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047418; batch adversarial loss: 0.438297\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084870; batch adversarial loss: 0.451563\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083724; batch adversarial loss: 0.437510\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024412; batch adversarial loss: 0.500079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077510; batch adversarial loss: 0.362601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072262; batch adversarial loss: 0.485094\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028390; batch adversarial loss: 0.414303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066319; batch adversarial loss: 0.512818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047636; batch adversarial loss: 0.424238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041746; batch adversarial loss: 0.410702\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.448275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.529532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065540; batch adversarial loss: 0.429329\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055839; batch adversarial loss: 0.436495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044993; batch adversarial loss: 0.402658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073519; batch adversarial loss: 0.378357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068609; batch adversarial loss: 0.464458\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.518541\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059184; batch adversarial loss: 0.345951\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.421292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041276; batch adversarial loss: 0.383915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049520; batch adversarial loss: 0.421313\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.363910\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.449873\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.476491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.436265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.083309; batch adversarial loss: 0.409344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066746; batch adversarial loss: 0.464579\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066838; batch adversarial loss: 0.375523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060657; batch adversarial loss: 0.382825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.450408\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059749; batch adversarial loss: 0.403990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.450985\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.574739\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065396; batch adversarial loss: 0.398369\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.476669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.481624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.499269\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049504; batch adversarial loss: 0.316459\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070289; batch adversarial loss: 0.535042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.366865\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046085; batch adversarial loss: 0.375202\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.446702\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.384226\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049078; batch adversarial loss: 0.387665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039845; batch adversarial loss: 0.441024\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.414215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038650; batch adversarial loss: 0.382847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031766; batch adversarial loss: 0.458061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022421; batch adversarial loss: 0.437063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039472; batch adversarial loss: 0.480207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034906; batch adversarial loss: 0.514492\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.377841\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028500; batch adversarial loss: 0.396452\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.453429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033487; batch adversarial loss: 0.445524\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044612; batch adversarial loss: 0.459001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017963; batch adversarial loss: 0.343711\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052142; batch adversarial loss: 0.403664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.421914\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032402; batch adversarial loss: 0.472692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.418011\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.452449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.458858\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.402869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.471132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.480702\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014721; batch adversarial loss: 0.471981\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034698; batch adversarial loss: 0.427563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026398; batch adversarial loss: 0.372757\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.371487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039552; batch adversarial loss: 0.394009\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.377999\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029643; batch adversarial loss: 0.450269\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.445277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.446072\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.375977\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025078; batch adversarial loss: 0.362209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031550; batch adversarial loss: 0.392815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.382241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027336; batch adversarial loss: 0.445629\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022268; batch adversarial loss: 0.451700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025109; batch adversarial loss: 0.451593\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.427051\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013901; batch adversarial loss: 0.616939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016848; batch adversarial loss: 0.451149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016180; batch adversarial loss: 0.478983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.362182\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.432742\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.409336\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.408788\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013846; batch adversarial loss: 0.398356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.364331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007561; batch adversarial loss: 0.454264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007466; batch adversarial loss: 0.421940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035742; batch adversarial loss: 0.398075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:13.265192: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:1591 op device:{requested: '', assigned: ''} def:{{{node 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688129; batch adversarial loss: 0.582458\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418286; batch adversarial loss: 0.582047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525055; batch adversarial loss: 0.583817\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428255; batch adversarial loss: 0.520912\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.566984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340495; batch adversarial loss: 0.611152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408788; batch adversarial loss: 0.555860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.536746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377252; batch adversarial loss: 0.547035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416875; batch adversarial loss: 0.571816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458405; batch adversarial loss: 0.447826\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361180; batch adversarial loss: 0.517236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285615; batch adversarial loss: 0.506002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346196; batch adversarial loss: 0.575380\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283920; batch adversarial loss: 0.515648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200360; batch adversarial loss: 0.501168\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243708; batch adversarial loss: 0.432575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178450; batch adversarial loss: 0.420903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254595; batch adversarial loss: 0.438466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257026; batch adversarial loss: 0.496501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.502721\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232064; batch adversarial loss: 0.468430\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189602; batch adversarial loss: 0.435759\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213089; batch adversarial loss: 0.513310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195573; batch adversarial loss: 0.461283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202941; batch adversarial loss: 0.458565\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216715; batch adversarial loss: 0.509816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226038; batch adversarial loss: 0.503132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185449; batch adversarial loss: 0.474548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197551; batch adversarial loss: 0.513540\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198968; batch adversarial loss: 0.444631\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178431; batch adversarial loss: 0.418701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165924; batch adversarial loss: 0.471863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200710; batch adversarial loss: 0.389130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215499; batch adversarial loss: 0.398050\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148965; batch adversarial loss: 0.436479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.196180; batch adversarial loss: 0.435999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219984; batch adversarial loss: 0.414746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253643; batch adversarial loss: 0.502879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148975; batch adversarial loss: 0.460152\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182249; batch adversarial loss: 0.430215\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212471; batch adversarial loss: 0.516455\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204900; batch adversarial loss: 0.486186\n",
      "epoch 43; iter: 0; batch classifier loss: 0.273834; batch adversarial loss: 0.370007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.184662; batch adversarial loss: 0.446620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211863; batch adversarial loss: 0.532505\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246754; batch adversarial loss: 0.378046\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.432995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217221; batch adversarial loss: 0.504403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199260; batch adversarial loss: 0.494291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225734; batch adversarial loss: 0.469332\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280469; batch adversarial loss: 0.450357\n",
      "epoch 52; iter: 0; batch classifier loss: 0.256328; batch adversarial loss: 0.400179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.235736; batch adversarial loss: 0.472313\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268841; batch adversarial loss: 0.423809\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215488; batch adversarial loss: 0.494381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.156838; batch adversarial loss: 0.493873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067571; batch adversarial loss: 0.446264\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103650; batch adversarial loss: 0.479958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080905; batch adversarial loss: 0.476880\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087581; batch adversarial loss: 0.438387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.527533\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069701; batch adversarial loss: 0.451979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092830; batch adversarial loss: 0.408839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179970; batch adversarial loss: 0.439693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190992; batch adversarial loss: 0.491628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146571; batch adversarial loss: 0.574472\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124498; batch adversarial loss: 0.413266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.170022; batch adversarial loss: 0.442749\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124150; batch adversarial loss: 0.469246\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086658; batch adversarial loss: 0.446183\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097854; batch adversarial loss: 0.510166\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098005; batch adversarial loss: 0.506230\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103036; batch adversarial loss: 0.476823\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119643; batch adversarial loss: 0.513143\n",
      "epoch 75; iter: 0; batch classifier loss: 0.154620; batch adversarial loss: 0.419525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.417197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090060; batch adversarial loss: 0.433126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108649; batch adversarial loss: 0.491992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072665; batch adversarial loss: 0.427414\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078432; batch adversarial loss: 0.416684\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081628; batch adversarial loss: 0.618467\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081460; batch adversarial loss: 0.451962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083842; batch adversarial loss: 0.409290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065025; batch adversarial loss: 0.527774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076811; batch adversarial loss: 0.395808\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080542; batch adversarial loss: 0.426802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035755; batch adversarial loss: 0.457259\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075089; batch adversarial loss: 0.522649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073160; batch adversarial loss: 0.524856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075504; batch adversarial loss: 0.454985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082712; batch adversarial loss: 0.468551\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081159; batch adversarial loss: 0.424298\n",
      "epoch 93; iter: 0; batch classifier loss: 0.105341; batch adversarial loss: 0.483678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103236; batch adversarial loss: 0.413750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.477983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096910; batch adversarial loss: 0.419712\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088785; batch adversarial loss: 0.338753\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056480; batch adversarial loss: 0.493365\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078842; batch adversarial loss: 0.472535\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.404357\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062635; batch adversarial loss: 0.445790\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078453; batch adversarial loss: 0.472064\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038869; batch adversarial loss: 0.438187\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.479073\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.491621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031616; batch adversarial loss: 0.548412\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.448620\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.465527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.452133\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.402920\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019532; batch adversarial loss: 0.465544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056462; batch adversarial loss: 0.441909\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072204; batch adversarial loss: 0.602850\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.479939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050471; batch adversarial loss: 0.433319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060567; batch adversarial loss: 0.398176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047180; batch adversarial loss: 0.439185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029035; batch adversarial loss: 0.418488\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033030; batch adversarial loss: 0.450658\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051230; batch adversarial loss: 0.409980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034502; batch adversarial loss: 0.483479\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066685; batch adversarial loss: 0.415055\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036303; batch adversarial loss: 0.464543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.493312\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030684; batch adversarial loss: 0.400999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.445230\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032854; batch adversarial loss: 0.453296\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026536; batch adversarial loss: 0.507458\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.440097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.370093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036277; batch adversarial loss: 0.417342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.464351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032374; batch adversarial loss: 0.545062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.349027\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016774; batch adversarial loss: 0.495524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030935; batch adversarial loss: 0.449530\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.456351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013323; batch adversarial loss: 0.456658\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030194; batch adversarial loss: 0.510743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021454; batch adversarial loss: 0.356752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028846; batch adversarial loss: 0.352905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023706; batch adversarial loss: 0.536787\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019686; batch adversarial loss: 0.470078\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041820; batch adversarial loss: 0.487558\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011119; batch adversarial loss: 0.483874\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030574; batch adversarial loss: 0.457222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024936; batch adversarial loss: 0.558170\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.372945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.432468\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023059; batch adversarial loss: 0.319447\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.445123\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013528; batch adversarial loss: 0.437946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.482155\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012327; batch adversarial loss: 0.448138\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.413030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040082; batch adversarial loss: 0.496351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021876; batch adversarial loss: 0.453756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029481; batch adversarial loss: 0.465553\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004143; batch adversarial loss: 0.414448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013102; batch adversarial loss: 0.464395\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008841; batch adversarial loss: 0.449652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.577473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012078; batch adversarial loss: 0.431391\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005280; batch adversarial loss: 0.348936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.531446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007558; batch adversarial loss: 0.368732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007948; batch adversarial loss: 0.418823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011378; batch adversarial loss: 0.462137\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012475; batch adversarial loss: 0.522107\n",
      "epoch 170; iter: 0; batch classifier loss: 0.089205; batch adversarial loss: 0.425102\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013193; batch adversarial loss: 0.438883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.464129\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.464161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.416692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.454887\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003722; batch adversarial loss: 0.416714\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009313; batch adversarial loss: 0.439547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013868; batch adversarial loss: 0.486130\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022029; batch adversarial loss: 0.498505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008864; batch adversarial loss: 0.420729\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038184; batch adversarial loss: 0.417415\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.408334\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026545; batch adversarial loss: 0.569768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006229; batch adversarial loss: 0.342425\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011448; batch adversarial loss: 0.482688\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023002; batch adversarial loss: 0.445266\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004066; batch adversarial loss: 0.428464\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003665; batch adversarial loss: 0.430902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027354; batch adversarial loss: 0.399141\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005157; batch adversarial loss: 0.474395\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.400792\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050361; batch adversarial loss: 0.441677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.475218\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006026; batch adversarial loss: 0.468294\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.498031\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.443660\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005842; batch adversarial loss: 0.529499\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009330; batch adversarial loss: 0.451309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.396820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:49.999533: W tensorflow/c/c_api.cc:304] Operation '{name:'04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:2398 op device:{requested: '', assigned: ''} def:{{{node 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709423; batch adversarial loss: 0.826485\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589269; batch adversarial loss: 0.774333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.757826; batch adversarial loss: 0.757554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651808; batch adversarial loss: 0.683050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559073; batch adversarial loss: 0.616526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383718; batch adversarial loss: 0.587390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361682; batch adversarial loss: 0.608442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300812; batch adversarial loss: 0.533616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428041; batch adversarial loss: 0.522132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334713; batch adversarial loss: 0.554177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.478305\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403465; batch adversarial loss: 0.537060\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316303; batch adversarial loss: 0.511609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331920; batch adversarial loss: 0.503228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314666; batch adversarial loss: 0.467400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338908; batch adversarial loss: 0.471192\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334456; batch adversarial loss: 0.463481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237582; batch adversarial loss: 0.487386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243639; batch adversarial loss: 0.559268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223562; batch adversarial loss: 0.497359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.560765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308990; batch adversarial loss: 0.482442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294239; batch adversarial loss: 0.508942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245820; batch adversarial loss: 0.469365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199940; batch adversarial loss: 0.491858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237852; batch adversarial loss: 0.483418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248950; batch adversarial loss: 0.494269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215890; batch adversarial loss: 0.493594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219729; batch adversarial loss: 0.477457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219291; batch adversarial loss: 0.576004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205509; batch adversarial loss: 0.407661\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229055; batch adversarial loss: 0.420588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231041; batch adversarial loss: 0.436854\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188074; batch adversarial loss: 0.454388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252571; batch adversarial loss: 0.415374\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175120; batch adversarial loss: 0.415148\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156770; batch adversarial loss: 0.482264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153350; batch adversarial loss: 0.431682\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211564; batch adversarial loss: 0.467146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260667; batch adversarial loss: 0.425384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224133; batch adversarial loss: 0.424066\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186538; batch adversarial loss: 0.481687\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217674; batch adversarial loss: 0.570059\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.480069\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287237; batch adversarial loss: 0.476578\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318581; batch adversarial loss: 0.362229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227443; batch adversarial loss: 0.465089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194799; batch adversarial loss: 0.446107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306833; batch adversarial loss: 0.507393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202465; batch adversarial loss: 0.537706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223188; batch adversarial loss: 0.423028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225845; batch adversarial loss: 0.447576\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155381; batch adversarial loss: 0.486634\n",
      "epoch 53; iter: 0; batch classifier loss: 0.203742; batch adversarial loss: 0.445566\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250815; batch adversarial loss: 0.460954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182396; batch adversarial loss: 0.564597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178321; batch adversarial loss: 0.466417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135660; batch adversarial loss: 0.492085\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227268; batch adversarial loss: 0.379017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185556; batch adversarial loss: 0.459743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153740; batch adversarial loss: 0.510053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155630; batch adversarial loss: 0.541576\n",
      "epoch 62; iter: 0; batch classifier loss: 0.116137; batch adversarial loss: 0.521728\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178817; batch adversarial loss: 0.517786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213310; batch adversarial loss: 0.396766\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174103; batch adversarial loss: 0.519237\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168989; batch adversarial loss: 0.469374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.438444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227675; batch adversarial loss: 0.382676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129285; batch adversarial loss: 0.448061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153188; batch adversarial loss: 0.513892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189201; batch adversarial loss: 0.483813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143782; batch adversarial loss: 0.399117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.194640; batch adversarial loss: 0.492915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222503; batch adversarial loss: 0.506290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192905; batch adversarial loss: 0.444399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.185618; batch adversarial loss: 0.465811\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102490; batch adversarial loss: 0.387088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.260674; batch adversarial loss: 0.397151\n",
      "epoch 79; iter: 0; batch classifier loss: 0.162815; batch adversarial loss: 0.474389\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195085; batch adversarial loss: 0.410728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132135; batch adversarial loss: 0.481101\n",
      "epoch 82; iter: 0; batch classifier loss: 0.157003; batch adversarial loss: 0.405431\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114738; batch adversarial loss: 0.472957\n",
      "epoch 84; iter: 0; batch classifier loss: 0.124425; batch adversarial loss: 0.469340\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133828; batch adversarial loss: 0.459536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127560; batch adversarial loss: 0.468921\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106405; batch adversarial loss: 0.604421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144443; batch adversarial loss: 0.520639\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117262; batch adversarial loss: 0.506146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087750; batch adversarial loss: 0.443731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113289; batch adversarial loss: 0.463015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128436; batch adversarial loss: 0.406349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095744; batch adversarial loss: 0.532681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072927; batch adversarial loss: 0.510598\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050717; batch adversarial loss: 0.512368\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103528; batch adversarial loss: 0.485659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055867; batch adversarial loss: 0.489014\n",
      "epoch 98; iter: 0; batch classifier loss: 0.119304; batch adversarial loss: 0.409256\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058918; batch adversarial loss: 0.356944\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078266; batch adversarial loss: 0.489582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100184; batch adversarial loss: 0.437631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.432486\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076005; batch adversarial loss: 0.420993\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023383; batch adversarial loss: 0.489630\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.427848\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057579; batch adversarial loss: 0.446779\n",
      "epoch 107; iter: 0; batch classifier loss: 0.016594; batch adversarial loss: 0.571494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043061; batch adversarial loss: 0.435629\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.449064\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.429082\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064466; batch adversarial loss: 0.544246\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.414706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.438979\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041520; batch adversarial loss: 0.450136\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039195; batch adversarial loss: 0.526165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046723; batch adversarial loss: 0.487179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028024; batch adversarial loss: 0.413543\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043546; batch adversarial loss: 0.430986\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042654; batch adversarial loss: 0.482377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.380076\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046653; batch adversarial loss: 0.495118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.513909\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023094; batch adversarial loss: 0.336286\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063677; batch adversarial loss: 0.488526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023231; batch adversarial loss: 0.407590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.499945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025814; batch adversarial loss: 0.477885\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016976; batch adversarial loss: 0.424454\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.436375\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017588; batch adversarial loss: 0.497257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035290; batch adversarial loss: 0.445353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.495507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.398855\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.477906\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012807; batch adversarial loss: 0.425623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030065; batch adversarial loss: 0.464185\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.495098\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036601; batch adversarial loss: 0.409268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009201; batch adversarial loss: 0.415366\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010369; batch adversarial loss: 0.548791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.535071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036020; batch adversarial loss: 0.589606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015933; batch adversarial loss: 0.460440\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012548; batch adversarial loss: 0.467244\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013664; batch adversarial loss: 0.545864\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026615; batch adversarial loss: 0.433055\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026677; batch adversarial loss: 0.394158\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015726; batch adversarial loss: 0.499501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.500811\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023914; batch adversarial loss: 0.507878\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023069; batch adversarial loss: 0.444022\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015060; batch adversarial loss: 0.406906\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.431451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029299; batch adversarial loss: 0.384312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.425266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010244; batch adversarial loss: 0.462371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013574; batch adversarial loss: 0.496028\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.442006\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011610; batch adversarial loss: 0.426134\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.502678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007833; batch adversarial loss: 0.470883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020268; batch adversarial loss: 0.378876\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024588; batch adversarial loss: 0.436137\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023924; batch adversarial loss: 0.466352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030063; batch adversarial loss: 0.400956\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.604907\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008819; batch adversarial loss: 0.359732\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005808; batch adversarial loss: 0.514479\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026108; batch adversarial loss: 0.435591\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.438637\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025742; batch adversarial loss: 0.494849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024279; batch adversarial loss: 0.371164\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.457860\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007689; batch adversarial loss: 0.433103\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013153; batch adversarial loss: 0.531247\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007330; batch adversarial loss: 0.419843\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.491824\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.441699\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.515906\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031273; batch adversarial loss: 0.458018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.432972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.494271\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028760; batch adversarial loss: 0.477630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003358; batch adversarial loss: 0.410230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008431; batch adversarial loss: 0.415887\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012250; batch adversarial loss: 0.528063\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018286; batch adversarial loss: 0.525953\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012842; batch adversarial loss: 0.436430\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.486868\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016325; batch adversarial loss: 0.362743\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025971; batch adversarial loss: 0.450625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002842; batch adversarial loss: 0.520413\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.450268\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011491; batch adversarial loss: 0.497005\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.466075\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.474331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.001744; batch adversarial loss: 0.376615\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002974; batch adversarial loss: 0.495768\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006627; batch adversarial loss: 0.450932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:49:25.594013: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:3205 op device:{requested: '', assigned: ''} def:{{{node 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.683073; batch adversarial loss: 0.620856\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440653; batch adversarial loss: 0.621911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365344; batch adversarial loss: 0.600834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300769; batch adversarial loss: 0.601682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.272899; batch adversarial loss: 0.534356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387933; batch adversarial loss: 0.513569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376173; batch adversarial loss: 0.530133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.561520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275634; batch adversarial loss: 0.532561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282988; batch adversarial loss: 0.506175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250687; batch adversarial loss: 0.404790\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310366; batch adversarial loss: 0.531628\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267975; batch adversarial loss: 0.560586\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.544327\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312451; batch adversarial loss: 0.493957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489029; batch adversarial loss: 0.491952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488049; batch adversarial loss: 0.555351\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559185; batch adversarial loss: 0.456053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281974; batch adversarial loss: 0.509155\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237257; batch adversarial loss: 0.485235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170045; batch adversarial loss: 0.451948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208757; batch adversarial loss: 0.488383\n",
      "epoch 22; iter: 0; batch classifier loss: 0.176183; batch adversarial loss: 0.451187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195614; batch adversarial loss: 0.419134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.445964\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174144; batch adversarial loss: 0.449422\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182457; batch adversarial loss: 0.482860\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198129; batch adversarial loss: 0.478548\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212512; batch adversarial loss: 0.394042\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183227; batch adversarial loss: 0.388321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174824; batch adversarial loss: 0.420980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156038; batch adversarial loss: 0.456845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223948; batch adversarial loss: 0.470265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105976; batch adversarial loss: 0.556003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142961; batch adversarial loss: 0.437921\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196068; batch adversarial loss: 0.411923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141115; batch adversarial loss: 0.470426\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165741; batch adversarial loss: 0.353729\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152037; batch adversarial loss: 0.526223\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099027; batch adversarial loss: 0.464474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110921; batch adversarial loss: 0.452975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089708; batch adversarial loss: 0.475388\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117443; batch adversarial loss: 0.463111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081043; batch adversarial loss: 0.560608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120436; batch adversarial loss: 0.472981\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098060; batch adversarial loss: 0.487844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127252; batch adversarial loss: 0.368227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155660; batch adversarial loss: 0.397125\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104707; batch adversarial loss: 0.495177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094743; batch adversarial loss: 0.437039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128758; batch adversarial loss: 0.367638\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070209; batch adversarial loss: 0.419098\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121524; batch adversarial loss: 0.511020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109622; batch adversarial loss: 0.444450\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133209; batch adversarial loss: 0.376170\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119858; batch adversarial loss: 0.415048\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084955; batch adversarial loss: 0.505013\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079445; batch adversarial loss: 0.437708\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173282; batch adversarial loss: 0.451169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167735; batch adversarial loss: 0.457671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118800; batch adversarial loss: 0.457323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104539; batch adversarial loss: 0.457290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104589; batch adversarial loss: 0.386224\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178848; batch adversarial loss: 0.489418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118512; batch adversarial loss: 0.493791\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118857; batch adversarial loss: 0.426787\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088094; batch adversarial loss: 0.422159\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.431979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.475427\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085103; batch adversarial loss: 0.465173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144985; batch adversarial loss: 0.411650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137528; batch adversarial loss: 0.399713\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100343; batch adversarial loss: 0.345952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114244; batch adversarial loss: 0.513249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079822; batch adversarial loss: 0.488730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163532; batch adversarial loss: 0.430517\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106552; batch adversarial loss: 0.413256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108928; batch adversarial loss: 0.469671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.419774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080087; batch adversarial loss: 0.451439\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133886; batch adversarial loss: 0.384145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108813; batch adversarial loss: 0.489638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127258; batch adversarial loss: 0.392087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086930; batch adversarial loss: 0.473320\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.472512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.449457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.437829\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079782; batch adversarial loss: 0.453353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.143531; batch adversarial loss: 0.466258\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069261; batch adversarial loss: 0.354200\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.470479\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062476; batch adversarial loss: 0.541695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082710; batch adversarial loss: 0.480140\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.473447\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075548; batch adversarial loss: 0.447946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058477; batch adversarial loss: 0.426762\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.453171\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.335832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053453; batch adversarial loss: 0.476380\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073238; batch adversarial loss: 0.586781\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.427228\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042540; batch adversarial loss: 0.432745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071360; batch adversarial loss: 0.362941\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093896; batch adversarial loss: 0.463941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057524; batch adversarial loss: 0.437521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051401; batch adversarial loss: 0.405707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.473556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065696; batch adversarial loss: 0.484608\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.450714\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050737; batch adversarial loss: 0.470143\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064994; batch adversarial loss: 0.515462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064557; batch adversarial loss: 0.451665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038048; batch adversarial loss: 0.495670\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069824; batch adversarial loss: 0.392696\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.484216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044866; batch adversarial loss: 0.430529\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073175; batch adversarial loss: 0.408202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.107425; batch adversarial loss: 0.540736\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043385; batch adversarial loss: 0.383689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049156; batch adversarial loss: 0.482229\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043849; batch adversarial loss: 0.469089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058626; batch adversarial loss: 0.445064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015754; batch adversarial loss: 0.330612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.485688\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.408941\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.451863\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019002; batch adversarial loss: 0.464778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026591; batch adversarial loss: 0.464596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.404924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.422667\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.410978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.448252\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026199; batch adversarial loss: 0.412464\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039348; batch adversarial loss: 0.566884\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051199; batch adversarial loss: 0.374595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.502335\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086487; batch adversarial loss: 0.358220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060143; batch adversarial loss: 0.515063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053990; batch adversarial loss: 0.432021\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.428206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.459213\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.467816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.384554\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.339316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024966; batch adversarial loss: 0.508985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.497956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026609; batch adversarial loss: 0.396169\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042491; batch adversarial loss: 0.516891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.594180\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040416; batch adversarial loss: 0.530106\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020989; batch adversarial loss: 0.460259\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008401; batch adversarial loss: 0.446931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014468; batch adversarial loss: 0.462676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.427720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067858; batch adversarial loss: 0.356513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.426754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.408194\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024619; batch adversarial loss: 0.531720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044226; batch adversarial loss: 0.399916\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024355; batch adversarial loss: 0.398681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.469875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043514; batch adversarial loss: 0.437727\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.424770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.405221\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023990; batch adversarial loss: 0.350152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040421; batch adversarial loss: 0.382282\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045091; batch adversarial loss: 0.472792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046813; batch adversarial loss: 0.379816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026784; batch adversarial loss: 0.394039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.414904\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.413440\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013882; batch adversarial loss: 0.478051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.448272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.448238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065883; batch adversarial loss: 0.425081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.481297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.461707\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051299; batch adversarial loss: 0.391626\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021155; batch adversarial loss: 0.433748\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028798; batch adversarial loss: 0.413467\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019515; batch adversarial loss: 0.445502\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012136; batch adversarial loss: 0.463219\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.507201\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012701; batch adversarial loss: 0.405407\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.458699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.426156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.356023\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017771; batch adversarial loss: 0.448996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058177; batch adversarial loss: 0.411220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014598; batch adversarial loss: 0.374938\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023809; batch adversarial loss: 0.396063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017848; batch adversarial loss: 0.529327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005764; batch adversarial loss: 0.395014\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005059; batch adversarial loss: 0.442585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016724; batch adversarial loss: 0.405878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024334; batch adversarial loss: 0.359202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006897; batch adversarial loss: 0.479158\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007722; batch adversarial loss: 0.473242\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028269; batch adversarial loss: 0.322968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.561645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:50:02.788655: W tensorflow/c/c_api.cc:304] Operation '{name:'04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:4012 op device:{requested: '', assigned: ''} def:{{{node 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688715; batch adversarial loss: 0.983039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628121; batch adversarial loss: 1.100539\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900819; batch adversarial loss: 1.126426\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017392; batch adversarial loss: 1.014833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997079; batch adversarial loss: 0.934127\n",
      "epoch 5; iter: 0; batch classifier loss: 0.972972; batch adversarial loss: 0.840362\n",
      "epoch 6; iter: 0; batch classifier loss: 1.035811; batch adversarial loss: 0.765038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.989932; batch adversarial loss: 0.694059\n",
      "epoch 8; iter: 0; batch classifier loss: 1.016223; batch adversarial loss: 0.648634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.816278; batch adversarial loss: 0.583646\n",
      "epoch 10; iter: 0; batch classifier loss: 0.814806; batch adversarial loss: 0.581283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388503; batch adversarial loss: 0.534007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460209; batch adversarial loss: 0.522313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363631; batch adversarial loss: 0.483172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334066; batch adversarial loss: 0.538998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330832; batch adversarial loss: 0.503753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335103; batch adversarial loss: 0.460181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217084; batch adversarial loss: 0.449338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222560; batch adversarial loss: 0.452156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253071; batch adversarial loss: 0.532440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192251; batch adversarial loss: 0.515274\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195617; batch adversarial loss: 0.457270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.116874; batch adversarial loss: 0.416551\n",
      "epoch 23; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.418451\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130526; batch adversarial loss: 0.442453\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148387; batch adversarial loss: 0.546933\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121442; batch adversarial loss: 0.433987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.104637; batch adversarial loss: 0.486104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.091559; batch adversarial loss: 0.451715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.084214; batch adversarial loss: 0.447392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.066105; batch adversarial loss: 0.413685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.391311\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114118; batch adversarial loss: 0.363025\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084376; batch adversarial loss: 0.496647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109469; batch adversarial loss: 0.473723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130510; batch adversarial loss: 0.433919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102940; batch adversarial loss: 0.484450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109572; batch adversarial loss: 0.418393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.059485; batch adversarial loss: 0.538812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107677; batch adversarial loss: 0.465860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131476; batch adversarial loss: 0.472353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.057669; batch adversarial loss: 0.450761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082112; batch adversarial loss: 0.501039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063107; batch adversarial loss: 0.426068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101416; batch adversarial loss: 0.474336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090052; batch adversarial loss: 0.427132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081061; batch adversarial loss: 0.443573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100561; batch adversarial loss: 0.462411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082665; batch adversarial loss: 0.528099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080586; batch adversarial loss: 0.463851\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.467955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065128; batch adversarial loss: 0.363463\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065074; batch adversarial loss: 0.505935\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062227; batch adversarial loss: 0.450037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082096; batch adversarial loss: 0.483712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098301; batch adversarial loss: 0.472368\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.470020\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061266; batch adversarial loss: 0.469520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091018; batch adversarial loss: 0.460826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088777; batch adversarial loss: 0.368837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072266; batch adversarial loss: 0.417231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088821; batch adversarial loss: 0.371266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084045; batch adversarial loss: 0.388032\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099800; batch adversarial loss: 0.480330\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070695; batch adversarial loss: 0.464629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.461426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091146; batch adversarial loss: 0.408800\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106377; batch adversarial loss: 0.504875\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043170; batch adversarial loss: 0.464844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072073; batch adversarial loss: 0.433548\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.480371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057055; batch adversarial loss: 0.423309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088492; batch adversarial loss: 0.363886\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047265; batch adversarial loss: 0.382111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040557; batch adversarial loss: 0.378222\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.436483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047782; batch adversarial loss: 0.469712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.431864\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059991; batch adversarial loss: 0.420678\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064905; batch adversarial loss: 0.493314\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.376153\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050206; batch adversarial loss: 0.409281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046113; batch adversarial loss: 0.467115\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035233; batch adversarial loss: 0.469703\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029775; batch adversarial loss: 0.505177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042924; batch adversarial loss: 0.485360\n",
      "epoch 86; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.443047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.547391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.348584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.445219\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048613; batch adversarial loss: 0.498932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028670; batch adversarial loss: 0.392131\n",
      "epoch 92; iter: 0; batch classifier loss: 0.024187; batch adversarial loss: 0.528975\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032129; batch adversarial loss: 0.476735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.491378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.406544\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035445; batch adversarial loss: 0.499140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063905; batch adversarial loss: 0.452456\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.370576\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046255; batch adversarial loss: 0.461843\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.526640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037838; batch adversarial loss: 0.428831\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029502; batch adversarial loss: 0.517934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036693; batch adversarial loss: 0.479803\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.462126\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022528; batch adversarial loss: 0.480492\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051269; batch adversarial loss: 0.390230\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.428924\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042159; batch adversarial loss: 0.443559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021290; batch adversarial loss: 0.487578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023505; batch adversarial loss: 0.492512\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017535; batch adversarial loss: 0.410937\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.450347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038833; batch adversarial loss: 0.396705\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033631; batch adversarial loss: 0.478048\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033618; batch adversarial loss: 0.445996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021869; batch adversarial loss: 0.450988\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025700; batch adversarial loss: 0.489628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052874; batch adversarial loss: 0.503270\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044407; batch adversarial loss: 0.487963\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.468673\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042812; batch adversarial loss: 0.489505\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.412301\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036888; batch adversarial loss: 0.312297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.461313\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038236; batch adversarial loss: 0.519647\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039189; batch adversarial loss: 0.494202\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.501105\n",
      "epoch 128; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.499304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018803; batch adversarial loss: 0.537932\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061528; batch adversarial loss: 0.496497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.009915; batch adversarial loss: 0.458411\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034905; batch adversarial loss: 0.429200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.538931\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020050; batch adversarial loss: 0.378343\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036235; batch adversarial loss: 0.495071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033578; batch adversarial loss: 0.513097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.465550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021714; batch adversarial loss: 0.450820\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014111; batch adversarial loss: 0.409608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.388635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.446668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048083; batch adversarial loss: 0.429200\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025612; batch adversarial loss: 0.396818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.315482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024941; batch adversarial loss: 0.376494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041394; batch adversarial loss: 0.386173\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024354; batch adversarial loss: 0.495191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014848; batch adversarial loss: 0.530843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.405986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053988; batch adversarial loss: 0.362676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024418; batch adversarial loss: 0.431975\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030281; batch adversarial loss: 0.427211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.485753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040641; batch adversarial loss: 0.496311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024292; batch adversarial loss: 0.391502\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.431918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.478216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.474453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026862; batch adversarial loss: 0.497809\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.467878\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010025; batch adversarial loss: 0.482063\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.359276\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006330; batch adversarial loss: 0.433474\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029055; batch adversarial loss: 0.578649\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.478374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024393; batch adversarial loss: 0.476705\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.578530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.552534\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.532417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.422551\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.436369\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031451; batch adversarial loss: 0.428115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.416464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021471; batch adversarial loss: 0.379303\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009096; batch adversarial loss: 0.368390\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.411759\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008289; batch adversarial loss: 0.522269\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945a805",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65fce0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c49270",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb933b4632f547a3ba8301fd5364c345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fe8f8b2384482bacdbfb5f813ffc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce3377f82a7496e821f1474f8b313b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.792746; batch adversarial loss: 1.005012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.949620; batch adversarial loss: 1.258500\n",
      "epoch 2; iter: 0; batch classifier loss: 1.028043; batch adversarial loss: 1.144422\n",
      "epoch 3; iter: 0; batch classifier loss: 1.045848; batch adversarial loss: 1.075771\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997219; batch adversarial loss: 0.978551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.916257; batch adversarial loss: 0.886703\n",
      "epoch 6; iter: 0; batch classifier loss: 0.807742; batch adversarial loss: 0.777476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.756174; batch adversarial loss: 0.765084\n",
      "epoch 8; iter: 0; batch classifier loss: 0.751323; batch adversarial loss: 0.715508\n",
      "epoch 9; iter: 0; batch classifier loss: 0.661528; batch adversarial loss: 0.746465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532497; batch adversarial loss: 0.583311\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556063; batch adversarial loss: 0.609865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509892; batch adversarial loss: 0.630546\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474373; batch adversarial loss: 0.588323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566039; batch adversarial loss: 0.598633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544423; batch adversarial loss: 0.595941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478303; batch adversarial loss: 0.716907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506884; batch adversarial loss: 0.531912\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484061; batch adversarial loss: 0.641703\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484366; batch adversarial loss: 0.609042\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496752; batch adversarial loss: 0.581835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515339; batch adversarial loss: 0.610445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452971; batch adversarial loss: 0.628669\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8c3ce0",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51486d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa705dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:57:10 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5652dffefd14b5a972cdc717368bcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:57:10 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 4329,   723,  8157,  8934,  5880,  1877,  9980,  9115, 13634,\n",
      "            12168,  6957,  9083, 14260,  5349,  7879,  3078, 10032, 13643,\n",
      "            12025,  7489],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 4329,   723,  8157,  8934,  5880,  1877,  9980,  9115, 13634,\n",
      "            12168,  6957,  9083, 14260,  5349,  7879,  3078, 10032, 13643,\n",
      "            12025,  7489],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c6183c0c3140bcaa0934a0b999e03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d35ebec1a245fe9aacb7c36d602507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.699528; batch adversarial loss: 0.710668\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555086; batch adversarial loss: 0.685506\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581394; batch adversarial loss: 0.634996\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537524; batch adversarial loss: 0.650625\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619349; batch adversarial loss: 0.605039\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551424; batch adversarial loss: 0.586381\n",
      "epoch 6; iter: 0; batch classifier loss: 0.611123; batch adversarial loss: 0.622264\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546990; batch adversarial loss: 0.584881\n",
      "epoch 8; iter: 0; batch classifier loss: 0.589645; batch adversarial loss: 0.581468\n",
      "epoch 9; iter: 0; batch classifier loss: 0.638602; batch adversarial loss: 0.586711\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539493; batch adversarial loss: 0.561233\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573660; batch adversarial loss: 0.620766\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478246; batch adversarial loss: 0.572913\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524665; batch adversarial loss: 0.583921\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510056; batch adversarial loss: 0.549494\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440042; batch adversarial loss: 0.522471\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515568; batch adversarial loss: 0.624700\n",
      "epoch 17; iter: 0; batch classifier loss: 0.456414; batch adversarial loss: 0.596202\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468039; batch adversarial loss: 0.551941\n",
      "epoch 19; iter: 0; batch classifier loss: 0.588963; batch adversarial loss: 0.622344\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472940; batch adversarial loss: 0.553282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531767; batch adversarial loss: 0.553781\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494186; batch adversarial loss: 0.586699\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454862; batch adversarial loss: 0.638905\n",
      "epoch 24; iter: 0; batch classifier loss: 0.558468; batch adversarial loss: 0.572339\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519950; batch adversarial loss: 0.578008\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471012; batch adversarial loss: 0.568335\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495130; batch adversarial loss: 0.518698\n",
      "epoch 28; iter: 0; batch classifier loss: 0.577067; batch adversarial loss: 0.559142\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463840; batch adversarial loss: 0.543185\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538432; batch adversarial loss: 0.610365\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486101; batch adversarial loss: 0.562418\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458458; batch adversarial loss: 0.504120\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472366; batch adversarial loss: 0.521868\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460543; batch adversarial loss: 0.547325\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443695; batch adversarial loss: 0.592314\n",
      "epoch 36; iter: 0; batch classifier loss: 0.416417; batch adversarial loss: 0.509915\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466286; batch adversarial loss: 0.493632\n",
      "epoch 38; iter: 0; batch classifier loss: 0.514206; batch adversarial loss: 0.590079\n",
      "epoch 39; iter: 0; batch classifier loss: 0.384745; batch adversarial loss: 0.511685\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462119; batch adversarial loss: 0.519855\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449185; batch adversarial loss: 0.553870\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417311; batch adversarial loss: 0.630076\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444446; batch adversarial loss: 0.663992\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412970; batch adversarial loss: 0.578095\n",
      "epoch 45; iter: 0; batch classifier loss: 0.523870; batch adversarial loss: 0.518153\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436367; batch adversarial loss: 0.604756\n",
      "epoch 47; iter: 0; batch classifier loss: 0.494308; batch adversarial loss: 0.615119\n",
      "epoch 48; iter: 0; batch classifier loss: 0.503899; batch adversarial loss: 0.573402\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480608; batch adversarial loss: 0.552534\n",
      "epoch 50; iter: 0; batch classifier loss: 0.546660; batch adversarial loss: 0.614940\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465634; batch adversarial loss: 0.553580\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448545; batch adversarial loss: 0.536475\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395586; batch adversarial loss: 0.491850\n",
      "epoch 54; iter: 0; batch classifier loss: 0.477851; batch adversarial loss: 0.591243\n",
      "epoch 55; iter: 0; batch classifier loss: 0.544273; batch adversarial loss: 0.519048\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420716; batch adversarial loss: 0.517338\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446201; batch adversarial loss: 0.681602\n",
      "epoch 58; iter: 0; batch classifier loss: 0.486851; batch adversarial loss: 0.508389\n",
      "epoch 59; iter: 0; batch classifier loss: 0.379562; batch adversarial loss: 0.534952\n",
      "epoch 60; iter: 0; batch classifier loss: 0.375521; batch adversarial loss: 0.535354\n",
      "epoch 61; iter: 0; batch classifier loss: 0.461340; batch adversarial loss: 0.544492\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429138; batch adversarial loss: 0.627043\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439798; batch adversarial loss: 0.581025\n",
      "epoch 64; iter: 0; batch classifier loss: 0.487477; batch adversarial loss: 0.626541\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455103; batch adversarial loss: 0.517695\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451670; batch adversarial loss: 0.507940\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384668; batch adversarial loss: 0.490289\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430561; batch adversarial loss: 0.562193\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397282; batch adversarial loss: 0.544998\n",
      "epoch 70; iter: 0; batch classifier loss: 0.491351; batch adversarial loss: 0.572583\n",
      "epoch 71; iter: 0; batch classifier loss: 0.360918; batch adversarial loss: 0.562972\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430506; batch adversarial loss: 0.570767\n",
      "epoch 73; iter: 0; batch classifier loss: 0.432657; batch adversarial loss: 0.498353\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426816; batch adversarial loss: 0.516694\n",
      "epoch 75; iter: 0; batch classifier loss: 0.330186; batch adversarial loss: 0.543413\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363572; batch adversarial loss: 0.563397\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403010; batch adversarial loss: 0.534915\n",
      "epoch 78; iter: 0; batch classifier loss: 0.426167; batch adversarial loss: 0.499259\n",
      "epoch 79; iter: 0; batch classifier loss: 0.471048; batch adversarial loss: 0.526613\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435096; batch adversarial loss: 0.525628\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429883; batch adversarial loss: 0.645622\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416643; batch adversarial loss: 0.579995\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372225; batch adversarial loss: 0.527432\n",
      "epoch 84; iter: 0; batch classifier loss: 0.320630; batch adversarial loss: 0.473096\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378864; batch adversarial loss: 0.554096\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350659; batch adversarial loss: 0.534014\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360392; batch adversarial loss: 0.599530\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389511; batch adversarial loss: 0.552559\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413671; batch adversarial loss: 0.508006\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405466; batch adversarial loss: 0.617979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416877; batch adversarial loss: 0.616188\n",
      "epoch 92; iter: 0; batch classifier loss: 0.473272; batch adversarial loss: 0.581053\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385120; batch adversarial loss: 0.654625\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362678; batch adversarial loss: 0.580860\n",
      "epoch 95; iter: 0; batch classifier loss: 0.484347; batch adversarial loss: 0.536420\n",
      "epoch 96; iter: 0; batch classifier loss: 0.591472; batch adversarial loss: 0.626213\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399740; batch adversarial loss: 0.571563\n",
      "epoch 98; iter: 0; batch classifier loss: 0.477363; batch adversarial loss: 0.572943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.372579; batch adversarial loss: 0.626288\n",
      "epoch 100; iter: 0; batch classifier loss: 0.438383; batch adversarial loss: 0.616931\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355314; batch adversarial loss: 0.553953\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345900; batch adversarial loss: 0.507714\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419574; batch adversarial loss: 0.553179\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385073; batch adversarial loss: 0.589766\n",
      "epoch 105; iter: 0; batch classifier loss: 0.420337; batch adversarial loss: 0.526981\n",
      "epoch 106; iter: 0; batch classifier loss: 0.481834; batch adversarial loss: 0.571915\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366614; batch adversarial loss: 0.571807\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404646; batch adversarial loss: 0.533876\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344137; batch adversarial loss: 0.571365\n",
      "epoch 110; iter: 0; batch classifier loss: 0.419557; batch adversarial loss: 0.499482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.458764; batch adversarial loss: 0.545366\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363988; batch adversarial loss: 0.570013\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380439; batch adversarial loss: 0.536745\n",
      "epoch 114; iter: 0; batch classifier loss: 0.435983; batch adversarial loss: 0.545233\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409667; batch adversarial loss: 0.516958\n",
      "epoch 116; iter: 0; batch classifier loss: 0.374902; batch adversarial loss: 0.544477\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400778; batch adversarial loss: 0.527241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356613; batch adversarial loss: 0.553668\n",
      "epoch 119; iter: 0; batch classifier loss: 0.412754; batch adversarial loss: 0.526742\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399397; batch adversarial loss: 0.490966\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368083; batch adversarial loss: 0.534434\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379409; batch adversarial loss: 0.581287\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377588; batch adversarial loss: 0.562746\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387683; batch adversarial loss: 0.554599\n",
      "epoch 125; iter: 0; batch classifier loss: 0.475557; batch adversarial loss: 0.462040\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384885; batch adversarial loss: 0.617543\n",
      "epoch 127; iter: 0; batch classifier loss: 0.441406; batch adversarial loss: 0.571238\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409795; batch adversarial loss: 0.563528\n",
      "epoch 129; iter: 0; batch classifier loss: 0.478830; batch adversarial loss: 0.608602\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394687; batch adversarial loss: 0.544030\n",
      "epoch 131; iter: 0; batch classifier loss: 0.482882; batch adversarial loss: 0.562500\n",
      "epoch 132; iter: 0; batch classifier loss: 0.386613; batch adversarial loss: 0.534627\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377706; batch adversarial loss: 0.589827\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381894; batch adversarial loss: 0.508312\n",
      "epoch 135; iter: 0; batch classifier loss: 0.327034; batch adversarial loss: 0.516798\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421908; batch adversarial loss: 0.481454\n",
      "epoch 137; iter: 0; batch classifier loss: 0.420584; batch adversarial loss: 0.572305\n",
      "epoch 138; iter: 0; batch classifier loss: 0.437805; batch adversarial loss: 0.598826\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343660; batch adversarial loss: 0.571004\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358739; batch adversarial loss: 0.626871\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375721; batch adversarial loss: 0.462823\n",
      "epoch 142; iter: 0; batch classifier loss: 0.401585; batch adversarial loss: 0.506115\n",
      "epoch 143; iter: 0; batch classifier loss: 0.407016; batch adversarial loss: 0.489188\n",
      "epoch 144; iter: 0; batch classifier loss: 0.364963; batch adversarial loss: 0.481426\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376983; batch adversarial loss: 0.499332\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371150; batch adversarial loss: 0.490863\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363522; batch adversarial loss: 0.498539\n",
      "epoch 148; iter: 0; batch classifier loss: 0.453799; batch adversarial loss: 0.517191\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379686; batch adversarial loss: 0.580683\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381490; batch adversarial loss: 0.454090\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345041; batch adversarial loss: 0.544311\n",
      "epoch 152; iter: 0; batch classifier loss: 0.404593; batch adversarial loss: 0.536659\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339878; batch adversarial loss: 0.499470\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345380; batch adversarial loss: 0.501501\n",
      "epoch 155; iter: 0; batch classifier loss: 0.384537; batch adversarial loss: 0.570681\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351798; batch adversarial loss: 0.651778\n",
      "epoch 157; iter: 0; batch classifier loss: 0.380225; batch adversarial loss: 0.506948\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320514; batch adversarial loss: 0.534915\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361854; batch adversarial loss: 0.525480\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360921; batch adversarial loss: 0.453543\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350217; batch adversarial loss: 0.516800\n",
      "epoch 162; iter: 0; batch classifier loss: 0.295755; batch adversarial loss: 0.561991\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330438; batch adversarial loss: 0.481262\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346533; batch adversarial loss: 0.506889\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355293; batch adversarial loss: 0.501112\n",
      "epoch 166; iter: 0; batch classifier loss: 0.392788; batch adversarial loss: 0.491595\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394108; batch adversarial loss: 0.563432\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331629; batch adversarial loss: 0.536956\n",
      "epoch 169; iter: 0; batch classifier loss: 0.383283; batch adversarial loss: 0.508374\n",
      "epoch 170; iter: 0; batch classifier loss: 0.394778; batch adversarial loss: 0.589195\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363078; batch adversarial loss: 0.598794\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392018; batch adversarial loss: 0.571620\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369021; batch adversarial loss: 0.562419\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385547; batch adversarial loss: 0.616299\n",
      "epoch 175; iter: 0; batch classifier loss: 0.317507; batch adversarial loss: 0.545137\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358884; batch adversarial loss: 0.607760\n",
      "epoch 177; iter: 0; batch classifier loss: 0.426131; batch adversarial loss: 0.580760\n",
      "epoch 178; iter: 0; batch classifier loss: 0.430308; batch adversarial loss: 0.527814\n",
      "epoch 179; iter: 0; batch classifier loss: 0.414080; batch adversarial loss: 0.579273\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333205; batch adversarial loss: 0.616799\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354659; batch adversarial loss: 0.599115\n",
      "epoch 182; iter: 0; batch classifier loss: 0.427725; batch adversarial loss: 0.589756\n",
      "epoch 183; iter: 0; batch classifier loss: 0.408287; batch adversarial loss: 0.616097\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376354; batch adversarial loss: 0.535675\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390730; batch adversarial loss: 0.517757\n",
      "epoch 186; iter: 0; batch classifier loss: 0.344588; batch adversarial loss: 0.543689\n",
      "epoch 187; iter: 0; batch classifier loss: 0.379027; batch adversarial loss: 0.479872\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404042; batch adversarial loss: 0.589279\n",
      "epoch 189; iter: 0; batch classifier loss: 0.411542; batch adversarial loss: 0.563170\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357683; batch adversarial loss: 0.561714\n",
      "epoch 191; iter: 0; batch classifier loss: 0.384780; batch adversarial loss: 0.516818\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306794; batch adversarial loss: 0.546474\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376903; batch adversarial loss: 0.571885\n",
      "epoch 194; iter: 0; batch classifier loss: 0.421551; batch adversarial loss: 0.570818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.455091; batch adversarial loss: 0.498312\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332596; batch adversarial loss: 0.544225\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356793; batch adversarial loss: 0.599101\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336114; batch adversarial loss: 0.661576\n",
      "epoch 199; iter: 0; batch classifier loss: 0.439557; batch adversarial loss: 0.526020\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698596; batch adversarial loss: 0.679559\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571863; batch adversarial loss: 0.664595\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625800; batch adversarial loss: 0.627086\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615154; batch adversarial loss: 0.607033\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576993; batch adversarial loss: 0.626256\n",
      "epoch 5; iter: 0; batch classifier loss: 0.626169; batch adversarial loss: 0.606369\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563685; batch adversarial loss: 0.564432\n",
      "epoch 7; iter: 0; batch classifier loss: 0.451780; batch adversarial loss: 0.572738\n",
      "epoch 8; iter: 0; batch classifier loss: 0.606483; batch adversarial loss: 0.558420\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508884; batch adversarial loss: 0.573710\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535823; batch adversarial loss: 0.519897\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504623; batch adversarial loss: 0.589420\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533548; batch adversarial loss: 0.616497\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465981; batch adversarial loss: 0.583455\n",
      "epoch 14; iter: 0; batch classifier loss: 0.562144; batch adversarial loss: 0.574170\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537902; batch adversarial loss: 0.613603\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552497; batch adversarial loss: 0.589793\n",
      "epoch 17; iter: 0; batch classifier loss: 0.458277; batch adversarial loss: 0.588324\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479700; batch adversarial loss: 0.574453\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501397; batch adversarial loss: 0.608298\n",
      "epoch 20; iter: 0; batch classifier loss: 0.542205; batch adversarial loss: 0.575257\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532291; batch adversarial loss: 0.558698\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531502; batch adversarial loss: 0.608449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457286; batch adversarial loss: 0.548655\n",
      "epoch 24; iter: 0; batch classifier loss: 0.536392; batch adversarial loss: 0.540372\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436579; batch adversarial loss: 0.621408\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482769; batch adversarial loss: 0.505722\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460133; batch adversarial loss: 0.548098\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440183; batch adversarial loss: 0.496613\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455671; batch adversarial loss: 0.510820\n",
      "epoch 30; iter: 0; batch classifier loss: 0.411330; batch adversarial loss: 0.545943\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449256; batch adversarial loss: 0.511013\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433439; batch adversarial loss: 0.501456\n",
      "epoch 33; iter: 0; batch classifier loss: 0.493995; batch adversarial loss: 0.554260\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431900; batch adversarial loss: 0.527362\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486876; batch adversarial loss: 0.616038\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444313; batch adversarial loss: 0.455083\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446898; batch adversarial loss: 0.580493\n",
      "epoch 38; iter: 0; batch classifier loss: 0.410038; batch adversarial loss: 0.571838\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441877; batch adversarial loss: 0.535617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423189; batch adversarial loss: 0.607767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435124; batch adversarial loss: 0.544566\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450411; batch adversarial loss: 0.580615\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483230; batch adversarial loss: 0.481855\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429285; batch adversarial loss: 0.508394\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456844; batch adversarial loss: 0.544864\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446814; batch adversarial loss: 0.517543\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433922; batch adversarial loss: 0.562822\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431941; batch adversarial loss: 0.526410\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410133; batch adversarial loss: 0.562710\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434456; batch adversarial loss: 0.563103\n",
      "epoch 51; iter: 0; batch classifier loss: 0.492132; batch adversarial loss: 0.562181\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424372; batch adversarial loss: 0.581225\n",
      "epoch 53; iter: 0; batch classifier loss: 0.369321; batch adversarial loss: 0.653098\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402900; batch adversarial loss: 0.553671\n",
      "epoch 55; iter: 0; batch classifier loss: 0.496103; batch adversarial loss: 0.553148\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441149; batch adversarial loss: 0.569088\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430472; batch adversarial loss: 0.579853\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408498; batch adversarial loss: 0.515465\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424742; batch adversarial loss: 0.626519\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423804; batch adversarial loss: 0.572139\n",
      "epoch 61; iter: 0; batch classifier loss: 0.469922; batch adversarial loss: 0.562470\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428564; batch adversarial loss: 0.604019\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447985; batch adversarial loss: 0.616741\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369128; batch adversarial loss: 0.498415\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443503; batch adversarial loss: 0.479993\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382904; batch adversarial loss: 0.592518\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399124; batch adversarial loss: 0.582174\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408131; batch adversarial loss: 0.526024\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397930; batch adversarial loss: 0.544649\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377384; batch adversarial loss: 0.544314\n",
      "epoch 71; iter: 0; batch classifier loss: 0.503189; batch adversarial loss: 0.553701\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413696; batch adversarial loss: 0.571649\n",
      "epoch 73; iter: 0; batch classifier loss: 0.461177; batch adversarial loss: 0.489712\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443076; batch adversarial loss: 0.499361\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401317; batch adversarial loss: 0.590522\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418544; batch adversarial loss: 0.644233\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371550; batch adversarial loss: 0.480930\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394021; batch adversarial loss: 0.553751\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385884; batch adversarial loss: 0.499846\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365253; batch adversarial loss: 0.663335\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434640; batch adversarial loss: 0.526248\n",
      "epoch 82; iter: 0; batch classifier loss: 0.490708; batch adversarial loss: 0.552497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398542; batch adversarial loss: 0.527619\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396029; batch adversarial loss: 0.561882\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435579; batch adversarial loss: 0.553860\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371671; batch adversarial loss: 0.470436\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386352; batch adversarial loss: 0.526499\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431995; batch adversarial loss: 0.554405\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390726; batch adversarial loss: 0.508621\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395574; batch adversarial loss: 0.570154\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349613; batch adversarial loss: 0.553709\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366731; batch adversarial loss: 0.489858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.345513; batch adversarial loss: 0.598256\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377577; batch adversarial loss: 0.544192\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417893; batch adversarial loss: 0.471501\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345795; batch adversarial loss: 0.480565\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388471; batch adversarial loss: 0.580145\n",
      "epoch 98; iter: 0; batch classifier loss: 0.360978; batch adversarial loss: 0.563947\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387779; batch adversarial loss: 0.516488\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396406; batch adversarial loss: 0.654159\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396159; batch adversarial loss: 0.489775\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383455; batch adversarial loss: 0.644561\n",
      "epoch 103; iter: 0; batch classifier loss: 0.299459; batch adversarial loss: 0.644572\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419146; batch adversarial loss: 0.609331\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411201; batch adversarial loss: 0.498176\n",
      "epoch 106; iter: 0; batch classifier loss: 0.442526; batch adversarial loss: 0.562635\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412568; batch adversarial loss: 0.654485\n",
      "epoch 108; iter: 0; batch classifier loss: 0.360782; batch adversarial loss: 0.535618\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422932; batch adversarial loss: 0.517537\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359705; batch adversarial loss: 0.589161\n",
      "epoch 111; iter: 0; batch classifier loss: 0.329464; batch adversarial loss: 0.480162\n",
      "epoch 112; iter: 0; batch classifier loss: 0.278724; batch adversarial loss: 0.599265\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373738; batch adversarial loss: 0.517235\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352389; batch adversarial loss: 0.553369\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371814; batch adversarial loss: 0.546184\n",
      "epoch 116; iter: 0; batch classifier loss: 0.424958; batch adversarial loss: 0.507940\n",
      "epoch 117; iter: 0; batch classifier loss: 0.403403; batch adversarial loss: 0.498458\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341587; batch adversarial loss: 0.534564\n",
      "epoch 119; iter: 0; batch classifier loss: 0.332326; batch adversarial loss: 0.499475\n",
      "epoch 120; iter: 0; batch classifier loss: 0.389551; batch adversarial loss: 0.526767\n",
      "epoch 121; iter: 0; batch classifier loss: 0.465224; batch adversarial loss: 0.489762\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418292; batch adversarial loss: 0.609016\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351694; batch adversarial loss: 0.516060\n",
      "epoch 124; iter: 0; batch classifier loss: 0.355906; batch adversarial loss: 0.590323\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346326; batch adversarial loss: 0.562980\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314259; batch adversarial loss: 0.580949\n",
      "epoch 127; iter: 0; batch classifier loss: 0.351572; batch adversarial loss: 0.526231\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338094; batch adversarial loss: 0.571838\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427760; batch adversarial loss: 0.480556\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390198; batch adversarial loss: 0.526721\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392888; batch adversarial loss: 0.563907\n",
      "epoch 132; iter: 0; batch classifier loss: 0.409077; batch adversarial loss: 0.617086\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392616; batch adversarial loss: 0.472645\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394056; batch adversarial loss: 0.508768\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382189; batch adversarial loss: 0.589994\n",
      "epoch 136; iter: 0; batch classifier loss: 0.452074; batch adversarial loss: 0.518849\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332141; batch adversarial loss: 0.617365\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373240; batch adversarial loss: 0.516810\n",
      "epoch 139; iter: 0; batch classifier loss: 0.317811; batch adversarial loss: 0.480415\n",
      "epoch 140; iter: 0; batch classifier loss: 0.369480; batch adversarial loss: 0.590654\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399616; batch adversarial loss: 0.652351\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367573; batch adversarial loss: 0.572056\n",
      "epoch 143; iter: 0; batch classifier loss: 0.317207; batch adversarial loss: 0.591187\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348047; batch adversarial loss: 0.535738\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338586; batch adversarial loss: 0.600290\n",
      "epoch 146; iter: 0; batch classifier loss: 0.464951; batch adversarial loss: 0.534633\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362904; batch adversarial loss: 0.527071\n",
      "epoch 148; iter: 0; batch classifier loss: 0.414569; batch adversarial loss: 0.506369\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377889; batch adversarial loss: 0.490004\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394762; batch adversarial loss: 0.527764\n",
      "epoch 151; iter: 0; batch classifier loss: 0.388206; batch adversarial loss: 0.608540\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368497; batch adversarial loss: 0.546059\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402615; batch adversarial loss: 0.563039\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390538; batch adversarial loss: 0.571221\n",
      "epoch 155; iter: 0; batch classifier loss: 0.426402; batch adversarial loss: 0.534953\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404719; batch adversarial loss: 0.489383\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319382; batch adversarial loss: 0.508586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.410053; batch adversarial loss: 0.479618\n",
      "epoch 159; iter: 0; batch classifier loss: 0.512847; batch adversarial loss: 0.553965\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370769; batch adversarial loss: 0.527722\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400512; batch adversarial loss: 0.535030\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351290; batch adversarial loss: 0.498862\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338720; batch adversarial loss: 0.553023\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380355; batch adversarial loss: 0.619610\n",
      "epoch 165; iter: 0; batch classifier loss: 0.422927; batch adversarial loss: 0.546209\n",
      "epoch 166; iter: 0; batch classifier loss: 0.291534; batch adversarial loss: 0.544871\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374640; batch adversarial loss: 0.472973\n",
      "epoch 168; iter: 0; batch classifier loss: 0.290605; batch adversarial loss: 0.488945\n",
      "epoch 169; iter: 0; batch classifier loss: 0.446789; batch adversarial loss: 0.599737\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349497; batch adversarial loss: 0.542980\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408588; batch adversarial loss: 0.554209\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372948; batch adversarial loss: 0.535100\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410853; batch adversarial loss: 0.535323\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350623; batch adversarial loss: 0.542766\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376496; batch adversarial loss: 0.543184\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319750; batch adversarial loss: 0.553817\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376365; batch adversarial loss: 0.517980\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353252; batch adversarial loss: 0.497118\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377924; batch adversarial loss: 0.607884\n",
      "epoch 180; iter: 0; batch classifier loss: 0.416486; batch adversarial loss: 0.543096\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332385; batch adversarial loss: 0.581586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355963; batch adversarial loss: 0.534697\n",
      "epoch 183; iter: 0; batch classifier loss: 0.334650; batch adversarial loss: 0.633648\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401737; batch adversarial loss: 0.553813\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352203; batch adversarial loss: 0.562581\n",
      "epoch 186; iter: 0; batch classifier loss: 0.406030; batch adversarial loss: 0.552611\n",
      "epoch 187; iter: 0; batch classifier loss: 0.316013; batch adversarial loss: 0.607841\n",
      "epoch 188; iter: 0; batch classifier loss: 0.315966; batch adversarial loss: 0.534384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.348378; batch adversarial loss: 0.563731\n",
      "epoch 190; iter: 0; batch classifier loss: 0.421612; batch adversarial loss: 0.526859\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364668; batch adversarial loss: 0.553964\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378506; batch adversarial loss: 0.544193\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361050; batch adversarial loss: 0.553638\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342759; batch adversarial loss: 0.599936\n",
      "epoch 195; iter: 0; batch classifier loss: 0.459827; batch adversarial loss: 0.499966\n",
      "epoch 196; iter: 0; batch classifier loss: 0.397784; batch adversarial loss: 0.516505\n",
      "epoch 197; iter: 0; batch classifier loss: 0.435784; batch adversarial loss: 0.508098\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381643; batch adversarial loss: 0.489654\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309566; batch adversarial loss: 0.544954\n",
      "epoch 0; iter: 0; batch classifier loss: 0.778333; batch adversarial loss: 0.777658\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597652; batch adversarial loss: 0.688671\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578232; batch adversarial loss: 0.687046\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547523; batch adversarial loss: 0.664002\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577149; batch adversarial loss: 0.641754\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577497; batch adversarial loss: 0.593946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512811; batch adversarial loss: 0.599185\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497401; batch adversarial loss: 0.634562\n",
      "epoch 8; iter: 0; batch classifier loss: 0.492691; batch adversarial loss: 0.568808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484642; batch adversarial loss: 0.557430\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468892; batch adversarial loss: 0.535472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533898; batch adversarial loss: 0.578792\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474113; batch adversarial loss: 0.558057\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522671; batch adversarial loss: 0.596057\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493334; batch adversarial loss: 0.631357\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520977; batch adversarial loss: 0.632675\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463427; batch adversarial loss: 0.513496\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509330; batch adversarial loss: 0.616536\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502757; batch adversarial loss: 0.584578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497187; batch adversarial loss: 0.590309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487647; batch adversarial loss: 0.609221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463097; batch adversarial loss: 0.617589\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446760; batch adversarial loss: 0.560349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502799; batch adversarial loss: 0.592522\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466299; batch adversarial loss: 0.522438\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496617; batch adversarial loss: 0.583888\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497205; batch adversarial loss: 0.603417\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446608; batch adversarial loss: 0.561411\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465088; batch adversarial loss: 0.591907\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459919; batch adversarial loss: 0.573985\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397072; batch adversarial loss: 0.580724\n",
      "epoch 31; iter: 0; batch classifier loss: 0.532639; batch adversarial loss: 0.565790\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485359; batch adversarial loss: 0.474968\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486724; batch adversarial loss: 0.563598\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463142; batch adversarial loss: 0.530019\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405837; batch adversarial loss: 0.513077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.394993; batch adversarial loss: 0.546572\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497796; batch adversarial loss: 0.528907\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492563; batch adversarial loss: 0.545678\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429051; batch adversarial loss: 0.494549\n",
      "epoch 40; iter: 0; batch classifier loss: 0.387442; batch adversarial loss: 0.545249\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443415; batch adversarial loss: 0.544525\n",
      "epoch 42; iter: 0; batch classifier loss: 0.519699; batch adversarial loss: 0.518870\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495773; batch adversarial loss: 0.571366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433354; batch adversarial loss: 0.570745\n",
      "epoch 45; iter: 0; batch classifier loss: 0.339501; batch adversarial loss: 0.587744\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436350; batch adversarial loss: 0.509692\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465455; batch adversarial loss: 0.563105\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445147; batch adversarial loss: 0.464811\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463778; batch adversarial loss: 0.553620\n",
      "epoch 50; iter: 0; batch classifier loss: 0.497962; batch adversarial loss: 0.571719\n",
      "epoch 51; iter: 0; batch classifier loss: 0.326986; batch adversarial loss: 0.438975\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458108; batch adversarial loss: 0.544962\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406457; batch adversarial loss: 0.527639\n",
      "epoch 54; iter: 0; batch classifier loss: 0.396599; batch adversarial loss: 0.606310\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462003; batch adversarial loss: 0.571413\n",
      "epoch 56; iter: 0; batch classifier loss: 0.508340; batch adversarial loss: 0.553749\n",
      "epoch 57; iter: 0; batch classifier loss: 0.447541; batch adversarial loss: 0.491066\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417817; batch adversarial loss: 0.563160\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452502; batch adversarial loss: 0.588556\n",
      "epoch 60; iter: 0; batch classifier loss: 0.415974; batch adversarial loss: 0.536215\n",
      "epoch 61; iter: 0; batch classifier loss: 0.437764; batch adversarial loss: 0.501289\n",
      "epoch 62; iter: 0; batch classifier loss: 0.420563; batch adversarial loss: 0.527331\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403226; batch adversarial loss: 0.588126\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376510; batch adversarial loss: 0.551959\n",
      "epoch 65; iter: 0; batch classifier loss: 0.526616; batch adversarial loss: 0.612986\n",
      "epoch 66; iter: 0; batch classifier loss: 0.358903; batch adversarial loss: 0.572110\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441029; batch adversarial loss: 0.605163\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447628; batch adversarial loss: 0.625238\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411788; batch adversarial loss: 0.528009\n",
      "epoch 70; iter: 0; batch classifier loss: 0.440640; batch adversarial loss: 0.563735\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404285; batch adversarial loss: 0.527046\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403265; batch adversarial loss: 0.553361\n",
      "epoch 73; iter: 0; batch classifier loss: 0.516165; batch adversarial loss: 0.598627\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471443; batch adversarial loss: 0.553521\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448118; batch adversarial loss: 0.526534\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419451; batch adversarial loss: 0.580444\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382536; batch adversarial loss: 0.534519\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444751; batch adversarial loss: 0.535776\n",
      "epoch 79; iter: 0; batch classifier loss: 0.344910; batch adversarial loss: 0.616279\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350854; batch adversarial loss: 0.598149\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371696; batch adversarial loss: 0.525162\n",
      "epoch 82; iter: 0; batch classifier loss: 0.522033; batch adversarial loss: 0.527273\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446356; batch adversarial loss: 0.534892\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421526; batch adversarial loss: 0.588778\n",
      "epoch 85; iter: 0; batch classifier loss: 0.505881; batch adversarial loss: 0.554793\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390095; batch adversarial loss: 0.546205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.358454; batch adversarial loss: 0.640934\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372351; batch adversarial loss: 0.597251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376114; batch adversarial loss: 0.597062\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391576; batch adversarial loss: 0.518710\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404018; batch adversarial loss: 0.579915\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392410; batch adversarial loss: 0.571662\n",
      "epoch 93; iter: 0; batch classifier loss: 0.414752; batch adversarial loss: 0.571194\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435539; batch adversarial loss: 0.588858\n",
      "epoch 95; iter: 0; batch classifier loss: 0.455047; batch adversarial loss: 0.509732\n",
      "epoch 96; iter: 0; batch classifier loss: 0.280245; batch adversarial loss: 0.571539\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396916; batch adversarial loss: 0.588816\n",
      "epoch 98; iter: 0; batch classifier loss: 0.452221; batch adversarial loss: 0.544861\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392004; batch adversarial loss: 0.492876\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373731; batch adversarial loss: 0.580332\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335111; batch adversarial loss: 0.491888\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345731; batch adversarial loss: 0.562389\n",
      "epoch 103; iter: 0; batch classifier loss: 0.439491; batch adversarial loss: 0.526868\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400321; batch adversarial loss: 0.571126\n",
      "epoch 105; iter: 0; batch classifier loss: 0.434343; batch adversarial loss: 0.579948\n",
      "epoch 106; iter: 0; batch classifier loss: 0.501836; batch adversarial loss: 0.614998\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331135; batch adversarial loss: 0.605969\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369651; batch adversarial loss: 0.500817\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415820; batch adversarial loss: 0.588297\n",
      "epoch 110; iter: 0; batch classifier loss: 0.464999; batch adversarial loss: 0.580697\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378659; batch adversarial loss: 0.615288\n",
      "epoch 112; iter: 0; batch classifier loss: 0.455049; batch adversarial loss: 0.536081\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421379; batch adversarial loss: 0.596799\n",
      "epoch 114; iter: 0; batch classifier loss: 0.423460; batch adversarial loss: 0.499566\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367828; batch adversarial loss: 0.615123\n",
      "epoch 116; iter: 0; batch classifier loss: 0.404429; batch adversarial loss: 0.554224\n",
      "epoch 117; iter: 0; batch classifier loss: 0.343116; batch adversarial loss: 0.571439\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406054; batch adversarial loss: 0.553736\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386557; batch adversarial loss: 0.535841\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388762; batch adversarial loss: 0.526989\n",
      "epoch 121; iter: 0; batch classifier loss: 0.459016; batch adversarial loss: 0.606858\n",
      "epoch 122; iter: 0; batch classifier loss: 0.491106; batch adversarial loss: 0.544409\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414829; batch adversarial loss: 0.686451\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351266; batch adversarial loss: 0.501000\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402528; batch adversarial loss: 0.509487\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400174; batch adversarial loss: 0.536020\n",
      "epoch 127; iter: 0; batch classifier loss: 0.424386; batch adversarial loss: 0.571381\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372768; batch adversarial loss: 0.518533\n",
      "epoch 129; iter: 0; batch classifier loss: 0.326583; batch adversarial loss: 0.500299\n",
      "epoch 130; iter: 0; batch classifier loss: 0.467724; batch adversarial loss: 0.562760\n",
      "epoch 131; iter: 0; batch classifier loss: 0.346627; batch adversarial loss: 0.589339\n",
      "epoch 132; iter: 0; batch classifier loss: 0.420996; batch adversarial loss: 0.606692\n",
      "epoch 133; iter: 0; batch classifier loss: 0.436599; batch adversarial loss: 0.570039\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355685; batch adversarial loss: 0.517366\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354495; batch adversarial loss: 0.561429\n",
      "epoch 136; iter: 0; batch classifier loss: 0.298042; batch adversarial loss: 0.570921\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383321; batch adversarial loss: 0.578241\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345579; batch adversarial loss: 0.535115\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357669; batch adversarial loss: 0.591228\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361355; batch adversarial loss: 0.571173\n",
      "epoch 141; iter: 0; batch classifier loss: 0.354484; batch adversarial loss: 0.517649\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375706; batch adversarial loss: 0.590287\n",
      "epoch 143; iter: 0; batch classifier loss: 0.409267; batch adversarial loss: 0.642213\n",
      "epoch 144; iter: 0; batch classifier loss: 0.301515; batch adversarial loss: 0.624837\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391057; batch adversarial loss: 0.501855\n",
      "epoch 146; iter: 0; batch classifier loss: 0.320759; batch adversarial loss: 0.588075\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374059; batch adversarial loss: 0.527458\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344835; batch adversarial loss: 0.570859\n",
      "epoch 149; iter: 0; batch classifier loss: 0.420827; batch adversarial loss: 0.466545\n",
      "epoch 150; iter: 0; batch classifier loss: 0.401333; batch adversarial loss: 0.597553\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382303; batch adversarial loss: 0.518800\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385626; batch adversarial loss: 0.649788\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350726; batch adversarial loss: 0.527350\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400544; batch adversarial loss: 0.553617\n",
      "epoch 155; iter: 0; batch classifier loss: 0.427476; batch adversarial loss: 0.614831\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319219; batch adversarial loss: 0.561188\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346613; batch adversarial loss: 0.571186\n",
      "epoch 158; iter: 0; batch classifier loss: 0.309342; batch adversarial loss: 0.554205\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400111; batch adversarial loss: 0.544766\n",
      "epoch 160; iter: 0; batch classifier loss: 0.408365; batch adversarial loss: 0.500806\n",
      "epoch 161; iter: 0; batch classifier loss: 0.317355; batch adversarial loss: 0.579311\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353556; batch adversarial loss: 0.606243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.436706; batch adversarial loss: 0.561562\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366450; batch adversarial loss: 0.465487\n",
      "epoch 165; iter: 0; batch classifier loss: 0.457345; batch adversarial loss: 0.517960\n",
      "epoch 166; iter: 0; batch classifier loss: 0.425513; batch adversarial loss: 0.500075\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397308; batch adversarial loss: 0.544495\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380227; batch adversarial loss: 0.561930\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334457; batch adversarial loss: 0.553629\n",
      "epoch 170; iter: 0; batch classifier loss: 0.296421; batch adversarial loss: 0.544703\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380368; batch adversarial loss: 0.553655\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381739; batch adversarial loss: 0.544819\n",
      "epoch 173; iter: 0; batch classifier loss: 0.393479; batch adversarial loss: 0.562410\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395086; batch adversarial loss: 0.553856\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336181; batch adversarial loss: 0.624466\n",
      "epoch 176; iter: 0; batch classifier loss: 0.421329; batch adversarial loss: 0.571204\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391241; batch adversarial loss: 0.500813\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407464; batch adversarial loss: 0.509505\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384960; batch adversarial loss: 0.597796\n",
      "epoch 180; iter: 0; batch classifier loss: 0.399482; batch adversarial loss: 0.562499\n",
      "epoch 181; iter: 0; batch classifier loss: 0.389945; batch adversarial loss: 0.500170\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387981; batch adversarial loss: 0.606286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.310785; batch adversarial loss: 0.588993\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339064; batch adversarial loss: 0.589009\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326328; batch adversarial loss: 0.580553\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407085; batch adversarial loss: 0.597349\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358313; batch adversarial loss: 0.564726\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345527; batch adversarial loss: 0.554116\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305286; batch adversarial loss: 0.484668\n",
      "epoch 190; iter: 0; batch classifier loss: 0.325370; batch adversarial loss: 0.641091\n",
      "epoch 191; iter: 0; batch classifier loss: 0.414972; batch adversarial loss: 0.551690\n",
      "epoch 192; iter: 0; batch classifier loss: 0.451633; batch adversarial loss: 0.588726\n",
      "epoch 193; iter: 0; batch classifier loss: 0.346033; batch adversarial loss: 0.652102\n",
      "epoch 194; iter: 0; batch classifier loss: 0.296512; batch adversarial loss: 0.570743\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351032; batch adversarial loss: 0.623462\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370056; batch adversarial loss: 0.518586\n",
      "epoch 197; iter: 0; batch classifier loss: 0.402575; batch adversarial loss: 0.588871\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360993; batch adversarial loss: 0.526781\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358820; batch adversarial loss: 0.482849\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700817; batch adversarial loss: 0.764274\n",
      "epoch 1; iter: 0; batch classifier loss: 0.650075; batch adversarial loss: 0.754672\n",
      "epoch 2; iter: 0; batch classifier loss: 0.554804; batch adversarial loss: 0.733887\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530430; batch adversarial loss: 0.676196\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569838; batch adversarial loss: 0.661879\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530186; batch adversarial loss: 0.645740\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482599; batch adversarial loss: 0.624113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516188; batch adversarial loss: 0.603737\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562535; batch adversarial loss: 0.605584\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521474; batch adversarial loss: 0.578730\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584533; batch adversarial loss: 0.620045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.510451; batch adversarial loss: 0.605119\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501751; batch adversarial loss: 0.570422\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529233; batch adversarial loss: 0.564264\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523807; batch adversarial loss: 0.512719\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522626; batch adversarial loss: 0.506413\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485638; batch adversarial loss: 0.526241\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507008; batch adversarial loss: 0.583429\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493417; batch adversarial loss: 0.512894\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447303; batch adversarial loss: 0.599699\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504007; batch adversarial loss: 0.570188\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486698; batch adversarial loss: 0.549296\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526873; batch adversarial loss: 0.505014\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479110; batch adversarial loss: 0.521798\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460571; batch adversarial loss: 0.548113\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483748; batch adversarial loss: 0.602049\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514300; batch adversarial loss: 0.563258\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444387; batch adversarial loss: 0.499657\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432129; batch adversarial loss: 0.544564\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464346; batch adversarial loss: 0.566257\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486743; batch adversarial loss: 0.522524\n",
      "epoch 31; iter: 0; batch classifier loss: 0.386795; batch adversarial loss: 0.601691\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447853; batch adversarial loss: 0.519550\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448071; batch adversarial loss: 0.564909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497498; batch adversarial loss: 0.552093\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465995; batch adversarial loss: 0.510835\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445356; batch adversarial loss: 0.565929\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508526; batch adversarial loss: 0.527786\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454289; batch adversarial loss: 0.640970\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476009; batch adversarial loss: 0.565023\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459147; batch adversarial loss: 0.528086\n",
      "epoch 41; iter: 0; batch classifier loss: 0.491525; batch adversarial loss: 0.553128\n",
      "epoch 42; iter: 0; batch classifier loss: 0.503261; batch adversarial loss: 0.501049\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390162; batch adversarial loss: 0.590330\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488533; batch adversarial loss: 0.508143\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464384; batch adversarial loss: 0.538664\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410742; batch adversarial loss: 0.498459\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461802; batch adversarial loss: 0.571642\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424954; batch adversarial loss: 0.436714\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418159; batch adversarial loss: 0.518185\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454372; batch adversarial loss: 0.563174\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399672; batch adversarial loss: 0.570845\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520271; batch adversarial loss: 0.561949\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413738; batch adversarial loss: 0.543165\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447931; batch adversarial loss: 0.608819\n",
      "epoch 55; iter: 0; batch classifier loss: 0.524195; batch adversarial loss: 0.636001\n",
      "epoch 56; iter: 0; batch classifier loss: 0.510288; batch adversarial loss: 0.563281\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456077; batch adversarial loss: 0.488145\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455358; batch adversarial loss: 0.498849\n",
      "epoch 59; iter: 0; batch classifier loss: 0.488325; batch adversarial loss: 0.525326\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421176; batch adversarial loss: 0.555322\n",
      "epoch 61; iter: 0; batch classifier loss: 0.350089; batch adversarial loss: 0.517259\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446193; batch adversarial loss: 0.514407\n",
      "epoch 63; iter: 0; batch classifier loss: 0.440306; batch adversarial loss: 0.546733\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435757; batch adversarial loss: 0.535132\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433038; batch adversarial loss: 0.522992\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452687; batch adversarial loss: 0.551803\n",
      "epoch 67; iter: 0; batch classifier loss: 0.330983; batch adversarial loss: 0.535001\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426175; batch adversarial loss: 0.506097\n",
      "epoch 69; iter: 0; batch classifier loss: 0.466821; batch adversarial loss: 0.571838\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418801; batch adversarial loss: 0.510668\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419589; batch adversarial loss: 0.562059\n",
      "epoch 72; iter: 0; batch classifier loss: 0.354973; batch adversarial loss: 0.492162\n",
      "epoch 73; iter: 0; batch classifier loss: 0.460172; batch adversarial loss: 0.575894\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422697; batch adversarial loss: 0.479876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395719; batch adversarial loss: 0.564530\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424743; batch adversarial loss: 0.497445\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414281; batch adversarial loss: 0.602259\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416944; batch adversarial loss: 0.554256\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384567; batch adversarial loss: 0.602965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.296144; batch adversarial loss: 0.515829\n",
      "epoch 81; iter: 0; batch classifier loss: 0.340523; batch adversarial loss: 0.496924\n",
      "epoch 82; iter: 0; batch classifier loss: 0.327742; batch adversarial loss: 0.516535\n",
      "epoch 83; iter: 0; batch classifier loss: 0.484190; batch adversarial loss: 0.581933\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378139; batch adversarial loss: 0.553473\n",
      "epoch 85; iter: 0; batch classifier loss: 0.439941; batch adversarial loss: 0.543851\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380608; batch adversarial loss: 0.496854\n",
      "epoch 87; iter: 0; batch classifier loss: 0.522266; batch adversarial loss: 0.572970\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368929; batch adversarial loss: 0.497677\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405744; batch adversarial loss: 0.574297\n",
      "epoch 90; iter: 0; batch classifier loss: 0.325903; batch adversarial loss: 0.545550\n",
      "epoch 91; iter: 0; batch classifier loss: 0.317413; batch adversarial loss: 0.469479\n",
      "epoch 92; iter: 0; batch classifier loss: 0.447583; batch adversarial loss: 0.498770\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437453; batch adversarial loss: 0.552656\n",
      "epoch 94; iter: 0; batch classifier loss: 0.451556; batch adversarial loss: 0.525209\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368336; batch adversarial loss: 0.574042\n",
      "epoch 96; iter: 0; batch classifier loss: 0.442674; batch adversarial loss: 0.479271\n",
      "epoch 97; iter: 0; batch classifier loss: 0.347192; batch adversarial loss: 0.534994\n",
      "epoch 98; iter: 0; batch classifier loss: 0.453904; batch adversarial loss: 0.470928\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401843; batch adversarial loss: 0.524778\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410355; batch adversarial loss: 0.599415\n",
      "epoch 101; iter: 0; batch classifier loss: 0.432142; batch adversarial loss: 0.528958\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400448; batch adversarial loss: 0.536395\n",
      "epoch 103; iter: 0; batch classifier loss: 0.443326; batch adversarial loss: 0.609392\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428736; batch adversarial loss: 0.543793\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364992; batch adversarial loss: 0.545562\n",
      "epoch 106; iter: 0; batch classifier loss: 0.482331; batch adversarial loss: 0.469574\n",
      "epoch 107; iter: 0; batch classifier loss: 0.385273; batch adversarial loss: 0.544895\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361297; batch adversarial loss: 0.460682\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413805; batch adversarial loss: 0.499562\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398809; batch adversarial loss: 0.543287\n",
      "epoch 111; iter: 0; batch classifier loss: 0.290715; batch adversarial loss: 0.561092\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368748; batch adversarial loss: 0.526259\n",
      "epoch 113; iter: 0; batch classifier loss: 0.408265; batch adversarial loss: 0.573466\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347837; batch adversarial loss: 0.664794\n",
      "epoch 115; iter: 0; batch classifier loss: 0.349120; batch adversarial loss: 0.527871\n",
      "epoch 116; iter: 0; batch classifier loss: 0.311577; batch adversarial loss: 0.579821\n",
      "epoch 117; iter: 0; batch classifier loss: 0.327872; batch adversarial loss: 0.553422\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391338; batch adversarial loss: 0.574152\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388457; batch adversarial loss: 0.477886\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394731; batch adversarial loss: 0.581518\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370015; batch adversarial loss: 0.656997\n",
      "epoch 122; iter: 0; batch classifier loss: 0.375056; batch adversarial loss: 0.525357\n",
      "epoch 123; iter: 0; batch classifier loss: 0.440191; batch adversarial loss: 0.478604\n",
      "epoch 124; iter: 0; batch classifier loss: 0.470383; batch adversarial loss: 0.582219\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400785; batch adversarial loss: 0.609923\n",
      "epoch 126; iter: 0; batch classifier loss: 0.408074; batch adversarial loss: 0.611525\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355701; batch adversarial loss: 0.442934\n",
      "epoch 128; iter: 0; batch classifier loss: 0.382604; batch adversarial loss: 0.580609\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380478; batch adversarial loss: 0.552346\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376405; batch adversarial loss: 0.526818\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407479; batch adversarial loss: 0.535170\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327327; batch adversarial loss: 0.496871\n",
      "epoch 133; iter: 0; batch classifier loss: 0.407312; batch adversarial loss: 0.587077\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338499; batch adversarial loss: 0.505651\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403148; batch adversarial loss: 0.560736\n",
      "epoch 136; iter: 0; batch classifier loss: 0.388130; batch adversarial loss: 0.589524\n",
      "epoch 137; iter: 0; batch classifier loss: 0.304062; batch adversarial loss: 0.528438\n",
      "epoch 138; iter: 0; batch classifier loss: 0.273442; batch adversarial loss: 0.510358\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366324; batch adversarial loss: 0.538215\n",
      "epoch 140; iter: 0; batch classifier loss: 0.463995; batch adversarial loss: 0.497552\n",
      "epoch 141; iter: 0; batch classifier loss: 0.462687; batch adversarial loss: 0.501302\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374330; batch adversarial loss: 0.544863\n",
      "epoch 143; iter: 0; batch classifier loss: 0.393755; batch adversarial loss: 0.516372\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367711; batch adversarial loss: 0.591513\n",
      "epoch 145; iter: 0; batch classifier loss: 0.419368; batch adversarial loss: 0.470672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349053; batch adversarial loss: 0.554075\n",
      "epoch 147; iter: 0; batch classifier loss: 0.424957; batch adversarial loss: 0.573352\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349234; batch adversarial loss: 0.544282\n",
      "epoch 149; iter: 0; batch classifier loss: 0.428818; batch adversarial loss: 0.554312\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364609; batch adversarial loss: 0.522071\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362404; batch adversarial loss: 0.571267\n",
      "epoch 152; iter: 0; batch classifier loss: 0.435058; batch adversarial loss: 0.526196\n",
      "epoch 153; iter: 0; batch classifier loss: 0.285924; batch adversarial loss: 0.602864\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365279; batch adversarial loss: 0.543013\n",
      "epoch 155; iter: 0; batch classifier loss: 0.435100; batch adversarial loss: 0.526876\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367662; batch adversarial loss: 0.544818\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308476; batch adversarial loss: 0.536085\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396827; batch adversarial loss: 0.486728\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349504; batch adversarial loss: 0.555375\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401701; batch adversarial loss: 0.581403\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345843; batch adversarial loss: 0.541075\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357103; batch adversarial loss: 0.624861\n",
      "epoch 163; iter: 0; batch classifier loss: 0.436860; batch adversarial loss: 0.512873\n",
      "epoch 164; iter: 0; batch classifier loss: 0.329118; batch adversarial loss: 0.498517\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361697; batch adversarial loss: 0.516588\n",
      "epoch 166; iter: 0; batch classifier loss: 0.444981; batch adversarial loss: 0.573940\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390431; batch adversarial loss: 0.593963\n",
      "epoch 168; iter: 0; batch classifier loss: 0.394896; batch adversarial loss: 0.582692\n",
      "epoch 169; iter: 0; batch classifier loss: 0.413956; batch adversarial loss: 0.523979\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342521; batch adversarial loss: 0.552977\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386244; batch adversarial loss: 0.571985\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355296; batch adversarial loss: 0.546772\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340620; batch adversarial loss: 0.516866\n",
      "epoch 174; iter: 0; batch classifier loss: 0.461544; batch adversarial loss: 0.487849\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331574; batch adversarial loss: 0.495311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.383607; batch adversarial loss: 0.601455\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336904; batch adversarial loss: 0.601378\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353374; batch adversarial loss: 0.570357\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367747; batch adversarial loss: 0.550849\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392158; batch adversarial loss: 0.479874\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352146; batch adversarial loss: 0.600010\n",
      "epoch 182; iter: 0; batch classifier loss: 0.395251; batch adversarial loss: 0.503030\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341551; batch adversarial loss: 0.581617\n",
      "epoch 184; iter: 0; batch classifier loss: 0.427335; batch adversarial loss: 0.624294\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362714; batch adversarial loss: 0.554948\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353987; batch adversarial loss: 0.528154\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353339; batch adversarial loss: 0.543644\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345807; batch adversarial loss: 0.561951\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371195; batch adversarial loss: 0.515212\n",
      "epoch 190; iter: 0; batch classifier loss: 0.398241; batch adversarial loss: 0.570508\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329910; batch adversarial loss: 0.628195\n",
      "epoch 192; iter: 0; batch classifier loss: 0.430745; batch adversarial loss: 0.589894\n",
      "epoch 193; iter: 0; batch classifier loss: 0.328220; batch adversarial loss: 0.527410\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358552; batch adversarial loss: 0.565246\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382965; batch adversarial loss: 0.555553\n",
      "epoch 196; iter: 0; batch classifier loss: 0.402098; batch adversarial loss: 0.646124\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392103; batch adversarial loss: 0.534896\n",
      "epoch 198; iter: 0; batch classifier loss: 0.416802; batch adversarial loss: 0.581457\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349596; batch adversarial loss: 0.609174\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698638; batch adversarial loss: 0.614353\n",
      "epoch 1; iter: 0; batch classifier loss: 0.689498; batch adversarial loss: 0.675642\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579252; batch adversarial loss: 0.650871\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575238; batch adversarial loss: 0.642327\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601143; batch adversarial loss: 0.664831\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597909; batch adversarial loss: 0.614593\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512797; batch adversarial loss: 0.623748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568067; batch adversarial loss: 0.623637\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557924; batch adversarial loss: 0.601306\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537136; batch adversarial loss: 0.565939\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518929; batch adversarial loss: 0.535791\n",
      "epoch 11; iter: 0; batch classifier loss: 0.463876; batch adversarial loss: 0.567398\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550131; batch adversarial loss: 0.606419\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429120; batch adversarial loss: 0.575834\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493440; batch adversarial loss: 0.606290\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505456; batch adversarial loss: 0.560918\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495522; batch adversarial loss: 0.589898\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556027; batch adversarial loss: 0.533152\n",
      "epoch 18; iter: 0; batch classifier loss: 0.574347; batch adversarial loss: 0.479504\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489363; batch adversarial loss: 0.562586\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500274; batch adversarial loss: 0.556062\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464545; batch adversarial loss: 0.572679\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496620; batch adversarial loss: 0.621985\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450666; batch adversarial loss: 0.604450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.419686; batch adversarial loss: 0.587976\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491794; batch adversarial loss: 0.532528\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438746; batch adversarial loss: 0.519597\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436969; batch adversarial loss: 0.585404\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386591; batch adversarial loss: 0.521268\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484116; batch adversarial loss: 0.530652\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488188; batch adversarial loss: 0.486015\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463309; batch adversarial loss: 0.613635\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510853; batch adversarial loss: 0.606006\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388578; batch adversarial loss: 0.580003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392989; batch adversarial loss: 0.606658\n",
      "epoch 35; iter: 0; batch classifier loss: 0.519173; batch adversarial loss: 0.570900\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449448; batch adversarial loss: 0.508530\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412470; batch adversarial loss: 0.580530\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430048; batch adversarial loss: 0.535557\n",
      "epoch 39; iter: 0; batch classifier loss: 0.502251; batch adversarial loss: 0.553572\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420055; batch adversarial loss: 0.553440\n",
      "epoch 41; iter: 0; batch classifier loss: 0.505887; batch adversarial loss: 0.507998\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418279; batch adversarial loss: 0.598355\n",
      "epoch 43; iter: 0; batch classifier loss: 0.520517; batch adversarial loss: 0.626764\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400536; batch adversarial loss: 0.597900\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433175; batch adversarial loss: 0.480604\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441491; batch adversarial loss: 0.526120\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439061; batch adversarial loss: 0.553500\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481584; batch adversarial loss: 0.552508\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389476; batch adversarial loss: 0.465722\n",
      "epoch 50; iter: 0; batch classifier loss: 0.513802; batch adversarial loss: 0.500220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379554; batch adversarial loss: 0.585754\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427489; batch adversarial loss: 0.482775\n",
      "epoch 53; iter: 0; batch classifier loss: 0.486467; batch adversarial loss: 0.531106\n",
      "epoch 54; iter: 0; batch classifier loss: 0.389594; batch adversarial loss: 0.532229\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483948; batch adversarial loss: 0.507287\n",
      "epoch 56; iter: 0; batch classifier loss: 0.352036; batch adversarial loss: 0.545952\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471554; batch adversarial loss: 0.450514\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360967; batch adversarial loss: 0.611353\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452838; batch adversarial loss: 0.499107\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457296; batch adversarial loss: 0.618118\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396719; batch adversarial loss: 0.544180\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387718; batch adversarial loss: 0.573595\n",
      "epoch 63; iter: 0; batch classifier loss: 0.511705; batch adversarial loss: 0.469093\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440351; batch adversarial loss: 0.526044\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429780; batch adversarial loss: 0.636204\n",
      "epoch 66; iter: 0; batch classifier loss: 0.394245; batch adversarial loss: 0.581416\n",
      "epoch 67; iter: 0; batch classifier loss: 0.383953; batch adversarial loss: 0.560686\n",
      "epoch 68; iter: 0; batch classifier loss: 0.481786; batch adversarial loss: 0.544958\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384766; batch adversarial loss: 0.526556\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417638; batch adversarial loss: 0.501121\n",
      "epoch 71; iter: 0; batch classifier loss: 0.430956; batch adversarial loss: 0.552991\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.596809\n",
      "epoch 73; iter: 0; batch classifier loss: 0.471708; batch adversarial loss: 0.578172\n",
      "epoch 74; iter: 0; batch classifier loss: 0.321263; batch adversarial loss: 0.649459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.417923; batch adversarial loss: 0.525757\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411468; batch adversarial loss: 0.571966\n",
      "epoch 77; iter: 0; batch classifier loss: 0.466723; batch adversarial loss: 0.499526\n",
      "epoch 78; iter: 0; batch classifier loss: 0.367612; batch adversarial loss: 0.563360\n",
      "epoch 79; iter: 0; batch classifier loss: 0.360942; batch adversarial loss: 0.496565\n",
      "epoch 80; iter: 0; batch classifier loss: 0.425654; batch adversarial loss: 0.514901\n",
      "epoch 81; iter: 0; batch classifier loss: 0.411350; batch adversarial loss: 0.501824\n",
      "epoch 82; iter: 0; batch classifier loss: 0.434375; batch adversarial loss: 0.543900\n",
      "epoch 83; iter: 0; batch classifier loss: 0.366589; batch adversarial loss: 0.650798\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433521; batch adversarial loss: 0.524651\n",
      "epoch 85; iter: 0; batch classifier loss: 0.333677; batch adversarial loss: 0.591460\n",
      "epoch 86; iter: 0; batch classifier loss: 0.483036; batch adversarial loss: 0.527367\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430166; batch adversarial loss: 0.543974\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426507; batch adversarial loss: 0.508110\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384207; batch adversarial loss: 0.525919\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404952; batch adversarial loss: 0.543773\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394172; batch adversarial loss: 0.608566\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353955; batch adversarial loss: 0.562198\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361830; batch adversarial loss: 0.494946\n",
      "epoch 94; iter: 0; batch classifier loss: 0.417113; batch adversarial loss: 0.570279\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442293; batch adversarial loss: 0.518151\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403309; batch adversarial loss: 0.591271\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408019; batch adversarial loss: 0.470188\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387440; batch adversarial loss: 0.490832\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350515; batch adversarial loss: 0.508664\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370889; batch adversarial loss: 0.590459\n",
      "epoch 101; iter: 0; batch classifier loss: 0.354148; batch adversarial loss: 0.515911\n",
      "epoch 102; iter: 0; batch classifier loss: 0.378528; batch adversarial loss: 0.498123\n",
      "epoch 103; iter: 0; batch classifier loss: 0.331393; batch adversarial loss: 0.489315\n",
      "epoch 104; iter: 0; batch classifier loss: 0.487271; batch adversarial loss: 0.587788\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445394; batch adversarial loss: 0.554816\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373791; batch adversarial loss: 0.546681\n",
      "epoch 107; iter: 0; batch classifier loss: 0.442929; batch adversarial loss: 0.544248\n",
      "epoch 108; iter: 0; batch classifier loss: 0.374795; batch adversarial loss: 0.527080\n",
      "epoch 109; iter: 0; batch classifier loss: 0.349728; batch adversarial loss: 0.553673\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375882; batch adversarial loss: 0.572882\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431123; batch adversarial loss: 0.563989\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388584; batch adversarial loss: 0.628712\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421171; batch adversarial loss: 0.592371\n",
      "epoch 114; iter: 0; batch classifier loss: 0.323497; batch adversarial loss: 0.573082\n",
      "epoch 115; iter: 0; batch classifier loss: 0.424733; batch adversarial loss: 0.481919\n",
      "epoch 116; iter: 0; batch classifier loss: 0.344405; batch adversarial loss: 0.617476\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402593; batch adversarial loss: 0.573534\n",
      "epoch 118; iter: 0; batch classifier loss: 0.273864; batch adversarial loss: 0.499084\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371789; batch adversarial loss: 0.636032\n",
      "epoch 120; iter: 0; batch classifier loss: 0.412487; batch adversarial loss: 0.516735\n",
      "epoch 121; iter: 0; batch classifier loss: 0.426911; batch adversarial loss: 0.472084\n",
      "epoch 122; iter: 0; batch classifier loss: 0.348645; batch adversarial loss: 0.571751\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388410; batch adversarial loss: 0.499394\n",
      "epoch 124; iter: 0; batch classifier loss: 0.416929; batch adversarial loss: 0.527111\n",
      "epoch 125; iter: 0; batch classifier loss: 0.302704; batch adversarial loss: 0.498336\n",
      "epoch 126; iter: 0; batch classifier loss: 0.409729; batch adversarial loss: 0.454449\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347015; batch adversarial loss: 0.507886\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390558; batch adversarial loss: 0.554406\n",
      "epoch 129; iter: 0; batch classifier loss: 0.424902; batch adversarial loss: 0.552855\n",
      "epoch 130; iter: 0; batch classifier loss: 0.439891; batch adversarial loss: 0.535582\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326218; batch adversarial loss: 0.635769\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392511; batch adversarial loss: 0.516184\n",
      "epoch 133; iter: 0; batch classifier loss: 0.429907; batch adversarial loss: 0.609293\n",
      "epoch 134; iter: 0; batch classifier loss: 0.436157; batch adversarial loss: 0.608284\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 0.479677\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371203; batch adversarial loss: 0.571649\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384597; batch adversarial loss: 0.589559\n",
      "epoch 138; iter: 0; batch classifier loss: 0.372386; batch adversarial loss: 0.553954\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408887; batch adversarial loss: 0.544986\n",
      "epoch 140; iter: 0; batch classifier loss: 0.318559; batch adversarial loss: 0.470281\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388220; batch adversarial loss: 0.562700\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322768; batch adversarial loss: 0.508037\n",
      "epoch 143; iter: 0; batch classifier loss: 0.372691; batch adversarial loss: 0.535639\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409347; batch adversarial loss: 0.525878\n",
      "epoch 145; iter: 0; batch classifier loss: 0.439151; batch adversarial loss: 0.581775\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367221; batch adversarial loss: 0.580408\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369379; batch adversarial loss: 0.616403\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419182; batch adversarial loss: 0.498503\n",
      "epoch 149; iter: 0; batch classifier loss: 0.306924; batch adversarial loss: 0.588895\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365612; batch adversarial loss: 0.607380\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351806; batch adversarial loss: 0.581470\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389861; batch adversarial loss: 0.571475\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357518; batch adversarial loss: 0.516237\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358348; batch adversarial loss: 0.536824\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358097; batch adversarial loss: 0.572365\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373785; batch adversarial loss: 0.562215\n",
      "epoch 157; iter: 0; batch classifier loss: 0.480599; batch adversarial loss: 0.518058\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391052; batch adversarial loss: 0.544349\n",
      "epoch 159; iter: 0; batch classifier loss: 0.378468; batch adversarial loss: 0.526401\n",
      "epoch 160; iter: 0; batch classifier loss: 0.442518; batch adversarial loss: 0.580944\n",
      "epoch 161; iter: 0; batch classifier loss: 0.389416; batch adversarial loss: 0.545446\n",
      "epoch 162; iter: 0; batch classifier loss: 0.273290; batch adversarial loss: 0.527426\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392418; batch adversarial loss: 0.618001\n",
      "epoch 164; iter: 0; batch classifier loss: 0.424373; batch adversarial loss: 0.555292\n",
      "epoch 165; iter: 0; batch classifier loss: 0.285295; batch adversarial loss: 0.452097\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332571; batch adversarial loss: 0.608174\n",
      "epoch 167; iter: 0; batch classifier loss: 0.420545; batch adversarial loss: 0.535433\n",
      "epoch 168; iter: 0; batch classifier loss: 0.407212; batch adversarial loss: 0.517135\n",
      "epoch 169; iter: 0; batch classifier loss: 0.402976; batch adversarial loss: 0.463069\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412741; batch adversarial loss: 0.590948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.276834; batch adversarial loss: 0.571749\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348484; batch adversarial loss: 0.517732\n",
      "epoch 173; iter: 0; batch classifier loss: 0.464422; batch adversarial loss: 0.506974\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339567; batch adversarial loss: 0.535840\n",
      "epoch 175; iter: 0; batch classifier loss: 0.354417; batch adversarial loss: 0.497386\n",
      "epoch 176; iter: 0; batch classifier loss: 0.404491; batch adversarial loss: 0.544879\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355960; batch adversarial loss: 0.598527\n",
      "epoch 178; iter: 0; batch classifier loss: 0.365214; batch adversarial loss: 0.526131\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359576; batch adversarial loss: 0.498067\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369052; batch adversarial loss: 0.526242\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337592; batch adversarial loss: 0.590008\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382238; batch adversarial loss: 0.463226\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379090; batch adversarial loss: 0.500168\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354267; batch adversarial loss: 0.608504\n",
      "epoch 185; iter: 0; batch classifier loss: 0.289274; batch adversarial loss: 0.507987\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386961; batch adversarial loss: 0.518386\n",
      "epoch 187; iter: 0; batch classifier loss: 0.422507; batch adversarial loss: 0.555163\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397373; batch adversarial loss: 0.580416\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384613; batch adversarial loss: 0.507058\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380457; batch adversarial loss: 0.552549\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352435; batch adversarial loss: 0.498360\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339089; batch adversarial loss: 0.507632\n",
      "epoch 193; iter: 0; batch classifier loss: 0.415672; batch adversarial loss: 0.525581\n",
      "epoch 194; iter: 0; batch classifier loss: 0.371886; batch adversarial loss: 0.508304\n",
      "epoch 195; iter: 0; batch classifier loss: 0.318561; batch adversarial loss: 0.490076\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368886; batch adversarial loss: 0.507083\n",
      "epoch 197; iter: 0; batch classifier loss: 0.402811; batch adversarial loss: 0.515533\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342482; batch adversarial loss: 0.545727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.377529; batch adversarial loss: 0.581028\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693292; batch adversarial loss: 0.849322\n",
      "epoch 1; iter: 0; batch classifier loss: 0.857658; batch adversarial loss: 1.046711\n",
      "epoch 2; iter: 0; batch classifier loss: 0.969363; batch adversarial loss: 1.017985\n",
      "epoch 3; iter: 0; batch classifier loss: 0.979454; batch adversarial loss: 0.933429\n",
      "epoch 4; iter: 0; batch classifier loss: 0.916233; batch adversarial loss: 0.851595\n",
      "epoch 5; iter: 0; batch classifier loss: 0.883970; batch adversarial loss: 0.785866\n",
      "epoch 6; iter: 0; batch classifier loss: 0.769220; batch adversarial loss: 0.730039\n",
      "epoch 7; iter: 0; batch classifier loss: 0.652109; batch adversarial loss: 0.697965\n",
      "epoch 8; iter: 0; batch classifier loss: 0.616314; batch adversarial loss: 0.622963\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531722; batch adversarial loss: 0.587368\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592441; batch adversarial loss: 0.622770\n",
      "epoch 11; iter: 0; batch classifier loss: 0.497304; batch adversarial loss: 0.599943\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539569; batch adversarial loss: 0.571982\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545239; batch adversarial loss: 0.567383\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552970; batch adversarial loss: 0.541030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.453120; batch adversarial loss: 0.558239\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469664; batch adversarial loss: 0.572765\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541183; batch adversarial loss: 0.610581\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560082; batch adversarial loss: 0.522027\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465337; batch adversarial loss: 0.565976\n",
      "epoch 20; iter: 0; batch classifier loss: 0.464124; batch adversarial loss: 0.580231\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476043; batch adversarial loss: 0.520834\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467254; batch adversarial loss: 0.523363\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514782; batch adversarial loss: 0.527996\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433591; batch adversarial loss: 0.622681\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520944; batch adversarial loss: 0.514518\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494246; batch adversarial loss: 0.543430\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456249; batch adversarial loss: 0.519678\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499932; batch adversarial loss: 0.527024\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466060; batch adversarial loss: 0.541875\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457126; batch adversarial loss: 0.600982\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490374; batch adversarial loss: 0.496389\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434379; batch adversarial loss: 0.563453\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470414; batch adversarial loss: 0.551400\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414431; batch adversarial loss: 0.521160\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470387; batch adversarial loss: 0.521589\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478047; batch adversarial loss: 0.552927\n",
      "epoch 37; iter: 0; batch classifier loss: 0.519676; batch adversarial loss: 0.549599\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459231; batch adversarial loss: 0.590893\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427325; batch adversarial loss: 0.478714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424522; batch adversarial loss: 0.544848\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408926; batch adversarial loss: 0.605565\n",
      "epoch 42; iter: 0; batch classifier loss: 0.491540; batch adversarial loss: 0.544526\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365096; batch adversarial loss: 0.526866\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478788; batch adversarial loss: 0.616930\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421925; batch adversarial loss: 0.599085\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427497; batch adversarial loss: 0.486991\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450497; batch adversarial loss: 0.573215\n",
      "epoch 48; iter: 0; batch classifier loss: 0.492134; batch adversarial loss: 0.586372\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441321; batch adversarial loss: 0.599924\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418765; batch adversarial loss: 0.616814\n",
      "epoch 51; iter: 0; batch classifier loss: 0.385792; batch adversarial loss: 0.606384\n",
      "epoch 52; iter: 0; batch classifier loss: 0.481102; batch adversarial loss: 0.563583\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386828; batch adversarial loss: 0.552472\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394569; batch adversarial loss: 0.515999\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404004; batch adversarial loss: 0.533857\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445690; batch adversarial loss: 0.605383\n",
      "epoch 57; iter: 0; batch classifier loss: 0.365104; batch adversarial loss: 0.544685\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394968; batch adversarial loss: 0.477226\n",
      "epoch 59; iter: 0; batch classifier loss: 0.484175; batch adversarial loss: 0.580804\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434533; batch adversarial loss: 0.553873\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397935; batch adversarial loss: 0.496850\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403093; batch adversarial loss: 0.543023\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413559; batch adversarial loss: 0.534234\n",
      "epoch 64; iter: 0; batch classifier loss: 0.474689; batch adversarial loss: 0.534702\n",
      "epoch 65; iter: 0; batch classifier loss: 0.454443; batch adversarial loss: 0.545023\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421304; batch adversarial loss: 0.497507\n",
      "epoch 67; iter: 0; batch classifier loss: 0.463546; batch adversarial loss: 0.544652\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381531; batch adversarial loss: 0.588287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.413567; batch adversarial loss: 0.588411\n",
      "epoch 70; iter: 0; batch classifier loss: 0.440803; batch adversarial loss: 0.459702\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427571; batch adversarial loss: 0.561948\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442839; batch adversarial loss: 0.516435\n",
      "epoch 73; iter: 0; batch classifier loss: 0.322775; batch adversarial loss: 0.523703\n",
      "epoch 74; iter: 0; batch classifier loss: 0.434866; batch adversarial loss: 0.505742\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384659; batch adversarial loss: 0.541551\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424143; batch adversarial loss: 0.498941\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380173; batch adversarial loss: 0.588860\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378105; batch adversarial loss: 0.487627\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396495; batch adversarial loss: 0.584562\n",
      "epoch 80; iter: 0; batch classifier loss: 0.361299; batch adversarial loss: 0.516577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392419; batch adversarial loss: 0.525750\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447625; batch adversarial loss: 0.467242\n",
      "epoch 83; iter: 0; batch classifier loss: 0.457013; batch adversarial loss: 0.505878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421710; batch adversarial loss: 0.562019\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368885; batch adversarial loss: 0.580165\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355007; batch adversarial loss: 0.479806\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395267; batch adversarial loss: 0.550909\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345547; batch adversarial loss: 0.520337\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369056; batch adversarial loss: 0.554016\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354196; batch adversarial loss: 0.526704\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391956; batch adversarial loss: 0.577429\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376160; batch adversarial loss: 0.561232\n",
      "epoch 93; iter: 0; batch classifier loss: 0.346716; batch adversarial loss: 0.607761\n",
      "epoch 94; iter: 0; batch classifier loss: 0.339797; batch adversarial loss: 0.462647\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416677; batch adversarial loss: 0.559392\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396905; batch adversarial loss: 0.575254\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413493; batch adversarial loss: 0.541864\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397606; batch adversarial loss: 0.568309\n",
      "epoch 99; iter: 0; batch classifier loss: 0.362550; batch adversarial loss: 0.526182\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341301; batch adversarial loss: 0.529344\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434371; batch adversarial loss: 0.404672\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414765; batch adversarial loss: 0.463833\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427847; batch adversarial loss: 0.505503\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384041; batch adversarial loss: 0.518725\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359474; batch adversarial loss: 0.534834\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377399; batch adversarial loss: 0.507742\n",
      "epoch 107; iter: 0; batch classifier loss: 0.300512; batch adversarial loss: 0.585873\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363852; batch adversarial loss: 0.541879\n",
      "epoch 109; iter: 0; batch classifier loss: 0.309237; batch adversarial loss: 0.557085\n",
      "epoch 110; iter: 0; batch classifier loss: 0.314122; batch adversarial loss: 0.607830\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433959; batch adversarial loss: 0.535305\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411408; batch adversarial loss: 0.444977\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362847; batch adversarial loss: 0.535275\n",
      "epoch 114; iter: 0; batch classifier loss: 0.338195; batch adversarial loss: 0.589940\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386678; batch adversarial loss: 0.614303\n",
      "epoch 116; iter: 0; batch classifier loss: 0.272263; batch adversarial loss: 0.575430\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354043; batch adversarial loss: 0.549270\n",
      "epoch 118; iter: 0; batch classifier loss: 0.432330; batch adversarial loss: 0.670815\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410620; batch adversarial loss: 0.635714\n",
      "epoch 120; iter: 0; batch classifier loss: 0.291740; batch adversarial loss: 0.526254\n",
      "epoch 121; iter: 0; batch classifier loss: 0.329003; batch adversarial loss: 0.479759\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381109; batch adversarial loss: 0.514248\n",
      "epoch 123; iter: 0; batch classifier loss: 0.338962; batch adversarial loss: 0.619803\n",
      "epoch 124; iter: 0; batch classifier loss: 0.505968; batch adversarial loss: 0.635676\n",
      "epoch 125; iter: 0; batch classifier loss: 0.364312; batch adversarial loss: 0.494515\n",
      "epoch 126; iter: 0; batch classifier loss: 0.284432; batch adversarial loss: 0.534147\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353318; batch adversarial loss: 0.573570\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387197; batch adversarial loss: 0.519910\n",
      "epoch 129; iter: 0; batch classifier loss: 0.301644; batch adversarial loss: 0.581172\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378886; batch adversarial loss: 0.554113\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349737; batch adversarial loss: 0.479137\n",
      "epoch 132; iter: 0; batch classifier loss: 0.283678; batch adversarial loss: 0.487066\n",
      "epoch 133; iter: 0; batch classifier loss: 0.478013; batch adversarial loss: 0.549922\n",
      "epoch 134; iter: 0; batch classifier loss: 0.291560; batch adversarial loss: 0.546700\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339082; batch adversarial loss: 0.517183\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326926; batch adversarial loss: 0.440614\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371609; batch adversarial loss: 0.604613\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348070; batch adversarial loss: 0.602614\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361750; batch adversarial loss: 0.476329\n",
      "epoch 140; iter: 0; batch classifier loss: 0.303366; batch adversarial loss: 0.554491\n",
      "epoch 141; iter: 0; batch classifier loss: 0.333895; batch adversarial loss: 0.545084\n",
      "epoch 142; iter: 0; batch classifier loss: 0.309515; batch adversarial loss: 0.580713\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330674; batch adversarial loss: 0.594306\n",
      "epoch 144; iter: 0; batch classifier loss: 0.299643; batch adversarial loss: 0.580490\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371267; batch adversarial loss: 0.468218\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361065; batch adversarial loss: 0.534256\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319699; batch adversarial loss: 0.504385\n",
      "epoch 148; iter: 0; batch classifier loss: 0.318755; batch adversarial loss: 0.560839\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358460; batch adversarial loss: 0.587588\n",
      "epoch 150; iter: 0; batch classifier loss: 0.304638; batch adversarial loss: 0.531879\n",
      "epoch 151; iter: 0; batch classifier loss: 0.407868; batch adversarial loss: 0.563151\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360299; batch adversarial loss: 0.547809\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316634; batch adversarial loss: 0.560711\n",
      "epoch 154; iter: 0; batch classifier loss: 0.432790; batch adversarial loss: 0.538476\n",
      "epoch 155; iter: 0; batch classifier loss: 0.313054; batch adversarial loss: 0.589584\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390923; batch adversarial loss: 0.567558\n",
      "epoch 157; iter: 0; batch classifier loss: 0.268802; batch adversarial loss: 0.464016\n",
      "epoch 158; iter: 0; batch classifier loss: 0.358205; batch adversarial loss: 0.534773\n",
      "epoch 159; iter: 0; batch classifier loss: 0.335785; batch adversarial loss: 0.561209\n",
      "epoch 160; iter: 0; batch classifier loss: 0.425635; batch adversarial loss: 0.508094\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385532; batch adversarial loss: 0.522344\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385159; batch adversarial loss: 0.547010\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375801; batch adversarial loss: 0.545413\n",
      "epoch 164; iter: 0; batch classifier loss: 0.276621; batch adversarial loss: 0.652139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.330876; batch adversarial loss: 0.588265\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387681; batch adversarial loss: 0.582164\n",
      "epoch 167; iter: 0; batch classifier loss: 0.314794; batch adversarial loss: 0.553844\n",
      "epoch 168; iter: 0; batch classifier loss: 0.287125; batch adversarial loss: 0.547221\n",
      "epoch 169; iter: 0; batch classifier loss: 0.420069; batch adversarial loss: 0.470195\n",
      "epoch 170; iter: 0; batch classifier loss: 0.287774; batch adversarial loss: 0.553101\n",
      "epoch 171; iter: 0; batch classifier loss: 0.324354; batch adversarial loss: 0.534689\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365371; batch adversarial loss: 0.508519\n",
      "epoch 173; iter: 0; batch classifier loss: 0.261106; batch adversarial loss: 0.597066\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360672; batch adversarial loss: 0.578937\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346494; batch adversarial loss: 0.524881\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382445; batch adversarial loss: 0.602331\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345361; batch adversarial loss: 0.594274\n",
      "epoch 178; iter: 0; batch classifier loss: 0.325257; batch adversarial loss: 0.551243\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298594; batch adversarial loss: 0.612468\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350102; batch adversarial loss: 0.524080\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376386; batch adversarial loss: 0.595647\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344201; batch adversarial loss: 0.487601\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382199; batch adversarial loss: 0.544000\n",
      "epoch 184; iter: 0; batch classifier loss: 0.320511; batch adversarial loss: 0.508714\n",
      "epoch 185; iter: 0; batch classifier loss: 0.407973; batch adversarial loss: 0.534443\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396728; batch adversarial loss: 0.571323\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346957; batch adversarial loss: 0.515597\n",
      "epoch 188; iter: 0; batch classifier loss: 0.297797; batch adversarial loss: 0.552003\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348135; batch adversarial loss: 0.574037\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297727; batch adversarial loss: 0.537647\n",
      "epoch 191; iter: 0; batch classifier loss: 0.312469; batch adversarial loss: 0.405211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347120; batch adversarial loss: 0.535975\n",
      "epoch 193; iter: 0; batch classifier loss: 0.365112; batch adversarial loss: 0.534533\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386367; batch adversarial loss: 0.508667\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357920; batch adversarial loss: 0.570557\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374811; batch adversarial loss: 0.561932\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375331; batch adversarial loss: 0.525712\n",
      "epoch 198; iter: 0; batch classifier loss: 0.276297; batch adversarial loss: 0.572170\n",
      "epoch 199; iter: 0; batch classifier loss: 0.287286; batch adversarial loss: 0.523280\n",
      "epoch 0; iter: 0; batch classifier loss: 0.754877; batch adversarial loss: 0.650594\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621629; batch adversarial loss: 0.643578\n",
      "epoch 2; iter: 0; batch classifier loss: 0.535781; batch adversarial loss: 0.644332\n",
      "epoch 3; iter: 0; batch classifier loss: 0.529902; batch adversarial loss: 0.623192\n",
      "epoch 4; iter: 0; batch classifier loss: 0.637522; batch adversarial loss: 0.617952\n",
      "epoch 5; iter: 0; batch classifier loss: 0.624898; batch adversarial loss: 0.635344\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552531; batch adversarial loss: 0.575862\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526908; batch adversarial loss: 0.569426\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516955; batch adversarial loss: 0.603544\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577734; batch adversarial loss: 0.579492\n",
      "epoch 10; iter: 0; batch classifier loss: 0.627782; batch adversarial loss: 0.571187\n",
      "epoch 11; iter: 0; batch classifier loss: 0.476935; batch adversarial loss: 0.604083\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529517; batch adversarial loss: 0.563123\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485345; batch adversarial loss: 0.595092\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540999; batch adversarial loss: 0.595756\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516107; batch adversarial loss: 0.551640\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505437; batch adversarial loss: 0.601047\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558625; batch adversarial loss: 0.583243\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499109; batch adversarial loss: 0.529840\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487040; batch adversarial loss: 0.538266\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432021; batch adversarial loss: 0.573783\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538138; batch adversarial loss: 0.627440\n",
      "epoch 22; iter: 0; batch classifier loss: 0.460027; batch adversarial loss: 0.533788\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487520; batch adversarial loss: 0.612402\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487700; batch adversarial loss: 0.601408\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490807; batch adversarial loss: 0.580363\n",
      "epoch 26; iter: 0; batch classifier loss: 0.515793; batch adversarial loss: 0.534050\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467759; batch adversarial loss: 0.506860\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435074; batch adversarial loss: 0.506966\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455163; batch adversarial loss: 0.488629\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417256; batch adversarial loss: 0.576895\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435253; batch adversarial loss: 0.581840\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428135; batch adversarial loss: 0.622993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481490; batch adversarial loss: 0.509162\n",
      "epoch 34; iter: 0; batch classifier loss: 0.512398; batch adversarial loss: 0.544444\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404561; batch adversarial loss: 0.570724\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448664; batch adversarial loss: 0.503629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424659; batch adversarial loss: 0.529434\n",
      "epoch 38; iter: 0; batch classifier loss: 0.376024; batch adversarial loss: 0.521793\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439946; batch adversarial loss: 0.527001\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472322; batch adversarial loss: 0.579974\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437385; batch adversarial loss: 0.587929\n",
      "epoch 42; iter: 0; batch classifier loss: 0.504702; batch adversarial loss: 0.596378\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430752; batch adversarial loss: 0.535983\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499119; batch adversarial loss: 0.562176\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444349; batch adversarial loss: 0.544584\n",
      "epoch 46; iter: 0; batch classifier loss: 0.473055; batch adversarial loss: 0.562471\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465925; batch adversarial loss: 0.649163\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438579; batch adversarial loss: 0.500194\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422162; batch adversarial loss: 0.526440\n",
      "epoch 50; iter: 0; batch classifier loss: 0.370146; batch adversarial loss: 0.553590\n",
      "epoch 51; iter: 0; batch classifier loss: 0.369375; batch adversarial loss: 0.599082\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462661; batch adversarial loss: 0.535504\n",
      "epoch 53; iter: 0; batch classifier loss: 0.484107; batch adversarial loss: 0.580944\n",
      "epoch 54; iter: 0; batch classifier loss: 0.489989; batch adversarial loss: 0.544383\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429421; batch adversarial loss: 0.544538\n",
      "epoch 56; iter: 0; batch classifier loss: 0.382297; batch adversarial loss: 0.508450\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449669; batch adversarial loss: 0.590333\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404655; batch adversarial loss: 0.554310\n",
      "epoch 59; iter: 0; batch classifier loss: 0.450290; batch adversarial loss: 0.571785\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374954; batch adversarial loss: 0.597854\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454190; batch adversarial loss: 0.524506\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433703; batch adversarial loss: 0.536026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.420343; batch adversarial loss: 0.589753\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463111; batch adversarial loss: 0.599474\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451719; batch adversarial loss: 0.535900\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447790; batch adversarial loss: 0.490575\n",
      "epoch 67; iter: 0; batch classifier loss: 0.350165; batch adversarial loss: 0.563305\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431190; batch adversarial loss: 0.501424\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425371; batch adversarial loss: 0.553746\n",
      "epoch 70; iter: 0; batch classifier loss: 0.460786; batch adversarial loss: 0.482651\n",
      "epoch 71; iter: 0; batch classifier loss: 0.447234; batch adversarial loss: 0.534385\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455977; batch adversarial loss: 0.570769\n",
      "epoch 73; iter: 0; batch classifier loss: 0.496479; batch adversarial loss: 0.589352\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384184; batch adversarial loss: 0.544954\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430369; batch adversarial loss: 0.526602\n",
      "epoch 76; iter: 0; batch classifier loss: 0.453800; batch adversarial loss: 0.617089\n",
      "epoch 77; iter: 0; batch classifier loss: 0.443700; batch adversarial loss: 0.545351\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461148; batch adversarial loss: 0.562852\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408132; batch adversarial loss: 0.589349\n",
      "epoch 80; iter: 0; batch classifier loss: 0.428729; batch adversarial loss: 0.463036\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434312; batch adversarial loss: 0.653105\n",
      "epoch 82; iter: 0; batch classifier loss: 0.317647; batch adversarial loss: 0.553053\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403755; batch adversarial loss: 0.515507\n",
      "epoch 84; iter: 0; batch classifier loss: 0.422666; batch adversarial loss: 0.571063\n",
      "epoch 85; iter: 0; batch classifier loss: 0.469572; batch adversarial loss: 0.553882\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394754; batch adversarial loss: 0.570315\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440459; batch adversarial loss: 0.544681\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427037; batch adversarial loss: 0.525288\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438001; batch adversarial loss: 0.562870\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349526; batch adversarial loss: 0.653615\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454918; batch adversarial loss: 0.452508\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428674; batch adversarial loss: 0.626617\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377212; batch adversarial loss: 0.473688\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452529; batch adversarial loss: 0.553931\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426349; batch adversarial loss: 0.563098\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364042; batch adversarial loss: 0.556323\n",
      "epoch 97; iter: 0; batch classifier loss: 0.528994; batch adversarial loss: 0.597522\n",
      "epoch 98; iter: 0; batch classifier loss: 0.424689; batch adversarial loss: 0.565296\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378465; batch adversarial loss: 0.560594\n",
      "epoch 100; iter: 0; batch classifier loss: 0.478750; batch adversarial loss: 0.545264\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403142; batch adversarial loss: 0.490124\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369554; batch adversarial loss: 0.562708\n",
      "epoch 103; iter: 0; batch classifier loss: 0.465950; batch adversarial loss: 0.536073\n",
      "epoch 104; iter: 0; batch classifier loss: 0.443878; batch adversarial loss: 0.546102\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343072; batch adversarial loss: 0.537917\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382705; batch adversarial loss: 0.516023\n",
      "epoch 107; iter: 0; batch classifier loss: 0.290802; batch adversarial loss: 0.545569\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361466; batch adversarial loss: 0.605910\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381267; batch adversarial loss: 0.506626\n",
      "epoch 110; iter: 0; batch classifier loss: 0.449691; batch adversarial loss: 0.480262\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386545; batch adversarial loss: 0.499556\n",
      "epoch 112; iter: 0; batch classifier loss: 0.427401; batch adversarial loss: 0.499831\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362233; batch adversarial loss: 0.560934\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389200; batch adversarial loss: 0.526138\n",
      "epoch 115; iter: 0; batch classifier loss: 0.437924; batch adversarial loss: 0.524187\n",
      "epoch 116; iter: 0; batch classifier loss: 0.436020; batch adversarial loss: 0.563354\n",
      "epoch 117; iter: 0; batch classifier loss: 0.403590; batch adversarial loss: 0.597261\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374046; batch adversarial loss: 0.501882\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402223; batch adversarial loss: 0.527337\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387366; batch adversarial loss: 0.579268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385151; batch adversarial loss: 0.517506\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403963; batch adversarial loss: 0.586690\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367213; batch adversarial loss: 0.508153\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339904; batch adversarial loss: 0.582552\n",
      "epoch 125; iter: 0; batch classifier loss: 0.465885; batch adversarial loss: 0.589253\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358712; batch adversarial loss: 0.525456\n",
      "epoch 127; iter: 0; batch classifier loss: 0.431006; batch adversarial loss: 0.581330\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322386; batch adversarial loss: 0.472405\n",
      "epoch 129; iter: 0; batch classifier loss: 0.446771; batch adversarial loss: 0.535223\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380329; batch adversarial loss: 0.620220\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408306; batch adversarial loss: 0.470792\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371374; batch adversarial loss: 0.527521\n",
      "epoch 133; iter: 0; batch classifier loss: 0.400948; batch adversarial loss: 0.526284\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352442; batch adversarial loss: 0.517987\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373031; batch adversarial loss: 0.498445\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345041; batch adversarial loss: 0.579936\n",
      "epoch 137; iter: 0; batch classifier loss: 0.406402; batch adversarial loss: 0.601413\n",
      "epoch 138; iter: 0; batch classifier loss: 0.434186; batch adversarial loss: 0.617321\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399014; batch adversarial loss: 0.499713\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399164; batch adversarial loss: 0.633917\n",
      "epoch 141; iter: 0; batch classifier loss: 0.415207; batch adversarial loss: 0.534966\n",
      "epoch 142; iter: 0; batch classifier loss: 0.377971; batch adversarial loss: 0.508340\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328999; batch adversarial loss: 0.517229\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381907; batch adversarial loss: 0.571156\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367958; batch adversarial loss: 0.551193\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367920; batch adversarial loss: 0.579910\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365087; batch adversarial loss: 0.492602\n",
      "epoch 148; iter: 0; batch classifier loss: 0.456674; batch adversarial loss: 0.555484\n",
      "epoch 149; iter: 0; batch classifier loss: 0.477901; batch adversarial loss: 0.555108\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351898; batch adversarial loss: 0.599814\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353296; batch adversarial loss: 0.508137\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383841; batch adversarial loss: 0.561959\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404314; batch adversarial loss: 0.527431\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397527; batch adversarial loss: 0.624864\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401988; batch adversarial loss: 0.523063\n",
      "epoch 156; iter: 0; batch classifier loss: 0.466880; batch adversarial loss: 0.554006\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411196; batch adversarial loss: 0.525999\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381854; batch adversarial loss: 0.571537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.411408; batch adversarial loss: 0.617639\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387370; batch adversarial loss: 0.538790\n",
      "epoch 161; iter: 0; batch classifier loss: 0.487340; batch adversarial loss: 0.561929\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382229; batch adversarial loss: 0.525941\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367481; batch adversarial loss: 0.564147\n",
      "epoch 164; iter: 0; batch classifier loss: 0.365268; batch adversarial loss: 0.527043\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371252; batch adversarial loss: 0.554251\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369744; batch adversarial loss: 0.590698\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384810; batch adversarial loss: 0.570792\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366777; batch adversarial loss: 0.596697\n",
      "epoch 169; iter: 0; batch classifier loss: 0.347207; batch adversarial loss: 0.716611\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369792; batch adversarial loss: 0.542507\n",
      "epoch 171; iter: 0; batch classifier loss: 0.265224; batch adversarial loss: 0.500718\n",
      "epoch 172; iter: 0; batch classifier loss: 0.383286; batch adversarial loss: 0.556312\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404204; batch adversarial loss: 0.600222\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368764; batch adversarial loss: 0.623225\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311618; batch adversarial loss: 0.528094\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383934; batch adversarial loss: 0.588035\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375602; batch adversarial loss: 0.587184\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362862; batch adversarial loss: 0.534230\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362929; batch adversarial loss: 0.569662\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382694; batch adversarial loss: 0.545153\n",
      "epoch 181; iter: 0; batch classifier loss: 0.260077; batch adversarial loss: 0.592416\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351098; batch adversarial loss: 0.518711\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349940; batch adversarial loss: 0.551878\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381406; batch adversarial loss: 0.526992\n",
      "epoch 185; iter: 0; batch classifier loss: 0.459333; batch adversarial loss: 0.533160\n",
      "epoch 186; iter: 0; batch classifier loss: 0.321174; batch adversarial loss: 0.552585\n",
      "epoch 187; iter: 0; batch classifier loss: 0.435779; batch adversarial loss: 0.605552\n",
      "epoch 188; iter: 0; batch classifier loss: 0.354429; batch adversarial loss: 0.609102\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362500; batch adversarial loss: 0.601556\n",
      "epoch 190; iter: 0; batch classifier loss: 0.410590; batch adversarial loss: 0.563666\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321943; batch adversarial loss: 0.636014\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361597; batch adversarial loss: 0.657856\n",
      "epoch 193; iter: 0; batch classifier loss: 0.446339; batch adversarial loss: 0.521354\n",
      "epoch 194; iter: 0; batch classifier loss: 0.363279; batch adversarial loss: 0.570120\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383995; batch adversarial loss: 0.498356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400135; batch adversarial loss: 0.508776\n",
      "epoch 197; iter: 0; batch classifier loss: 0.363821; batch adversarial loss: 0.578665\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371981; batch adversarial loss: 0.499727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.298196; batch adversarial loss: 0.456278\n",
      "epoch 0; iter: 0; batch classifier loss: 0.805490; batch adversarial loss: 0.569858\n",
      "epoch 1; iter: 0; batch classifier loss: 0.656506; batch adversarial loss: 0.649764\n",
      "epoch 2; iter: 0; batch classifier loss: 0.548126; batch adversarial loss: 0.646743\n",
      "epoch 3; iter: 0; batch classifier loss: 0.653224; batch adversarial loss: 0.665929\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562898; batch adversarial loss: 0.649988\n",
      "epoch 5; iter: 0; batch classifier loss: 0.626934; batch adversarial loss: 0.666661\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529352; batch adversarial loss: 0.584020\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542320; batch adversarial loss: 0.605344\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595503; batch adversarial loss: 0.613703\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577368; batch adversarial loss: 0.623006\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526032; batch adversarial loss: 0.631300\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554860; batch adversarial loss: 0.627915\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510788; batch adversarial loss: 0.615597\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525944; batch adversarial loss: 0.562802\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569236; batch adversarial loss: 0.587138\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476805; batch adversarial loss: 0.548709\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553920; batch adversarial loss: 0.547818\n",
      "epoch 17; iter: 0; batch classifier loss: 0.406141; batch adversarial loss: 0.498842\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473377; batch adversarial loss: 0.560869\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516948; batch adversarial loss: 0.626463\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491970; batch adversarial loss: 0.542824\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474211; batch adversarial loss: 0.525864\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521895; batch adversarial loss: 0.579348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491241; batch adversarial loss: 0.563959\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506061; batch adversarial loss: 0.473295\n",
      "epoch 25; iter: 0; batch classifier loss: 0.416146; batch adversarial loss: 0.436353\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479501; batch adversarial loss: 0.614283\n",
      "epoch 27; iter: 0; batch classifier loss: 0.554865; batch adversarial loss: 0.612651\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483467; batch adversarial loss: 0.621305\n",
      "epoch 29; iter: 0; batch classifier loss: 0.470116; batch adversarial loss: 0.516971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453704; batch adversarial loss: 0.615775\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471123; batch adversarial loss: 0.651466\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464599; batch adversarial loss: 0.583319\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460230; batch adversarial loss: 0.607298\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420534; batch adversarial loss: 0.492321\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457156; batch adversarial loss: 0.589350\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508321; batch adversarial loss: 0.553263\n",
      "epoch 37; iter: 0; batch classifier loss: 0.515487; batch adversarial loss: 0.553859\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454269; batch adversarial loss: 0.490974\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452428; batch adversarial loss: 0.525798\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524541; batch adversarial loss: 0.644659\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468466; batch adversarial loss: 0.516492\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433594; batch adversarial loss: 0.606187\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447964; batch adversarial loss: 0.545068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448775; batch adversarial loss: 0.516575\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430325; batch adversarial loss: 0.627220\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464330; batch adversarial loss: 0.536708\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410735; batch adversarial loss: 0.552185\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440501; batch adversarial loss: 0.525756\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433113; batch adversarial loss: 0.526959\n",
      "epoch 50; iter: 0; batch classifier loss: 0.367060; batch adversarial loss: 0.498904\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438910; batch adversarial loss: 0.526106\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404988; batch adversarial loss: 0.526078\n",
      "epoch 53; iter: 0; batch classifier loss: 0.463569; batch adversarial loss: 0.489930\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421130; batch adversarial loss: 0.552188\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476503; batch adversarial loss: 0.497292\n",
      "epoch 56; iter: 0; batch classifier loss: 0.556175; batch adversarial loss: 0.626749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.402775; batch adversarial loss: 0.628450\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437917; batch adversarial loss: 0.537043\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419685; batch adversarial loss: 0.526755\n",
      "epoch 60; iter: 0; batch classifier loss: 0.355544; batch adversarial loss: 0.571658\n",
      "epoch 61; iter: 0; batch classifier loss: 0.476258; batch adversarial loss: 0.536818\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403850; batch adversarial loss: 0.580912\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417351; batch adversarial loss: 0.463193\n",
      "epoch 64; iter: 0; batch classifier loss: 0.452380; batch adversarial loss: 0.581275\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411366; batch adversarial loss: 0.571558\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432592; batch adversarial loss: 0.554764\n",
      "epoch 67; iter: 0; batch classifier loss: 0.364367; batch adversarial loss: 0.608468\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382667; batch adversarial loss: 0.552339\n",
      "epoch 69; iter: 0; batch classifier loss: 0.344406; batch adversarial loss: 0.462487\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430823; batch adversarial loss: 0.544564\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373696; batch adversarial loss: 0.517469\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399261; batch adversarial loss: 0.498579\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394605; batch adversarial loss: 0.589187\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452534; batch adversarial loss: 0.598515\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404531; batch adversarial loss: 0.571924\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383582; batch adversarial loss: 0.598978\n",
      "epoch 77; iter: 0; batch classifier loss: 0.494683; batch adversarial loss: 0.590048\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439634; batch adversarial loss: 0.508106\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420692; batch adversarial loss: 0.589526\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427878; batch adversarial loss: 0.571969\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371847; batch adversarial loss: 0.617771\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391704; batch adversarial loss: 0.473512\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371340; batch adversarial loss: 0.564359\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365273; batch adversarial loss: 0.517083\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378423; batch adversarial loss: 0.544504\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378674; batch adversarial loss: 0.524712\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391287; batch adversarial loss: 0.572320\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420019; batch adversarial loss: 0.471751\n",
      "epoch 89; iter: 0; batch classifier loss: 0.451569; batch adversarial loss: 0.545029\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381391; batch adversarial loss: 0.508087\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414302; batch adversarial loss: 0.517593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425409; batch adversarial loss: 0.499104\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369003; batch adversarial loss: 0.534978\n",
      "epoch 94; iter: 0; batch classifier loss: 0.361656; batch adversarial loss: 0.535115\n",
      "epoch 95; iter: 0; batch classifier loss: 0.403801; batch adversarial loss: 0.599759\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364612; batch adversarial loss: 0.472166\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358839; batch adversarial loss: 0.533906\n",
      "epoch 98; iter: 0; batch classifier loss: 0.405886; batch adversarial loss: 0.526623\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388800; batch adversarial loss: 0.469689\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372512; batch adversarial loss: 0.564527\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420278; batch adversarial loss: 0.552296\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353099; batch adversarial loss: 0.590187\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438337; batch adversarial loss: 0.617136\n",
      "epoch 104; iter: 0; batch classifier loss: 0.403928; batch adversarial loss: 0.554046\n",
      "epoch 105; iter: 0; batch classifier loss: 0.482322; batch adversarial loss: 0.619295\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371319; batch adversarial loss: 0.535126\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392434; batch adversarial loss: 0.589209\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334094; batch adversarial loss: 0.563507\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419060; batch adversarial loss: 0.535611\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350769; batch adversarial loss: 0.545622\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367786; batch adversarial loss: 0.581394\n",
      "epoch 112; iter: 0; batch classifier loss: 0.469110; batch adversarial loss: 0.526464\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351720; batch adversarial loss: 0.469751\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422962; batch adversarial loss: 0.607310\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388069; batch adversarial loss: 0.534631\n",
      "epoch 116; iter: 0; batch classifier loss: 0.352555; batch adversarial loss: 0.563928\n",
      "epoch 117; iter: 0; batch classifier loss: 0.341337; batch adversarial loss: 0.445254\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333229; batch adversarial loss: 0.526600\n",
      "epoch 119; iter: 0; batch classifier loss: 0.478570; batch adversarial loss: 0.601329\n",
      "epoch 120; iter: 0; batch classifier loss: 0.439620; batch adversarial loss: 0.527641\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356241; batch adversarial loss: 0.470863\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371738; batch adversarial loss: 0.507189\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385550; batch adversarial loss: 0.471428\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377977; batch adversarial loss: 0.553835\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375013; batch adversarial loss: 0.499044\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334825; batch adversarial loss: 0.498877\n",
      "epoch 127; iter: 0; batch classifier loss: 0.404655; batch adversarial loss: 0.579549\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373524; batch adversarial loss: 0.462597\n",
      "epoch 129; iter: 0; batch classifier loss: 0.425085; batch adversarial loss: 0.645622\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373855; batch adversarial loss: 0.553884\n",
      "epoch 131; iter: 0; batch classifier loss: 0.314541; batch adversarial loss: 0.490041\n",
      "epoch 132; iter: 0; batch classifier loss: 0.399008; batch adversarial loss: 0.561583\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354833; batch adversarial loss: 0.554993\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382795; batch adversarial loss: 0.562265\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380048; batch adversarial loss: 0.525994\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416373; batch adversarial loss: 0.562986\n",
      "epoch 137; iter: 0; batch classifier loss: 0.373986; batch adversarial loss: 0.572199\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415808; batch adversarial loss: 0.526689\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321304; batch adversarial loss: 0.617201\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400915; batch adversarial loss: 0.529193\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379379; batch adversarial loss: 0.508772\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369862; batch adversarial loss: 0.518298\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328558; batch adversarial loss: 0.589998\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406793; batch adversarial loss: 0.554061\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400634; batch adversarial loss: 0.544220\n",
      "epoch 146; iter: 0; batch classifier loss: 0.429985; batch adversarial loss: 0.589397\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388864; batch adversarial loss: 0.625925\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366064; batch adversarial loss: 0.580502\n",
      "epoch 149; iter: 0; batch classifier loss: 0.450050; batch adversarial loss: 0.507990\n",
      "epoch 150; iter: 0; batch classifier loss: 0.331439; batch adversarial loss: 0.581301\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372616; batch adversarial loss: 0.545545\n",
      "epoch 152; iter: 0; batch classifier loss: 0.481045; batch adversarial loss: 0.662869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.356270; batch adversarial loss: 0.489444\n",
      "epoch 154; iter: 0; batch classifier loss: 0.304606; batch adversarial loss: 0.554613\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342287; batch adversarial loss: 0.499040\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339733; batch adversarial loss: 0.471860\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312760; batch adversarial loss: 0.563003\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319728; batch adversarial loss: 0.526417\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394377; batch adversarial loss: 0.543422\n",
      "epoch 160; iter: 0; batch classifier loss: 0.402164; batch adversarial loss: 0.544253\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388955; batch adversarial loss: 0.561750\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385852; batch adversarial loss: 0.554546\n",
      "epoch 163; iter: 0; batch classifier loss: 0.409345; batch adversarial loss: 0.571661\n",
      "epoch 164; iter: 0; batch classifier loss: 0.370792; batch adversarial loss: 0.497781\n",
      "epoch 165; iter: 0; batch classifier loss: 0.455053; batch adversarial loss: 0.571762\n",
      "epoch 166; iter: 0; batch classifier loss: 0.394557; batch adversarial loss: 0.526233\n",
      "epoch 167; iter: 0; batch classifier loss: 0.410422; batch adversarial loss: 0.462237\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383752; batch adversarial loss: 0.588622\n",
      "epoch 169; iter: 0; batch classifier loss: 0.260257; batch adversarial loss: 0.480685\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404911; batch adversarial loss: 0.518368\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378391; batch adversarial loss: 0.516539\n",
      "epoch 172; iter: 0; batch classifier loss: 0.314370; batch adversarial loss: 0.663011\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354225; batch adversarial loss: 0.560788\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389499; batch adversarial loss: 0.610051\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384167; batch adversarial loss: 0.580478\n",
      "epoch 176; iter: 0; batch classifier loss: 0.476286; batch adversarial loss: 0.518108\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369752; batch adversarial loss: 0.590526\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342371; batch adversarial loss: 0.570498\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378269; batch adversarial loss: 0.580239\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375160; batch adversarial loss: 0.563374\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305847; batch adversarial loss: 0.610028\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405329; batch adversarial loss: 0.499024\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370020; batch adversarial loss: 0.526845\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381568; batch adversarial loss: 0.554209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.444181; batch adversarial loss: 0.545250\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407728; batch adversarial loss: 0.507314\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352080; batch adversarial loss: 0.635340\n",
      "epoch 188; iter: 0; batch classifier loss: 0.323085; batch adversarial loss: 0.527851\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343753; batch adversarial loss: 0.607519\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395081; batch adversarial loss: 0.499426\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367131; batch adversarial loss: 0.553841\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361793; batch adversarial loss: 0.599840\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362926; batch adversarial loss: 0.571475\n",
      "epoch 194; iter: 0; batch classifier loss: 0.327769; batch adversarial loss: 0.599800\n",
      "epoch 195; iter: 0; batch classifier loss: 0.474219; batch adversarial loss: 0.590484\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323348; batch adversarial loss: 0.590048\n",
      "epoch 197; iter: 0; batch classifier loss: 0.299802; batch adversarial loss: 0.608454\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321906; batch adversarial loss: 0.499049\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373567; batch adversarial loss: 0.580715\n",
      "epoch 0; iter: 0; batch classifier loss: 0.757511; batch adversarial loss: 0.612925\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596185; batch adversarial loss: 0.657058\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576992; batch adversarial loss: 0.657909\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576844; batch adversarial loss: 0.689695\n",
      "epoch 4; iter: 0; batch classifier loss: 0.515471; batch adversarial loss: 0.627316\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592854; batch adversarial loss: 0.579811\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561457; batch adversarial loss: 0.633560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573498; batch adversarial loss: 0.628243\n",
      "epoch 8; iter: 0; batch classifier loss: 0.457840; batch adversarial loss: 0.571590\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520617; batch adversarial loss: 0.582262\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479531; batch adversarial loss: 0.592968\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549552; batch adversarial loss: 0.625751\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455389; batch adversarial loss: 0.600128\n",
      "epoch 13; iter: 0; batch classifier loss: 0.561840; batch adversarial loss: 0.525741\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469050; batch adversarial loss: 0.501648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515063; batch adversarial loss: 0.553689\n",
      "epoch 16; iter: 0; batch classifier loss: 0.555880; batch adversarial loss: 0.570152\n",
      "epoch 17; iter: 0; batch classifier loss: 0.422198; batch adversarial loss: 0.571655\n",
      "epoch 18; iter: 0; batch classifier loss: 0.435359; batch adversarial loss: 0.543516\n",
      "epoch 19; iter: 0; batch classifier loss: 0.399834; batch adversarial loss: 0.545522\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496944; batch adversarial loss: 0.541973\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520736; batch adversarial loss: 0.588514\n",
      "epoch 22; iter: 0; batch classifier loss: 0.564999; batch adversarial loss: 0.537475\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522674; batch adversarial loss: 0.517998\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488201; batch adversarial loss: 0.630954\n",
      "epoch 25; iter: 0; batch classifier loss: 0.426289; batch adversarial loss: 0.594015\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389900; batch adversarial loss: 0.563501\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434460; batch adversarial loss: 0.555744\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459699; batch adversarial loss: 0.586833\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425660; batch adversarial loss: 0.554388\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440938; batch adversarial loss: 0.562010\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505001; batch adversarial loss: 0.519470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467598; batch adversarial loss: 0.519054\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475218; batch adversarial loss: 0.527520\n",
      "epoch 34; iter: 0; batch classifier loss: 0.487686; batch adversarial loss: 0.536845\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476500; batch adversarial loss: 0.570416\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437846; batch adversarial loss: 0.594372\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432464; batch adversarial loss: 0.554892\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431371; batch adversarial loss: 0.545238\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436207; batch adversarial loss: 0.511284\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459847; batch adversarial loss: 0.525447\n",
      "epoch 41; iter: 0; batch classifier loss: 0.372770; batch adversarial loss: 0.600363\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446904; batch adversarial loss: 0.535086\n",
      "epoch 43; iter: 0; batch classifier loss: 0.485045; batch adversarial loss: 0.607712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.570441; batch adversarial loss: 0.516889\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450000; batch adversarial loss: 0.601413\n",
      "epoch 46; iter: 0; batch classifier loss: 0.530057; batch adversarial loss: 0.558818\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400385; batch adversarial loss: 0.501846\n",
      "epoch 48; iter: 0; batch classifier loss: 0.374133; batch adversarial loss: 0.546890\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414668; batch adversarial loss: 0.553699\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441901; batch adversarial loss: 0.534138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.406196; batch adversarial loss: 0.529785\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399304; batch adversarial loss: 0.525093\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456955; batch adversarial loss: 0.553965\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416959; batch adversarial loss: 0.554178\n",
      "epoch 55; iter: 0; batch classifier loss: 0.363800; batch adversarial loss: 0.563143\n",
      "epoch 56; iter: 0; batch classifier loss: 0.476950; batch adversarial loss: 0.523623\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416905; batch adversarial loss: 0.498640\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442870; batch adversarial loss: 0.508177\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456009; batch adversarial loss: 0.524529\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447393; batch adversarial loss: 0.509987\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459082; batch adversarial loss: 0.533145\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388902; batch adversarial loss: 0.532026\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403161; batch adversarial loss: 0.527582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420579; batch adversarial loss: 0.562848\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439422; batch adversarial loss: 0.589704\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445330; batch adversarial loss: 0.563158\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404351; batch adversarial loss: 0.525433\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380785; batch adversarial loss: 0.570638\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388353; batch adversarial loss: 0.566441\n",
      "epoch 70; iter: 0; batch classifier loss: 0.495869; batch adversarial loss: 0.516307\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395668; batch adversarial loss: 0.503149\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349171; batch adversarial loss: 0.623779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372788; batch adversarial loss: 0.600310\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454517; batch adversarial loss: 0.573340\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371590; batch adversarial loss: 0.525116\n",
      "epoch 76; iter: 0; batch classifier loss: 0.438247; batch adversarial loss: 0.529195\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436567; batch adversarial loss: 0.516077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461321; batch adversarial loss: 0.567385\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386371; batch adversarial loss: 0.533589\n",
      "epoch 80; iter: 0; batch classifier loss: 0.413095; batch adversarial loss: 0.534516\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375843; batch adversarial loss: 0.572021\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391153; batch adversarial loss: 0.599609\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371987; batch adversarial loss: 0.491644\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410961; batch adversarial loss: 0.535631\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344454; batch adversarial loss: 0.594154\n",
      "epoch 86; iter: 0; batch classifier loss: 0.376084; batch adversarial loss: 0.531197\n",
      "epoch 87; iter: 0; batch classifier loss: 0.480797; batch adversarial loss: 0.551328\n",
      "epoch 88; iter: 0; batch classifier loss: 0.330197; batch adversarial loss: 0.542154\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411393; batch adversarial loss: 0.501560\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410712; batch adversarial loss: 0.556927\n",
      "epoch 91; iter: 0; batch classifier loss: 0.298682; batch adversarial loss: 0.457343\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412377; batch adversarial loss: 0.559173\n",
      "epoch 93; iter: 0; batch classifier loss: 0.469215; batch adversarial loss: 0.453825\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431521; batch adversarial loss: 0.506588\n",
      "epoch 95; iter: 0; batch classifier loss: 0.465288; batch adversarial loss: 0.564042\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395065; batch adversarial loss: 0.520706\n",
      "epoch 97; iter: 0; batch classifier loss: 0.330758; batch adversarial loss: 0.547644\n",
      "epoch 98; iter: 0; batch classifier loss: 0.441585; batch adversarial loss: 0.556057\n",
      "epoch 99; iter: 0; batch classifier loss: 0.497198; batch adversarial loss: 0.573924\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433986; batch adversarial loss: 0.502180\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360317; batch adversarial loss: 0.482005\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369268; batch adversarial loss: 0.542030\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409911; batch adversarial loss: 0.512402\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365275; batch adversarial loss: 0.561777\n",
      "epoch 105; iter: 0; batch classifier loss: 0.422127; batch adversarial loss: 0.507651\n",
      "epoch 106; iter: 0; batch classifier loss: 0.325226; batch adversarial loss: 0.588609\n",
      "epoch 107; iter: 0; batch classifier loss: 0.491857; batch adversarial loss: 0.552417\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352816; batch adversarial loss: 0.528469\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380840; batch adversarial loss: 0.541519\n",
      "epoch 110; iter: 0; batch classifier loss: 0.327557; batch adversarial loss: 0.560763\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441272; batch adversarial loss: 0.527152\n",
      "epoch 112; iter: 0; batch classifier loss: 0.380853; batch adversarial loss: 0.544432\n",
      "epoch 113; iter: 0; batch classifier loss: 0.469300; batch adversarial loss: 0.482833\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367980; batch adversarial loss: 0.598657\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398969; batch adversarial loss: 0.495826\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400899; batch adversarial loss: 0.543644\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325540; batch adversarial loss: 0.582057\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414567; batch adversarial loss: 0.479393\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381716; batch adversarial loss: 0.548940\n",
      "epoch 120; iter: 0; batch classifier loss: 0.429297; batch adversarial loss: 0.594045\n",
      "epoch 121; iter: 0; batch classifier loss: 0.363815; batch adversarial loss: 0.508982\n",
      "epoch 122; iter: 0; batch classifier loss: 0.469869; batch adversarial loss: 0.510577\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403350; batch adversarial loss: 0.512139\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398796; batch adversarial loss: 0.536028\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365866; batch adversarial loss: 0.571183\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399581; batch adversarial loss: 0.554093\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380448; batch adversarial loss: 0.532017\n",
      "epoch 128; iter: 0; batch classifier loss: 0.467349; batch adversarial loss: 0.523969\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370587; batch adversarial loss: 0.498856\n",
      "epoch 130; iter: 0; batch classifier loss: 0.410985; batch adversarial loss: 0.516155\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376640; batch adversarial loss: 0.568047\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319748; batch adversarial loss: 0.561308\n",
      "epoch 133; iter: 0; batch classifier loss: 0.313748; batch adversarial loss: 0.532537\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368487; batch adversarial loss: 0.612727\n",
      "epoch 135; iter: 0; batch classifier loss: 0.444931; batch adversarial loss: 0.499374\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402023; batch adversarial loss: 0.610217\n",
      "epoch 137; iter: 0; batch classifier loss: 0.445869; batch adversarial loss: 0.554372\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377351; batch adversarial loss: 0.606484\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383542; batch adversarial loss: 0.555188\n",
      "epoch 140; iter: 0; batch classifier loss: 0.412759; batch adversarial loss: 0.546481\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361626; batch adversarial loss: 0.545902\n",
      "epoch 142; iter: 0; batch classifier loss: 0.447495; batch adversarial loss: 0.608940\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386888; batch adversarial loss: 0.609507\n",
      "epoch 144; iter: 0; batch classifier loss: 0.418603; batch adversarial loss: 0.516567\n",
      "epoch 145; iter: 0; batch classifier loss: 0.440299; batch adversarial loss: 0.508114\n",
      "epoch 146; iter: 0; batch classifier loss: 0.409802; batch adversarial loss: 0.624926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.471070; batch adversarial loss: 0.517959\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362833; batch adversarial loss: 0.582949\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360777; batch adversarial loss: 0.588539\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348498; batch adversarial loss: 0.481147\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374077; batch adversarial loss: 0.503358\n",
      "epoch 152; iter: 0; batch classifier loss: 0.422773; batch adversarial loss: 0.507870\n",
      "epoch 153; iter: 0; batch classifier loss: 0.468223; batch adversarial loss: 0.582268\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344379; batch adversarial loss: 0.498222\n",
      "epoch 155; iter: 0; batch classifier loss: 0.438509; batch adversarial loss: 0.518827\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383270; batch adversarial loss: 0.555537\n",
      "epoch 157; iter: 0; batch classifier loss: 0.438031; batch adversarial loss: 0.605778\n",
      "epoch 158; iter: 0; batch classifier loss: 0.393812; batch adversarial loss: 0.575742\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362655; batch adversarial loss: 0.541947\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380607; batch adversarial loss: 0.533191\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334211; batch adversarial loss: 0.549601\n",
      "epoch 162; iter: 0; batch classifier loss: 0.308162; batch adversarial loss: 0.526438\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342624; batch adversarial loss: 0.563811\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386993; batch adversarial loss: 0.633661\n",
      "epoch 165; iter: 0; batch classifier loss: 0.404618; batch adversarial loss: 0.584066\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373974; batch adversarial loss: 0.607674\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329441; batch adversarial loss: 0.499101\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333944; batch adversarial loss: 0.589708\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386439; batch adversarial loss: 0.553240\n",
      "epoch 170; iter: 0; batch classifier loss: 0.456606; batch adversarial loss: 0.508532\n",
      "epoch 171; iter: 0; batch classifier loss: 0.404784; batch adversarial loss: 0.566801\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384128; batch adversarial loss: 0.551833\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337099; batch adversarial loss: 0.591115\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363457; batch adversarial loss: 0.592582\n",
      "epoch 175; iter: 0; batch classifier loss: 0.417916; batch adversarial loss: 0.582291\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343226; batch adversarial loss: 0.507656\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387721; batch adversarial loss: 0.545229\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384835; batch adversarial loss: 0.581725\n",
      "epoch 179; iter: 0; batch classifier loss: 0.283279; batch adversarial loss: 0.556431\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338488; batch adversarial loss: 0.562054\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334091; batch adversarial loss: 0.662501\n",
      "epoch 182; iter: 0; batch classifier loss: 0.416122; batch adversarial loss: 0.626559\n",
      "epoch 183; iter: 0; batch classifier loss: 0.432239; batch adversarial loss: 0.579708\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331075; batch adversarial loss: 0.580522\n",
      "epoch 185; iter: 0; batch classifier loss: 0.394249; batch adversarial loss: 0.562279\n",
      "epoch 186; iter: 0; batch classifier loss: 0.358911; batch adversarial loss: 0.590706\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313123; batch adversarial loss: 0.548461\n",
      "epoch 188; iter: 0; batch classifier loss: 0.429782; batch adversarial loss: 0.561488\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331969; batch adversarial loss: 0.533170\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375268; batch adversarial loss: 0.544029\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362555; batch adversarial loss: 0.609566\n",
      "epoch 192; iter: 0; batch classifier loss: 0.415511; batch adversarial loss: 0.534457\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296798; batch adversarial loss: 0.582279\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359077; batch adversarial loss: 0.417273\n",
      "epoch 195; iter: 0; batch classifier loss: 0.285186; batch adversarial loss: 0.518432\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310425; batch adversarial loss: 0.504012\n",
      "epoch 197; iter: 0; batch classifier loss: 0.411258; batch adversarial loss: 0.572941\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362213; batch adversarial loss: 0.513925\n",
      "epoch 199; iter: 0; batch classifier loss: 0.317529; batch adversarial loss: 0.565095\n",
      "epoch 0; iter: 0; batch classifier loss: 0.807224; batch adversarial loss: 0.874231\n",
      "epoch 1; iter: 0; batch classifier loss: 0.823367; batch adversarial loss: 0.879259\n",
      "epoch 2; iter: 0; batch classifier loss: 0.873917; batch adversarial loss: 0.814559\n",
      "epoch 3; iter: 0; batch classifier loss: 0.757492; batch adversarial loss: 0.735979\n",
      "epoch 4; iter: 0; batch classifier loss: 0.654876; batch adversarial loss: 0.649800\n",
      "epoch 5; iter: 0; batch classifier loss: 0.624772; batch adversarial loss: 0.627655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556444; batch adversarial loss: 0.621288\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535693; batch adversarial loss: 0.628680\n",
      "epoch 8; iter: 0; batch classifier loss: 0.603820; batch adversarial loss: 0.590756\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610106; batch adversarial loss: 0.605104\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521053; batch adversarial loss: 0.627821\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520354; batch adversarial loss: 0.570145\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498280; batch adversarial loss: 0.630234\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513516; batch adversarial loss: 0.565456\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568653; batch adversarial loss: 0.579455\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505482; batch adversarial loss: 0.578553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477457; batch adversarial loss: 0.564039\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465823; batch adversarial loss: 0.587085\n",
      "epoch 18; iter: 0; batch classifier loss: 0.459065; batch adversarial loss: 0.545803\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496960; batch adversarial loss: 0.575197\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511648; batch adversarial loss: 0.567012\n",
      "epoch 21; iter: 0; batch classifier loss: 0.451921; batch adversarial loss: 0.576665\n",
      "epoch 22; iter: 0; batch classifier loss: 0.551440; batch adversarial loss: 0.594441\n",
      "epoch 23; iter: 0; batch classifier loss: 0.427224; batch adversarial loss: 0.582317\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436629; batch adversarial loss: 0.521672\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498549; batch adversarial loss: 0.569315\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522877; batch adversarial loss: 0.595157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465346; batch adversarial loss: 0.576343\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494112; batch adversarial loss: 0.542628\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471421; batch adversarial loss: 0.571519\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431451; batch adversarial loss: 0.533053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464132; batch adversarial loss: 0.585194\n",
      "epoch 32; iter: 0; batch classifier loss: 0.535175; batch adversarial loss: 0.515288\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432254; batch adversarial loss: 0.480606\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429744; batch adversarial loss: 0.556286\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495817; batch adversarial loss: 0.625320\n",
      "epoch 36; iter: 0; batch classifier loss: 0.489204; batch adversarial loss: 0.468825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461303; batch adversarial loss: 0.548407\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417517; batch adversarial loss: 0.555332\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513326; batch adversarial loss: 0.479264\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468609; batch adversarial loss: 0.524555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429195; batch adversarial loss: 0.546671\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454417; batch adversarial loss: 0.606268\n",
      "epoch 43; iter: 0; batch classifier loss: 0.472300; batch adversarial loss: 0.562421\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509978; batch adversarial loss: 0.530122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.525113; batch adversarial loss: 0.564045\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436461; batch adversarial loss: 0.509264\n",
      "epoch 47; iter: 0; batch classifier loss: 0.514402; batch adversarial loss: 0.545935\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451380; batch adversarial loss: 0.519409\n",
      "epoch 49; iter: 0; batch classifier loss: 0.491362; batch adversarial loss: 0.517259\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476276; batch adversarial loss: 0.535585\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428491; batch adversarial loss: 0.489995\n",
      "epoch 52; iter: 0; batch classifier loss: 0.493034; batch adversarial loss: 0.508057\n",
      "epoch 53; iter: 0; batch classifier loss: 0.501578; batch adversarial loss: 0.536520\n",
      "epoch 54; iter: 0; batch classifier loss: 0.378437; batch adversarial loss: 0.526406\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434394; batch adversarial loss: 0.625954\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436845; batch adversarial loss: 0.563329\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393460; batch adversarial loss: 0.553924\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442411; batch adversarial loss: 0.589700\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424936; batch adversarial loss: 0.500128\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452121; batch adversarial loss: 0.535279\n",
      "epoch 61; iter: 0; batch classifier loss: 0.377471; batch adversarial loss: 0.516604\n",
      "epoch 62; iter: 0; batch classifier loss: 0.506344; batch adversarial loss: 0.553694\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391832; batch adversarial loss: 0.481197\n",
      "epoch 64; iter: 0; batch classifier loss: 0.458261; batch adversarial loss: 0.590584\n",
      "epoch 65; iter: 0; batch classifier loss: 0.482359; batch adversarial loss: 0.570758\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389966; batch adversarial loss: 0.490436\n",
      "epoch 67; iter: 0; batch classifier loss: 0.466017; batch adversarial loss: 0.577184\n",
      "epoch 68; iter: 0; batch classifier loss: 0.457861; batch adversarial loss: 0.474859\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419919; batch adversarial loss: 0.560839\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387792; batch adversarial loss: 0.581017\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404033; batch adversarial loss: 0.534708\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382717; batch adversarial loss: 0.489898\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390226; batch adversarial loss: 0.536563\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423671; batch adversarial loss: 0.531411\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423935; batch adversarial loss: 0.632115\n",
      "epoch 76; iter: 0; batch classifier loss: 0.477365; batch adversarial loss: 0.480082\n",
      "epoch 77; iter: 0; batch classifier loss: 0.452608; batch adversarial loss: 0.474952\n",
      "epoch 78; iter: 0; batch classifier loss: 0.446598; batch adversarial loss: 0.532986\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392786; batch adversarial loss: 0.544147\n",
      "epoch 80; iter: 0; batch classifier loss: 0.311757; batch adversarial loss: 0.529792\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393807; batch adversarial loss: 0.495099\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362069; batch adversarial loss: 0.500006\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405361; batch adversarial loss: 0.580031\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368246; batch adversarial loss: 0.589743\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364831; batch adversarial loss: 0.644549\n",
      "epoch 86; iter: 0; batch classifier loss: 0.463836; batch adversarial loss: 0.568919\n",
      "epoch 87; iter: 0; batch classifier loss: 0.463205; batch adversarial loss: 0.608712\n",
      "epoch 88; iter: 0; batch classifier loss: 0.475972; batch adversarial loss: 0.589055\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378503; batch adversarial loss: 0.560479\n",
      "epoch 90; iter: 0; batch classifier loss: 0.439493; batch adversarial loss: 0.595952\n",
      "epoch 91; iter: 0; batch classifier loss: 0.371832; batch adversarial loss: 0.545200\n",
      "epoch 92; iter: 0; batch classifier loss: 0.307952; batch adversarial loss: 0.519392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387943; batch adversarial loss: 0.524297\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381460; batch adversarial loss: 0.607302\n",
      "epoch 95; iter: 0; batch classifier loss: 0.370243; batch adversarial loss: 0.534134\n",
      "epoch 96; iter: 0; batch classifier loss: 0.510479; batch adversarial loss: 0.551487\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420216; batch adversarial loss: 0.634082\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409591; batch adversarial loss: 0.528979\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424947; batch adversarial loss: 0.607598\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381293; batch adversarial loss: 0.590765\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359091; batch adversarial loss: 0.650787\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416371; batch adversarial loss: 0.541494\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399600; batch adversarial loss: 0.552431\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367520; batch adversarial loss: 0.563133\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362769; batch adversarial loss: 0.535501\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379684; batch adversarial loss: 0.597191\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421353; batch adversarial loss: 0.548473\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367688; batch adversarial loss: 0.579495\n",
      "epoch 109; iter: 0; batch classifier loss: 0.382075; batch adversarial loss: 0.587936\n",
      "epoch 110; iter: 0; batch classifier loss: 0.364273; batch adversarial loss: 0.511377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.477930; batch adversarial loss: 0.512610\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366228; batch adversarial loss: 0.575446\n",
      "epoch 113; iter: 0; batch classifier loss: 0.393113; batch adversarial loss: 0.578630\n",
      "epoch 114; iter: 0; batch classifier loss: 0.301439; batch adversarial loss: 0.607325\n",
      "epoch 115; iter: 0; batch classifier loss: 0.349506; batch adversarial loss: 0.566335\n",
      "epoch 116; iter: 0; batch classifier loss: 0.317942; batch adversarial loss: 0.477778\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333182; batch adversarial loss: 0.507662\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366468; batch adversarial loss: 0.463686\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408977; batch adversarial loss: 0.500754\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407910; batch adversarial loss: 0.545137\n",
      "epoch 121; iter: 0; batch classifier loss: 0.409789; batch adversarial loss: 0.528091\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364556; batch adversarial loss: 0.504779\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380017; batch adversarial loss: 0.544046\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387393; batch adversarial loss: 0.640794\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394432; batch adversarial loss: 0.562822\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361710; batch adversarial loss: 0.501425\n",
      "epoch 127; iter: 0; batch classifier loss: 0.494641; batch adversarial loss: 0.508889\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410365; batch adversarial loss: 0.526480\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434920; batch adversarial loss: 0.601628\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345528; batch adversarial loss: 0.574825\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344885; batch adversarial loss: 0.535047\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359445; batch adversarial loss: 0.577983\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395527; batch adversarial loss: 0.514953\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337408; batch adversarial loss: 0.532063\n",
      "epoch 135; iter: 0; batch classifier loss: 0.374006; batch adversarial loss: 0.521728\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414906; batch adversarial loss: 0.547318\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377060; batch adversarial loss: 0.544254\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389065; batch adversarial loss: 0.612143\n",
      "epoch 139; iter: 0; batch classifier loss: 0.387653; batch adversarial loss: 0.584145\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352584; batch adversarial loss: 0.580040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.320715; batch adversarial loss: 0.528692\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396189; batch adversarial loss: 0.534633\n",
      "epoch 143; iter: 0; batch classifier loss: 0.451920; batch adversarial loss: 0.526849\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327630; batch adversarial loss: 0.584682\n",
      "epoch 145; iter: 0; batch classifier loss: 0.321357; batch adversarial loss: 0.543701\n",
      "epoch 146; iter: 0; batch classifier loss: 0.292776; batch adversarial loss: 0.587919\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391771; batch adversarial loss: 0.550956\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363656; batch adversarial loss: 0.536846\n",
      "epoch 149; iter: 0; batch classifier loss: 0.414324; batch adversarial loss: 0.552694\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330788; batch adversarial loss: 0.596419\n",
      "epoch 151; iter: 0; batch classifier loss: 0.377917; batch adversarial loss: 0.454206\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355831; batch adversarial loss: 0.606610\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362300; batch adversarial loss: 0.541333\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329831; batch adversarial loss: 0.539508\n",
      "epoch 155; iter: 0; batch classifier loss: 0.426352; batch adversarial loss: 0.533754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386546; batch adversarial loss: 0.588978\n",
      "epoch 157; iter: 0; batch classifier loss: 0.447195; batch adversarial loss: 0.554948\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331777; batch adversarial loss: 0.600835\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366620; batch adversarial loss: 0.570500\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328355; batch adversarial loss: 0.516235\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412109; batch adversarial loss: 0.458530\n",
      "epoch 162; iter: 0; batch classifier loss: 0.437441; batch adversarial loss: 0.555376\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373402; batch adversarial loss: 0.572283\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353951; batch adversarial loss: 0.557062\n",
      "epoch 165; iter: 0; batch classifier loss: 0.420974; batch adversarial loss: 0.523200\n",
      "epoch 166; iter: 0; batch classifier loss: 0.400206; batch adversarial loss: 0.549799\n",
      "epoch 167; iter: 0; batch classifier loss: 0.420856; batch adversarial loss: 0.513539\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388814; batch adversarial loss: 0.498995\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407945; batch adversarial loss: 0.454595\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306311; batch adversarial loss: 0.577449\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328546; batch adversarial loss: 0.509797\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326997; batch adversarial loss: 0.602026\n",
      "epoch 173; iter: 0; batch classifier loss: 0.353824; batch adversarial loss: 0.589722\n",
      "epoch 174; iter: 0; batch classifier loss: 0.388881; batch adversarial loss: 0.524082\n",
      "epoch 175; iter: 0; batch classifier loss: 0.407217; batch adversarial loss: 0.554143\n",
      "epoch 176; iter: 0; batch classifier loss: 0.418355; batch adversarial loss: 0.603271\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354254; batch adversarial loss: 0.598144\n",
      "epoch 178; iter: 0; batch classifier loss: 0.413783; batch adversarial loss: 0.553249\n",
      "epoch 179; iter: 0; batch classifier loss: 0.316621; batch adversarial loss: 0.554701\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375495; batch adversarial loss: 0.542216\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347080; batch adversarial loss: 0.553747\n",
      "epoch 182; iter: 0; batch classifier loss: 0.437890; batch adversarial loss: 0.572130\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367042; batch adversarial loss: 0.633458\n",
      "epoch 184; iter: 0; batch classifier loss: 0.279660; batch adversarial loss: 0.569665\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397826; batch adversarial loss: 0.489375\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349512; batch adversarial loss: 0.580011\n",
      "epoch 187; iter: 0; batch classifier loss: 0.306960; batch adversarial loss: 0.615222\n",
      "epoch 188; iter: 0; batch classifier loss: 0.245047; batch adversarial loss: 0.598525\n",
      "epoch 189; iter: 0; batch classifier loss: 0.428587; batch adversarial loss: 0.492665\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400102; batch adversarial loss: 0.481287\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319331; batch adversarial loss: 0.464029\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376772; batch adversarial loss: 0.532771\n",
      "epoch 193; iter: 0; batch classifier loss: 0.409342; batch adversarial loss: 0.551496\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392662; batch adversarial loss: 0.489336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.313160; batch adversarial loss: 0.587563\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320455; batch adversarial loss: 0.617028\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342268; batch adversarial loss: 0.550368\n",
      "epoch 198; iter: 0; batch classifier loss: 0.454654; batch adversarial loss: 0.504215\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359964; batch adversarial loss: 0.536484\n",
      "epoch 0; iter: 0; batch classifier loss: 0.850305; batch adversarial loss: 0.477435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551872; batch adversarial loss: 0.630812\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561885; batch adversarial loss: 0.592164\n",
      "epoch 3; iter: 0; batch classifier loss: 0.587857; batch adversarial loss: 0.650926\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595371; batch adversarial loss: 0.655482\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576269; batch adversarial loss: 0.688382\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508365; batch adversarial loss: 0.548460\n",
      "epoch 7; iter: 0; batch classifier loss: 0.651864; batch adversarial loss: 0.673140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.617057; batch adversarial loss: 0.615724\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549611; batch adversarial loss: 0.599098\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564608; batch adversarial loss: 0.647901\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550476; batch adversarial loss: 0.605941\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559226; batch adversarial loss: 0.568518\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484457; batch adversarial loss: 0.603092\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519831; batch adversarial loss: 0.579620\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435060; batch adversarial loss: 0.557500\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507995; batch adversarial loss: 0.475944\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468384; batch adversarial loss: 0.552498\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523889; batch adversarial loss: 0.579866\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488249; batch adversarial loss: 0.620293\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525199; batch adversarial loss: 0.536988\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464291; batch adversarial loss: 0.541726\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526769; batch adversarial loss: 0.482966\n",
      "epoch 23; iter: 0; batch classifier loss: 0.437187; batch adversarial loss: 0.550612\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496800; batch adversarial loss: 0.522172\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531603; batch adversarial loss: 0.581695\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404623; batch adversarial loss: 0.562708\n",
      "epoch 27; iter: 0; batch classifier loss: 0.496178; batch adversarial loss: 0.507471\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451977; batch adversarial loss: 0.606023\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493164; batch adversarial loss: 0.471933\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444652; batch adversarial loss: 0.543787\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402654; batch adversarial loss: 0.531158\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483925; batch adversarial loss: 0.493286\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439332; batch adversarial loss: 0.581592\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439921; batch adversarial loss: 0.582221\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497073; batch adversarial loss: 0.531161\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454605; batch adversarial loss: 0.431409\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489131; batch adversarial loss: 0.534575\n",
      "epoch 38; iter: 0; batch classifier loss: 0.411787; batch adversarial loss: 0.620707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.434362; batch adversarial loss: 0.570813\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441372; batch adversarial loss: 0.588241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468821; batch adversarial loss: 0.498500\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427495; batch adversarial loss: 0.541731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.367934; batch adversarial loss: 0.516539\n",
      "epoch 44; iter: 0; batch classifier loss: 0.354171; batch adversarial loss: 0.584181\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413271; batch adversarial loss: 0.589249\n",
      "epoch 46; iter: 0; batch classifier loss: 0.494972; batch adversarial loss: 0.470127\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357046; batch adversarial loss: 0.532764\n",
      "epoch 48; iter: 0; batch classifier loss: 0.458538; batch adversarial loss: 0.525498\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412248; batch adversarial loss: 0.479945\n",
      "epoch 50; iter: 0; batch classifier loss: 0.558744; batch adversarial loss: 0.543250\n",
      "epoch 51; iter: 0; batch classifier loss: 0.492391; batch adversarial loss: 0.534934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399151; batch adversarial loss: 0.493121\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384804; batch adversarial loss: 0.561369\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420734; batch adversarial loss: 0.534788\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436754; batch adversarial loss: 0.553903\n",
      "epoch 56; iter: 0; batch classifier loss: 0.460658; batch adversarial loss: 0.479534\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450877; batch adversarial loss: 0.541681\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388210; batch adversarial loss: 0.569419\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420166; batch adversarial loss: 0.582721\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390313; batch adversarial loss: 0.536232\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399518; batch adversarial loss: 0.487242\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435188; batch adversarial loss: 0.588662\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418617; batch adversarial loss: 0.467068\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426125; batch adversarial loss: 0.521300\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433897; batch adversarial loss: 0.579619\n",
      "epoch 66; iter: 0; batch classifier loss: 0.469926; batch adversarial loss: 0.541480\n",
      "epoch 67; iter: 0; batch classifier loss: 0.419706; batch adversarial loss: 0.575440\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409333; batch adversarial loss: 0.575822\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395485; batch adversarial loss: 0.528031\n",
      "epoch 70; iter: 0; batch classifier loss: 0.311635; batch adversarial loss: 0.543670\n",
      "epoch 71; iter: 0; batch classifier loss: 0.510115; batch adversarial loss: 0.496063\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392941; batch adversarial loss: 0.509810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426188; batch adversarial loss: 0.581180\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367084; batch adversarial loss: 0.526449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405607; batch adversarial loss: 0.600217\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420755; batch adversarial loss: 0.580900\n",
      "epoch 77; iter: 0; batch classifier loss: 0.329087; batch adversarial loss: 0.561762\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354705; batch adversarial loss: 0.544168\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372258; batch adversarial loss: 0.478223\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374734; batch adversarial loss: 0.488980\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429227; batch adversarial loss: 0.488624\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403238; batch adversarial loss: 0.516538\n",
      "epoch 83; iter: 0; batch classifier loss: 0.470808; batch adversarial loss: 0.582270\n",
      "epoch 84; iter: 0; batch classifier loss: 0.425314; batch adversarial loss: 0.507605\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450205; batch adversarial loss: 0.506776\n",
      "epoch 86; iter: 0; batch classifier loss: 0.443977; batch adversarial loss: 0.535432\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382069; batch adversarial loss: 0.488576\n",
      "epoch 88; iter: 0; batch classifier loss: 0.313871; batch adversarial loss: 0.526554\n",
      "epoch 89; iter: 0; batch classifier loss: 0.392285; batch adversarial loss: 0.581315\n",
      "epoch 90; iter: 0; batch classifier loss: 0.379422; batch adversarial loss: 0.573241\n",
      "epoch 91; iter: 0; batch classifier loss: 0.453151; batch adversarial loss: 0.580643\n",
      "epoch 92; iter: 0; batch classifier loss: 0.448232; batch adversarial loss: 0.498391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374288; batch adversarial loss: 0.572130\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416103; batch adversarial loss: 0.507773\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417954; batch adversarial loss: 0.553586\n",
      "epoch 96; iter: 0; batch classifier loss: 0.440695; batch adversarial loss: 0.496803\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379778; batch adversarial loss: 0.514773\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370855; batch adversarial loss: 0.590303\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378862; batch adversarial loss: 0.469527\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403885; batch adversarial loss: 0.525871\n",
      "epoch 101; iter: 0; batch classifier loss: 0.447303; batch adversarial loss: 0.571599\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390308; batch adversarial loss: 0.582276\n",
      "epoch 103; iter: 0; batch classifier loss: 0.332030; batch adversarial loss: 0.497902\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423583; batch adversarial loss: 0.487958\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360987; batch adversarial loss: 0.657991\n",
      "epoch 106; iter: 0; batch classifier loss: 0.344152; batch adversarial loss: 0.562373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413720; batch adversarial loss: 0.534680\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403793; batch adversarial loss: 0.496723\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357554; batch adversarial loss: 0.554591\n",
      "epoch 110; iter: 0; batch classifier loss: 0.423054; batch adversarial loss: 0.488490\n",
      "epoch 111; iter: 0; batch classifier loss: 0.478671; batch adversarial loss: 0.536715\n",
      "epoch 112; iter: 0; batch classifier loss: 0.449809; batch adversarial loss: 0.526345\n",
      "epoch 113; iter: 0; batch classifier loss: 0.476784; batch adversarial loss: 0.508389\n",
      "epoch 114; iter: 0; batch classifier loss: 0.281330; batch adversarial loss: 0.489357\n",
      "epoch 115; iter: 0; batch classifier loss: 0.444462; batch adversarial loss: 0.535864\n",
      "epoch 116; iter: 0; batch classifier loss: 0.434654; batch adversarial loss: 0.594136\n",
      "epoch 117; iter: 0; batch classifier loss: 0.421010; batch adversarial loss: 0.433370\n",
      "epoch 118; iter: 0; batch classifier loss: 0.262749; batch adversarial loss: 0.468782\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368779; batch adversarial loss: 0.517444\n",
      "epoch 120; iter: 0; batch classifier loss: 0.402049; batch adversarial loss: 0.498659\n",
      "epoch 121; iter: 0; batch classifier loss: 0.310706; batch adversarial loss: 0.580901\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328348; batch adversarial loss: 0.590707\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414287; batch adversarial loss: 0.535574\n",
      "epoch 124; iter: 0; batch classifier loss: 0.310165; batch adversarial loss: 0.639391\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342636; batch adversarial loss: 0.612062\n",
      "epoch 126; iter: 0; batch classifier loss: 0.423046; batch adversarial loss: 0.507783\n",
      "epoch 127; iter: 0; batch classifier loss: 0.427683; batch adversarial loss: 0.553287\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361583; batch adversarial loss: 0.498829\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388579; batch adversarial loss: 0.516036\n",
      "epoch 130; iter: 0; batch classifier loss: 0.417737; batch adversarial loss: 0.545111\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323993; batch adversarial loss: 0.600492\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388476; batch adversarial loss: 0.524884\n",
      "epoch 133; iter: 0; batch classifier loss: 0.456861; batch adversarial loss: 0.572082\n",
      "epoch 134; iter: 0; batch classifier loss: 0.425126; batch adversarial loss: 0.480216\n",
      "epoch 135; iter: 0; batch classifier loss: 0.439634; batch adversarial loss: 0.499338\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348763; batch adversarial loss: 0.666470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.314367; batch adversarial loss: 0.561979\n",
      "epoch 138; iter: 0; batch classifier loss: 0.429650; batch adversarial loss: 0.583656\n",
      "epoch 139; iter: 0; batch classifier loss: 0.422341; batch adversarial loss: 0.478764\n",
      "epoch 140; iter: 0; batch classifier loss: 0.476117; batch adversarial loss: 0.460365\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339471; batch adversarial loss: 0.525948\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412110; batch adversarial loss: 0.657547\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353065; batch adversarial loss: 0.562048\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336360; batch adversarial loss: 0.565274\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342700; batch adversarial loss: 0.629166\n",
      "epoch 146; iter: 0; batch classifier loss: 0.475367; batch adversarial loss: 0.553950\n",
      "epoch 147; iter: 0; batch classifier loss: 0.333026; batch adversarial loss: 0.582945\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381552; batch adversarial loss: 0.488132\n",
      "epoch 149; iter: 0; batch classifier loss: 0.425720; batch adversarial loss: 0.600938\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353648; batch adversarial loss: 0.489288\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354712; batch adversarial loss: 0.488329\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394625; batch adversarial loss: 0.610031\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386201; batch adversarial loss: 0.572528\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362425; batch adversarial loss: 0.469854\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327125; batch adversarial loss: 0.441261\n",
      "epoch 156; iter: 0; batch classifier loss: 0.452929; batch adversarial loss: 0.637502\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335361; batch adversarial loss: 0.622626\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382234; batch adversarial loss: 0.592755\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391214; batch adversarial loss: 0.544526\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319815; batch adversarial loss: 0.496602\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401692; batch adversarial loss: 0.545022\n",
      "epoch 162; iter: 0; batch classifier loss: 0.427783; batch adversarial loss: 0.648337\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331402; batch adversarial loss: 0.572508\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312451; batch adversarial loss: 0.542599\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386699; batch adversarial loss: 0.516284\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353974; batch adversarial loss: 0.580145\n",
      "epoch 167; iter: 0; batch classifier loss: 0.311644; batch adversarial loss: 0.574328\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342278; batch adversarial loss: 0.609553\n",
      "epoch 169; iter: 0; batch classifier loss: 0.433151; batch adversarial loss: 0.488722\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363693; batch adversarial loss: 0.563438\n",
      "epoch 171; iter: 0; batch classifier loss: 0.319696; batch adversarial loss: 0.517298\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381208; batch adversarial loss: 0.488323\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292808; batch adversarial loss: 0.543462\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325244; batch adversarial loss: 0.544740\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363433; batch adversarial loss: 0.572116\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373375; batch adversarial loss: 0.456793\n",
      "epoch 177; iter: 0; batch classifier loss: 0.398380; batch adversarial loss: 0.534721\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352990; batch adversarial loss: 0.667058\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392001; batch adversarial loss: 0.562407\n",
      "epoch 180; iter: 0; batch classifier loss: 0.311660; batch adversarial loss: 0.533208\n",
      "epoch 181; iter: 0; batch classifier loss: 0.433143; batch adversarial loss: 0.478752\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378729; batch adversarial loss: 0.528069\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372411; batch adversarial loss: 0.566910\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371312; batch adversarial loss: 0.564873\n",
      "epoch 185; iter: 0; batch classifier loss: 0.448485; batch adversarial loss: 0.515509\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376401; batch adversarial loss: 0.552864\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393497; batch adversarial loss: 0.603262\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358396; batch adversarial loss: 0.509202\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352324; batch adversarial loss: 0.572660\n",
      "epoch 190; iter: 0; batch classifier loss: 0.424791; batch adversarial loss: 0.544677\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329860; batch adversarial loss: 0.526480\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293003; batch adversarial loss: 0.591667\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398076; batch adversarial loss: 0.480625\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374192; batch adversarial loss: 0.551517\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397099; batch adversarial loss: 0.527976\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351437; batch adversarial loss: 0.526840\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323344; batch adversarial loss: 0.554536\n",
      "epoch 198; iter: 0; batch classifier loss: 0.320554; batch adversarial loss: 0.599940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.275428; batch adversarial loss: 0.609796\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681821; batch adversarial loss: 0.597628\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630266; batch adversarial loss: 0.681522\n",
      "epoch 2; iter: 0; batch classifier loss: 0.662367; batch adversarial loss: 0.609928\n",
      "epoch 3; iter: 0; batch classifier loss: 0.523430; batch adversarial loss: 0.646105\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598360; batch adversarial loss: 0.666803\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538623; batch adversarial loss: 0.668910\n",
      "epoch 6; iter: 0; batch classifier loss: 0.453853; batch adversarial loss: 0.613028\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519137; batch adversarial loss: 0.629124\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551389; batch adversarial loss: 0.582431\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541242; batch adversarial loss: 0.608342\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548105; batch adversarial loss: 0.581782\n",
      "epoch 11; iter: 0; batch classifier loss: 0.648815; batch adversarial loss: 0.604552\n",
      "epoch 12; iter: 0; batch classifier loss: 0.576966; batch adversarial loss: 0.595404\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515280; batch adversarial loss: 0.689460\n",
      "epoch 14; iter: 0; batch classifier loss: 0.583549; batch adversarial loss: 0.606378\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507025; batch adversarial loss: 0.618879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.440629; batch adversarial loss: 0.483197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483806; batch adversarial loss: 0.541197\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512475; batch adversarial loss: 0.560353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533648; batch adversarial loss: 0.591737\n",
      "epoch 20; iter: 0; batch classifier loss: 0.547630; batch adversarial loss: 0.552490\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491978; batch adversarial loss: 0.505713\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498040; batch adversarial loss: 0.560552\n",
      "epoch 23; iter: 0; batch classifier loss: 0.447161; batch adversarial loss: 0.559051\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464080; batch adversarial loss: 0.559039\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492843; batch adversarial loss: 0.515188\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494654; batch adversarial loss: 0.530139\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493865; batch adversarial loss: 0.562575\n",
      "epoch 28; iter: 0; batch classifier loss: 0.420454; batch adversarial loss: 0.493953\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439789; batch adversarial loss: 0.535917\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538731; batch adversarial loss: 0.554000\n",
      "epoch 31; iter: 0; batch classifier loss: 0.418556; batch adversarial loss: 0.544820\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525668; batch adversarial loss: 0.544462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.486730; batch adversarial loss: 0.526100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401652; batch adversarial loss: 0.562714\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476557; batch adversarial loss: 0.580805\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455563; batch adversarial loss: 0.490167\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457819; batch adversarial loss: 0.490297\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481211; batch adversarial loss: 0.635885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.469055; batch adversarial loss: 0.534762\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481671; batch adversarial loss: 0.489749\n",
      "epoch 41; iter: 0; batch classifier loss: 0.541542; batch adversarial loss: 0.572169\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474400; batch adversarial loss: 0.507084\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422098; batch adversarial loss: 0.525466\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445732; batch adversarial loss: 0.563793\n",
      "epoch 45; iter: 0; batch classifier loss: 0.500933; batch adversarial loss: 0.544545\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414882; batch adversarial loss: 0.562608\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476814; batch adversarial loss: 0.480358\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427189; batch adversarial loss: 0.516447\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415719; batch adversarial loss: 0.499306\n",
      "epoch 50; iter: 0; batch classifier loss: 0.525199; batch adversarial loss: 0.545516\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416585; batch adversarial loss: 0.517007\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405230; batch adversarial loss: 0.628386\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433786; batch adversarial loss: 0.544415\n",
      "epoch 54; iter: 0; batch classifier loss: 0.387615; batch adversarial loss: 0.591622\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427385; batch adversarial loss: 0.600202\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451458; batch adversarial loss: 0.572308\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428298; batch adversarial loss: 0.498209\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442291; batch adversarial loss: 0.572251\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399042; batch adversarial loss: 0.516970\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424329; batch adversarial loss: 0.562897\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458784; batch adversarial loss: 0.535277\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388498; batch adversarial loss: 0.489118\n",
      "epoch 63; iter: 0; batch classifier loss: 0.350978; batch adversarial loss: 0.479322\n",
      "epoch 64; iter: 0; batch classifier loss: 0.350613; batch adversarial loss: 0.506848\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413382; batch adversarial loss: 0.553539\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398131; batch adversarial loss: 0.553037\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372697; batch adversarial loss: 0.544108\n",
      "epoch 68; iter: 0; batch classifier loss: 0.353048; batch adversarial loss: 0.433374\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405799; batch adversarial loss: 0.562619\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434231; batch adversarial loss: 0.535370\n",
      "epoch 71; iter: 0; batch classifier loss: 0.489861; batch adversarial loss: 0.544552\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412860; batch adversarial loss: 0.726882\n",
      "epoch 73; iter: 0; batch classifier loss: 0.330171; batch adversarial loss: 0.480405\n",
      "epoch 74; iter: 0; batch classifier loss: 0.332140; batch adversarial loss: 0.571943\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364374; batch adversarial loss: 0.553666\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406956; batch adversarial loss: 0.627779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.342974; batch adversarial loss: 0.488616\n",
      "epoch 78; iter: 0; batch classifier loss: 0.342265; batch adversarial loss: 0.600257\n",
      "epoch 79; iter: 0; batch classifier loss: 0.316309; batch adversarial loss: 0.526172\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435575; batch adversarial loss: 0.452874\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421438; batch adversarial loss: 0.581285\n",
      "epoch 82; iter: 0; batch classifier loss: 0.327167; batch adversarial loss: 0.525994\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409898; batch adversarial loss: 0.443088\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348304; batch adversarial loss: 0.627117\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381295; batch adversarial loss: 0.562687\n",
      "epoch 86; iter: 0; batch classifier loss: 0.438356; batch adversarial loss: 0.554606\n",
      "epoch 87; iter: 0; batch classifier loss: 0.456602; batch adversarial loss: 0.570457\n",
      "epoch 88; iter: 0; batch classifier loss: 0.523312; batch adversarial loss: 0.552369\n",
      "epoch 89; iter: 0; batch classifier loss: 0.533390; batch adversarial loss: 0.517770\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410982; batch adversarial loss: 0.534779\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391599; batch adversarial loss: 0.571794\n",
      "epoch 92; iter: 0; batch classifier loss: 0.468117; batch adversarial loss: 0.587687\n",
      "epoch 93; iter: 0; batch classifier loss: 0.406304; batch adversarial loss: 0.518228\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449724; batch adversarial loss: 0.524893\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410162; batch adversarial loss: 0.498201\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395567; batch adversarial loss: 0.554905\n",
      "epoch 97; iter: 0; batch classifier loss: 0.304956; batch adversarial loss: 0.441765\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367313; batch adversarial loss: 0.516383\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412422; batch adversarial loss: 0.459831\n",
      "epoch 100; iter: 0; batch classifier loss: 0.426642; batch adversarial loss: 0.487867\n",
      "epoch 101; iter: 0; batch classifier loss: 0.322346; batch adversarial loss: 0.591733\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382527; batch adversarial loss: 0.601503\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360989; batch adversarial loss: 0.581392\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422594; batch adversarial loss: 0.543213\n",
      "epoch 105; iter: 0; batch classifier loss: 0.387744; batch adversarial loss: 0.497935\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381917; batch adversarial loss: 0.505975\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335641; batch adversarial loss: 0.508031\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362054; batch adversarial loss: 0.517716\n",
      "epoch 109; iter: 0; batch classifier loss: 0.432696; batch adversarial loss: 0.554073\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339583; batch adversarial loss: 0.515593\n",
      "epoch 111; iter: 0; batch classifier loss: 0.417390; batch adversarial loss: 0.517264\n",
      "epoch 112; iter: 0; batch classifier loss: 0.469508; batch adversarial loss: 0.488999\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328534; batch adversarial loss: 0.486713\n",
      "epoch 114; iter: 0; batch classifier loss: 0.343316; batch adversarial loss: 0.639129\n",
      "epoch 115; iter: 0; batch classifier loss: 0.454950; batch adversarial loss: 0.544349\n",
      "epoch 116; iter: 0; batch classifier loss: 0.463745; batch adversarial loss: 0.563971\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415711; batch adversarial loss: 0.543408\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351804; batch adversarial loss: 0.553320\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363180; batch adversarial loss: 0.506445\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366290; batch adversarial loss: 0.573502\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397700; batch adversarial loss: 0.469606\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345827; batch adversarial loss: 0.609245\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429797; batch adversarial loss: 0.570883\n",
      "epoch 124; iter: 0; batch classifier loss: 0.389555; batch adversarial loss: 0.588970\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379657; batch adversarial loss: 0.573133\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413030; batch adversarial loss: 0.478235\n",
      "epoch 127; iter: 0; batch classifier loss: 0.290672; batch adversarial loss: 0.534281\n",
      "epoch 128; iter: 0; batch classifier loss: 0.429219; batch adversarial loss: 0.535032\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427384; batch adversarial loss: 0.563365\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348154; batch adversarial loss: 0.584460\n",
      "epoch 131; iter: 0; batch classifier loss: 0.370452; batch adversarial loss: 0.488799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.330810; batch adversarial loss: 0.536529\n",
      "epoch 133; iter: 0; batch classifier loss: 0.363490; batch adversarial loss: 0.516335\n",
      "epoch 134; iter: 0; batch classifier loss: 0.447795; batch adversarial loss: 0.608588\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376212; batch adversarial loss: 0.509354\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343297; batch adversarial loss: 0.552894\n",
      "epoch 137; iter: 0; batch classifier loss: 0.316244; batch adversarial loss: 0.572163\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411543; batch adversarial loss: 0.608648\n",
      "epoch 139; iter: 0; batch classifier loss: 0.353057; batch adversarial loss: 0.526324\n",
      "epoch 140; iter: 0; batch classifier loss: 0.315636; batch adversarial loss: 0.526700\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389447; batch adversarial loss: 0.535809\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321565; batch adversarial loss: 0.599780\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371937; batch adversarial loss: 0.582485\n",
      "epoch 144; iter: 0; batch classifier loss: 0.445727; batch adversarial loss: 0.507432\n",
      "epoch 145; iter: 0; batch classifier loss: 0.330466; batch adversarial loss: 0.508199\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350067; batch adversarial loss: 0.505032\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372113; batch adversarial loss: 0.514989\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403376; batch adversarial loss: 0.488815\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391128; batch adversarial loss: 0.526013\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340978; batch adversarial loss: 0.561930\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384843; batch adversarial loss: 0.608803\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379306; batch adversarial loss: 0.592561\n",
      "epoch 153; iter: 0; batch classifier loss: 0.420535; batch adversarial loss: 0.516622\n",
      "epoch 154; iter: 0; batch classifier loss: 0.414272; batch adversarial loss: 0.665849\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373993; batch adversarial loss: 0.570137\n",
      "epoch 156; iter: 0; batch classifier loss: 0.306464; batch adversarial loss: 0.626459\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353205; batch adversarial loss: 0.597046\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375358; batch adversarial loss: 0.524990\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341211; batch adversarial loss: 0.534985\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334089; batch adversarial loss: 0.544134\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357905; batch adversarial loss: 0.582758\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361227; batch adversarial loss: 0.562006\n",
      "epoch 163; iter: 0; batch classifier loss: 0.425755; batch adversarial loss: 0.545635\n",
      "epoch 164; iter: 0; batch classifier loss: 0.331604; batch adversarial loss: 0.525075\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366914; batch adversarial loss: 0.515237\n",
      "epoch 166; iter: 0; batch classifier loss: 0.429789; batch adversarial loss: 0.591209\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349503; batch adversarial loss: 0.496987\n",
      "epoch 168; iter: 0; batch classifier loss: 0.420281; batch adversarial loss: 0.554782\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385783; batch adversarial loss: 0.581309\n",
      "epoch 170; iter: 0; batch classifier loss: 0.438773; batch adversarial loss: 0.590661\n",
      "epoch 171; iter: 0; batch classifier loss: 0.254909; batch adversarial loss: 0.562596\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363653; batch adversarial loss: 0.581238\n",
      "epoch 173; iter: 0; batch classifier loss: 0.406876; batch adversarial loss: 0.461031\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347121; batch adversarial loss: 0.506922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362292; batch adversarial loss: 0.572784\n",
      "epoch 176; iter: 0; batch classifier loss: 0.415269; batch adversarial loss: 0.590669\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381224; batch adversarial loss: 0.580931\n",
      "epoch 178; iter: 0; batch classifier loss: 0.310463; batch adversarial loss: 0.571829\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406201; batch adversarial loss: 0.599673\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355297; batch adversarial loss: 0.626484\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386387; batch adversarial loss: 0.562971\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404077; batch adversarial loss: 0.544493\n",
      "epoch 183; iter: 0; batch classifier loss: 0.269133; batch adversarial loss: 0.517438\n",
      "epoch 184; iter: 0; batch classifier loss: 0.361301; batch adversarial loss: 0.580730\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351659; batch adversarial loss: 0.562694\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379639; batch adversarial loss: 0.553484\n",
      "epoch 187; iter: 0; batch classifier loss: 0.404517; batch adversarial loss: 0.571282\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386954; batch adversarial loss: 0.553404\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414307; batch adversarial loss: 0.516239\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366785; batch adversarial loss: 0.553485\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367577; batch adversarial loss: 0.526018\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375809; batch adversarial loss: 0.580676\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325068; batch adversarial loss: 0.507527\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338371; batch adversarial loss: 0.599712\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307715; batch adversarial loss: 0.525373\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349515; batch adversarial loss: 0.654644\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321601; batch adversarial loss: 0.563503\n",
      "epoch 198; iter: 0; batch classifier loss: 0.367772; batch adversarial loss: 0.507421\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371813; batch adversarial loss: 0.490234\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660329; batch adversarial loss: 0.633144\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608729; batch adversarial loss: 0.643486\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565277; batch adversarial loss: 0.659936\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579887; batch adversarial loss: 0.649888\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579829; batch adversarial loss: 0.668652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585020; batch adversarial loss: 0.637289\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513486; batch adversarial loss: 0.575372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.572733; batch adversarial loss: 0.529639\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527260; batch adversarial loss: 0.584782\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528751; batch adversarial loss: 0.625238\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501684; batch adversarial loss: 0.543109\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516537; batch adversarial loss: 0.566252\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521876; batch adversarial loss: 0.568654\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541481; batch adversarial loss: 0.534116\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499805; batch adversarial loss: 0.570386\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526679; batch adversarial loss: 0.517583\n",
      "epoch 16; iter: 0; batch classifier loss: 0.446864; batch adversarial loss: 0.555180\n",
      "epoch 17; iter: 0; batch classifier loss: 0.439701; batch adversarial loss: 0.496940\n",
      "epoch 18; iter: 0; batch classifier loss: 0.417243; batch adversarial loss: 0.553899\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468878; batch adversarial loss: 0.570111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491037; batch adversarial loss: 0.478051\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499854; batch adversarial loss: 0.522631\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529753; batch adversarial loss: 0.508578\n",
      "epoch 23; iter: 0; batch classifier loss: 0.453677; batch adversarial loss: 0.460473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527069; batch adversarial loss: 0.563747\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494876; batch adversarial loss: 0.586675\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426019; batch adversarial loss: 0.561630\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469707; batch adversarial loss: 0.513026\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439368; batch adversarial loss: 0.599570\n",
      "epoch 29; iter: 0; batch classifier loss: 0.529072; batch adversarial loss: 0.502283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.471482; batch adversarial loss: 0.519076\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421084; batch adversarial loss: 0.579464\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435676; batch adversarial loss: 0.499949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474481; batch adversarial loss: 0.587861\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398651; batch adversarial loss: 0.541657\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491623; batch adversarial loss: 0.510420\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422766; batch adversarial loss: 0.579525\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491347; batch adversarial loss: 0.489168\n",
      "epoch 38; iter: 0; batch classifier loss: 0.385016; batch adversarial loss: 0.451332\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468680; batch adversarial loss: 0.566496\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507343; batch adversarial loss: 0.521293\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470888; batch adversarial loss: 0.591707\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400784; batch adversarial loss: 0.556509\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459357; batch adversarial loss: 0.450567\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468947; batch adversarial loss: 0.583397\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506415; batch adversarial loss: 0.533357\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406027; batch adversarial loss: 0.509607\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483963; batch adversarial loss: 0.571728\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402182; batch adversarial loss: 0.507589\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419308; batch adversarial loss: 0.577328\n",
      "epoch 50; iter: 0; batch classifier loss: 0.582366; batch adversarial loss: 0.486418\n",
      "epoch 51; iter: 0; batch classifier loss: 0.525739; batch adversarial loss: 0.534257\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455154; batch adversarial loss: 0.554962\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439016; batch adversarial loss: 0.496302\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457629; batch adversarial loss: 0.563434\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412628; batch adversarial loss: 0.504447\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448538; batch adversarial loss: 0.546054\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403592; batch adversarial loss: 0.597579\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430643; batch adversarial loss: 0.583488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.487920; batch adversarial loss: 0.544799\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436412; batch adversarial loss: 0.569504\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422128; batch adversarial loss: 0.545392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.447063; batch adversarial loss: 0.590300\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398101; batch adversarial loss: 0.488252\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431370; batch adversarial loss: 0.555224\n",
      "epoch 65; iter: 0; batch classifier loss: 0.368213; batch adversarial loss: 0.528671\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404350; batch adversarial loss: 0.506421\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400678; batch adversarial loss: 0.573386\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432519; batch adversarial loss: 0.509681\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415482; batch adversarial loss: 0.559233\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392064; batch adversarial loss: 0.486339\n",
      "epoch 71; iter: 0; batch classifier loss: 0.383247; batch adversarial loss: 0.533147\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466327; batch adversarial loss: 0.546716\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401895; batch adversarial loss: 0.575809\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441648; batch adversarial loss: 0.504036\n",
      "epoch 75; iter: 0; batch classifier loss: 0.351554; batch adversarial loss: 0.536718\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440608; batch adversarial loss: 0.473112\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361073; batch adversarial loss: 0.519734\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406762; batch adversarial loss: 0.508752\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392784; batch adversarial loss: 0.529024\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460263; batch adversarial loss: 0.575961\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369528; batch adversarial loss: 0.538944\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395638; batch adversarial loss: 0.586028\n",
      "epoch 83; iter: 0; batch classifier loss: 0.362983; batch adversarial loss: 0.500297\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411880; batch adversarial loss: 0.560988\n",
      "epoch 85; iter: 0; batch classifier loss: 0.432593; batch adversarial loss: 0.411838\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378230; batch adversarial loss: 0.596374\n",
      "epoch 87; iter: 0; batch classifier loss: 0.358784; batch adversarial loss: 0.480031\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376353; batch adversarial loss: 0.566112\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404842; batch adversarial loss: 0.535220\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385918; batch adversarial loss: 0.570316\n",
      "epoch 91; iter: 0; batch classifier loss: 0.371757; batch adversarial loss: 0.545275\n",
      "epoch 92; iter: 0; batch classifier loss: 0.486754; batch adversarial loss: 0.663182\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389986; batch adversarial loss: 0.499203\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397281; batch adversarial loss: 0.595775\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362638; batch adversarial loss: 0.492801\n",
      "epoch 96; iter: 0; batch classifier loss: 0.317559; batch adversarial loss: 0.575349\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402177; batch adversarial loss: 0.517270\n",
      "epoch 98; iter: 0; batch classifier loss: 0.443698; batch adversarial loss: 0.574850\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396057; batch adversarial loss: 0.536709\n",
      "epoch 100; iter: 0; batch classifier loss: 0.476648; batch adversarial loss: 0.466083\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407602; batch adversarial loss: 0.521418\n",
      "epoch 102; iter: 0; batch classifier loss: 0.338273; batch adversarial loss: 0.513439\n",
      "epoch 103; iter: 0; batch classifier loss: 0.428917; batch adversarial loss: 0.527065\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372333; batch adversarial loss: 0.556016\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362319; batch adversarial loss: 0.490046\n",
      "epoch 106; iter: 0; batch classifier loss: 0.336614; batch adversarial loss: 0.586253\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431944; batch adversarial loss: 0.575603\n",
      "epoch 108; iter: 0; batch classifier loss: 0.416072; batch adversarial loss: 0.559773\n",
      "epoch 109; iter: 0; batch classifier loss: 0.414061; batch adversarial loss: 0.547519\n",
      "epoch 110; iter: 0; batch classifier loss: 0.435240; batch adversarial loss: 0.549428\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365502; batch adversarial loss: 0.587084\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361937; batch adversarial loss: 0.556153\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354010; batch adversarial loss: 0.550375\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406170; batch adversarial loss: 0.566015\n",
      "epoch 115; iter: 0; batch classifier loss: 0.501223; batch adversarial loss: 0.543033\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356397; batch adversarial loss: 0.464730\n",
      "epoch 117; iter: 0; batch classifier loss: 0.451156; batch adversarial loss: 0.517757\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341705; batch adversarial loss: 0.521668\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378605; batch adversarial loss: 0.504897\n",
      "epoch 120; iter: 0; batch classifier loss: 0.334251; batch adversarial loss: 0.562107\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406999; batch adversarial loss: 0.534550\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378979; batch adversarial loss: 0.549214\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360503; batch adversarial loss: 0.506176\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395062; batch adversarial loss: 0.498318\n",
      "epoch 125; iter: 0; batch classifier loss: 0.378620; batch adversarial loss: 0.544871\n",
      "epoch 126; iter: 0; batch classifier loss: 0.433157; batch adversarial loss: 0.561914\n",
      "epoch 127; iter: 0; batch classifier loss: 0.321194; batch adversarial loss: 0.584478\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342265; batch adversarial loss: 0.525882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.448365; batch adversarial loss: 0.536127\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366406; batch adversarial loss: 0.545893\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384159; batch adversarial loss: 0.483690\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325739; batch adversarial loss: 0.627939\n",
      "epoch 133; iter: 0; batch classifier loss: 0.422084; batch adversarial loss: 0.526260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374636; batch adversarial loss: 0.549903\n",
      "epoch 135; iter: 0; batch classifier loss: 0.393283; batch adversarial loss: 0.613224\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346562; batch adversarial loss: 0.567167\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341670; batch adversarial loss: 0.562897\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320061; batch adversarial loss: 0.591817\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393788; batch adversarial loss: 0.555493\n",
      "epoch 140; iter: 0; batch classifier loss: 0.410805; batch adversarial loss: 0.610728\n",
      "epoch 141; iter: 0; batch classifier loss: 0.407142; batch adversarial loss: 0.566524\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370317; batch adversarial loss: 0.610135\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354553; batch adversarial loss: 0.594630\n",
      "epoch 144; iter: 0; batch classifier loss: 0.449431; batch adversarial loss: 0.569972\n",
      "epoch 145; iter: 0; batch classifier loss: 0.320318; batch adversarial loss: 0.582006\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329350; batch adversarial loss: 0.496545\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377291; batch adversarial loss: 0.614033\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378511; batch adversarial loss: 0.556212\n",
      "epoch 149; iter: 0; batch classifier loss: 0.327444; batch adversarial loss: 0.565986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433296; batch adversarial loss: 0.535032\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319669; batch adversarial loss: 0.617711\n",
      "epoch 152; iter: 0; batch classifier loss: 0.408666; batch adversarial loss: 0.515175\n",
      "epoch 153; iter: 0; batch classifier loss: 0.377785; batch adversarial loss: 0.518565\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374080; batch adversarial loss: 0.560718\n",
      "epoch 155; iter: 0; batch classifier loss: 0.467949; batch adversarial loss: 0.531247\n",
      "epoch 156; iter: 0; batch classifier loss: 0.444884; batch adversarial loss: 0.475598\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340623; batch adversarial loss: 0.526828\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336216; batch adversarial loss: 0.533270\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339163; batch adversarial loss: 0.549934\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343309; batch adversarial loss: 0.451885\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337961; batch adversarial loss: 0.472472\n",
      "epoch 162; iter: 0; batch classifier loss: 0.416742; batch adversarial loss: 0.508480\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338633; batch adversarial loss: 0.563946\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371388; batch adversarial loss: 0.581619\n",
      "epoch 165; iter: 0; batch classifier loss: 0.427674; batch adversarial loss: 0.553663\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323325; batch adversarial loss: 0.511862\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407923; batch adversarial loss: 0.564041\n",
      "epoch 168; iter: 0; batch classifier loss: 0.427513; batch adversarial loss: 0.550522\n",
      "epoch 169; iter: 0; batch classifier loss: 0.313022; batch adversarial loss: 0.468316\n",
      "epoch 170; iter: 0; batch classifier loss: 0.432859; batch adversarial loss: 0.483921\n",
      "epoch 171; iter: 0; batch classifier loss: 0.406887; batch adversarial loss: 0.482044\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353042; batch adversarial loss: 0.542261\n",
      "epoch 173; iter: 0; batch classifier loss: 0.310641; batch adversarial loss: 0.469516\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341691; batch adversarial loss: 0.574880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.401636; batch adversarial loss: 0.565530\n",
      "epoch 176; iter: 0; batch classifier loss: 0.282924; batch adversarial loss: 0.477616\n",
      "epoch 177; iter: 0; batch classifier loss: 0.403795; batch adversarial loss: 0.634523\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357447; batch adversarial loss: 0.537987\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345747; batch adversarial loss: 0.588976\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338801; batch adversarial loss: 0.591210\n",
      "epoch 181; iter: 0; batch classifier loss: 0.419876; batch adversarial loss: 0.546087\n",
      "epoch 182; iter: 0; batch classifier loss: 0.301536; batch adversarial loss: 0.591149\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369248; batch adversarial loss: 0.531941\n",
      "epoch 184; iter: 0; batch classifier loss: 0.341882; batch adversarial loss: 0.530860\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399317; batch adversarial loss: 0.522924\n",
      "epoch 186; iter: 0; batch classifier loss: 0.401054; batch adversarial loss: 0.594087\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351353; batch adversarial loss: 0.570882\n",
      "epoch 188; iter: 0; batch classifier loss: 0.296150; batch adversarial loss: 0.556892\n",
      "epoch 189; iter: 0; batch classifier loss: 0.415714; batch adversarial loss: 0.438993\n",
      "epoch 190; iter: 0; batch classifier loss: 0.439600; batch adversarial loss: 0.633019\n",
      "epoch 191; iter: 0; batch classifier loss: 0.436792; batch adversarial loss: 0.544251\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343782; batch adversarial loss: 0.572254\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398652; batch adversarial loss: 0.614570\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419354; batch adversarial loss: 0.593081\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335788; batch adversarial loss: 0.556944\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352234; batch adversarial loss: 0.590044\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354537; batch adversarial loss: 0.459816\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404496; batch adversarial loss: 0.432456\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306536; batch adversarial loss: 0.588704\n",
      "epoch 0; iter: 0; batch classifier loss: 0.632181; batch adversarial loss: 0.731672\n",
      "epoch 1; iter: 0; batch classifier loss: 0.674536; batch adversarial loss: 0.741387\n",
      "epoch 2; iter: 0; batch classifier loss: 0.718165; batch adversarial loss: 0.692580\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619607; batch adversarial loss: 0.650118\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606857; batch adversarial loss: 0.644969\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578803; batch adversarial loss: 0.628092\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494307; batch adversarial loss: 0.604380\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530841; batch adversarial loss: 0.610571\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555131; batch adversarial loss: 0.558382\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519139; batch adversarial loss: 0.592208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559573; batch adversarial loss: 0.565362\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457645; batch adversarial loss: 0.584668\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499906; batch adversarial loss: 0.570492\n",
      "epoch 13; iter: 0; batch classifier loss: 0.449017; batch adversarial loss: 0.526296\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533640; batch adversarial loss: 0.575304\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516527; batch adversarial loss: 0.573054\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498636; batch adversarial loss: 0.525787\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533707; batch adversarial loss: 0.537255\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506625; batch adversarial loss: 0.554830\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465445; batch adversarial loss: 0.541414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.455895; batch adversarial loss: 0.564475\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516234; batch adversarial loss: 0.595186\n",
      "epoch 22; iter: 0; batch classifier loss: 0.544850; batch adversarial loss: 0.516747\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504594; batch adversarial loss: 0.520038\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477844; batch adversarial loss: 0.583008\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511451; batch adversarial loss: 0.571634\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497709; batch adversarial loss: 0.516577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.486452; batch adversarial loss: 0.489134\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529010; batch adversarial loss: 0.562044\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476582; batch adversarial loss: 0.510772\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446678; batch adversarial loss: 0.531917\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458034; batch adversarial loss: 0.492231\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517430; batch adversarial loss: 0.517779\n",
      "epoch 33; iter: 0; batch classifier loss: 0.543563; batch adversarial loss: 0.626771\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492913; batch adversarial loss: 0.565312\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502531; batch adversarial loss: 0.634770\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425997; batch adversarial loss: 0.527045\n",
      "epoch 37; iter: 0; batch classifier loss: 0.597523; batch adversarial loss: 0.537305\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392859; batch adversarial loss: 0.516890\n",
      "epoch 39; iter: 0; batch classifier loss: 0.402598; batch adversarial loss: 0.606774\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446842; batch adversarial loss: 0.589817\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417343; batch adversarial loss: 0.589555\n",
      "epoch 42; iter: 0; batch classifier loss: 0.413721; batch adversarial loss: 0.532923\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413002; batch adversarial loss: 0.519714\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383674; batch adversarial loss: 0.615913\n",
      "epoch 45; iter: 0; batch classifier loss: 0.486270; batch adversarial loss: 0.527329\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371439; batch adversarial loss: 0.590221\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406152; batch adversarial loss: 0.517066\n",
      "epoch 48; iter: 0; batch classifier loss: 0.476273; batch adversarial loss: 0.517715\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394190; batch adversarial loss: 0.506228\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412510; batch adversarial loss: 0.608213\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445597; batch adversarial loss: 0.535412\n",
      "epoch 52; iter: 0; batch classifier loss: 0.395924; batch adversarial loss: 0.517135\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383623; batch adversarial loss: 0.534297\n",
      "epoch 54; iter: 0; batch classifier loss: 0.466122; batch adversarial loss: 0.524674\n",
      "epoch 55; iter: 0; batch classifier loss: 0.358296; batch adversarial loss: 0.554509\n",
      "epoch 56; iter: 0; batch classifier loss: 0.353205; batch adversarial loss: 0.543651\n",
      "epoch 57; iter: 0; batch classifier loss: 0.377649; batch adversarial loss: 0.599268\n",
      "epoch 58; iter: 0; batch classifier loss: 0.350299; batch adversarial loss: 0.534337\n",
      "epoch 59; iter: 0; batch classifier loss: 0.320252; batch adversarial loss: 0.587719\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404907; batch adversarial loss: 0.559390\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427208; batch adversarial loss: 0.505076\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403302; batch adversarial loss: 0.487607\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429956; batch adversarial loss: 0.547429\n",
      "epoch 64; iter: 0; batch classifier loss: 0.355477; batch adversarial loss: 0.462959\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402773; batch adversarial loss: 0.496535\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430928; batch adversarial loss: 0.617781\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391180; batch adversarial loss: 0.566289\n",
      "epoch 68; iter: 0; batch classifier loss: 0.429735; batch adversarial loss: 0.535259\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424303; batch adversarial loss: 0.556074\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412457; batch adversarial loss: 0.582952\n",
      "epoch 71; iter: 0; batch classifier loss: 0.352442; batch adversarial loss: 0.573139\n",
      "epoch 72; iter: 0; batch classifier loss: 0.423321; batch adversarial loss: 0.581641\n",
      "epoch 73; iter: 0; batch classifier loss: 0.323554; batch adversarial loss: 0.564318\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406128; batch adversarial loss: 0.581037\n",
      "epoch 75; iter: 0; batch classifier loss: 0.494188; batch adversarial loss: 0.534747\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420370; batch adversarial loss: 0.518402\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413729; batch adversarial loss: 0.535161\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380434; batch adversarial loss: 0.517640\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411799; batch adversarial loss: 0.580569\n",
      "epoch 80; iter: 0; batch classifier loss: 0.463089; batch adversarial loss: 0.543714\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392670; batch adversarial loss: 0.498745\n",
      "epoch 82; iter: 0; batch classifier loss: 0.444400; batch adversarial loss: 0.507314\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376423; batch adversarial loss: 0.562544\n",
      "epoch 84; iter: 0; batch classifier loss: 0.330606; batch adversarial loss: 0.526734\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406412; batch adversarial loss: 0.527846\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432511; batch adversarial loss: 0.488108\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392379; batch adversarial loss: 0.561510\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383908; batch adversarial loss: 0.609225\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379550; batch adversarial loss: 0.554322\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434588; batch adversarial loss: 0.581937\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361138; batch adversarial loss: 0.562938\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364673; batch adversarial loss: 0.580813\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371023; batch adversarial loss: 0.591319\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362151; batch adversarial loss: 0.527128\n",
      "epoch 95; iter: 0; batch classifier loss: 0.286935; batch adversarial loss: 0.553958\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346984; batch adversarial loss: 0.635184\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413058; batch adversarial loss: 0.599502\n",
      "epoch 98; iter: 0; batch classifier loss: 0.347615; batch adversarial loss: 0.562930\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376132; batch adversarial loss: 0.635957\n",
      "epoch 100; iter: 0; batch classifier loss: 0.336252; batch adversarial loss: 0.544643\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342862; batch adversarial loss: 0.610806\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347516; batch adversarial loss: 0.534923\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366260; batch adversarial loss: 0.580355\n",
      "epoch 104; iter: 0; batch classifier loss: 0.353050; batch adversarial loss: 0.489214\n",
      "epoch 105; iter: 0; batch classifier loss: 0.477655; batch adversarial loss: 0.510786\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353795; batch adversarial loss: 0.607945\n",
      "epoch 107; iter: 0; batch classifier loss: 0.317132; batch adversarial loss: 0.535101\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395017; batch adversarial loss: 0.600447\n",
      "epoch 109; iter: 0; batch classifier loss: 0.437925; batch adversarial loss: 0.588720\n",
      "epoch 110; iter: 0; batch classifier loss: 0.302516; batch adversarial loss: 0.463301\n",
      "epoch 111; iter: 0; batch classifier loss: 0.417143; batch adversarial loss: 0.544171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.439945; batch adversarial loss: 0.590944\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375737; batch adversarial loss: 0.578435\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412069; batch adversarial loss: 0.454048\n",
      "epoch 115; iter: 0; batch classifier loss: 0.296765; batch adversarial loss: 0.545395\n",
      "epoch 116; iter: 0; batch classifier loss: 0.326326; batch adversarial loss: 0.518200\n",
      "epoch 117; iter: 0; batch classifier loss: 0.309931; batch adversarial loss: 0.535759\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414842; batch adversarial loss: 0.580463\n",
      "epoch 119; iter: 0; batch classifier loss: 0.418856; batch adversarial loss: 0.553709\n",
      "epoch 120; iter: 0; batch classifier loss: 0.329647; batch adversarial loss: 0.498939\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379962; batch adversarial loss: 0.617196\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368247; batch adversarial loss: 0.562611\n",
      "epoch 123; iter: 0; batch classifier loss: 0.302025; batch adversarial loss: 0.590147\n",
      "epoch 124; iter: 0; batch classifier loss: 0.355107; batch adversarial loss: 0.516689\n",
      "epoch 125; iter: 0; batch classifier loss: 0.320646; batch adversarial loss: 0.535837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.315676; batch adversarial loss: 0.562885\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341348; batch adversarial loss: 0.516954\n",
      "epoch 128; iter: 0; batch classifier loss: 0.333400; batch adversarial loss: 0.517131\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348716; batch adversarial loss: 0.572673\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345670; batch adversarial loss: 0.553603\n",
      "epoch 131; iter: 0; batch classifier loss: 0.307640; batch adversarial loss: 0.553295\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335730; batch adversarial loss: 0.544251\n",
      "epoch 133; iter: 0; batch classifier loss: 0.322526; batch adversarial loss: 0.590254\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378263; batch adversarial loss: 0.599104\n",
      "epoch 135; iter: 0; batch classifier loss: 0.404205; batch adversarial loss: 0.526121\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382448; batch adversarial loss: 0.553752\n",
      "epoch 137; iter: 0; batch classifier loss: 0.322433; batch adversarial loss: 0.544845\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309483; batch adversarial loss: 0.571768\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386721; batch adversarial loss: 0.526135\n",
      "epoch 140; iter: 0; batch classifier loss: 0.315578; batch adversarial loss: 0.580777\n",
      "epoch 141; iter: 0; batch classifier loss: 0.313824; batch adversarial loss: 0.571484\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378639; batch adversarial loss: 0.542867\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366686; batch adversarial loss: 0.580268\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367814; batch adversarial loss: 0.525245\n",
      "epoch 145; iter: 0; batch classifier loss: 0.394652; batch adversarial loss: 0.589344\n",
      "epoch 146; iter: 0; batch classifier loss: 0.321294; batch adversarial loss: 0.569281\n",
      "epoch 147; iter: 0; batch classifier loss: 0.311698; batch adversarial loss: 0.580661\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279328; batch adversarial loss: 0.544994\n",
      "epoch 149; iter: 0; batch classifier loss: 0.325475; batch adversarial loss: 0.487773\n",
      "epoch 150; iter: 0; batch classifier loss: 0.411012; batch adversarial loss: 0.546524\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384160; batch adversarial loss: 0.534275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365823; batch adversarial loss: 0.618918\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373018; batch adversarial loss: 0.507006\n",
      "epoch 154; iter: 0; batch classifier loss: 0.333760; batch adversarial loss: 0.505838\n",
      "epoch 155; iter: 0; batch classifier loss: 0.421206; batch adversarial loss: 0.618215\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346906; batch adversarial loss: 0.537071\n",
      "epoch 157; iter: 0; batch classifier loss: 0.325660; batch adversarial loss: 0.454928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.410773; batch adversarial loss: 0.445651\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407444; batch adversarial loss: 0.589525\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311652; batch adversarial loss: 0.535695\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366436; batch adversarial loss: 0.517842\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312537; batch adversarial loss: 0.491672\n",
      "epoch 163; iter: 0; batch classifier loss: 0.418030; batch adversarial loss: 0.572991\n",
      "epoch 164; iter: 0; batch classifier loss: 0.247563; batch adversarial loss: 0.544410\n",
      "epoch 165; iter: 0; batch classifier loss: 0.432902; batch adversarial loss: 0.628399\n",
      "epoch 166; iter: 0; batch classifier loss: 0.294698; batch adversarial loss: 0.499089\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359930; batch adversarial loss: 0.434814\n",
      "epoch 168; iter: 0; batch classifier loss: 0.414710; batch adversarial loss: 0.489907\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351440; batch adversarial loss: 0.536006\n",
      "epoch 170; iter: 0; batch classifier loss: 0.309154; batch adversarial loss: 0.526198\n",
      "epoch 171; iter: 0; batch classifier loss: 0.310000; batch adversarial loss: 0.507953\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369723; batch adversarial loss: 0.526086\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403820; batch adversarial loss: 0.544900\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353251; batch adversarial loss: 0.553406\n",
      "epoch 175; iter: 0; batch classifier loss: 0.386361; batch adversarial loss: 0.517254\n",
      "epoch 176; iter: 0; batch classifier loss: 0.304011; batch adversarial loss: 0.553547\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312587; batch adversarial loss: 0.581362\n",
      "epoch 178; iter: 0; batch classifier loss: 0.290743; batch adversarial loss: 0.525959\n",
      "epoch 179; iter: 0; batch classifier loss: 0.427100; batch adversarial loss: 0.544428\n",
      "epoch 180; iter: 0; batch classifier loss: 0.268857; batch adversarial loss: 0.553637\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411993; batch adversarial loss: 0.572036\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373735; batch adversarial loss: 0.590321\n",
      "epoch 183; iter: 0; batch classifier loss: 0.316495; batch adversarial loss: 0.553527\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377787; batch adversarial loss: 0.562615\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358243; batch adversarial loss: 0.544602\n",
      "epoch 186; iter: 0; batch classifier loss: 0.293213; batch adversarial loss: 0.571760\n",
      "epoch 187; iter: 0; batch classifier loss: 0.290915; batch adversarial loss: 0.498869\n",
      "epoch 188; iter: 0; batch classifier loss: 0.309692; batch adversarial loss: 0.535554\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295311; batch adversarial loss: 0.590417\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346861; batch adversarial loss: 0.526538\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325639; batch adversarial loss: 0.544392\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358997; batch adversarial loss: 0.599513\n",
      "epoch 193; iter: 0; batch classifier loss: 0.301392; batch adversarial loss: 0.515542\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314560; batch adversarial loss: 0.580558\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375831; batch adversarial loss: 0.506546\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354918; batch adversarial loss: 0.516494\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341183; batch adversarial loss: 0.599392\n",
      "epoch 198; iter: 0; batch classifier loss: 0.425705; batch adversarial loss: 0.542655\n",
      "epoch 199; iter: 0; batch classifier loss: 0.313739; batch adversarial loss: 0.490303\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693978; batch adversarial loss: 0.724181\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597553; batch adversarial loss: 0.681956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576861; batch adversarial loss: 0.652730\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553828; batch adversarial loss: 0.618198\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566872; batch adversarial loss: 0.603474\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576238; batch adversarial loss: 0.606984\n",
      "epoch 6; iter: 0; batch classifier loss: 0.637492; batch adversarial loss: 0.580839\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550645; batch adversarial loss: 0.613284\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529340; batch adversarial loss: 0.591811\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531404; batch adversarial loss: 0.603860\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477171; batch adversarial loss: 0.633375\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562758; batch adversarial loss: 0.553182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537860; batch adversarial loss: 0.552417\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506892; batch adversarial loss: 0.534019\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540194; batch adversarial loss: 0.540568\n",
      "epoch 15; iter: 0; batch classifier loss: 0.606403; batch adversarial loss: 0.522684\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506659; batch adversarial loss: 0.568445\n",
      "epoch 17; iter: 0; batch classifier loss: 0.611811; batch adversarial loss: 0.476202\n",
      "epoch 18; iter: 0; batch classifier loss: 0.600207; batch adversarial loss: 0.547023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490763; batch adversarial loss: 0.532434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515222; batch adversarial loss: 0.557119\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513567; batch adversarial loss: 0.496366\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528812; batch adversarial loss: 0.592768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.484643; batch adversarial loss: 0.551848\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541207; batch adversarial loss: 0.577951\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465166; batch adversarial loss: 0.531896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440180; batch adversarial loss: 0.568683\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483455; batch adversarial loss: 0.580980\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495833; batch adversarial loss: 0.519499\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445735; batch adversarial loss: 0.535611\n",
      "epoch 30; iter: 0; batch classifier loss: 0.501506; batch adversarial loss: 0.518335\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517453; batch adversarial loss: 0.543069\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443902; batch adversarial loss: 0.572629\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446364; batch adversarial loss: 0.545219\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401619; batch adversarial loss: 0.605965\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504230; batch adversarial loss: 0.500389\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480603; batch adversarial loss: 0.580884\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426385; batch adversarial loss: 0.544710\n",
      "epoch 38; iter: 0; batch classifier loss: 0.571500; batch adversarial loss: 0.563081\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448124; batch adversarial loss: 0.562869\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465388; batch adversarial loss: 0.535153\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398109; batch adversarial loss: 0.507801\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477852; batch adversarial loss: 0.544871\n",
      "epoch 43; iter: 0; batch classifier loss: 0.527281; batch adversarial loss: 0.516672\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489027; batch adversarial loss: 0.534919\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438756; batch adversarial loss: 0.589480\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388857; batch adversarial loss: 0.544662\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497681; batch adversarial loss: 0.506935\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423436; batch adversarial loss: 0.488933\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458025; batch adversarial loss: 0.573827\n",
      "epoch 50; iter: 0; batch classifier loss: 0.567406; batch adversarial loss: 0.487284\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430919; batch adversarial loss: 0.553474\n",
      "epoch 52; iter: 0; batch classifier loss: 0.348085; batch adversarial loss: 0.536381\n",
      "epoch 53; iter: 0; batch classifier loss: 0.478669; batch adversarial loss: 0.563507\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440305; batch adversarial loss: 0.488250\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378328; batch adversarial loss: 0.619058\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.572399\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463898; batch adversarial loss: 0.535016\n",
      "epoch 58; iter: 0; batch classifier loss: 0.510070; batch adversarial loss: 0.562696\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374907; batch adversarial loss: 0.505552\n",
      "epoch 60; iter: 0; batch classifier loss: 0.415115; batch adversarial loss: 0.534461\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433708; batch adversarial loss: 0.553397\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425214; batch adversarial loss: 0.618262\n",
      "epoch 63; iter: 0; batch classifier loss: 0.365924; batch adversarial loss: 0.513253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420567; batch adversarial loss: 0.430199\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415710; batch adversarial loss: 0.555187\n",
      "epoch 66; iter: 0; batch classifier loss: 0.424056; batch adversarial loss: 0.553706\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402779; batch adversarial loss: 0.525909\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373791; batch adversarial loss: 0.467864\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418272; batch adversarial loss: 0.534652\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400048; batch adversarial loss: 0.507050\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420008; batch adversarial loss: 0.516922\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377740; batch adversarial loss: 0.592173\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417441; batch adversarial loss: 0.554511\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435655; batch adversarial loss: 0.535359\n",
      "epoch 75; iter: 0; batch classifier loss: 0.270329; batch adversarial loss: 0.507449\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363510; batch adversarial loss: 0.524939\n",
      "epoch 77; iter: 0; batch classifier loss: 0.384215; batch adversarial loss: 0.609285\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402439; batch adversarial loss: 0.496557\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437506; batch adversarial loss: 0.581074\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401732; batch adversarial loss: 0.553103\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406378; batch adversarial loss: 0.508025\n",
      "epoch 82; iter: 0; batch classifier loss: 0.402200; batch adversarial loss: 0.581218\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403307; batch adversarial loss: 0.583716\n",
      "epoch 84; iter: 0; batch classifier loss: 0.481103; batch adversarial loss: 0.479499\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415402; batch adversarial loss: 0.487674\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431140; batch adversarial loss: 0.648770\n",
      "epoch 87; iter: 0; batch classifier loss: 0.330147; batch adversarial loss: 0.527376\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369970; batch adversarial loss: 0.629108\n",
      "epoch 89; iter: 0; batch classifier loss: 0.437707; batch adversarial loss: 0.449654\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425995; batch adversarial loss: 0.555156\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359842; batch adversarial loss: 0.544208\n",
      "epoch 92; iter: 0; batch classifier loss: 0.495032; batch adversarial loss: 0.514190\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363735; batch adversarial loss: 0.514708\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405778; batch adversarial loss: 0.527165\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419669; batch adversarial loss: 0.498759\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414042; batch adversarial loss: 0.507468\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408725; batch adversarial loss: 0.497755\n",
      "epoch 98; iter: 0; batch classifier loss: 0.465229; batch adversarial loss: 0.574495\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368232; batch adversarial loss: 0.570543\n",
      "epoch 100; iter: 0; batch classifier loss: 0.331206; batch adversarial loss: 0.583035\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387262; batch adversarial loss: 0.469389\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416408; batch adversarial loss: 0.476047\n",
      "epoch 103; iter: 0; batch classifier loss: 0.530990; batch adversarial loss: 0.544245\n",
      "epoch 104; iter: 0; batch classifier loss: 0.379160; batch adversarial loss: 0.534301\n",
      "epoch 105; iter: 0; batch classifier loss: 0.419488; batch adversarial loss: 0.515740\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404251; batch adversarial loss: 0.497059\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373801; batch adversarial loss: 0.505278\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332445; batch adversarial loss: 0.545553\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346088; batch adversarial loss: 0.485040\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429923; batch adversarial loss: 0.468249\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394624; batch adversarial loss: 0.526986\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410221; batch adversarial loss: 0.545364\n",
      "epoch 113; iter: 0; batch classifier loss: 0.320597; batch adversarial loss: 0.514921\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365290; batch adversarial loss: 0.555693\n",
      "epoch 115; iter: 0; batch classifier loss: 0.425815; batch adversarial loss: 0.440813\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400078; batch adversarial loss: 0.590622\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333737; batch adversarial loss: 0.600187\n",
      "epoch 118; iter: 0; batch classifier loss: 0.293587; batch adversarial loss: 0.575390\n",
      "epoch 119; iter: 0; batch classifier loss: 0.496235; batch adversarial loss: 0.544525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418424; batch adversarial loss: 0.600018\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392516; batch adversarial loss: 0.571750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.382863; batch adversarial loss: 0.565557\n",
      "epoch 123; iter: 0; batch classifier loss: 0.391969; batch adversarial loss: 0.507362\n",
      "epoch 124; iter: 0; batch classifier loss: 0.320533; batch adversarial loss: 0.536243\n",
      "epoch 125; iter: 0; batch classifier loss: 0.388848; batch adversarial loss: 0.562958\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383675; batch adversarial loss: 0.573103\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382282; batch adversarial loss: 0.505428\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370651; batch adversarial loss: 0.508786\n",
      "epoch 129; iter: 0; batch classifier loss: 0.410602; batch adversarial loss: 0.524313\n",
      "epoch 130; iter: 0; batch classifier loss: 0.430318; batch adversarial loss: 0.516172\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405066; batch adversarial loss: 0.533736\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407865; batch adversarial loss: 0.503828\n",
      "epoch 133; iter: 0; batch classifier loss: 0.401585; batch adversarial loss: 0.553515\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338524; batch adversarial loss: 0.555426\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349718; batch adversarial loss: 0.505331\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393379; batch adversarial loss: 0.441126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.410879; batch adversarial loss: 0.516360\n",
      "epoch 138; iter: 0; batch classifier loss: 0.354323; batch adversarial loss: 0.476878\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373729; batch adversarial loss: 0.459379\n",
      "epoch 140; iter: 0; batch classifier loss: 0.319475; batch adversarial loss: 0.525684\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379635; batch adversarial loss: 0.459276\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393768; batch adversarial loss: 0.535202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.422123; batch adversarial loss: 0.467272\n",
      "epoch 144; iter: 0; batch classifier loss: 0.293166; batch adversarial loss: 0.515219\n",
      "epoch 145; iter: 0; batch classifier loss: 0.442400; batch adversarial loss: 0.582569\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387069; batch adversarial loss: 0.553127\n",
      "epoch 147; iter: 0; batch classifier loss: 0.366781; batch adversarial loss: 0.489847\n",
      "epoch 148; iter: 0; batch classifier loss: 0.427387; batch adversarial loss: 0.553765\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336201; batch adversarial loss: 0.517238\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358748; batch adversarial loss: 0.525291\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383440; batch adversarial loss: 0.449592\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353880; batch adversarial loss: 0.422756\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353854; batch adversarial loss: 0.505525\n",
      "epoch 154; iter: 0; batch classifier loss: 0.459518; batch adversarial loss: 0.610612\n",
      "epoch 155; iter: 0; batch classifier loss: 0.453464; batch adversarial loss: 0.496270\n",
      "epoch 156; iter: 0; batch classifier loss: 0.430189; batch adversarial loss: 0.592387\n",
      "epoch 157; iter: 0; batch classifier loss: 0.322426; batch adversarial loss: 0.525295\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397483; batch adversarial loss: 0.555546\n",
      "epoch 159; iter: 0; batch classifier loss: 0.401087; batch adversarial loss: 0.478061\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343837; batch adversarial loss: 0.478936\n",
      "epoch 161; iter: 0; batch classifier loss: 0.448861; batch adversarial loss: 0.516964\n",
      "epoch 162; iter: 0; batch classifier loss: 0.321724; batch adversarial loss: 0.516274\n",
      "epoch 163; iter: 0; batch classifier loss: 0.406887; batch adversarial loss: 0.523730\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397628; batch adversarial loss: 0.607944\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383447; batch adversarial loss: 0.480542\n",
      "epoch 166; iter: 0; batch classifier loss: 0.309617; batch adversarial loss: 0.506772\n",
      "epoch 167; iter: 0; batch classifier loss: 0.361690; batch adversarial loss: 0.562321\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363649; batch adversarial loss: 0.499033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374832; batch adversarial loss: 0.516601\n",
      "epoch 170; iter: 0; batch classifier loss: 0.394989; batch adversarial loss: 0.553903\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384713; batch adversarial loss: 0.601014\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326946; batch adversarial loss: 0.611386\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371805; batch adversarial loss: 0.592588\n",
      "epoch 174; iter: 0; batch classifier loss: 0.308854; batch adversarial loss: 0.553730\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339884; batch adversarial loss: 0.536129\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368123; batch adversarial loss: 0.544088\n",
      "epoch 177; iter: 0; batch classifier loss: 0.302697; batch adversarial loss: 0.508686\n",
      "epoch 178; iter: 0; batch classifier loss: 0.386253; batch adversarial loss: 0.525890\n",
      "epoch 179; iter: 0; batch classifier loss: 0.409770; batch adversarial loss: 0.535341\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353944; batch adversarial loss: 0.524760\n",
      "epoch 181; iter: 0; batch classifier loss: 0.412554; batch adversarial loss: 0.545211\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348855; batch adversarial loss: 0.572379\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347101; batch adversarial loss: 0.535573\n",
      "epoch 184; iter: 0; batch classifier loss: 0.280479; batch adversarial loss: 0.499578\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387399; batch adversarial loss: 0.573796\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327741; batch adversarial loss: 0.536494\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325206; batch adversarial loss: 0.516199\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361049; batch adversarial loss: 0.553897\n",
      "epoch 189; iter: 0; batch classifier loss: 0.359863; batch adversarial loss: 0.571623\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354558; batch adversarial loss: 0.554401\n",
      "epoch 191; iter: 0; batch classifier loss: 0.401899; batch adversarial loss: 0.535154\n",
      "epoch 192; iter: 0; batch classifier loss: 0.288795; batch adversarial loss: 0.572357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.399064; batch adversarial loss: 0.553587\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368260; batch adversarial loss: 0.470091\n",
      "epoch 195; iter: 0; batch classifier loss: 0.471207; batch adversarial loss: 0.552914\n",
      "epoch 196; iter: 0; batch classifier loss: 0.329705; batch adversarial loss: 0.574367\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386832; batch adversarial loss: 0.533017\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350743; batch adversarial loss: 0.513655\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338947; batch adversarial loss: 0.525023\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665828; batch adversarial loss: 0.769236\n",
      "epoch 1; iter: 0; batch classifier loss: 0.568978; batch adversarial loss: 0.729547\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531059; batch adversarial loss: 0.702300\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550907; batch adversarial loss: 0.667744\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542611; batch adversarial loss: 0.648533\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548035; batch adversarial loss: 0.619326\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564786; batch adversarial loss: 0.639270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565989; batch adversarial loss: 0.578923\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497245; batch adversarial loss: 0.581949\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540651; batch adversarial loss: 0.546582\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489993; batch adversarial loss: 0.583760\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515655; batch adversarial loss: 0.552477\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547428; batch adversarial loss: 0.514166\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550653; batch adversarial loss: 0.556133\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477624; batch adversarial loss: 0.519138\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505377; batch adversarial loss: 0.553460\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513589; batch adversarial loss: 0.606003\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499612; batch adversarial loss: 0.552708\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462001; batch adversarial loss: 0.553557\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485202; batch adversarial loss: 0.596610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.474457; batch adversarial loss: 0.611318\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520398; batch adversarial loss: 0.482281\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480515; batch adversarial loss: 0.564649\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519260; batch adversarial loss: 0.504003\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505837; batch adversarial loss: 0.566329\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467106; batch adversarial loss: 0.497540\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476081; batch adversarial loss: 0.561943\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509196; batch adversarial loss: 0.580664\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438088; batch adversarial loss: 0.533305\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483672; batch adversarial loss: 0.572224\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478739; batch adversarial loss: 0.555858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483234; batch adversarial loss: 0.497165\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436662; batch adversarial loss: 0.596760\n",
      "epoch 33; iter: 0; batch classifier loss: 0.528386; batch adversarial loss: 0.580744\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468172; batch adversarial loss: 0.520070\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488610; batch adversarial loss: 0.562337\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508181; batch adversarial loss: 0.501199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423098; batch adversarial loss: 0.606607\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441169; batch adversarial loss: 0.580793\n",
      "epoch 39; iter: 0; batch classifier loss: 0.400856; batch adversarial loss: 0.536026\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453698; batch adversarial loss: 0.490611\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441369; batch adversarial loss: 0.580456\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408303; batch adversarial loss: 0.680148\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491359; batch adversarial loss: 0.526541\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421320; batch adversarial loss: 0.517189\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425170; batch adversarial loss: 0.598817\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467376; batch adversarial loss: 0.605826\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409187; batch adversarial loss: 0.526941\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364628; batch adversarial loss: 0.543416\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425864; batch adversarial loss: 0.536735\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462937; batch adversarial loss: 0.516969\n",
      "epoch 51; iter: 0; batch classifier loss: 0.493247; batch adversarial loss: 0.451866\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471771; batch adversarial loss: 0.532643\n",
      "epoch 53; iter: 0; batch classifier loss: 0.366036; batch adversarial loss: 0.591176\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448303; batch adversarial loss: 0.477580\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423519; batch adversarial loss: 0.554705\n",
      "epoch 56; iter: 0; batch classifier loss: 0.519976; batch adversarial loss: 0.558391\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408852; batch adversarial loss: 0.581714\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390614; batch adversarial loss: 0.538217\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398153; batch adversarial loss: 0.616141\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384243; batch adversarial loss: 0.553005\n",
      "epoch 61; iter: 0; batch classifier loss: 0.345752; batch adversarial loss: 0.477228\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459058; batch adversarial loss: 0.535674\n",
      "epoch 63; iter: 0; batch classifier loss: 0.343919; batch adversarial loss: 0.563774\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413594; batch adversarial loss: 0.476502\n",
      "epoch 65; iter: 0; batch classifier loss: 0.533772; batch adversarial loss: 0.628704\n",
      "epoch 66; iter: 0; batch classifier loss: 0.450976; batch adversarial loss: 0.509664\n",
      "epoch 67; iter: 0; batch classifier loss: 0.419688; batch adversarial loss: 0.609028\n",
      "epoch 68; iter: 0; batch classifier loss: 0.365285; batch adversarial loss: 0.488655\n",
      "epoch 69; iter: 0; batch classifier loss: 0.454874; batch adversarial loss: 0.571165\n",
      "epoch 70; iter: 0; batch classifier loss: 0.477847; batch adversarial loss: 0.489472\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376707; batch adversarial loss: 0.499712\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387843; batch adversarial loss: 0.534953\n",
      "epoch 73; iter: 0; batch classifier loss: 0.331664; batch adversarial loss: 0.553861\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356106; batch adversarial loss: 0.599534\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400064; batch adversarial loss: 0.451768\n",
      "epoch 76; iter: 0; batch classifier loss: 0.431594; batch adversarial loss: 0.599502\n",
      "epoch 77; iter: 0; batch classifier loss: 0.457551; batch adversarial loss: 0.581603\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359356; batch adversarial loss: 0.545318\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380189; batch adversarial loss: 0.562135\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426771; batch adversarial loss: 0.518544\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384885; batch adversarial loss: 0.525193\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368635; batch adversarial loss: 0.563490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.354561; batch adversarial loss: 0.499150\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395262; batch adversarial loss: 0.627104\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381169; batch adversarial loss: 0.496373\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400335; batch adversarial loss: 0.526257\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356876; batch adversarial loss: 0.509641\n",
      "epoch 88; iter: 0; batch classifier loss: 0.461756; batch adversarial loss: 0.590400\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394059; batch adversarial loss: 0.499506\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404189; batch adversarial loss: 0.526984\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352760; batch adversarial loss: 0.623560\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348603; batch adversarial loss: 0.517782\n",
      "epoch 93; iter: 0; batch classifier loss: 0.452818; batch adversarial loss: 0.471955\n",
      "epoch 94; iter: 0; batch classifier loss: 0.349807; batch adversarial loss: 0.500431\n",
      "epoch 95; iter: 0; batch classifier loss: 0.403108; batch adversarial loss: 0.598857\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345864; batch adversarial loss: 0.575217\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363293; batch adversarial loss: 0.572377\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403176; batch adversarial loss: 0.590627\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359263; batch adversarial loss: 0.580929\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389429; batch adversarial loss: 0.481858\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353434; batch adversarial loss: 0.518728\n",
      "epoch 102; iter: 0; batch classifier loss: 0.344381; batch adversarial loss: 0.534548\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367076; batch adversarial loss: 0.599047\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397367; batch adversarial loss: 0.553280\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373331; batch adversarial loss: 0.526343\n",
      "epoch 106; iter: 0; batch classifier loss: 0.460169; batch adversarial loss: 0.562807\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392962; batch adversarial loss: 0.582070\n",
      "epoch 108; iter: 0; batch classifier loss: 0.438412; batch adversarial loss: 0.638149\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359369; batch adversarial loss: 0.601360\n",
      "epoch 110; iter: 0; batch classifier loss: 0.326258; batch adversarial loss: 0.525572\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355178; batch adversarial loss: 0.573133\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406641; batch adversarial loss: 0.535144\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345950; batch adversarial loss: 0.488345\n",
      "epoch 114; iter: 0; batch classifier loss: 0.313760; batch adversarial loss: 0.637845\n",
      "epoch 115; iter: 0; batch classifier loss: 0.319165; batch adversarial loss: 0.525283\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372417; batch adversarial loss: 0.600960\n",
      "epoch 117; iter: 0; batch classifier loss: 0.287305; batch adversarial loss: 0.581993\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389182; batch adversarial loss: 0.516959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.419598; batch adversarial loss: 0.498071\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341419; batch adversarial loss: 0.506947\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338874; batch adversarial loss: 0.562680\n",
      "epoch 122; iter: 0; batch classifier loss: 0.324789; batch adversarial loss: 0.581852\n",
      "epoch 123; iter: 0; batch classifier loss: 0.419253; batch adversarial loss: 0.534900\n",
      "epoch 124; iter: 0; batch classifier loss: 0.424528; batch adversarial loss: 0.590553\n",
      "epoch 125; iter: 0; batch classifier loss: 0.306617; batch adversarial loss: 0.526436\n",
      "epoch 126; iter: 0; batch classifier loss: 0.460372; batch adversarial loss: 0.526475\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396750; batch adversarial loss: 0.553717\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403619; batch adversarial loss: 0.609679\n",
      "epoch 129; iter: 0; batch classifier loss: 0.296266; batch adversarial loss: 0.544919\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325157; batch adversarial loss: 0.459738\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372237; batch adversarial loss: 0.460114\n",
      "epoch 132; iter: 0; batch classifier loss: 0.374975; batch adversarial loss: 0.506973\n",
      "epoch 133; iter: 0; batch classifier loss: 0.457846; batch adversarial loss: 0.553796\n",
      "epoch 134; iter: 0; batch classifier loss: 0.389701; batch adversarial loss: 0.535226\n",
      "epoch 135; iter: 0; batch classifier loss: 0.398455; batch adversarial loss: 0.478521\n",
      "epoch 136; iter: 0; batch classifier loss: 0.400625; batch adversarial loss: 0.506623\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351823; batch adversarial loss: 0.553325\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364870; batch adversarial loss: 0.470750\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344160; batch adversarial loss: 0.590208\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360669; batch adversarial loss: 0.469230\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348036; batch adversarial loss: 0.562402\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330334; batch adversarial loss: 0.507250\n",
      "epoch 143; iter: 0; batch classifier loss: 0.439308; batch adversarial loss: 0.497932\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395464; batch adversarial loss: 0.571829\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377083; batch adversarial loss: 0.629396\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389520; batch adversarial loss: 0.461713\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381783; batch adversarial loss: 0.487942\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323763; batch adversarial loss: 0.553363\n",
      "epoch 149; iter: 0; batch classifier loss: 0.447728; batch adversarial loss: 0.563520\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337437; batch adversarial loss: 0.563253\n",
      "epoch 151; iter: 0; batch classifier loss: 0.463949; batch adversarial loss: 0.516794\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398230; batch adversarial loss: 0.573100\n",
      "epoch 153; iter: 0; batch classifier loss: 0.397625; batch adversarial loss: 0.620344\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404539; batch adversarial loss: 0.572098\n",
      "epoch 155; iter: 0; batch classifier loss: 0.299444; batch adversarial loss: 0.488270\n",
      "epoch 156; iter: 0; batch classifier loss: 0.331158; batch adversarial loss: 0.507398\n",
      "epoch 157; iter: 0; batch classifier loss: 0.395012; batch adversarial loss: 0.498651\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373749; batch adversarial loss: 0.527551\n",
      "epoch 159; iter: 0; batch classifier loss: 0.319464; batch adversarial loss: 0.507188\n",
      "epoch 160; iter: 0; batch classifier loss: 0.302959; batch adversarial loss: 0.618953\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400905; batch adversarial loss: 0.599411\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370067; batch adversarial loss: 0.506561\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342679; batch adversarial loss: 0.525685\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350804; batch adversarial loss: 0.591079\n",
      "epoch 165; iter: 0; batch classifier loss: 0.448080; batch adversarial loss: 0.469889\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323853; batch adversarial loss: 0.516380\n",
      "epoch 167; iter: 0; batch classifier loss: 0.388841; batch adversarial loss: 0.506357\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315762; batch adversarial loss: 0.619857\n",
      "epoch 169; iter: 0; batch classifier loss: 0.441852; batch adversarial loss: 0.536659\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349761; batch adversarial loss: 0.431660\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363484; batch adversarial loss: 0.534429\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333188; batch adversarial loss: 0.581856\n",
      "epoch 173; iter: 0; batch classifier loss: 0.374646; batch adversarial loss: 0.590398\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380976; batch adversarial loss: 0.507080\n",
      "epoch 175; iter: 0; batch classifier loss: 0.353299; batch adversarial loss: 0.628823\n",
      "epoch 176; iter: 0; batch classifier loss: 0.386976; batch adversarial loss: 0.442779\n",
      "epoch 177; iter: 0; batch classifier loss: 0.353818; batch adversarial loss: 0.609625\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336707; batch adversarial loss: 0.525952\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337023; batch adversarial loss: 0.524637\n",
      "epoch 180; iter: 0; batch classifier loss: 0.309791; batch adversarial loss: 0.581176\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337625; batch adversarial loss: 0.573609\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383216; batch adversarial loss: 0.535905\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358995; batch adversarial loss: 0.563712\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350782; batch adversarial loss: 0.535275\n",
      "epoch 185; iter: 0; batch classifier loss: 0.434553; batch adversarial loss: 0.535214\n",
      "epoch 186; iter: 0; batch classifier loss: 0.306819; batch adversarial loss: 0.563265\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.442755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363350; batch adversarial loss: 0.571184\n",
      "epoch 189; iter: 0; batch classifier loss: 0.233917; batch adversarial loss: 0.516670\n",
      "epoch 190; iter: 0; batch classifier loss: 0.316753; batch adversarial loss: 0.488347\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347472; batch adversarial loss: 0.553259\n",
      "epoch 192; iter: 0; batch classifier loss: 0.379052; batch adversarial loss: 0.580875\n",
      "epoch 193; iter: 0; batch classifier loss: 0.363023; batch adversarial loss: 0.563238\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321251; batch adversarial loss: 0.591785\n",
      "epoch 195; iter: 0; batch classifier loss: 0.314209; batch adversarial loss: 0.609486\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286598; batch adversarial loss: 0.544156\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386178; batch adversarial loss: 0.534492\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319515; batch adversarial loss: 0.516815\n",
      "epoch 199; iter: 0; batch classifier loss: 0.456715; batch adversarial loss: 0.535426\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735971; batch adversarial loss: 0.690331\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618524; batch adversarial loss: 0.662086\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592529; batch adversarial loss: 0.642902\n",
      "epoch 3; iter: 0; batch classifier loss: 0.604177; batch adversarial loss: 0.629783\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588807; batch adversarial loss: 0.608537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575159; batch adversarial loss: 0.619194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484208; batch adversarial loss: 0.649375\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529419; batch adversarial loss: 0.597416\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522617; batch adversarial loss: 0.591201\n",
      "epoch 9; iter: 0; batch classifier loss: 0.469744; batch adversarial loss: 0.589632\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504073; batch adversarial loss: 0.586381\n",
      "epoch 11; iter: 0; batch classifier loss: 0.486313; batch adversarial loss: 0.580614\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516039; batch adversarial loss: 0.568253\n",
      "epoch 13; iter: 0; batch classifier loss: 0.602480; batch adversarial loss: 0.614524\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569347; batch adversarial loss: 0.593088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.558693; batch adversarial loss: 0.603964\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454229; batch adversarial loss: 0.543967\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506572; batch adversarial loss: 0.564994\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497037; batch adversarial loss: 0.603501\n",
      "epoch 19; iter: 0; batch classifier loss: 0.546552; batch adversarial loss: 0.589311\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518068; batch adversarial loss: 0.552741\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477033; batch adversarial loss: 0.522551\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493073; batch adversarial loss: 0.573869\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502272; batch adversarial loss: 0.549347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477936; batch adversarial loss: 0.531358\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504796; batch adversarial loss: 0.587949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483138; batch adversarial loss: 0.612163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459727; batch adversarial loss: 0.529868\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475537; batch adversarial loss: 0.561843\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461520; batch adversarial loss: 0.519389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463479; batch adversarial loss: 0.544603\n",
      "epoch 31; iter: 0; batch classifier loss: 0.524389; batch adversarial loss: 0.545073\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438124; batch adversarial loss: 0.545510\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425711; batch adversarial loss: 0.622283\n",
      "epoch 34; iter: 0; batch classifier loss: 0.493593; batch adversarial loss: 0.570651\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433719; batch adversarial loss: 0.510778\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390597; batch adversarial loss: 0.518013\n",
      "epoch 37; iter: 0; batch classifier loss: 0.559589; batch adversarial loss: 0.527561\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512113; batch adversarial loss: 0.631671\n",
      "epoch 39; iter: 0; batch classifier loss: 0.531928; batch adversarial loss: 0.500486\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401468; batch adversarial loss: 0.545696\n",
      "epoch 41; iter: 0; batch classifier loss: 0.374874; batch adversarial loss: 0.527601\n",
      "epoch 42; iter: 0; batch classifier loss: 0.376120; batch adversarial loss: 0.580773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484990; batch adversarial loss: 0.526698\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474591; batch adversarial loss: 0.571854\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411866; batch adversarial loss: 0.607407\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453866; batch adversarial loss: 0.500214\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460602; batch adversarial loss: 0.542921\n",
      "epoch 48; iter: 0; batch classifier loss: 0.390433; batch adversarial loss: 0.507881\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418531; batch adversarial loss: 0.571488\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432671; batch adversarial loss: 0.633744\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414424; batch adversarial loss: 0.543404\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424341; batch adversarial loss: 0.562438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.510026; batch adversarial loss: 0.615040\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421055; batch adversarial loss: 0.589457\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450491; batch adversarial loss: 0.535481\n",
      "epoch 56; iter: 0; batch classifier loss: 0.464586; batch adversarial loss: 0.535706\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450557; batch adversarial loss: 0.615471\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419683; batch adversarial loss: 0.626814\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424175; batch adversarial loss: 0.553064\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451160; batch adversarial loss: 0.616688\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445310; batch adversarial loss: 0.607467\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372143; batch adversarial loss: 0.517468\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417951; batch adversarial loss: 0.543789\n",
      "epoch 64; iter: 0; batch classifier loss: 0.512372; batch adversarial loss: 0.544773\n",
      "epoch 65; iter: 0; batch classifier loss: 0.464291; batch adversarial loss: 0.528446\n",
      "epoch 66; iter: 0; batch classifier loss: 0.448708; batch adversarial loss: 0.518343\n",
      "epoch 67; iter: 0; batch classifier loss: 0.520236; batch adversarial loss: 0.571773\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423149; batch adversarial loss: 0.590546\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406214; batch adversarial loss: 0.515224\n",
      "epoch 70; iter: 0; batch classifier loss: 0.487126; batch adversarial loss: 0.642229\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425480; batch adversarial loss: 0.589328\n",
      "epoch 72; iter: 0; batch classifier loss: 0.321289; batch adversarial loss: 0.498755\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409052; batch adversarial loss: 0.553795\n",
      "epoch 74; iter: 0; batch classifier loss: 0.407717; batch adversarial loss: 0.537277\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443904; batch adversarial loss: 0.516469\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388606; batch adversarial loss: 0.507382\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401616; batch adversarial loss: 0.491825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393992; batch adversarial loss: 0.464576\n",
      "epoch 79; iter: 0; batch classifier loss: 0.447653; batch adversarial loss: 0.521544\n",
      "epoch 80; iter: 0; batch classifier loss: 0.386195; batch adversarial loss: 0.483144\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407007; batch adversarial loss: 0.606840\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411207; batch adversarial loss: 0.562216\n",
      "epoch 83; iter: 0; batch classifier loss: 0.519542; batch adversarial loss: 0.508159\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378708; batch adversarial loss: 0.518880\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419165; batch adversarial loss: 0.615945\n",
      "epoch 86; iter: 0; batch classifier loss: 0.445041; batch adversarial loss: 0.472962\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383223; batch adversarial loss: 0.553592\n",
      "epoch 88; iter: 0; batch classifier loss: 0.451153; batch adversarial loss: 0.563349\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406979; batch adversarial loss: 0.598201\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378557; batch adversarial loss: 0.517495\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422874; batch adversarial loss: 0.562297\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395600; batch adversarial loss: 0.551466\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417043; batch adversarial loss: 0.559276\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426762; batch adversarial loss: 0.733400\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427155; batch adversarial loss: 0.537064\n",
      "epoch 96; iter: 0; batch classifier loss: 0.473959; batch adversarial loss: 0.570402\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440632; batch adversarial loss: 0.535997\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406080; batch adversarial loss: 0.545204\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359665; batch adversarial loss: 0.608256\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370537; batch adversarial loss: 0.553454\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353292; batch adversarial loss: 0.545514\n",
      "epoch 102; iter: 0; batch classifier loss: 0.476985; batch adversarial loss: 0.481461\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416111; batch adversarial loss: 0.572381\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391216; batch adversarial loss: 0.518495\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373133; batch adversarial loss: 0.496708\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395535; batch adversarial loss: 0.526942\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363984; batch adversarial loss: 0.654160\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363696; batch adversarial loss: 0.552484\n",
      "epoch 109; iter: 0; batch classifier loss: 0.395172; batch adversarial loss: 0.600372\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390851; batch adversarial loss: 0.589139\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335684; batch adversarial loss: 0.563544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430391; batch adversarial loss: 0.535016\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362896; batch adversarial loss: 0.455749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.430998; batch adversarial loss: 0.589599\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445946; batch adversarial loss: 0.518170\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392581; batch adversarial loss: 0.553495\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388683; batch adversarial loss: 0.635047\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367382; batch adversarial loss: 0.560510\n",
      "epoch 119; iter: 0; batch classifier loss: 0.450004; batch adversarial loss: 0.551418\n",
      "epoch 120; iter: 0; batch classifier loss: 0.461602; batch adversarial loss: 0.551953\n",
      "epoch 121; iter: 0; batch classifier loss: 0.475408; batch adversarial loss: 0.571714\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394146; batch adversarial loss: 0.553658\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393264; batch adversarial loss: 0.562264\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358883; batch adversarial loss: 0.555726\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353210; batch adversarial loss: 0.553169\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395471; batch adversarial loss: 0.525632\n",
      "epoch 127; iter: 0; batch classifier loss: 0.470429; batch adversarial loss: 0.458479\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385149; batch adversarial loss: 0.613131\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403933; batch adversarial loss: 0.571094\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340810; batch adversarial loss: 0.523738\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338960; batch adversarial loss: 0.532273\n",
      "epoch 132; iter: 0; batch classifier loss: 0.301947; batch adversarial loss: 0.577539\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.473471\n",
      "epoch 134; iter: 0; batch classifier loss: 0.513996; batch adversarial loss: 0.545614\n",
      "epoch 135; iter: 0; batch classifier loss: 0.458032; batch adversarial loss: 0.640512\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397709; batch adversarial loss: 0.465339\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372790; batch adversarial loss: 0.478040\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366349; batch adversarial loss: 0.625448\n",
      "epoch 139; iter: 0; batch classifier loss: 0.417058; batch adversarial loss: 0.577359\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393700; batch adversarial loss: 0.550304\n",
      "epoch 141; iter: 0; batch classifier loss: 0.410876; batch adversarial loss: 0.518269\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393493; batch adversarial loss: 0.553801\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389249; batch adversarial loss: 0.556297\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350337; batch adversarial loss: 0.446100\n",
      "epoch 145; iter: 0; batch classifier loss: 0.442697; batch adversarial loss: 0.576595\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395613; batch adversarial loss: 0.544869\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347111; batch adversarial loss: 0.571593\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392015; batch adversarial loss: 0.535031\n",
      "epoch 149; iter: 0; batch classifier loss: 0.390191; batch adversarial loss: 0.517462\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356772; batch adversarial loss: 0.553457\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341576; batch adversarial loss: 0.519570\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363222; batch adversarial loss: 0.579824\n",
      "epoch 153; iter: 0; batch classifier loss: 0.425148; batch adversarial loss: 0.500188\n",
      "epoch 154; iter: 0; batch classifier loss: 0.420116; batch adversarial loss: 0.497435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.404895; batch adversarial loss: 0.488203\n",
      "epoch 156; iter: 0; batch classifier loss: 0.364123; batch adversarial loss: 0.617499\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400145; batch adversarial loss: 0.583435\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340378; batch adversarial loss: 0.498240\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390441; batch adversarial loss: 0.599740\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333008; batch adversarial loss: 0.554801\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384114; batch adversarial loss: 0.560045\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368652; batch adversarial loss: 0.569737\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330111; batch adversarial loss: 0.482716\n",
      "epoch 164; iter: 0; batch classifier loss: 0.433190; batch adversarial loss: 0.582663\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361396; batch adversarial loss: 0.569532\n",
      "epoch 166; iter: 0; batch classifier loss: 0.419117; batch adversarial loss: 0.553884\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349536; batch adversarial loss: 0.555093\n",
      "epoch 168; iter: 0; batch classifier loss: 0.413332; batch adversarial loss: 0.552893\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374329; batch adversarial loss: 0.628152\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322135; batch adversarial loss: 0.605937\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353129; batch adversarial loss: 0.463647\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366664; batch adversarial loss: 0.494431\n",
      "epoch 173; iter: 0; batch classifier loss: 0.424308; batch adversarial loss: 0.542116\n",
      "epoch 174; iter: 0; batch classifier loss: 0.447644; batch adversarial loss: 0.616526\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325844; batch adversarial loss: 0.481674\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319665; batch adversarial loss: 0.596397\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335629; batch adversarial loss: 0.519125\n",
      "epoch 178; iter: 0; batch classifier loss: 0.296244; batch adversarial loss: 0.553033\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298786; batch adversarial loss: 0.571326\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368604; batch adversarial loss: 0.661780\n",
      "epoch 181; iter: 0; batch classifier loss: 0.394032; batch adversarial loss: 0.604303\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376746; batch adversarial loss: 0.499792\n",
      "epoch 183; iter: 0; batch classifier loss: 0.411687; batch adversarial loss: 0.503481\n",
      "epoch 184; iter: 0; batch classifier loss: 0.333755; batch adversarial loss: 0.657432\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319279; batch adversarial loss: 0.534937\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390596; batch adversarial loss: 0.507756\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339843; batch adversarial loss: 0.581463\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361556; batch adversarial loss: 0.558368\n",
      "epoch 189; iter: 0; batch classifier loss: 0.434339; batch adversarial loss: 0.558934\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391159; batch adversarial loss: 0.507180\n",
      "epoch 191; iter: 0; batch classifier loss: 0.424920; batch adversarial loss: 0.557040\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349279; batch adversarial loss: 0.535156\n",
      "epoch 193; iter: 0; batch classifier loss: 0.363467; batch adversarial loss: 0.543776\n",
      "epoch 194; iter: 0; batch classifier loss: 0.272106; batch adversarial loss: 0.552238\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390195; batch adversarial loss: 0.546469\n",
      "epoch 196; iter: 0; batch classifier loss: 0.432147; batch adversarial loss: 0.529329\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345859; batch adversarial loss: 0.507956\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354428; batch adversarial loss: 0.507030\n",
      "epoch 199; iter: 0; batch classifier loss: 0.375802; batch adversarial loss: 0.525070\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730290; batch adversarial loss: 0.973258\n",
      "epoch 1; iter: 0; batch classifier loss: 0.876866; batch adversarial loss: 1.277170\n",
      "epoch 2; iter: 0; batch classifier loss: 0.980246; batch adversarial loss: 1.197292\n",
      "epoch 3; iter: 0; batch classifier loss: 1.109485; batch adversarial loss: 1.100899\n",
      "epoch 4; iter: 0; batch classifier loss: 1.202928; batch adversarial loss: 1.054228\n",
      "epoch 5; iter: 0; batch classifier loss: 1.042511; batch adversarial loss: 0.919942\n",
      "epoch 6; iter: 0; batch classifier loss: 1.223090; batch adversarial loss: 0.886078\n",
      "epoch 7; iter: 0; batch classifier loss: 1.047298; batch adversarial loss: 0.814272\n",
      "epoch 8; iter: 0; batch classifier loss: 1.119014; batch adversarial loss: 0.769571\n",
      "epoch 9; iter: 0; batch classifier loss: 1.006583; batch adversarial loss: 0.689119\n",
      "epoch 10; iter: 0; batch classifier loss: 0.922622; batch adversarial loss: 0.625027\n",
      "epoch 11; iter: 0; batch classifier loss: 0.718635; batch adversarial loss: 0.629743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.621977; batch adversarial loss: 0.595981\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541269; batch adversarial loss: 0.585172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522586; batch adversarial loss: 0.614145\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465802; batch adversarial loss: 0.560741\n",
      "epoch 16; iter: 0; batch classifier loss: 0.567890; batch adversarial loss: 0.546668\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505912; batch adversarial loss: 0.571793\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512680; batch adversarial loss: 0.531687\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545797; batch adversarial loss: 0.631348\n",
      "epoch 20; iter: 0; batch classifier loss: 0.533590; batch adversarial loss: 0.556750\n",
      "epoch 21; iter: 0; batch classifier loss: 0.574246; batch adversarial loss: 0.586680\n",
      "epoch 22; iter: 0; batch classifier loss: 0.585670; batch adversarial loss: 0.555509\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432644; batch adversarial loss: 0.560004\n",
      "epoch 24; iter: 0; batch classifier loss: 0.543876; batch adversarial loss: 0.505772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472546; batch adversarial loss: 0.552875\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459232; batch adversarial loss: 0.584741\n",
      "epoch 27; iter: 0; batch classifier loss: 0.579030; batch adversarial loss: 0.611776\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481427; batch adversarial loss: 0.535535\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454095; batch adversarial loss: 0.565149\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456277; batch adversarial loss: 0.548445\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480384; batch adversarial loss: 0.509059\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419701; batch adversarial loss: 0.597958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462476; batch adversarial loss: 0.592856\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460907; batch adversarial loss: 0.572955\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479950; batch adversarial loss: 0.493839\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397948; batch adversarial loss: 0.560495\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442386; batch adversarial loss: 0.562115\n",
      "epoch 38; iter: 0; batch classifier loss: 0.495784; batch adversarial loss: 0.477368\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431110; batch adversarial loss: 0.594132\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492470; batch adversarial loss: 0.523265\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499768; batch adversarial loss: 0.582404\n",
      "epoch 42; iter: 0; batch classifier loss: 0.437212; batch adversarial loss: 0.533512\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474530; batch adversarial loss: 0.697511\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462452; batch adversarial loss: 0.533850\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415163; batch adversarial loss: 0.531731\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459066; batch adversarial loss: 0.559813\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397305; batch adversarial loss: 0.640852\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491957; batch adversarial loss: 0.570749\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373840; batch adversarial loss: 0.546240\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450861; batch adversarial loss: 0.583339\n",
      "epoch 51; iter: 0; batch classifier loss: 0.358204; batch adversarial loss: 0.596425\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390253; batch adversarial loss: 0.618818\n",
      "epoch 53; iter: 0; batch classifier loss: 0.385792; batch adversarial loss: 0.581399\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418723; batch adversarial loss: 0.501290\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443098; batch adversarial loss: 0.600185\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396104; batch adversarial loss: 0.518839\n",
      "epoch 57; iter: 0; batch classifier loss: 0.514419; batch adversarial loss: 0.653725\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386106; batch adversarial loss: 0.636030\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421565; batch adversarial loss: 0.517212\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437865; batch adversarial loss: 0.544567\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417504; batch adversarial loss: 0.572167\n",
      "epoch 62; iter: 0; batch classifier loss: 0.517236; batch adversarial loss: 0.517463\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384703; batch adversarial loss: 0.553581\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434224; batch adversarial loss: 0.499321\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438936; batch adversarial loss: 0.499035\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449164; batch adversarial loss: 0.543903\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414007; batch adversarial loss: 0.598624\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395129; batch adversarial loss: 0.480168\n",
      "epoch 69; iter: 0; batch classifier loss: 0.481264; batch adversarial loss: 0.507286\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416016; batch adversarial loss: 0.599867\n",
      "epoch 71; iter: 0; batch classifier loss: 0.455021; batch adversarial loss: 0.525918\n",
      "epoch 72; iter: 0; batch classifier loss: 0.375908; batch adversarial loss: 0.571218\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375899; batch adversarial loss: 0.561686\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465704; batch adversarial loss: 0.580653\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370233; batch adversarial loss: 0.498499\n",
      "epoch 76; iter: 0; batch classifier loss: 0.356962; batch adversarial loss: 0.517915\n",
      "epoch 77; iter: 0; batch classifier loss: 0.337511; batch adversarial loss: 0.555629\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358955; batch adversarial loss: 0.623643\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411639; batch adversarial loss: 0.564989\n",
      "epoch 80; iter: 0; batch classifier loss: 0.329193; batch adversarial loss: 0.535695\n",
      "epoch 81; iter: 0; batch classifier loss: 0.447455; batch adversarial loss: 0.637663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363981; batch adversarial loss: 0.513671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416018; batch adversarial loss: 0.480777\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415689; batch adversarial loss: 0.566192\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403099; batch adversarial loss: 0.531293\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356876; batch adversarial loss: 0.506799\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406470; batch adversarial loss: 0.606891\n",
      "epoch 88; iter: 0; batch classifier loss: 0.321681; batch adversarial loss: 0.496279\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400486; batch adversarial loss: 0.530700\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345875; batch adversarial loss: 0.522966\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364352; batch adversarial loss: 0.543270\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353855; batch adversarial loss: 0.520152\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367942; batch adversarial loss: 0.651177\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449622; batch adversarial loss: 0.489750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.370274; batch adversarial loss: 0.631040\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384722; batch adversarial loss: 0.534400\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384131; batch adversarial loss: 0.508114\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375735; batch adversarial loss: 0.539601\n",
      "epoch 99; iter: 0; batch classifier loss: 0.343147; batch adversarial loss: 0.574786\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384481; batch adversarial loss: 0.497699\n",
      "epoch 101; iter: 0; batch classifier loss: 0.348393; batch adversarial loss: 0.586957\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373631; batch adversarial loss: 0.673620\n",
      "epoch 103; iter: 0; batch classifier loss: 0.316144; batch adversarial loss: 0.507388\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362888; batch adversarial loss: 0.489486\n",
      "epoch 105; iter: 0; batch classifier loss: 0.375613; batch adversarial loss: 0.612363\n",
      "epoch 106; iter: 0; batch classifier loss: 0.348495; batch adversarial loss: 0.582969\n",
      "epoch 107; iter: 0; batch classifier loss: 0.340382; batch adversarial loss: 0.489751\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388428; batch adversarial loss: 0.600122\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367508; batch adversarial loss: 0.499499\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381942; batch adversarial loss: 0.658333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.325192; batch adversarial loss: 0.508345\n",
      "epoch 112; iter: 0; batch classifier loss: 0.327800; batch adversarial loss: 0.596253\n",
      "epoch 113; iter: 0; batch classifier loss: 0.304905; batch adversarial loss: 0.582755\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361398; batch adversarial loss: 0.559222\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355724; batch adversarial loss: 0.518429\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412224; batch adversarial loss: 0.579744\n",
      "epoch 117; iter: 0; batch classifier loss: 0.343864; batch adversarial loss: 0.582075\n",
      "epoch 118; iter: 0; batch classifier loss: 0.303040; batch adversarial loss: 0.571648\n",
      "epoch 119; iter: 0; batch classifier loss: 0.346493; batch adversarial loss: 0.590811\n",
      "epoch 120; iter: 0; batch classifier loss: 0.458700; batch adversarial loss: 0.553618\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368289; batch adversarial loss: 0.435856\n",
      "epoch 122; iter: 0; batch classifier loss: 0.332839; batch adversarial loss: 0.539806\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346300; batch adversarial loss: 0.488255\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372283; batch adversarial loss: 0.607272\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371029; batch adversarial loss: 0.544581\n",
      "epoch 126; iter: 0; batch classifier loss: 0.352716; batch adversarial loss: 0.634039\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353005; batch adversarial loss: 0.577442\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356670; batch adversarial loss: 0.469732\n",
      "epoch 129; iter: 0; batch classifier loss: 0.439482; batch adversarial loss: 0.590650\n",
      "epoch 130; iter: 0; batch classifier loss: 0.367399; batch adversarial loss: 0.503224\n",
      "epoch 131; iter: 0; batch classifier loss: 0.292851; batch adversarial loss: 0.507666\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371513; batch adversarial loss: 0.585262\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397175; batch adversarial loss: 0.594322\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337727; batch adversarial loss: 0.542598\n",
      "epoch 135; iter: 0; batch classifier loss: 0.398328; batch adversarial loss: 0.573369\n",
      "epoch 136; iter: 0; batch classifier loss: 0.335477; batch adversarial loss: 0.514829\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368590; batch adversarial loss: 0.525375\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381206; batch adversarial loss: 0.590884\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356565; batch adversarial loss: 0.562417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396284; batch adversarial loss: 0.528685\n",
      "epoch 141; iter: 0; batch classifier loss: 0.309780; batch adversarial loss: 0.509960\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353163; batch adversarial loss: 0.580618\n",
      "epoch 143; iter: 0; batch classifier loss: 0.341846; batch adversarial loss: 0.519159\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346560; batch adversarial loss: 0.536489\n",
      "epoch 145; iter: 0; batch classifier loss: 0.315470; batch adversarial loss: 0.539927\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418991; batch adversarial loss: 0.563409\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391240; batch adversarial loss: 0.673173\n",
      "epoch 148; iter: 0; batch classifier loss: 0.451286; batch adversarial loss: 0.536262\n",
      "epoch 149; iter: 0; batch classifier loss: 0.408036; batch adversarial loss: 0.479983\n",
      "epoch 150; iter: 0; batch classifier loss: 0.386686; batch adversarial loss: 0.565498\n",
      "epoch 151; iter: 0; batch classifier loss: 0.302584; batch adversarial loss: 0.529455\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385353; batch adversarial loss: 0.480564\n",
      "epoch 153; iter: 0; batch classifier loss: 0.347757; batch adversarial loss: 0.552888\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365440; batch adversarial loss: 0.565699\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373683; batch adversarial loss: 0.473625\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378034; batch adversarial loss: 0.503553\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366629; batch adversarial loss: 0.573407\n",
      "epoch 158; iter: 0; batch classifier loss: 0.279591; batch adversarial loss: 0.585013\n",
      "epoch 159; iter: 0; batch classifier loss: 0.264675; batch adversarial loss: 0.468545\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395250; batch adversarial loss: 0.646997\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366025; batch adversarial loss: 0.616246\n",
      "epoch 162; iter: 0; batch classifier loss: 0.272126; batch adversarial loss: 0.519032\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364311; batch adversarial loss: 0.563924\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371576; batch adversarial loss: 0.537228\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374790; batch adversarial loss: 0.544054\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332069; batch adversarial loss: 0.543197\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337800; batch adversarial loss: 0.585686\n",
      "epoch 168; iter: 0; batch classifier loss: 0.242244; batch adversarial loss: 0.541588\n",
      "epoch 169; iter: 0; batch classifier loss: 0.361809; batch adversarial loss: 0.565378\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318710; batch adversarial loss: 0.554144\n",
      "epoch 171; iter: 0; batch classifier loss: 0.282877; batch adversarial loss: 0.517094\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368400; batch adversarial loss: 0.479334\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333942; batch adversarial loss: 0.596519\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364004; batch adversarial loss: 0.499283\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363784; batch adversarial loss: 0.550084\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383663; batch adversarial loss: 0.592415\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377673; batch adversarial loss: 0.535197\n",
      "epoch 178; iter: 0; batch classifier loss: 0.305553; batch adversarial loss: 0.499252\n",
      "epoch 179; iter: 0; batch classifier loss: 0.282374; batch adversarial loss: 0.532442\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322618; batch adversarial loss: 0.579916\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379352; batch adversarial loss: 0.592371\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344038; batch adversarial loss: 0.545597\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333299; batch adversarial loss: 0.552248\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332080; batch adversarial loss: 0.511064\n",
      "epoch 185; iter: 0; batch classifier loss: 0.277734; batch adversarial loss: 0.590185\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349875; batch adversarial loss: 0.589596\n",
      "epoch 187; iter: 0; batch classifier loss: 0.306945; batch adversarial loss: 0.573997\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.557987\n",
      "epoch 189; iter: 0; batch classifier loss: 0.286085; batch adversarial loss: 0.531233\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359615; batch adversarial loss: 0.634947\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358349; batch adversarial loss: 0.516662\n",
      "epoch 192; iter: 0; batch classifier loss: 0.276229; batch adversarial loss: 0.613897\n",
      "epoch 193; iter: 0; batch classifier loss: 0.269776; batch adversarial loss: 0.506298\n",
      "epoch 194; iter: 0; batch classifier loss: 0.231722; batch adversarial loss: 0.542343\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321889; batch adversarial loss: 0.526120\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400455; batch adversarial loss: 0.532087\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377007; batch adversarial loss: 0.571115\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382261; batch adversarial loss: 0.485603\n",
      "epoch 199; iter: 0; batch classifier loss: 0.307494; batch adversarial loss: 0.516189\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709493; batch adversarial loss: 0.876905\n",
      "epoch 1; iter: 0; batch classifier loss: 0.831272; batch adversarial loss: 0.967480\n",
      "epoch 2; iter: 0; batch classifier loss: 0.950699; batch adversarial loss: 0.935813\n",
      "epoch 3; iter: 0; batch classifier loss: 0.981308; batch adversarial loss: 0.853506\n",
      "epoch 4; iter: 0; batch classifier loss: 1.067674; batch adversarial loss: 0.795565\n",
      "epoch 5; iter: 0; batch classifier loss: 1.009414; batch adversarial loss: 0.721498\n",
      "epoch 6; iter: 0; batch classifier loss: 0.936639; batch adversarial loss: 0.663459\n",
      "epoch 7; iter: 0; batch classifier loss: 0.781839; batch adversarial loss: 0.632356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.629605; batch adversarial loss: 0.648438\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580462; batch adversarial loss: 0.629248\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533380; batch adversarial loss: 0.570181\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473455; batch adversarial loss: 0.553704\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578035; batch adversarial loss: 0.586489\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539497; batch adversarial loss: 0.555326\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532613; batch adversarial loss: 0.577399\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553627; batch adversarial loss: 0.529588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.574533; batch adversarial loss: 0.550590\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537010; batch adversarial loss: 0.558390\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529374; batch adversarial loss: 0.502432\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524719; batch adversarial loss: 0.537562\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530401; batch adversarial loss: 0.529525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479636; batch adversarial loss: 0.544576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505184; batch adversarial loss: 0.602180\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452398; batch adversarial loss: 0.532861\n",
      "epoch 24; iter: 0; batch classifier loss: 0.588944; batch adversarial loss: 0.532863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490120; batch adversarial loss: 0.559450\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519833; batch adversarial loss: 0.550229\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529312; batch adversarial loss: 0.593262\n",
      "epoch 28; iter: 0; batch classifier loss: 0.394154; batch adversarial loss: 0.595897\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456300; batch adversarial loss: 0.568908\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477211; batch adversarial loss: 0.537215\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490710; batch adversarial loss: 0.474089\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443486; batch adversarial loss: 0.492886\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465968; batch adversarial loss: 0.565317\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417442; batch adversarial loss: 0.507383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395541; batch adversarial loss: 0.564309\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462382; batch adversarial loss: 0.510872\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464096; batch adversarial loss: 0.542745\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452286; batch adversarial loss: 0.503503\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411647; batch adversarial loss: 0.599248\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383286; batch adversarial loss: 0.588400\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435585; batch adversarial loss: 0.581924\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431998; batch adversarial loss: 0.593745\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415687; batch adversarial loss: 0.676401\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462775; batch adversarial loss: 0.607375\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448244; batch adversarial loss: 0.534674\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454218; batch adversarial loss: 0.502429\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433198; batch adversarial loss: 0.517927\n",
      "epoch 48; iter: 0; batch classifier loss: 0.441797; batch adversarial loss: 0.570741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450753; batch adversarial loss: 0.501095\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434135; batch adversarial loss: 0.502622\n",
      "epoch 51; iter: 0; batch classifier loss: 0.537137; batch adversarial loss: 0.570135\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483139; batch adversarial loss: 0.588700\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422138; batch adversarial loss: 0.518501\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411624; batch adversarial loss: 0.580591\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479747; batch adversarial loss: 0.562701\n",
      "epoch 56; iter: 0; batch classifier loss: 0.337186; batch adversarial loss: 0.579257\n",
      "epoch 57; iter: 0; batch classifier loss: 0.331533; batch adversarial loss: 0.571644\n",
      "epoch 58; iter: 0; batch classifier loss: 0.397633; batch adversarial loss: 0.519032\n",
      "epoch 59; iter: 0; batch classifier loss: 0.451378; batch adversarial loss: 0.623376\n",
      "epoch 60; iter: 0; batch classifier loss: 0.438761; batch adversarial loss: 0.553595\n",
      "epoch 61; iter: 0; batch classifier loss: 0.378258; batch adversarial loss: 0.562395\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400851; batch adversarial loss: 0.518550\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412030; batch adversarial loss: 0.535901\n",
      "epoch 64; iter: 0; batch classifier loss: 0.357443; batch adversarial loss: 0.571082\n",
      "epoch 65; iter: 0; batch classifier loss: 0.361333; batch adversarial loss: 0.589064\n",
      "epoch 66; iter: 0; batch classifier loss: 0.468874; batch adversarial loss: 0.491346\n",
      "epoch 67; iter: 0; batch classifier loss: 0.456845; batch adversarial loss: 0.526631\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397772; batch adversarial loss: 0.534807\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398692; batch adversarial loss: 0.526873\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397273; batch adversarial loss: 0.579449\n",
      "epoch 71; iter: 0; batch classifier loss: 0.356861; batch adversarial loss: 0.623175\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385934; batch adversarial loss: 0.572882\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396012; batch adversarial loss: 0.587443\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402762; batch adversarial loss: 0.623522\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376097; batch adversarial loss: 0.615768\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386445; batch adversarial loss: 0.561162\n",
      "epoch 77; iter: 0; batch classifier loss: 0.430550; batch adversarial loss: 0.546059\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373903; batch adversarial loss: 0.623864\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387922; batch adversarial loss: 0.606249\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356799; batch adversarial loss: 0.561913\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356473; batch adversarial loss: 0.508604\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419345; batch adversarial loss: 0.590401\n",
      "epoch 83; iter: 0; batch classifier loss: 0.334559; batch adversarial loss: 0.606284\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376701; batch adversarial loss: 0.553174\n",
      "epoch 85; iter: 0; batch classifier loss: 0.339883; batch adversarial loss: 0.546254\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355420; batch adversarial loss: 0.500550\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400909; batch adversarial loss: 0.588596\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368383; batch adversarial loss: 0.498296\n",
      "epoch 89; iter: 0; batch classifier loss: 0.343790; batch adversarial loss: 0.544484\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354649; batch adversarial loss: 0.545557\n",
      "epoch 91; iter: 0; batch classifier loss: 0.309281; batch adversarial loss: 0.545846\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366840; batch adversarial loss: 0.545300\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356724; batch adversarial loss: 0.455438\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385184; batch adversarial loss: 0.588813\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429953; batch adversarial loss: 0.605922\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425659; batch adversarial loss: 0.449758\n",
      "epoch 97; iter: 0; batch classifier loss: 0.426249; batch adversarial loss: 0.527906\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392092; batch adversarial loss: 0.526290\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365001; batch adversarial loss: 0.521942\n",
      "epoch 100; iter: 0; batch classifier loss: 0.359664; batch adversarial loss: 0.543949\n",
      "epoch 101; iter: 0; batch classifier loss: 0.323413; batch adversarial loss: 0.519007\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351012; batch adversarial loss: 0.571693\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370502; batch adversarial loss: 0.518872\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390996; batch adversarial loss: 0.538616\n",
      "epoch 105; iter: 0; batch classifier loss: 0.357965; batch adversarial loss: 0.605144\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335004; batch adversarial loss: 0.570374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.393928; batch adversarial loss: 0.510449\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357958; batch adversarial loss: 0.563178\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356622; batch adversarial loss: 0.579768\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390590; batch adversarial loss: 0.544284\n",
      "epoch 111; iter: 0; batch classifier loss: 0.429097; batch adversarial loss: 0.579833\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357894; batch adversarial loss: 0.570348\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396491; batch adversarial loss: 0.447013\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362228; batch adversarial loss: 0.528333\n",
      "epoch 115; iter: 0; batch classifier loss: 0.335463; batch adversarial loss: 0.526524\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347088; batch adversarial loss: 0.473896\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346602; batch adversarial loss: 0.554665\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330154; batch adversarial loss: 0.545463\n",
      "epoch 119; iter: 0; batch classifier loss: 0.241963; batch adversarial loss: 0.553217\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330820; batch adversarial loss: 0.545713\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361529; batch adversarial loss: 0.510199\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372292; batch adversarial loss: 0.553382\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400653; batch adversarial loss: 0.634722\n",
      "epoch 124; iter: 0; batch classifier loss: 0.427630; batch adversarial loss: 0.599260\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382671; batch adversarial loss: 0.472992\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340740; batch adversarial loss: 0.543942\n",
      "epoch 127; iter: 0; batch classifier loss: 0.310732; batch adversarial loss: 0.615292\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348310; batch adversarial loss: 0.536183\n",
      "epoch 129; iter: 0; batch classifier loss: 0.287160; batch adversarial loss: 0.579513\n",
      "epoch 130; iter: 0; batch classifier loss: 0.295074; batch adversarial loss: 0.526182\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380240; batch adversarial loss: 0.616005\n",
      "epoch 132; iter: 0; batch classifier loss: 0.304199; batch adversarial loss: 0.570972\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379528; batch adversarial loss: 0.570637\n",
      "epoch 134; iter: 0; batch classifier loss: 0.301295; batch adversarial loss: 0.482320\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339937; batch adversarial loss: 0.561220\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372393; batch adversarial loss: 0.535069\n",
      "epoch 137; iter: 0; batch classifier loss: 0.293281; batch adversarial loss: 0.492333\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341981; batch adversarial loss: 0.608727\n",
      "epoch 139; iter: 0; batch classifier loss: 0.322455; batch adversarial loss: 0.509550\n",
      "epoch 140; iter: 0; batch classifier loss: 0.471309; batch adversarial loss: 0.526631\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411609; batch adversarial loss: 0.597100\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350456; batch adversarial loss: 0.554211\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350135; batch adversarial loss: 0.580050\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323668; batch adversarial loss: 0.536756\n",
      "epoch 145; iter: 0; batch classifier loss: 0.311834; batch adversarial loss: 0.560246\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401606; batch adversarial loss: 0.473949\n",
      "epoch 147; iter: 0; batch classifier loss: 0.356203; batch adversarial loss: 0.518098\n",
      "epoch 148; iter: 0; batch classifier loss: 0.309559; batch adversarial loss: 0.616897\n",
      "epoch 149; iter: 0; batch classifier loss: 0.325885; batch adversarial loss: 0.562948\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389503; batch adversarial loss: 0.526017\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364259; batch adversarial loss: 0.543957\n",
      "epoch 152; iter: 0; batch classifier loss: 0.392176; batch adversarial loss: 0.660092\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346592; batch adversarial loss: 0.555020\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376082; batch adversarial loss: 0.491950\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371207; batch adversarial loss: 0.571045\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321900; batch adversarial loss: 0.579909\n",
      "epoch 157; iter: 0; batch classifier loss: 0.332987; batch adversarial loss: 0.614183\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319171; batch adversarial loss: 0.553955\n",
      "epoch 159; iter: 0; batch classifier loss: 0.365508; batch adversarial loss: 0.570231\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370994; batch adversarial loss: 0.535318\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363964; batch adversarial loss: 0.545196\n",
      "epoch 162; iter: 0; batch classifier loss: 0.308269; batch adversarial loss: 0.570638\n",
      "epoch 163; iter: 0; batch classifier loss: 0.310511; batch adversarial loss: 0.553104\n",
      "epoch 164; iter: 0; batch classifier loss: 0.325783; batch adversarial loss: 0.491747\n",
      "epoch 165; iter: 0; batch classifier loss: 0.384776; batch adversarial loss: 0.640744\n",
      "epoch 166; iter: 0; batch classifier loss: 0.266061; batch adversarial loss: 0.607020\n",
      "epoch 167; iter: 0; batch classifier loss: 0.457378; batch adversarial loss: 0.527121\n",
      "epoch 168; iter: 0; batch classifier loss: 0.278932; batch adversarial loss: 0.579913\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367725; batch adversarial loss: 0.545230\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383621; batch adversarial loss: 0.553245\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383584; batch adversarial loss: 0.561988\n",
      "epoch 172; iter: 0; batch classifier loss: 0.335016; batch adversarial loss: 0.589349\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351171; batch adversarial loss: 0.473508\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378736; batch adversarial loss: 0.482934\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308225; batch adversarial loss: 0.517890\n",
      "epoch 176; iter: 0; batch classifier loss: 0.295336; batch adversarial loss: 0.526383\n",
      "epoch 177; iter: 0; batch classifier loss: 0.310193; batch adversarial loss: 0.551896\n",
      "epoch 178; iter: 0; batch classifier loss: 0.319394; batch adversarial loss: 0.544487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317078; batch adversarial loss: 0.597792\n",
      "epoch 180; iter: 0; batch classifier loss: 0.433308; batch adversarial loss: 0.473081\n",
      "epoch 181; iter: 0; batch classifier loss: 0.304865; batch adversarial loss: 0.544137\n",
      "epoch 182; iter: 0; batch classifier loss: 0.301785; batch adversarial loss: 0.614036\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388595; batch adversarial loss: 0.579143\n",
      "epoch 184; iter: 0; batch classifier loss: 0.451039; batch adversarial loss: 0.561991\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332455; batch adversarial loss: 0.578513\n",
      "epoch 186; iter: 0; batch classifier loss: 0.271035; batch adversarial loss: 0.544178\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325083; batch adversarial loss: 0.553577\n",
      "epoch 188; iter: 0; batch classifier loss: 0.242993; batch adversarial loss: 0.579970\n",
      "epoch 189; iter: 0; batch classifier loss: 0.374244; batch adversarial loss: 0.553572\n",
      "epoch 190; iter: 0; batch classifier loss: 0.291207; batch adversarial loss: 0.580110\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321720; batch adversarial loss: 0.546023\n",
      "epoch 192; iter: 0; batch classifier loss: 0.261985; batch adversarial loss: 0.464619\n",
      "epoch 193; iter: 0; batch classifier loss: 0.386300; batch adversarial loss: 0.508238\n",
      "epoch 194; iter: 0; batch classifier loss: 0.260549; batch adversarial loss: 0.508364\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302322; batch adversarial loss: 0.562448\n",
      "epoch 196; iter: 0; batch classifier loss: 0.274649; batch adversarial loss: 0.543584\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377377; batch adversarial loss: 0.535446\n",
      "epoch 198; iter: 0; batch classifier loss: 0.447280; batch adversarial loss: 0.597868\n",
      "epoch 199; iter: 0; batch classifier loss: 0.382346; batch adversarial loss: 0.641546\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701903; batch adversarial loss: 0.639680\n",
      "epoch 1; iter: 0; batch classifier loss: 0.536583; batch adversarial loss: 0.631960\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582739; batch adversarial loss: 0.646023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.625453; batch adversarial loss: 0.646266\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566951; batch adversarial loss: 0.633412\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550861; batch adversarial loss: 0.609281\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555391; batch adversarial loss: 0.602095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.589127; batch adversarial loss: 0.568909\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550508; batch adversarial loss: 0.572273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600456; batch adversarial loss: 0.605027\n",
      "epoch 10; iter: 0; batch classifier loss: 0.604255; batch adversarial loss: 0.597153\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507560; batch adversarial loss: 0.561157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548649; batch adversarial loss: 0.586693\n",
      "epoch 13; iter: 0; batch classifier loss: 0.631047; batch adversarial loss: 0.576921\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542953; batch adversarial loss: 0.556966\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544634; batch adversarial loss: 0.568880\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548969; batch adversarial loss: 0.570469\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514610; batch adversarial loss: 0.551614\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531956; batch adversarial loss: 0.624179\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476179; batch adversarial loss: 0.565477\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524736; batch adversarial loss: 0.527239\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524411; batch adversarial loss: 0.514589\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528975; batch adversarial loss: 0.641222\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495297; batch adversarial loss: 0.542741\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508086; batch adversarial loss: 0.539920\n",
      "epoch 25; iter: 0; batch classifier loss: 0.450043; batch adversarial loss: 0.475534\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442476; batch adversarial loss: 0.539796\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492083; batch adversarial loss: 0.603901\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454050; batch adversarial loss: 0.597361\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435856; batch adversarial loss: 0.528264\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477143; batch adversarial loss: 0.545651\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457812; batch adversarial loss: 0.570786\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463092; batch adversarial loss: 0.580412\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457850; batch adversarial loss: 0.563410\n",
      "epoch 34; iter: 0; batch classifier loss: 0.507495; batch adversarial loss: 0.544949\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407047; batch adversarial loss: 0.519832\n",
      "epoch 36; iter: 0; batch classifier loss: 0.563877; batch adversarial loss: 0.598421\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440229; batch adversarial loss: 0.537093\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436416; batch adversarial loss: 0.528470\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483980; batch adversarial loss: 0.516195\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414405; batch adversarial loss: 0.480597\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395004; batch adversarial loss: 0.637199\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409351; batch adversarial loss: 0.562896\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393909; batch adversarial loss: 0.618053\n",
      "epoch 44; iter: 0; batch classifier loss: 0.533630; batch adversarial loss: 0.481524\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471702; batch adversarial loss: 0.544648\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417752; batch adversarial loss: 0.590385\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426491; batch adversarial loss: 0.516280\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474289; batch adversarial loss: 0.553569\n",
      "epoch 49; iter: 0; batch classifier loss: 0.485003; batch adversarial loss: 0.542945\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428331; batch adversarial loss: 0.536601\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445444; batch adversarial loss: 0.577777\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411009; batch adversarial loss: 0.536330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359814; batch adversarial loss: 0.517630\n",
      "epoch 54; iter: 0; batch classifier loss: 0.391243; batch adversarial loss: 0.629598\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413348; batch adversarial loss: 0.637466\n",
      "epoch 56; iter: 0; batch classifier loss: 0.484025; batch adversarial loss: 0.506356\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440693; batch adversarial loss: 0.508208\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435139; batch adversarial loss: 0.583327\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447763; batch adversarial loss: 0.553153\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382984; batch adversarial loss: 0.580309\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433424; batch adversarial loss: 0.462693\n",
      "epoch 62; iter: 0; batch classifier loss: 0.356013; batch adversarial loss: 0.517315\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379393; batch adversarial loss: 0.571980\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384453; batch adversarial loss: 0.525657\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397666; batch adversarial loss: 0.545085\n",
      "epoch 66; iter: 0; batch classifier loss: 0.455568; batch adversarial loss: 0.582058\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360884; batch adversarial loss: 0.545131\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415253; batch adversarial loss: 0.442747\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374598; batch adversarial loss: 0.536096\n",
      "epoch 70; iter: 0; batch classifier loss: 0.363745; batch adversarial loss: 0.518473\n",
      "epoch 71; iter: 0; batch classifier loss: 0.354962; batch adversarial loss: 0.465962\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427966; batch adversarial loss: 0.518678\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447782; batch adversarial loss: 0.541740\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424362; batch adversarial loss: 0.568478\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393764; batch adversarial loss: 0.529446\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418253; batch adversarial loss: 0.456173\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360153; batch adversarial loss: 0.609177\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406395; batch adversarial loss: 0.523470\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428935; batch adversarial loss: 0.531663\n",
      "epoch 80; iter: 0; batch classifier loss: 0.386093; batch adversarial loss: 0.560985\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391713; batch adversarial loss: 0.556793\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399177; batch adversarial loss: 0.545803\n",
      "epoch 83; iter: 0; batch classifier loss: 0.363320; batch adversarial loss: 0.565048\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429446; batch adversarial loss: 0.544372\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367559; batch adversarial loss: 0.576017\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381252; batch adversarial loss: 0.580997\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428311; batch adversarial loss: 0.466521\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401918; batch adversarial loss: 0.510478\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381485; batch adversarial loss: 0.597685\n",
      "epoch 90; iter: 0; batch classifier loss: 0.481250; batch adversarial loss: 0.535555\n",
      "epoch 91; iter: 0; batch classifier loss: 0.420195; batch adversarial loss: 0.509366\n",
      "epoch 92; iter: 0; batch classifier loss: 0.477075; batch adversarial loss: 0.552808\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391186; batch adversarial loss: 0.567891\n",
      "epoch 94; iter: 0; batch classifier loss: 0.540674; batch adversarial loss: 0.605561\n",
      "epoch 95; iter: 0; batch classifier loss: 0.369325; batch adversarial loss: 0.623159\n",
      "epoch 96; iter: 0; batch classifier loss: 0.424851; batch adversarial loss: 0.527339\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371324; batch adversarial loss: 0.571086\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359475; batch adversarial loss: 0.563455\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388830; batch adversarial loss: 0.525543\n",
      "epoch 100; iter: 0; batch classifier loss: 0.426293; batch adversarial loss: 0.528961\n",
      "epoch 101; iter: 0; batch classifier loss: 0.340226; batch adversarial loss: 0.487941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.391172; batch adversarial loss: 0.545640\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371754; batch adversarial loss: 0.498165\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373617; batch adversarial loss: 0.609669\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415169; batch adversarial loss: 0.609505\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366526; batch adversarial loss: 0.488683\n",
      "epoch 107; iter: 0; batch classifier loss: 0.359072; batch adversarial loss: 0.583637\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380197; batch adversarial loss: 0.598146\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366152; batch adversarial loss: 0.571047\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352486; batch adversarial loss: 0.552652\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416288; batch adversarial loss: 0.508003\n",
      "epoch 112; iter: 0; batch classifier loss: 0.426082; batch adversarial loss: 0.578199\n",
      "epoch 113; iter: 0; batch classifier loss: 0.454378; batch adversarial loss: 0.578096\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406788; batch adversarial loss: 0.527458\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419567; batch adversarial loss: 0.526304\n",
      "epoch 116; iter: 0; batch classifier loss: 0.312783; batch adversarial loss: 0.536702\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367906; batch adversarial loss: 0.572265\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367394; batch adversarial loss: 0.618844\n",
      "epoch 119; iter: 0; batch classifier loss: 0.345814; batch adversarial loss: 0.527498\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379777; batch adversarial loss: 0.564702\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383978; batch adversarial loss: 0.498627\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385556; batch adversarial loss: 0.600713\n",
      "epoch 123; iter: 0; batch classifier loss: 0.430913; batch adversarial loss: 0.581900\n",
      "epoch 124; iter: 0; batch classifier loss: 0.437677; batch adversarial loss: 0.534829\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395056; batch adversarial loss: 0.591365\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347613; batch adversarial loss: 0.552316\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391333; batch adversarial loss: 0.499315\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415027; batch adversarial loss: 0.580205\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334504; batch adversarial loss: 0.571199\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345074; batch adversarial loss: 0.571120\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382994; batch adversarial loss: 0.580113\n",
      "epoch 132; iter: 0; batch classifier loss: 0.391247; batch adversarial loss: 0.599943\n",
      "epoch 133; iter: 0; batch classifier loss: 0.400697; batch adversarial loss: 0.544706\n",
      "epoch 134; iter: 0; batch classifier loss: 0.441658; batch adversarial loss: 0.626982\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365763; batch adversarial loss: 0.526754\n",
      "epoch 136; iter: 0; batch classifier loss: 0.473272; batch adversarial loss: 0.526498\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345418; batch adversarial loss: 0.545043\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381822; batch adversarial loss: 0.536960\n",
      "epoch 139; iter: 0; batch classifier loss: 0.468803; batch adversarial loss: 0.562749\n",
      "epoch 140; iter: 0; batch classifier loss: 0.449428; batch adversarial loss: 0.552964\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336456; batch adversarial loss: 0.498921\n",
      "epoch 142; iter: 0; batch classifier loss: 0.429811; batch adversarial loss: 0.535403\n",
      "epoch 143; iter: 0; batch classifier loss: 0.442398; batch adversarial loss: 0.480732\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368063; batch adversarial loss: 0.590344\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418246; batch adversarial loss: 0.500384\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348874; batch adversarial loss: 0.569752\n",
      "epoch 147; iter: 0; batch classifier loss: 0.398855; batch adversarial loss: 0.571750\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381054; batch adversarial loss: 0.453188\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360685; batch adversarial loss: 0.498560\n",
      "epoch 150; iter: 0; batch classifier loss: 0.417651; batch adversarial loss: 0.571362\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379272; batch adversarial loss: 0.544555\n",
      "epoch 152; iter: 0; batch classifier loss: 0.393544; batch adversarial loss: 0.580973\n",
      "epoch 153; iter: 0; batch classifier loss: 0.436477; batch adversarial loss: 0.470557\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348763; batch adversarial loss: 0.498804\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367318; batch adversarial loss: 0.553609\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380823; batch adversarial loss: 0.526612\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372776; batch adversarial loss: 0.517082\n",
      "epoch 158; iter: 0; batch classifier loss: 0.296686; batch adversarial loss: 0.581375\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361928; batch adversarial loss: 0.572261\n",
      "epoch 160; iter: 0; batch classifier loss: 0.447540; batch adversarial loss: 0.553831\n",
      "epoch 161; iter: 0; batch classifier loss: 0.379290; batch adversarial loss: 0.516982\n",
      "epoch 162; iter: 0; batch classifier loss: 0.431947; batch adversarial loss: 0.480547\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327654; batch adversarial loss: 0.663781\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394637; batch adversarial loss: 0.562399\n",
      "epoch 165; iter: 0; batch classifier loss: 0.391607; batch adversarial loss: 0.571862\n",
      "epoch 166; iter: 0; batch classifier loss: 0.413528; batch adversarial loss: 0.581134\n",
      "epoch 167; iter: 0; batch classifier loss: 0.426440; batch adversarial loss: 0.562515\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308019; batch adversarial loss: 0.498222\n",
      "epoch 169; iter: 0; batch classifier loss: 0.441799; batch adversarial loss: 0.590604\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382291; batch adversarial loss: 0.534957\n",
      "epoch 171; iter: 0; batch classifier loss: 0.405341; batch adversarial loss: 0.443838\n",
      "epoch 172; iter: 0; batch classifier loss: 0.405892; batch adversarial loss: 0.507816\n",
      "epoch 173; iter: 0; batch classifier loss: 0.368304; batch adversarial loss: 0.553821\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349766; batch adversarial loss: 0.526111\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344440; batch adversarial loss: 0.479924\n",
      "epoch 176; iter: 0; batch classifier loss: 0.428497; batch adversarial loss: 0.526073\n",
      "epoch 177; iter: 0; batch classifier loss: 0.405414; batch adversarial loss: 0.572055\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387698; batch adversarial loss: 0.489159\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318062; batch adversarial loss: 0.553519\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368657; batch adversarial loss: 0.599565\n",
      "epoch 181; iter: 0; batch classifier loss: 0.471899; batch adversarial loss: 0.553610\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329846; batch adversarial loss: 0.544379\n",
      "epoch 183; iter: 0; batch classifier loss: 0.405154; batch adversarial loss: 0.553713\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413767; batch adversarial loss: 0.562930\n",
      "epoch 185; iter: 0; batch classifier loss: 0.432739; batch adversarial loss: 0.543393\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340084; batch adversarial loss: 0.525777\n",
      "epoch 187; iter: 0; batch classifier loss: 0.316492; batch adversarial loss: 0.562843\n",
      "epoch 188; iter: 0; batch classifier loss: 0.394198; batch adversarial loss: 0.599959\n",
      "epoch 189; iter: 0; batch classifier loss: 0.424241; batch adversarial loss: 0.517235\n",
      "epoch 190; iter: 0; batch classifier loss: 0.406524; batch adversarial loss: 0.525561\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356725; batch adversarial loss: 0.526196\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349446; batch adversarial loss: 0.579532\n",
      "epoch 193; iter: 0; batch classifier loss: 0.290199; batch adversarial loss: 0.517168\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341933; batch adversarial loss: 0.627663\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379860; batch adversarial loss: 0.544863\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346603; batch adversarial loss: 0.544745\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352688; batch adversarial loss: 0.508271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.358274; batch adversarial loss: 0.506775\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386230; batch adversarial loss: 0.544755\n",
      "epoch 0; iter: 0; batch classifier loss: 0.777751; batch adversarial loss: 0.530417\n",
      "epoch 1; iter: 0; batch classifier loss: 0.671179; batch adversarial loss: 0.695728\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595167; batch adversarial loss: 0.630107\n",
      "epoch 3; iter: 0; batch classifier loss: 0.645371; batch adversarial loss: 0.739728\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577210; batch adversarial loss: 0.741489\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518541; batch adversarial loss: 0.695179\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538238; batch adversarial loss: 0.676095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615867; batch adversarial loss: 0.623127\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598750; batch adversarial loss: 0.697023\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567781; batch adversarial loss: 0.577482\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525636; batch adversarial loss: 0.574362\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591044; batch adversarial loss: 0.583265\n",
      "epoch 12; iter: 0; batch classifier loss: 0.561039; batch adversarial loss: 0.544834\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430373; batch adversarial loss: 0.631198\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529268; batch adversarial loss: 0.553564\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516708; batch adversarial loss: 0.568986\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491936; batch adversarial loss: 0.516345\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473852; batch adversarial loss: 0.592019\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446233; batch adversarial loss: 0.628676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526281; batch adversarial loss: 0.527757\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522423; batch adversarial loss: 0.578662\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522295; batch adversarial loss: 0.564939\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533369; batch adversarial loss: 0.529609\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468473; batch adversarial loss: 0.536556\n",
      "epoch 24; iter: 0; batch classifier loss: 0.558576; batch adversarial loss: 0.556194\n",
      "epoch 25; iter: 0; batch classifier loss: 0.405697; batch adversarial loss: 0.493832\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476422; batch adversarial loss: 0.562397\n",
      "epoch 27; iter: 0; batch classifier loss: 0.568947; batch adversarial loss: 0.606535\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454606; batch adversarial loss: 0.581711\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471008; batch adversarial loss: 0.596332\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433535; batch adversarial loss: 0.507256\n",
      "epoch 31; iter: 0; batch classifier loss: 0.569809; batch adversarial loss: 0.555290\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465496; batch adversarial loss: 0.581112\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471020; batch adversarial loss: 0.544395\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408186; batch adversarial loss: 0.471970\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485129; batch adversarial loss: 0.563005\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444002; batch adversarial loss: 0.526195\n",
      "epoch 37; iter: 0; batch classifier loss: 0.492406; batch adversarial loss: 0.561533\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447447; batch adversarial loss: 0.533766\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448445; batch adversarial loss: 0.526273\n",
      "epoch 40; iter: 0; batch classifier loss: 0.580996; batch adversarial loss: 0.624217\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446350; batch adversarial loss: 0.551267\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374376; batch adversarial loss: 0.534138\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495217; batch adversarial loss: 0.601895\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461468; batch adversarial loss: 0.440263\n",
      "epoch 45; iter: 0; batch classifier loss: 0.475110; batch adversarial loss: 0.438766\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440563; batch adversarial loss: 0.533337\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386116; batch adversarial loss: 0.523206\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399449; batch adversarial loss: 0.487205\n",
      "epoch 49; iter: 0; batch classifier loss: 0.358569; batch adversarial loss: 0.534533\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457280; batch adversarial loss: 0.472505\n",
      "epoch 51; iter: 0; batch classifier loss: 0.361667; batch adversarial loss: 0.508764\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435303; batch adversarial loss: 0.551515\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429451; batch adversarial loss: 0.533452\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457298; batch adversarial loss: 0.629363\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479223; batch adversarial loss: 0.561796\n",
      "epoch 56; iter: 0; batch classifier loss: 0.481545; batch adversarial loss: 0.555284\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437889; batch adversarial loss: 0.516985\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438887; batch adversarial loss: 0.524863\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387623; batch adversarial loss: 0.499819\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423875; batch adversarial loss: 0.524610\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470072; batch adversarial loss: 0.569566\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410318; batch adversarial loss: 0.504005\n",
      "epoch 63; iter: 0; batch classifier loss: 0.440925; batch adversarial loss: 0.562542\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441064; batch adversarial loss: 0.602878\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380216; batch adversarial loss: 0.486947\n",
      "epoch 66; iter: 0; batch classifier loss: 0.455104; batch adversarial loss: 0.538618\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426237; batch adversarial loss: 0.526854\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402547; batch adversarial loss: 0.582451\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358046; batch adversarial loss: 0.560612\n",
      "epoch 70; iter: 0; batch classifier loss: 0.508645; batch adversarial loss: 0.488035\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410812; batch adversarial loss: 0.534254\n",
      "epoch 72; iter: 0; batch classifier loss: 0.339193; batch adversarial loss: 0.518544\n",
      "epoch 73; iter: 0; batch classifier loss: 0.399977; batch adversarial loss: 0.538273\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439487; batch adversarial loss: 0.637801\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387629; batch adversarial loss: 0.551623\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443047; batch adversarial loss: 0.494669\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401234; batch adversarial loss: 0.588722\n",
      "epoch 78; iter: 0; batch classifier loss: 0.364677; batch adversarial loss: 0.563040\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388574; batch adversarial loss: 0.554520\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422911; batch adversarial loss: 0.454329\n",
      "epoch 81; iter: 0; batch classifier loss: 0.458567; batch adversarial loss: 0.555682\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358338; batch adversarial loss: 0.510944\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375516; batch adversarial loss: 0.465691\n",
      "epoch 84; iter: 0; batch classifier loss: 0.299371; batch adversarial loss: 0.544074\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367512; batch adversarial loss: 0.478155\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433739; batch adversarial loss: 0.590107\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377735; batch adversarial loss: 0.586243\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365852; batch adversarial loss: 0.611497\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401245; batch adversarial loss: 0.487513\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359765; batch adversarial loss: 0.530545\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385647; batch adversarial loss: 0.597915\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420108; batch adversarial loss: 0.528197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320440; batch adversarial loss: 0.522210\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422296; batch adversarial loss: 0.521470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.320651; batch adversarial loss: 0.498482\n",
      "epoch 96; iter: 0; batch classifier loss: 0.448910; batch adversarial loss: 0.544822\n",
      "epoch 97; iter: 0; batch classifier loss: 0.492479; batch adversarial loss: 0.528017\n",
      "epoch 98; iter: 0; batch classifier loss: 0.325572; batch adversarial loss: 0.521420\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396543; batch adversarial loss: 0.524670\n",
      "epoch 100; iter: 0; batch classifier loss: 0.490630; batch adversarial loss: 0.560909\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395309; batch adversarial loss: 0.518289\n",
      "epoch 102; iter: 0; batch classifier loss: 0.454125; batch adversarial loss: 0.580960\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427231; batch adversarial loss: 0.520101\n",
      "epoch 104; iter: 0; batch classifier loss: 0.432577; batch adversarial loss: 0.555373\n",
      "epoch 105; iter: 0; batch classifier loss: 0.306578; batch adversarial loss: 0.545525\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409573; batch adversarial loss: 0.476351\n",
      "epoch 107; iter: 0; batch classifier loss: 0.340511; batch adversarial loss: 0.506223\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399946; batch adversarial loss: 0.582129\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367578; batch adversarial loss: 0.584970\n",
      "epoch 110; iter: 0; batch classifier loss: 0.462734; batch adversarial loss: 0.533249\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409190; batch adversarial loss: 0.572789\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405426; batch adversarial loss: 0.573946\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380889; batch adversarial loss: 0.518228\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390162; batch adversarial loss: 0.496914\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373825; batch adversarial loss: 0.547347\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393735; batch adversarial loss: 0.587450\n",
      "epoch 117; iter: 0; batch classifier loss: 0.475648; batch adversarial loss: 0.481619\n",
      "epoch 118; iter: 0; batch classifier loss: 0.289914; batch adversarial loss: 0.576845\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417693; batch adversarial loss: 0.542492\n",
      "epoch 120; iter: 0; batch classifier loss: 0.450411; batch adversarial loss: 0.542491\n",
      "epoch 121; iter: 0; batch classifier loss: 0.469032; batch adversarial loss: 0.539454\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366272; batch adversarial loss: 0.524568\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360171; batch adversarial loss: 0.488516\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347355; batch adversarial loss: 0.543406\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413259; batch adversarial loss: 0.526771\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330371; batch adversarial loss: 0.611399\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438434; batch adversarial loss: 0.608117\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411954; batch adversarial loss: 0.483481\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356206; batch adversarial loss: 0.570359\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359550; batch adversarial loss: 0.586663\n",
      "epoch 131; iter: 0; batch classifier loss: 0.486649; batch adversarial loss: 0.487314\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403721; batch adversarial loss: 0.554525\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390049; batch adversarial loss: 0.505098\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329036; batch adversarial loss: 0.468089\n",
      "epoch 135; iter: 0; batch classifier loss: 0.384016; batch adversarial loss: 0.519263\n",
      "epoch 136; iter: 0; batch classifier loss: 0.430870; batch adversarial loss: 0.574012\n",
      "epoch 137; iter: 0; batch classifier loss: 0.338408; batch adversarial loss: 0.540838\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373663; batch adversarial loss: 0.531853\n",
      "epoch 139; iter: 0; batch classifier loss: 0.306475; batch adversarial loss: 0.476478\n",
      "epoch 140; iter: 0; batch classifier loss: 0.321801; batch adversarial loss: 0.487440\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368991; batch adversarial loss: 0.534418\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372023; batch adversarial loss: 0.541473\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353337; batch adversarial loss: 0.524204\n",
      "epoch 144; iter: 0; batch classifier loss: 0.418241; batch adversarial loss: 0.475981\n",
      "epoch 145; iter: 0; batch classifier loss: 0.422357; batch adversarial loss: 0.495346\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341638; batch adversarial loss: 0.562645\n",
      "epoch 147; iter: 0; batch classifier loss: 0.466373; batch adversarial loss: 0.577695\n",
      "epoch 148; iter: 0; batch classifier loss: 0.402185; batch adversarial loss: 0.465989\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320772; batch adversarial loss: 0.516608\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353155; batch adversarial loss: 0.428284\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358802; batch adversarial loss: 0.563611\n",
      "epoch 152; iter: 0; batch classifier loss: 0.367496; batch adversarial loss: 0.567506\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344639; batch adversarial loss: 0.497136\n",
      "epoch 154; iter: 0; batch classifier loss: 0.368630; batch adversarial loss: 0.475820\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362223; batch adversarial loss: 0.532818\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418439; batch adversarial loss: 0.528025\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346877; batch adversarial loss: 0.586275\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344304; batch adversarial loss: 0.566366\n",
      "epoch 159; iter: 0; batch classifier loss: 0.451547; batch adversarial loss: 0.597411\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413865; batch adversarial loss: 0.620977\n",
      "epoch 161; iter: 0; batch classifier loss: 0.451288; batch adversarial loss: 0.561474\n",
      "epoch 162; iter: 0; batch classifier loss: 0.391670; batch adversarial loss: 0.542058\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385778; batch adversarial loss: 0.573943\n",
      "epoch 164; iter: 0; batch classifier loss: 0.418127; batch adversarial loss: 0.447490\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399271; batch adversarial loss: 0.532791\n",
      "epoch 166; iter: 0; batch classifier loss: 0.415544; batch adversarial loss: 0.478744\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384379; batch adversarial loss: 0.547746\n",
      "epoch 168; iter: 0; batch classifier loss: 0.469437; batch adversarial loss: 0.566872\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337241; batch adversarial loss: 0.578108\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393781; batch adversarial loss: 0.438214\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378480; batch adversarial loss: 0.514634\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363278; batch adversarial loss: 0.427571\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362150; batch adversarial loss: 0.511098\n",
      "epoch 174; iter: 0; batch classifier loss: 0.293559; batch adversarial loss: 0.481001\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359897; batch adversarial loss: 0.567916\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354398; batch adversarial loss: 0.545946\n",
      "epoch 177; iter: 0; batch classifier loss: 0.323101; batch adversarial loss: 0.506641\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350364; batch adversarial loss: 0.595943\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384218; batch adversarial loss: 0.557192\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352914; batch adversarial loss: 0.525552\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334541; batch adversarial loss: 0.564682\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374446; batch adversarial loss: 0.587735\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379603; batch adversarial loss: 0.609008\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360207; batch adversarial loss: 0.530518\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338944; batch adversarial loss: 0.531628\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365694; batch adversarial loss: 0.509040\n",
      "epoch 187; iter: 0; batch classifier loss: 0.276840; batch adversarial loss: 0.497147\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358065; batch adversarial loss: 0.533332\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376143; batch adversarial loss: 0.575614\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338118; batch adversarial loss: 0.587198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.309883; batch adversarial loss: 0.509447\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367637; batch adversarial loss: 0.516445\n",
      "epoch 193; iter: 0; batch classifier loss: 0.292604; batch adversarial loss: 0.542029\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359856; batch adversarial loss: 0.581733\n",
      "epoch 195; iter: 0; batch classifier loss: 0.419253; batch adversarial loss: 0.538338\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309668; batch adversarial loss: 0.557616\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320560; batch adversarial loss: 0.531737\n",
      "epoch 198; iter: 0; batch classifier loss: 0.464665; batch adversarial loss: 0.601184\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374455; batch adversarial loss: 0.544686\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702330; batch adversarial loss: 0.727875\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628754; batch adversarial loss: 0.692769\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609008; batch adversarial loss: 0.646364\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593771; batch adversarial loss: 0.643603\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590351; batch adversarial loss: 0.578319\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551409; batch adversarial loss: 0.588444\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539032; batch adversarial loss: 0.610895\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571331; batch adversarial loss: 0.553381\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523567; batch adversarial loss: 0.556210\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513477; batch adversarial loss: 0.602422\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504894; batch adversarial loss: 0.516994\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532612; batch adversarial loss: 0.601571\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555080; batch adversarial loss: 0.583670\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523717; batch adversarial loss: 0.563219\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579051; batch adversarial loss: 0.532105\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493237; batch adversarial loss: 0.551033\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515829; batch adversarial loss: 0.606443\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519117; batch adversarial loss: 0.565787\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531879; batch adversarial loss: 0.521251\n",
      "epoch 19; iter: 0; batch classifier loss: 0.573684; batch adversarial loss: 0.544419\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553381; batch adversarial loss: 0.615211\n",
      "epoch 21; iter: 0; batch classifier loss: 0.433492; batch adversarial loss: 0.550488\n",
      "epoch 22; iter: 0; batch classifier loss: 0.420008; batch adversarial loss: 0.558518\n",
      "epoch 23; iter: 0; batch classifier loss: 0.551388; batch adversarial loss: 0.626106\n",
      "epoch 24; iter: 0; batch classifier loss: 0.542639; batch adversarial loss: 0.517863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.529965; batch adversarial loss: 0.541037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496486; batch adversarial loss: 0.544167\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478654; batch adversarial loss: 0.466031\n",
      "epoch 28; iter: 0; batch classifier loss: 0.467721; batch adversarial loss: 0.487267\n",
      "epoch 29; iter: 0; batch classifier loss: 0.400696; batch adversarial loss: 0.546621\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453900; batch adversarial loss: 0.496347\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441564; batch adversarial loss: 0.619263\n",
      "epoch 32; iter: 0; batch classifier loss: 0.511610; batch adversarial loss: 0.478929\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496958; batch adversarial loss: 0.574360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456096; batch adversarial loss: 0.603795\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456503; batch adversarial loss: 0.572076\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439007; batch adversarial loss: 0.625712\n",
      "epoch 37; iter: 0; batch classifier loss: 0.527915; batch adversarial loss: 0.606526\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498110; batch adversarial loss: 0.535983\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438345; batch adversarial loss: 0.538591\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465462; batch adversarial loss: 0.532882\n",
      "epoch 41; iter: 0; batch classifier loss: 0.551862; batch adversarial loss: 0.526374\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475238; batch adversarial loss: 0.544709\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426694; batch adversarial loss: 0.526151\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395002; batch adversarial loss: 0.515339\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427708; batch adversarial loss: 0.574295\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425334; batch adversarial loss: 0.545267\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462775; batch adversarial loss: 0.610503\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456444; batch adversarial loss: 0.546381\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415149; batch adversarial loss: 0.461174\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421646; batch adversarial loss: 0.516475\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482377; batch adversarial loss: 0.589826\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442540; batch adversarial loss: 0.619603\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454744; batch adversarial loss: 0.461694\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429800; batch adversarial loss: 0.599916\n",
      "epoch 55; iter: 0; batch classifier loss: 0.335908; batch adversarial loss: 0.497965\n",
      "epoch 56; iter: 0; batch classifier loss: 0.465499; batch adversarial loss: 0.544321\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405347; batch adversarial loss: 0.565731\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446619; batch adversarial loss: 0.498542\n",
      "epoch 59; iter: 0; batch classifier loss: 0.481725; batch adversarial loss: 0.508775\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.471782\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449205; batch adversarial loss: 0.518988\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442322; batch adversarial loss: 0.611993\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395073; batch adversarial loss: 0.535514\n",
      "epoch 64; iter: 0; batch classifier loss: 0.392469; batch adversarial loss: 0.626117\n",
      "epoch 65; iter: 0; batch classifier loss: 0.544106; batch adversarial loss: 0.507533\n",
      "epoch 66; iter: 0; batch classifier loss: 0.473592; batch adversarial loss: 0.617736\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429223; batch adversarial loss: 0.594134\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381786; batch adversarial loss: 0.489936\n",
      "epoch 69; iter: 0; batch classifier loss: 0.379911; batch adversarial loss: 0.543764\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419713; batch adversarial loss: 0.500622\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405599; batch adversarial loss: 0.598368\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411722; batch adversarial loss: 0.486441\n",
      "epoch 73; iter: 0; batch classifier loss: 0.443489; batch adversarial loss: 0.525639\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443384; batch adversarial loss: 0.470938\n",
      "epoch 75; iter: 0; batch classifier loss: 0.410822; batch adversarial loss: 0.525097\n",
      "epoch 76; iter: 0; batch classifier loss: 0.480691; batch adversarial loss: 0.601218\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407967; batch adversarial loss: 0.501131\n",
      "epoch 78; iter: 0; batch classifier loss: 0.483436; batch adversarial loss: 0.526298\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401132; batch adversarial loss: 0.553763\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410718; batch adversarial loss: 0.539331\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369414; batch adversarial loss: 0.531726\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415517; batch adversarial loss: 0.508374\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348481; batch adversarial loss: 0.477651\n",
      "epoch 84; iter: 0; batch classifier loss: 0.476087; batch adversarial loss: 0.555501\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398228; batch adversarial loss: 0.554343\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430909; batch adversarial loss: 0.506925\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392613; batch adversarial loss: 0.565642\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460095; batch adversarial loss: 0.485379\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399582; batch adversarial loss: 0.531525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.390912; batch adversarial loss: 0.546377\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380414; batch adversarial loss: 0.624716\n",
      "epoch 92; iter: 0; batch classifier loss: 0.431049; batch adversarial loss: 0.572403\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413827; batch adversarial loss: 0.568363\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351774; batch adversarial loss: 0.546848\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384510; batch adversarial loss: 0.610864\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398231; batch adversarial loss: 0.527492\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381836; batch adversarial loss: 0.613145\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409936; batch adversarial loss: 0.553324\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426696; batch adversarial loss: 0.522482\n",
      "epoch 100; iter: 0; batch classifier loss: 0.422122; batch adversarial loss: 0.588985\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396861; batch adversarial loss: 0.573274\n",
      "epoch 102; iter: 0; batch classifier loss: 0.406672; batch adversarial loss: 0.558402\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339305; batch adversarial loss: 0.545908\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363489; batch adversarial loss: 0.575557\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417544; batch adversarial loss: 0.585876\n",
      "epoch 106; iter: 0; batch classifier loss: 0.451228; batch adversarial loss: 0.575672\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374214; batch adversarial loss: 0.534151\n",
      "epoch 108; iter: 0; batch classifier loss: 0.301424; batch adversarial loss: 0.510904\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370112; batch adversarial loss: 0.601747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.301967; batch adversarial loss: 0.499867\n",
      "epoch 111; iter: 0; batch classifier loss: 0.414400; batch adversarial loss: 0.612290\n",
      "epoch 112; iter: 0; batch classifier loss: 0.299268; batch adversarial loss: 0.478565\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400304; batch adversarial loss: 0.532716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366924; batch adversarial loss: 0.516155\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336264; batch adversarial loss: 0.514683\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364489; batch adversarial loss: 0.518961\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393578; batch adversarial loss: 0.636462\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393963; batch adversarial loss: 0.618074\n",
      "epoch 119; iter: 0; batch classifier loss: 0.451137; batch adversarial loss: 0.589187\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350470; batch adversarial loss: 0.600838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387829; batch adversarial loss: 0.522862\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363119; batch adversarial loss: 0.519195\n",
      "epoch 123; iter: 0; batch classifier loss: 0.397002; batch adversarial loss: 0.519376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343703; batch adversarial loss: 0.501363\n",
      "epoch 125; iter: 0; batch classifier loss: 0.434161; batch adversarial loss: 0.486143\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401058; batch adversarial loss: 0.500929\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394333; batch adversarial loss: 0.581323\n",
      "epoch 128; iter: 0; batch classifier loss: 0.303641; batch adversarial loss: 0.536184\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403055; batch adversarial loss: 0.613843\n",
      "epoch 130; iter: 0; batch classifier loss: 0.439396; batch adversarial loss: 0.593643\n",
      "epoch 131; iter: 0; batch classifier loss: 0.282034; batch adversarial loss: 0.514257\n",
      "epoch 132; iter: 0; batch classifier loss: 0.426970; batch adversarial loss: 0.493723\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342061; batch adversarial loss: 0.480240\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387754; batch adversarial loss: 0.537281\n",
      "epoch 135; iter: 0; batch classifier loss: 0.462925; batch adversarial loss: 0.527623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.376871; batch adversarial loss: 0.581010\n",
      "epoch 137; iter: 0; batch classifier loss: 0.435773; batch adversarial loss: 0.555609\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369588; batch adversarial loss: 0.498653\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338050; batch adversarial loss: 0.528500\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338975; batch adversarial loss: 0.525642\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383715; batch adversarial loss: 0.497623\n",
      "epoch 142; iter: 0; batch classifier loss: 0.423419; batch adversarial loss: 0.601648\n",
      "epoch 143; iter: 0; batch classifier loss: 0.507645; batch adversarial loss: 0.514697\n",
      "epoch 144; iter: 0; batch classifier loss: 0.455853; batch adversarial loss: 0.552171\n",
      "epoch 145; iter: 0; batch classifier loss: 0.463375; batch adversarial loss: 0.574790\n",
      "epoch 146; iter: 0; batch classifier loss: 0.326113; batch adversarial loss: 0.569796\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374569; batch adversarial loss: 0.519868\n",
      "epoch 148; iter: 0; batch classifier loss: 0.308333; batch adversarial loss: 0.479094\n",
      "epoch 149; iter: 0; batch classifier loss: 0.427716; batch adversarial loss: 0.622765\n",
      "epoch 150; iter: 0; batch classifier loss: 0.447757; batch adversarial loss: 0.674411\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365186; batch adversarial loss: 0.486158\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369597; batch adversarial loss: 0.499376\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336013; batch adversarial loss: 0.517017\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369428; batch adversarial loss: 0.544678\n",
      "epoch 155; iter: 0; batch classifier loss: 0.424329; batch adversarial loss: 0.532887\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340979; batch adversarial loss: 0.505540\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399049; batch adversarial loss: 0.534848\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373736; batch adversarial loss: 0.616995\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339322; batch adversarial loss: 0.574755\n",
      "epoch 160; iter: 0; batch classifier loss: 0.442293; batch adversarial loss: 0.560931\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374887; batch adversarial loss: 0.619874\n",
      "epoch 162; iter: 0; batch classifier loss: 0.413788; batch adversarial loss: 0.571073\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382520; batch adversarial loss: 0.586029\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381378; batch adversarial loss: 0.518330\n",
      "epoch 165; iter: 0; batch classifier loss: 0.512022; batch adversarial loss: 0.541437\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328542; batch adversarial loss: 0.585995\n",
      "epoch 167; iter: 0; batch classifier loss: 0.368871; batch adversarial loss: 0.488802\n",
      "epoch 168; iter: 0; batch classifier loss: 0.429391; batch adversarial loss: 0.505396\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372676; batch adversarial loss: 0.554126\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359171; batch adversarial loss: 0.539927\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386578; batch adversarial loss: 0.521693\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367705; batch adversarial loss: 0.628521\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355985; batch adversarial loss: 0.517021\n",
      "epoch 174; iter: 0; batch classifier loss: 0.444908; batch adversarial loss: 0.555627\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366893; batch adversarial loss: 0.466462\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354115; batch adversarial loss: 0.546350\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337630; batch adversarial loss: 0.578162\n",
      "epoch 178; iter: 0; batch classifier loss: 0.378587; batch adversarial loss: 0.535790\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303624; batch adversarial loss: 0.515197\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364424; batch adversarial loss: 0.513624\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366131; batch adversarial loss: 0.534675\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364665; batch adversarial loss: 0.528354\n",
      "epoch 183; iter: 0; batch classifier loss: 0.457334; batch adversarial loss: 0.652979\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365814; batch adversarial loss: 0.551209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397008; batch adversarial loss: 0.458418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.343695; batch adversarial loss: 0.556265\n",
      "epoch 187; iter: 0; batch classifier loss: 0.416713; batch adversarial loss: 0.433292\n",
      "epoch 188; iter: 0; batch classifier loss: 0.410442; batch adversarial loss: 0.489835\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315553; batch adversarial loss: 0.509863\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322707; batch adversarial loss: 0.528674\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306736; batch adversarial loss: 0.580680\n",
      "epoch 192; iter: 0; batch classifier loss: 0.431538; batch adversarial loss: 0.533297\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383683; batch adversarial loss: 0.511408\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384617; batch adversarial loss: 0.480972\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306390; batch adversarial loss: 0.537157\n",
      "epoch 196; iter: 0; batch classifier loss: 0.409987; batch adversarial loss: 0.639771\n",
      "epoch 197; iter: 0; batch classifier loss: 0.400215; batch adversarial loss: 0.573137\n",
      "epoch 198; iter: 0; batch classifier loss: 0.427808; batch adversarial loss: 0.526929\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381445; batch adversarial loss: 0.645207\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677003; batch adversarial loss: 0.771010\n",
      "epoch 1; iter: 0; batch classifier loss: 0.766364; batch adversarial loss: 0.881615\n",
      "epoch 2; iter: 0; batch classifier loss: 0.927284; batch adversarial loss: 0.833303\n",
      "epoch 3; iter: 0; batch classifier loss: 0.811762; batch adversarial loss: 0.742109\n",
      "epoch 4; iter: 0; batch classifier loss: 0.794091; batch adversarial loss: 0.686853\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630988; batch adversarial loss: 0.633558\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568810; batch adversarial loss: 0.618763\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566017; batch adversarial loss: 0.615130\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533951; batch adversarial loss: 0.649058\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503072; batch adversarial loss: 0.574208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501723; batch adversarial loss: 0.597738\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531850; batch adversarial loss: 0.618704\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484704; batch adversarial loss: 0.606610\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564950; batch adversarial loss: 0.573550\n",
      "epoch 14; iter: 0; batch classifier loss: 0.585537; batch adversarial loss: 0.531882\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427259; batch adversarial loss: 0.561860\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547896; batch adversarial loss: 0.537228\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527888; batch adversarial loss: 0.537794\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500549; batch adversarial loss: 0.569933\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497193; batch adversarial loss: 0.530922\n",
      "epoch 20; iter: 0; batch classifier loss: 0.467966; batch adversarial loss: 0.578504\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497528; batch adversarial loss: 0.544648\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438633; batch adversarial loss: 0.603229\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520953; batch adversarial loss: 0.578963\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436384; batch adversarial loss: 0.598122\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522641; batch adversarial loss: 0.532425\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487765; batch adversarial loss: 0.475491\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494290; batch adversarial loss: 0.605266\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494468; batch adversarial loss: 0.482556\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488283; batch adversarial loss: 0.582614\n",
      "epoch 30; iter: 0; batch classifier loss: 0.497831; batch adversarial loss: 0.520932\n",
      "epoch 31; iter: 0; batch classifier loss: 0.559496; batch adversarial loss: 0.483100\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459601; batch adversarial loss: 0.523115\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501790; batch adversarial loss: 0.566679\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461330; batch adversarial loss: 0.529992\n",
      "epoch 35; iter: 0; batch classifier loss: 0.368224; batch adversarial loss: 0.558003\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481494; batch adversarial loss: 0.530307\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427130; batch adversarial loss: 0.432486\n",
      "epoch 38; iter: 0; batch classifier loss: 0.353378; batch adversarial loss: 0.582939\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439179; batch adversarial loss: 0.431579\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481609; batch adversarial loss: 0.520508\n",
      "epoch 41; iter: 0; batch classifier loss: 0.326448; batch adversarial loss: 0.589020\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418966; batch adversarial loss: 0.597609\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455536; batch adversarial loss: 0.580047\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403478; batch adversarial loss: 0.536221\n",
      "epoch 45; iter: 0; batch classifier loss: 0.375540; batch adversarial loss: 0.508140\n",
      "epoch 46; iter: 0; batch classifier loss: 0.339338; batch adversarial loss: 0.499017\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418897; batch adversarial loss: 0.581215\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416812; batch adversarial loss: 0.599045\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390577; batch adversarial loss: 0.544464\n",
      "epoch 50; iter: 0; batch classifier loss: 0.444609; batch adversarial loss: 0.508077\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425964; batch adversarial loss: 0.581698\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375623; batch adversarial loss: 0.516953\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437882; batch adversarial loss: 0.571526\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379401; batch adversarial loss: 0.507390\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400016; batch adversarial loss: 0.450553\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371008; batch adversarial loss: 0.581786\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449282; batch adversarial loss: 0.563068\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442766; batch adversarial loss: 0.544084\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408049; batch adversarial loss: 0.526091\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443224; batch adversarial loss: 0.580509\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418070; batch adversarial loss: 0.554122\n",
      "epoch 62; iter: 0; batch classifier loss: 0.366804; batch adversarial loss: 0.579121\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399475; batch adversarial loss: 0.577695\n",
      "epoch 64; iter: 0; batch classifier loss: 0.327241; batch adversarial loss: 0.527854\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389213; batch adversarial loss: 0.543437\n",
      "epoch 66; iter: 0; batch classifier loss: 0.337707; batch adversarial loss: 0.607471\n",
      "epoch 67; iter: 0; batch classifier loss: 0.373029; batch adversarial loss: 0.479112\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405836; batch adversarial loss: 0.486728\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430374; batch adversarial loss: 0.532990\n",
      "epoch 70; iter: 0; batch classifier loss: 0.389328; batch adversarial loss: 0.580157\n",
      "epoch 71; iter: 0; batch classifier loss: 0.309505; batch adversarial loss: 0.523035\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449231; batch adversarial loss: 0.517835\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371777; batch adversarial loss: 0.537093\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418140; batch adversarial loss: 0.600523\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415818; batch adversarial loss: 0.551851\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440939; batch adversarial loss: 0.512396\n",
      "epoch 77; iter: 0; batch classifier loss: 0.428676; batch adversarial loss: 0.518916\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390704; batch adversarial loss: 0.541121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.360807; batch adversarial loss: 0.545683\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378699; batch adversarial loss: 0.594525\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383785; batch adversarial loss: 0.535416\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363418; batch adversarial loss: 0.568427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.380843; batch adversarial loss: 0.561933\n",
      "epoch 84; iter: 0; batch classifier loss: 0.337909; batch adversarial loss: 0.559251\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414490; batch adversarial loss: 0.569331\n",
      "epoch 86; iter: 0; batch classifier loss: 0.354431; batch adversarial loss: 0.556197\n",
      "epoch 87; iter: 0; batch classifier loss: 0.355493; batch adversarial loss: 0.544927\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379851; batch adversarial loss: 0.541504\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433879; batch adversarial loss: 0.631552\n",
      "epoch 90; iter: 0; batch classifier loss: 0.360587; batch adversarial loss: 0.546540\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388673; batch adversarial loss: 0.619740\n",
      "epoch 92; iter: 0; batch classifier loss: 0.346393; batch adversarial loss: 0.649563\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352471; batch adversarial loss: 0.540335\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405026; batch adversarial loss: 0.503700\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376027; batch adversarial loss: 0.530169\n",
      "epoch 96; iter: 0; batch classifier loss: 0.338712; batch adversarial loss: 0.497812\n",
      "epoch 97; iter: 0; batch classifier loss: 0.322218; batch adversarial loss: 0.516624\n",
      "epoch 98; iter: 0; batch classifier loss: 0.335241; batch adversarial loss: 0.551689\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425323; batch adversarial loss: 0.524510\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417411; batch adversarial loss: 0.580366\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363073; batch adversarial loss: 0.606829\n",
      "epoch 102; iter: 0; batch classifier loss: 0.450624; batch adversarial loss: 0.514844\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426201; batch adversarial loss: 0.471986\n",
      "epoch 104; iter: 0; batch classifier loss: 0.343155; batch adversarial loss: 0.511998\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382270; batch adversarial loss: 0.633502\n",
      "epoch 106; iter: 0; batch classifier loss: 0.311347; batch adversarial loss: 0.545796\n",
      "epoch 107; iter: 0; batch classifier loss: 0.342151; batch adversarial loss: 0.629171\n",
      "epoch 108; iter: 0; batch classifier loss: 0.358085; batch adversarial loss: 0.583870\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406244; batch adversarial loss: 0.513180\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414572; batch adversarial loss: 0.510807\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381201; batch adversarial loss: 0.504077\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339307; batch adversarial loss: 0.507834\n",
      "epoch 113; iter: 0; batch classifier loss: 0.299931; batch adversarial loss: 0.536088\n",
      "epoch 114; iter: 0; batch classifier loss: 0.318274; batch adversarial loss: 0.610216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371845; batch adversarial loss: 0.561980\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402517; batch adversarial loss: 0.609681\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386362; batch adversarial loss: 0.528496\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347034; batch adversarial loss: 0.568827\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372441; batch adversarial loss: 0.544385\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374521; batch adversarial loss: 0.597549\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378268; batch adversarial loss: 0.564881\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327038; batch adversarial loss: 0.525779\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395308; batch adversarial loss: 0.532703\n",
      "epoch 124; iter: 0; batch classifier loss: 0.297926; batch adversarial loss: 0.544601\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329345; batch adversarial loss: 0.480589\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354514; batch adversarial loss: 0.612736\n",
      "epoch 127; iter: 0; batch classifier loss: 0.398802; batch adversarial loss: 0.538777\n",
      "epoch 128; iter: 0; batch classifier loss: 0.298623; batch adversarial loss: 0.539776\n",
      "epoch 129; iter: 0; batch classifier loss: 0.327029; batch adversarial loss: 0.481968\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382902; batch adversarial loss: 0.509021\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338048; batch adversarial loss: 0.566490\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395512; batch adversarial loss: 0.532121\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336228; batch adversarial loss: 0.507252\n",
      "epoch 134; iter: 0; batch classifier loss: 0.317634; batch adversarial loss: 0.572919\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314480; batch adversarial loss: 0.571849\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357583; batch adversarial loss: 0.527997\n",
      "epoch 137; iter: 0; batch classifier loss: 0.335082; batch adversarial loss: 0.494414\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366251; batch adversarial loss: 0.505427\n",
      "epoch 139; iter: 0; batch classifier loss: 0.297422; batch adversarial loss: 0.576331\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347091; batch adversarial loss: 0.518126\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367112; batch adversarial loss: 0.534027\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408618; batch adversarial loss: 0.507411\n",
      "epoch 143; iter: 0; batch classifier loss: 0.423261; batch adversarial loss: 0.454608\n",
      "epoch 144; iter: 0; batch classifier loss: 0.364611; batch adversarial loss: 0.570855\n",
      "epoch 145; iter: 0; batch classifier loss: 0.392274; batch adversarial loss: 0.482091\n",
      "epoch 146; iter: 0; batch classifier loss: 0.300480; batch adversarial loss: 0.518621\n",
      "epoch 147; iter: 0; batch classifier loss: 0.298593; batch adversarial loss: 0.601692\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353366; batch adversarial loss: 0.571141\n",
      "epoch 149; iter: 0; batch classifier loss: 0.302530; batch adversarial loss: 0.496932\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330263; batch adversarial loss: 0.562585\n",
      "epoch 151; iter: 0; batch classifier loss: 0.333601; batch adversarial loss: 0.547466\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336146; batch adversarial loss: 0.551208\n",
      "epoch 153; iter: 0; batch classifier loss: 0.397611; batch adversarial loss: 0.547914\n",
      "epoch 154; iter: 0; batch classifier loss: 0.405558; batch adversarial loss: 0.598435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354943; batch adversarial loss: 0.648288\n",
      "epoch 156; iter: 0; batch classifier loss: 0.393490; batch adversarial loss: 0.508401\n",
      "epoch 157; iter: 0; batch classifier loss: 0.320036; batch adversarial loss: 0.507737\n",
      "epoch 158; iter: 0; batch classifier loss: 0.306701; batch adversarial loss: 0.536159\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390153; batch adversarial loss: 0.488602\n",
      "epoch 160; iter: 0; batch classifier loss: 0.359541; batch adversarial loss: 0.523979\n",
      "epoch 161; iter: 0; batch classifier loss: 0.377058; batch adversarial loss: 0.462008\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378169; batch adversarial loss: 0.551297\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375676; batch adversarial loss: 0.571174\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355843; batch adversarial loss: 0.595439\n",
      "epoch 165; iter: 0; batch classifier loss: 0.296742; batch adversarial loss: 0.574162\n",
      "epoch 166; iter: 0; batch classifier loss: 0.258920; batch adversarial loss: 0.603806\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345296; batch adversarial loss: 0.526303\n",
      "epoch 168; iter: 0; batch classifier loss: 0.405395; batch adversarial loss: 0.570454\n",
      "epoch 169; iter: 0; batch classifier loss: 0.286747; batch adversarial loss: 0.497026\n",
      "epoch 170; iter: 0; batch classifier loss: 0.357021; batch adversarial loss: 0.607307\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342107; batch adversarial loss: 0.627750\n",
      "epoch 172; iter: 0; batch classifier loss: 0.371767; batch adversarial loss: 0.535035\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383052; batch adversarial loss: 0.532561\n",
      "epoch 174; iter: 0; batch classifier loss: 0.434632; batch adversarial loss: 0.501816\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402869; batch adversarial loss: 0.535572\n",
      "epoch 176; iter: 0; batch classifier loss: 0.318706; batch adversarial loss: 0.541314\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384065; batch adversarial loss: 0.587225\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352116; batch adversarial loss: 0.495897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.299208; batch adversarial loss: 0.549727\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307945; batch adversarial loss: 0.541272\n",
      "epoch 181; iter: 0; batch classifier loss: 0.335022; batch adversarial loss: 0.627592\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331290; batch adversarial loss: 0.554965\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341692; batch adversarial loss: 0.565171\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386109; batch adversarial loss: 0.519157\n",
      "epoch 185; iter: 0; batch classifier loss: 0.441218; batch adversarial loss: 0.567641\n",
      "epoch 186; iter: 0; batch classifier loss: 0.485468; batch adversarial loss: 0.513583\n",
      "epoch 187; iter: 0; batch classifier loss: 0.297751; batch adversarial loss: 0.542459\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345496; batch adversarial loss: 0.518030\n",
      "epoch 189; iter: 0; batch classifier loss: 0.451718; batch adversarial loss: 0.604238\n",
      "epoch 190; iter: 0; batch classifier loss: 0.409632; batch adversarial loss: 0.499736\n",
      "epoch 191; iter: 0; batch classifier loss: 0.332435; batch adversarial loss: 0.617590\n",
      "epoch 192; iter: 0; batch classifier loss: 0.410208; batch adversarial loss: 0.514333\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388952; batch adversarial loss: 0.564037\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347889; batch adversarial loss: 0.506517\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369594; batch adversarial loss: 0.590394\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360922; batch adversarial loss: 0.487850\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341466; batch adversarial loss: 0.552398\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323116; batch adversarial loss: 0.609359\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357850; batch adversarial loss: 0.553109\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674583; batch adversarial loss: 0.557487\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593728; batch adversarial loss: 0.660108\n",
      "epoch 2; iter: 0; batch classifier loss: 0.626564; batch adversarial loss: 0.583435\n",
      "epoch 3; iter: 0; batch classifier loss: 0.611619; batch adversarial loss: 0.607242\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542339; batch adversarial loss: 0.567161\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569928; batch adversarial loss: 0.602210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528480; batch adversarial loss: 0.580227\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524893; batch adversarial loss: 0.569748\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547499; batch adversarial loss: 0.613236\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500886; batch adversarial loss: 0.524531\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586045; batch adversarial loss: 0.629204\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505466; batch adversarial loss: 0.583284\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492217; batch adversarial loss: 0.533520\n",
      "epoch 13; iter: 0; batch classifier loss: 0.463158; batch adversarial loss: 0.576773\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435636; batch adversarial loss: 0.605251\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497650; batch adversarial loss: 0.548660\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531474; batch adversarial loss: 0.566133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500234; batch adversarial loss: 0.522869\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476036; batch adversarial loss: 0.570220\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472987; batch adversarial loss: 0.552650\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515177; batch adversarial loss: 0.591506\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495534; batch adversarial loss: 0.507644\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469569; batch adversarial loss: 0.517749\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493855; batch adversarial loss: 0.554498\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485085; batch adversarial loss: 0.598870\n",
      "epoch 25; iter: 0; batch classifier loss: 0.587974; batch adversarial loss: 0.564736\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471980; batch adversarial loss: 0.557867\n",
      "epoch 27; iter: 0; batch classifier loss: 0.607650; batch adversarial loss: 0.521147\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429531; batch adversarial loss: 0.540714\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461695; batch adversarial loss: 0.587110\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512306; batch adversarial loss: 0.545108\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486127; batch adversarial loss: 0.520033\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416277; batch adversarial loss: 0.478894\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453581; batch adversarial loss: 0.566445\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456228; batch adversarial loss: 0.525926\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434085; batch adversarial loss: 0.493037\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456428; batch adversarial loss: 0.580386\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392353; batch adversarial loss: 0.546625\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461192; batch adversarial loss: 0.554280\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500865; batch adversarial loss: 0.516933\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389047; batch adversarial loss: 0.616501\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435995; batch adversarial loss: 0.570938\n",
      "epoch 42; iter: 0; batch classifier loss: 0.479944; batch adversarial loss: 0.534442\n",
      "epoch 43; iter: 0; batch classifier loss: 0.334848; batch adversarial loss: 0.544271\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408520; batch adversarial loss: 0.470225\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418539; batch adversarial loss: 0.544053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445809; batch adversarial loss: 0.487439\n",
      "epoch 47; iter: 0; batch classifier loss: 0.388352; batch adversarial loss: 0.618401\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439017; batch adversarial loss: 0.534370\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384724; batch adversarial loss: 0.663055\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394637; batch adversarial loss: 0.516657\n",
      "epoch 51; iter: 0; batch classifier loss: 0.509173; batch adversarial loss: 0.599715\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463516; batch adversarial loss: 0.562517\n",
      "epoch 53; iter: 0; batch classifier loss: 0.474558; batch adversarial loss: 0.480333\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392875; batch adversarial loss: 0.526188\n",
      "epoch 55; iter: 0; batch classifier loss: 0.527594; batch adversarial loss: 0.599902\n",
      "epoch 56; iter: 0; batch classifier loss: 0.471570; batch adversarial loss: 0.535519\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431740; batch adversarial loss: 0.543852\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410576; batch adversarial loss: 0.545136\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447342; batch adversarial loss: 0.599933\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373894; batch adversarial loss: 0.609002\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408163; batch adversarial loss: 0.619323\n",
      "epoch 62; iter: 0; batch classifier loss: 0.485903; batch adversarial loss: 0.467000\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395038; batch adversarial loss: 0.439133\n",
      "epoch 64; iter: 0; batch classifier loss: 0.383641; batch adversarial loss: 0.534392\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416281; batch adversarial loss: 0.479632\n",
      "epoch 66; iter: 0; batch classifier loss: 0.390656; batch adversarial loss: 0.552490\n",
      "epoch 67; iter: 0; batch classifier loss: 0.299547; batch adversarial loss: 0.583070\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397908; batch adversarial loss: 0.533272\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475655; batch adversarial loss: 0.554899\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409863; batch adversarial loss: 0.486598\n",
      "epoch 71; iter: 0; batch classifier loss: 0.470719; batch adversarial loss: 0.518653\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379978; batch adversarial loss: 0.629072\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411935; batch adversarial loss: 0.489824\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394373; batch adversarial loss: 0.488700\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371506; batch adversarial loss: 0.416058\n",
      "epoch 76; iter: 0; batch classifier loss: 0.389399; batch adversarial loss: 0.573791\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383607; batch adversarial loss: 0.481965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.346984; batch adversarial loss: 0.487447\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413404; batch adversarial loss: 0.562952\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412561; batch adversarial loss: 0.590223\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391310; batch adversarial loss: 0.572474\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363777; batch adversarial loss: 0.572991\n",
      "epoch 83; iter: 0; batch classifier loss: 0.447985; batch adversarial loss: 0.581182\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356356; batch adversarial loss: 0.573431\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400904; batch adversarial loss: 0.497286\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385505; batch adversarial loss: 0.598596\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409103; batch adversarial loss: 0.525937\n",
      "epoch 88; iter: 0; batch classifier loss: 0.328126; batch adversarial loss: 0.616969\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370264; batch adversarial loss: 0.572487\n",
      "epoch 90; iter: 0; batch classifier loss: 0.295216; batch adversarial loss: 0.591329\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373680; batch adversarial loss: 0.535250\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370848; batch adversarial loss: 0.516895\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412658; batch adversarial loss: 0.553325\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390757; batch adversarial loss: 0.507126\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396527; batch adversarial loss: 0.469950\n",
      "epoch 96; iter: 0; batch classifier loss: 0.339058; batch adversarial loss: 0.572728\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334431; batch adversarial loss: 0.563935\n",
      "epoch 98; iter: 0; batch classifier loss: 0.431705; batch adversarial loss: 0.554182\n",
      "epoch 99; iter: 0; batch classifier loss: 0.371181; batch adversarial loss: 0.583194\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361991; batch adversarial loss: 0.480856\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364055; batch adversarial loss: 0.519548\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402972; batch adversarial loss: 0.578787\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394616; batch adversarial loss: 0.560173\n",
      "epoch 104; iter: 0; batch classifier loss: 0.445707; batch adversarial loss: 0.563361\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417827; batch adversarial loss: 0.556552\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394939; batch adversarial loss: 0.452546\n",
      "epoch 107; iter: 0; batch classifier loss: 0.307821; batch adversarial loss: 0.507305\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412016; batch adversarial loss: 0.581487\n",
      "epoch 109; iter: 0; batch classifier loss: 0.319643; batch adversarial loss: 0.591706\n",
      "epoch 110; iter: 0; batch classifier loss: 0.354969; batch adversarial loss: 0.553718\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387821; batch adversarial loss: 0.545258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.320211; batch adversarial loss: 0.477383\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377175; batch adversarial loss: 0.544775\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377809; batch adversarial loss: 0.582204\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345027; batch adversarial loss: 0.533908\n",
      "epoch 116; iter: 0; batch classifier loss: 0.378711; batch adversarial loss: 0.542439\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379186; batch adversarial loss: 0.565346\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390000; batch adversarial loss: 0.498598\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340287; batch adversarial loss: 0.572220\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340400; batch adversarial loss: 0.627304\n",
      "epoch 121; iter: 0; batch classifier loss: 0.445169; batch adversarial loss: 0.561918\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350810; batch adversarial loss: 0.544360\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373490; batch adversarial loss: 0.524384\n",
      "epoch 124; iter: 0; batch classifier loss: 0.430066; batch adversarial loss: 0.526092\n",
      "epoch 125; iter: 0; batch classifier loss: 0.396275; batch adversarial loss: 0.583089\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355534; batch adversarial loss: 0.552055\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371719; batch adversarial loss: 0.526985\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369602; batch adversarial loss: 0.552056\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350211; batch adversarial loss: 0.498337\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389158; batch adversarial loss: 0.507670\n",
      "epoch 131; iter: 0; batch classifier loss: 0.299032; batch adversarial loss: 0.571259\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400931; batch adversarial loss: 0.574754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.333030; batch adversarial loss: 0.486273\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352047; batch adversarial loss: 0.580902\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343717; batch adversarial loss: 0.598302\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377229; batch adversarial loss: 0.516657\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350000; batch adversarial loss: 0.580001\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355495; batch adversarial loss: 0.525153\n",
      "epoch 139; iter: 0; batch classifier loss: 0.442459; batch adversarial loss: 0.516676\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328850; batch adversarial loss: 0.545286\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422848; batch adversarial loss: 0.545428\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318487; batch adversarial loss: 0.552360\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334755; batch adversarial loss: 0.506771\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400785; batch adversarial loss: 0.468755\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377746; batch adversarial loss: 0.479948\n",
      "epoch 146; iter: 0; batch classifier loss: 0.300183; batch adversarial loss: 0.571980\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388138; batch adversarial loss: 0.589276\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364160; batch adversarial loss: 0.525209\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383255; batch adversarial loss: 0.563263\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360403; batch adversarial loss: 0.575011\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391418; batch adversarial loss: 0.499280\n",
      "epoch 152; iter: 0; batch classifier loss: 0.319153; batch adversarial loss: 0.580161\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366088; batch adversarial loss: 0.571630\n",
      "epoch 154; iter: 0; batch classifier loss: 0.388261; batch adversarial loss: 0.553543\n",
      "epoch 155; iter: 0; batch classifier loss: 0.427094; batch adversarial loss: 0.563995\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356388; batch adversarial loss: 0.627895\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418409; batch adversarial loss: 0.565323\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343321; batch adversarial loss: 0.589188\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341799; batch adversarial loss: 0.554285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316566; batch adversarial loss: 0.554019\n",
      "epoch 161; iter: 0; batch classifier loss: 0.395053; batch adversarial loss: 0.508406\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387501; batch adversarial loss: 0.489822\n",
      "epoch 163; iter: 0; batch classifier loss: 0.421381; batch adversarial loss: 0.525951\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381206; batch adversarial loss: 0.581127\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375334; batch adversarial loss: 0.480958\n",
      "epoch 166; iter: 0; batch classifier loss: 0.244447; batch adversarial loss: 0.535506\n",
      "epoch 167; iter: 0; batch classifier loss: 0.357835; batch adversarial loss: 0.536269\n",
      "epoch 168; iter: 0; batch classifier loss: 0.469331; batch adversarial loss: 0.545201\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382975; batch adversarial loss: 0.609438\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385741; batch adversarial loss: 0.589962\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359149; batch adversarial loss: 0.525258\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318592; batch adversarial loss: 0.600059\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371703; batch adversarial loss: 0.440649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.351216; batch adversarial loss: 0.497020\n",
      "epoch 175; iter: 0; batch classifier loss: 0.305896; batch adversarial loss: 0.580334\n",
      "epoch 176; iter: 0; batch classifier loss: 0.401468; batch adversarial loss: 0.543350\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354119; batch adversarial loss: 0.637786\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336732; batch adversarial loss: 0.609711\n",
      "epoch 179; iter: 0; batch classifier loss: 0.376194; batch adversarial loss: 0.555041\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327190; batch adversarial loss: 0.516477\n",
      "epoch 181; iter: 0; batch classifier loss: 0.444769; batch adversarial loss: 0.525430\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368220; batch adversarial loss: 0.517922\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327639; batch adversarial loss: 0.618735\n",
      "epoch 184; iter: 0; batch classifier loss: 0.316821; batch adversarial loss: 0.600274\n",
      "epoch 185; iter: 0; batch classifier loss: 0.323987; batch adversarial loss: 0.591866\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334048; batch adversarial loss: 0.592038\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385820; batch adversarial loss: 0.655626\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341836; batch adversarial loss: 0.517216\n",
      "epoch 189; iter: 0; batch classifier loss: 0.453585; batch adversarial loss: 0.592274\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407573; batch adversarial loss: 0.544352\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331055; batch adversarial loss: 0.525496\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305785; batch adversarial loss: 0.479776\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372230; batch adversarial loss: 0.583368\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313074; batch adversarial loss: 0.515944\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361940; batch adversarial loss: 0.471697\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359763; batch adversarial loss: 0.524420\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341356; batch adversarial loss: 0.514924\n",
      "epoch 198; iter: 0; batch classifier loss: 0.391075; batch adversarial loss: 0.572508\n",
      "epoch 199; iter: 0; batch classifier loss: 0.436301; batch adversarial loss: 0.535020\n",
      "epoch 0; iter: 0; batch classifier loss: 0.787780; batch adversarial loss: 0.714545\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614932; batch adversarial loss: 0.704345\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551338; batch adversarial loss: 0.687612\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596004; batch adversarial loss: 0.680987\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564635; batch adversarial loss: 0.640015\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559700; batch adversarial loss: 0.626483\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552554; batch adversarial loss: 0.584664\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575880; batch adversarial loss: 0.598118\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501080; batch adversarial loss: 0.612027\n",
      "epoch 9; iter: 0; batch classifier loss: 0.620820; batch adversarial loss: 0.559351\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481310; batch adversarial loss: 0.575116\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555035; batch adversarial loss: 0.634676\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530889; batch adversarial loss: 0.526850\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506653; batch adversarial loss: 0.626127\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535316; batch adversarial loss: 0.574806\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490200; batch adversarial loss: 0.551546\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510248; batch adversarial loss: 0.644250\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462751; batch adversarial loss: 0.571934\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507901; batch adversarial loss: 0.654697\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509821; batch adversarial loss: 0.644290\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457665; batch adversarial loss: 0.537035\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473144; batch adversarial loss: 0.498116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441170; batch adversarial loss: 0.573469\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497358; batch adversarial loss: 0.531832\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503684; batch adversarial loss: 0.496044\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467276; batch adversarial loss: 0.459900\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522377; batch adversarial loss: 0.531196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479744; batch adversarial loss: 0.551730\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459034; batch adversarial loss: 0.569720\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510440; batch adversarial loss: 0.553722\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508789; batch adversarial loss: 0.584379\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430556; batch adversarial loss: 0.581876\n",
      "epoch 32; iter: 0; batch classifier loss: 0.404313; batch adversarial loss: 0.533724\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477741; batch adversarial loss: 0.627709\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439339; batch adversarial loss: 0.544131\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441763; batch adversarial loss: 0.521845\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445340; batch adversarial loss: 0.530961\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479977; batch adversarial loss: 0.600201\n",
      "epoch 38; iter: 0; batch classifier loss: 0.515563; batch adversarial loss: 0.615081\n",
      "epoch 39; iter: 0; batch classifier loss: 0.495816; batch adversarial loss: 0.561673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441604; batch adversarial loss: 0.534537\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506229; batch adversarial loss: 0.537834\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474892; batch adversarial loss: 0.486539\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431163; batch adversarial loss: 0.509874\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460652; batch adversarial loss: 0.544945\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479822; batch adversarial loss: 0.502455\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488737; batch adversarial loss: 0.526094\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493446; batch adversarial loss: 0.561989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406254; batch adversarial loss: 0.564357\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436644; batch adversarial loss: 0.536083\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430629; batch adversarial loss: 0.554352\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428151; batch adversarial loss: 0.501977\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405073; batch adversarial loss: 0.580598\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449334; batch adversarial loss: 0.579714\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473613; batch adversarial loss: 0.579372\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483523; batch adversarial loss: 0.535134\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453008; batch adversarial loss: 0.491334\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466839; batch adversarial loss: 0.553796\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407213; batch adversarial loss: 0.492135\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394030; batch adversarial loss: 0.527395\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406008; batch adversarial loss: 0.553768\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440869; batch adversarial loss: 0.500359\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398143; batch adversarial loss: 0.509161\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425956; batch adversarial loss: 0.589350\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384959; batch adversarial loss: 0.535967\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417481; batch adversarial loss: 0.642620\n",
      "epoch 66; iter: 0; batch classifier loss: 0.475910; batch adversarial loss: 0.526846\n",
      "epoch 67; iter: 0; batch classifier loss: 0.367637; batch adversarial loss: 0.535349\n",
      "epoch 68; iter: 0; batch classifier loss: 0.451809; batch adversarial loss: 0.517006\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396505; batch adversarial loss: 0.598597\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462366; batch adversarial loss: 0.597938\n",
      "epoch 71; iter: 0; batch classifier loss: 0.456140; batch adversarial loss: 0.481797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.387260; batch adversarial loss: 0.509486\n",
      "epoch 73; iter: 0; batch classifier loss: 0.364456; batch adversarial loss: 0.562148\n",
      "epoch 74; iter: 0; batch classifier loss: 0.455508; batch adversarial loss: 0.562622\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373016; batch adversarial loss: 0.526541\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369436; batch adversarial loss: 0.562492\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441198; batch adversarial loss: 0.518130\n",
      "epoch 78; iter: 0; batch classifier loss: 0.384269; batch adversarial loss: 0.562462\n",
      "epoch 79; iter: 0; batch classifier loss: 0.351393; batch adversarial loss: 0.624961\n",
      "epoch 80; iter: 0; batch classifier loss: 0.464691; batch adversarial loss: 0.598271\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398771; batch adversarial loss: 0.580238\n",
      "epoch 82; iter: 0; batch classifier loss: 0.451930; batch adversarial loss: 0.481929\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404469; batch adversarial loss: 0.562504\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406847; batch adversarial loss: 0.580764\n",
      "epoch 85; iter: 0; batch classifier loss: 0.459359; batch adversarial loss: 0.607378\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385194; batch adversarial loss: 0.535473\n",
      "epoch 87; iter: 0; batch classifier loss: 0.438079; batch adversarial loss: 0.562857\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376860; batch adversarial loss: 0.553317\n",
      "epoch 89; iter: 0; batch classifier loss: 0.430764; batch adversarial loss: 0.579905\n",
      "epoch 90; iter: 0; batch classifier loss: 0.354277; batch adversarial loss: 0.580608\n",
      "epoch 91; iter: 0; batch classifier loss: 0.332223; batch adversarial loss: 0.589286\n",
      "epoch 92; iter: 0; batch classifier loss: 0.333987; batch adversarial loss: 0.535812\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399086; batch adversarial loss: 0.624876\n",
      "epoch 94; iter: 0; batch classifier loss: 0.317861; batch adversarial loss: 0.606439\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384205; batch adversarial loss: 0.616268\n",
      "epoch 96; iter: 0; batch classifier loss: 0.379913; batch adversarial loss: 0.535842\n",
      "epoch 97; iter: 0; batch classifier loss: 0.451004; batch adversarial loss: 0.588644\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384531; batch adversarial loss: 0.571588\n",
      "epoch 99; iter: 0; batch classifier loss: 0.479125; batch adversarial loss: 0.589148\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374615; batch adversarial loss: 0.589260\n",
      "epoch 101; iter: 0; batch classifier loss: 0.412969; batch adversarial loss: 0.571471\n",
      "epoch 102; iter: 0; batch classifier loss: 0.421571; batch adversarial loss: 0.508882\n",
      "epoch 103; iter: 0; batch classifier loss: 0.451506; batch adversarial loss: 0.562706\n",
      "epoch 104; iter: 0; batch classifier loss: 0.347325; batch adversarial loss: 0.517902\n",
      "epoch 105; iter: 0; batch classifier loss: 0.357087; batch adversarial loss: 0.526720\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326332; batch adversarial loss: 0.437591\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357844; batch adversarial loss: 0.536065\n",
      "epoch 108; iter: 0; batch classifier loss: 0.452368; batch adversarial loss: 0.544420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.439561; batch adversarial loss: 0.535174\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430095; batch adversarial loss: 0.641646\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415284; batch adversarial loss: 0.571965\n",
      "epoch 112; iter: 0; batch classifier loss: 0.334602; batch adversarial loss: 0.526646\n",
      "epoch 113; iter: 0; batch classifier loss: 0.478207; batch adversarial loss: 0.590074\n",
      "epoch 114; iter: 0; batch classifier loss: 0.343649; batch adversarial loss: 0.643507\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382607; batch adversarial loss: 0.553232\n",
      "epoch 116; iter: 0; batch classifier loss: 0.444610; batch adversarial loss: 0.589194\n",
      "epoch 117; iter: 0; batch classifier loss: 0.449646; batch adversarial loss: 0.544526\n",
      "epoch 118; iter: 0; batch classifier loss: 0.409511; batch adversarial loss: 0.545256\n",
      "epoch 119; iter: 0; batch classifier loss: 0.455509; batch adversarial loss: 0.544282\n",
      "epoch 120; iter: 0; batch classifier loss: 0.461668; batch adversarial loss: 0.499819\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395708; batch adversarial loss: 0.500376\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415153; batch adversarial loss: 0.527313\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394893; batch adversarial loss: 0.545208\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408000; batch adversarial loss: 0.571218\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389863; batch adversarial loss: 0.545570\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316518; batch adversarial loss: 0.563153\n",
      "epoch 127; iter: 0; batch classifier loss: 0.338706; batch adversarial loss: 0.589310\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355269; batch adversarial loss: 0.544360\n",
      "epoch 129; iter: 0; batch classifier loss: 0.331485; batch adversarial loss: 0.473512\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371657; batch adversarial loss: 0.536189\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368054; batch adversarial loss: 0.580248\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373575; batch adversarial loss: 0.562829\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371860; batch adversarial loss: 0.625043\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357181; batch adversarial loss: 0.607131\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373110; batch adversarial loss: 0.597961\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393541; batch adversarial loss: 0.535523\n",
      "epoch 137; iter: 0; batch classifier loss: 0.438050; batch adversarial loss: 0.544531\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341083; batch adversarial loss: 0.571352\n",
      "epoch 139; iter: 0; batch classifier loss: 0.438118; batch adversarial loss: 0.562069\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366941; batch adversarial loss: 0.606342\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329319; batch adversarial loss: 0.535844\n",
      "epoch 142; iter: 0; batch classifier loss: 0.309832; batch adversarial loss: 0.545126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.453438; batch adversarial loss: 0.508752\n",
      "epoch 144; iter: 0; batch classifier loss: 0.395676; batch adversarial loss: 0.517408\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385440; batch adversarial loss: 0.463784\n",
      "epoch 146; iter: 0; batch classifier loss: 0.464488; batch adversarial loss: 0.633989\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344194; batch adversarial loss: 0.562331\n",
      "epoch 148; iter: 0; batch classifier loss: 0.382733; batch adversarial loss: 0.518501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.423908; batch adversarial loss: 0.553139\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399973; batch adversarial loss: 0.535215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340214; batch adversarial loss: 0.464490\n",
      "epoch 152; iter: 0; batch classifier loss: 0.414968; batch adversarial loss: 0.616141\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330376; batch adversarial loss: 0.526835\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381741; batch adversarial loss: 0.562399\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360750; batch adversarial loss: 0.544401\n",
      "epoch 156; iter: 0; batch classifier loss: 0.422520; batch adversarial loss: 0.464751\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400320; batch adversarial loss: 0.553530\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398010; batch adversarial loss: 0.589759\n",
      "epoch 159; iter: 0; batch classifier loss: 0.416567; batch adversarial loss: 0.571137\n",
      "epoch 160; iter: 0; batch classifier loss: 0.367083; batch adversarial loss: 0.589084\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369971; batch adversarial loss: 0.543374\n",
      "epoch 162; iter: 0; batch classifier loss: 0.377522; batch adversarial loss: 0.491533\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359783; batch adversarial loss: 0.598129\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366298; batch adversarial loss: 0.490650\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363462; batch adversarial loss: 0.650838\n",
      "epoch 166; iter: 0; batch classifier loss: 0.279135; batch adversarial loss: 0.536632\n",
      "epoch 167; iter: 0; batch classifier loss: 0.375559; batch adversarial loss: 0.553762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.392462; batch adversarial loss: 0.537066\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371643; batch adversarial loss: 0.579642\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373190; batch adversarial loss: 0.633339\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363961; batch adversarial loss: 0.571087\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344795; batch adversarial loss: 0.562909\n",
      "epoch 173; iter: 0; batch classifier loss: 0.374279; batch adversarial loss: 0.572243\n",
      "epoch 174; iter: 0; batch classifier loss: 0.288074; batch adversarial loss: 0.544688\n",
      "epoch 175; iter: 0; batch classifier loss: 0.255664; batch adversarial loss: 0.482919\n",
      "epoch 176; iter: 0; batch classifier loss: 0.421386; batch adversarial loss: 0.517966\n",
      "epoch 177; iter: 0; batch classifier loss: 0.415767; batch adversarial loss: 0.509632\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326733; batch adversarial loss: 0.588876\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334455; batch adversarial loss: 0.526534\n",
      "epoch 180; iter: 0; batch classifier loss: 0.293361; batch adversarial loss: 0.536095\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383791; batch adversarial loss: 0.491180\n",
      "epoch 182; iter: 0; batch classifier loss: 0.321866; batch adversarial loss: 0.571569\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364348; batch adversarial loss: 0.544168\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338304; batch adversarial loss: 0.589521\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311743; batch adversarial loss: 0.580962\n",
      "epoch 186; iter: 0; batch classifier loss: 0.391551; batch adversarial loss: 0.536283\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387090; batch adversarial loss: 0.598478\n",
      "epoch 188; iter: 0; batch classifier loss: 0.421231; batch adversarial loss: 0.499977\n",
      "epoch 189; iter: 0; batch classifier loss: 0.299640; batch adversarial loss: 0.491513\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333950; batch adversarial loss: 0.606437\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344055; batch adversarial loss: 0.634125\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389975; batch adversarial loss: 0.579803\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387317; batch adversarial loss: 0.473319\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348596; batch adversarial loss: 0.554680\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349680; batch adversarial loss: 0.526452\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334850; batch adversarial loss: 0.526571\n",
      "epoch 197; iter: 0; batch classifier loss: 0.418969; batch adversarial loss: 0.669214\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343285; batch adversarial loss: 0.526772\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388561; batch adversarial loss: 0.527108\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700280; batch adversarial loss: 0.554341\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607018; batch adversarial loss: 0.659662\n",
      "epoch 2; iter: 0; batch classifier loss: 0.643987; batch adversarial loss: 0.678167\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565460; batch adversarial loss: 0.605660\n",
      "epoch 4; iter: 0; batch classifier loss: 0.540442; batch adversarial loss: 0.694847\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561210; batch adversarial loss: 0.618463\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502346; batch adversarial loss: 0.637853\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581234; batch adversarial loss: 0.619052\n",
      "epoch 8; iter: 0; batch classifier loss: 0.487118; batch adversarial loss: 0.574730\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559500; batch adversarial loss: 0.553592\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588206; batch adversarial loss: 0.548450\n",
      "epoch 11; iter: 0; batch classifier loss: 0.616447; batch adversarial loss: 0.580439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532146; batch adversarial loss: 0.628111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541707; batch adversarial loss: 0.520766\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563251; batch adversarial loss: 0.540998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487852; batch adversarial loss: 0.577162\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505414; batch adversarial loss: 0.585654\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488557; batch adversarial loss: 0.559640\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444270; batch adversarial loss: 0.532340\n",
      "epoch 19; iter: 0; batch classifier loss: 0.452849; batch adversarial loss: 0.469111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504752; batch adversarial loss: 0.502743\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468875; batch adversarial loss: 0.558224\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517388; batch adversarial loss: 0.507741\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487973; batch adversarial loss: 0.529108\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491168; batch adversarial loss: 0.539237\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465878; batch adversarial loss: 0.512462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484036; batch adversarial loss: 0.525104\n",
      "epoch 27; iter: 0; batch classifier loss: 0.377985; batch adversarial loss: 0.586895\n",
      "epoch 28; iter: 0; batch classifier loss: 0.584927; batch adversarial loss: 0.639393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.513907; batch adversarial loss: 0.536989\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450440; batch adversarial loss: 0.546021\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520928; batch adversarial loss: 0.564316\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435783; batch adversarial loss: 0.544870\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519777; batch adversarial loss: 0.598855\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501725; batch adversarial loss: 0.500713\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474433; batch adversarial loss: 0.535605\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430984; batch adversarial loss: 0.606907\n",
      "epoch 37; iter: 0; batch classifier loss: 0.521706; batch adversarial loss: 0.571882\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435938; batch adversarial loss: 0.518465\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454891; batch adversarial loss: 0.500336\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440308; batch adversarial loss: 0.553702\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449430; batch adversarial loss: 0.624236\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418494; batch adversarial loss: 0.562293\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491843; batch adversarial loss: 0.597841\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424968; batch adversarial loss: 0.517405\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457673; batch adversarial loss: 0.562363\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468374; batch adversarial loss: 0.607174\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455807; batch adversarial loss: 0.580318\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465679; batch adversarial loss: 0.535736\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443772; batch adversarial loss: 0.598400\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473740; batch adversarial loss: 0.579772\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429581; batch adversarial loss: 0.554215\n",
      "epoch 52; iter: 0; batch classifier loss: 0.479737; batch adversarial loss: 0.562237\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449445; batch adversarial loss: 0.544597\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469803; batch adversarial loss: 0.535594\n",
      "epoch 55; iter: 0; batch classifier loss: 0.360086; batch adversarial loss: 0.571768\n",
      "epoch 56; iter: 0; batch classifier loss: 0.483024; batch adversarial loss: 0.544220\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440139; batch adversarial loss: 0.489775\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431371; batch adversarial loss: 0.535332\n",
      "epoch 59; iter: 0; batch classifier loss: 0.430165; batch adversarial loss: 0.581645\n",
      "epoch 60; iter: 0; batch classifier loss: 0.478275; batch adversarial loss: 0.555322\n",
      "epoch 61; iter: 0; batch classifier loss: 0.476084; batch adversarial loss: 0.573036\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433431; batch adversarial loss: 0.481953\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406711; batch adversarial loss: 0.509111\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380766; batch adversarial loss: 0.553477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.459659; batch adversarial loss: 0.553431\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435862; batch adversarial loss: 0.455422\n",
      "epoch 67; iter: 0; batch classifier loss: 0.370072; batch adversarial loss: 0.562372\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434401; batch adversarial loss: 0.598811\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411834; batch adversarial loss: 0.607778\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455644; batch adversarial loss: 0.463304\n",
      "epoch 71; iter: 0; batch classifier loss: 0.456707; batch adversarial loss: 0.490225\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405477; batch adversarial loss: 0.634056\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386571; batch adversarial loss: 0.499375\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435619; batch adversarial loss: 0.571262\n",
      "epoch 75; iter: 0; batch classifier loss: 0.392345; batch adversarial loss: 0.589541\n",
      "epoch 76; iter: 0; batch classifier loss: 0.487331; batch adversarial loss: 0.572968\n",
      "epoch 77; iter: 0; batch classifier loss: 0.499662; batch adversarial loss: 0.508741\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467318; batch adversarial loss: 0.517857\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413140; batch adversarial loss: 0.508988\n",
      "epoch 80; iter: 0; batch classifier loss: 0.434702; batch adversarial loss: 0.553194\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372548; batch adversarial loss: 0.563048\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400819; batch adversarial loss: 0.500106\n",
      "epoch 83; iter: 0; batch classifier loss: 0.362491; batch adversarial loss: 0.535806\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399623; batch adversarial loss: 0.544998\n",
      "epoch 85; iter: 0; batch classifier loss: 0.324355; batch adversarial loss: 0.535591\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408591; batch adversarial loss: 0.508430\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398409; batch adversarial loss: 0.518016\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383160; batch adversarial loss: 0.616727\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380563; batch adversarial loss: 0.580905\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385409; batch adversarial loss: 0.580587\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405973; batch adversarial loss: 0.553480\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381444; batch adversarial loss: 0.481531\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421196; batch adversarial loss: 0.626181\n",
      "epoch 94; iter: 0; batch classifier loss: 0.468087; batch adversarial loss: 0.535459\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419930; batch adversarial loss: 0.589338\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341623; batch adversarial loss: 0.562228\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362089; batch adversarial loss: 0.625884\n",
      "epoch 98; iter: 0; batch classifier loss: 0.428048; batch adversarial loss: 0.508823\n",
      "epoch 99; iter: 0; batch classifier loss: 0.340308; batch adversarial loss: 0.617113\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431722; batch adversarial loss: 0.508042\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352819; batch adversarial loss: 0.590018\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367071; batch adversarial loss: 0.526051\n",
      "epoch 103; iter: 0; batch classifier loss: 0.445547; batch adversarial loss: 0.544327\n",
      "epoch 104; iter: 0; batch classifier loss: 0.444958; batch adversarial loss: 0.517723\n",
      "epoch 105; iter: 0; batch classifier loss: 0.441474; batch adversarial loss: 0.509215\n",
      "epoch 106; iter: 0; batch classifier loss: 0.291135; batch adversarial loss: 0.464054\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364899; batch adversarial loss: 0.500123\n",
      "epoch 108; iter: 0; batch classifier loss: 0.448518; batch adversarial loss: 0.536043\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419797; batch adversarial loss: 0.661713\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378112; batch adversarial loss: 0.526034\n",
      "epoch 111; iter: 0; batch classifier loss: 0.314130; batch adversarial loss: 0.471459\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367915; batch adversarial loss: 0.599453\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399826; batch adversarial loss: 0.555403\n",
      "epoch 114; iter: 0; batch classifier loss: 0.297802; batch adversarial loss: 0.607699\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386220; batch adversarial loss: 0.536425\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377661; batch adversarial loss: 0.526282\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368229; batch adversarial loss: 0.527215\n",
      "epoch 118; iter: 0; batch classifier loss: 0.336986; batch adversarial loss: 0.571769\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431332; batch adversarial loss: 0.518338\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409423; batch adversarial loss: 0.490487\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335908; batch adversarial loss: 0.544647\n",
      "epoch 122; iter: 0; batch classifier loss: 0.425001; batch adversarial loss: 0.499984\n",
      "epoch 123; iter: 0; batch classifier loss: 0.338586; batch adversarial loss: 0.561715\n",
      "epoch 124; iter: 0; batch classifier loss: 0.437129; batch adversarial loss: 0.490441\n",
      "epoch 125; iter: 0; batch classifier loss: 0.470508; batch adversarial loss: 0.560477\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329099; batch adversarial loss: 0.572487\n",
      "epoch 127; iter: 0; batch classifier loss: 0.486641; batch adversarial loss: 0.607853\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352839; batch adversarial loss: 0.543251\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353948; batch adversarial loss: 0.518438\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343034; batch adversarial loss: 0.545631\n",
      "epoch 131; iter: 0; batch classifier loss: 0.390332; batch adversarial loss: 0.534894\n",
      "epoch 132; iter: 0; batch classifier loss: 0.383542; batch adversarial loss: 0.499333\n",
      "epoch 133; iter: 0; batch classifier loss: 0.424147; batch adversarial loss: 0.625364\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351706; batch adversarial loss: 0.535939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347299; batch adversarial loss: 0.527314\n",
      "epoch 136; iter: 0; batch classifier loss: 0.342238; batch adversarial loss: 0.552876\n",
      "epoch 137; iter: 0; batch classifier loss: 0.448507; batch adversarial loss: 0.553931\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378018; batch adversarial loss: 0.554539\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361332; batch adversarial loss: 0.561674\n",
      "epoch 140; iter: 0; batch classifier loss: 0.417845; batch adversarial loss: 0.508580\n",
      "epoch 141; iter: 0; batch classifier loss: 0.317656; batch adversarial loss: 0.491435\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333184; batch adversarial loss: 0.562414\n",
      "epoch 143; iter: 0; batch classifier loss: 0.357595; batch adversarial loss: 0.571522\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424839; batch adversarial loss: 0.562143\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355877; batch adversarial loss: 0.624913\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382524; batch adversarial loss: 0.544809\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394065; batch adversarial loss: 0.561962\n",
      "epoch 148; iter: 0; batch classifier loss: 0.359250; batch adversarial loss: 0.616305\n",
      "epoch 149; iter: 0; batch classifier loss: 0.321485; batch adversarial loss: 0.473573\n",
      "epoch 150; iter: 0; batch classifier loss: 0.463985; batch adversarial loss: 0.546022\n",
      "epoch 151; iter: 0; batch classifier loss: 0.418459; batch adversarial loss: 0.687804\n",
      "epoch 152; iter: 0; batch classifier loss: 0.406296; batch adversarial loss: 0.472405\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357216; batch adversarial loss: 0.561847\n",
      "epoch 154; iter: 0; batch classifier loss: 0.380727; batch adversarial loss: 0.517688\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350924; batch adversarial loss: 0.563191\n",
      "epoch 156; iter: 0; batch classifier loss: 0.369575; batch adversarial loss: 0.562779\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358080; batch adversarial loss: 0.553067\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352894; batch adversarial loss: 0.616801\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367350; batch adversarial loss: 0.563289\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398878; batch adversarial loss: 0.571118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.297169; batch adversarial loss: 0.598023\n",
      "epoch 162; iter: 0; batch classifier loss: 0.393638; batch adversarial loss: 0.579812\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355070; batch adversarial loss: 0.534950\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353863; batch adversarial loss: 0.572235\n",
      "epoch 165; iter: 0; batch classifier loss: 0.325556; batch adversarial loss: 0.607247\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374885; batch adversarial loss: 0.535256\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372193; batch adversarial loss: 0.589862\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378913; batch adversarial loss: 0.553347\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372798; batch adversarial loss: 0.580684\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410636; batch adversarial loss: 0.553202\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388442; batch adversarial loss: 0.490957\n",
      "epoch 172; iter: 0; batch classifier loss: 0.425400; batch adversarial loss: 0.471330\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356567; batch adversarial loss: 0.535447\n",
      "epoch 174; iter: 0; batch classifier loss: 0.484378; batch adversarial loss: 0.516739\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379735; batch adversarial loss: 0.553840\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364307; batch adversarial loss: 0.545671\n",
      "epoch 177; iter: 0; batch classifier loss: 0.416437; batch adversarial loss: 0.517152\n",
      "epoch 178; iter: 0; batch classifier loss: 0.426406; batch adversarial loss: 0.543648\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344366; batch adversarial loss: 0.553884\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337010; batch adversarial loss: 0.563141\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363149; batch adversarial loss: 0.607202\n",
      "epoch 182; iter: 0; batch classifier loss: 0.428926; batch adversarial loss: 0.578810\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388296; batch adversarial loss: 0.489765\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352677; batch adversarial loss: 0.552300\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332317; batch adversarial loss: 0.535244\n",
      "epoch 186; iter: 0; batch classifier loss: 0.362213; batch adversarial loss: 0.553690\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374037; batch adversarial loss: 0.553267\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395242; batch adversarial loss: 0.688950\n",
      "epoch 189; iter: 0; batch classifier loss: 0.503842; batch adversarial loss: 0.527847\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385504; batch adversarial loss: 0.596554\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366337; batch adversarial loss: 0.517962\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348707; batch adversarial loss: 0.570561\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403661; batch adversarial loss: 0.525783\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384117; batch adversarial loss: 0.508922\n",
      "epoch 195; iter: 0; batch classifier loss: 0.386089; batch adversarial loss: 0.526898\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342370; batch adversarial loss: 0.652247\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373466; batch adversarial loss: 0.670231\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360957; batch adversarial loss: 0.587970\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407755; batch adversarial loss: 0.579917\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705267; batch adversarial loss: 0.625843\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572572; batch adversarial loss: 0.650392\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582468; batch adversarial loss: 0.649686\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569363; batch adversarial loss: 0.685449\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520647; batch adversarial loss: 0.650988\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570898; batch adversarial loss: 0.597650\n",
      "epoch 6; iter: 0; batch classifier loss: 0.493306; batch adversarial loss: 0.626750\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575192; batch adversarial loss: 0.561114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554443; batch adversarial loss: 0.585280\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492785; batch adversarial loss: 0.608351\n",
      "epoch 10; iter: 0; batch classifier loss: 0.613459; batch adversarial loss: 0.616133\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582085; batch adversarial loss: 0.604312\n",
      "epoch 12; iter: 0; batch classifier loss: 0.604927; batch adversarial loss: 0.560732\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493073; batch adversarial loss: 0.557233\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520334; batch adversarial loss: 0.501999\n",
      "epoch 15; iter: 0; batch classifier loss: 0.464979; batch adversarial loss: 0.516119\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541806; batch adversarial loss: 0.591532\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462626; batch adversarial loss: 0.595469\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452933; batch adversarial loss: 0.592789\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505299; batch adversarial loss: 0.535778\n",
      "epoch 20; iter: 0; batch classifier loss: 0.550422; batch adversarial loss: 0.567033\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470583; batch adversarial loss: 0.524027\n",
      "epoch 22; iter: 0; batch classifier loss: 0.390207; batch adversarial loss: 0.529912\n",
      "epoch 23; iter: 0; batch classifier loss: 0.413155; batch adversarial loss: 0.569147\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514318; batch adversarial loss: 0.539082\n",
      "epoch 25; iter: 0; batch classifier loss: 0.565186; batch adversarial loss: 0.550514\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440462; batch adversarial loss: 0.612290\n",
      "epoch 27; iter: 0; batch classifier loss: 0.395413; batch adversarial loss: 0.579676\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487314; batch adversarial loss: 0.587799\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444127; batch adversarial loss: 0.559917\n",
      "epoch 30; iter: 0; batch classifier loss: 0.385654; batch adversarial loss: 0.546692\n",
      "epoch 31; iter: 0; batch classifier loss: 0.350756; batch adversarial loss: 0.579127\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483104; batch adversarial loss: 0.521199\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423932; batch adversarial loss: 0.580003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.498159; batch adversarial loss: 0.562652\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414145; batch adversarial loss: 0.580102\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464868; batch adversarial loss: 0.571739\n",
      "epoch 37; iter: 0; batch classifier loss: 0.522913; batch adversarial loss: 0.536929\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399033; batch adversarial loss: 0.527385\n",
      "epoch 39; iter: 0; batch classifier loss: 0.364418; batch adversarial loss: 0.492006\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427018; batch adversarial loss: 0.544501\n",
      "epoch 41; iter: 0; batch classifier loss: 0.381879; batch adversarial loss: 0.579681\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498944; batch adversarial loss: 0.605913\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420680; batch adversarial loss: 0.535697\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447437; batch adversarial loss: 0.607355\n",
      "epoch 45; iter: 0; batch classifier loss: 0.390210; batch adversarial loss: 0.589396\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388826; batch adversarial loss: 0.589510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.354442; batch adversarial loss: 0.533543\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489343; batch adversarial loss: 0.598687\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427604; batch adversarial loss: 0.551777\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443530; batch adversarial loss: 0.509689\n",
      "epoch 51; iter: 0; batch classifier loss: 0.484632; batch adversarial loss: 0.571093\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462892; batch adversarial loss: 0.508253\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379270; batch adversarial loss: 0.572514\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437558; batch adversarial loss: 0.553135\n",
      "epoch 55; iter: 0; batch classifier loss: 0.373627; batch adversarial loss: 0.580121\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438317; batch adversarial loss: 0.500556\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374880; batch adversarial loss: 0.572715\n",
      "epoch 58; iter: 0; batch classifier loss: 0.330945; batch adversarial loss: 0.509504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.323543; batch adversarial loss: 0.597614\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444494; batch adversarial loss: 0.624330\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463725; batch adversarial loss: 0.509777\n",
      "epoch 62; iter: 0; batch classifier loss: 0.469393; batch adversarial loss: 0.528960\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416924; batch adversarial loss: 0.544476\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397257; batch adversarial loss: 0.526972\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407290; batch adversarial loss: 0.465198\n",
      "epoch 66; iter: 0; batch classifier loss: 0.527833; batch adversarial loss: 0.519037\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416277; batch adversarial loss: 0.535842\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439048; batch adversarial loss: 0.651998\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440855; batch adversarial loss: 0.534921\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343136; batch adversarial loss: 0.615622\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394916; batch adversarial loss: 0.535977\n",
      "epoch 72; iter: 0; batch classifier loss: 0.465598; batch adversarial loss: 0.527190\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377505; batch adversarial loss: 0.508880\n",
      "epoch 74; iter: 0; batch classifier loss: 0.306407; batch adversarial loss: 0.510217\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397927; batch adversarial loss: 0.544218\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465700; batch adversarial loss: 0.517827\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368149; batch adversarial loss: 0.509106\n",
      "epoch 78; iter: 0; batch classifier loss: 0.476898; batch adversarial loss: 0.607363\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421714; batch adversarial loss: 0.571704\n",
      "epoch 80; iter: 0; batch classifier loss: 0.361364; batch adversarial loss: 0.560859\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385189; batch adversarial loss: 0.579619\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395146; batch adversarial loss: 0.509591\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389579; batch adversarial loss: 0.509224\n",
      "epoch 84; iter: 0; batch classifier loss: 0.340327; batch adversarial loss: 0.614537\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452228; batch adversarial loss: 0.516913\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381521; batch adversarial loss: 0.572327\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393725; batch adversarial loss: 0.474996\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387232; batch adversarial loss: 0.525883\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389658; batch adversarial loss: 0.630993\n",
      "epoch 90; iter: 0; batch classifier loss: 0.422789; batch adversarial loss: 0.552740\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384808; batch adversarial loss: 0.516159\n",
      "epoch 92; iter: 0; batch classifier loss: 0.435932; batch adversarial loss: 0.563038\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349776; batch adversarial loss: 0.544216\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432407; batch adversarial loss: 0.535534\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414204; batch adversarial loss: 0.545450\n",
      "epoch 96; iter: 0; batch classifier loss: 0.411099; batch adversarial loss: 0.553964\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402521; batch adversarial loss: 0.527243\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369357; batch adversarial loss: 0.482919\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403177; batch adversarial loss: 0.616681\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385003; batch adversarial loss: 0.617115\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414385; batch adversarial loss: 0.535421\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362290; batch adversarial loss: 0.589697\n",
      "epoch 103; iter: 0; batch classifier loss: 0.449826; batch adversarial loss: 0.553280\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386829; batch adversarial loss: 0.464020\n",
      "epoch 105; iter: 0; batch classifier loss: 0.425110; batch adversarial loss: 0.634269\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421615; batch adversarial loss: 0.526338\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394844; batch adversarial loss: 0.544725\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363276; batch adversarial loss: 0.624677\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333236; batch adversarial loss: 0.571547\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369710; batch adversarial loss: 0.571389\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379215; batch adversarial loss: 0.552795\n",
      "epoch 112; iter: 0; batch classifier loss: 0.454057; batch adversarial loss: 0.606454\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370173; batch adversarial loss: 0.510111\n",
      "epoch 114; iter: 0; batch classifier loss: 0.458026; batch adversarial loss: 0.561568\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348899; batch adversarial loss: 0.570996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343501; batch adversarial loss: 0.536082\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416197; batch adversarial loss: 0.545478\n",
      "epoch 118; iter: 0; batch classifier loss: 0.369773; batch adversarial loss: 0.552501\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348362; batch adversarial loss: 0.538094\n",
      "epoch 120; iter: 0; batch classifier loss: 0.405198; batch adversarial loss: 0.518657\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389619; batch adversarial loss: 0.508618\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350328; batch adversarial loss: 0.499642\n",
      "epoch 123; iter: 0; batch classifier loss: 0.280430; batch adversarial loss: 0.508539\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377263; batch adversarial loss: 0.554109\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343954; batch adversarial loss: 0.581351\n",
      "epoch 126; iter: 0; batch classifier loss: 0.467576; batch adversarial loss: 0.501217\n",
      "epoch 127; iter: 0; batch classifier loss: 0.314191; batch adversarial loss: 0.483276\n",
      "epoch 128; iter: 0; batch classifier loss: 0.378341; batch adversarial loss: 0.500709\n",
      "epoch 129; iter: 0; batch classifier loss: 0.424256; batch adversarial loss: 0.517531\n",
      "epoch 130; iter: 0; batch classifier loss: 0.326656; batch adversarial loss: 0.606193\n",
      "epoch 131; iter: 0; batch classifier loss: 0.302082; batch adversarial loss: 0.465463\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406735; batch adversarial loss: 0.581598\n",
      "epoch 133; iter: 0; batch classifier loss: 0.359560; batch adversarial loss: 0.534853\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341464; batch adversarial loss: 0.554790\n",
      "epoch 135; iter: 0; batch classifier loss: 0.422342; batch adversarial loss: 0.571524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327464; batch adversarial loss: 0.580141\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384165; batch adversarial loss: 0.552760\n",
      "epoch 138; iter: 0; batch classifier loss: 0.454163; batch adversarial loss: 0.579558\n",
      "epoch 139; iter: 0; batch classifier loss: 0.282366; batch adversarial loss: 0.500181\n",
      "epoch 140; iter: 0; batch classifier loss: 0.298635; batch adversarial loss: 0.556055\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434340; batch adversarial loss: 0.589667\n",
      "epoch 142; iter: 0; batch classifier loss: 0.276905; batch adversarial loss: 0.563144\n",
      "epoch 143; iter: 0; batch classifier loss: 0.316385; batch adversarial loss: 0.653951\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331833; batch adversarial loss: 0.616290\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351476; batch adversarial loss: 0.607436\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334904; batch adversarial loss: 0.590048\n",
      "epoch 147; iter: 0; batch classifier loss: 0.413517; batch adversarial loss: 0.536109\n",
      "epoch 148; iter: 0; batch classifier loss: 0.435987; batch adversarial loss: 0.535806\n",
      "epoch 149; iter: 0; batch classifier loss: 0.340895; batch adversarial loss: 0.616716\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384250; batch adversarial loss: 0.526139\n",
      "epoch 151; iter: 0; batch classifier loss: 0.433142; batch adversarial loss: 0.633965\n",
      "epoch 152; iter: 0; batch classifier loss: 0.279038; batch adversarial loss: 0.599668\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321854; batch adversarial loss: 0.535003\n",
      "epoch 154; iter: 0; batch classifier loss: 0.327097; batch adversarial loss: 0.569853\n",
      "epoch 155; iter: 0; batch classifier loss: 0.290683; batch adversarial loss: 0.551958\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333641; batch adversarial loss: 0.499658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 157; iter: 0; batch classifier loss: 0.357486; batch adversarial loss: 0.563376\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315036; batch adversarial loss: 0.613188\n",
      "epoch 159; iter: 0; batch classifier loss: 0.357082; batch adversarial loss: 0.509831\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307756; batch adversarial loss: 0.553410\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357451; batch adversarial loss: 0.499577\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350609; batch adversarial loss: 0.570717\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349462; batch adversarial loss: 0.581891\n",
      "epoch 164; iter: 0; batch classifier loss: 0.287171; batch adversarial loss: 0.554306\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361142; batch adversarial loss: 0.545335\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372835; batch adversarial loss: 0.563078\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407631; batch adversarial loss: 0.527533\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401831; batch adversarial loss: 0.553533\n",
      "epoch 169; iter: 0; batch classifier loss: 0.463878; batch adversarial loss: 0.499191\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345849; batch adversarial loss: 0.527377\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332982; batch adversarial loss: 0.546115\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342129; batch adversarial loss: 0.607473\n",
      "epoch 173; iter: 0; batch classifier loss: 0.440522; batch adversarial loss: 0.526338\n",
      "epoch 174; iter: 0; batch classifier loss: 0.416980; batch adversarial loss: 0.545744\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360093; batch adversarial loss: 0.571477\n",
      "epoch 176; iter: 0; batch classifier loss: 0.261672; batch adversarial loss: 0.543475\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392582; batch adversarial loss: 0.591401\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323465; batch adversarial loss: 0.642758\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394016; batch adversarial loss: 0.527501\n",
      "epoch 180; iter: 0; batch classifier loss: 0.348949; batch adversarial loss: 0.544149\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370630; batch adversarial loss: 0.608084\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378829; batch adversarial loss: 0.551826\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385466; batch adversarial loss: 0.562354\n",
      "epoch 184; iter: 0; batch classifier loss: 0.434953; batch adversarial loss: 0.491506\n",
      "epoch 185; iter: 0; batch classifier loss: 0.317803; batch adversarial loss: 0.624535\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330896; batch adversarial loss: 0.515993\n",
      "epoch 187; iter: 0; batch classifier loss: 0.381513; batch adversarial loss: 0.561323\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330570; batch adversarial loss: 0.583472\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351768; batch adversarial loss: 0.615908\n",
      "epoch 190; iter: 0; batch classifier loss: 0.294597; batch adversarial loss: 0.607141\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380130; batch adversarial loss: 0.537660\n",
      "epoch 192; iter: 0; batch classifier loss: 0.268547; batch adversarial loss: 0.562070\n",
      "epoch 193; iter: 0; batch classifier loss: 0.303287; batch adversarial loss: 0.572012\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335347; batch adversarial loss: 0.608627\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334324; batch adversarial loss: 0.508352\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357328; batch adversarial loss: 0.553885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372936; batch adversarial loss: 0.462476\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370460; batch adversarial loss: 0.571485\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348218; batch adversarial loss: 0.615033\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670242; batch adversarial loss: 0.629500\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551470; batch adversarial loss: 0.625924\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567748; batch adversarial loss: 0.610233\n",
      "epoch 3; iter: 0; batch classifier loss: 0.608127; batch adversarial loss: 0.629604\n",
      "epoch 4; iter: 0; batch classifier loss: 0.494824; batch adversarial loss: 0.613783\n",
      "epoch 5; iter: 0; batch classifier loss: 0.610357; batch adversarial loss: 0.583389\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565063; batch adversarial loss: 0.617346\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517523; batch adversarial loss: 0.603851\n",
      "epoch 8; iter: 0; batch classifier loss: 0.648247; batch adversarial loss: 0.653602\n",
      "epoch 9; iter: 0; batch classifier loss: 0.469951; batch adversarial loss: 0.571311\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588009; batch adversarial loss: 0.560772\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579493; batch adversarial loss: 0.679242\n",
      "epoch 12; iter: 0; batch classifier loss: 0.593006; batch adversarial loss: 0.624787\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517094; batch adversarial loss: 0.576255\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573790; batch adversarial loss: 0.541176\n",
      "epoch 15; iter: 0; batch classifier loss: 0.421942; batch adversarial loss: 0.504987\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528211; batch adversarial loss: 0.641145\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535805; batch adversarial loss: 0.679401\n",
      "epoch 18; iter: 0; batch classifier loss: 0.435830; batch adversarial loss: 0.549839\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473199; batch adversarial loss: 0.575261\n",
      "epoch 20; iter: 0; batch classifier loss: 0.568341; batch adversarial loss: 0.514480\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460365; batch adversarial loss: 0.501059\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459278; batch adversarial loss: 0.602937\n",
      "epoch 23; iter: 0; batch classifier loss: 0.385796; batch adversarial loss: 0.559848\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495969; batch adversarial loss: 0.628508\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508652; batch adversarial loss: 0.548064\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456049; batch adversarial loss: 0.561788\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449165; batch adversarial loss: 0.615520\n",
      "epoch 28; iter: 0; batch classifier loss: 0.403578; batch adversarial loss: 0.545786\n",
      "epoch 29; iter: 0; batch classifier loss: 0.562148; batch adversarial loss: 0.571737\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435222; batch adversarial loss: 0.537050\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416615; batch adversarial loss: 0.579513\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419016; batch adversarial loss: 0.570768\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424236; batch adversarial loss: 0.606458\n",
      "epoch 34; iter: 0; batch classifier loss: 0.507558; batch adversarial loss: 0.607380\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468675; batch adversarial loss: 0.572351\n",
      "epoch 36; iter: 0; batch classifier loss: 0.393331; batch adversarial loss: 0.579959\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392935; batch adversarial loss: 0.599135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440991; batch adversarial loss: 0.589981\n",
      "epoch 39; iter: 0; batch classifier loss: 0.509334; batch adversarial loss: 0.535328\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421133; batch adversarial loss: 0.499615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422562; batch adversarial loss: 0.599030\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439945; batch adversarial loss: 0.562933\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469721; batch adversarial loss: 0.489468\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396779; batch adversarial loss: 0.535061\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437876; batch adversarial loss: 0.498251\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403020; batch adversarial loss: 0.490891\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453163; batch adversarial loss: 0.599136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381170; batch adversarial loss: 0.571882\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457416; batch adversarial loss: 0.598966\n",
      "epoch 50; iter: 0; batch classifier loss: 0.505776; batch adversarial loss: 0.499308\n",
      "epoch 51; iter: 0; batch classifier loss: 0.500656; batch adversarial loss: 0.535875\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445027; batch adversarial loss: 0.500030\n",
      "epoch 53; iter: 0; batch classifier loss: 0.525281; batch adversarial loss: 0.507370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.402891; batch adversarial loss: 0.534681\n",
      "epoch 55; iter: 0; batch classifier loss: 0.488453; batch adversarial loss: 0.572781\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366248; batch adversarial loss: 0.580987\n",
      "epoch 57; iter: 0; batch classifier loss: 0.479575; batch adversarial loss: 0.480032\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425729; batch adversarial loss: 0.571421\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374299; batch adversarial loss: 0.479298\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441973; batch adversarial loss: 0.553271\n",
      "epoch 61; iter: 0; batch classifier loss: 0.393100; batch adversarial loss: 0.481176\n",
      "epoch 62; iter: 0; batch classifier loss: 0.338250; batch adversarial loss: 0.599860\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406460; batch adversarial loss: 0.544309\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466502; batch adversarial loss: 0.507321\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380328; batch adversarial loss: 0.618422\n",
      "epoch 66; iter: 0; batch classifier loss: 0.479489; batch adversarial loss: 0.543447\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398427; batch adversarial loss: 0.553906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383402; batch adversarial loss: 0.572073\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360478; batch adversarial loss: 0.526138\n",
      "epoch 70; iter: 0; batch classifier loss: 0.360541; batch adversarial loss: 0.535551\n",
      "epoch 71; iter: 0; batch classifier loss: 0.401997; batch adversarial loss: 0.552752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430616; batch adversarial loss: 0.599717\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410878; batch adversarial loss: 0.561782\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415084; batch adversarial loss: 0.564317\n",
      "epoch 75; iter: 0; batch classifier loss: 0.361677; batch adversarial loss: 0.626277\n",
      "epoch 76; iter: 0; batch classifier loss: 0.444391; batch adversarial loss: 0.518787\n",
      "epoch 77; iter: 0; batch classifier loss: 0.466115; batch adversarial loss: 0.590918\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444871; batch adversarial loss: 0.527207\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390914; batch adversarial loss: 0.497415\n",
      "epoch 80; iter: 0; batch classifier loss: 0.397668; batch adversarial loss: 0.582511\n",
      "epoch 81; iter: 0; batch classifier loss: 0.350529; batch adversarial loss: 0.572397\n",
      "epoch 82; iter: 0; batch classifier loss: 0.431715; batch adversarial loss: 0.535857\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370047; batch adversarial loss: 0.617542\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404018; batch adversarial loss: 0.480117\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361388; batch adversarial loss: 0.581095\n",
      "epoch 86; iter: 0; batch classifier loss: 0.375698; batch adversarial loss: 0.563312\n",
      "epoch 87; iter: 0; batch classifier loss: 0.339556; batch adversarial loss: 0.497663\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382093; batch adversarial loss: 0.572306\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428569; batch adversarial loss: 0.553955\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394375; batch adversarial loss: 0.461311\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381304; batch adversarial loss: 0.554047\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372093; batch adversarial loss: 0.645318\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375665; batch adversarial loss: 0.609025\n",
      "epoch 94; iter: 0; batch classifier loss: 0.461282; batch adversarial loss: 0.527865\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396355; batch adversarial loss: 0.518390\n",
      "epoch 96; iter: 0; batch classifier loss: 0.440663; batch adversarial loss: 0.516132\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404668; batch adversarial loss: 0.553051\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438605; batch adversarial loss: 0.562444\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364618; batch adversarial loss: 0.463829\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398437; batch adversarial loss: 0.516538\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387005; batch adversarial loss: 0.525964\n",
      "epoch 102; iter: 0; batch classifier loss: 0.485599; batch adversarial loss: 0.664432\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362778; batch adversarial loss: 0.526273\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361579; batch adversarial loss: 0.525806\n",
      "epoch 105; iter: 0; batch classifier loss: 0.443983; batch adversarial loss: 0.582227\n",
      "epoch 106; iter: 0; batch classifier loss: 0.429836; batch adversarial loss: 0.563511\n",
      "epoch 107; iter: 0; batch classifier loss: 0.287690; batch adversarial loss: 0.507260\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348128; batch adversarial loss: 0.470268\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359228; batch adversarial loss: 0.553811\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.628140\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378508; batch adversarial loss: 0.627350\n",
      "epoch 112; iter: 0; batch classifier loss: 0.454901; batch adversarial loss: 0.544960\n",
      "epoch 113; iter: 0; batch classifier loss: 0.442590; batch adversarial loss: 0.647813\n",
      "epoch 114; iter: 0; batch classifier loss: 0.314442; batch adversarial loss: 0.579561\n",
      "epoch 115; iter: 0; batch classifier loss: 0.361208; batch adversarial loss: 0.534206\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371323; batch adversarial loss: 0.611531\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383577; batch adversarial loss: 0.522248\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362449; batch adversarial loss: 0.525133\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404430; batch adversarial loss: 0.528661\n",
      "epoch 120; iter: 0; batch classifier loss: 0.486263; batch adversarial loss: 0.501381\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412514; batch adversarial loss: 0.538657\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366920; batch adversarial loss: 0.508036\n",
      "epoch 123; iter: 0; batch classifier loss: 0.467784; batch adversarial loss: 0.498338\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397742; batch adversarial loss: 0.490377\n",
      "epoch 125; iter: 0; batch classifier loss: 0.347302; batch adversarial loss: 0.499428\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374874; batch adversarial loss: 0.580793\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389642; batch adversarial loss: 0.517521\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373852; batch adversarial loss: 0.608124\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334559; batch adversarial loss: 0.589950\n",
      "epoch 130; iter: 0; batch classifier loss: 0.327211; batch adversarial loss: 0.498532\n",
      "epoch 131; iter: 0; batch classifier loss: 0.308835; batch adversarial loss: 0.471119\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357856; batch adversarial loss: 0.405834\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324947; batch adversarial loss: 0.599464\n",
      "epoch 134; iter: 0; batch classifier loss: 0.444290; batch adversarial loss: 0.508297\n",
      "epoch 135; iter: 0; batch classifier loss: 0.398586; batch adversarial loss: 0.461345\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370363; batch adversarial loss: 0.572226\n",
      "epoch 137; iter: 0; batch classifier loss: 0.435846; batch adversarial loss: 0.600534\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382925; batch adversarial loss: 0.581342\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407920; batch adversarial loss: 0.553511\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390354; batch adversarial loss: 0.498618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423851; batch adversarial loss: 0.526977\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420368; batch adversarial loss: 0.516812\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364489; batch adversarial loss: 0.470950\n",
      "epoch 144; iter: 0; batch classifier loss: 0.387082; batch adversarial loss: 0.516874\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375749; batch adversarial loss: 0.571915\n",
      "epoch 146; iter: 0; batch classifier loss: 0.302114; batch adversarial loss: 0.544322\n",
      "epoch 147; iter: 0; batch classifier loss: 0.380335; batch adversarial loss: 0.534652\n",
      "epoch 148; iter: 0; batch classifier loss: 0.421747; batch adversarial loss: 0.517308\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322062; batch adversarial loss: 0.608660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.392927; batch adversarial loss: 0.516772\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395377; batch adversarial loss: 0.479521\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379380; batch adversarial loss: 0.553912\n",
      "epoch 153; iter: 0; batch classifier loss: 0.292587; batch adversarial loss: 0.627969\n",
      "epoch 154; iter: 0; batch classifier loss: 0.426846; batch adversarial loss: 0.553389\n",
      "epoch 155; iter: 0; batch classifier loss: 0.305043; batch adversarial loss: 0.581742\n",
      "epoch 156; iter: 0; batch classifier loss: 0.389531; batch adversarial loss: 0.580978\n",
      "epoch 157; iter: 0; batch classifier loss: 0.440973; batch adversarial loss: 0.508008\n",
      "epoch 158; iter: 0; batch classifier loss: 0.459243; batch adversarial loss: 0.535216\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359378; batch adversarial loss: 0.581540\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353605; batch adversarial loss: 0.526181\n",
      "epoch 161; iter: 0; batch classifier loss: 0.396033; batch adversarial loss: 0.462048\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306352; batch adversarial loss: 0.644648\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321051; batch adversarial loss: 0.609007\n",
      "epoch 164; iter: 0; batch classifier loss: 0.319196; batch adversarial loss: 0.535024\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349076; batch adversarial loss: 0.526430\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321586; batch adversarial loss: 0.489702\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347302; batch adversarial loss: 0.498105\n",
      "epoch 168; iter: 0; batch classifier loss: 0.442570; batch adversarial loss: 0.590342\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384864; batch adversarial loss: 0.562522\n",
      "epoch 170; iter: 0; batch classifier loss: 0.474802; batch adversarial loss: 0.553662\n",
      "epoch 171; iter: 0; batch classifier loss: 0.450161; batch adversarial loss: 0.507225\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384622; batch adversarial loss: 0.627693\n",
      "epoch 173; iter: 0; batch classifier loss: 0.317978; batch adversarial loss: 0.480409\n",
      "epoch 174; iter: 0; batch classifier loss: 0.401335; batch adversarial loss: 0.626796\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346160; batch adversarial loss: 0.516518\n",
      "epoch 176; iter: 0; batch classifier loss: 0.337777; batch adversarial loss: 0.580799\n",
      "epoch 177; iter: 0; batch classifier loss: 0.419647; batch adversarial loss: 0.599190\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343215; batch adversarial loss: 0.552414\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356627; batch adversarial loss: 0.619018\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383191; batch adversarial loss: 0.553126\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397051; batch adversarial loss: 0.563563\n",
      "epoch 182; iter: 0; batch classifier loss: 0.400517; batch adversarial loss: 0.581304\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376394; batch adversarial loss: 0.563571\n",
      "epoch 184; iter: 0; batch classifier loss: 0.427824; batch adversarial loss: 0.507085\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354264; batch adversarial loss: 0.581593\n",
      "epoch 186; iter: 0; batch classifier loss: 0.426695; batch adversarial loss: 0.609007\n",
      "epoch 187; iter: 0; batch classifier loss: 0.337658; batch adversarial loss: 0.508139\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356029; batch adversarial loss: 0.554767\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336066; batch adversarial loss: 0.552693\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385067; batch adversarial loss: 0.581778\n",
      "epoch 191; iter: 0; batch classifier loss: 0.407981; batch adversarial loss: 0.489319\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365391; batch adversarial loss: 0.470859\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361132; batch adversarial loss: 0.534905\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404971; batch adversarial loss: 0.618561\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347852; batch adversarial loss: 0.571841\n",
      "epoch 196; iter: 0; batch classifier loss: 0.406161; batch adversarial loss: 0.562765\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407130; batch adversarial loss: 0.572546\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371811; batch adversarial loss: 0.544603\n",
      "epoch 199; iter: 0; batch classifier loss: 0.444271; batch adversarial loss: 0.591190\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696795; batch adversarial loss: 0.672611\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596334; batch adversarial loss: 0.648070\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527850; batch adversarial loss: 0.651168\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550466; batch adversarial loss: 0.638215\n",
      "epoch 4; iter: 0; batch classifier loss: 0.481827; batch adversarial loss: 0.580006\n",
      "epoch 5; iter: 0; batch classifier loss: 0.503411; batch adversarial loss: 0.607727\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596894; batch adversarial loss: 0.587576\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546231; batch adversarial loss: 0.634521\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515016; batch adversarial loss: 0.597985\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472746; batch adversarial loss: 0.570910\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521686; batch adversarial loss: 0.593546\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566184; batch adversarial loss: 0.663031\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549682; batch adversarial loss: 0.606571\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476250; batch adversarial loss: 0.568298\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487679; batch adversarial loss: 0.637255\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490367; batch adversarial loss: 0.574150\n",
      "epoch 16; iter: 0; batch classifier loss: 0.589907; batch adversarial loss: 0.613857\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506458; batch adversarial loss: 0.607745\n",
      "epoch 18; iter: 0; batch classifier loss: 0.554241; batch adversarial loss: 0.637162\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545989; batch adversarial loss: 0.604673\n",
      "epoch 20; iter: 0; batch classifier loss: 0.560016; batch adversarial loss: 0.562332\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520418; batch adversarial loss: 0.609871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494588; batch adversarial loss: 0.591941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484564; batch adversarial loss: 0.581308\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426067; batch adversarial loss: 0.556535\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506619; batch adversarial loss: 0.530108\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425359; batch adversarial loss: 0.538642\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529193; batch adversarial loss: 0.637878\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402027; batch adversarial loss: 0.603271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500245; batch adversarial loss: 0.547926\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442097; batch adversarial loss: 0.583012\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474162; batch adversarial loss: 0.518241\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427034; batch adversarial loss: 0.548702\n",
      "epoch 33; iter: 0; batch classifier loss: 0.513980; batch adversarial loss: 0.537758\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461965; batch adversarial loss: 0.519973\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466295; batch adversarial loss: 0.537540\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421602; batch adversarial loss: 0.519463\n",
      "epoch 37; iter: 0; batch classifier loss: 0.413909; batch adversarial loss: 0.519509\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505698; batch adversarial loss: 0.536199\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470964; batch adversarial loss: 0.536442\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490545; batch adversarial loss: 0.509784\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404903; batch adversarial loss: 0.535751\n",
      "epoch 42; iter: 0; batch classifier loss: 0.397835; batch adversarial loss: 0.553800\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419459; batch adversarial loss: 0.650365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426513; batch adversarial loss: 0.509503\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460784; batch adversarial loss: 0.509607\n",
      "epoch 46; iter: 0; batch classifier loss: 0.512114; batch adversarial loss: 0.527059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.470797; batch adversarial loss: 0.553266\n",
      "epoch 48; iter: 0; batch classifier loss: 0.518112; batch adversarial loss: 0.544077\n",
      "epoch 49; iter: 0; batch classifier loss: 0.370390; batch adversarial loss: 0.580839\n",
      "epoch 50; iter: 0; batch classifier loss: 0.444668; batch adversarial loss: 0.572078\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399116; batch adversarial loss: 0.535853\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380412; batch adversarial loss: 0.500201\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439774; batch adversarial loss: 0.481042\n",
      "epoch 54; iter: 0; batch classifier loss: 0.482603; batch adversarial loss: 0.542930\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405975; batch adversarial loss: 0.598000\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448917; batch adversarial loss: 0.580015\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475950; batch adversarial loss: 0.600001\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380280; batch adversarial loss: 0.552721\n",
      "epoch 59; iter: 0; batch classifier loss: 0.492529; batch adversarial loss: 0.534110\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431472; batch adversarial loss: 0.498422\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385767; batch adversarial loss: 0.579919\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443575; batch adversarial loss: 0.535738\n",
      "epoch 63; iter: 0; batch classifier loss: 0.451474; batch adversarial loss: 0.509408\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414783; batch adversarial loss: 0.509736\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451927; batch adversarial loss: 0.589596\n",
      "epoch 66; iter: 0; batch classifier loss: 0.478609; batch adversarial loss: 0.526009\n",
      "epoch 67; iter: 0; batch classifier loss: 0.462245; batch adversarial loss: 0.552766\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394345; batch adversarial loss: 0.570455\n",
      "epoch 69; iter: 0; batch classifier loss: 0.469110; batch adversarial loss: 0.551631\n",
      "epoch 70; iter: 0; batch classifier loss: 0.457442; batch adversarial loss: 0.553560\n",
      "epoch 71; iter: 0; batch classifier loss: 0.467439; batch adversarial loss: 0.570626\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419358; batch adversarial loss: 0.517063\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386576; batch adversarial loss: 0.514860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378860; batch adversarial loss: 0.517982\n",
      "epoch 75; iter: 0; batch classifier loss: 0.335023; batch adversarial loss: 0.519120\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415375; batch adversarial loss: 0.579940\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372877; batch adversarial loss: 0.508080\n",
      "epoch 78; iter: 0; batch classifier loss: 0.432086; batch adversarial loss: 0.580504\n",
      "epoch 79; iter: 0; batch classifier loss: 0.290937; batch adversarial loss: 0.591344\n",
      "epoch 80; iter: 0; batch classifier loss: 0.341932; batch adversarial loss: 0.571784\n",
      "epoch 81; iter: 0; batch classifier loss: 0.331881; batch adversarial loss: 0.536013\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374484; batch adversarial loss: 0.587905\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392583; batch adversarial loss: 0.500822\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390269; batch adversarial loss: 0.624019\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406977; batch adversarial loss: 0.500083\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418447; batch adversarial loss: 0.580371\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420011; batch adversarial loss: 0.562082\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416148; batch adversarial loss: 0.491215\n",
      "epoch 89; iter: 0; batch classifier loss: 0.453662; batch adversarial loss: 0.570617\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378134; batch adversarial loss: 0.544461\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385673; batch adversarial loss: 0.626014\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368511; batch adversarial loss: 0.589774\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455209; batch adversarial loss: 0.606077\n",
      "epoch 94; iter: 0; batch classifier loss: 0.454425; batch adversarial loss: 0.474401\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409498; batch adversarial loss: 0.580288\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389479; batch adversarial loss: 0.544409\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437571; batch adversarial loss: 0.509380\n",
      "epoch 98; iter: 0; batch classifier loss: 0.353276; batch adversarial loss: 0.553987\n",
      "epoch 99; iter: 0; batch classifier loss: 0.432813; batch adversarial loss: 0.561967\n",
      "epoch 100; iter: 0; batch classifier loss: 0.476479; batch adversarial loss: 0.544528\n",
      "epoch 101; iter: 0; batch classifier loss: 0.327075; batch adversarial loss: 0.609264\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427969; batch adversarial loss: 0.545074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409588; batch adversarial loss: 0.535117\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368108; batch adversarial loss: 0.590087\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442118; batch adversarial loss: 0.553621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345740; batch adversarial loss: 0.471114\n",
      "epoch 107; iter: 0; batch classifier loss: 0.327478; batch adversarial loss: 0.662393\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373277; batch adversarial loss: 0.553844\n",
      "epoch 109; iter: 0; batch classifier loss: 0.378662; batch adversarial loss: 0.554945\n",
      "epoch 110; iter: 0; batch classifier loss: 0.341445; batch adversarial loss: 0.598855\n",
      "epoch 111; iter: 0; batch classifier loss: 0.341772; batch adversarial loss: 0.517848\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370401; batch adversarial loss: 0.562445\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413381; batch adversarial loss: 0.535861\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412716; batch adversarial loss: 0.535646\n",
      "epoch 115; iter: 0; batch classifier loss: 0.424764; batch adversarial loss: 0.570937\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357895; batch adversarial loss: 0.517872\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340579; batch adversarial loss: 0.580983\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341381; batch adversarial loss: 0.588956\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339891; batch adversarial loss: 0.517902\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348658; batch adversarial loss: 0.651038\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346070; batch adversarial loss: 0.481817\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358614; batch adversarial loss: 0.553477\n",
      "epoch 123; iter: 0; batch classifier loss: 0.441699; batch adversarial loss: 0.615110\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390510; batch adversarial loss: 0.490551\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342798; batch adversarial loss: 0.553094\n",
      "epoch 126; iter: 0; batch classifier loss: 0.471838; batch adversarial loss: 0.536295\n",
      "epoch 127; iter: 0; batch classifier loss: 0.319921; batch adversarial loss: 0.563439\n",
      "epoch 128; iter: 0; batch classifier loss: 0.492860; batch adversarial loss: 0.517153\n",
      "epoch 129; iter: 0; batch classifier loss: 0.450342; batch adversarial loss: 0.608467\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397311; batch adversarial loss: 0.617027\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368348; batch adversarial loss: 0.570896\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358120; batch adversarial loss: 0.598812\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397013; batch adversarial loss: 0.561563\n",
      "epoch 134; iter: 0; batch classifier loss: 0.342219; batch adversarial loss: 0.535335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362602; batch adversarial loss: 0.544656\n",
      "epoch 136; iter: 0; batch classifier loss: 0.458083; batch adversarial loss: 0.546365\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332826; batch adversarial loss: 0.589117\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333751; batch adversarial loss: 0.598054\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334089; batch adversarial loss: 0.517533\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375641; batch adversarial loss: 0.608853\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329886; batch adversarial loss: 0.489600\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335272; batch adversarial loss: 0.517572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.298695; batch adversarial loss: 0.553849\n",
      "epoch 144; iter: 0; batch classifier loss: 0.330588; batch adversarial loss: 0.480641\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399801; batch adversarial loss: 0.480909\n",
      "epoch 146; iter: 0; batch classifier loss: 0.390923; batch adversarial loss: 0.607895\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390227; batch adversarial loss: 0.581376\n",
      "epoch 148; iter: 0; batch classifier loss: 0.284070; batch adversarial loss: 0.553753\n",
      "epoch 149; iter: 0; batch classifier loss: 0.403122; batch adversarial loss: 0.472643\n",
      "epoch 150; iter: 0; batch classifier loss: 0.437958; batch adversarial loss: 0.571149\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405722; batch adversarial loss: 0.544989\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355122; batch adversarial loss: 0.562570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.310089; batch adversarial loss: 0.499461\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359268; batch adversarial loss: 0.553236\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340650; batch adversarial loss: 0.634596\n",
      "epoch 156; iter: 0; batch classifier loss: 0.310918; batch adversarial loss: 0.572214\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364035; batch adversarial loss: 0.589905\n",
      "epoch 158; iter: 0; batch classifier loss: 0.419347; batch adversarial loss: 0.508958\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363315; batch adversarial loss: 0.562446\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337511; batch adversarial loss: 0.517575\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341054; batch adversarial loss: 0.490791\n",
      "epoch 162; iter: 0; batch classifier loss: 0.322553; batch adversarial loss: 0.571405\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364466; batch adversarial loss: 0.491227\n",
      "epoch 164; iter: 0; batch classifier loss: 0.438484; batch adversarial loss: 0.482344\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318392; batch adversarial loss: 0.616552\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365987; batch adversarial loss: 0.535212\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344701; batch adversarial loss: 0.589336\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331236; batch adversarial loss: 0.544753\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403710; batch adversarial loss: 0.472713\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365601; batch adversarial loss: 0.598544\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321739; batch adversarial loss: 0.535375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372060; batch adversarial loss: 0.562293\n",
      "epoch 173; iter: 0; batch classifier loss: 0.303761; batch adversarial loss: 0.571474\n",
      "epoch 174; iter: 0; batch classifier loss: 0.266135; batch adversarial loss: 0.490582\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337557; batch adversarial loss: 0.625456\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388679; batch adversarial loss: 0.589548\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378080; batch adversarial loss: 0.535182\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361822; batch adversarial loss: 0.589571\n",
      "epoch 179; iter: 0; batch classifier loss: 0.396556; batch adversarial loss: 0.581091\n",
      "epoch 180; iter: 0; batch classifier loss: 0.478001; batch adversarial loss: 0.562429\n",
      "epoch 181; iter: 0; batch classifier loss: 0.309363; batch adversarial loss: 0.607426\n",
      "epoch 182; iter: 0; batch classifier loss: 0.398840; batch adversarial loss: 0.517694\n",
      "epoch 183; iter: 0; batch classifier loss: 0.368500; batch adversarial loss: 0.535861\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374674; batch adversarial loss: 0.553760\n",
      "epoch 185; iter: 0; batch classifier loss: 0.406913; batch adversarial loss: 0.553565\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324872; batch adversarial loss: 0.616383\n",
      "epoch 187; iter: 0; batch classifier loss: 0.295963; batch adversarial loss: 0.526722\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371722; batch adversarial loss: 0.517670\n",
      "epoch 189; iter: 0; batch classifier loss: 0.307866; batch adversarial loss: 0.553258\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386957; batch adversarial loss: 0.535628\n",
      "epoch 191; iter: 0; batch classifier loss: 0.239218; batch adversarial loss: 0.544721\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329990; batch adversarial loss: 0.607286\n",
      "epoch 193; iter: 0; batch classifier loss: 0.346061; batch adversarial loss: 0.526848\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399287; batch adversarial loss: 0.554101\n",
      "epoch 195; iter: 0; batch classifier loss: 0.378820; batch adversarial loss: 0.579972\n",
      "epoch 196; iter: 0; batch classifier loss: 0.429931; batch adversarial loss: 0.652742\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348734; batch adversarial loss: 0.607230\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359000; batch adversarial loss: 0.607339\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364308; batch adversarial loss: 0.553558\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713153; batch adversarial loss: 0.582841\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608703; batch adversarial loss: 0.644377\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615610; batch adversarial loss: 0.678707\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577212; batch adversarial loss: 0.682866\n",
      "epoch 4; iter: 0; batch classifier loss: 0.512102; batch adversarial loss: 0.632264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572266; batch adversarial loss: 0.678248\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561784; batch adversarial loss: 0.635738\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556693; batch adversarial loss: 0.628529\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559972; batch adversarial loss: 0.602785\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578090; batch adversarial loss: 0.563144\n",
      "epoch 10; iter: 0; batch classifier loss: 0.530688; batch adversarial loss: 0.601175\n",
      "epoch 11; iter: 0; batch classifier loss: 0.589941; batch adversarial loss: 0.583763\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484478; batch adversarial loss: 0.574650\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518158; batch adversarial loss: 0.558513\n",
      "epoch 14; iter: 0; batch classifier loss: 0.441388; batch adversarial loss: 0.546960\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498476; batch adversarial loss: 0.584932\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513522; batch adversarial loss: 0.570926\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481480; batch adversarial loss: 0.574555\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532649; batch adversarial loss: 0.611347\n",
      "epoch 19; iter: 0; batch classifier loss: 0.467319; batch adversarial loss: 0.555429\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488252; batch adversarial loss: 0.549174\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468207; batch adversarial loss: 0.534180\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462964; batch adversarial loss: 0.513234\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465130; batch adversarial loss: 0.578833\n",
      "epoch 24; iter: 0; batch classifier loss: 0.540515; batch adversarial loss: 0.564597\n",
      "epoch 25; iter: 0; batch classifier loss: 0.445892; batch adversarial loss: 0.558416\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457306; batch adversarial loss: 0.537154\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458138; batch adversarial loss: 0.563561\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492236; batch adversarial loss: 0.537623\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425972; batch adversarial loss: 0.562369\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452634; batch adversarial loss: 0.477688\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491386; batch adversarial loss: 0.501171\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449178; batch adversarial loss: 0.552653\n",
      "epoch 33; iter: 0; batch classifier loss: 0.359701; batch adversarial loss: 0.543683\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464674; batch adversarial loss: 0.517646\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474644; batch adversarial loss: 0.482213\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379462; batch adversarial loss: 0.582520\n",
      "epoch 37; iter: 0; batch classifier loss: 0.492760; batch adversarial loss: 0.537012\n",
      "epoch 38; iter: 0; batch classifier loss: 0.503603; batch adversarial loss: 0.562897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.448623; batch adversarial loss: 0.507498\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417523; batch adversarial loss: 0.604645\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441499; batch adversarial loss: 0.560070\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482076; batch adversarial loss: 0.489287\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450363; batch adversarial loss: 0.509652\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463463; batch adversarial loss: 0.535596\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397702; batch adversarial loss: 0.597543\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441877; batch adversarial loss: 0.536342\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420044; batch adversarial loss: 0.558834\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446844; batch adversarial loss: 0.534632\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476591; batch adversarial loss: 0.563062\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414212; batch adversarial loss: 0.526961\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430536; batch adversarial loss: 0.517660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420657; batch adversarial loss: 0.551381\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442247; batch adversarial loss: 0.560015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.396032; batch adversarial loss: 0.546632\n",
      "epoch 55; iter: 0; batch classifier loss: 0.470589; batch adversarial loss: 0.643681\n",
      "epoch 56; iter: 0; batch classifier loss: 0.471762; batch adversarial loss: 0.487144\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399016; batch adversarial loss: 0.607534\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407010; batch adversarial loss: 0.563077\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414136; batch adversarial loss: 0.572652\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376629; batch adversarial loss: 0.547785\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447367; batch adversarial loss: 0.551354\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394814; batch adversarial loss: 0.489965\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433091; batch adversarial loss: 0.525915\n",
      "epoch 64; iter: 0; batch classifier loss: 0.396875; batch adversarial loss: 0.510024\n",
      "epoch 65; iter: 0; batch classifier loss: 0.345228; batch adversarial loss: 0.525381\n",
      "epoch 66; iter: 0; batch classifier loss: 0.393486; batch adversarial loss: 0.597798\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431353; batch adversarial loss: 0.526264\n",
      "epoch 68; iter: 0; batch classifier loss: 0.337846; batch adversarial loss: 0.489514\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448626; batch adversarial loss: 0.508809\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437519; batch adversarial loss: 0.591702\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419290; batch adversarial loss: 0.606620\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410861; batch adversarial loss: 0.472233\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438400; batch adversarial loss: 0.667607\n",
      "epoch 74; iter: 0; batch classifier loss: 0.369368; batch adversarial loss: 0.526371\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381957; batch adversarial loss: 0.561521\n",
      "epoch 76; iter: 0; batch classifier loss: 0.445204; batch adversarial loss: 0.523881\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372275; batch adversarial loss: 0.505418\n",
      "epoch 78; iter: 0; batch classifier loss: 0.334116; batch adversarial loss: 0.489372\n",
      "epoch 79; iter: 0; batch classifier loss: 0.441226; batch adversarial loss: 0.625616\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394626; batch adversarial loss: 0.554665\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369691; batch adversarial loss: 0.584957\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342814; batch adversarial loss: 0.536146\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341213; batch adversarial loss: 0.573008\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367397; batch adversarial loss: 0.611347\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416519; batch adversarial loss: 0.578882\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408055; batch adversarial loss: 0.606840\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366194; batch adversarial loss: 0.627957\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373286; batch adversarial loss: 0.596119\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409197; batch adversarial loss: 0.715813\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426456; batch adversarial loss: 0.589112\n",
      "epoch 91; iter: 0; batch classifier loss: 0.316256; batch adversarial loss: 0.550821\n",
      "epoch 92; iter: 0; batch classifier loss: 0.465114; batch adversarial loss: 0.615818\n",
      "epoch 93; iter: 0; batch classifier loss: 0.376306; batch adversarial loss: 0.517485\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375542; batch adversarial loss: 0.558047\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359945; batch adversarial loss: 0.535534\n",
      "epoch 96; iter: 0; batch classifier loss: 0.427761; batch adversarial loss: 0.572254\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422288; batch adversarial loss: 0.531952\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385548; batch adversarial loss: 0.570626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396916; batch adversarial loss: 0.510209\n",
      "epoch 100; iter: 0; batch classifier loss: 0.452203; batch adversarial loss: 0.564299\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370458; batch adversarial loss: 0.588977\n",
      "epoch 102; iter: 0; batch classifier loss: 0.514065; batch adversarial loss: 0.548928\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386010; batch adversarial loss: 0.470175\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383091; batch adversarial loss: 0.506832\n",
      "epoch 105; iter: 0; batch classifier loss: 0.334979; batch adversarial loss: 0.544968\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370515; batch adversarial loss: 0.506091\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436357; batch adversarial loss: 0.534285\n",
      "epoch 108; iter: 0; batch classifier loss: 0.347661; batch adversarial loss: 0.527818\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396377; batch adversarial loss: 0.600985\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368733; batch adversarial loss: 0.575696\n",
      "epoch 111; iter: 0; batch classifier loss: 0.446477; batch adversarial loss: 0.599214\n",
      "epoch 112; iter: 0; batch classifier loss: 0.437852; batch adversarial loss: 0.546697\n",
      "epoch 113; iter: 0; batch classifier loss: 0.434186; batch adversarial loss: 0.567761\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388073; batch adversarial loss: 0.553424\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356792; batch adversarial loss: 0.566302\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380016; batch adversarial loss: 0.507189\n",
      "epoch 117; iter: 0; batch classifier loss: 0.433067; batch adversarial loss: 0.424008\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366288; batch adversarial loss: 0.613718\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441943; batch adversarial loss: 0.565896\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398634; batch adversarial loss: 0.553993\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319376; batch adversarial loss: 0.560372\n",
      "epoch 122; iter: 0; batch classifier loss: 0.445180; batch adversarial loss: 0.570391\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388206; batch adversarial loss: 0.532889\n",
      "epoch 124; iter: 0; batch classifier loss: 0.300542; batch adversarial loss: 0.573147\n",
      "epoch 125; iter: 0; batch classifier loss: 0.324584; batch adversarial loss: 0.594447\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347428; batch adversarial loss: 0.554628\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365106; batch adversarial loss: 0.498303\n",
      "epoch 128; iter: 0; batch classifier loss: 0.440201; batch adversarial loss: 0.580846\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344803; batch adversarial loss: 0.593538\n",
      "epoch 130; iter: 0; batch classifier loss: 0.415257; batch adversarial loss: 0.583191\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396951; batch adversarial loss: 0.478791\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414617; batch adversarial loss: 0.525723\n",
      "epoch 133; iter: 0; batch classifier loss: 0.427648; batch adversarial loss: 0.536598\n",
      "epoch 134; iter: 0; batch classifier loss: 0.316775; batch adversarial loss: 0.598408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.376117; batch adversarial loss: 0.603243\n",
      "epoch 136; iter: 0; batch classifier loss: 0.350777; batch adversarial loss: 0.507950\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.576706\n",
      "epoch 138; iter: 0; batch classifier loss: 0.325493; batch adversarial loss: 0.578240\n",
      "epoch 139; iter: 0; batch classifier loss: 0.370518; batch adversarial loss: 0.562289\n",
      "epoch 140; iter: 0; batch classifier loss: 0.306107; batch adversarial loss: 0.463864\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389533; batch adversarial loss: 0.545052\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368858; batch adversarial loss: 0.528336\n",
      "epoch 143; iter: 0; batch classifier loss: 0.384400; batch adversarial loss: 0.544489\n",
      "epoch 144; iter: 0; batch classifier loss: 0.456410; batch adversarial loss: 0.562811\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382817; batch adversarial loss: 0.552821\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405008; batch adversarial loss: 0.565134\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327342; batch adversarial loss: 0.554841\n",
      "epoch 148; iter: 0; batch classifier loss: 0.423787; batch adversarial loss: 0.597658\n",
      "epoch 149; iter: 0; batch classifier loss: 0.386652; batch adversarial loss: 0.556244\n",
      "epoch 150; iter: 0; batch classifier loss: 0.484524; batch adversarial loss: 0.626386\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337933; batch adversarial loss: 0.578384\n",
      "epoch 152; iter: 0; batch classifier loss: 0.412010; batch adversarial loss: 0.588974\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370410; batch adversarial loss: 0.552889\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320187; batch adversarial loss: 0.510306\n",
      "epoch 155; iter: 0; batch classifier loss: 0.444942; batch adversarial loss: 0.489132\n",
      "epoch 156; iter: 0; batch classifier loss: 0.427257; batch adversarial loss: 0.462999\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331111; batch adversarial loss: 0.472198\n",
      "epoch 158; iter: 0; batch classifier loss: 0.324155; batch adversarial loss: 0.568546\n",
      "epoch 159; iter: 0; batch classifier loss: 0.306574; batch adversarial loss: 0.514682\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395254; batch adversarial loss: 0.502462\n",
      "epoch 161; iter: 0; batch classifier loss: 0.307802; batch adversarial loss: 0.544526\n",
      "epoch 162; iter: 0; batch classifier loss: 0.411263; batch adversarial loss: 0.587824\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363402; batch adversarial loss: 0.523653\n",
      "epoch 164; iter: 0; batch classifier loss: 0.406239; batch adversarial loss: 0.571697\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357957; batch adversarial loss: 0.589732\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350420; batch adversarial loss: 0.471356\n",
      "epoch 167; iter: 0; batch classifier loss: 0.263654; batch adversarial loss: 0.469360\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389896; batch adversarial loss: 0.585948\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339816; batch adversarial loss: 0.546286\n",
      "epoch 170; iter: 0; batch classifier loss: 0.338008; batch adversarial loss: 0.519672\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383288; batch adversarial loss: 0.497522\n",
      "epoch 172; iter: 0; batch classifier loss: 0.421655; batch adversarial loss: 0.482905\n",
      "epoch 173; iter: 0; batch classifier loss: 0.426928; batch adversarial loss: 0.562932\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393788; batch adversarial loss: 0.510085\n",
      "epoch 175; iter: 0; batch classifier loss: 0.206939; batch adversarial loss: 0.515564\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344642; batch adversarial loss: 0.582125\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371521; batch adversarial loss: 0.529540\n",
      "epoch 178; iter: 0; batch classifier loss: 0.402431; batch adversarial loss: 0.514022\n",
      "epoch 179; iter: 0; batch classifier loss: 0.325243; batch adversarial loss: 0.518810\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391544; batch adversarial loss: 0.491402\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395385; batch adversarial loss: 0.509979\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381842; batch adversarial loss: 0.631990\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323349; batch adversarial loss: 0.542902\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309119; batch adversarial loss: 0.642818\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332545; batch adversarial loss: 0.560983\n",
      "epoch 186; iter: 0; batch classifier loss: 0.394551; batch adversarial loss: 0.490575\n",
      "epoch 187; iter: 0; batch classifier loss: 0.318802; batch adversarial loss: 0.536325\n",
      "epoch 188; iter: 0; batch classifier loss: 0.398666; batch adversarial loss: 0.536993\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380453; batch adversarial loss: 0.521052\n",
      "epoch 190; iter: 0; batch classifier loss: 0.425794; batch adversarial loss: 0.526425\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340623; batch adversarial loss: 0.591545\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369388; batch adversarial loss: 0.509194\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382925; batch adversarial loss: 0.569809\n",
      "epoch 194; iter: 0; batch classifier loss: 0.270542; batch adversarial loss: 0.554234\n",
      "epoch 195; iter: 0; batch classifier loss: 0.367671; batch adversarial loss: 0.588394\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349142; batch adversarial loss: 0.532568\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322364; batch adversarial loss: 0.554901\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382937; batch adversarial loss: 0.497046\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335267; batch adversarial loss: 0.563675\n",
      "epoch 0; iter: 0; batch classifier loss: 0.636146; batch adversarial loss: 0.720114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.699104; batch adversarial loss: 0.738755\n",
      "epoch 2; iter: 0; batch classifier loss: 0.650561; batch adversarial loss: 0.670718\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570064; batch adversarial loss: 0.624486\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569114; batch adversarial loss: 0.631443\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588791; batch adversarial loss: 0.644535\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528370; batch adversarial loss: 0.592824\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550750; batch adversarial loss: 0.580692\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491043; batch adversarial loss: 0.610358\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572571; batch adversarial loss: 0.559097\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575546; batch adversarial loss: 0.607839\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535090; batch adversarial loss: 0.598964\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480989; batch adversarial loss: 0.582302\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570732; batch adversarial loss: 0.537020\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578618; batch adversarial loss: 0.566129\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514817; batch adversarial loss: 0.465832\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503289; batch adversarial loss: 0.534125\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513507; batch adversarial loss: 0.509600\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504750; batch adversarial loss: 0.589438\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490981; batch adversarial loss: 0.564418\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474373; batch adversarial loss: 0.509725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542387; batch adversarial loss: 0.574018\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478596; batch adversarial loss: 0.568631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.543830; batch adversarial loss: 0.560849\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476916; batch adversarial loss: 0.559664\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484005; batch adversarial loss: 0.616803\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497329; batch adversarial loss: 0.457016\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453819; batch adversarial loss: 0.517421\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486044; batch adversarial loss: 0.538535\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464146; batch adversarial loss: 0.535763\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514855; batch adversarial loss: 0.513503\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474023; batch adversarial loss: 0.599130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.493719; batch adversarial loss: 0.599232\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457544; batch adversarial loss: 0.592086\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479026; batch adversarial loss: 0.533314\n",
      "epoch 35; iter: 0; batch classifier loss: 0.509562; batch adversarial loss: 0.517056\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434076; batch adversarial loss: 0.505055\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452741; batch adversarial loss: 0.548731\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504555; batch adversarial loss: 0.519353\n",
      "epoch 39; iter: 0; batch classifier loss: 0.381645; batch adversarial loss: 0.513035\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400927; batch adversarial loss: 0.543701\n",
      "epoch 41; iter: 0; batch classifier loss: 0.533540; batch adversarial loss: 0.543302\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466117; batch adversarial loss: 0.530966\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406524; batch adversarial loss: 0.588243\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393686; batch adversarial loss: 0.573667\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440875; batch adversarial loss: 0.546195\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437476; batch adversarial loss: 0.562690\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484352; batch adversarial loss: 0.526559\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399626; batch adversarial loss: 0.571144\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462395; batch adversarial loss: 0.556009\n",
      "epoch 50; iter: 0; batch classifier loss: 0.495233; batch adversarial loss: 0.527079\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490531; batch adversarial loss: 0.509308\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461784; batch adversarial loss: 0.490766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421880; batch adversarial loss: 0.535498\n",
      "epoch 54; iter: 0; batch classifier loss: 0.479184; batch adversarial loss: 0.507692\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443895; batch adversarial loss: 0.562187\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429969; batch adversarial loss: 0.562551\n",
      "epoch 57; iter: 0; batch classifier loss: 0.469929; batch adversarial loss: 0.621675\n",
      "epoch 58; iter: 0; batch classifier loss: 0.492050; batch adversarial loss: 0.528161\n",
      "epoch 59; iter: 0; batch classifier loss: 0.350675; batch adversarial loss: 0.526462\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385697; batch adversarial loss: 0.593176\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399175; batch adversarial loss: 0.498065\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457776; batch adversarial loss: 0.534962\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404048; batch adversarial loss: 0.553798\n",
      "epoch 64; iter: 0; batch classifier loss: 0.526669; batch adversarial loss: 0.526186\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408918; batch adversarial loss: 0.553656\n",
      "epoch 66; iter: 0; batch classifier loss: 0.476863; batch adversarial loss: 0.544224\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387282; batch adversarial loss: 0.517243\n",
      "epoch 68; iter: 0; batch classifier loss: 0.349471; batch adversarial loss: 0.572111\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397548; batch adversarial loss: 0.526797\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430337; batch adversarial loss: 0.518839\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415671; batch adversarial loss: 0.518745\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435914; batch adversarial loss: 0.572093\n",
      "epoch 73; iter: 0; batch classifier loss: 0.354927; batch adversarial loss: 0.534549\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448368; batch adversarial loss: 0.610301\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387635; batch adversarial loss: 0.544860\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374758; batch adversarial loss: 0.488080\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362475; batch adversarial loss: 0.563055\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440857; batch adversarial loss: 0.535125\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424543; batch adversarial loss: 0.591926\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369245; batch adversarial loss: 0.600908\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370144; batch adversarial loss: 0.535711\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381501; batch adversarial loss: 0.573224\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395543; batch adversarial loss: 0.525900\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393063; batch adversarial loss: 0.423106\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398826; batch adversarial loss: 0.535493\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446181; batch adversarial loss: 0.601050\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368907; batch adversarial loss: 0.534982\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411340; batch adversarial loss: 0.573071\n",
      "epoch 89; iter: 0; batch classifier loss: 0.471385; batch adversarial loss: 0.581615\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444462; batch adversarial loss: 0.553376\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384511; batch adversarial loss: 0.525301\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387476; batch adversarial loss: 0.573129\n",
      "epoch 93; iter: 0; batch classifier loss: 0.505656; batch adversarial loss: 0.572975\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419301; batch adversarial loss: 0.562989\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398892; batch adversarial loss: 0.526146\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390773; batch adversarial loss: 0.507484\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405929; batch adversarial loss: 0.553738\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409959; batch adversarial loss: 0.572861\n",
      "epoch 99; iter: 0; batch classifier loss: 0.474064; batch adversarial loss: 0.544448\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358445; batch adversarial loss: 0.497589\n",
      "epoch 101; iter: 0; batch classifier loss: 0.495111; batch adversarial loss: 0.554010\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397401; batch adversarial loss: 0.553902\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350588; batch adversarial loss: 0.535042\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361785; batch adversarial loss: 0.525418\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432132; batch adversarial loss: 0.544383\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394143; batch adversarial loss: 0.554232\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372252; batch adversarial loss: 0.600752\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387353; batch adversarial loss: 0.535132\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402160; batch adversarial loss: 0.563289\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388272; batch adversarial loss: 0.497799\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400883; batch adversarial loss: 0.525913\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394028; batch adversarial loss: 0.562684\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383378; batch adversarial loss: 0.553438\n",
      "epoch 114; iter: 0; batch classifier loss: 0.427452; batch adversarial loss: 0.525362\n",
      "epoch 115; iter: 0; batch classifier loss: 0.443929; batch adversarial loss: 0.554658\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420460; batch adversarial loss: 0.450760\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338069; batch adversarial loss: 0.535374\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381366; batch adversarial loss: 0.544686\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389684; batch adversarial loss: 0.469655\n",
      "epoch 120; iter: 0; batch classifier loss: 0.464719; batch adversarial loss: 0.543404\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378880; batch adversarial loss: 0.572608\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379034; batch adversarial loss: 0.601003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329368; batch adversarial loss: 0.488910\n",
      "epoch 124; iter: 0; batch classifier loss: 0.446230; batch adversarial loss: 0.592650\n",
      "epoch 125; iter: 0; batch classifier loss: 0.352390; batch adversarial loss: 0.554032\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416267; batch adversarial loss: 0.461319\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349467; batch adversarial loss: 0.553757\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361997; batch adversarial loss: 0.534896\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434057; batch adversarial loss: 0.507298\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391904; batch adversarial loss: 0.525878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.499828; batch adversarial loss: 0.497735\n",
      "epoch 132; iter: 0; batch classifier loss: 0.438605; batch adversarial loss: 0.581754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.451115; batch adversarial loss: 0.535492\n",
      "epoch 134; iter: 0; batch classifier loss: 0.419665; batch adversarial loss: 0.516563\n",
      "epoch 135; iter: 0; batch classifier loss: 0.475977; batch adversarial loss: 0.544580\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387437; batch adversarial loss: 0.525745\n",
      "epoch 137; iter: 0; batch classifier loss: 0.460299; batch adversarial loss: 0.534788\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392187; batch adversarial loss: 0.487882\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343484; batch adversarial loss: 0.600725\n",
      "epoch 140; iter: 0; batch classifier loss: 0.326587; batch adversarial loss: 0.505674\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381916; batch adversarial loss: 0.525328\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353928; batch adversarial loss: 0.591587\n",
      "epoch 143; iter: 0; batch classifier loss: 0.343563; batch adversarial loss: 0.498291\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347929; batch adversarial loss: 0.498404\n",
      "epoch 145; iter: 0; batch classifier loss: 0.308035; batch adversarial loss: 0.516468\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377035; batch adversarial loss: 0.572599\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334929; batch adversarial loss: 0.488966\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364492; batch adversarial loss: 0.535162\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363663; batch adversarial loss: 0.498232\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370964; batch adversarial loss: 0.563373\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384360; batch adversarial loss: 0.600525\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352539; batch adversarial loss: 0.544517\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356479; batch adversarial loss: 0.507011\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373186; batch adversarial loss: 0.516607\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377738; batch adversarial loss: 0.582035\n",
      "epoch 156; iter: 0; batch classifier loss: 0.331110; batch adversarial loss: 0.488602\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361408; batch adversarial loss: 0.525883\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372122; batch adversarial loss: 0.488451\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351364; batch adversarial loss: 0.553810\n",
      "epoch 160; iter: 0; batch classifier loss: 0.310281; batch adversarial loss: 0.563354\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359181; batch adversarial loss: 0.525719\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368838; batch adversarial loss: 0.553869\n",
      "epoch 163; iter: 0; batch classifier loss: 0.418834; batch adversarial loss: 0.525899\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360952; batch adversarial loss: 0.488312\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345410; batch adversarial loss: 0.469753\n",
      "epoch 166; iter: 0; batch classifier loss: 0.401930; batch adversarial loss: 0.534764\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363935; batch adversarial loss: 0.535025\n",
      "epoch 168; iter: 0; batch classifier loss: 0.417313; batch adversarial loss: 0.497691\n",
      "epoch 169; iter: 0; batch classifier loss: 0.469584; batch adversarial loss: 0.460655\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412301; batch adversarial loss: 0.469783\n",
      "epoch 171; iter: 0; batch classifier loss: 0.324953; batch adversarial loss: 0.507258\n",
      "epoch 172; iter: 0; batch classifier loss: 0.356654; batch adversarial loss: 0.563089\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360879; batch adversarial loss: 0.469866\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324834; batch adversarial loss: 0.572651\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352958; batch adversarial loss: 0.525750\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334046; batch adversarial loss: 0.554119\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380340; batch adversarial loss: 0.451369\n",
      "epoch 178; iter: 0; batch classifier loss: 0.404773; batch adversarial loss: 0.638138\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359589; batch adversarial loss: 0.563333\n",
      "epoch 180; iter: 0; batch classifier loss: 0.303661; batch adversarial loss: 0.516410\n",
      "epoch 181; iter: 0; batch classifier loss: 0.396489; batch adversarial loss: 0.553647\n",
      "epoch 182; iter: 0; batch classifier loss: 0.310951; batch adversarial loss: 0.516519\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355121; batch adversarial loss: 0.516399\n",
      "epoch 184; iter: 0; batch classifier loss: 0.462470; batch adversarial loss: 0.515722\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373298; batch adversarial loss: 0.552455\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356151; batch adversarial loss: 0.507152\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358589; batch adversarial loss: 0.544398\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348406; batch adversarial loss: 0.534465\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381366; batch adversarial loss: 0.469604\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401951; batch adversarial loss: 0.500161\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382564; batch adversarial loss: 0.534794\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404484; batch adversarial loss: 0.572471\n",
      "epoch 193; iter: 0; batch classifier loss: 0.293141; batch adversarial loss: 0.490853\n",
      "epoch 194; iter: 0; batch classifier loss: 0.345500; batch adversarial loss: 0.608571\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392421; batch adversarial loss: 0.574969\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387209; batch adversarial loss: 0.519046\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317927; batch adversarial loss: 0.516110\n",
      "epoch 198; iter: 0; batch classifier loss: 0.401624; batch adversarial loss: 0.442484\n",
      "epoch 199; iter: 0; batch classifier loss: 0.400812; batch adversarial loss: 0.571589\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694054; batch adversarial loss: 0.834962\n",
      "epoch 1; iter: 0; batch classifier loss: 0.752740; batch adversarial loss: 1.010165\n",
      "epoch 2; iter: 0; batch classifier loss: 0.832802; batch adversarial loss: 0.950990\n",
      "epoch 3; iter: 0; batch classifier loss: 0.836932; batch adversarial loss: 0.872787\n",
      "epoch 4; iter: 0; batch classifier loss: 0.789890; batch adversarial loss: 0.778325\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681269; batch adversarial loss: 0.726933\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558401; batch adversarial loss: 0.658470\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523950; batch adversarial loss: 0.629343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539134; batch adversarial loss: 0.606063\n",
      "epoch 9; iter: 0; batch classifier loss: 0.473787; batch adversarial loss: 0.633532\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542318; batch adversarial loss: 0.613164\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544049; batch adversarial loss: 0.588357\n",
      "epoch 12; iter: 0; batch classifier loss: 0.451452; batch adversarial loss: 0.578481\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515518; batch adversarial loss: 0.579037\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545858; batch adversarial loss: 0.582781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569156; batch adversarial loss: 0.593148\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513548; batch adversarial loss: 0.545223\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506097; batch adversarial loss: 0.543587\n",
      "epoch 18; iter: 0; batch classifier loss: 0.470925; batch adversarial loss: 0.547807\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488558; batch adversarial loss: 0.601226\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500695; batch adversarial loss: 0.473847\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510737; batch adversarial loss: 0.580487\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495452; batch adversarial loss: 0.500585\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484307; batch adversarial loss: 0.498535\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492755; batch adversarial loss: 0.558736\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465849; batch adversarial loss: 0.516415\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433491; batch adversarial loss: 0.550449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430743; batch adversarial loss: 0.538653\n",
      "epoch 28; iter: 0; batch classifier loss: 0.563547; batch adversarial loss: 0.611546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.456079; batch adversarial loss: 0.515140\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465110; batch adversarial loss: 0.543481\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495160; batch adversarial loss: 0.543692\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459044; batch adversarial loss: 0.611395\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466483; batch adversarial loss: 0.491863\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390472; batch adversarial loss: 0.641002\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503009; batch adversarial loss: 0.634116\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421349; batch adversarial loss: 0.599199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404911; batch adversarial loss: 0.491383\n",
      "epoch 38; iter: 0; batch classifier loss: 0.495993; batch adversarial loss: 0.585371\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430525; batch adversarial loss: 0.545377\n",
      "epoch 40; iter: 0; batch classifier loss: 0.498637; batch adversarial loss: 0.606290\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411781; batch adversarial loss: 0.546380\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409689; batch adversarial loss: 0.543422\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421493; batch adversarial loss: 0.545077\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452075; batch adversarial loss: 0.536888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.526527; batch adversarial loss: 0.588758\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440474; batch adversarial loss: 0.570370\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373204; batch adversarial loss: 0.537108\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448156; batch adversarial loss: 0.508016\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398423; batch adversarial loss: 0.498755\n",
      "epoch 50; iter: 0; batch classifier loss: 0.385100; batch adversarial loss: 0.606006\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421148; batch adversarial loss: 0.599870\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442106; batch adversarial loss: 0.573602\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442395; batch adversarial loss: 0.571541\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455510; batch adversarial loss: 0.507753\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431071; batch adversarial loss: 0.508502\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439916; batch adversarial loss: 0.562504\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441866; batch adversarial loss: 0.553184\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413872; batch adversarial loss: 0.572903\n",
      "epoch 59; iter: 0; batch classifier loss: 0.324135; batch adversarial loss: 0.563287\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413907; batch adversarial loss: 0.462184\n",
      "epoch 61; iter: 0; batch classifier loss: 0.372439; batch adversarial loss: 0.470739\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424167; batch adversarial loss: 0.500050\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441510; batch adversarial loss: 0.599223\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397064; batch adversarial loss: 0.619554\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449558; batch adversarial loss: 0.536333\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380149; batch adversarial loss: 0.471490\n",
      "epoch 67; iter: 0; batch classifier loss: 0.466667; batch adversarial loss: 0.533840\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402530; batch adversarial loss: 0.663814\n",
      "epoch 69; iter: 0; batch classifier loss: 0.338690; batch adversarial loss: 0.582562\n",
      "epoch 70; iter: 0; batch classifier loss: 0.456887; batch adversarial loss: 0.523820\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435456; batch adversarial loss: 0.569624\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400163; batch adversarial loss: 0.535647\n",
      "epoch 73; iter: 0; batch classifier loss: 0.464040; batch adversarial loss: 0.515754\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411420; batch adversarial loss: 0.573700\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390868; batch adversarial loss: 0.524101\n",
      "epoch 76; iter: 0; batch classifier loss: 0.362047; batch adversarial loss: 0.555048\n",
      "epoch 77; iter: 0; batch classifier loss: 0.302708; batch adversarial loss: 0.552698\n",
      "epoch 78; iter: 0; batch classifier loss: 0.451288; batch adversarial loss: 0.617984\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417322; batch adversarial loss: 0.564241\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418636; batch adversarial loss: 0.563471\n",
      "epoch 81; iter: 0; batch classifier loss: 0.347529; batch adversarial loss: 0.544741\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382227; batch adversarial loss: 0.561664\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411533; batch adversarial loss: 0.535998\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409949; batch adversarial loss: 0.663560\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416599; batch adversarial loss: 0.488192\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416838; batch adversarial loss: 0.571924\n",
      "epoch 87; iter: 0; batch classifier loss: 0.451839; batch adversarial loss: 0.507637\n",
      "epoch 88; iter: 0; batch classifier loss: 0.403782; batch adversarial loss: 0.618584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389618; batch adversarial loss: 0.518599\n",
      "epoch 90; iter: 0; batch classifier loss: 0.431936; batch adversarial loss: 0.552297\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403313; batch adversarial loss: 0.563289\n",
      "epoch 92; iter: 0; batch classifier loss: 0.337609; batch adversarial loss: 0.555457\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347347; batch adversarial loss: 0.637587\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384639; batch adversarial loss: 0.546834\n",
      "epoch 95; iter: 0; batch classifier loss: 0.351693; batch adversarial loss: 0.542387\n",
      "epoch 96; iter: 0; batch classifier loss: 0.415426; batch adversarial loss: 0.489764\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374530; batch adversarial loss: 0.555362\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371076; batch adversarial loss: 0.550385\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405803; batch adversarial loss: 0.589791\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383315; batch adversarial loss: 0.563395\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362002; batch adversarial loss: 0.534646\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372923; batch adversarial loss: 0.527623\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395849; batch adversarial loss: 0.469321\n",
      "epoch 104; iter: 0; batch classifier loss: 0.356072; batch adversarial loss: 0.505478\n",
      "epoch 105; iter: 0; batch classifier loss: 0.305303; batch adversarial loss: 0.559157\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376240; batch adversarial loss: 0.544869\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331685; batch adversarial loss: 0.597326\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351345; batch adversarial loss: 0.461635\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353776; batch adversarial loss: 0.527794\n",
      "epoch 110; iter: 0; batch classifier loss: 0.322205; batch adversarial loss: 0.572682\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345186; batch adversarial loss: 0.626081\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372788; batch adversarial loss: 0.582019\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377578; batch adversarial loss: 0.619066\n",
      "epoch 114; iter: 0; batch classifier loss: 0.317952; batch adversarial loss: 0.506973\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346065; batch adversarial loss: 0.525818\n",
      "epoch 116; iter: 0; batch classifier loss: 0.275133; batch adversarial loss: 0.507758\n",
      "epoch 117; iter: 0; batch classifier loss: 0.294605; batch adversarial loss: 0.480996\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401410; batch adversarial loss: 0.541634\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390296; batch adversarial loss: 0.553024\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337400; batch adversarial loss: 0.590790\n",
      "epoch 121; iter: 0; batch classifier loss: 0.454401; batch adversarial loss: 0.469619\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367131; batch adversarial loss: 0.608482\n",
      "epoch 123; iter: 0; batch classifier loss: 0.468029; batch adversarial loss: 0.581429\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369752; batch adversarial loss: 0.545247\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391014; batch adversarial loss: 0.546296\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381095; batch adversarial loss: 0.585410\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422888; batch adversarial loss: 0.544678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.375364; batch adversarial loss: 0.608975\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389643; batch adversarial loss: 0.590771\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371838; batch adversarial loss: 0.550864\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375776; batch adversarial loss: 0.490287\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312544; batch adversarial loss: 0.490000\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377376; batch adversarial loss: 0.550201\n",
      "epoch 134; iter: 0; batch classifier loss: 0.297819; batch adversarial loss: 0.505836\n",
      "epoch 135; iter: 0; batch classifier loss: 0.407175; batch adversarial loss: 0.533274\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387675; batch adversarial loss: 0.537435\n",
      "epoch 137; iter: 0; batch classifier loss: 0.417615; batch adversarial loss: 0.506438\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322766; batch adversarial loss: 0.562588\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333483; batch adversarial loss: 0.507604\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383206; batch adversarial loss: 0.609814\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383523; batch adversarial loss: 0.691877\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405291; batch adversarial loss: 0.598528\n",
      "epoch 143; iter: 0; batch classifier loss: 0.417469; batch adversarial loss: 0.529496\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341904; batch adversarial loss: 0.595518\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375983; batch adversarial loss: 0.525974\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332582; batch adversarial loss: 0.570298\n",
      "epoch 147; iter: 0; batch classifier loss: 0.323520; batch adversarial loss: 0.554034\n",
      "epoch 148; iter: 0; batch classifier loss: 0.307433; batch adversarial loss: 0.544094\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314647; batch adversarial loss: 0.574614\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345477; batch adversarial loss: 0.532882\n",
      "epoch 151; iter: 0; batch classifier loss: 0.346310; batch adversarial loss: 0.543756\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374269; batch adversarial loss: 0.532689\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387592; batch adversarial loss: 0.620535\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376777; batch adversarial loss: 0.556313\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367711; batch adversarial loss: 0.592300\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366539; batch adversarial loss: 0.581890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341970; batch adversarial loss: 0.477703\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337912; batch adversarial loss: 0.496225\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388296; batch adversarial loss: 0.583214\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385403; batch adversarial loss: 0.568448\n",
      "epoch 161; iter: 0; batch classifier loss: 0.465074; batch adversarial loss: 0.497133\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394182; batch adversarial loss: 0.580023\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373556; batch adversarial loss: 0.517466\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341673; batch adversarial loss: 0.597706\n",
      "epoch 165; iter: 0; batch classifier loss: 0.313254; batch adversarial loss: 0.553483\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342665; batch adversarial loss: 0.533424\n",
      "epoch 167; iter: 0; batch classifier loss: 0.315720; batch adversarial loss: 0.526842\n",
      "epoch 168; iter: 0; batch classifier loss: 0.298934; batch adversarial loss: 0.544671\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312957; batch adversarial loss: 0.499349\n",
      "epoch 170; iter: 0; batch classifier loss: 0.293948; batch adversarial loss: 0.596869\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383832; batch adversarial loss: 0.490435\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350075; batch adversarial loss: 0.539180\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342996; batch adversarial loss: 0.513712\n",
      "epoch 174; iter: 0; batch classifier loss: 0.317455; batch adversarial loss: 0.599627\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337265; batch adversarial loss: 0.555981\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380346; batch adversarial loss: 0.597048\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318742; batch adversarial loss: 0.458830\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372503; batch adversarial loss: 0.510157\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298214; batch adversarial loss: 0.579382\n",
      "epoch 180; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.533933\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401033; batch adversarial loss: 0.501656\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352881; batch adversarial loss: 0.535258\n",
      "epoch 183; iter: 0; batch classifier loss: 0.230007; batch adversarial loss: 0.534346\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336052; batch adversarial loss: 0.560906\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384504; batch adversarial loss: 0.572186\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323369; batch adversarial loss: 0.517991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345219; batch adversarial loss: 0.503810\n",
      "epoch 188; iter: 0; batch classifier loss: 0.429122; batch adversarial loss: 0.510101\n",
      "epoch 189; iter: 0; batch classifier loss: 0.325883; batch adversarial loss: 0.509659\n",
      "epoch 190; iter: 0; batch classifier loss: 0.362455; batch adversarial loss: 0.525376\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349954; batch adversarial loss: 0.554591\n",
      "epoch 192; iter: 0; batch classifier loss: 0.275066; batch adversarial loss: 0.619583\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316163; batch adversarial loss: 0.572163\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396896; batch adversarial loss: 0.552405\n",
      "epoch 195; iter: 0; batch classifier loss: 0.412216; batch adversarial loss: 0.574695\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339013; batch adversarial loss: 0.536659\n",
      "epoch 197; iter: 0; batch classifier loss: 0.325036; batch adversarial loss: 0.494609\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393600; batch adversarial loss: 0.570462\n",
      "epoch 199; iter: 0; batch classifier loss: 0.274588; batch adversarial loss: 0.599448\n",
      "epoch 0; iter: 0; batch classifier loss: 0.769984; batch adversarial loss: 0.860760\n",
      "epoch 1; iter: 0; batch classifier loss: 0.688448; batch adversarial loss: 0.851423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.781965; batch adversarial loss: 0.821320\n",
      "epoch 3; iter: 0; batch classifier loss: 0.772592; batch adversarial loss: 0.765060\n",
      "epoch 4; iter: 0; batch classifier loss: 1.001981; batch adversarial loss: 0.691597\n",
      "epoch 5; iter: 0; batch classifier loss: 0.739787; batch adversarial loss: 0.670831\n",
      "epoch 6; iter: 0; batch classifier loss: 0.696303; batch adversarial loss: 0.602748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543971; batch adversarial loss: 0.627597\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546193; batch adversarial loss: 0.588620\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578370; batch adversarial loss: 0.602119\n",
      "epoch 10; iter: 0; batch classifier loss: 0.463139; batch adversarial loss: 0.567628\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493686; batch adversarial loss: 0.588137\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461900; batch adversarial loss: 0.550392\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528304; batch adversarial loss: 0.586238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514086; batch adversarial loss: 0.568475\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508514; batch adversarial loss: 0.541847\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539675; batch adversarial loss: 0.530800\n",
      "epoch 17; iter: 0; batch classifier loss: 0.460897; batch adversarial loss: 0.597825\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478739; batch adversarial loss: 0.587279\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500369; batch adversarial loss: 0.590161\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512945; batch adversarial loss: 0.594958\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504296; batch adversarial loss: 0.631096\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451770; batch adversarial loss: 0.552148\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489499; batch adversarial loss: 0.567691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.440758; batch adversarial loss: 0.635099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500831; batch adversarial loss: 0.542018\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527998; batch adversarial loss: 0.604497\n",
      "epoch 27; iter: 0; batch classifier loss: 0.557777; batch adversarial loss: 0.593737\n",
      "epoch 28; iter: 0; batch classifier loss: 0.503797; batch adversarial loss: 0.576868\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509151; batch adversarial loss: 0.613010\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471944; batch adversarial loss: 0.509752\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491921; batch adversarial loss: 0.564026\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441740; batch adversarial loss: 0.584399\n",
      "epoch 33; iter: 0; batch classifier loss: 0.493577; batch adversarial loss: 0.565253\n",
      "epoch 34; iter: 0; batch classifier loss: 0.489791; batch adversarial loss: 0.536116\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480784; batch adversarial loss: 0.449576\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420399; batch adversarial loss: 0.516448\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402774; batch adversarial loss: 0.505721\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427182; batch adversarial loss: 0.579288\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462647; batch adversarial loss: 0.520920\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424558; batch adversarial loss: 0.478444\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434704; batch adversarial loss: 0.519890\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451032; batch adversarial loss: 0.622785\n",
      "epoch 43; iter: 0; batch classifier loss: 0.500991; batch adversarial loss: 0.666698\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475920; batch adversarial loss: 0.570954\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419517; batch adversarial loss: 0.456867\n",
      "epoch 46; iter: 0; batch classifier loss: 0.502003; batch adversarial loss: 0.615238\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437187; batch adversarial loss: 0.535755\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445760; batch adversarial loss: 0.571303\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414857; batch adversarial loss: 0.597301\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412987; batch adversarial loss: 0.570521\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450370; batch adversarial loss: 0.482687\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412704; batch adversarial loss: 0.482044\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429745; batch adversarial loss: 0.642859\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413916; batch adversarial loss: 0.525875\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403257; batch adversarial loss: 0.535691\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433027; batch adversarial loss: 0.634174\n",
      "epoch 57; iter: 0; batch classifier loss: 0.419783; batch adversarial loss: 0.490627\n",
      "epoch 58; iter: 0; batch classifier loss: 0.352749; batch adversarial loss: 0.544579\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413643; batch adversarial loss: 0.535936\n",
      "epoch 60; iter: 0; batch classifier loss: 0.501930; batch adversarial loss: 0.527458\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444187; batch adversarial loss: 0.553187\n",
      "epoch 62; iter: 0; batch classifier loss: 0.374473; batch adversarial loss: 0.545082\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400716; batch adversarial loss: 0.534951\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450760; batch adversarial loss: 0.551715\n",
      "epoch 65; iter: 0; batch classifier loss: 0.359555; batch adversarial loss: 0.473547\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410926; batch adversarial loss: 0.554067\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420454; batch adversarial loss: 0.544837\n",
      "epoch 68; iter: 0; batch classifier loss: 0.518268; batch adversarial loss: 0.537050\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447086; batch adversarial loss: 0.543900\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410550; batch adversarial loss: 0.481456\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369845; batch adversarial loss: 0.507806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392518; batch adversarial loss: 0.606007\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371970; batch adversarial loss: 0.551433\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397421; batch adversarial loss: 0.555422\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387994; batch adversarial loss: 0.526054\n",
      "epoch 76; iter: 0; batch classifier loss: 0.324168; batch adversarial loss: 0.588675\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400864; batch adversarial loss: 0.499838\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378007; batch adversarial loss: 0.562314\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381524; batch adversarial loss: 0.499657\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378051; batch adversarial loss: 0.569798\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406766; batch adversarial loss: 0.553345\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406768; batch adversarial loss: 0.518274\n",
      "epoch 83; iter: 0; batch classifier loss: 0.393228; batch adversarial loss: 0.565063\n",
      "epoch 84; iter: 0; batch classifier loss: 0.385340; batch adversarial loss: 0.534690\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381161; batch adversarial loss: 0.527005\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331373; batch adversarial loss: 0.518662\n",
      "epoch 87; iter: 0; batch classifier loss: 0.444937; batch adversarial loss: 0.553661\n",
      "epoch 88; iter: 0; batch classifier loss: 0.474349; batch adversarial loss: 0.555357\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386768; batch adversarial loss: 0.552060\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389478; batch adversarial loss: 0.544087\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416987; batch adversarial loss: 0.598280\n",
      "epoch 92; iter: 0; batch classifier loss: 0.443876; batch adversarial loss: 0.602063\n",
      "epoch 93; iter: 0; batch classifier loss: 0.336046; batch adversarial loss: 0.561994\n",
      "epoch 94; iter: 0; batch classifier loss: 0.400831; batch adversarial loss: 0.507596\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343391; batch adversarial loss: 0.536341\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326041; batch adversarial loss: 0.535947\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362007; batch adversarial loss: 0.517244\n",
      "epoch 98; iter: 0; batch classifier loss: 0.300203; batch adversarial loss: 0.587854\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361103; batch adversarial loss: 0.640347\n",
      "epoch 100; iter: 0; batch classifier loss: 0.331979; batch adversarial loss: 0.534503\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383315; batch adversarial loss: 0.569262\n",
      "epoch 102; iter: 0; batch classifier loss: 0.387109; batch adversarial loss: 0.542340\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346721; batch adversarial loss: 0.509376\n",
      "epoch 104; iter: 0; batch classifier loss: 0.406482; batch adversarial loss: 0.475290\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389727; batch adversarial loss: 0.453487\n",
      "epoch 106; iter: 0; batch classifier loss: 0.470619; batch adversarial loss: 0.527189\n",
      "epoch 107; iter: 0; batch classifier loss: 0.318168; batch adversarial loss: 0.535079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.345181; batch adversarial loss: 0.562349\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374703; batch adversarial loss: 0.614522\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343263; batch adversarial loss: 0.618468\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412418; batch adversarial loss: 0.516038\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390345; batch adversarial loss: 0.586210\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413017; batch adversarial loss: 0.517535\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400461; batch adversarial loss: 0.606784\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343825; batch adversarial loss: 0.464812\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319015; batch adversarial loss: 0.523388\n",
      "epoch 117; iter: 0; batch classifier loss: 0.436391; batch adversarial loss: 0.524993\n",
      "epoch 118; iter: 0; batch classifier loss: 0.331278; batch adversarial loss: 0.498198\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431596; batch adversarial loss: 0.562296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398296; batch adversarial loss: 0.579292\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404449; batch adversarial loss: 0.575624\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400546; batch adversarial loss: 0.564010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.322393; batch adversarial loss: 0.523433\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358175; batch adversarial loss: 0.578994\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374963; batch adversarial loss: 0.524865\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373488; batch adversarial loss: 0.489754\n",
      "epoch 127; iter: 0; batch classifier loss: 0.314495; batch adversarial loss: 0.534994\n",
      "epoch 128; iter: 0; batch classifier loss: 0.426614; batch adversarial loss: 0.528347\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346261; batch adversarial loss: 0.526994\n",
      "epoch 130; iter: 0; batch classifier loss: 0.329640; batch adversarial loss: 0.595289\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391217; batch adversarial loss: 0.561745\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355795; batch adversarial loss: 0.615702\n",
      "epoch 133; iter: 0; batch classifier loss: 0.389737; batch adversarial loss: 0.587885\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357689; batch adversarial loss: 0.515494\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365568; batch adversarial loss: 0.500593\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340363; batch adversarial loss: 0.574401\n",
      "epoch 137; iter: 0; batch classifier loss: 0.293913; batch adversarial loss: 0.529563\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353453; batch adversarial loss: 0.559393\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366624; batch adversarial loss: 0.543700\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396046; batch adversarial loss: 0.579189\n",
      "epoch 141; iter: 0; batch classifier loss: 0.340763; batch adversarial loss: 0.499367\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384457; batch adversarial loss: 0.491939\n",
      "epoch 143; iter: 0; batch classifier loss: 0.402158; batch adversarial loss: 0.585973\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388101; batch adversarial loss: 0.535607\n",
      "epoch 145; iter: 0; batch classifier loss: 0.444787; batch adversarial loss: 0.563235\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384248; batch adversarial loss: 0.542587\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354028; batch adversarial loss: 0.615079\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368503; batch adversarial loss: 0.460993\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405626; batch adversarial loss: 0.553312\n",
      "epoch 150; iter: 0; batch classifier loss: 0.324048; batch adversarial loss: 0.488354\n",
      "epoch 151; iter: 0; batch classifier loss: 0.456928; batch adversarial loss: 0.552432\n",
      "epoch 152; iter: 0; batch classifier loss: 0.345472; batch adversarial loss: 0.600503\n",
      "epoch 153; iter: 0; batch classifier loss: 0.300870; batch adversarial loss: 0.553851\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325458; batch adversarial loss: 0.613892\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338842; batch adversarial loss: 0.546821\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344372; batch adversarial loss: 0.527643\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341620; batch adversarial loss: 0.498373\n",
      "epoch 158; iter: 0; batch classifier loss: 0.405749; batch adversarial loss: 0.616996\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325778; batch adversarial loss: 0.544834\n",
      "epoch 160; iter: 0; batch classifier loss: 0.254592; batch adversarial loss: 0.579329\n",
      "epoch 161; iter: 0; batch classifier loss: 0.292285; batch adversarial loss: 0.534194\n",
      "epoch 162; iter: 0; batch classifier loss: 0.362999; batch adversarial loss: 0.623430\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349476; batch adversarial loss: 0.623655\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312496; batch adversarial loss: 0.568314\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376417; batch adversarial loss: 0.453267\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361898; batch adversarial loss: 0.478504\n",
      "epoch 167; iter: 0; batch classifier loss: 0.470337; batch adversarial loss: 0.491054\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359640; batch adversarial loss: 0.515048\n",
      "epoch 169; iter: 0; batch classifier loss: 0.335276; batch adversarial loss: 0.633888\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409772; batch adversarial loss: 0.588152\n",
      "epoch 171; iter: 0; batch classifier loss: 0.398587; batch adversarial loss: 0.554761\n",
      "epoch 172; iter: 0; batch classifier loss: 0.292875; batch adversarial loss: 0.589633\n",
      "epoch 173; iter: 0; batch classifier loss: 0.395519; batch adversarial loss: 0.570323\n",
      "epoch 174; iter: 0; batch classifier loss: 0.304386; batch adversarial loss: 0.538415\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372383; batch adversarial loss: 0.490494\n",
      "epoch 176; iter: 0; batch classifier loss: 0.238264; batch adversarial loss: 0.527091\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309833; batch adversarial loss: 0.607021\n",
      "epoch 178; iter: 0; batch classifier loss: 0.348406; batch adversarial loss: 0.526206\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333118; batch adversarial loss: 0.553942\n",
      "epoch 180; iter: 0; batch classifier loss: 0.428710; batch adversarial loss: 0.570968\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358008; batch adversarial loss: 0.552248\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333795; batch adversarial loss: 0.583024\n",
      "epoch 183; iter: 0; batch classifier loss: 0.504669; batch adversarial loss: 0.669142\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355003; batch adversarial loss: 0.500637\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367592; batch adversarial loss: 0.508072\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324167; batch adversarial loss: 0.642978\n",
      "epoch 187; iter: 0; batch classifier loss: 0.268588; batch adversarial loss: 0.554522\n",
      "epoch 188; iter: 0; batch classifier loss: 0.261105; batch adversarial loss: 0.562090\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322248; batch adversarial loss: 0.558628\n",
      "epoch 190; iter: 0; batch classifier loss: 0.319388; batch adversarial loss: 0.550286\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325683; batch adversarial loss: 0.477957\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375269; batch adversarial loss: 0.545513\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370356; batch adversarial loss: 0.553033\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332817; batch adversarial loss: 0.562380\n",
      "epoch 195; iter: 0; batch classifier loss: 0.286579; batch adversarial loss: 0.543903\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364790; batch adversarial loss: 0.490460\n",
      "epoch 197; iter: 0; batch classifier loss: 0.292063; batch adversarial loss: 0.599649\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319404; batch adversarial loss: 0.570665\n",
      "epoch 199; iter: 0; batch classifier loss: 0.301614; batch adversarial loss: 0.612992\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670856; batch adversarial loss: 0.632878\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597695; batch adversarial loss: 0.689397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581076; batch adversarial loss: 0.731966\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562382; batch adversarial loss: 0.744579\n",
      "epoch 4; iter: 0; batch classifier loss: 0.678454; batch adversarial loss: 0.810082\n",
      "epoch 5; iter: 0; batch classifier loss: 0.642786; batch adversarial loss: 0.774812\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609368; batch adversarial loss: 0.655079\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566660; batch adversarial loss: 0.653924\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588523; batch adversarial loss: 0.615237\n",
      "epoch 9; iter: 0; batch classifier loss: 0.648305; batch adversarial loss: 0.663803\n",
      "epoch 10; iter: 0; batch classifier loss: 0.704071; batch adversarial loss: 0.651955\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567564; batch adversarial loss: 0.576809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526439; batch adversarial loss: 0.596475\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471929; batch adversarial loss: 0.603686\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510243; batch adversarial loss: 0.565560\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537895; batch adversarial loss: 0.572114\n",
      "epoch 16; iter: 0; batch classifier loss: 0.562358; batch adversarial loss: 0.497717\n",
      "epoch 17; iter: 0; batch classifier loss: 0.569826; batch adversarial loss: 0.556094\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547219; batch adversarial loss: 0.577451\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523793; batch adversarial loss: 0.541752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.502373; batch adversarial loss: 0.602030\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511892; batch adversarial loss: 0.566465\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473966; batch adversarial loss: 0.589992\n",
      "epoch 23; iter: 0; batch classifier loss: 0.573959; batch adversarial loss: 0.548471\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528090; batch adversarial loss: 0.530912\n",
      "epoch 25; iter: 0; batch classifier loss: 0.379575; batch adversarial loss: 0.487608\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520953; batch adversarial loss: 0.579399\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477706; batch adversarial loss: 0.604635\n",
      "epoch 28; iter: 0; batch classifier loss: 0.410737; batch adversarial loss: 0.469330\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462840; batch adversarial loss: 0.528490\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457036; batch adversarial loss: 0.588773\n",
      "epoch 31; iter: 0; batch classifier loss: 0.538697; batch adversarial loss: 0.588031\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499104; batch adversarial loss: 0.502737\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476639; batch adversarial loss: 0.526916\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458951; batch adversarial loss: 0.528159\n",
      "epoch 35; iter: 0; batch classifier loss: 0.540886; batch adversarial loss: 0.589368\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407404; batch adversarial loss: 0.510434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407098; batch adversarial loss: 0.534772\n",
      "epoch 38; iter: 0; batch classifier loss: 0.517969; batch adversarial loss: 0.552976\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445698; batch adversarial loss: 0.518301\n",
      "epoch 40; iter: 0; batch classifier loss: 0.515945; batch adversarial loss: 0.508004\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435773; batch adversarial loss: 0.554199\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439471; batch adversarial loss: 0.490536\n",
      "epoch 43; iter: 0; batch classifier loss: 0.501924; batch adversarial loss: 0.597959\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444575; batch adversarial loss: 0.570318\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461274; batch adversarial loss: 0.579765\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447836; batch adversarial loss: 0.498396\n",
      "epoch 47; iter: 0; batch classifier loss: 0.506363; batch adversarial loss: 0.608587\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474905; batch adversarial loss: 0.535506\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427070; batch adversarial loss: 0.510309\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394838; batch adversarial loss: 0.536261\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413757; batch adversarial loss: 0.571413\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439960; batch adversarial loss: 0.580949\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404070; batch adversarial loss: 0.535456\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402721; batch adversarial loss: 0.632246\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453000; batch adversarial loss: 0.519583\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438406; batch adversarial loss: 0.581601\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418095; batch adversarial loss: 0.509000\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463545; batch adversarial loss: 0.591002\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383968; batch adversarial loss: 0.482942\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390641; batch adversarial loss: 0.572995\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441188; batch adversarial loss: 0.598932\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409799; batch adversarial loss: 0.536408\n",
      "epoch 63; iter: 0; batch classifier loss: 0.452603; batch adversarial loss: 0.556417\n",
      "epoch 64; iter: 0; batch classifier loss: 0.481133; batch adversarial loss: 0.526380\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406595; batch adversarial loss: 0.562380\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405302; batch adversarial loss: 0.580129\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406253; batch adversarial loss: 0.580296\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411310; batch adversarial loss: 0.571947\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435694; batch adversarial loss: 0.571133\n",
      "epoch 70; iter: 0; batch classifier loss: 0.339998; batch adversarial loss: 0.545465\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377349; batch adversarial loss: 0.606524\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414774; batch adversarial loss: 0.563431\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427407; batch adversarial loss: 0.553452\n",
      "epoch 74; iter: 0; batch classifier loss: 0.348450; batch adversarial loss: 0.536321\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372733; batch adversarial loss: 0.616400\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465714; batch adversarial loss: 0.483046\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418456; batch adversarial loss: 0.571872\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395932; batch adversarial loss: 0.545799\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439380; batch adversarial loss: 0.570047\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426146; batch adversarial loss: 0.571159\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368832; batch adversarial loss: 0.500876\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350397; batch adversarial loss: 0.482553\n",
      "epoch 83; iter: 0; batch classifier loss: 0.521561; batch adversarial loss: 0.482384\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403029; batch adversarial loss: 0.544033\n",
      "epoch 85; iter: 0; batch classifier loss: 0.492162; batch adversarial loss: 0.544615\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370841; batch adversarial loss: 0.544252\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377026; batch adversarial loss: 0.589732\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400874; batch adversarial loss: 0.633773\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413005; batch adversarial loss: 0.553388\n",
      "epoch 90; iter: 0; batch classifier loss: 0.499089; batch adversarial loss: 0.545357\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407046; batch adversarial loss: 0.563483\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379348; batch adversarial loss: 0.518257\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353848; batch adversarial loss: 0.597062\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383419; batch adversarial loss: 0.616200\n",
      "epoch 95; iter: 0; batch classifier loss: 0.486976; batch adversarial loss: 0.606754\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335772; batch adversarial loss: 0.553783\n",
      "epoch 97; iter: 0; batch classifier loss: 0.448443; batch adversarial loss: 0.659341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.408948; batch adversarial loss: 0.518211\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422848; batch adversarial loss: 0.545024\n",
      "epoch 100; iter: 0; batch classifier loss: 0.487160; batch adversarial loss: 0.571502\n",
      "epoch 101; iter: 0; batch classifier loss: 0.404311; batch adversarial loss: 0.526650\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365671; batch adversarial loss: 0.518436\n",
      "epoch 103; iter: 0; batch classifier loss: 0.421052; batch adversarial loss: 0.491430\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401232; batch adversarial loss: 0.562399\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409615; batch adversarial loss: 0.517673\n",
      "epoch 106; iter: 0; batch classifier loss: 0.436119; batch adversarial loss: 0.509530\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404657; batch adversarial loss: 0.570919\n",
      "epoch 108; iter: 0; batch classifier loss: 0.481277; batch adversarial loss: 0.669207\n",
      "epoch 109; iter: 0; batch classifier loss: 0.453158; batch adversarial loss: 0.500190\n",
      "epoch 110; iter: 0; batch classifier loss: 0.447839; batch adversarial loss: 0.509514\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384932; batch adversarial loss: 0.553652\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385444; batch adversarial loss: 0.544533\n",
      "epoch 113; iter: 0; batch classifier loss: 0.445102; batch adversarial loss: 0.571441\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418678; batch adversarial loss: 0.544871\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339241; batch adversarial loss: 0.652067\n",
      "epoch 116; iter: 0; batch classifier loss: 0.434546; batch adversarial loss: 0.580101\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411163; batch adversarial loss: 0.535691\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345831; batch adversarial loss: 0.580326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.375706; batch adversarial loss: 0.445788\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420371; batch adversarial loss: 0.491626\n",
      "epoch 121; iter: 0; batch classifier loss: 0.494885; batch adversarial loss: 0.572526\n",
      "epoch 122; iter: 0; batch classifier loss: 0.462215; batch adversarial loss: 0.580182\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355132; batch adversarial loss: 0.535902\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325077; batch adversarial loss: 0.498260\n",
      "epoch 125; iter: 0; batch classifier loss: 0.312044; batch adversarial loss: 0.571516\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360081; batch adversarial loss: 0.616733\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391464; batch adversarial loss: 0.606046\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395441; batch adversarial loss: 0.554715\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406000; batch adversarial loss: 0.553690\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350076; batch adversarial loss: 0.526762\n",
      "epoch 131; iter: 0; batch classifier loss: 0.316252; batch adversarial loss: 0.562605\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414504; batch adversarial loss: 0.544522\n",
      "epoch 133; iter: 0; batch classifier loss: 0.413388; batch adversarial loss: 0.536046\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405321; batch adversarial loss: 0.492283\n",
      "epoch 135; iter: 0; batch classifier loss: 0.432310; batch adversarial loss: 0.624165\n",
      "epoch 136; iter: 0; batch classifier loss: 0.439967; batch adversarial loss: 0.536126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.510000; batch adversarial loss: 0.571079\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405113; batch adversarial loss: 0.501737\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393441; batch adversarial loss: 0.534923\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389548; batch adversarial loss: 0.561383\n",
      "epoch 141; iter: 0; batch classifier loss: 0.486942; batch adversarial loss: 0.527580\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418822; batch adversarial loss: 0.501670\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388622; batch adversarial loss: 0.579247\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365212; batch adversarial loss: 0.554513\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362635; batch adversarial loss: 0.571006\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365641; batch adversarial loss: 0.598281\n",
      "epoch 147; iter: 0; batch classifier loss: 0.389213; batch adversarial loss: 0.544553\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371461; batch adversarial loss: 0.608515\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336003; batch adversarial loss: 0.544824\n",
      "epoch 150; iter: 0; batch classifier loss: 0.469820; batch adversarial loss: 0.508004\n",
      "epoch 151; iter: 0; batch classifier loss: 0.463008; batch adversarial loss: 0.598592\n",
      "epoch 152; iter: 0; batch classifier loss: 0.427380; batch adversarial loss: 0.562460\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402103; batch adversarial loss: 0.552869\n",
      "epoch 154; iter: 0; batch classifier loss: 0.418480; batch adversarial loss: 0.670009\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406214; batch adversarial loss: 0.562124\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367316; batch adversarial loss: 0.543683\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418721; batch adversarial loss: 0.526664\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325140; batch adversarial loss: 0.456269\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354470; batch adversarial loss: 0.527274\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357773; batch adversarial loss: 0.615296\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367521; batch adversarial loss: 0.597496\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380679; batch adversarial loss: 0.430368\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364303; batch adversarial loss: 0.553466\n",
      "epoch 164; iter: 0; batch classifier loss: 0.281374; batch adversarial loss: 0.641424\n",
      "epoch 165; iter: 0; batch classifier loss: 0.468888; batch adversarial loss: 0.589242\n",
      "epoch 166; iter: 0; batch classifier loss: 0.416309; batch adversarial loss: 0.500091\n",
      "epoch 167; iter: 0; batch classifier loss: 0.428290; batch adversarial loss: 0.508704\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387542; batch adversarial loss: 0.589315\n",
      "epoch 169; iter: 0; batch classifier loss: 0.417394; batch adversarial loss: 0.571140\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353781; batch adversarial loss: 0.544675\n",
      "epoch 171; iter: 0; batch classifier loss: 0.507904; batch adversarial loss: 0.473169\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351296; batch adversarial loss: 0.517671\n",
      "epoch 173; iter: 0; batch classifier loss: 0.449725; batch adversarial loss: 0.543887\n",
      "epoch 174; iter: 0; batch classifier loss: 0.320545; batch adversarial loss: 0.535828\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356006; batch adversarial loss: 0.526983\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365527; batch adversarial loss: 0.651700\n",
      "epoch 177; iter: 0; batch classifier loss: 0.382386; batch adversarial loss: 0.491542\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318576; batch adversarial loss: 0.544747\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369545; batch adversarial loss: 0.580068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372320; batch adversarial loss: 0.615504\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343873; batch adversarial loss: 0.544564\n",
      "epoch 182; iter: 0; batch classifier loss: 0.279083; batch adversarial loss: 0.562319\n",
      "epoch 183; iter: 0; batch classifier loss: 0.419500; batch adversarial loss: 0.589301\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404691; batch adversarial loss: 0.553614\n",
      "epoch 185; iter: 0; batch classifier loss: 0.404187; batch adversarial loss: 0.491559\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398806; batch adversarial loss: 0.589078\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364157; batch adversarial loss: 0.509157\n",
      "epoch 188; iter: 0; batch classifier loss: 0.306372; batch adversarial loss: 0.571338\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371300; batch adversarial loss: 0.562440\n",
      "epoch 190; iter: 0; batch classifier loss: 0.303899; batch adversarial loss: 0.597968\n",
      "epoch 191; iter: 0; batch classifier loss: 0.422735; batch adversarial loss: 0.518332\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368656; batch adversarial loss: 0.535698\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348224; batch adversarial loss: 0.526713\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374358; batch adversarial loss: 0.544226\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311075; batch adversarial loss: 0.571504\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392595; batch adversarial loss: 0.544686\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356781; batch adversarial loss: 0.571299\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371929; batch adversarial loss: 0.544292\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350534; batch adversarial loss: 0.526626\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724100; batch adversarial loss: 0.859952\n",
      "epoch 1; iter: 0; batch classifier loss: 0.789605; batch adversarial loss: 0.899883\n",
      "epoch 2; iter: 0; batch classifier loss: 0.786084; batch adversarial loss: 0.845565\n",
      "epoch 3; iter: 0; batch classifier loss: 0.860915; batch adversarial loss: 0.807845\n",
      "epoch 4; iter: 0; batch classifier loss: 0.751191; batch adversarial loss: 0.723272\n",
      "epoch 5; iter: 0; batch classifier loss: 0.688692; batch adversarial loss: 0.687780\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585329; batch adversarial loss: 0.625277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595722; batch adversarial loss: 0.622696\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576569; batch adversarial loss: 0.597690\n",
      "epoch 9; iter: 0; batch classifier loss: 0.592581; batch adversarial loss: 0.568856\n",
      "epoch 10; iter: 0; batch classifier loss: 0.596449; batch adversarial loss: 0.589281\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524031; batch adversarial loss: 0.588464\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590339; batch adversarial loss: 0.573428\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511309; batch adversarial loss: 0.593243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557897; batch adversarial loss: 0.541259\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500563; batch adversarial loss: 0.537009\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487865; batch adversarial loss: 0.573064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.575191; batch adversarial loss: 0.599127\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556362; batch adversarial loss: 0.547922\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491399; batch adversarial loss: 0.568975\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473554; batch adversarial loss: 0.643154\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500008; batch adversarial loss: 0.594465\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506509; batch adversarial loss: 0.503782\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488165; batch adversarial loss: 0.601689\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484300; batch adversarial loss: 0.539776\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506916; batch adversarial loss: 0.515128\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498997; batch adversarial loss: 0.531479\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433125; batch adversarial loss: 0.476953\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419632; batch adversarial loss: 0.515734\n",
      "epoch 29; iter: 0; batch classifier loss: 0.515755; batch adversarial loss: 0.552057\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509040; batch adversarial loss: 0.609325\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458296; batch adversarial loss: 0.578904\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427745; batch adversarial loss: 0.529265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457564; batch adversarial loss: 0.556184\n",
      "epoch 34; iter: 0; batch classifier loss: 0.444538; batch adversarial loss: 0.452094\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426660; batch adversarial loss: 0.551324\n",
      "epoch 36; iter: 0; batch classifier loss: 0.475367; batch adversarial loss: 0.529545\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421087; batch adversarial loss: 0.571930\n",
      "epoch 38; iter: 0; batch classifier loss: 0.491296; batch adversarial loss: 0.553784\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490758; batch adversarial loss: 0.527690\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454244; batch adversarial loss: 0.496931\n",
      "epoch 41; iter: 0; batch classifier loss: 0.492897; batch adversarial loss: 0.545580\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396261; batch adversarial loss: 0.540067\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419211; batch adversarial loss: 0.575835\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395004; batch adversarial loss: 0.558705\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422548; batch adversarial loss: 0.397708\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429242; batch adversarial loss: 0.482764\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458899; batch adversarial loss: 0.599517\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410445; batch adversarial loss: 0.565030\n",
      "epoch 49; iter: 0; batch classifier loss: 0.505840; batch adversarial loss: 0.601740\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438348; batch adversarial loss: 0.556393\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440522; batch adversarial loss: 0.657977\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471371; batch adversarial loss: 0.537040\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393326; batch adversarial loss: 0.641787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422027; batch adversarial loss: 0.572701\n",
      "epoch 55; iter: 0; batch classifier loss: 0.464640; batch adversarial loss: 0.652579\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425316; batch adversarial loss: 0.590014\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407471; batch adversarial loss: 0.678134\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389586; batch adversarial loss: 0.570416\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411047; batch adversarial loss: 0.570433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.540094; batch adversarial loss: 0.519319\n",
      "epoch 61; iter: 0; batch classifier loss: 0.496311; batch adversarial loss: 0.606490\n",
      "epoch 62; iter: 0; batch classifier loss: 0.357019; batch adversarial loss: 0.609964\n",
      "epoch 63; iter: 0; batch classifier loss: 0.380313; batch adversarial loss: 0.643683\n",
      "epoch 64; iter: 0; batch classifier loss: 0.472385; batch adversarial loss: 0.552659\n",
      "epoch 65; iter: 0; batch classifier loss: 0.366054; batch adversarial loss: 0.615787\n",
      "epoch 66; iter: 0; batch classifier loss: 0.493100; batch adversarial loss: 0.430101\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418601; batch adversarial loss: 0.527452\n",
      "epoch 68; iter: 0; batch classifier loss: 0.493868; batch adversarial loss: 0.554311\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435953; batch adversarial loss: 0.633931\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465026; batch adversarial loss: 0.571035\n",
      "epoch 71; iter: 0; batch classifier loss: 0.375739; batch adversarial loss: 0.634109\n",
      "epoch 72; iter: 0; batch classifier loss: 0.431209; batch adversarial loss: 0.543895\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426964; batch adversarial loss: 0.562089\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346018; batch adversarial loss: 0.607082\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376519; batch adversarial loss: 0.616170\n",
      "epoch 76; iter: 0; batch classifier loss: 0.434492; batch adversarial loss: 0.525839\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364702; batch adversarial loss: 0.535311\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416948; batch adversarial loss: 0.580061\n",
      "epoch 79; iter: 0; batch classifier loss: 0.331462; batch adversarial loss: 0.607919\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421662; batch adversarial loss: 0.552986\n",
      "epoch 81; iter: 0; batch classifier loss: 0.380050; batch adversarial loss: 0.571171\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421184; batch adversarial loss: 0.527578\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451468; batch adversarial loss: 0.535172\n",
      "epoch 84; iter: 0; batch classifier loss: 0.454966; batch adversarial loss: 0.552993\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441068; batch adversarial loss: 0.543919\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390624; batch adversarial loss: 0.581847\n",
      "epoch 87; iter: 0; batch classifier loss: 0.414793; batch adversarial loss: 0.516500\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426670; batch adversarial loss: 0.615968\n",
      "epoch 89; iter: 0; batch classifier loss: 0.327600; batch adversarial loss: 0.607115\n",
      "epoch 90; iter: 0; batch classifier loss: 0.306000; batch adversarial loss: 0.500336\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385649; batch adversarial loss: 0.580239\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370146; batch adversarial loss: 0.517358\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422879; batch adversarial loss: 0.517270\n",
      "epoch 94; iter: 0; batch classifier loss: 0.473524; batch adversarial loss: 0.570640\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391773; batch adversarial loss: 0.563122\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372330; batch adversarial loss: 0.598387\n",
      "epoch 97; iter: 0; batch classifier loss: 0.460319; batch adversarial loss: 0.518372\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393148; batch adversarial loss: 0.545076\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342625; batch adversarial loss: 0.581955\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371162; batch adversarial loss: 0.518790\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358828; batch adversarial loss: 0.562357\n",
      "epoch 102; iter: 0; batch classifier loss: 0.403041; batch adversarial loss: 0.608279\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419661; batch adversarial loss: 0.633688\n",
      "epoch 104; iter: 0; batch classifier loss: 0.452627; batch adversarial loss: 0.578649\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404345; batch adversarial loss: 0.535714\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384985; batch adversarial loss: 0.545766\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364684; batch adversarial loss: 0.606425\n",
      "epoch 108; iter: 0; batch classifier loss: 0.356699; batch adversarial loss: 0.545036\n",
      "epoch 109; iter: 0; batch classifier loss: 0.455221; batch adversarial loss: 0.561910\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348525; batch adversarial loss: 0.561261\n",
      "epoch 111; iter: 0; batch classifier loss: 0.390736; batch adversarial loss: 0.578891\n",
      "epoch 112; iter: 0; batch classifier loss: 0.417602; batch adversarial loss: 0.607078\n",
      "epoch 113; iter: 0; batch classifier loss: 0.320483; batch adversarial loss: 0.498525\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375204; batch adversarial loss: 0.517972\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350526; batch adversarial loss: 0.535630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.396275; batch adversarial loss: 0.606933\n",
      "epoch 117; iter: 0; batch classifier loss: 0.355641; batch adversarial loss: 0.544221\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345960; batch adversarial loss: 0.554424\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352611; batch adversarial loss: 0.492196\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415795; batch adversarial loss: 0.488757\n",
      "epoch 121; iter: 0; batch classifier loss: 0.312464; batch adversarial loss: 0.589953\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339612; batch adversarial loss: 0.500051\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361993; batch adversarial loss: 0.580777\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395433; batch adversarial loss: 0.553866\n",
      "epoch 125; iter: 0; batch classifier loss: 0.436661; batch adversarial loss: 0.571555\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350832; batch adversarial loss: 0.517114\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372823; batch adversarial loss: 0.535561\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422420; batch adversarial loss: 0.544877\n",
      "epoch 129; iter: 0; batch classifier loss: 0.455542; batch adversarial loss: 0.481982\n",
      "epoch 130; iter: 0; batch classifier loss: 0.424207; batch adversarial loss: 0.490878\n",
      "epoch 131; iter: 0; batch classifier loss: 0.393274; batch adversarial loss: 0.499344\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318397; batch adversarial loss: 0.561301\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386635; batch adversarial loss: 0.445544\n",
      "epoch 134; iter: 0; batch classifier loss: 0.319076; batch adversarial loss: 0.543957\n",
      "epoch 135; iter: 0; batch classifier loss: 0.333508; batch adversarial loss: 0.445140\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336588; batch adversarial loss: 0.563257\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405651; batch adversarial loss: 0.534950\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373494; batch adversarial loss: 0.508021\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388386; batch adversarial loss: 0.482384\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374701; batch adversarial loss: 0.499750\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328832; batch adversarial loss: 0.527932\n",
      "epoch 142; iter: 0; batch classifier loss: 0.430634; batch adversarial loss: 0.508598\n",
      "epoch 143; iter: 0; batch classifier loss: 0.409008; batch adversarial loss: 0.580843\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372337; batch adversarial loss: 0.552549\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350942; batch adversarial loss: 0.571984\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334303; batch adversarial loss: 0.723963\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414052; batch adversarial loss: 0.635290\n",
      "epoch 148; iter: 0; batch classifier loss: 0.425830; batch adversarial loss: 0.535075\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398294; batch adversarial loss: 0.590136\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377594; batch adversarial loss: 0.563180\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339627; batch adversarial loss: 0.517380\n",
      "epoch 152; iter: 0; batch classifier loss: 0.458092; batch adversarial loss: 0.588795\n",
      "epoch 153; iter: 0; batch classifier loss: 0.495418; batch adversarial loss: 0.543319\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329375; batch adversarial loss: 0.472392\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346097; batch adversarial loss: 0.580437\n",
      "epoch 156; iter: 0; batch classifier loss: 0.422979; batch adversarial loss: 0.533784\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334916; batch adversarial loss: 0.536476\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388603; batch adversarial loss: 0.581275\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372020; batch adversarial loss: 0.446886\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379410; batch adversarial loss: 0.544072\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343284; batch adversarial loss: 0.518427\n",
      "epoch 162; iter: 0; batch classifier loss: 0.342494; batch adversarial loss: 0.571689\n",
      "epoch 163; iter: 0; batch classifier loss: 0.308642; batch adversarial loss: 0.543016\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360284; batch adversarial loss: 0.526756\n",
      "epoch 165; iter: 0; batch classifier loss: 0.337608; batch adversarial loss: 0.562212\n",
      "epoch 166; iter: 0; batch classifier loss: 0.306691; batch adversarial loss: 0.580237\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321538; batch adversarial loss: 0.481460\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338806; batch adversarial loss: 0.491425\n",
      "epoch 169; iter: 0; batch classifier loss: 0.296341; batch adversarial loss: 0.473139\n",
      "epoch 170; iter: 0; batch classifier loss: 0.282079; batch adversarial loss: 0.499335\n",
      "epoch 171; iter: 0; batch classifier loss: 0.400844; batch adversarial loss: 0.552802\n",
      "epoch 172; iter: 0; batch classifier loss: 0.293164; batch adversarial loss: 0.489802\n",
      "epoch 173; iter: 0; batch classifier loss: 0.376703; batch adversarial loss: 0.500178\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387609; batch adversarial loss: 0.580992\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313502; batch adversarial loss: 0.552683\n",
      "epoch 176; iter: 0; batch classifier loss: 0.429538; batch adversarial loss: 0.527288\n",
      "epoch 177; iter: 0; batch classifier loss: 0.370916; batch adversarial loss: 0.518402\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383945; batch adversarial loss: 0.579989\n",
      "epoch 179; iter: 0; batch classifier loss: 0.261214; batch adversarial loss: 0.554148\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335159; batch adversarial loss: 0.607436\n",
      "epoch 181; iter: 0; batch classifier loss: 0.408731; batch adversarial loss: 0.607640\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361687; batch adversarial loss: 0.499701\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386584; batch adversarial loss: 0.562287\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413111; batch adversarial loss: 0.572895\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359978; batch adversarial loss: 0.535939\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375786; batch adversarial loss: 0.553724\n",
      "epoch 187; iter: 0; batch classifier loss: 0.412839; batch adversarial loss: 0.465061\n",
      "epoch 188; iter: 0; batch classifier loss: 0.315277; batch adversarial loss: 0.562734\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373259; batch adversarial loss: 0.545072\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340053; batch adversarial loss: 0.597674\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320365; batch adversarial loss: 0.553378\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339885; batch adversarial loss: 0.536452\n",
      "epoch 193; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.499476\n",
      "epoch 194; iter: 0; batch classifier loss: 0.440375; batch adversarial loss: 0.544731\n",
      "epoch 195; iter: 0; batch classifier loss: 0.294550; batch adversarial loss: 0.516935\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322657; batch adversarial loss: 0.536486\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353750; batch adversarial loss: 0.534805\n",
      "epoch 198; iter: 0; batch classifier loss: 0.379824; batch adversarial loss: 0.507423\n",
      "epoch 199; iter: 0; batch classifier loss: 0.282314; batch adversarial loss: 0.517062\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683618; batch adversarial loss: 0.688269\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595851; batch adversarial loss: 0.670336\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585768; batch adversarial loss: 0.644476\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584720; batch adversarial loss: 0.616155\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586146; batch adversarial loss: 0.578718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598426; batch adversarial loss: 0.597157\n",
      "epoch 6; iter: 0; batch classifier loss: 0.500302; batch adversarial loss: 0.547933\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510719; batch adversarial loss: 0.617261\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464789; batch adversarial loss: 0.549867\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544444; batch adversarial loss: 0.600239\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513388; batch adversarial loss: 0.603356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.436213; batch adversarial loss: 0.605641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.563006; batch adversarial loss: 0.490946\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521881; batch adversarial loss: 0.574235\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509724; batch adversarial loss: 0.559105\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424121; batch adversarial loss: 0.625655\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464106; batch adversarial loss: 0.562359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507089; batch adversarial loss: 0.585077\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508280; batch adversarial loss: 0.567173\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473722; batch adversarial loss: 0.599089\n",
      "epoch 20; iter: 0; batch classifier loss: 0.443024; batch adversarial loss: 0.644044\n",
      "epoch 21; iter: 0; batch classifier loss: 0.554637; batch adversarial loss: 0.588048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507968; batch adversarial loss: 0.525838\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501219; batch adversarial loss: 0.599560\n",
      "epoch 24; iter: 0; batch classifier loss: 0.392474; batch adversarial loss: 0.529619\n",
      "epoch 25; iter: 0; batch classifier loss: 0.414452; batch adversarial loss: 0.498165\n",
      "epoch 26; iter: 0; batch classifier loss: 0.447807; batch adversarial loss: 0.460586\n",
      "epoch 27; iter: 0; batch classifier loss: 0.555787; batch adversarial loss: 0.556493\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421005; batch adversarial loss: 0.529375\n",
      "epoch 29; iter: 0; batch classifier loss: 0.513124; batch adversarial loss: 0.539591\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417766; batch adversarial loss: 0.550297\n",
      "epoch 31; iter: 0; batch classifier loss: 0.594492; batch adversarial loss: 0.488927\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435230; batch adversarial loss: 0.469091\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469654; batch adversarial loss: 0.589986\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412309; batch adversarial loss: 0.601155\n",
      "epoch 35; iter: 0; batch classifier loss: 0.573307; batch adversarial loss: 0.504046\n",
      "epoch 36; iter: 0; batch classifier loss: 0.552004; batch adversarial loss: 0.592244\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463861; batch adversarial loss: 0.528003\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437729; batch adversarial loss: 0.572650\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503913; batch adversarial loss: 0.607804\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446911; batch adversarial loss: 0.623959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464047; batch adversarial loss: 0.590040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445166; batch adversarial loss: 0.534719\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483278; batch adversarial loss: 0.591165\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481424; batch adversarial loss: 0.479657\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420749; batch adversarial loss: 0.562564\n",
      "epoch 46; iter: 0; batch classifier loss: 0.473529; batch adversarial loss: 0.534854\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485347; batch adversarial loss: 0.488575\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412467; batch adversarial loss: 0.488859\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460347; batch adversarial loss: 0.535860\n",
      "epoch 50; iter: 0; batch classifier loss: 0.447514; batch adversarial loss: 0.562065\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433404; batch adversarial loss: 0.516871\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385888; batch adversarial loss: 0.563233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.517022; batch adversarial loss: 0.572351\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415759; batch adversarial loss: 0.535002\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387511; batch adversarial loss: 0.489997\n",
      "epoch 56; iter: 0; batch classifier loss: 0.369667; batch adversarial loss: 0.582401\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414375; batch adversarial loss: 0.480352\n",
      "epoch 58; iter: 0; batch classifier loss: 0.371164; batch adversarial loss: 0.442686\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476062; batch adversarial loss: 0.525493\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452033; batch adversarial loss: 0.479570\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455318; batch adversarial loss: 0.516230\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438574; batch adversarial loss: 0.481376\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447259; batch adversarial loss: 0.526053\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409600; batch adversarial loss: 0.619608\n",
      "epoch 65; iter: 0; batch classifier loss: 0.354900; batch adversarial loss: 0.487444\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453563; batch adversarial loss: 0.591557\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435594; batch adversarial loss: 0.525879\n",
      "epoch 68; iter: 0; batch classifier loss: 0.370473; batch adversarial loss: 0.454523\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373472; batch adversarial loss: 0.553283\n",
      "epoch 70; iter: 0; batch classifier loss: 0.440003; batch adversarial loss: 0.598522\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412822; batch adversarial loss: 0.591018\n",
      "epoch 72; iter: 0; batch classifier loss: 0.508216; batch adversarial loss: 0.544998\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409782; batch adversarial loss: 0.665366\n",
      "epoch 74; iter: 0; batch classifier loss: 0.366429; batch adversarial loss: 0.497864\n",
      "epoch 75; iter: 0; batch classifier loss: 0.374688; batch adversarial loss: 0.600610\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413092; batch adversarial loss: 0.449916\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442795; batch adversarial loss: 0.619202\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378705; batch adversarial loss: 0.553222\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406965; batch adversarial loss: 0.507728\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441368; batch adversarial loss: 0.582420\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368129; batch adversarial loss: 0.508706\n",
      "epoch 82; iter: 0; batch classifier loss: 0.341224; batch adversarial loss: 0.509022\n",
      "epoch 83; iter: 0; batch classifier loss: 0.438675; batch adversarial loss: 0.592823\n",
      "epoch 84; iter: 0; batch classifier loss: 0.452460; batch adversarial loss: 0.507495\n",
      "epoch 85; iter: 0; batch classifier loss: 0.335242; batch adversarial loss: 0.638409\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382347; batch adversarial loss: 0.517563\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397538; batch adversarial loss: 0.591373\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386191; batch adversarial loss: 0.580078\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362366; batch adversarial loss: 0.544155\n",
      "epoch 90; iter: 0; batch classifier loss: 0.314253; batch adversarial loss: 0.526267\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455594; batch adversarial loss: 0.572733\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367703; batch adversarial loss: 0.478389\n",
      "epoch 93; iter: 0; batch classifier loss: 0.335197; batch adversarial loss: 0.610558\n",
      "epoch 94; iter: 0; batch classifier loss: 0.355391; batch adversarial loss: 0.497086\n",
      "epoch 95; iter: 0; batch classifier loss: 0.492998; batch adversarial loss: 0.591697\n",
      "epoch 96; iter: 0; batch classifier loss: 0.342114; batch adversarial loss: 0.553436\n",
      "epoch 97; iter: 0; batch classifier loss: 0.450488; batch adversarial loss: 0.498289\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388002; batch adversarial loss: 0.590905\n",
      "epoch 99; iter: 0; batch classifier loss: 0.462740; batch adversarial loss: 0.478519\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376108; batch adversarial loss: 0.553044\n",
      "epoch 101; iter: 0; batch classifier loss: 0.346027; batch adversarial loss: 0.581285\n",
      "epoch 102; iter: 0; batch classifier loss: 0.324850; batch adversarial loss: 0.582585\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386075; batch adversarial loss: 0.500232\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408443; batch adversarial loss: 0.489971\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410977; batch adversarial loss: 0.450119\n",
      "epoch 106; iter: 0; batch classifier loss: 0.425698; batch adversarial loss: 0.502168\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378497; batch adversarial loss: 0.600502\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403917; batch adversarial loss: 0.562310\n",
      "epoch 109; iter: 0; batch classifier loss: 0.324977; batch adversarial loss: 0.525840\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402388; batch adversarial loss: 0.433956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.413749; batch adversarial loss: 0.461132\n",
      "epoch 112; iter: 0; batch classifier loss: 0.399705; batch adversarial loss: 0.479453\n",
      "epoch 113; iter: 0; batch classifier loss: 0.453881; batch adversarial loss: 0.536681\n",
      "epoch 114; iter: 0; batch classifier loss: 0.339688; batch adversarial loss: 0.515686\n",
      "epoch 115; iter: 0; batch classifier loss: 0.450020; batch adversarial loss: 0.535424\n",
      "epoch 116; iter: 0; batch classifier loss: 0.478676; batch adversarial loss: 0.551542\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407917; batch adversarial loss: 0.598449\n",
      "epoch 118; iter: 0; batch classifier loss: 0.426019; batch adversarial loss: 0.552890\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347456; batch adversarial loss: 0.610707\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328611; batch adversarial loss: 0.560588\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376758; batch adversarial loss: 0.498639\n",
      "epoch 122; iter: 0; batch classifier loss: 0.341545; batch adversarial loss: 0.544889\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356227; batch adversarial loss: 0.608055\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401207; batch adversarial loss: 0.602794\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392032; batch adversarial loss: 0.452748\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362377; batch adversarial loss: 0.515953\n",
      "epoch 127; iter: 0; batch classifier loss: 0.313087; batch adversarial loss: 0.525389\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404404; batch adversarial loss: 0.525841\n",
      "epoch 129; iter: 0; batch classifier loss: 0.345148; batch adversarial loss: 0.525532\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325891; batch adversarial loss: 0.506038\n",
      "epoch 131; iter: 0; batch classifier loss: 0.474728; batch adversarial loss: 0.533963\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330483; batch adversarial loss: 0.544606\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354100; batch adversarial loss: 0.544032\n",
      "epoch 134; iter: 0; batch classifier loss: 0.275543; batch adversarial loss: 0.553289\n",
      "epoch 135; iter: 0; batch classifier loss: 0.359945; batch adversarial loss: 0.499057\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336433; batch adversarial loss: 0.564594\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343760; batch adversarial loss: 0.523132\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373044; batch adversarial loss: 0.570321\n",
      "epoch 139; iter: 0; batch classifier loss: 0.400106; batch adversarial loss: 0.570908\n",
      "epoch 140; iter: 0; batch classifier loss: 0.275166; batch adversarial loss: 0.573236\n",
      "epoch 141; iter: 0; batch classifier loss: 0.426427; batch adversarial loss: 0.601742\n",
      "epoch 142; iter: 0; batch classifier loss: 0.359798; batch adversarial loss: 0.508140\n",
      "epoch 143; iter: 0; batch classifier loss: 0.435174; batch adversarial loss: 0.582489\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342397; batch adversarial loss: 0.658777\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347883; batch adversarial loss: 0.572713\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396344; batch adversarial loss: 0.507215\n",
      "epoch 147; iter: 0; batch classifier loss: 0.430481; batch adversarial loss: 0.578954\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371840; batch adversarial loss: 0.525442\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413408; batch adversarial loss: 0.463034\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311359; batch adversarial loss: 0.618226\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361937; batch adversarial loss: 0.580666\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380011; batch adversarial loss: 0.571978\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327110; batch adversarial loss: 0.495725\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363684; batch adversarial loss: 0.498545\n",
      "epoch 155; iter: 0; batch classifier loss: 0.328143; batch adversarial loss: 0.572882\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340163; batch adversarial loss: 0.507279\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363310; batch adversarial loss: 0.543690\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380348; batch adversarial loss: 0.535161\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371105; batch adversarial loss: 0.600644\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307889; batch adversarial loss: 0.561257\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316144; batch adversarial loss: 0.470555\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358472; batch adversarial loss: 0.544388\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397218; batch adversarial loss: 0.460546\n",
      "epoch 164; iter: 0; batch classifier loss: 0.437540; batch adversarial loss: 0.535871\n",
      "epoch 165; iter: 0; batch classifier loss: 0.414697; batch adversarial loss: 0.525600\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404607; batch adversarial loss: 0.600025\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342215; batch adversarial loss: 0.536271\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361841; batch adversarial loss: 0.570089\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302214; batch adversarial loss: 0.517139\n",
      "epoch 170; iter: 0; batch classifier loss: 0.309076; batch adversarial loss: 0.562741\n",
      "epoch 171; iter: 0; batch classifier loss: 0.429446; batch adversarial loss: 0.489783\n",
      "epoch 172; iter: 0; batch classifier loss: 0.415845; batch adversarial loss: 0.580107\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356058; batch adversarial loss: 0.526601\n",
      "epoch 174; iter: 0; batch classifier loss: 0.457010; batch adversarial loss: 0.582572\n",
      "epoch 175; iter: 0; batch classifier loss: 0.475286; batch adversarial loss: 0.555994\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336370; batch adversarial loss: 0.590533\n",
      "epoch 177; iter: 0; batch classifier loss: 0.441559; batch adversarial loss: 0.591291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357276; batch adversarial loss: 0.470021\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394636; batch adversarial loss: 0.527264\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369693; batch adversarial loss: 0.423150\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336077; batch adversarial loss: 0.517640\n",
      "epoch 182; iter: 0; batch classifier loss: 0.452578; batch adversarial loss: 0.526624\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345897; batch adversarial loss: 0.626831\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416153; batch adversarial loss: 0.553971\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303399; batch adversarial loss: 0.553700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.403007; batch adversarial loss: 0.543924\n",
      "epoch 187; iter: 0; batch classifier loss: 0.468095; batch adversarial loss: 0.545654\n",
      "epoch 188; iter: 0; batch classifier loss: 0.315398; batch adversarial loss: 0.592389\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342662; batch adversarial loss: 0.495092\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338779; batch adversarial loss: 0.561359\n",
      "epoch 191; iter: 0; batch classifier loss: 0.478538; batch adversarial loss: 0.526228\n",
      "epoch 192; iter: 0; batch classifier loss: 0.415638; batch adversarial loss: 0.542674\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375024; batch adversarial loss: 0.552856\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360139; batch adversarial loss: 0.517073\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365641; batch adversarial loss: 0.610096\n",
      "epoch 196; iter: 0; batch classifier loss: 0.303260; batch adversarial loss: 0.561479\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388965; batch adversarial loss: 0.505449\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381663; batch adversarial loss: 0.507048\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335674; batch adversarial loss: 0.563875\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663807; batch adversarial loss: 0.672359\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580119; batch adversarial loss: 0.665059\n",
      "epoch 2; iter: 0; batch classifier loss: 0.638584; batch adversarial loss: 0.649386\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562084; batch adversarial loss: 0.654184\n",
      "epoch 4; iter: 0; batch classifier loss: 0.629274; batch adversarial loss: 0.628248\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596560; batch adversarial loss: 0.606662\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595233; batch adversarial loss: 0.617018\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528143; batch adversarial loss: 0.579776\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503538; batch adversarial loss: 0.608545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.530185; batch adversarial loss: 0.598737\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586408; batch adversarial loss: 0.564200\n",
      "epoch 11; iter: 0; batch classifier loss: 0.608651; batch adversarial loss: 0.592903\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516286; batch adversarial loss: 0.580872\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510973; batch adversarial loss: 0.544539\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406182; batch adversarial loss: 0.528552\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543104; batch adversarial loss: 0.485588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507026; batch adversarial loss: 0.565974\n",
      "epoch 17; iter: 0; batch classifier loss: 0.449577; batch adversarial loss: 0.470080\n",
      "epoch 18; iter: 0; batch classifier loss: 0.598530; batch adversarial loss: 0.608102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451498; batch adversarial loss: 0.630960\n",
      "epoch 20; iter: 0; batch classifier loss: 0.605814; batch adversarial loss: 0.592134\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478548; batch adversarial loss: 0.587034\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509381; batch adversarial loss: 0.544542\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460097; batch adversarial loss: 0.551250\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442424; batch adversarial loss: 0.555721\n",
      "epoch 25; iter: 0; batch classifier loss: 0.395470; batch adversarial loss: 0.515654\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444450; batch adversarial loss: 0.553563\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476925; batch adversarial loss: 0.587319\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494949; batch adversarial loss: 0.541716\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438401; batch adversarial loss: 0.537067\n",
      "epoch 30; iter: 0; batch classifier loss: 0.534200; batch adversarial loss: 0.578681\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456216; batch adversarial loss: 0.554580\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466601; batch adversarial loss: 0.552342\n",
      "epoch 33; iter: 0; batch classifier loss: 0.545680; batch adversarial loss: 0.544086\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472515; batch adversarial loss: 0.589227\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474491; batch adversarial loss: 0.562604\n",
      "epoch 36; iter: 0; batch classifier loss: 0.380925; batch adversarial loss: 0.500282\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426664; batch adversarial loss: 0.543613\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408589; batch adversarial loss: 0.543780\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430749; batch adversarial loss: 0.525666\n",
      "epoch 40; iter: 0; batch classifier loss: 0.386050; batch adversarial loss: 0.573036\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423555; batch adversarial loss: 0.637204\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484764; batch adversarial loss: 0.535345\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465782; batch adversarial loss: 0.535129\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406002; batch adversarial loss: 0.591022\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417294; batch adversarial loss: 0.434080\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497541; batch adversarial loss: 0.562998\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487789; batch adversarial loss: 0.534920\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401285; batch adversarial loss: 0.515671\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387928; batch adversarial loss: 0.544414\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498573; batch adversarial loss: 0.433168\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448622; batch adversarial loss: 0.571700\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451051; batch adversarial loss: 0.526737\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402084; batch adversarial loss: 0.497274\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422660; batch adversarial loss: 0.469952\n",
      "epoch 55; iter: 0; batch classifier loss: 0.380595; batch adversarial loss: 0.534522\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420283; batch adversarial loss: 0.563353\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463148; batch adversarial loss: 0.536301\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439906; batch adversarial loss: 0.488157\n",
      "epoch 59; iter: 0; batch classifier loss: 0.471529; batch adversarial loss: 0.574077\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481772; batch adversarial loss: 0.553647\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409870; batch adversarial loss: 0.554880\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459102; batch adversarial loss: 0.581451\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424116; batch adversarial loss: 0.524545\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436545; batch adversarial loss: 0.524637\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387270; batch adversarial loss: 0.591238\n",
      "epoch 66; iter: 0; batch classifier loss: 0.509521; batch adversarial loss: 0.534108\n",
      "epoch 67; iter: 0; batch classifier loss: 0.357658; batch adversarial loss: 0.601180\n",
      "epoch 68; iter: 0; batch classifier loss: 0.361263; batch adversarial loss: 0.562877\n",
      "epoch 69; iter: 0; batch classifier loss: 0.456634; batch adversarial loss: 0.590338\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406829; batch adversarial loss: 0.582417\n",
      "epoch 71; iter: 0; batch classifier loss: 0.367778; batch adversarial loss: 0.525774\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427230; batch adversarial loss: 0.516336\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388361; batch adversarial loss: 0.562460\n",
      "epoch 74; iter: 0; batch classifier loss: 0.377384; batch adversarial loss: 0.544405\n",
      "epoch 75; iter: 0; batch classifier loss: 0.458497; batch adversarial loss: 0.524591\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411837; batch adversarial loss: 0.573540\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355665; batch adversarial loss: 0.665714\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369834; batch adversarial loss: 0.525644\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370533; batch adversarial loss: 0.564009\n",
      "epoch 80; iter: 0; batch classifier loss: 0.444765; batch adversarial loss: 0.609486\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358211; batch adversarial loss: 0.562296\n",
      "epoch 82; iter: 0; batch classifier loss: 0.511738; batch adversarial loss: 0.579754\n",
      "epoch 83; iter: 0; batch classifier loss: 0.354611; batch adversarial loss: 0.610897\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415396; batch adversarial loss: 0.507510\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419671; batch adversarial loss: 0.535406\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378847; batch adversarial loss: 0.553505\n",
      "epoch 87; iter: 0; batch classifier loss: 0.425844; batch adversarial loss: 0.515872\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363296; batch adversarial loss: 0.611105\n",
      "epoch 89; iter: 0; batch classifier loss: 0.306629; batch adversarial loss: 0.619550\n",
      "epoch 90; iter: 0; batch classifier loss: 0.329176; batch adversarial loss: 0.545411\n",
      "epoch 91; iter: 0; batch classifier loss: 0.392460; batch adversarial loss: 0.573574\n",
      "epoch 92; iter: 0; batch classifier loss: 0.474437; batch adversarial loss: 0.495907\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370431; batch adversarial loss: 0.573660\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365254; batch adversarial loss: 0.535118\n",
      "epoch 95; iter: 0; batch classifier loss: 0.323823; batch adversarial loss: 0.564364\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359493; batch adversarial loss: 0.552531\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392619; batch adversarial loss: 0.516009\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359066; batch adversarial loss: 0.552821\n",
      "epoch 99; iter: 0; batch classifier loss: 0.462424; batch adversarial loss: 0.572225\n",
      "epoch 100; iter: 0; batch classifier loss: 0.297881; batch adversarial loss: 0.527323\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413429; batch adversarial loss: 0.525767\n",
      "epoch 102; iter: 0; batch classifier loss: 0.488057; batch adversarial loss: 0.526347\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416171; batch adversarial loss: 0.610410\n",
      "epoch 104; iter: 0; batch classifier loss: 0.357184; batch adversarial loss: 0.573721\n",
      "epoch 105; iter: 0; batch classifier loss: 0.354596; batch adversarial loss: 0.517554\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334076; batch adversarial loss: 0.609736\n",
      "epoch 107; iter: 0; batch classifier loss: 0.398072; batch adversarial loss: 0.414143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.365780; batch adversarial loss: 0.571472\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383775; batch adversarial loss: 0.541326\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396513; batch adversarial loss: 0.534549\n",
      "epoch 111; iter: 0; batch classifier loss: 0.330159; batch adversarial loss: 0.607640\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414290; batch adversarial loss: 0.524811\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370223; batch adversarial loss: 0.583745\n",
      "epoch 114; iter: 0; batch classifier loss: 0.414688; batch adversarial loss: 0.517868\n",
      "epoch 115; iter: 0; batch classifier loss: 0.464271; batch adversarial loss: 0.572006\n",
      "epoch 116; iter: 0; batch classifier loss: 0.386335; batch adversarial loss: 0.534745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389840; batch adversarial loss: 0.517186\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392689; batch adversarial loss: 0.536337\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441166; batch adversarial loss: 0.525317\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361425; batch adversarial loss: 0.516954\n",
      "epoch 121; iter: 0; batch classifier loss: 0.308571; batch adversarial loss: 0.535520\n",
      "epoch 122; iter: 0; batch classifier loss: 0.405193; batch adversarial loss: 0.600195\n",
      "epoch 123; iter: 0; batch classifier loss: 0.427167; batch adversarial loss: 0.563966\n",
      "epoch 124; iter: 0; batch classifier loss: 0.317367; batch adversarial loss: 0.535224\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384618; batch adversarial loss: 0.545676\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336905; batch adversarial loss: 0.543983\n",
      "epoch 127; iter: 0; batch classifier loss: 0.338131; batch adversarial loss: 0.554484\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356372; batch adversarial loss: 0.506120\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343308; batch adversarial loss: 0.488675\n",
      "epoch 130; iter: 0; batch classifier loss: 0.404958; batch adversarial loss: 0.525498\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400352; batch adversarial loss: 0.495543\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381921; batch adversarial loss: 0.563955\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370807; batch adversarial loss: 0.498882\n",
      "epoch 134; iter: 0; batch classifier loss: 0.410724; batch adversarial loss: 0.599642\n",
      "epoch 135; iter: 0; batch classifier loss: 0.355025; batch adversarial loss: 0.526603\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366608; batch adversarial loss: 0.581654\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351455; batch adversarial loss: 0.620641\n",
      "epoch 138; iter: 0; batch classifier loss: 0.421536; batch adversarial loss: 0.563614\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394788; batch adversarial loss: 0.591555\n",
      "epoch 140; iter: 0; batch classifier loss: 0.443165; batch adversarial loss: 0.489459\n",
      "epoch 141; iter: 0; batch classifier loss: 0.355716; batch adversarial loss: 0.536275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418910; batch adversarial loss: 0.628790\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373080; batch adversarial loss: 0.460822\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379935; batch adversarial loss: 0.497752\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369981; batch adversarial loss: 0.564145\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330982; batch adversarial loss: 0.487461\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368751; batch adversarial loss: 0.589864\n",
      "epoch 148; iter: 0; batch classifier loss: 0.377963; batch adversarial loss: 0.544535\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337689; batch adversarial loss: 0.496715\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409463; batch adversarial loss: 0.488820\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432496; batch adversarial loss: 0.514746\n",
      "epoch 152; iter: 0; batch classifier loss: 0.423111; batch adversarial loss: 0.515468\n",
      "epoch 153; iter: 0; batch classifier loss: 0.378516; batch adversarial loss: 0.534945\n",
      "epoch 154; iter: 0; batch classifier loss: 0.396282; batch adversarial loss: 0.544756\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365323; batch adversarial loss: 0.601498\n",
      "epoch 156; iter: 0; batch classifier loss: 0.458412; batch adversarial loss: 0.600502\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396918; batch adversarial loss: 0.544537\n",
      "epoch 158; iter: 0; batch classifier loss: 0.520692; batch adversarial loss: 0.573305\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359851; batch adversarial loss: 0.582985\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398491; batch adversarial loss: 0.525340\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380762; batch adversarial loss: 0.571299\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356409; batch adversarial loss: 0.600169\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367336; batch adversarial loss: 0.610361\n",
      "epoch 164; iter: 0; batch classifier loss: 0.475073; batch adversarial loss: 0.516733\n",
      "epoch 165; iter: 0; batch classifier loss: 0.310405; batch adversarial loss: 0.469108\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353407; batch adversarial loss: 0.469302\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346227; batch adversarial loss: 0.422566\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306915; batch adversarial loss: 0.440616\n",
      "epoch 169; iter: 0; batch classifier loss: 0.361062; batch adversarial loss: 0.572947\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363371; batch adversarial loss: 0.524932\n",
      "epoch 171; iter: 0; batch classifier loss: 0.410915; batch adversarial loss: 0.553947\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388354; batch adversarial loss: 0.555620\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373729; batch adversarial loss: 0.507041\n",
      "epoch 174; iter: 0; batch classifier loss: 0.307001; batch adversarial loss: 0.580394\n",
      "epoch 175; iter: 0; batch classifier loss: 0.428264; batch adversarial loss: 0.555031\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395711; batch adversarial loss: 0.593551\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346397; batch adversarial loss: 0.515259\n",
      "epoch 178; iter: 0; batch classifier loss: 0.288898; batch adversarial loss: 0.574297\n",
      "epoch 179; iter: 0; batch classifier loss: 0.331721; batch adversarial loss: 0.562906\n",
      "epoch 180; iter: 0; batch classifier loss: 0.410004; batch adversarial loss: 0.555345\n",
      "epoch 181; iter: 0; batch classifier loss: 0.460359; batch adversarial loss: 0.496634\n",
      "epoch 182; iter: 0; batch classifier loss: 0.400378; batch adversarial loss: 0.506817\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304199; batch adversarial loss: 0.564956\n",
      "epoch 184; iter: 0; batch classifier loss: 0.407315; batch adversarial loss: 0.553378\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381855; batch adversarial loss: 0.507761\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333031; batch adversarial loss: 0.629705\n",
      "epoch 187; iter: 0; batch classifier loss: 0.288756; batch adversarial loss: 0.488171\n",
      "epoch 188; iter: 0; batch classifier loss: 0.437586; batch adversarial loss: 0.506157\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338075; batch adversarial loss: 0.553777\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336095; batch adversarial loss: 0.469772\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339321; batch adversarial loss: 0.572906\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344006; batch adversarial loss: 0.607488\n",
      "epoch 193; iter: 0; batch classifier loss: 0.293558; batch adversarial loss: 0.534686\n",
      "epoch 194; iter: 0; batch classifier loss: 0.425536; batch adversarial loss: 0.534976\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361231; batch adversarial loss: 0.609179\n",
      "epoch 196; iter: 0; batch classifier loss: 0.269751; batch adversarial loss: 0.506014\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412890; batch adversarial loss: 0.516870\n",
      "epoch 198; iter: 0; batch classifier loss: 0.455095; batch adversarial loss: 0.459860\n",
      "epoch 199; iter: 0; batch classifier loss: 0.268301; batch adversarial loss: 0.590465\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707239; batch adversarial loss: 0.863174\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575101; batch adversarial loss: 0.872787\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602134; batch adversarial loss: 0.805370\n",
      "epoch 3; iter: 0; batch classifier loss: 0.574513; batch adversarial loss: 0.712775\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542323; batch adversarial loss: 0.671091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.596951; batch adversarial loss: 0.646848\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517234; batch adversarial loss: 0.644580\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571154; batch adversarial loss: 0.667113\n",
      "epoch 8; iter: 0; batch classifier loss: 0.540323; batch adversarial loss: 0.639933\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538938; batch adversarial loss: 0.607322\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506538; batch adversarial loss: 0.639613\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560339; batch adversarial loss: 0.613209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542576; batch adversarial loss: 0.546295\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485891; batch adversarial loss: 0.569678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480431; batch adversarial loss: 0.537329\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452917; batch adversarial loss: 0.618233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531237; batch adversarial loss: 0.558523\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515815; batch adversarial loss: 0.569317\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500860; batch adversarial loss: 0.585501\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462661; batch adversarial loss: 0.544706\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529655; batch adversarial loss: 0.554220\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509201; batch adversarial loss: 0.592762\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500680; batch adversarial loss: 0.549002\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468738; batch adversarial loss: 0.511929\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463300; batch adversarial loss: 0.531670\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512646; batch adversarial loss: 0.595066\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472129; batch adversarial loss: 0.567870\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461106; batch adversarial loss: 0.490641\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496038; batch adversarial loss: 0.543562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475001; batch adversarial loss: 0.563324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421942; batch adversarial loss: 0.561455\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496988; batch adversarial loss: 0.531371\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431462; batch adversarial loss: 0.476269\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474827; batch adversarial loss: 0.467387\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475821; batch adversarial loss: 0.555517\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440538; batch adversarial loss: 0.602759\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476123; batch adversarial loss: 0.646512\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466486; batch adversarial loss: 0.490154\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450375; batch adversarial loss: 0.593585\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440340; batch adversarial loss: 0.549019\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437647; batch adversarial loss: 0.583726\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431110; batch adversarial loss: 0.516615\n",
      "epoch 42; iter: 0; batch classifier loss: 0.430116; batch adversarial loss: 0.574839\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430629; batch adversarial loss: 0.559791\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460725; batch adversarial loss: 0.501868\n",
      "epoch 45; iter: 0; batch classifier loss: 0.452222; batch adversarial loss: 0.529316\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455986; batch adversarial loss: 0.563952\n",
      "epoch 47; iter: 0; batch classifier loss: 0.448639; batch adversarial loss: 0.588503\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411770; batch adversarial loss: 0.643354\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439987; batch adversarial loss: 0.528005\n",
      "epoch 50; iter: 0; batch classifier loss: 0.376404; batch adversarial loss: 0.563145\n",
      "epoch 51; iter: 0; batch classifier loss: 0.475605; batch adversarial loss: 0.471359\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414969; batch adversarial loss: 0.527964\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423140; batch adversarial loss: 0.552963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438766; batch adversarial loss: 0.543072\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480295; batch adversarial loss: 0.571157\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404721; batch adversarial loss: 0.573342\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490321; batch adversarial loss: 0.516297\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436460; batch adversarial loss: 0.496954\n",
      "epoch 59; iter: 0; batch classifier loss: 0.551195; batch adversarial loss: 0.514366\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467555; batch adversarial loss: 0.460421\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389093; batch adversarial loss: 0.646010\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426960; batch adversarial loss: 0.533735\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468251; batch adversarial loss: 0.628033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395554; batch adversarial loss: 0.580236\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375911; batch adversarial loss: 0.554177\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460083; batch adversarial loss: 0.480480\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384389; batch adversarial loss: 0.480693\n",
      "epoch 68; iter: 0; batch classifier loss: 0.490235; batch adversarial loss: 0.550532\n",
      "epoch 69; iter: 0; batch classifier loss: 0.464334; batch adversarial loss: 0.526486\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427631; batch adversarial loss: 0.599120\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385349; batch adversarial loss: 0.571378\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462452; batch adversarial loss: 0.562855\n",
      "epoch 73; iter: 0; batch classifier loss: 0.475371; batch adversarial loss: 0.519312\n",
      "epoch 74; iter: 0; batch classifier loss: 0.421609; batch adversarial loss: 0.599610\n",
      "epoch 75; iter: 0; batch classifier loss: 0.480910; batch adversarial loss: 0.610381\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379253; batch adversarial loss: 0.554164\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412766; batch adversarial loss: 0.458997\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375476; batch adversarial loss: 0.562380\n",
      "epoch 79; iter: 0; batch classifier loss: 0.477721; batch adversarial loss: 0.478437\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422469; batch adversarial loss: 0.451823\n",
      "epoch 81; iter: 0; batch classifier loss: 0.449988; batch adversarial loss: 0.571281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414542; batch adversarial loss: 0.534414\n",
      "epoch 83; iter: 0; batch classifier loss: 0.287731; batch adversarial loss: 0.563967\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397171; batch adversarial loss: 0.606167\n",
      "epoch 85; iter: 0; batch classifier loss: 0.324998; batch adversarial loss: 0.580630\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417266; batch adversarial loss: 0.543763\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376065; batch adversarial loss: 0.599208\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398442; batch adversarial loss: 0.601205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368064; batch adversarial loss: 0.609629\n",
      "epoch 90; iter: 0; batch classifier loss: 0.447240; batch adversarial loss: 0.570789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396514; batch adversarial loss: 0.590736\n",
      "epoch 92; iter: 0; batch classifier loss: 0.523088; batch adversarial loss: 0.563949\n",
      "epoch 93; iter: 0; batch classifier loss: 0.329369; batch adversarial loss: 0.543820\n",
      "epoch 94; iter: 0; batch classifier loss: 0.399611; batch adversarial loss: 0.524104\n",
      "epoch 95; iter: 0; batch classifier loss: 0.455597; batch adversarial loss: 0.573402\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410352; batch adversarial loss: 0.563283\n",
      "epoch 97; iter: 0; batch classifier loss: 0.337932; batch adversarial loss: 0.527874\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385107; batch adversarial loss: 0.537079\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456652; batch adversarial loss: 0.553090\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421223; batch adversarial loss: 0.516490\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420938; batch adversarial loss: 0.487697\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398223; batch adversarial loss: 0.591468\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375198; batch adversarial loss: 0.489164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.383023; batch adversarial loss: 0.562138\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368473; batch adversarial loss: 0.497769\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357952; batch adversarial loss: 0.500178\n",
      "epoch 107; iter: 0; batch classifier loss: 0.360392; batch adversarial loss: 0.553402\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353657; batch adversarial loss: 0.581025\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403718; batch adversarial loss: 0.526505\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396717; batch adversarial loss: 0.423487\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386290; batch adversarial loss: 0.470913\n",
      "epoch 112; iter: 0; batch classifier loss: 0.460219; batch adversarial loss: 0.588858\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381188; batch adversarial loss: 0.552520\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386871; batch adversarial loss: 0.608639\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340191; batch adversarial loss: 0.534171\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347068; batch adversarial loss: 0.581461\n",
      "epoch 117; iter: 0; batch classifier loss: 0.331864; batch adversarial loss: 0.452709\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333919; batch adversarial loss: 0.674310\n",
      "epoch 119; iter: 0; batch classifier loss: 0.391767; batch adversarial loss: 0.553174\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367976; batch adversarial loss: 0.609583\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400196; batch adversarial loss: 0.535427\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399073; batch adversarial loss: 0.546291\n",
      "epoch 123; iter: 0; batch classifier loss: 0.406665; batch adversarial loss: 0.508309\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395839; batch adversarial loss: 0.554341\n",
      "epoch 125; iter: 0; batch classifier loss: 0.458619; batch adversarial loss: 0.553596\n",
      "epoch 126; iter: 0; batch classifier loss: 0.418693; batch adversarial loss: 0.525274\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417742; batch adversarial loss: 0.497471\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380697; batch adversarial loss: 0.508933\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369819; batch adversarial loss: 0.583140\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332515; batch adversarial loss: 0.590125\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373415; batch adversarial loss: 0.573011\n",
      "epoch 132; iter: 0; batch classifier loss: 0.466847; batch adversarial loss: 0.535952\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387799; batch adversarial loss: 0.479417\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379383; batch adversarial loss: 0.535804\n",
      "epoch 135; iter: 0; batch classifier loss: 0.407739; batch adversarial loss: 0.506486\n",
      "epoch 136; iter: 0; batch classifier loss: 0.415047; batch adversarial loss: 0.509391\n",
      "epoch 137; iter: 0; batch classifier loss: 0.408558; batch adversarial loss: 0.525254\n",
      "epoch 138; iter: 0; batch classifier loss: 0.432114; batch adversarial loss: 0.638053\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372484; batch adversarial loss: 0.580851\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383207; batch adversarial loss: 0.582239\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365283; batch adversarial loss: 0.441967\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391051; batch adversarial loss: 0.514800\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361829; batch adversarial loss: 0.508137\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331313; batch adversarial loss: 0.490378\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382185; batch adversarial loss: 0.490169\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332381; batch adversarial loss: 0.544322\n",
      "epoch 147; iter: 0; batch classifier loss: 0.308908; batch adversarial loss: 0.535362\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397416; batch adversarial loss: 0.536450\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344957; batch adversarial loss: 0.543717\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378506; batch adversarial loss: 0.562491\n",
      "epoch 151; iter: 0; batch classifier loss: 0.427781; batch adversarial loss: 0.607839\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332962; batch adversarial loss: 0.488673\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356998; batch adversarial loss: 0.565162\n",
      "epoch 154; iter: 0; batch classifier loss: 0.416619; batch adversarial loss: 0.589209\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394464; batch adversarial loss: 0.600218\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367042; batch adversarial loss: 0.590240\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298554; batch adversarial loss: 0.554352\n",
      "epoch 158; iter: 0; batch classifier loss: 0.335104; batch adversarial loss: 0.543249\n",
      "epoch 159; iter: 0; batch classifier loss: 0.355026; batch adversarial loss: 0.559298\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369180; batch adversarial loss: 0.527861\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.516686\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373274; batch adversarial loss: 0.608517\n",
      "epoch 163; iter: 0; batch classifier loss: 0.424910; batch adversarial loss: 0.452385\n",
      "epoch 164; iter: 0; batch classifier loss: 0.383286; batch adversarial loss: 0.563536\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385184; batch adversarial loss: 0.540979\n",
      "epoch 166; iter: 0; batch classifier loss: 0.418040; batch adversarial loss: 0.544114\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362369; batch adversarial loss: 0.469374\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395879; batch adversarial loss: 0.489244\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344322; batch adversarial loss: 0.525040\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380391; batch adversarial loss: 0.517077\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409429; batch adversarial loss: 0.537141\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334803; batch adversarial loss: 0.610812\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387059; batch adversarial loss: 0.526212\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376313; batch adversarial loss: 0.508710\n",
      "epoch 175; iter: 0; batch classifier loss: 0.406881; batch adversarial loss: 0.478144\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413089; batch adversarial loss: 0.615441\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363203; batch adversarial loss: 0.536016\n",
      "epoch 178; iter: 0; batch classifier loss: 0.306732; batch adversarial loss: 0.486732\n",
      "epoch 179; iter: 0; batch classifier loss: 0.292303; batch adversarial loss: 0.588064\n",
      "epoch 180; iter: 0; batch classifier loss: 0.420599; batch adversarial loss: 0.470046\n",
      "epoch 181; iter: 0; batch classifier loss: 0.419609; batch adversarial loss: 0.599882\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329500; batch adversarial loss: 0.552445\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343658; batch adversarial loss: 0.525248\n",
      "epoch 184; iter: 0; batch classifier loss: 0.448359; batch adversarial loss: 0.552299\n",
      "epoch 185; iter: 0; batch classifier loss: 0.302413; batch adversarial loss: 0.552336\n",
      "epoch 186; iter: 0; batch classifier loss: 0.286026; batch adversarial loss: 0.478209\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369051; batch adversarial loss: 0.601390\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391952; batch adversarial loss: 0.534226\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352031; batch adversarial loss: 0.517022\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347028; batch adversarial loss: 0.496464\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392247; batch adversarial loss: 0.609349\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355569; batch adversarial loss: 0.526220\n",
      "epoch 193; iter: 0; batch classifier loss: 0.413424; batch adversarial loss: 0.553137\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392945; batch adversarial loss: 0.526127\n",
      "epoch 195; iter: 0; batch classifier loss: 0.455010; batch adversarial loss: 0.581559\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403196; batch adversarial loss: 0.462984\n",
      "epoch 197; iter: 0; batch classifier loss: 0.424412; batch adversarial loss: 0.591356\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326271; batch adversarial loss: 0.589617\n",
      "epoch 199; iter: 0; batch classifier loss: 0.399064; batch adversarial loss: 0.569476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.718652; batch adversarial loss: 0.628702\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584144; batch adversarial loss: 0.628266\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551690; batch adversarial loss: 0.624554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.513744; batch adversarial loss: 0.616925\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555246; batch adversarial loss: 0.636156\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612517; batch adversarial loss: 0.646460\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536295; batch adversarial loss: 0.587100\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582111; batch adversarial loss: 0.587517\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551731; batch adversarial loss: 0.598697\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554311; batch adversarial loss: 0.644531\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542337; batch adversarial loss: 0.555744\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539482; batch adversarial loss: 0.521347\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532236; batch adversarial loss: 0.564833\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502518; batch adversarial loss: 0.631238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483899; batch adversarial loss: 0.568139\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530181; batch adversarial loss: 0.592935\n",
      "epoch 16; iter: 0; batch classifier loss: 0.544654; batch adversarial loss: 0.544450\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497004; batch adversarial loss: 0.586812\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484203; batch adversarial loss: 0.584431\n",
      "epoch 19; iter: 0; batch classifier loss: 0.560977; batch adversarial loss: 0.576716\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503258; batch adversarial loss: 0.616408\n",
      "epoch 21; iter: 0; batch classifier loss: 0.595316; batch adversarial loss: 0.597330\n",
      "epoch 22; iter: 0; batch classifier loss: 0.527260; batch adversarial loss: 0.557998\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502462; batch adversarial loss: 0.563615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505507; batch adversarial loss: 0.571843\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420809; batch adversarial loss: 0.545396\n",
      "epoch 26; iter: 0; batch classifier loss: 0.554752; batch adversarial loss: 0.571386\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463601; batch adversarial loss: 0.561165\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414240; batch adversarial loss: 0.533873\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502369; batch adversarial loss: 0.582104\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483492; batch adversarial loss: 0.472605\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489357; batch adversarial loss: 0.561083\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434173; batch adversarial loss: 0.443179\n",
      "epoch 33; iter: 0; batch classifier loss: 0.550737; batch adversarial loss: 0.534760\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473951; batch adversarial loss: 0.562401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465123; batch adversarial loss: 0.582306\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454155; batch adversarial loss: 0.521336\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499723; batch adversarial loss: 0.590185\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497473; batch adversarial loss: 0.591207\n",
      "epoch 39; iter: 0; batch classifier loss: 0.395508; batch adversarial loss: 0.496708\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477718; batch adversarial loss: 0.486408\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427779; batch adversarial loss: 0.490144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.442601; batch adversarial loss: 0.541382\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443013; batch adversarial loss: 0.510389\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449635; batch adversarial loss: 0.555392\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472391; batch adversarial loss: 0.515838\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436442; batch adversarial loss: 0.488679\n",
      "epoch 47; iter: 0; batch classifier loss: 0.495261; batch adversarial loss: 0.518324\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487920; batch adversarial loss: 0.468756\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456034; batch adversarial loss: 0.499438\n",
      "epoch 50; iter: 0; batch classifier loss: 0.475040; batch adversarial loss: 0.518684\n",
      "epoch 51; iter: 0; batch classifier loss: 0.352430; batch adversarial loss: 0.562383\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470023; batch adversarial loss: 0.469507\n",
      "epoch 53; iter: 0; batch classifier loss: 0.532463; batch adversarial loss: 0.553256\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408074; batch adversarial loss: 0.469377\n",
      "epoch 55; iter: 0; batch classifier loss: 0.474455; batch adversarial loss: 0.525212\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444372; batch adversarial loss: 0.535933\n",
      "epoch 57; iter: 0; batch classifier loss: 0.377560; batch adversarial loss: 0.593134\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400753; batch adversarial loss: 0.553991\n",
      "epoch 59; iter: 0; batch classifier loss: 0.346863; batch adversarial loss: 0.562932\n",
      "epoch 60; iter: 0; batch classifier loss: 0.488430; batch adversarial loss: 0.571326\n",
      "epoch 61; iter: 0; batch classifier loss: 0.465520; batch adversarial loss: 0.618319\n",
      "epoch 62; iter: 0; batch classifier loss: 0.324138; batch adversarial loss: 0.533642\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400731; batch adversarial loss: 0.433272\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401763; batch adversarial loss: 0.574412\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376373; batch adversarial loss: 0.564934\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386561; batch adversarial loss: 0.544761\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445501; batch adversarial loss: 0.506901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.479126; batch adversarial loss: 0.562605\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475180; batch adversarial loss: 0.545422\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411221; batch adversarial loss: 0.524816\n",
      "epoch 71; iter: 0; batch classifier loss: 0.383540; batch adversarial loss: 0.526978\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414546; batch adversarial loss: 0.544882\n",
      "epoch 73; iter: 0; batch classifier loss: 0.323178; batch adversarial loss: 0.525714\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403895; batch adversarial loss: 0.534467\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433259; batch adversarial loss: 0.565294\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405772; batch adversarial loss: 0.603309\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416759; batch adversarial loss: 0.507434\n",
      "epoch 78; iter: 0; batch classifier loss: 0.434870; batch adversarial loss: 0.636937\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375432; batch adversarial loss: 0.609916\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430128; batch adversarial loss: 0.582505\n",
      "epoch 81; iter: 0; batch classifier loss: 0.420085; batch adversarial loss: 0.552297\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368697; batch adversarial loss: 0.562255\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401644; batch adversarial loss: 0.532885\n",
      "epoch 84; iter: 0; batch classifier loss: 0.334503; batch adversarial loss: 0.486201\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405763; batch adversarial loss: 0.536414\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400222; batch adversarial loss: 0.506474\n",
      "epoch 87; iter: 0; batch classifier loss: 0.414166; batch adversarial loss: 0.526998\n",
      "epoch 88; iter: 0; batch classifier loss: 0.323056; batch adversarial loss: 0.608474\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436970; batch adversarial loss: 0.535651\n",
      "epoch 90; iter: 0; batch classifier loss: 0.335136; batch adversarial loss: 0.552082\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348487; batch adversarial loss: 0.470030\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428628; batch adversarial loss: 0.527012\n",
      "epoch 93; iter: 0; batch classifier loss: 0.306165; batch adversarial loss: 0.525405\n",
      "epoch 94; iter: 0; batch classifier loss: 0.409454; batch adversarial loss: 0.441765\n",
      "epoch 95; iter: 0; batch classifier loss: 0.433414; batch adversarial loss: 0.498001\n",
      "epoch 96; iter: 0; batch classifier loss: 0.480326; batch adversarial loss: 0.543536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359928; batch adversarial loss: 0.564344\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380143; batch adversarial loss: 0.507515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.414600; batch adversarial loss: 0.602066\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413480; batch adversarial loss: 0.533673\n",
      "epoch 101; iter: 0; batch classifier loss: 0.427921; batch adversarial loss: 0.499459\n",
      "epoch 102; iter: 0; batch classifier loss: 0.317784; batch adversarial loss: 0.592068\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379872; batch adversarial loss: 0.553082\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348110; batch adversarial loss: 0.618747\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373418; batch adversarial loss: 0.563704\n",
      "epoch 106; iter: 0; batch classifier loss: 0.341589; batch adversarial loss: 0.551277\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382584; batch adversarial loss: 0.440581\n",
      "epoch 108; iter: 0; batch classifier loss: 0.343093; batch adversarial loss: 0.619301\n",
      "epoch 109; iter: 0; batch classifier loss: 0.435043; batch adversarial loss: 0.562219\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372904; batch adversarial loss: 0.602210\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407306; batch adversarial loss: 0.524071\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365927; batch adversarial loss: 0.525254\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377146; batch adversarial loss: 0.477750\n",
      "epoch 114; iter: 0; batch classifier loss: 0.333879; batch adversarial loss: 0.515163\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354791; batch adversarial loss: 0.515255\n",
      "epoch 116; iter: 0; batch classifier loss: 0.411402; batch adversarial loss: 0.562141\n",
      "epoch 117; iter: 0; batch classifier loss: 0.495374; batch adversarial loss: 0.557061\n",
      "epoch 118; iter: 0; batch classifier loss: 0.443788; batch adversarial loss: 0.573580\n",
      "epoch 119; iter: 0; batch classifier loss: 0.329036; batch adversarial loss: 0.515908\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380064; batch adversarial loss: 0.536891\n",
      "epoch 121; iter: 0; batch classifier loss: 0.480087; batch adversarial loss: 0.618628\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358146; batch adversarial loss: 0.547548\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348193; batch adversarial loss: 0.489058\n",
      "epoch 124; iter: 0; batch classifier loss: 0.425642; batch adversarial loss: 0.553680\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370585; batch adversarial loss: 0.525560\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357640; batch adversarial loss: 0.523613\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350099; batch adversarial loss: 0.618722\n",
      "epoch 128; iter: 0; batch classifier loss: 0.363417; batch adversarial loss: 0.571468\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428115; batch adversarial loss: 0.507685\n",
      "epoch 130; iter: 0; batch classifier loss: 0.436411; batch adversarial loss: 0.543058\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335559; batch adversarial loss: 0.581122\n",
      "epoch 132; iter: 0; batch classifier loss: 0.386221; batch adversarial loss: 0.580495\n",
      "epoch 133; iter: 0; batch classifier loss: 0.436646; batch adversarial loss: 0.554729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.302814; batch adversarial loss: 0.543448\n",
      "epoch 135; iter: 0; batch classifier loss: 0.431748; batch adversarial loss: 0.516504\n",
      "epoch 136; iter: 0; batch classifier loss: 0.320745; batch adversarial loss: 0.592833\n",
      "epoch 137; iter: 0; batch classifier loss: 0.331240; batch adversarial loss: 0.506316\n",
      "epoch 138; iter: 0; batch classifier loss: 0.431052; batch adversarial loss: 0.572713\n",
      "epoch 139; iter: 0; batch classifier loss: 0.465026; batch adversarial loss: 0.554229\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357935; batch adversarial loss: 0.488969\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424360; batch adversarial loss: 0.599505\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383837; batch adversarial loss: 0.528052\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356017; batch adversarial loss: 0.458082\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367144; batch adversarial loss: 0.478980\n",
      "epoch 145; iter: 0; batch classifier loss: 0.442821; batch adversarial loss: 0.589743\n",
      "epoch 146; iter: 0; batch classifier loss: 0.291817; batch adversarial loss: 0.503894\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348365; batch adversarial loss: 0.516063\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337304; batch adversarial loss: 0.552504\n",
      "epoch 149; iter: 0; batch classifier loss: 0.441118; batch adversarial loss: 0.506193\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364092; batch adversarial loss: 0.498366\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337973; batch adversarial loss: 0.543612\n",
      "epoch 152; iter: 0; batch classifier loss: 0.425056; batch adversarial loss: 0.617119\n",
      "epoch 153; iter: 0; batch classifier loss: 0.443668; batch adversarial loss: 0.553164\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384333; batch adversarial loss: 0.553325\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413941; batch adversarial loss: 0.525561\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312422; batch adversarial loss: 0.525600\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313411; batch adversarial loss: 0.570967\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435666; batch adversarial loss: 0.488450\n",
      "epoch 159; iter: 0; batch classifier loss: 0.460710; batch adversarial loss: 0.544266\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364033; batch adversarial loss: 0.608172\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374209; batch adversarial loss: 0.498278\n",
      "epoch 162; iter: 0; batch classifier loss: 0.459065; batch adversarial loss: 0.580570\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379455; batch adversarial loss: 0.499138\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385157; batch adversarial loss: 0.507618\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369871; batch adversarial loss: 0.552439\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350559; batch adversarial loss: 0.551487\n",
      "epoch 167; iter: 0; batch classifier loss: 0.464037; batch adversarial loss: 0.524804\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342424; batch adversarial loss: 0.553112\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376965; batch adversarial loss: 0.628132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.316914; batch adversarial loss: 0.561314\n",
      "epoch 171; iter: 0; batch classifier loss: 0.476546; batch adversarial loss: 0.536645\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317594; batch adversarial loss: 0.534881\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386022; batch adversarial loss: 0.572818\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366036; batch adversarial loss: 0.600415\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402398; batch adversarial loss: 0.554752\n",
      "epoch 176; iter: 0; batch classifier loss: 0.359119; batch adversarial loss: 0.527381\n",
      "epoch 177; iter: 0; batch classifier loss: 0.446005; batch adversarial loss: 0.591129\n",
      "epoch 178; iter: 0; batch classifier loss: 0.292928; batch adversarial loss: 0.545899\n",
      "epoch 179; iter: 0; batch classifier loss: 0.418827; batch adversarial loss: 0.535870\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339320; batch adversarial loss: 0.543557\n",
      "epoch 181; iter: 0; batch classifier loss: 0.425856; batch adversarial loss: 0.554365\n",
      "epoch 182; iter: 0; batch classifier loss: 0.436433; batch adversarial loss: 0.619674\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338553; batch adversarial loss: 0.441803\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359375; batch adversarial loss: 0.488439\n",
      "epoch 185; iter: 0; batch classifier loss: 0.411153; batch adversarial loss: 0.552416\n",
      "epoch 186; iter: 0; batch classifier loss: 0.415147; batch adversarial loss: 0.599882\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367931; batch adversarial loss: 0.525529\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336527; batch adversarial loss: 0.591082\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383692; batch adversarial loss: 0.452170\n",
      "epoch 190; iter: 0; batch classifier loss: 0.409117; batch adversarial loss: 0.535689\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353354; batch adversarial loss: 0.535132\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388394; batch adversarial loss: 0.543213\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350802; batch adversarial loss: 0.536200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391139; batch adversarial loss: 0.564010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.328776; batch adversarial loss: 0.564015\n",
      "epoch 196; iter: 0; batch classifier loss: 0.393131; batch adversarial loss: 0.564484\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362895; batch adversarial loss: 0.571751\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331735; batch adversarial loss: 0.516797\n",
      "epoch 199; iter: 0; batch classifier loss: 0.444229; batch adversarial loss: 0.515369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671913; batch adversarial loss: 0.714924\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630471; batch adversarial loss: 0.765135\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542036; batch adversarial loss: 0.694280\n",
      "epoch 3; iter: 0; batch classifier loss: 0.545573; batch adversarial loss: 0.656869\n",
      "epoch 4; iter: 0; batch classifier loss: 0.483834; batch adversarial loss: 0.675649\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582923; batch adversarial loss: 0.631451\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551721; batch adversarial loss: 0.605025\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501513; batch adversarial loss: 0.544574\n",
      "epoch 8; iter: 0; batch classifier loss: 0.450475; batch adversarial loss: 0.556359\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510993; batch adversarial loss: 0.582285\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560159; batch adversarial loss: 0.587919\n",
      "epoch 11; iter: 0; batch classifier loss: 0.484121; batch adversarial loss: 0.630235\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521183; batch adversarial loss: 0.589989\n",
      "epoch 13; iter: 0; batch classifier loss: 0.470231; batch adversarial loss: 0.721176\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534848; batch adversarial loss: 0.552633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529652; batch adversarial loss: 0.620808\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492931; batch adversarial loss: 0.620762\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507679; batch adversarial loss: 0.592740\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449885; batch adversarial loss: 0.577174\n",
      "epoch 19; iter: 0; batch classifier loss: 0.575856; batch adversarial loss: 0.635572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548730; batch adversarial loss: 0.554477\n",
      "epoch 21; iter: 0; batch classifier loss: 0.506636; batch adversarial loss: 0.626474\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455713; batch adversarial loss: 0.583327\n",
      "epoch 23; iter: 0; batch classifier loss: 0.441626; batch adversarial loss: 0.544374\n",
      "epoch 24; iter: 0; batch classifier loss: 0.548739; batch adversarial loss: 0.601646\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428865; batch adversarial loss: 0.505167\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433436; batch adversarial loss: 0.553747\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468654; batch adversarial loss: 0.557370\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481134; batch adversarial loss: 0.561903\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445933; batch adversarial loss: 0.497202\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479544; batch adversarial loss: 0.552906\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453318; batch adversarial loss: 0.540930\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493702; batch adversarial loss: 0.518548\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456524; batch adversarial loss: 0.577499\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439803; batch adversarial loss: 0.605689\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478369; batch adversarial loss: 0.513956\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485576; batch adversarial loss: 0.488565\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499511; batch adversarial loss: 0.553179\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419268; batch adversarial loss: 0.519010\n",
      "epoch 39; iter: 0; batch classifier loss: 0.426134; batch adversarial loss: 0.503871\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489916; batch adversarial loss: 0.565462\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447633; batch adversarial loss: 0.639869\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462013; batch adversarial loss: 0.560534\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412118; batch adversarial loss: 0.544895\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389381; batch adversarial loss: 0.580297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430649; batch adversarial loss: 0.537225\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400987; batch adversarial loss: 0.553902\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415980; batch adversarial loss: 0.573051\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466885; batch adversarial loss: 0.499522\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438374; batch adversarial loss: 0.545962\n",
      "epoch 50; iter: 0; batch classifier loss: 0.490862; batch adversarial loss: 0.545005\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411146; batch adversarial loss: 0.498469\n",
      "epoch 52; iter: 0; batch classifier loss: 0.384634; batch adversarial loss: 0.572085\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445005; batch adversarial loss: 0.544792\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426872; batch adversarial loss: 0.534834\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458118; batch adversarial loss: 0.544401\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417826; batch adversarial loss: 0.545045\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458096; batch adversarial loss: 0.545263\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401077; batch adversarial loss: 0.609823\n",
      "epoch 59; iter: 0; batch classifier loss: 0.443550; batch adversarial loss: 0.553781\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409432; batch adversarial loss: 0.553592\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422080; batch adversarial loss: 0.480310\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440012; batch adversarial loss: 0.498027\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468148; batch adversarial loss: 0.497709\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442292; batch adversarial loss: 0.554571\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356703; batch adversarial loss: 0.515845\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414287; batch adversarial loss: 0.525519\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385495; batch adversarial loss: 0.432941\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415945; batch adversarial loss: 0.591344\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428176; batch adversarial loss: 0.516305\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352005; batch adversarial loss: 0.599287\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438852; batch adversarial loss: 0.486690\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347966; batch adversarial loss: 0.534652\n",
      "epoch 73; iter: 0; batch classifier loss: 0.413520; batch adversarial loss: 0.514991\n",
      "epoch 74; iter: 0; batch classifier loss: 0.450986; batch adversarial loss: 0.545097\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396097; batch adversarial loss: 0.516016\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335803; batch adversarial loss: 0.536783\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372318; batch adversarial loss: 0.496679\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409741; batch adversarial loss: 0.506597\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411684; batch adversarial loss: 0.542998\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429709; batch adversarial loss: 0.563209\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409954; batch adversarial loss: 0.495999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.434501; batch adversarial loss: 0.600817\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451997; batch adversarial loss: 0.546322\n",
      "epoch 84; iter: 0; batch classifier loss: 0.317896; batch adversarial loss: 0.525273\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401150; batch adversarial loss: 0.507604\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385137; batch adversarial loss: 0.524909\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386035; batch adversarial loss: 0.582219\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.589620\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422363; batch adversarial loss: 0.582428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.331327; batch adversarial loss: 0.488507\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454241; batch adversarial loss: 0.545505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.446619; batch adversarial loss: 0.601358\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364699; batch adversarial loss: 0.570826\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396749; batch adversarial loss: 0.579944\n",
      "epoch 95; iter: 0; batch classifier loss: 0.435911; batch adversarial loss: 0.489215\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405029; batch adversarial loss: 0.506022\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382527; batch adversarial loss: 0.517322\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390634; batch adversarial loss: 0.609612\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399257; batch adversarial loss: 0.581421\n",
      "epoch 100; iter: 0; batch classifier loss: 0.454417; batch adversarial loss: 0.535334\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397187; batch adversarial loss: 0.599953\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386953; batch adversarial loss: 0.562526\n",
      "epoch 103; iter: 0; batch classifier loss: 0.452771; batch adversarial loss: 0.525126\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386285; batch adversarial loss: 0.497039\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392166; batch adversarial loss: 0.523484\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376699; batch adversarial loss: 0.562136\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328978; batch adversarial loss: 0.580195\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417003; batch adversarial loss: 0.534703\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428207; batch adversarial loss: 0.545892\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439190; batch adversarial loss: 0.638461\n",
      "epoch 111; iter: 0; batch classifier loss: 0.437610; batch adversarial loss: 0.581513\n",
      "epoch 112; iter: 0; batch classifier loss: 0.342559; batch adversarial loss: 0.555024\n",
      "epoch 113; iter: 0; batch classifier loss: 0.317460; batch adversarial loss: 0.471481\n",
      "epoch 114; iter: 0; batch classifier loss: 0.440911; batch adversarial loss: 0.589353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332255; batch adversarial loss: 0.498674\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401112; batch adversarial loss: 0.562147\n",
      "epoch 117; iter: 0; batch classifier loss: 0.347220; batch adversarial loss: 0.534760\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360699; batch adversarial loss: 0.616387\n",
      "epoch 119; iter: 0; batch classifier loss: 0.424819; batch adversarial loss: 0.600839\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372216; batch adversarial loss: 0.543843\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362775; batch adversarial loss: 0.526718\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349313; batch adversarial loss: 0.581703\n",
      "epoch 123; iter: 0; batch classifier loss: 0.382323; batch adversarial loss: 0.553963\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360013; batch adversarial loss: 0.525828\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418385; batch adversarial loss: 0.516999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.288150; batch adversarial loss: 0.535664\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422912; batch adversarial loss: 0.507658\n",
      "epoch 128; iter: 0; batch classifier loss: 0.323969; batch adversarial loss: 0.497253\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380585; batch adversarial loss: 0.525756\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373507; batch adversarial loss: 0.610598\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382356; batch adversarial loss: 0.535508\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352660; batch adversarial loss: 0.497222\n",
      "epoch 133; iter: 0; batch classifier loss: 0.448941; batch adversarial loss: 0.572082\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375435; batch adversarial loss: 0.544590\n",
      "epoch 135; iter: 0; batch classifier loss: 0.355064; batch adversarial loss: 0.601366\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404739; batch adversarial loss: 0.508080\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370022; batch adversarial loss: 0.496371\n",
      "epoch 138; iter: 0; batch classifier loss: 0.315942; batch adversarial loss: 0.476230\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331428; batch adversarial loss: 0.488891\n",
      "epoch 140; iter: 0; batch classifier loss: 0.382372; batch adversarial loss: 0.503921\n",
      "epoch 141; iter: 0; batch classifier loss: 0.298465; batch adversarial loss: 0.591662\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410129; batch adversarial loss: 0.562906\n",
      "epoch 143; iter: 0; batch classifier loss: 0.347418; batch adversarial loss: 0.545561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.308110; batch adversarial loss: 0.563870\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383315; batch adversarial loss: 0.528704\n",
      "epoch 146; iter: 0; batch classifier loss: 0.477857; batch adversarial loss: 0.553074\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327766; batch adversarial loss: 0.518180\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353650; batch adversarial loss: 0.563345\n",
      "epoch 149; iter: 0; batch classifier loss: 0.393074; batch adversarial loss: 0.591915\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381489; batch adversarial loss: 0.618235\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325954; batch adversarial loss: 0.526413\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372714; batch adversarial loss: 0.608280\n",
      "epoch 153; iter: 0; batch classifier loss: 0.437884; batch adversarial loss: 0.608676\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349078; batch adversarial loss: 0.571726\n",
      "epoch 155; iter: 0; batch classifier loss: 0.426195; batch adversarial loss: 0.545664\n",
      "epoch 156; iter: 0; batch classifier loss: 0.432969; batch adversarial loss: 0.544002\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378869; batch adversarial loss: 0.507356\n",
      "epoch 158; iter: 0; batch classifier loss: 0.409370; batch adversarial loss: 0.544369\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347099; batch adversarial loss: 0.563070\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395645; batch adversarial loss: 0.562746\n",
      "epoch 161; iter: 0; batch classifier loss: 0.442194; batch adversarial loss: 0.618501\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355026; batch adversarial loss: 0.544602\n",
      "epoch 163; iter: 0; batch classifier loss: 0.407209; batch adversarial loss: 0.497801\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345878; batch adversarial loss: 0.516776\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329158; batch adversarial loss: 0.534646\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370056; batch adversarial loss: 0.508220\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323427; batch adversarial loss: 0.489651\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378668; batch adversarial loss: 0.471146\n",
      "epoch 169; iter: 0; batch classifier loss: 0.310849; batch adversarial loss: 0.516811\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368730; batch adversarial loss: 0.516717\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401289; batch adversarial loss: 0.553460\n",
      "epoch 172; iter: 0; batch classifier loss: 0.401726; batch adversarial loss: 0.544132\n",
      "epoch 173; iter: 0; batch classifier loss: 0.405403; batch adversarial loss: 0.516378\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373430; batch adversarial loss: 0.592000\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383606; batch adversarial loss: 0.543982\n",
      "epoch 176; iter: 0; batch classifier loss: 0.276228; batch adversarial loss: 0.526456\n",
      "epoch 177; iter: 0; batch classifier loss: 0.402325; batch adversarial loss: 0.581464\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295044; batch adversarial loss: 0.553743\n",
      "epoch 179; iter: 0; batch classifier loss: 0.401280; batch adversarial loss: 0.526278\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354219; batch adversarial loss: 0.488344\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330858; batch adversarial loss: 0.656134\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391236; batch adversarial loss: 0.570129\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342595; batch adversarial loss: 0.617203\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317372; batch adversarial loss: 0.486318\n",
      "epoch 185; iter: 0; batch classifier loss: 0.329496; batch adversarial loss: 0.563630\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371415; batch adversarial loss: 0.619419\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358594; batch adversarial loss: 0.591598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.483779; batch adversarial loss: 0.487483\n",
      "epoch 189; iter: 0; batch classifier loss: 0.310235; batch adversarial loss: 0.525545\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345567; batch adversarial loss: 0.520735\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432722; batch adversarial loss: 0.565545\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354223; batch adversarial loss: 0.554569\n",
      "epoch 193; iter: 0; batch classifier loss: 0.391014; batch adversarial loss: 0.499471\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407505; batch adversarial loss: 0.554153\n",
      "epoch 195; iter: 0; batch classifier loss: 0.419461; batch adversarial loss: 0.462476\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378149; batch adversarial loss: 0.536636\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412921; batch adversarial loss: 0.545064\n",
      "epoch 198; iter: 0; batch classifier loss: 0.443987; batch adversarial loss: 0.581333\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306926; batch adversarial loss: 0.480303\n",
      "epoch 0; iter: 0; batch classifier loss: 0.633288; batch adversarial loss: 0.636182\n",
      "epoch 1; iter: 0; batch classifier loss: 0.663988; batch adversarial loss: 0.625700\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556721; batch adversarial loss: 0.609513\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497238; batch adversarial loss: 0.641167\n",
      "epoch 4; iter: 0; batch classifier loss: 0.647970; batch adversarial loss: 0.586310\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554287; batch adversarial loss: 0.611626\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538769; batch adversarial loss: 0.595625\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604210; batch adversarial loss: 0.586734\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575154; batch adversarial loss: 0.627877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564918; batch adversarial loss: 0.610178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517580; batch adversarial loss: 0.605950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536489; batch adversarial loss: 0.600791\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520420; batch adversarial loss: 0.583196\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583187; batch adversarial loss: 0.593328\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533185; batch adversarial loss: 0.579697\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529241; batch adversarial loss: 0.561997\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554594; batch adversarial loss: 0.492866\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509541; batch adversarial loss: 0.501213\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528463; batch adversarial loss: 0.567471\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497035; batch adversarial loss: 0.576805\n",
      "epoch 20; iter: 0; batch classifier loss: 0.459351; batch adversarial loss: 0.561184\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514843; batch adversarial loss: 0.560535\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517453; batch adversarial loss: 0.601139\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489214; batch adversarial loss: 0.570818\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516093; batch adversarial loss: 0.591235\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468467; batch adversarial loss: 0.468088\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505637; batch adversarial loss: 0.578662\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501925; batch adversarial loss: 0.507446\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446915; batch adversarial loss: 0.493660\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463946; batch adversarial loss: 0.494520\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455302; batch adversarial loss: 0.536093\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511280; batch adversarial loss: 0.562456\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425210; batch adversarial loss: 0.544475\n",
      "epoch 33; iter: 0; batch classifier loss: 0.394537; batch adversarial loss: 0.587835\n",
      "epoch 34; iter: 0; batch classifier loss: 0.442000; batch adversarial loss: 0.579750\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397633; batch adversarial loss: 0.589603\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436686; batch adversarial loss: 0.536008\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455221; batch adversarial loss: 0.553664\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482125; batch adversarial loss: 0.544252\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431228; batch adversarial loss: 0.471332\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450650; batch adversarial loss: 0.589977\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451175; batch adversarial loss: 0.571868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.473783; batch adversarial loss: 0.507853\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450912; batch adversarial loss: 0.553664\n",
      "epoch 44; iter: 0; batch classifier loss: 0.515559; batch adversarial loss: 0.562406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506488; batch adversarial loss: 0.516673\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396358; batch adversarial loss: 0.517049\n",
      "epoch 47; iter: 0; batch classifier loss: 0.500133; batch adversarial loss: 0.488392\n",
      "epoch 48; iter: 0; batch classifier loss: 0.374358; batch adversarial loss: 0.544498\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398260; batch adversarial loss: 0.526013\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449888; batch adversarial loss: 0.535414\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455824; batch adversarial loss: 0.535047\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462687; batch adversarial loss: 0.562716\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471002; batch adversarial loss: 0.507102\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463033; batch adversarial loss: 0.581218\n",
      "epoch 55; iter: 0; batch classifier loss: 0.457363; batch adversarial loss: 0.544072\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446211; batch adversarial loss: 0.525620\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414866; batch adversarial loss: 0.647127\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429271; batch adversarial loss: 0.469894\n",
      "epoch 59; iter: 0; batch classifier loss: 0.453163; batch adversarial loss: 0.479595\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407509; batch adversarial loss: 0.460979\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420888; batch adversarial loss: 0.572703\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388806; batch adversarial loss: 0.544747\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379934; batch adversarial loss: 0.470605\n",
      "epoch 64; iter: 0; batch classifier loss: 0.500011; batch adversarial loss: 0.553411\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382369; batch adversarial loss: 0.488658\n",
      "epoch 66; iter: 0; batch classifier loss: 0.462363; batch adversarial loss: 0.563550\n",
      "epoch 67; iter: 0; batch classifier loss: 0.372946; batch adversarial loss: 0.563148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.440731; batch adversarial loss: 0.525906\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401065; batch adversarial loss: 0.572911\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429033; batch adversarial loss: 0.553926\n",
      "epoch 71; iter: 0; batch classifier loss: 0.472597; batch adversarial loss: 0.451522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414202; batch adversarial loss: 0.526082\n",
      "epoch 73; iter: 0; batch classifier loss: 0.319290; batch adversarial loss: 0.590900\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384143; batch adversarial loss: 0.535412\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436409; batch adversarial loss: 0.610166\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409402; batch adversarial loss: 0.544344\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379650; batch adversarial loss: 0.572566\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377181; batch adversarial loss: 0.497857\n",
      "epoch 79; iter: 0; batch classifier loss: 0.451024; batch adversarial loss: 0.516010\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399325; batch adversarial loss: 0.507499\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382607; batch adversarial loss: 0.516964\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380431; batch adversarial loss: 0.525302\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407773; batch adversarial loss: 0.516266\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386711; batch adversarial loss: 0.554318\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390876; batch adversarial loss: 0.516448\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364616; batch adversarial loss: 0.544520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.483616; batch adversarial loss: 0.460696\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357395; batch adversarial loss: 0.554081\n",
      "epoch 89; iter: 0; batch classifier loss: 0.330898; batch adversarial loss: 0.628890\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362521; batch adversarial loss: 0.655284\n",
      "epoch 91; iter: 0; batch classifier loss: 0.337781; batch adversarial loss: 0.544303\n",
      "epoch 92; iter: 0; batch classifier loss: 0.317001; batch adversarial loss: 0.590600\n",
      "epoch 93; iter: 0; batch classifier loss: 0.396818; batch adversarial loss: 0.572232\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401867; batch adversarial loss: 0.590162\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396562; batch adversarial loss: 0.498631\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389665; batch adversarial loss: 0.534726\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391240; batch adversarial loss: 0.617368\n",
      "epoch 98; iter: 0; batch classifier loss: 0.353662; batch adversarial loss: 0.507230\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446393; batch adversarial loss: 0.643209\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401954; batch adversarial loss: 0.526554\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408806; batch adversarial loss: 0.544153\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372073; batch adversarial loss: 0.562558\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375536; batch adversarial loss: 0.552307\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368359; batch adversarial loss: 0.605203\n",
      "epoch 105; iter: 0; batch classifier loss: 0.493002; batch adversarial loss: 0.513493\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398509; batch adversarial loss: 0.547392\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397612; batch adversarial loss: 0.514091\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338412; batch adversarial loss: 0.516473\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383353; batch adversarial loss: 0.528553\n",
      "epoch 110; iter: 0; batch classifier loss: 0.393589; batch adversarial loss: 0.515200\n",
      "epoch 111; iter: 0; batch classifier loss: 0.300113; batch adversarial loss: 0.485157\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394651; batch adversarial loss: 0.560184\n",
      "epoch 113; iter: 0; batch classifier loss: 0.367698; batch adversarial loss: 0.625210\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400875; batch adversarial loss: 0.480618\n",
      "epoch 115; iter: 0; batch classifier loss: 0.304782; batch adversarial loss: 0.560504\n",
      "epoch 116; iter: 0; batch classifier loss: 0.414231; batch adversarial loss: 0.452158\n",
      "epoch 117; iter: 0; batch classifier loss: 0.335016; batch adversarial loss: 0.565908\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360634; batch adversarial loss: 0.589630\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396476; batch adversarial loss: 0.466287\n",
      "epoch 120; iter: 0; batch classifier loss: 0.490513; batch adversarial loss: 0.533759\n",
      "epoch 121; iter: 0; batch classifier loss: 0.435242; batch adversarial loss: 0.494888\n",
      "epoch 122; iter: 0; batch classifier loss: 0.500089; batch adversarial loss: 0.586373\n",
      "epoch 123; iter: 0; batch classifier loss: 0.444446; batch adversarial loss: 0.574624\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360013; batch adversarial loss: 0.486718\n",
      "epoch 125; iter: 0; batch classifier loss: 0.446480; batch adversarial loss: 0.530851\n",
      "epoch 126; iter: 0; batch classifier loss: 0.417859; batch adversarial loss: 0.531779\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346539; batch adversarial loss: 0.460137\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364443; batch adversarial loss: 0.553048\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367473; batch adversarial loss: 0.566679\n",
      "epoch 130; iter: 0; batch classifier loss: 0.426645; batch adversarial loss: 0.546079\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375449; batch adversarial loss: 0.526911\n",
      "epoch 132; iter: 0; batch classifier loss: 0.299334; batch adversarial loss: 0.516723\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379392; batch adversarial loss: 0.552559\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371430; batch adversarial loss: 0.554083\n",
      "epoch 135; iter: 0; batch classifier loss: 0.465688; batch adversarial loss: 0.495639\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427498; batch adversarial loss: 0.580091\n",
      "epoch 137; iter: 0; batch classifier loss: 0.287430; batch adversarial loss: 0.527045\n",
      "epoch 138; iter: 0; batch classifier loss: 0.444462; batch adversarial loss: 0.534018\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374197; batch adversarial loss: 0.553368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346382; batch adversarial loss: 0.483725\n",
      "epoch 141; iter: 0; batch classifier loss: 0.288489; batch adversarial loss: 0.452402\n",
      "epoch 142; iter: 0; batch classifier loss: 0.327726; batch adversarial loss: 0.577131\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370358; batch adversarial loss: 0.601937\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369913; batch adversarial loss: 0.582140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.408035; batch adversarial loss: 0.552011\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363016; batch adversarial loss: 0.553138\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383051; batch adversarial loss: 0.562876\n",
      "epoch 148; iter: 0; batch classifier loss: 0.309094; batch adversarial loss: 0.524947\n",
      "epoch 149; iter: 0; batch classifier loss: 0.414037; batch adversarial loss: 0.515731\n",
      "epoch 150; iter: 0; batch classifier loss: 0.304725; batch adversarial loss: 0.589559\n",
      "epoch 151; iter: 0; batch classifier loss: 0.308207; batch adversarial loss: 0.563658\n",
      "epoch 152; iter: 0; batch classifier loss: 0.294841; batch adversarial loss: 0.506836\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371514; batch adversarial loss: 0.497554\n",
      "epoch 154; iter: 0; batch classifier loss: 0.304301; batch adversarial loss: 0.637523\n",
      "epoch 155; iter: 0; batch classifier loss: 0.438992; batch adversarial loss: 0.532401\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367738; batch adversarial loss: 0.544917\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351575; batch adversarial loss: 0.562014\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382253; batch adversarial loss: 0.514444\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344902; batch adversarial loss: 0.560767\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387470; batch adversarial loss: 0.598829\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322229; batch adversarial loss: 0.580546\n",
      "epoch 162; iter: 0; batch classifier loss: 0.233733; batch adversarial loss: 0.543789\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349248; batch adversarial loss: 0.479043\n",
      "epoch 164; iter: 0; batch classifier loss: 0.437902; batch adversarial loss: 0.583852\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418815; batch adversarial loss: 0.474148\n",
      "epoch 166; iter: 0; batch classifier loss: 0.383407; batch adversarial loss: 0.543773\n",
      "epoch 167; iter: 0; batch classifier loss: 0.494594; batch adversarial loss: 0.519162\n",
      "epoch 168; iter: 0; batch classifier loss: 0.405297; batch adversarial loss: 0.505602\n",
      "epoch 169; iter: 0; batch classifier loss: 0.427953; batch adversarial loss: 0.485838\n",
      "epoch 170; iter: 0; batch classifier loss: 0.418764; batch adversarial loss: 0.544119\n",
      "epoch 171; iter: 0; batch classifier loss: 0.470696; batch adversarial loss: 0.461422\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365482; batch adversarial loss: 0.590542\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382767; batch adversarial loss: 0.573494\n",
      "epoch 174; iter: 0; batch classifier loss: 0.303056; batch adversarial loss: 0.531017\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323212; batch adversarial loss: 0.604529\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344507; batch adversarial loss: 0.523442\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330163; batch adversarial loss: 0.519235\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335794; batch adversarial loss: 0.558086\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357427; batch adversarial loss: 0.551558\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346230; batch adversarial loss: 0.631288\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411623; batch adversarial loss: 0.634186\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341006; batch adversarial loss: 0.559158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.349096; batch adversarial loss: 0.434330\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376856; batch adversarial loss: 0.536577\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402154; batch adversarial loss: 0.519882\n",
      "epoch 186; iter: 0; batch classifier loss: 0.388955; batch adversarial loss: 0.565006\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362575; batch adversarial loss: 0.550461\n",
      "epoch 188; iter: 0; batch classifier loss: 0.299300; batch adversarial loss: 0.532782\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379781; batch adversarial loss: 0.515710\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352768; batch adversarial loss: 0.500570\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347472; batch adversarial loss: 0.507623\n",
      "epoch 192; iter: 0; batch classifier loss: 0.432113; batch adversarial loss: 0.523120\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320288; batch adversarial loss: 0.557217\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380788; batch adversarial loss: 0.600027\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384008; batch adversarial loss: 0.516153\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364728; batch adversarial loss: 0.574820\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336937; batch adversarial loss: 0.571850\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348412; batch adversarial loss: 0.497874\n",
      "epoch 199; iter: 0; batch classifier loss: 0.414920; batch adversarial loss: 0.479036\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713552; batch adversarial loss: 0.824754\n",
      "epoch 1; iter: 0; batch classifier loss: 0.684033; batch adversarial loss: 0.844895\n",
      "epoch 2; iter: 0; batch classifier loss: 0.783848; batch adversarial loss: 0.772657\n",
      "epoch 3; iter: 0; batch classifier loss: 0.714488; batch adversarial loss: 0.721848\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614356; batch adversarial loss: 0.690156\n",
      "epoch 5; iter: 0; batch classifier loss: 0.504594; batch adversarial loss: 0.649471\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516487; batch adversarial loss: 0.614748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548338; batch adversarial loss: 0.613626\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515778; batch adversarial loss: 0.605083\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530786; batch adversarial loss: 0.617014\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547504; batch adversarial loss: 0.607036\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577118; batch adversarial loss: 0.620863\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488772; batch adversarial loss: 0.575407\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506143; batch adversarial loss: 0.554895\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544745; batch adversarial loss: 0.544018\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481795; batch adversarial loss: 0.514268\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543357; batch adversarial loss: 0.578519\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505752; batch adversarial loss: 0.492074\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501768; batch adversarial loss: 0.488313\n",
      "epoch 19; iter: 0; batch classifier loss: 0.371836; batch adversarial loss: 0.540911\n",
      "epoch 20; iter: 0; batch classifier loss: 0.561218; batch adversarial loss: 0.518704\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497484; batch adversarial loss: 0.570290\n",
      "epoch 22; iter: 0; batch classifier loss: 0.461993; batch adversarial loss: 0.556078\n",
      "epoch 23; iter: 0; batch classifier loss: 0.386834; batch adversarial loss: 0.599742\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508570; batch adversarial loss: 0.595820\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511079; batch adversarial loss: 0.545770\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510065; batch adversarial loss: 0.543440\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480143; batch adversarial loss: 0.555758\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484344; batch adversarial loss: 0.662372\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534694; batch adversarial loss: 0.594445\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540655; batch adversarial loss: 0.568547\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469904; batch adversarial loss: 0.491036\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520484; batch adversarial loss: 0.596938\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461460; batch adversarial loss: 0.520821\n",
      "epoch 34; iter: 0; batch classifier loss: 0.518358; batch adversarial loss: 0.579953\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449288; batch adversarial loss: 0.544822\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481300; batch adversarial loss: 0.588230\n",
      "epoch 37; iter: 0; batch classifier loss: 0.518238; batch adversarial loss: 0.475207\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403958; batch adversarial loss: 0.502608\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465372; batch adversarial loss: 0.527768\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418415; batch adversarial loss: 0.580878\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469175; batch adversarial loss: 0.571009\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420246; batch adversarial loss: 0.579530\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396242; batch adversarial loss: 0.501324\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461390; batch adversarial loss: 0.554118\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466033; batch adversarial loss: 0.437688\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438565; batch adversarial loss: 0.560529\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406831; batch adversarial loss: 0.528729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413784; batch adversarial loss: 0.526230\n",
      "epoch 49; iter: 0; batch classifier loss: 0.370063; batch adversarial loss: 0.535455\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435472; batch adversarial loss: 0.617795\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431294; batch adversarial loss: 0.526143\n",
      "epoch 52; iter: 0; batch classifier loss: 0.453027; batch adversarial loss: 0.552969\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452390; batch adversarial loss: 0.597823\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412575; batch adversarial loss: 0.571566\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409099; batch adversarial loss: 0.534504\n",
      "epoch 56; iter: 0; batch classifier loss: 0.368640; batch adversarial loss: 0.564465\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414253; batch adversarial loss: 0.536106\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433194; batch adversarial loss: 0.527551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.354106; batch adversarial loss: 0.499865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421092; batch adversarial loss: 0.587640\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455599; batch adversarial loss: 0.598578\n",
      "epoch 62; iter: 0; batch classifier loss: 0.353735; batch adversarial loss: 0.545348\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400357; batch adversarial loss: 0.588210\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431317; batch adversarial loss: 0.509307\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374725; batch adversarial loss: 0.497679\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389886; batch adversarial loss: 0.527086\n",
      "epoch 67; iter: 0; batch classifier loss: 0.367366; batch adversarial loss: 0.451717\n",
      "epoch 68; iter: 0; batch classifier loss: 0.346186; batch adversarial loss: 0.499740\n",
      "epoch 69; iter: 0; batch classifier loss: 0.346286; batch adversarial loss: 0.551477\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398222; batch adversarial loss: 0.590709\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417784; batch adversarial loss: 0.553783\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455656; batch adversarial loss: 0.589652\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448497; batch adversarial loss: 0.553136\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381147; batch adversarial loss: 0.563115\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.480308\n",
      "epoch 76; iter: 0; batch classifier loss: 0.447948; batch adversarial loss: 0.526126\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435774; batch adversarial loss: 0.520083\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389356; batch adversarial loss: 0.498058\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404795; batch adversarial loss: 0.519140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.414768; batch adversarial loss: 0.589897\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426328; batch adversarial loss: 0.508487\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411727; batch adversarial loss: 0.608214\n",
      "epoch 83; iter: 0; batch classifier loss: 0.450335; batch adversarial loss: 0.626986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.304606; batch adversarial loss: 0.461278\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349638; batch adversarial loss: 0.589805\n",
      "epoch 86; iter: 0; batch classifier loss: 0.443235; batch adversarial loss: 0.571419\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416453; batch adversarial loss: 0.542460\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424028; batch adversarial loss: 0.597690\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350978; batch adversarial loss: 0.571295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407568; batch adversarial loss: 0.526341\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413205; batch adversarial loss: 0.571682\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362900; batch adversarial loss: 0.628570\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366898; batch adversarial loss: 0.580110\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385616; batch adversarial loss: 0.563666\n",
      "epoch 95; iter: 0; batch classifier loss: 0.349133; batch adversarial loss: 0.536523\n",
      "epoch 96; iter: 0; batch classifier loss: 0.439247; batch adversarial loss: 0.545271\n",
      "epoch 97; iter: 0; batch classifier loss: 0.428976; batch adversarial loss: 0.608657\n",
      "epoch 98; iter: 0; batch classifier loss: 0.336099; batch adversarial loss: 0.554608\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407043; batch adversarial loss: 0.533455\n",
      "epoch 100; iter: 0; batch classifier loss: 0.340876; batch adversarial loss: 0.610596\n",
      "epoch 101; iter: 0; batch classifier loss: 0.435958; batch adversarial loss: 0.517900\n",
      "epoch 102; iter: 0; batch classifier loss: 0.352685; batch adversarial loss: 0.507388\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402466; batch adversarial loss: 0.590314\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392382; batch adversarial loss: 0.537589\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417431; batch adversarial loss: 0.498244\n",
      "epoch 106; iter: 0; batch classifier loss: 0.298658; batch adversarial loss: 0.617945\n",
      "epoch 107; iter: 0; batch classifier loss: 0.544325; batch adversarial loss: 0.517991\n",
      "epoch 108; iter: 0; batch classifier loss: 0.342686; batch adversarial loss: 0.508283\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397619; batch adversarial loss: 0.552150\n",
      "epoch 110; iter: 0; batch classifier loss: 0.424973; batch adversarial loss: 0.560078\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363872; batch adversarial loss: 0.508041\n",
      "epoch 112; iter: 0; batch classifier loss: 0.416914; batch adversarial loss: 0.562640\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401022; batch adversarial loss: 0.543771\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346700; batch adversarial loss: 0.544103\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380559; batch adversarial loss: 0.552126\n",
      "epoch 116; iter: 0; batch classifier loss: 0.360299; batch adversarial loss: 0.585976\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416017; batch adversarial loss: 0.524241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352379; batch adversarial loss: 0.552797\n",
      "epoch 119; iter: 0; batch classifier loss: 0.355965; batch adversarial loss: 0.616843\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422339; batch adversarial loss: 0.546367\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339284; batch adversarial loss: 0.497288\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398039; batch adversarial loss: 0.517261\n",
      "epoch 123; iter: 0; batch classifier loss: 0.406028; batch adversarial loss: 0.566177\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369914; batch adversarial loss: 0.554321\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413661; batch adversarial loss: 0.492132\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398457; batch adversarial loss: 0.552976\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348595; batch adversarial loss: 0.607815\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375373; batch adversarial loss: 0.551975\n",
      "epoch 129; iter: 0; batch classifier loss: 0.305568; batch adversarial loss: 0.579912\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325407; batch adversarial loss: 0.483370\n",
      "epoch 131; iter: 0; batch classifier loss: 0.341540; batch adversarial loss: 0.541435\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371417; batch adversarial loss: 0.578966\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392959; batch adversarial loss: 0.543697\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396287; batch adversarial loss: 0.554547\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389996; batch adversarial loss: 0.589063\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389188; batch adversarial loss: 0.480181\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396552; batch adversarial loss: 0.482300\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367440; batch adversarial loss: 0.508687\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344869; batch adversarial loss: 0.635804\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357127; batch adversarial loss: 0.552849\n",
      "epoch 141; iter: 0; batch classifier loss: 0.291295; batch adversarial loss: 0.543970\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379789; batch adversarial loss: 0.516904\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349813; batch adversarial loss: 0.580138\n",
      "epoch 144; iter: 0; batch classifier loss: 0.466027; batch adversarial loss: 0.609836\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383102; batch adversarial loss: 0.464441\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376141; batch adversarial loss: 0.544183\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369022; batch adversarial loss: 0.528164\n",
      "epoch 148; iter: 0; batch classifier loss: 0.321699; batch adversarial loss: 0.598068\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344078; batch adversarial loss: 0.516296\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361100; batch adversarial loss: 0.568971\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325448; batch adversarial loss: 0.506565\n",
      "epoch 152; iter: 0; batch classifier loss: 0.466174; batch adversarial loss: 0.471066\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391910; batch adversarial loss: 0.504414\n",
      "epoch 154; iter: 0; batch classifier loss: 0.438638; batch adversarial loss: 0.554289\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343443; batch adversarial loss: 0.534331\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312892; batch adversarial loss: 0.542922\n",
      "epoch 157; iter: 0; batch classifier loss: 0.322673; batch adversarial loss: 0.615055\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386254; batch adversarial loss: 0.488267\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387919; batch adversarial loss: 0.581601\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340315; batch adversarial loss: 0.505811\n",
      "epoch 161; iter: 0; batch classifier loss: 0.417875; batch adversarial loss: 0.622422\n",
      "epoch 162; iter: 0; batch classifier loss: 0.414711; batch adversarial loss: 0.452616\n",
      "epoch 163; iter: 0; batch classifier loss: 0.401698; batch adversarial loss: 0.635596\n",
      "epoch 164; iter: 0; batch classifier loss: 0.308111; batch adversarial loss: 0.534417\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386785; batch adversarial loss: 0.555022\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355981; batch adversarial loss: 0.507957\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379236; batch adversarial loss: 0.544105\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357189; batch adversarial loss: 0.557233\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306768; batch adversarial loss: 0.548660\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359661; batch adversarial loss: 0.634569\n",
      "epoch 171; iter: 0; batch classifier loss: 0.427332; batch adversarial loss: 0.508302\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336369; batch adversarial loss: 0.517296\n",
      "epoch 173; iter: 0; batch classifier loss: 0.441083; batch adversarial loss: 0.534534\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334287; batch adversarial loss: 0.479365\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363230; batch adversarial loss: 0.570195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.444203; batch adversarial loss: 0.564231\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391951; batch adversarial loss: 0.552164\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287944; batch adversarial loss: 0.551188\n",
      "epoch 179; iter: 0; batch classifier loss: 0.398523; batch adversarial loss: 0.525123\n",
      "epoch 180; iter: 0; batch classifier loss: 0.341566; batch adversarial loss: 0.554035\n",
      "epoch 181; iter: 0; batch classifier loss: 0.293399; batch adversarial loss: 0.497254\n",
      "epoch 182; iter: 0; batch classifier loss: 0.295646; batch adversarial loss: 0.573972\n",
      "epoch 183; iter: 0; batch classifier loss: 0.328481; batch adversarial loss: 0.586446\n",
      "epoch 184; iter: 0; batch classifier loss: 0.388618; batch adversarial loss: 0.536409\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330071; batch adversarial loss: 0.601435\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312709; batch adversarial loss: 0.569096\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305891; batch adversarial loss: 0.515118\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391237; batch adversarial loss: 0.599478\n",
      "epoch 189; iter: 0; batch classifier loss: 0.293464; batch adversarial loss: 0.481165\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364247; batch adversarial loss: 0.612922\n",
      "epoch 191; iter: 0; batch classifier loss: 0.443383; batch adversarial loss: 0.452046\n",
      "epoch 192; iter: 0; batch classifier loss: 0.432788; batch adversarial loss: 0.451899\n",
      "epoch 193; iter: 0; batch classifier loss: 0.241568; batch adversarial loss: 0.489833\n",
      "epoch 194; iter: 0; batch classifier loss: 0.300567; batch adversarial loss: 0.533686\n",
      "epoch 195; iter: 0; batch classifier loss: 0.428826; batch adversarial loss: 0.643170\n",
      "epoch 196; iter: 0; batch classifier loss: 0.279633; batch adversarial loss: 0.591368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.256989; batch adversarial loss: 0.533373\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350864; batch adversarial loss: 0.470979\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370368; batch adversarial loss: 0.589017\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679482; batch adversarial loss: 0.639894\n",
      "epoch 1; iter: 0; batch classifier loss: 0.636654; batch adversarial loss: 0.662013\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593783; batch adversarial loss: 0.677369\n",
      "epoch 3; iter: 0; batch classifier loss: 0.509142; batch adversarial loss: 0.654916\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597612; batch adversarial loss: 0.652018\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544168; batch adversarial loss: 0.603273\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520124; batch adversarial loss: 0.601707\n",
      "epoch 7; iter: 0; batch classifier loss: 0.661753; batch adversarial loss: 0.623115\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525196; batch adversarial loss: 0.583079\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475332; batch adversarial loss: 0.604025\n",
      "epoch 10; iter: 0; batch classifier loss: 0.585664; batch adversarial loss: 0.565309\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531651; batch adversarial loss: 0.579897\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552477; batch adversarial loss: 0.596233\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557576; batch adversarial loss: 0.545237\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473048; batch adversarial loss: 0.529313\n",
      "epoch 15; iter: 0; batch classifier loss: 0.467935; batch adversarial loss: 0.557285\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531187; batch adversarial loss: 0.619164\n",
      "epoch 17; iter: 0; batch classifier loss: 0.442788; batch adversarial loss: 0.563769\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526779; batch adversarial loss: 0.525281\n",
      "epoch 19; iter: 0; batch classifier loss: 0.552501; batch adversarial loss: 0.618799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527950; batch adversarial loss: 0.532199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.466749; batch adversarial loss: 0.611706\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494868; batch adversarial loss: 0.628163\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482799; batch adversarial loss: 0.545530\n",
      "epoch 24; iter: 0; batch classifier loss: 0.472999; batch adversarial loss: 0.541945\n",
      "epoch 25; iter: 0; batch classifier loss: 0.529119; batch adversarial loss: 0.548261\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494217; batch adversarial loss: 0.521432\n",
      "epoch 27; iter: 0; batch classifier loss: 0.548464; batch adversarial loss: 0.571611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464088; batch adversarial loss: 0.601465\n",
      "epoch 29; iter: 0; batch classifier loss: 0.541031; batch adversarial loss: 0.547249\n",
      "epoch 30; iter: 0; batch classifier loss: 0.412479; batch adversarial loss: 0.581478\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426913; batch adversarial loss: 0.544905\n",
      "epoch 32; iter: 0; batch classifier loss: 0.511574; batch adversarial loss: 0.494648\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456086; batch adversarial loss: 0.518878\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456429; batch adversarial loss: 0.502626\n",
      "epoch 35; iter: 0; batch classifier loss: 0.541808; batch adversarial loss: 0.649894\n",
      "epoch 36; iter: 0; batch classifier loss: 0.528885; batch adversarial loss: 0.571013\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459263; batch adversarial loss: 0.685585\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403823; batch adversarial loss: 0.544824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411875; batch adversarial loss: 0.562721\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445919; batch adversarial loss: 0.536212\n",
      "epoch 41; iter: 0; batch classifier loss: 0.391596; batch adversarial loss: 0.544465\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383672; batch adversarial loss: 0.598143\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482363; batch adversarial loss: 0.509271\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398018; batch adversarial loss: 0.615712\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434129; batch adversarial loss: 0.544567\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449601; batch adversarial loss: 0.579943\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371019; batch adversarial loss: 0.552658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469775; batch adversarial loss: 0.596937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456381; batch adversarial loss: 0.553754\n",
      "epoch 50; iter: 0; batch classifier loss: 0.355675; batch adversarial loss: 0.587779\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401743; batch adversarial loss: 0.596120\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446290; batch adversarial loss: 0.572592\n",
      "epoch 53; iter: 0; batch classifier loss: 0.350987; batch adversarial loss: 0.506980\n",
      "epoch 54; iter: 0; batch classifier loss: 0.337107; batch adversarial loss: 0.633411\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402035; batch adversarial loss: 0.615603\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417169; batch adversarial loss: 0.543343\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443203; batch adversarial loss: 0.581340\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384760; batch adversarial loss: 0.570220\n",
      "epoch 59; iter: 0; batch classifier loss: 0.437931; batch adversarial loss: 0.635421\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450772; batch adversarial loss: 0.581141\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444068; batch adversarial loss: 0.589482\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446263; batch adversarial loss: 0.562594\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432313; batch adversarial loss: 0.570546\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441110; batch adversarial loss: 0.546111\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419508; batch adversarial loss: 0.499258\n",
      "epoch 66; iter: 0; batch classifier loss: 0.330101; batch adversarial loss: 0.544647\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401446; batch adversarial loss: 0.562587\n",
      "epoch 68; iter: 0; batch classifier loss: 0.374937; batch adversarial loss: 0.490484\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428716; batch adversarial loss: 0.561918\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391444; batch adversarial loss: 0.568348\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406006; batch adversarial loss: 0.506144\n",
      "epoch 72; iter: 0; batch classifier loss: 0.337420; batch adversarial loss: 0.600647\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393717; batch adversarial loss: 0.554898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.396589; batch adversarial loss: 0.546631\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436898; batch adversarial loss: 0.581210\n",
      "epoch 76; iter: 0; batch classifier loss: 0.457339; batch adversarial loss: 0.527098\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375476; batch adversarial loss: 0.553375\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350967; batch adversarial loss: 0.645309\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400189; batch adversarial loss: 0.644770\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411255; batch adversarial loss: 0.561112\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406486; batch adversarial loss: 0.508873\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380482; batch adversarial loss: 0.535480\n",
      "epoch 83; iter: 0; batch classifier loss: 0.339402; batch adversarial loss: 0.560340\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352288; batch adversarial loss: 0.525840\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442566; batch adversarial loss: 0.475311\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379819; batch adversarial loss: 0.589004\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430838; batch adversarial loss: 0.582274\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374852; batch adversarial loss: 0.625871\n",
      "epoch 89; iter: 0; batch classifier loss: 0.330693; batch adversarial loss: 0.537355\n",
      "epoch 90; iter: 0; batch classifier loss: 0.299863; batch adversarial loss: 0.544474\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387468; batch adversarial loss: 0.590582\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373975; batch adversarial loss: 0.589851\n",
      "epoch 93; iter: 0; batch classifier loss: 0.411573; batch adversarial loss: 0.498547\n",
      "epoch 94; iter: 0; batch classifier loss: 0.337376; batch adversarial loss: 0.517283\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358850; batch adversarial loss: 0.643352\n",
      "epoch 96; iter: 0; batch classifier loss: 0.465223; batch adversarial loss: 0.606794\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373914; batch adversarial loss: 0.499788\n",
      "epoch 98; iter: 0; batch classifier loss: 0.313316; batch adversarial loss: 0.636570\n",
      "epoch 99; iter: 0; batch classifier loss: 0.475323; batch adversarial loss: 0.559869\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358750; batch adversarial loss: 0.638525\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400152; batch adversarial loss: 0.527605\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351977; batch adversarial loss: 0.562869\n",
      "epoch 103; iter: 0; batch classifier loss: 0.343278; batch adversarial loss: 0.632014\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422283; batch adversarial loss: 0.590565\n",
      "epoch 105; iter: 0; batch classifier loss: 0.387625; batch adversarial loss: 0.526149\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356911; batch adversarial loss: 0.624969\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319723; batch adversarial loss: 0.488489\n",
      "epoch 108; iter: 0; batch classifier loss: 0.446928; batch adversarial loss: 0.571475\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337904; batch adversarial loss: 0.582628\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333759; batch adversarial loss: 0.517657\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369620; batch adversarial loss: 0.570384\n",
      "epoch 112; iter: 0; batch classifier loss: 0.407472; batch adversarial loss: 0.534135\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360419; batch adversarial loss: 0.491084\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340760; batch adversarial loss: 0.580453\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435307; batch adversarial loss: 0.489610\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377122; batch adversarial loss: 0.643963\n",
      "epoch 117; iter: 0; batch classifier loss: 0.304222; batch adversarial loss: 0.452799\n",
      "epoch 118; iter: 0; batch classifier loss: 0.319403; batch adversarial loss: 0.528560\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347897; batch adversarial loss: 0.606657\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328631; batch adversarial loss: 0.555912\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398082; batch adversarial loss: 0.526823\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394931; batch adversarial loss: 0.580961\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357107; batch adversarial loss: 0.475454\n",
      "epoch 124; iter: 0; batch classifier loss: 0.335997; batch adversarial loss: 0.552072\n",
      "epoch 125; iter: 0; batch classifier loss: 0.379155; batch adversarial loss: 0.578900\n",
      "epoch 126; iter: 0; batch classifier loss: 0.297067; batch adversarial loss: 0.516353\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387586; batch adversarial loss: 0.596254\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330721; batch adversarial loss: 0.524093\n",
      "epoch 129; iter: 0; batch classifier loss: 0.465712; batch adversarial loss: 0.569744\n",
      "epoch 130; iter: 0; batch classifier loss: 0.410635; batch adversarial loss: 0.473304\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377142; batch adversarial loss: 0.624688\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406808; batch adversarial loss: 0.533707\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394584; batch adversarial loss: 0.510096\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338118; batch adversarial loss: 0.563946\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358694; batch adversarial loss: 0.545588\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385349; batch adversarial loss: 0.591091\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384036; batch adversarial loss: 0.454666\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387877; batch adversarial loss: 0.500233\n",
      "epoch 139; iter: 0; batch classifier loss: 0.337847; batch adversarial loss: 0.516539\n",
      "epoch 140; iter: 0; batch classifier loss: 0.394004; batch adversarial loss: 0.581596\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368122; batch adversarial loss: 0.562839\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381375; batch adversarial loss: 0.489060\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342377; batch adversarial loss: 0.562294\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406534; batch adversarial loss: 0.525639\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340318; batch adversarial loss: 0.525832\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361943; batch adversarial loss: 0.634505\n",
      "epoch 147; iter: 0; batch classifier loss: 0.279588; batch adversarial loss: 0.490886\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384939; batch adversarial loss: 0.545563\n",
      "epoch 149; iter: 0; batch classifier loss: 0.412317; batch adversarial loss: 0.553542\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337444; batch adversarial loss: 0.516994\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415767; batch adversarial loss: 0.536316\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363992; batch adversarial loss: 0.572288\n",
      "epoch 153; iter: 0; batch classifier loss: 0.314941; batch adversarial loss: 0.545348\n",
      "epoch 154; iter: 0; batch classifier loss: 0.436999; batch adversarial loss: 0.597681\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341789; batch adversarial loss: 0.562164\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341121; batch adversarial loss: 0.544644\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372894; batch adversarial loss: 0.535928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.452875; batch adversarial loss: 0.597566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375221; batch adversarial loss: 0.517911\n",
      "epoch 160; iter: 0; batch classifier loss: 0.293240; batch adversarial loss: 0.561478\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374520; batch adversarial loss: 0.598573\n",
      "epoch 162; iter: 0; batch classifier loss: 0.421456; batch adversarial loss: 0.544891\n",
      "epoch 163; iter: 0; batch classifier loss: 0.404148; batch adversarial loss: 0.646024\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341891; batch adversarial loss: 0.599115\n",
      "epoch 165; iter: 0; batch classifier loss: 0.297758; batch adversarial loss: 0.563601\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339563; batch adversarial loss: 0.563987\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358732; batch adversarial loss: 0.581392\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327131; batch adversarial loss: 0.552725\n",
      "epoch 169; iter: 0; batch classifier loss: 0.438341; batch adversarial loss: 0.598882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.345610; batch adversarial loss: 0.516164\n",
      "epoch 171; iter: 0; batch classifier loss: 0.361564; batch adversarial loss: 0.563090\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394043; batch adversarial loss: 0.580271\n",
      "epoch 173; iter: 0; batch classifier loss: 0.408456; batch adversarial loss: 0.534598\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374240; batch adversarial loss: 0.545494\n",
      "epoch 175; iter: 0; batch classifier loss: 0.424796; batch adversarial loss: 0.528155\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408549; batch adversarial loss: 0.642390\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361509; batch adversarial loss: 0.625821\n",
      "epoch 178; iter: 0; batch classifier loss: 0.460185; batch adversarial loss: 0.528143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390288; batch adversarial loss: 0.562769\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337486; batch adversarial loss: 0.535534\n",
      "epoch 181; iter: 0; batch classifier loss: 0.408773; batch adversarial loss: 0.669981\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364428; batch adversarial loss: 0.446753\n",
      "epoch 183; iter: 0; batch classifier loss: 0.374337; batch adversarial loss: 0.588564\n",
      "epoch 184; iter: 0; batch classifier loss: 0.305710; batch adversarial loss: 0.581564\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355152; batch adversarial loss: 0.553617\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323643; batch adversarial loss: 0.509288\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363644; batch adversarial loss: 0.634430\n",
      "epoch 188; iter: 0; batch classifier loss: 0.271675; batch adversarial loss: 0.571788\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361289; batch adversarial loss: 0.637179\n",
      "epoch 190; iter: 0; batch classifier loss: 0.286426; batch adversarial loss: 0.543868\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344235; batch adversarial loss: 0.589162\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365099; batch adversarial loss: 0.533209\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376318; batch adversarial loss: 0.508827\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321218; batch adversarial loss: 0.562621\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393626; batch adversarial loss: 0.534737\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314838; batch adversarial loss: 0.517718\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341882; batch adversarial loss: 0.555995\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393114; batch adversarial loss: 0.463474\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335150; batch adversarial loss: 0.587901\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687873; batch adversarial loss: 0.759559\n",
      "epoch 1; iter: 0; batch classifier loss: 0.760674; batch adversarial loss: 0.786793\n",
      "epoch 2; iter: 0; batch classifier loss: 0.751998; batch adversarial loss: 0.745753\n",
      "epoch 3; iter: 0; batch classifier loss: 0.694260; batch adversarial loss: 0.673561\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571252; batch adversarial loss: 0.632792\n",
      "epoch 5; iter: 0; batch classifier loss: 0.653628; batch adversarial loss: 0.612163\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579698; batch adversarial loss: 0.651376\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578563; batch adversarial loss: 0.610297\n",
      "epoch 8; iter: 0; batch classifier loss: 0.477445; batch adversarial loss: 0.598835\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490908; batch adversarial loss: 0.586493\n",
      "epoch 10; iter: 0; batch classifier loss: 0.596820; batch adversarial loss: 0.564327\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544644; batch adversarial loss: 0.545128\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504879; batch adversarial loss: 0.563880\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552590; batch adversarial loss: 0.589274\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480651; batch adversarial loss: 0.585402\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481292; batch adversarial loss: 0.580265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468265; batch adversarial loss: 0.544502\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469918; batch adversarial loss: 0.552513\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478162; batch adversarial loss: 0.517306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492067; batch adversarial loss: 0.582967\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521822; batch adversarial loss: 0.568027\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503325; batch adversarial loss: 0.525889\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455475; batch adversarial loss: 0.525808\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502250; batch adversarial loss: 0.595628\n",
      "epoch 24; iter: 0; batch classifier loss: 0.546810; batch adversarial loss: 0.520180\n",
      "epoch 25; iter: 0; batch classifier loss: 0.387954; batch adversarial loss: 0.561930\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510547; batch adversarial loss: 0.518036\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439543; batch adversarial loss: 0.547995\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496445; batch adversarial loss: 0.572723\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442712; batch adversarial loss: 0.605128\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499896; batch adversarial loss: 0.579006\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441923; batch adversarial loss: 0.575742\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442785; batch adversarial loss: 0.583461\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462683; batch adversarial loss: 0.619053\n",
      "epoch 34; iter: 0; batch classifier loss: 0.521691; batch adversarial loss: 0.624446\n",
      "epoch 35; iter: 0; batch classifier loss: 0.418436; batch adversarial loss: 0.552477\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366590; batch adversarial loss: 0.542314\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394898; batch adversarial loss: 0.544794\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450344; batch adversarial loss: 0.548276\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428341; batch adversarial loss: 0.575873\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421961; batch adversarial loss: 0.501854\n",
      "epoch 41; iter: 0; batch classifier loss: 0.492112; batch adversarial loss: 0.529035\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446605; batch adversarial loss: 0.632850\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409767; batch adversarial loss: 0.611188\n",
      "epoch 44; iter: 0; batch classifier loss: 0.359360; batch adversarial loss: 0.533924\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392841; batch adversarial loss: 0.505489\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380446; batch adversarial loss: 0.493038\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418508; batch adversarial loss: 0.571507\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432966; batch adversarial loss: 0.606995\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415543; batch adversarial loss: 0.514548\n",
      "epoch 50; iter: 0; batch classifier loss: 0.387703; batch adversarial loss: 0.500109\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470269; batch adversarial loss: 0.661757\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449862; batch adversarial loss: 0.545389\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415208; batch adversarial loss: 0.535890\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467353; batch adversarial loss: 0.562495\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417550; batch adversarial loss: 0.519033\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387301; batch adversarial loss: 0.482619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426903; batch adversarial loss: 0.499927\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448542; batch adversarial loss: 0.643581\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423758; batch adversarial loss: 0.544491\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376776; batch adversarial loss: 0.580892\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406780; batch adversarial loss: 0.479749\n",
      "epoch 62; iter: 0; batch classifier loss: 0.413658; batch adversarial loss: 0.471475\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422551; batch adversarial loss: 0.480170\n",
      "epoch 64; iter: 0; batch classifier loss: 0.379498; batch adversarial loss: 0.508078\n",
      "epoch 65; iter: 0; batch classifier loss: 0.465594; batch adversarial loss: 0.488917\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426356; batch adversarial loss: 0.517741\n",
      "epoch 67; iter: 0; batch classifier loss: 0.470417; batch adversarial loss: 0.517816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.427340; batch adversarial loss: 0.526927\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403846; batch adversarial loss: 0.499330\n",
      "epoch 70; iter: 0; batch classifier loss: 0.454559; batch adversarial loss: 0.527081\n",
      "epoch 71; iter: 0; batch classifier loss: 0.453142; batch adversarial loss: 0.562052\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428167; batch adversarial loss: 0.536021\n",
      "epoch 73; iter: 0; batch classifier loss: 0.454662; batch adversarial loss: 0.599222\n",
      "epoch 74; iter: 0; batch classifier loss: 0.347446; batch adversarial loss: 0.625472\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422490; batch adversarial loss: 0.525816\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377970; batch adversarial loss: 0.607887\n",
      "epoch 77; iter: 0; batch classifier loss: 0.397041; batch adversarial loss: 0.579938\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404856; batch adversarial loss: 0.571602\n",
      "epoch 79; iter: 0; batch classifier loss: 0.339113; batch adversarial loss: 0.616075\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391396; batch adversarial loss: 0.489480\n",
      "epoch 81; iter: 0; batch classifier loss: 0.452892; batch adversarial loss: 0.572352\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401481; batch adversarial loss: 0.571900\n",
      "epoch 83; iter: 0; batch classifier loss: 0.357868; batch adversarial loss: 0.590394\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441043; batch adversarial loss: 0.610033\n",
      "epoch 85; iter: 0; batch classifier loss: 0.463359; batch adversarial loss: 0.490603\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355721; batch adversarial loss: 0.579983\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364282; batch adversarial loss: 0.563577\n",
      "epoch 88; iter: 0; batch classifier loss: 0.453947; batch adversarial loss: 0.508629\n",
      "epoch 89; iter: 0; batch classifier loss: 0.335160; batch adversarial loss: 0.481748\n",
      "epoch 90; iter: 0; batch classifier loss: 0.328822; batch adversarial loss: 0.517512\n",
      "epoch 91; iter: 0; batch classifier loss: 0.415161; batch adversarial loss: 0.580981\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386413; batch adversarial loss: 0.553884\n",
      "epoch 93; iter: 0; batch classifier loss: 0.389470; batch adversarial loss: 0.571754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.355300; batch adversarial loss: 0.499282\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375346; batch adversarial loss: 0.525949\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414295; batch adversarial loss: 0.653516\n",
      "epoch 97; iter: 0; batch classifier loss: 0.330909; batch adversarial loss: 0.452747\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370000; batch adversarial loss: 0.562422\n",
      "epoch 99; iter: 0; batch classifier loss: 0.314413; batch adversarial loss: 0.579975\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349095; batch adversarial loss: 0.653377\n",
      "epoch 101; iter: 0; batch classifier loss: 0.469073; batch adversarial loss: 0.580773\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370321; batch adversarial loss: 0.562840\n",
      "epoch 103; iter: 0; batch classifier loss: 0.487282; batch adversarial loss: 0.544121\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387471; batch adversarial loss: 0.580353\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401847; batch adversarial loss: 0.553409\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404597; batch adversarial loss: 0.581014\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404967; batch adversarial loss: 0.571265\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378391; batch adversarial loss: 0.563461\n",
      "epoch 109; iter: 0; batch classifier loss: 0.330629; batch adversarial loss: 0.553154\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356993; batch adversarial loss: 0.526596\n",
      "epoch 111; iter: 0; batch classifier loss: 0.333994; batch adversarial loss: 0.489900\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381716; batch adversarial loss: 0.526885\n",
      "epoch 113; iter: 0; batch classifier loss: 0.319894; batch adversarial loss: 0.617413\n",
      "epoch 114; iter: 0; batch classifier loss: 0.324254; batch adversarial loss: 0.598668\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381510; batch adversarial loss: 0.562502\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339579; batch adversarial loss: 0.562508\n",
      "epoch 117; iter: 0; batch classifier loss: 0.364247; batch adversarial loss: 0.535469\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412935; batch adversarial loss: 0.544684\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414334; batch adversarial loss: 0.590382\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374101; batch adversarial loss: 0.572380\n",
      "epoch 121; iter: 0; batch classifier loss: 0.304501; batch adversarial loss: 0.571490\n",
      "epoch 122; iter: 0; batch classifier loss: 0.348366; batch adversarial loss: 0.535540\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396558; batch adversarial loss: 0.571664\n",
      "epoch 124; iter: 0; batch classifier loss: 0.414777; batch adversarial loss: 0.571721\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408706; batch adversarial loss: 0.617083\n",
      "epoch 126; iter: 0; batch classifier loss: 0.481913; batch adversarial loss: 0.580873\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421035; batch adversarial loss: 0.545403\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334412; batch adversarial loss: 0.462312\n",
      "epoch 129; iter: 0; batch classifier loss: 0.302599; batch adversarial loss: 0.571486\n",
      "epoch 130; iter: 0; batch classifier loss: 0.328837; batch adversarial loss: 0.507870\n",
      "epoch 131; iter: 0; batch classifier loss: 0.327877; batch adversarial loss: 0.544304\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340681; batch adversarial loss: 0.526722\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347784; batch adversarial loss: 0.626405\n",
      "epoch 134; iter: 0; batch classifier loss: 0.327867; batch adversarial loss: 0.535295\n",
      "epoch 135; iter: 0; batch classifier loss: 0.332328; batch adversarial loss: 0.563220\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404445; batch adversarial loss: 0.507716\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385989; batch adversarial loss: 0.571941\n",
      "epoch 138; iter: 0; batch classifier loss: 0.279003; batch adversarial loss: 0.553354\n",
      "epoch 139; iter: 0; batch classifier loss: 0.324187; batch adversarial loss: 0.580913\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337363; batch adversarial loss: 0.526420\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424804; batch adversarial loss: 0.553727\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405564; batch adversarial loss: 0.517208\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332881; batch adversarial loss: 0.517169\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367390; batch adversarial loss: 0.535308\n",
      "epoch 145; iter: 0; batch classifier loss: 0.314024; batch adversarial loss: 0.562542\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343333; batch adversarial loss: 0.526914\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368290; batch adversarial loss: 0.595440\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343070; batch adversarial loss: 0.599832\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350831; batch adversarial loss: 0.471755\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341181; batch adversarial loss: 0.524826\n",
      "epoch 151; iter: 0; batch classifier loss: 0.308020; batch adversarial loss: 0.544081\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344200; batch adversarial loss: 0.571555\n",
      "epoch 153; iter: 0; batch classifier loss: 0.420852; batch adversarial loss: 0.598366\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360471; batch adversarial loss: 0.580298\n",
      "epoch 155; iter: 0; batch classifier loss: 0.443084; batch adversarial loss: 0.590634\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333623; batch adversarial loss: 0.562876\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366276; batch adversarial loss: 0.572168\n",
      "epoch 158; iter: 0; batch classifier loss: 0.291795; batch adversarial loss: 0.673601\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352525; batch adversarial loss: 0.517026\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372920; batch adversarial loss: 0.608212\n",
      "epoch 161; iter: 0; batch classifier loss: 0.413634; batch adversarial loss: 0.544390\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400393; batch adversarial loss: 0.517318\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323812; batch adversarial loss: 0.562828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.272740; batch adversarial loss: 0.544371\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393323; batch adversarial loss: 0.618175\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366898; batch adversarial loss: 0.562970\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416016; batch adversarial loss: 0.490013\n",
      "epoch 168; iter: 0; batch classifier loss: 0.475411; batch adversarial loss: 0.608230\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381952; batch adversarial loss: 0.553368\n",
      "epoch 170; iter: 0; batch classifier loss: 0.377597; batch adversarial loss: 0.580915\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366640; batch adversarial loss: 0.545434\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360605; batch adversarial loss: 0.471662\n",
      "epoch 173; iter: 0; batch classifier loss: 0.384583; batch adversarial loss: 0.562589\n",
      "epoch 174; iter: 0; batch classifier loss: 0.352217; batch adversarial loss: 0.507942\n",
      "epoch 175; iter: 0; batch classifier loss: 0.302406; batch adversarial loss: 0.517408\n",
      "epoch 176; iter: 0; batch classifier loss: 0.402373; batch adversarial loss: 0.526448\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356676; batch adversarial loss: 0.544597\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312783; batch adversarial loss: 0.535333\n",
      "epoch 179; iter: 0; batch classifier loss: 0.274328; batch adversarial loss: 0.544312\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335615; batch adversarial loss: 0.525113\n",
      "epoch 181; iter: 0; batch classifier loss: 0.441814; batch adversarial loss: 0.571203\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381967; batch adversarial loss: 0.526083\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372236; batch adversarial loss: 0.535501\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328291; batch adversarial loss: 0.499012\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390272; batch adversarial loss: 0.572731\n",
      "epoch 186; iter: 0; batch classifier loss: 0.276853; batch adversarial loss: 0.599269\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340043; batch adversarial loss: 0.525600\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381096; batch adversarial loss: 0.507817\n",
      "epoch 189; iter: 0; batch classifier loss: 0.401587; batch adversarial loss: 0.536044\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359440; batch adversarial loss: 0.581706\n",
      "epoch 191; iter: 0; batch classifier loss: 0.376983; batch adversarial loss: 0.471807\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346180; batch adversarial loss: 0.562889\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325516; batch adversarial loss: 0.617724\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335105; batch adversarial loss: 0.499537\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387477; batch adversarial loss: 0.525937\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373598; batch adversarial loss: 0.571414\n",
      "epoch 197; iter: 0; batch classifier loss: 0.278805; batch adversarial loss: 0.617389\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324734; batch adversarial loss: 0.581131\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384726; batch adversarial loss: 0.545537\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753778; batch adversarial loss: 0.783156\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704628; batch adversarial loss: 0.772275\n",
      "epoch 2; iter: 0; batch classifier loss: 0.713852; batch adversarial loss: 0.717383\n",
      "epoch 3; iter: 0; batch classifier loss: 0.636415; batch adversarial loss: 0.678216\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564573; batch adversarial loss: 0.635972\n",
      "epoch 5; iter: 0; batch classifier loss: 0.535468; batch adversarial loss: 0.635008\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597853; batch adversarial loss: 0.590316\n",
      "epoch 7; iter: 0; batch classifier loss: 0.600676; batch adversarial loss: 0.592316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550883; batch adversarial loss: 0.591657\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530608; batch adversarial loss: 0.552549\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523843; batch adversarial loss: 0.546969\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535847; batch adversarial loss: 0.596304\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517469; batch adversarial loss: 0.557361\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536622; batch adversarial loss: 0.568487\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506032; batch adversarial loss: 0.577332\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501807; batch adversarial loss: 0.545980\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523879; batch adversarial loss: 0.506393\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537402; batch adversarial loss: 0.603492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524495; batch adversarial loss: 0.581751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485112; batch adversarial loss: 0.567896\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488170; batch adversarial loss: 0.603902\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499507; batch adversarial loss: 0.565259\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485051; batch adversarial loss: 0.614103\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493271; batch adversarial loss: 0.529834\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488039; batch adversarial loss: 0.669320\n",
      "epoch 25; iter: 0; batch classifier loss: 0.548497; batch adversarial loss: 0.587907\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512573; batch adversarial loss: 0.516359\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529635; batch adversarial loss: 0.529582\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515302; batch adversarial loss: 0.519808\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429720; batch adversarial loss: 0.624574\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404669; batch adversarial loss: 0.523093\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466059; batch adversarial loss: 0.538396\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417718; batch adversarial loss: 0.594056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450314; batch adversarial loss: 0.570973\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427090; batch adversarial loss: 0.488082\n",
      "epoch 35; iter: 0; batch classifier loss: 0.588309; batch adversarial loss: 0.534885\n",
      "epoch 36; iter: 0; batch classifier loss: 0.514815; batch adversarial loss: 0.554536\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407651; batch adversarial loss: 0.544531\n",
      "epoch 38; iter: 0; batch classifier loss: 0.499459; batch adversarial loss: 0.554323\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490981; batch adversarial loss: 0.545134\n",
      "epoch 40; iter: 0; batch classifier loss: 0.485479; batch adversarial loss: 0.577088\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463574; batch adversarial loss: 0.535579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.520202; batch adversarial loss: 0.543302\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416677; batch adversarial loss: 0.634581\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405529; batch adversarial loss: 0.643268\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402455; batch adversarial loss: 0.541703\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436086; batch adversarial loss: 0.565009\n",
      "epoch 47; iter: 0; batch classifier loss: 0.364892; batch adversarial loss: 0.571297\n",
      "epoch 48; iter: 0; batch classifier loss: 0.394420; batch adversarial loss: 0.519868\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438124; batch adversarial loss: 0.483752\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415647; batch adversarial loss: 0.536635\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431433; batch adversarial loss: 0.534314\n",
      "epoch 52; iter: 0; batch classifier loss: 0.474266; batch adversarial loss: 0.527226\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438481; batch adversarial loss: 0.554236\n",
      "epoch 54; iter: 0; batch classifier loss: 0.471214; batch adversarial loss: 0.578828\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441589; batch adversarial loss: 0.535082\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441694; batch adversarial loss: 0.552107\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457907; batch adversarial loss: 0.543764\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456808; batch adversarial loss: 0.544305\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433647; batch adversarial loss: 0.580373\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388327; batch adversarial loss: 0.447252\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397396; batch adversarial loss: 0.562839\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382208; batch adversarial loss: 0.571029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.454038; batch adversarial loss: 0.563049\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405926; batch adversarial loss: 0.491480\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448445; batch adversarial loss: 0.508945\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418054; batch adversarial loss: 0.491780\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402470; batch adversarial loss: 0.579629\n",
      "epoch 68; iter: 0; batch classifier loss: 0.387692; batch adversarial loss: 0.669734\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396873; batch adversarial loss: 0.597770\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417611; batch adversarial loss: 0.544707\n",
      "epoch 71; iter: 0; batch classifier loss: 0.452180; batch adversarial loss: 0.580490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.467152; batch adversarial loss: 0.597906\n",
      "epoch 73; iter: 0; batch classifier loss: 0.357054; batch adversarial loss: 0.508200\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452218; batch adversarial loss: 0.580077\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376737; batch adversarial loss: 0.536747\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386941; batch adversarial loss: 0.545418\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419082; batch adversarial loss: 0.606675\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395754; batch adversarial loss: 0.482358\n",
      "epoch 79; iter: 0; batch classifier loss: 0.412896; batch adversarial loss: 0.482972\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411125; batch adversarial loss: 0.509285\n",
      "epoch 81; iter: 0; batch classifier loss: 0.464798; batch adversarial loss: 0.500236\n",
      "epoch 82; iter: 0; batch classifier loss: 0.345271; batch adversarial loss: 0.535487\n",
      "epoch 83; iter: 0; batch classifier loss: 0.466719; batch adversarial loss: 0.589186\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429059; batch adversarial loss: 0.473579\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401294; batch adversarial loss: 0.606682\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389168; batch adversarial loss: 0.526942\n",
      "epoch 87; iter: 0; batch classifier loss: 0.425516; batch adversarial loss: 0.517716\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426136; batch adversarial loss: 0.526914\n",
      "epoch 89; iter: 0; batch classifier loss: 0.439155; batch adversarial loss: 0.562489\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426479; batch adversarial loss: 0.517952\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349682; batch adversarial loss: 0.615951\n",
      "epoch 92; iter: 0; batch classifier loss: 0.429389; batch adversarial loss: 0.589652\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410633; batch adversarial loss: 0.499733\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374746; batch adversarial loss: 0.542810\n",
      "epoch 95; iter: 0; batch classifier loss: 0.349359; batch adversarial loss: 0.517115\n",
      "epoch 96; iter: 0; batch classifier loss: 0.411928; batch adversarial loss: 0.608238\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404599; batch adversarial loss: 0.636373\n",
      "epoch 98; iter: 0; batch classifier loss: 0.475648; batch adversarial loss: 0.663071\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433383; batch adversarial loss: 0.480997\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360627; batch adversarial loss: 0.563805\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382179; batch adversarial loss: 0.597231\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400954; batch adversarial loss: 0.517526\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389380; batch adversarial loss: 0.589362\n",
      "epoch 104; iter: 0; batch classifier loss: 0.430528; batch adversarial loss: 0.553657\n",
      "epoch 105; iter: 0; batch classifier loss: 0.329662; batch adversarial loss: 0.596400\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390840; batch adversarial loss: 0.561005\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391095; batch adversarial loss: 0.629257\n",
      "epoch 108; iter: 0; batch classifier loss: 0.368772; batch adversarial loss: 0.517786\n",
      "epoch 109; iter: 0; batch classifier loss: 0.394763; batch adversarial loss: 0.483752\n",
      "epoch 110; iter: 0; batch classifier loss: 0.332164; batch adversarial loss: 0.638655\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393882; batch adversarial loss: 0.525014\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381994; batch adversarial loss: 0.597609\n",
      "epoch 113; iter: 0; batch classifier loss: 0.457319; batch adversarial loss: 0.583519\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383594; batch adversarial loss: 0.589297\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373359; batch adversarial loss: 0.501247\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359725; batch adversarial loss: 0.498654\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350149; batch adversarial loss: 0.528258\n",
      "epoch 118; iter: 0; batch classifier loss: 0.421645; batch adversarial loss: 0.554628\n",
      "epoch 119; iter: 0; batch classifier loss: 0.351626; batch adversarial loss: 0.597566\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378322; batch adversarial loss: 0.572139\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348053; batch adversarial loss: 0.552934\n",
      "epoch 122; iter: 0; batch classifier loss: 0.400252; batch adversarial loss: 0.580869\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408829; batch adversarial loss: 0.527610\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338164; batch adversarial loss: 0.561853\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389329; batch adversarial loss: 0.480458\n",
      "epoch 126; iter: 0; batch classifier loss: 0.430155; batch adversarial loss: 0.554301\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378755; batch adversarial loss: 0.533507\n",
      "epoch 128; iter: 0; batch classifier loss: 0.347175; batch adversarial loss: 0.563319\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355347; batch adversarial loss: 0.544985\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360827; batch adversarial loss: 0.526057\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355797; batch adversarial loss: 0.606676\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401674; batch adversarial loss: 0.508946\n",
      "epoch 133; iter: 0; batch classifier loss: 0.431991; batch adversarial loss: 0.571379\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341099; batch adversarial loss: 0.517924\n",
      "epoch 135; iter: 0; batch classifier loss: 0.309073; batch adversarial loss: 0.552800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356230; batch adversarial loss: 0.570738\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323178; batch adversarial loss: 0.500405\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365158; batch adversarial loss: 0.606991\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332514; batch adversarial loss: 0.509023\n",
      "epoch 140; iter: 0; batch classifier loss: 0.425082; batch adversarial loss: 0.634085\n",
      "epoch 141; iter: 0; batch classifier loss: 0.280756; batch adversarial loss: 0.537651\n",
      "epoch 142; iter: 0; batch classifier loss: 0.314804; batch adversarial loss: 0.605735\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351063; batch adversarial loss: 0.535644\n",
      "epoch 144; iter: 0; batch classifier loss: 0.321756; batch adversarial loss: 0.515009\n",
      "epoch 145; iter: 0; batch classifier loss: 0.445693; batch adversarial loss: 0.520098\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378567; batch adversarial loss: 0.553385\n",
      "epoch 147; iter: 0; batch classifier loss: 0.458505; batch adversarial loss: 0.571508\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366386; batch adversarial loss: 0.589773\n",
      "epoch 149; iter: 0; batch classifier loss: 0.332439; batch adversarial loss: 0.553692\n",
      "epoch 150; iter: 0; batch classifier loss: 0.305708; batch adversarial loss: 0.571461\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379235; batch adversarial loss: 0.587745\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346482; batch adversarial loss: 0.499738\n",
      "epoch 153; iter: 0; batch classifier loss: 0.295987; batch adversarial loss: 0.552382\n",
      "epoch 154; iter: 0; batch classifier loss: 0.435099; batch adversarial loss: 0.561453\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394397; batch adversarial loss: 0.542922\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403306; batch adversarial loss: 0.568426\n",
      "epoch 157; iter: 0; batch classifier loss: 0.401100; batch adversarial loss: 0.563328\n",
      "epoch 158; iter: 0; batch classifier loss: 0.432643; batch adversarial loss: 0.564412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.406759; batch adversarial loss: 0.515827\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349670; batch adversarial loss: 0.535212\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334469; batch adversarial loss: 0.553472\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386169; batch adversarial loss: 0.553836\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342395; batch adversarial loss: 0.598860\n",
      "epoch 164; iter: 0; batch classifier loss: 0.327197; batch adversarial loss: 0.517039\n",
      "epoch 165; iter: 0; batch classifier loss: 0.293496; batch adversarial loss: 0.635645\n",
      "epoch 166; iter: 0; batch classifier loss: 0.414397; batch adversarial loss: 0.589155\n",
      "epoch 167; iter: 0; batch classifier loss: 0.468937; batch adversarial loss: 0.599981\n",
      "epoch 168; iter: 0; batch classifier loss: 0.305260; batch adversarial loss: 0.517477\n",
      "epoch 169; iter: 0; batch classifier loss: 0.425712; batch adversarial loss: 0.508513\n",
      "epoch 170; iter: 0; batch classifier loss: 0.428058; batch adversarial loss: 0.562052\n",
      "epoch 171; iter: 0; batch classifier loss: 0.438188; batch adversarial loss: 0.572656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.428002; batch adversarial loss: 0.580772\n",
      "epoch 173; iter: 0; batch classifier loss: 0.467872; batch adversarial loss: 0.634089\n",
      "epoch 174; iter: 0; batch classifier loss: 0.438444; batch adversarial loss: 0.587904\n",
      "epoch 175; iter: 0; batch classifier loss: 0.418889; batch adversarial loss: 0.553395\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346179; batch adversarial loss: 0.500543\n",
      "epoch 177; iter: 0; batch classifier loss: 0.477076; batch adversarial loss: 0.527350\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351915; batch adversarial loss: 0.606817\n",
      "epoch 179; iter: 0; batch classifier loss: 0.307069; batch adversarial loss: 0.571366\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392787; batch adversarial loss: 0.572725\n",
      "epoch 181; iter: 0; batch classifier loss: 0.359661; batch adversarial loss: 0.482949\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367856; batch adversarial loss: 0.571888\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346704; batch adversarial loss: 0.616144\n",
      "epoch 184; iter: 0; batch classifier loss: 0.289528; batch adversarial loss: 0.589816\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351976; batch adversarial loss: 0.536730\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398709; batch adversarial loss: 0.527133\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313858; batch adversarial loss: 0.526474\n",
      "epoch 188; iter: 0; batch classifier loss: 0.360782; batch adversarial loss: 0.464795\n",
      "epoch 189; iter: 0; batch classifier loss: 0.302437; batch adversarial loss: 0.651853\n",
      "epoch 190; iter: 0; batch classifier loss: 0.393887; batch adversarial loss: 0.526749\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412490; batch adversarial loss: 0.561560\n",
      "epoch 192; iter: 0; batch classifier loss: 0.412783; batch adversarial loss: 0.517377\n",
      "epoch 193; iter: 0; batch classifier loss: 0.427714; batch adversarial loss: 0.624689\n",
      "epoch 194; iter: 0; batch classifier loss: 0.307434; batch adversarial loss: 0.580396\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382712; batch adversarial loss: 0.561534\n",
      "epoch 196; iter: 0; batch classifier loss: 0.437231; batch adversarial loss: 0.589725\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376333; batch adversarial loss: 0.482604\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355139; batch adversarial loss: 0.428706\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379052; batch adversarial loss: 0.580783\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693280; batch adversarial loss: 0.815806\n",
      "epoch 1; iter: 0; batch classifier loss: 0.702785; batch adversarial loss: 0.799094\n",
      "epoch 2; iter: 0; batch classifier loss: 0.815535; batch adversarial loss: 0.763610\n",
      "epoch 3; iter: 0; batch classifier loss: 0.790928; batch adversarial loss: 0.715687\n",
      "epoch 4; iter: 0; batch classifier loss: 0.652290; batch adversarial loss: 0.647708\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587311; batch adversarial loss: 0.600083\n",
      "epoch 6; iter: 0; batch classifier loss: 0.493568; batch adversarial loss: 0.613040\n",
      "epoch 7; iter: 0; batch classifier loss: 0.449119; batch adversarial loss: 0.608435\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553731; batch adversarial loss: 0.583691\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574491; batch adversarial loss: 0.578953\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488507; batch adversarial loss: 0.581485\n",
      "epoch 11; iter: 0; batch classifier loss: 0.625963; batch adversarial loss: 0.562973\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542070; batch adversarial loss: 0.584913\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545195; batch adversarial loss: 0.595261\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509355; batch adversarial loss: 0.569172\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475992; batch adversarial loss: 0.545473\n",
      "epoch 16; iter: 0; batch classifier loss: 0.446540; batch adversarial loss: 0.545467\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516316; batch adversarial loss: 0.521963\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520678; batch adversarial loss: 0.607084\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508234; batch adversarial loss: 0.602032\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508639; batch adversarial loss: 0.590786\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388877; batch adversarial loss: 0.584547\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513370; batch adversarial loss: 0.500764\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455661; batch adversarial loss: 0.656522\n",
      "epoch 24; iter: 0; batch classifier loss: 0.393560; batch adversarial loss: 0.505747\n",
      "epoch 25; iter: 0; batch classifier loss: 0.419750; batch adversarial loss: 0.611702\n",
      "epoch 26; iter: 0; batch classifier loss: 0.515958; batch adversarial loss: 0.538903\n",
      "epoch 27; iter: 0; batch classifier loss: 0.431540; batch adversarial loss: 0.557933\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439025; batch adversarial loss: 0.554380\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533651; batch adversarial loss: 0.600970\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524305; batch adversarial loss: 0.538837\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476354; batch adversarial loss: 0.591100\n",
      "epoch 32; iter: 0; batch classifier loss: 0.365109; batch adversarial loss: 0.586134\n",
      "epoch 33; iter: 0; batch classifier loss: 0.399094; batch adversarial loss: 0.507331\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457746; batch adversarial loss: 0.532473\n",
      "epoch 35; iter: 0; batch classifier loss: 0.500286; batch adversarial loss: 0.497366\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465984; batch adversarial loss: 0.541018\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465014; batch adversarial loss: 0.469570\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440534; batch adversarial loss: 0.560806\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441168; batch adversarial loss: 0.499503\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401271; batch adversarial loss: 0.593078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493303; batch adversarial loss: 0.433245\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433748; batch adversarial loss: 0.579114\n",
      "epoch 43; iter: 0; batch classifier loss: 0.404544; batch adversarial loss: 0.462687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407391; batch adversarial loss: 0.500813\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425214; batch adversarial loss: 0.461537\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405826; batch adversarial loss: 0.544774\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410088; batch adversarial loss: 0.492214\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389093; batch adversarial loss: 0.572429\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460846; batch adversarial loss: 0.536529\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391758; batch adversarial loss: 0.526242\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450729; batch adversarial loss: 0.498664\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450131; batch adversarial loss: 0.516899\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452259; batch adversarial loss: 0.489168\n",
      "epoch 54; iter: 0; batch classifier loss: 0.498688; batch adversarial loss: 0.553849\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417878; batch adversarial loss: 0.618476\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456282; batch adversarial loss: 0.553532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.400934; batch adversarial loss: 0.535721\n",
      "epoch 58; iter: 0; batch classifier loss: 0.489153; batch adversarial loss: 0.563222\n",
      "epoch 59; iter: 0; batch classifier loss: 0.353534; batch adversarial loss: 0.553034\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457069; batch adversarial loss: 0.554617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427512; batch adversarial loss: 0.542353\n",
      "epoch 62; iter: 0; batch classifier loss: 0.345094; batch adversarial loss: 0.543142\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390626; batch adversarial loss: 0.562292\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420684; batch adversarial loss: 0.609764\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450829; batch adversarial loss: 0.544047\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408816; batch adversarial loss: 0.581291\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447203; batch adversarial loss: 0.498168\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417937; batch adversarial loss: 0.517552\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357369; batch adversarial loss: 0.506473\n",
      "epoch 70; iter: 0; batch classifier loss: 0.320029; batch adversarial loss: 0.527082\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380262; batch adversarial loss: 0.544014\n",
      "epoch 72; iter: 0; batch classifier loss: 0.527324; batch adversarial loss: 0.563264\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386378; batch adversarial loss: 0.637926\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416632; batch adversarial loss: 0.534875\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377109; batch adversarial loss: 0.591950\n",
      "epoch 76; iter: 0; batch classifier loss: 0.330725; batch adversarial loss: 0.553940\n",
      "epoch 77; iter: 0; batch classifier loss: 0.342652; batch adversarial loss: 0.527026\n",
      "epoch 78; iter: 0; batch classifier loss: 0.320546; batch adversarial loss: 0.469069\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452161; batch adversarial loss: 0.516060\n",
      "epoch 80; iter: 0; batch classifier loss: 0.331704; batch adversarial loss: 0.536573\n",
      "epoch 81; iter: 0; batch classifier loss: 0.469879; batch adversarial loss: 0.497665\n",
      "epoch 82; iter: 0; batch classifier loss: 0.433739; batch adversarial loss: 0.583001\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391247; batch adversarial loss: 0.499935\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406355; batch adversarial loss: 0.533980\n",
      "epoch 85; iter: 0; batch classifier loss: 0.465504; batch adversarial loss: 0.589158\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381623; batch adversarial loss: 0.614884\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396112; batch adversarial loss: 0.441127\n",
      "epoch 88; iter: 0; batch classifier loss: 0.328193; batch adversarial loss: 0.527191\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382363; batch adversarial loss: 0.479086\n",
      "epoch 90; iter: 0; batch classifier loss: 0.416037; batch adversarial loss: 0.441297\n",
      "epoch 91; iter: 0; batch classifier loss: 0.326307; batch adversarial loss: 0.488667\n",
      "epoch 92; iter: 0; batch classifier loss: 0.335888; batch adversarial loss: 0.640405\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358278; batch adversarial loss: 0.591533\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303857; batch adversarial loss: 0.532970\n",
      "epoch 95; iter: 0; batch classifier loss: 0.453438; batch adversarial loss: 0.489628\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401312; batch adversarial loss: 0.585444\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366700; batch adversarial loss: 0.551661\n",
      "epoch 98; iter: 0; batch classifier loss: 0.413183; batch adversarial loss: 0.478318\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360212; batch adversarial loss: 0.478148\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349583; batch adversarial loss: 0.514638\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382684; batch adversarial loss: 0.546623\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377431; batch adversarial loss: 0.526328\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381081; batch adversarial loss: 0.507233\n",
      "epoch 104; iter: 0; batch classifier loss: 0.336841; batch adversarial loss: 0.561463\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382005; batch adversarial loss: 0.573659\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382854; batch adversarial loss: 0.533121\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388552; batch adversarial loss: 0.497069\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399808; batch adversarial loss: 0.499711\n",
      "epoch 109; iter: 0; batch classifier loss: 0.329313; batch adversarial loss: 0.515051\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426646; batch adversarial loss: 0.608725\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339861; batch adversarial loss: 0.600833\n",
      "epoch 112; iter: 0; batch classifier loss: 0.343946; batch adversarial loss: 0.591762\n",
      "epoch 113; iter: 0; batch classifier loss: 0.348933; batch adversarial loss: 0.496933\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364358; batch adversarial loss: 0.621166\n",
      "epoch 115; iter: 0; batch classifier loss: 0.442370; batch adversarial loss: 0.524386\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372087; batch adversarial loss: 0.572929\n",
      "epoch 117; iter: 0; batch classifier loss: 0.452821; batch adversarial loss: 0.525428\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405221; batch adversarial loss: 0.547154\n",
      "epoch 119; iter: 0; batch classifier loss: 0.289276; batch adversarial loss: 0.580069\n",
      "epoch 120; iter: 0; batch classifier loss: 0.404902; batch adversarial loss: 0.498536\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376198; batch adversarial loss: 0.581882\n",
      "epoch 122; iter: 0; batch classifier loss: 0.315041; batch adversarial loss: 0.573251\n",
      "epoch 123; iter: 0; batch classifier loss: 0.469363; batch adversarial loss: 0.590693\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374787; batch adversarial loss: 0.497963\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386033; batch adversarial loss: 0.600707\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316631; batch adversarial loss: 0.469026\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391398; batch adversarial loss: 0.497877\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366143; batch adversarial loss: 0.544218\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406631; batch adversarial loss: 0.544421\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387347; batch adversarial loss: 0.526320\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406654; batch adversarial loss: 0.496534\n",
      "epoch 132; iter: 0; batch classifier loss: 0.412803; batch adversarial loss: 0.516632\n",
      "epoch 133; iter: 0; batch classifier loss: 0.446451; batch adversarial loss: 0.527071\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340003; batch adversarial loss: 0.573834\n",
      "epoch 135; iter: 0; batch classifier loss: 0.309869; batch adversarial loss: 0.488206\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312485; batch adversarial loss: 0.563519\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413207; batch adversarial loss: 0.599712\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381601; batch adversarial loss: 0.525546\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395987; batch adversarial loss: 0.569501\n",
      "epoch 140; iter: 0; batch classifier loss: 0.322473; batch adversarial loss: 0.537463\n",
      "epoch 141; iter: 0; batch classifier loss: 0.327989; batch adversarial loss: 0.544785\n",
      "epoch 142; iter: 0; batch classifier loss: 0.310006; batch adversarial loss: 0.555883\n",
      "epoch 143; iter: 0; batch classifier loss: 0.295029; batch adversarial loss: 0.592715\n",
      "epoch 144; iter: 0; batch classifier loss: 0.491900; batch adversarial loss: 0.516153\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348784; batch adversarial loss: 0.535434\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368664; batch adversarial loss: 0.618587\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400626; batch adversarial loss: 0.496852\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338790; batch adversarial loss: 0.600728\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363690; batch adversarial loss: 0.553608\n",
      "epoch 150; iter: 0; batch classifier loss: 0.286896; batch adversarial loss: 0.573389\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358726; batch adversarial loss: 0.525585\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352957; batch adversarial loss: 0.552733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.412388; batch adversarial loss: 0.506964\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376097; batch adversarial loss: 0.600042\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362233; batch adversarial loss: 0.600471\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390630; batch adversarial loss: 0.524951\n",
      "epoch 157; iter: 0; batch classifier loss: 0.415707; batch adversarial loss: 0.488405\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347223; batch adversarial loss: 0.514965\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348396; batch adversarial loss: 0.535443\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331982; batch adversarial loss: 0.517147\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339629; batch adversarial loss: 0.581103\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379940; batch adversarial loss: 0.524909\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336870; batch adversarial loss: 0.608106\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394387; batch adversarial loss: 0.544343\n",
      "epoch 165; iter: 0; batch classifier loss: 0.283188; batch adversarial loss: 0.460687\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310187; batch adversarial loss: 0.578656\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347115; batch adversarial loss: 0.534911\n",
      "epoch 168; iter: 0; batch classifier loss: 0.278434; batch adversarial loss: 0.460319\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353865; batch adversarial loss: 0.551058\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336640; batch adversarial loss: 0.544876\n",
      "epoch 171; iter: 0; batch classifier loss: 0.457646; batch adversarial loss: 0.496367\n",
      "epoch 172; iter: 0; batch classifier loss: 0.307297; batch adversarial loss: 0.616611\n",
      "epoch 173; iter: 0; batch classifier loss: 0.460085; batch adversarial loss: 0.517419\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395938; batch adversarial loss: 0.563233\n",
      "epoch 175; iter: 0; batch classifier loss: 0.300581; batch adversarial loss: 0.468813\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353947; batch adversarial loss: 0.507913\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312388; batch adversarial loss: 0.513395\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333491; batch adversarial loss: 0.555796\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339496; batch adversarial loss: 0.597532\n",
      "epoch 180; iter: 0; batch classifier loss: 0.301724; batch adversarial loss: 0.528615\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363731; batch adversarial loss: 0.488459\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314365; batch adversarial loss: 0.499820\n",
      "epoch 183; iter: 0; batch classifier loss: 0.305334; batch adversarial loss: 0.620028\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404692; batch adversarial loss: 0.525846\n",
      "epoch 185; iter: 0; batch classifier loss: 0.291273; batch adversarial loss: 0.497080\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366985; batch adversarial loss: 0.524742\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314061; batch adversarial loss: 0.563096\n",
      "epoch 188; iter: 0; batch classifier loss: 0.323916; batch adversarial loss: 0.545311\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368791; batch adversarial loss: 0.524424\n",
      "epoch 190; iter: 0; batch classifier loss: 0.393915; batch adversarial loss: 0.546162\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322682; batch adversarial loss: 0.507542\n",
      "epoch 192; iter: 0; batch classifier loss: 0.301519; batch adversarial loss: 0.534936\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309644; batch adversarial loss: 0.601287\n",
      "epoch 194; iter: 0; batch classifier loss: 0.284085; batch adversarial loss: 0.562921\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397065; batch adversarial loss: 0.553517\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327594; batch adversarial loss: 0.506476\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336817; batch adversarial loss: 0.526214\n",
      "epoch 198; iter: 0; batch classifier loss: 0.437532; batch adversarial loss: 0.535545\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357034; batch adversarial loss: 0.470581\n",
      "epoch 0; iter: 0; batch classifier loss: 0.775324; batch adversarial loss: 0.876076\n",
      "epoch 1; iter: 0; batch classifier loss: 0.802639; batch adversarial loss: 0.852731\n",
      "epoch 2; iter: 0; batch classifier loss: 0.758707; batch adversarial loss: 0.748504\n",
      "epoch 3; iter: 0; batch classifier loss: 0.732691; batch adversarial loss: 0.736468\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614239; batch adversarial loss: 0.650127\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587269; batch adversarial loss: 0.633285\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597549; batch adversarial loss: 0.622699\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579559; batch adversarial loss: 0.615361\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538350; batch adversarial loss: 0.666441\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518614; batch adversarial loss: 0.585519\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551875; batch adversarial loss: 0.582631\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488650; batch adversarial loss: 0.601054\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533906; batch adversarial loss: 0.599324\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495189; batch adversarial loss: 0.642879\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548527; batch adversarial loss: 0.533097\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542398; batch adversarial loss: 0.602287\n",
      "epoch 16; iter: 0; batch classifier loss: 0.444320; batch adversarial loss: 0.583148\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467606; batch adversarial loss: 0.576972\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439022; batch adversarial loss: 0.574825\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496107; batch adversarial loss: 0.562271\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516794; batch adversarial loss: 0.571606\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480510; batch adversarial loss: 0.574899\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489091; batch adversarial loss: 0.622637\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506580; batch adversarial loss: 0.472778\n",
      "epoch 24; iter: 0; batch classifier loss: 0.443733; batch adversarial loss: 0.522614\n",
      "epoch 25; iter: 0; batch classifier loss: 0.426602; batch adversarial loss: 0.524805\n",
      "epoch 26; iter: 0; batch classifier loss: 0.574410; batch adversarial loss: 0.562398\n",
      "epoch 27; iter: 0; batch classifier loss: 0.438439; batch adversarial loss: 0.560367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.544740; batch adversarial loss: 0.539235\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475031; batch adversarial loss: 0.526807\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524266; batch adversarial loss: 0.638874\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445670; batch adversarial loss: 0.560632\n",
      "epoch 32; iter: 0; batch classifier loss: 0.476337; batch adversarial loss: 0.520851\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475858; batch adversarial loss: 0.506042\n",
      "epoch 34; iter: 0; batch classifier loss: 0.383146; batch adversarial loss: 0.533163\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460888; batch adversarial loss: 0.506992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422074; batch adversarial loss: 0.522797\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427163; batch adversarial loss: 0.559058\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386547; batch adversarial loss: 0.535385\n",
      "epoch 39; iter: 0; batch classifier loss: 0.506858; batch adversarial loss: 0.575507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.521253; batch adversarial loss: 0.554536\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456855; batch adversarial loss: 0.521389\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459690; batch adversarial loss: 0.546514\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395394; batch adversarial loss: 0.567260\n",
      "epoch 44; iter: 0; batch classifier loss: 0.550339; batch adversarial loss: 0.555390\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469887; batch adversarial loss: 0.528215\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430139; batch adversarial loss: 0.599081\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441377; batch adversarial loss: 0.454874\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424757; batch adversarial loss: 0.553956\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435243; batch adversarial loss: 0.563259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.444453; batch adversarial loss: 0.495165\n",
      "epoch 51; iter: 0; batch classifier loss: 0.370418; batch adversarial loss: 0.569874\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441463; batch adversarial loss: 0.470715\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390691; batch adversarial loss: 0.516523\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409403; batch adversarial loss: 0.600098\n",
      "epoch 55; iter: 0; batch classifier loss: 0.368880; batch adversarial loss: 0.683237\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463921; batch adversarial loss: 0.462411\n",
      "epoch 57; iter: 0; batch classifier loss: 0.377212; batch adversarial loss: 0.608227\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425852; batch adversarial loss: 0.515779\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419513; batch adversarial loss: 0.637729\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422658; batch adversarial loss: 0.498001\n",
      "epoch 61; iter: 0; batch classifier loss: 0.363635; batch adversarial loss: 0.526762\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368042; batch adversarial loss: 0.545421\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412116; batch adversarial loss: 0.542485\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431478; batch adversarial loss: 0.534889\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445982; batch adversarial loss: 0.599694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398395; batch adversarial loss: 0.533938\n",
      "epoch 67; iter: 0; batch classifier loss: 0.422091; batch adversarial loss: 0.619208\n",
      "epoch 68; iter: 0; batch classifier loss: 0.331304; batch adversarial loss: 0.565779\n",
      "epoch 69; iter: 0; batch classifier loss: 0.550351; batch adversarial loss: 0.524793\n",
      "epoch 70; iter: 0; batch classifier loss: 0.328667; batch adversarial loss: 0.516889\n",
      "epoch 71; iter: 0; batch classifier loss: 0.374521; batch adversarial loss: 0.572571\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448072; batch adversarial loss: 0.478441\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422850; batch adversarial loss: 0.535103\n",
      "epoch 74; iter: 0; batch classifier loss: 0.304305; batch adversarial loss: 0.609449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.325052; batch adversarial loss: 0.599813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384946; batch adversarial loss: 0.497906\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400909; batch adversarial loss: 0.591296\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392813; batch adversarial loss: 0.413535\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381220; batch adversarial loss: 0.526656\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470474; batch adversarial loss: 0.602874\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405066; batch adversarial loss: 0.526383\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405100; batch adversarial loss: 0.507261\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404912; batch adversarial loss: 0.544216\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382115; batch adversarial loss: 0.516496\n",
      "epoch 85; iter: 0; batch classifier loss: 0.429389; batch adversarial loss: 0.507388\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471678; batch adversarial loss: 0.470035\n",
      "epoch 87; iter: 0; batch classifier loss: 0.431701; batch adversarial loss: 0.544499\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349473; batch adversarial loss: 0.572258\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461915; batch adversarial loss: 0.553932\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463091; batch adversarial loss: 0.637959\n",
      "epoch 91; iter: 0; batch classifier loss: 0.489596; batch adversarial loss: 0.525593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378841; batch adversarial loss: 0.572493\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379657; batch adversarial loss: 0.554068\n",
      "epoch 94; iter: 0; batch classifier loss: 0.331751; batch adversarial loss: 0.545520\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397135; batch adversarial loss: 0.553734\n",
      "epoch 96; iter: 0; batch classifier loss: 0.450765; batch adversarial loss: 0.459313\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334700; batch adversarial loss: 0.505190\n",
      "epoch 98; iter: 0; batch classifier loss: 0.445260; batch adversarial loss: 0.534647\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397935; batch adversarial loss: 0.488865\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403760; batch adversarial loss: 0.544319\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370880; batch adversarial loss: 0.497930\n",
      "epoch 102; iter: 0; batch classifier loss: 0.423746; batch adversarial loss: 0.553538\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377716; batch adversarial loss: 0.506460\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390244; batch adversarial loss: 0.563321\n",
      "epoch 105; iter: 0; batch classifier loss: 0.326291; batch adversarial loss: 0.478722\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352175; batch adversarial loss: 0.421857\n",
      "epoch 107; iter: 0; batch classifier loss: 0.359863; batch adversarial loss: 0.488358\n",
      "epoch 108; iter: 0; batch classifier loss: 0.432902; batch adversarial loss: 0.497856\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379009; batch adversarial loss: 0.526181\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386168; batch adversarial loss: 0.498037\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336066; batch adversarial loss: 0.515815\n",
      "epoch 112; iter: 0; batch classifier loss: 0.420811; batch adversarial loss: 0.563147\n",
      "epoch 113; iter: 0; batch classifier loss: 0.307102; batch adversarial loss: 0.525974\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376770; batch adversarial loss: 0.591757\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419657; batch adversarial loss: 0.619663\n",
      "epoch 116; iter: 0; batch classifier loss: 0.433194; batch adversarial loss: 0.467984\n",
      "epoch 117; iter: 0; batch classifier loss: 0.432396; batch adversarial loss: 0.506248\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375257; batch adversarial loss: 0.488447\n",
      "epoch 119; iter: 0; batch classifier loss: 0.435526; batch adversarial loss: 0.562737\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418710; batch adversarial loss: 0.545798\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394172; batch adversarial loss: 0.544354\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369480; batch adversarial loss: 0.507151\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403310; batch adversarial loss: 0.544148\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398854; batch adversarial loss: 0.572844\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380844; batch adversarial loss: 0.421383\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403694; batch adversarial loss: 0.563221\n",
      "epoch 127; iter: 0; batch classifier loss: 0.418951; batch adversarial loss: 0.517146\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334074; batch adversarial loss: 0.525860\n",
      "epoch 129; iter: 0; batch classifier loss: 0.341423; batch adversarial loss: 0.600199\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372986; batch adversarial loss: 0.535523\n",
      "epoch 131; iter: 0; batch classifier loss: 0.314339; batch adversarial loss: 0.468523\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329006; batch adversarial loss: 0.527539\n",
      "epoch 133; iter: 0; batch classifier loss: 0.345206; batch adversarial loss: 0.545400\n",
      "epoch 134; iter: 0; batch classifier loss: 0.464327; batch adversarial loss: 0.581573\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369718; batch adversarial loss: 0.534773\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397963; batch adversarial loss: 0.553277\n",
      "epoch 137; iter: 0; batch classifier loss: 0.295474; batch adversarial loss: 0.516756\n",
      "epoch 138; iter: 0; batch classifier loss: 0.391742; batch adversarial loss: 0.563002\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369538; batch adversarial loss: 0.516670\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343215; batch adversarial loss: 0.562982\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368249; batch adversarial loss: 0.610713\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364101; batch adversarial loss: 0.581922\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380064; batch adversarial loss: 0.525287\n",
      "epoch 144; iter: 0; batch classifier loss: 0.335888; batch adversarial loss: 0.515882\n",
      "epoch 145; iter: 0; batch classifier loss: 0.423052; batch adversarial loss: 0.602847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.391120; batch adversarial loss: 0.524384\n",
      "epoch 147; iter: 0; batch classifier loss: 0.406694; batch adversarial loss: 0.553126\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339872; batch adversarial loss: 0.581959\n",
      "epoch 149; iter: 0; batch classifier loss: 0.296568; batch adversarial loss: 0.648930\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379631; batch adversarial loss: 0.516116\n",
      "epoch 151; iter: 0; batch classifier loss: 0.434949; batch adversarial loss: 0.498143\n",
      "epoch 152; iter: 0; batch classifier loss: 0.429802; batch adversarial loss: 0.620024\n",
      "epoch 153; iter: 0; batch classifier loss: 0.442727; batch adversarial loss: 0.496954\n",
      "epoch 154; iter: 0; batch classifier loss: 0.334870; batch adversarial loss: 0.498000\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340654; batch adversarial loss: 0.535413\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377212; batch adversarial loss: 0.498141\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384555; batch adversarial loss: 0.544109\n",
      "epoch 158; iter: 0; batch classifier loss: 0.402475; batch adversarial loss: 0.572725\n",
      "epoch 159; iter: 0; batch classifier loss: 0.335023; batch adversarial loss: 0.526605\n",
      "epoch 160; iter: 0; batch classifier loss: 0.420383; batch adversarial loss: 0.593091\n",
      "epoch 161; iter: 0; batch classifier loss: 0.409789; batch adversarial loss: 0.487614\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370533; batch adversarial loss: 0.478168\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388053; batch adversarial loss: 0.525681\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358970; batch adversarial loss: 0.488536\n",
      "epoch 165; iter: 0; batch classifier loss: 0.323890; batch adversarial loss: 0.628216\n",
      "epoch 166; iter: 0; batch classifier loss: 0.306672; batch adversarial loss: 0.609189\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318800; batch adversarial loss: 0.554138\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341455; batch adversarial loss: 0.516355\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354434; batch adversarial loss: 0.582624\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324391; batch adversarial loss: 0.545384\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390606; batch adversarial loss: 0.517166\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297581; batch adversarial loss: 0.534553\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389781; batch adversarial loss: 0.543865\n",
      "epoch 174; iter: 0; batch classifier loss: 0.416469; batch adversarial loss: 0.618924\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352062; batch adversarial loss: 0.582488\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353480; batch adversarial loss: 0.460755\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384418; batch adversarial loss: 0.581937\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337552; batch adversarial loss: 0.526461\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379326; batch adversarial loss: 0.535046\n",
      "epoch 180; iter: 0; batch classifier loss: 0.446429; batch adversarial loss: 0.497767\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321538; batch adversarial loss: 0.609857\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381465; batch adversarial loss: 0.619940\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393900; batch adversarial loss: 0.562868\n",
      "epoch 184; iter: 0; batch classifier loss: 0.312666; batch adversarial loss: 0.563308\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349788; batch adversarial loss: 0.535054\n",
      "epoch 186; iter: 0; batch classifier loss: 0.369589; batch adversarial loss: 0.543911\n",
      "epoch 187; iter: 0; batch classifier loss: 0.286389; batch adversarial loss: 0.497780\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366130; batch adversarial loss: 0.600509\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357544; batch adversarial loss: 0.488564\n",
      "epoch 190; iter: 0; batch classifier loss: 0.416497; batch adversarial loss: 0.572640\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364944; batch adversarial loss: 0.460382\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344292; batch adversarial loss: 0.497481\n",
      "epoch 193; iter: 0; batch classifier loss: 0.379155; batch adversarial loss: 0.544557\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356900; batch adversarial loss: 0.590559\n",
      "epoch 195; iter: 0; batch classifier loss: 0.435730; batch adversarial loss: 0.563116\n",
      "epoch 196; iter: 0; batch classifier loss: 0.379385; batch adversarial loss: 0.535206\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345385; batch adversarial loss: 0.582143\n",
      "epoch 198; iter: 0; batch classifier loss: 0.385553; batch adversarial loss: 0.526320\n",
      "epoch 199; iter: 0; batch classifier loss: 0.249929; batch adversarial loss: 0.535081\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716448; batch adversarial loss: 0.843772\n",
      "epoch 1; iter: 0; batch classifier loss: 0.874271; batch adversarial loss: 0.990956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.854875; batch adversarial loss: 0.857221\n",
      "epoch 3; iter: 0; batch classifier loss: 0.978870; batch adversarial loss: 0.877766\n",
      "epoch 4; iter: 0; batch classifier loss: 0.815599; batch adversarial loss: 0.802636\n",
      "epoch 5; iter: 0; batch classifier loss: 0.666264; batch adversarial loss: 0.731039\n",
      "epoch 6; iter: 0; batch classifier loss: 0.650218; batch adversarial loss: 0.642685\n",
      "epoch 7; iter: 0; batch classifier loss: 0.622324; batch adversarial loss: 0.586396\n",
      "epoch 8; iter: 0; batch classifier loss: 0.652644; batch adversarial loss: 0.647519\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574686; batch adversarial loss: 0.609319\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573866; batch adversarial loss: 0.603129\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528275; batch adversarial loss: 0.570952\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550618; batch adversarial loss: 0.609904\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502327; batch adversarial loss: 0.594358\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573411; batch adversarial loss: 0.556980\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500578; batch adversarial loss: 0.570637\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547889; batch adversarial loss: 0.587709\n",
      "epoch 17; iter: 0; batch classifier loss: 0.624666; batch adversarial loss: 0.637996\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503492; batch adversarial loss: 0.562449\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592318; batch adversarial loss: 0.601606\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512752; batch adversarial loss: 0.575774\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530866; batch adversarial loss: 0.576128\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531411; batch adversarial loss: 0.556765\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492029; batch adversarial loss: 0.662053\n",
      "epoch 24; iter: 0; batch classifier loss: 0.536810; batch adversarial loss: 0.668240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566022; batch adversarial loss: 0.579814\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480772; batch adversarial loss: 0.561824\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509652; batch adversarial loss: 0.588047\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442501; batch adversarial loss: 0.619531\n",
      "epoch 29; iter: 0; batch classifier loss: 0.523695; batch adversarial loss: 0.533443\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462191; batch adversarial loss: 0.615506\n",
      "epoch 31; iter: 0; batch classifier loss: 0.504391; batch adversarial loss: 0.554720\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428833; batch adversarial loss: 0.513293\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470555; batch adversarial loss: 0.568791\n",
      "epoch 34; iter: 0; batch classifier loss: 0.493166; batch adversarial loss: 0.534959\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441380; batch adversarial loss: 0.548741\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499603; batch adversarial loss: 0.529503\n",
      "epoch 37; iter: 0; batch classifier loss: 0.504087; batch adversarial loss: 0.496340\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417523; batch adversarial loss: 0.533737\n",
      "epoch 39; iter: 0; batch classifier loss: 0.518303; batch adversarial loss: 0.605296\n",
      "epoch 40; iter: 0; batch classifier loss: 0.482714; batch adversarial loss: 0.517758\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404700; batch adversarial loss: 0.603501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.421070; batch adversarial loss: 0.579683\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478314; batch adversarial loss: 0.537379\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407676; batch adversarial loss: 0.555223\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470562; batch adversarial loss: 0.520127\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370345; batch adversarial loss: 0.579081\n",
      "epoch 47; iter: 0; batch classifier loss: 0.550489; batch adversarial loss: 0.543067\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421046; batch adversarial loss: 0.570881\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383498; batch adversarial loss: 0.503883\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491521; batch adversarial loss: 0.509831\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463860; batch adversarial loss: 0.501029\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393786; batch adversarial loss: 0.554448\n",
      "epoch 53; iter: 0; batch classifier loss: 0.506994; batch adversarial loss: 0.621532\n",
      "epoch 54; iter: 0; batch classifier loss: 0.459092; batch adversarial loss: 0.562164\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439687; batch adversarial loss: 0.562549\n",
      "epoch 56; iter: 0; batch classifier loss: 0.458102; batch adversarial loss: 0.572108\n",
      "epoch 57; iter: 0; batch classifier loss: 0.480212; batch adversarial loss: 0.466400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.459324; batch adversarial loss: 0.544731\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343645; batch adversarial loss: 0.616168\n",
      "epoch 60; iter: 0; batch classifier loss: 0.359820; batch adversarial loss: 0.615906\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455506; batch adversarial loss: 0.473665\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440593; batch adversarial loss: 0.631180\n",
      "epoch 63; iter: 0; batch classifier loss: 0.372031; batch adversarial loss: 0.589378\n",
      "epoch 64; iter: 0; batch classifier loss: 0.336728; batch adversarial loss: 0.537062\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439671; batch adversarial loss: 0.491663\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457350; batch adversarial loss: 0.568926\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406291; batch adversarial loss: 0.606723\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438227; batch adversarial loss: 0.527662\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388509; batch adversarial loss: 0.562134\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427919; batch adversarial loss: 0.542530\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386833; batch adversarial loss: 0.567099\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414440; batch adversarial loss: 0.606906\n",
      "epoch 73; iter: 0; batch classifier loss: 0.457728; batch adversarial loss: 0.645737\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356066; batch adversarial loss: 0.599822\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389164; batch adversarial loss: 0.608216\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427579; batch adversarial loss: 0.506961\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373627; batch adversarial loss: 0.557189\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394343; batch adversarial loss: 0.499449\n",
      "epoch 79; iter: 0; batch classifier loss: 0.454551; batch adversarial loss: 0.569260\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416792; batch adversarial loss: 0.552777\n",
      "epoch 81; iter: 0; batch classifier loss: 0.455809; batch adversarial loss: 0.472226\n",
      "epoch 82; iter: 0; batch classifier loss: 0.357246; batch adversarial loss: 0.618823\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423864; batch adversarial loss: 0.595178\n",
      "epoch 84; iter: 0; batch classifier loss: 0.427819; batch adversarial loss: 0.512349\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435409; batch adversarial loss: 0.587067\n",
      "epoch 86; iter: 0; batch classifier loss: 0.434036; batch adversarial loss: 0.509702\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422418; batch adversarial loss: 0.553214\n",
      "epoch 88; iter: 0; batch classifier loss: 0.443222; batch adversarial loss: 0.550109\n",
      "epoch 89; iter: 0; batch classifier loss: 0.458241; batch adversarial loss: 0.543384\n",
      "epoch 90; iter: 0; batch classifier loss: 0.473935; batch adversarial loss: 0.523223\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405446; batch adversarial loss: 0.526817\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407840; batch adversarial loss: 0.537790\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450037; batch adversarial loss: 0.554719\n",
      "epoch 94; iter: 0; batch classifier loss: 0.281193; batch adversarial loss: 0.602289\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361776; batch adversarial loss: 0.548356\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414796; batch adversarial loss: 0.544536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395992; batch adversarial loss: 0.579641\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362890; batch adversarial loss: 0.494830\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410055; batch adversarial loss: 0.588093\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373655; batch adversarial loss: 0.609411\n",
      "epoch 101; iter: 0; batch classifier loss: 0.318062; batch adversarial loss: 0.600806\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335433; batch adversarial loss: 0.542889\n",
      "epoch 103; iter: 0; batch classifier loss: 0.447746; batch adversarial loss: 0.551941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.453349; batch adversarial loss: 0.588522\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383869; batch adversarial loss: 0.553721\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389535; batch adversarial loss: 0.609030\n",
      "epoch 107; iter: 0; batch classifier loss: 0.420711; batch adversarial loss: 0.648225\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357760; batch adversarial loss: 0.534941\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380157; batch adversarial loss: 0.536635\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421649; batch adversarial loss: 0.546862\n",
      "epoch 111; iter: 0; batch classifier loss: 0.327939; batch adversarial loss: 0.535534\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385527; batch adversarial loss: 0.569298\n",
      "epoch 113; iter: 0; batch classifier loss: 0.332607; batch adversarial loss: 0.500783\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394875; batch adversarial loss: 0.532937\n",
      "epoch 115; iter: 0; batch classifier loss: 0.457059; batch adversarial loss: 0.525234\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396439; batch adversarial loss: 0.501201\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358401; batch adversarial loss: 0.483874\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363241; batch adversarial loss: 0.579239\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363159; batch adversarial loss: 0.525203\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391973; batch adversarial loss: 0.544787\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381267; batch adversarial loss: 0.542823\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360547; batch adversarial loss: 0.582118\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388837; batch adversarial loss: 0.570778\n",
      "epoch 124; iter: 0; batch classifier loss: 0.362130; batch adversarial loss: 0.618298\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390680; batch adversarial loss: 0.540836\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386152; batch adversarial loss: 0.510249\n",
      "epoch 127; iter: 0; batch classifier loss: 0.416425; batch adversarial loss: 0.512186\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351281; batch adversarial loss: 0.546668\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369697; batch adversarial loss: 0.536998\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332845; batch adversarial loss: 0.605553\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376949; batch adversarial loss: 0.544894\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373630; batch adversarial loss: 0.513621\n",
      "epoch 133; iter: 0; batch classifier loss: 0.488520; batch adversarial loss: 0.594195\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377141; batch adversarial loss: 0.553371\n",
      "epoch 135; iter: 0; batch classifier loss: 0.423490; batch adversarial loss: 0.572661\n",
      "epoch 136; iter: 0; batch classifier loss: 0.409936; batch adversarial loss: 0.544763\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372566; batch adversarial loss: 0.593054\n",
      "epoch 138; iter: 0; batch classifier loss: 0.409291; batch adversarial loss: 0.496682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.384914; batch adversarial loss: 0.519478\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327880; batch adversarial loss: 0.457352\n",
      "epoch 141; iter: 0; batch classifier loss: 0.393399; batch adversarial loss: 0.613777\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396295; batch adversarial loss: 0.622708\n",
      "epoch 143; iter: 0; batch classifier loss: 0.421201; batch adversarial loss: 0.526475\n",
      "epoch 144; iter: 0; batch classifier loss: 0.311316; batch adversarial loss: 0.493497\n",
      "epoch 145; iter: 0; batch classifier loss: 0.307083; batch adversarial loss: 0.580557\n",
      "epoch 146; iter: 0; batch classifier loss: 0.409760; batch adversarial loss: 0.497450\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347652; batch adversarial loss: 0.553455\n",
      "epoch 148; iter: 0; batch classifier loss: 0.301758; batch adversarial loss: 0.523648\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339800; batch adversarial loss: 0.525348\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362032; batch adversarial loss: 0.599333\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378961; batch adversarial loss: 0.563891\n",
      "epoch 152; iter: 0; batch classifier loss: 0.450609; batch adversarial loss: 0.563174\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371937; batch adversarial loss: 0.507258\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374772; batch adversarial loss: 0.517054\n",
      "epoch 155; iter: 0; batch classifier loss: 0.281475; batch adversarial loss: 0.615210\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361931; batch adversarial loss: 0.552642\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349789; batch adversarial loss: 0.483576\n",
      "epoch 158; iter: 0; batch classifier loss: 0.401560; batch adversarial loss: 0.589751\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352629; batch adversarial loss: 0.572388\n",
      "epoch 160; iter: 0; batch classifier loss: 0.303455; batch adversarial loss: 0.521672\n",
      "epoch 161; iter: 0; batch classifier loss: 0.446970; batch adversarial loss: 0.578072\n",
      "epoch 162; iter: 0; batch classifier loss: 0.272011; batch adversarial loss: 0.500574\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335050; batch adversarial loss: 0.575814\n",
      "epoch 164; iter: 0; batch classifier loss: 0.365120; batch adversarial loss: 0.500829\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359619; batch adversarial loss: 0.557742\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352588; batch adversarial loss: 0.608614\n",
      "epoch 167; iter: 0; batch classifier loss: 0.304613; batch adversarial loss: 0.535051\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392144; batch adversarial loss: 0.576345\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358440; batch adversarial loss: 0.550144\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376558; batch adversarial loss: 0.533645\n",
      "epoch 171; iter: 0; batch classifier loss: 0.415055; batch adversarial loss: 0.572776\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398809; batch adversarial loss: 0.596739\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360226; batch adversarial loss: 0.557967\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369822; batch adversarial loss: 0.543376\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402513; batch adversarial loss: 0.591137\n",
      "epoch 176; iter: 0; batch classifier loss: 0.416339; batch adversarial loss: 0.521143\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366211; batch adversarial loss: 0.570659\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352829; batch adversarial loss: 0.518683\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340547; batch adversarial loss: 0.510298\n",
      "epoch 180; iter: 0; batch classifier loss: 0.385464; batch adversarial loss: 0.529260\n",
      "epoch 181; iter: 0; batch classifier loss: 0.306235; batch adversarial loss: 0.563951\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351429; batch adversarial loss: 0.490047\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388243; batch adversarial loss: 0.635751\n",
      "epoch 184; iter: 0; batch classifier loss: 0.345201; batch adversarial loss: 0.554309\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381487; batch adversarial loss: 0.463119\n",
      "epoch 186; iter: 0; batch classifier loss: 0.277949; batch adversarial loss: 0.566239\n",
      "epoch 187; iter: 0; batch classifier loss: 0.403040; batch adversarial loss: 0.596292\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336694; batch adversarial loss: 0.519520\n",
      "epoch 189; iter: 0; batch classifier loss: 0.419273; batch adversarial loss: 0.563098\n",
      "epoch 190; iter: 0; batch classifier loss: 0.363025; batch adversarial loss: 0.532853\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368231; batch adversarial loss: 0.555024\n",
      "epoch 192; iter: 0; batch classifier loss: 0.391006; batch adversarial loss: 0.571561\n",
      "epoch 193; iter: 0; batch classifier loss: 0.454797; batch adversarial loss: 0.489202\n",
      "epoch 194; iter: 0; batch classifier loss: 0.415202; batch adversarial loss: 0.642988\n",
      "epoch 195; iter: 0; batch classifier loss: 0.282710; batch adversarial loss: 0.592647\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352172; batch adversarial loss: 0.545882\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388373; batch adversarial loss: 0.581396\n",
      "epoch 198; iter: 0; batch classifier loss: 0.268161; batch adversarial loss: 0.528090\n",
      "epoch 199; iter: 0; batch classifier loss: 0.435955; batch adversarial loss: 0.546497\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719149; batch adversarial loss: 1.146284\n",
      "epoch 1; iter: 0; batch classifier loss: 0.988804; batch adversarial loss: 1.417481\n",
      "epoch 2; iter: 0; batch classifier loss: 1.144557; batch adversarial loss: 1.349072\n",
      "epoch 3; iter: 0; batch classifier loss: 1.158552; batch adversarial loss: 1.215362\n",
      "epoch 4; iter: 0; batch classifier loss: 1.008499; batch adversarial loss: 1.143209\n",
      "epoch 5; iter: 0; batch classifier loss: 1.108836; batch adversarial loss: 1.048417\n",
      "epoch 6; iter: 0; batch classifier loss: 1.187317; batch adversarial loss: 0.965938\n",
      "epoch 7; iter: 0; batch classifier loss: 1.208641; batch adversarial loss: 0.894057\n",
      "epoch 8; iter: 0; batch classifier loss: 1.207590; batch adversarial loss: 0.837333\n",
      "epoch 9; iter: 0; batch classifier loss: 1.141765; batch adversarial loss: 0.785955\n",
      "epoch 10; iter: 0; batch classifier loss: 1.116816; batch adversarial loss: 0.728765\n",
      "epoch 11; iter: 0; batch classifier loss: 1.192581; batch adversarial loss: 0.683932\n",
      "epoch 12; iter: 0; batch classifier loss: 1.067167; batch adversarial loss: 0.699892\n",
      "epoch 13; iter: 0; batch classifier loss: 1.084447; batch adversarial loss: 0.587523\n",
      "epoch 14; iter: 0; batch classifier loss: 0.931422; batch adversarial loss: 0.584027\n",
      "epoch 15; iter: 0; batch classifier loss: 0.732136; batch adversarial loss: 0.601070\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577200; batch adversarial loss: 0.657851\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526753; batch adversarial loss: 0.584765\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545430; batch adversarial loss: 0.538114\n",
      "epoch 19; iter: 0; batch classifier loss: 0.589887; batch adversarial loss: 0.584160\n",
      "epoch 20; iter: 0; batch classifier loss: 0.536368; batch adversarial loss: 0.595786\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477660; batch adversarial loss: 0.575273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493183; batch adversarial loss: 0.589551\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498348; batch adversarial loss: 0.533416\n",
      "epoch 24; iter: 0; batch classifier loss: 0.584928; batch adversarial loss: 0.584758\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468582; batch adversarial loss: 0.563621\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560344; batch adversarial loss: 0.572649\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421327; batch adversarial loss: 0.509126\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494485; batch adversarial loss: 0.611914\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501022; batch adversarial loss: 0.580806\n",
      "epoch 30; iter: 0; batch classifier loss: 0.511622; batch adversarial loss: 0.578778\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492371; batch adversarial loss: 0.571018\n",
      "epoch 32; iter: 0; batch classifier loss: 0.505735; batch adversarial loss: 0.534822\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447234; batch adversarial loss: 0.577472\n",
      "epoch 34; iter: 0; batch classifier loss: 0.541770; batch adversarial loss: 0.557206\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504436; batch adversarial loss: 0.524194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.507906; batch adversarial loss: 0.493799\n",
      "epoch 37; iter: 0; batch classifier loss: 0.557927; batch adversarial loss: 0.529231\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468966; batch adversarial loss: 0.490894\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462136; batch adversarial loss: 0.551444\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444850; batch adversarial loss: 0.619202\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473643; batch adversarial loss: 0.548650\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440715; batch adversarial loss: 0.506220\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382340; batch adversarial loss: 0.523506\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456112; batch adversarial loss: 0.493685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.552629; batch adversarial loss: 0.570482\n",
      "epoch 46; iter: 0; batch classifier loss: 0.513213; batch adversarial loss: 0.530742\n",
      "epoch 47; iter: 0; batch classifier loss: 0.359513; batch adversarial loss: 0.500481\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474836; batch adversarial loss: 0.605354\n",
      "epoch 49; iter: 0; batch classifier loss: 0.514307; batch adversarial loss: 0.543135\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470315; batch adversarial loss: 0.571242\n",
      "epoch 51; iter: 0; batch classifier loss: 0.412322; batch adversarial loss: 0.581254\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389454; batch adversarial loss: 0.536825\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430505; batch adversarial loss: 0.584043\n",
      "epoch 54; iter: 0; batch classifier loss: 0.378478; batch adversarial loss: 0.570328\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434607; batch adversarial loss: 0.661003\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377405; batch adversarial loss: 0.517868\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432438; batch adversarial loss: 0.581516\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423372; batch adversarial loss: 0.543072\n",
      "epoch 59; iter: 0; batch classifier loss: 0.345928; batch adversarial loss: 0.536255\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433830; batch adversarial loss: 0.528140\n",
      "epoch 61; iter: 0; batch classifier loss: 0.525366; batch adversarial loss: 0.588985\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414603; batch adversarial loss: 0.563370\n",
      "epoch 63; iter: 0; batch classifier loss: 0.368771; batch adversarial loss: 0.534752\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422095; batch adversarial loss: 0.516599\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441703; batch adversarial loss: 0.534788\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381874; batch adversarial loss: 0.544828\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394637; batch adversarial loss: 0.489022\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356273; batch adversarial loss: 0.608249\n",
      "epoch 69; iter: 0; batch classifier loss: 0.484960; batch adversarial loss: 0.525391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.405813; batch adversarial loss: 0.581714\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393888; batch adversarial loss: 0.583423\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415366; batch adversarial loss: 0.573089\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392855; batch adversarial loss: 0.482891\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403541; batch adversarial loss: 0.581461\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391518; batch adversarial loss: 0.481192\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359744; batch adversarial loss: 0.599584\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396522; batch adversarial loss: 0.562589\n",
      "epoch 78; iter: 0; batch classifier loss: 0.425354; batch adversarial loss: 0.555000\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432144; batch adversarial loss: 0.525385\n",
      "epoch 80; iter: 0; batch classifier loss: 0.397083; batch adversarial loss: 0.543134\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409245; batch adversarial loss: 0.536122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382649; batch adversarial loss: 0.578425\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383335; batch adversarial loss: 0.506363\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375561; batch adversarial loss: 0.571592\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424486; batch adversarial loss: 0.474017\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399509; batch adversarial loss: 0.599641\n",
      "epoch 87; iter: 0; batch classifier loss: 0.457152; batch adversarial loss: 0.515077\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388427; batch adversarial loss: 0.508048\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350691; batch adversarial loss: 0.567856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.361002; batch adversarial loss: 0.539607\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406080; batch adversarial loss: 0.522723\n",
      "epoch 92; iter: 0; batch classifier loss: 0.448748; batch adversarial loss: 0.533116\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397515; batch adversarial loss: 0.536947\n",
      "epoch 94; iter: 0; batch classifier loss: 0.485056; batch adversarial loss: 0.497826\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343869; batch adversarial loss: 0.516743\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382374; batch adversarial loss: 0.573297\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360249; batch adversarial loss: 0.540849\n",
      "epoch 98; iter: 0; batch classifier loss: 0.455307; batch adversarial loss: 0.591740\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378807; batch adversarial loss: 0.583709\n",
      "epoch 100; iter: 0; batch classifier loss: 0.314640; batch adversarial loss: 0.584282\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386513; batch adversarial loss: 0.461444\n",
      "epoch 102; iter: 0; batch classifier loss: 0.344094; batch adversarial loss: 0.552835\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364954; batch adversarial loss: 0.491880\n",
      "epoch 104; iter: 0; batch classifier loss: 0.403172; batch adversarial loss: 0.574955\n",
      "epoch 105; iter: 0; batch classifier loss: 0.376189; batch adversarial loss: 0.601473\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389193; batch adversarial loss: 0.578483\n",
      "epoch 107; iter: 0; batch classifier loss: 0.423091; batch adversarial loss: 0.538237\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405316; batch adversarial loss: 0.588211\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384034; batch adversarial loss: 0.504724\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373581; batch adversarial loss: 0.545362\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401116; batch adversarial loss: 0.562215\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433920; batch adversarial loss: 0.503111\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373317; batch adversarial loss: 0.515848\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367393; batch adversarial loss: 0.510231\n",
      "epoch 115; iter: 0; batch classifier loss: 0.353778; batch adversarial loss: 0.517973\n",
      "epoch 116; iter: 0; batch classifier loss: 0.281366; batch adversarial loss: 0.581923\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337040; batch adversarial loss: 0.540338\n",
      "epoch 118; iter: 0; batch classifier loss: 0.344186; batch adversarial loss: 0.571390\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386229; batch adversarial loss: 0.530422\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338115; batch adversarial loss: 0.469220\n",
      "epoch 121; iter: 0; batch classifier loss: 0.324834; batch adversarial loss: 0.508608\n",
      "epoch 122; iter: 0; batch classifier loss: 0.432747; batch adversarial loss: 0.505321\n",
      "epoch 123; iter: 0; batch classifier loss: 0.312190; batch adversarial loss: 0.650147\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352491; batch adversarial loss: 0.496789\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393906; batch adversarial loss: 0.537815\n",
      "epoch 126; iter: 0; batch classifier loss: 0.341745; batch adversarial loss: 0.558945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.322697; batch adversarial loss: 0.582144\n",
      "epoch 128; iter: 0; batch classifier loss: 0.321615; batch adversarial loss: 0.533360\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338489; batch adversarial loss: 0.551863\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425785; batch adversarial loss: 0.519675\n",
      "epoch 131; iter: 0; batch classifier loss: 0.342864; batch adversarial loss: 0.513538\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317034; batch adversarial loss: 0.574010\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361689; batch adversarial loss: 0.498507\n",
      "epoch 134; iter: 0; batch classifier loss: 0.303056; batch adversarial loss: 0.558460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.365999; batch adversarial loss: 0.509616\n",
      "epoch 136; iter: 0; batch classifier loss: 0.321218; batch adversarial loss: 0.609038\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378591; batch adversarial loss: 0.470658\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393290; batch adversarial loss: 0.605756\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405409; batch adversarial loss: 0.364831\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404735; batch adversarial loss: 0.513011\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409055; batch adversarial loss: 0.570101\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353792; batch adversarial loss: 0.588874\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.592802\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302620; batch adversarial loss: 0.507311\n",
      "epoch 145; iter: 0; batch classifier loss: 0.337801; batch adversarial loss: 0.559629\n",
      "epoch 146; iter: 0; batch classifier loss: 0.473543; batch adversarial loss: 0.572583\n",
      "epoch 147; iter: 0; batch classifier loss: 0.389097; batch adversarial loss: 0.548839\n",
      "epoch 148; iter: 0; batch classifier loss: 0.324410; batch adversarial loss: 0.578338\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316794; batch adversarial loss: 0.534256\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392620; batch adversarial loss: 0.502757\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379277; batch adversarial loss: 0.458479\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335094; batch adversarial loss: 0.543031\n",
      "epoch 153; iter: 0; batch classifier loss: 0.311401; batch adversarial loss: 0.471748\n",
      "epoch 154; iter: 0; batch classifier loss: 0.307216; batch adversarial loss: 0.464677\n",
      "epoch 155; iter: 0; batch classifier loss: 0.299615; batch adversarial loss: 0.567416\n",
      "epoch 156; iter: 0; batch classifier loss: 0.433157; batch adversarial loss: 0.554147\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331031; batch adversarial loss: 0.490613\n",
      "epoch 158; iter: 0; batch classifier loss: 0.249962; batch adversarial loss: 0.506854\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333428; batch adversarial loss: 0.529410\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344242; batch adversarial loss: 0.563221\n",
      "epoch 161; iter: 0; batch classifier loss: 0.300839; batch adversarial loss: 0.568653\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337356; batch adversarial loss: 0.544074\n",
      "epoch 163; iter: 0; batch classifier loss: 0.307406; batch adversarial loss: 0.470931\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371028; batch adversarial loss: 0.544158\n",
      "epoch 165; iter: 0; batch classifier loss: 0.283643; batch adversarial loss: 0.592971\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330799; batch adversarial loss: 0.524160\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323722; batch adversarial loss: 0.551194\n",
      "epoch 168; iter: 0; batch classifier loss: 0.381412; batch adversarial loss: 0.507250\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357611; batch adversarial loss: 0.506869\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339597; batch adversarial loss: 0.499537\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344604; batch adversarial loss: 0.530382\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344078; batch adversarial loss: 0.574724\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354364; batch adversarial loss: 0.556249\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344347; batch adversarial loss: 0.453907\n",
      "epoch 175; iter: 0; batch classifier loss: 0.312576; batch adversarial loss: 0.497540\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344280; batch adversarial loss: 0.553363\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337125; batch adversarial loss: 0.543599\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353431; batch adversarial loss: 0.545865\n",
      "epoch 179; iter: 0; batch classifier loss: 0.287578; batch adversarial loss: 0.509104\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329230; batch adversarial loss: 0.560080\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305597; batch adversarial loss: 0.593117\n",
      "epoch 182; iter: 0; batch classifier loss: 0.312467; batch adversarial loss: 0.610369\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341752; batch adversarial loss: 0.525342\n",
      "epoch 184; iter: 0; batch classifier loss: 0.307148; batch adversarial loss: 0.492549\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351484; batch adversarial loss: 0.496396\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377559; batch adversarial loss: 0.469758\n",
      "epoch 187; iter: 0; batch classifier loss: 0.283580; batch adversarial loss: 0.478680\n",
      "epoch 188; iter: 0; batch classifier loss: 0.319535; batch adversarial loss: 0.562703\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344284; batch adversarial loss: 0.542647\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314048; batch adversarial loss: 0.481199\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380205; batch adversarial loss: 0.552695\n",
      "epoch 192; iter: 0; batch classifier loss: 0.303513; batch adversarial loss: 0.524752\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339016; batch adversarial loss: 0.580393\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372021; batch adversarial loss: 0.488031\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350523; batch adversarial loss: 0.548709\n",
      "epoch 196; iter: 0; batch classifier loss: 0.311682; batch adversarial loss: 0.532368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.421433; batch adversarial loss: 0.523861\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366130; batch adversarial loss: 0.567990\n",
      "epoch 199; iter: 0; batch classifier loss: 0.320891; batch adversarial loss: 0.498073\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657707; batch adversarial loss: 0.651014\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632213; batch adversarial loss: 0.674661\n",
      "epoch 2; iter: 0; batch classifier loss: 0.546531; batch adversarial loss: 0.664750\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559904; batch adversarial loss: 0.616069\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646619; batch adversarial loss: 0.684468\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630771; batch adversarial loss: 0.636402\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568670; batch adversarial loss: 0.627273\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546944; batch adversarial loss: 0.610671\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619688; batch adversarial loss: 0.579425\n",
      "epoch 9; iter: 0; batch classifier loss: 0.684586; batch adversarial loss: 0.534291\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502776; batch adversarial loss: 0.593466\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517122; batch adversarial loss: 0.560099\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554339; batch adversarial loss: 0.625530\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509069; batch adversarial loss: 0.584493\n",
      "epoch 14; iter: 0; batch classifier loss: 0.587953; batch adversarial loss: 0.582932\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508486; batch adversarial loss: 0.567258\n",
      "epoch 16; iter: 0; batch classifier loss: 0.641126; batch adversarial loss: 0.599255\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568002; batch adversarial loss: 0.553873\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514031; batch adversarial loss: 0.616226\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458074; batch adversarial loss: 0.591667\n",
      "epoch 20; iter: 0; batch classifier loss: 0.569297; batch adversarial loss: 0.571217\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487586; batch adversarial loss: 0.487150\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415963; batch adversarial loss: 0.634811\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495362; batch adversarial loss: 0.619014\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502435; batch adversarial loss: 0.542770\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494596; batch adversarial loss: 0.469807\n",
      "epoch 26; iter: 0; batch classifier loss: 0.549582; batch adversarial loss: 0.619611\n",
      "epoch 27; iter: 0; batch classifier loss: 0.512572; batch adversarial loss: 0.580956\n",
      "epoch 28; iter: 0; batch classifier loss: 0.466463; batch adversarial loss: 0.563514\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486944; batch adversarial loss: 0.646260\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474422; batch adversarial loss: 0.580450\n",
      "epoch 31; iter: 0; batch classifier loss: 0.564920; batch adversarial loss: 0.562104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.445912; batch adversarial loss: 0.554210\n",
      "epoch 33; iter: 0; batch classifier loss: 0.508272; batch adversarial loss: 0.579290\n",
      "epoch 34; iter: 0; batch classifier loss: 0.407007; batch adversarial loss: 0.587093\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422830; batch adversarial loss: 0.612015\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495658; batch adversarial loss: 0.552737\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445437; batch adversarial loss: 0.510973\n",
      "epoch 38; iter: 0; batch classifier loss: 0.576374; batch adversarial loss: 0.529177\n",
      "epoch 39; iter: 0; batch classifier loss: 0.543462; batch adversarial loss: 0.510870\n",
      "epoch 40; iter: 0; batch classifier loss: 0.528696; batch adversarial loss: 0.509151\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499870; batch adversarial loss: 0.624176\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444821; batch adversarial loss: 0.544539\n",
      "epoch 43; iter: 0; batch classifier loss: 0.354337; batch adversarial loss: 0.597377\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415482; batch adversarial loss: 0.509584\n",
      "epoch 45; iter: 0; batch classifier loss: 0.515786; batch adversarial loss: 0.571775\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423762; batch adversarial loss: 0.544969\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424573; batch adversarial loss: 0.483690\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429352; batch adversarial loss: 0.535253\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401680; batch adversarial loss: 0.562397\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452450; batch adversarial loss: 0.598300\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441048; batch adversarial loss: 0.579991\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451120; batch adversarial loss: 0.632862\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415623; batch adversarial loss: 0.533174\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418734; batch adversarial loss: 0.526006\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428591; batch adversarial loss: 0.500490\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468676; batch adversarial loss: 0.501534\n",
      "epoch 57; iter: 0; batch classifier loss: 0.363350; batch adversarial loss: 0.605881\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434757; batch adversarial loss: 0.490184\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425989; batch adversarial loss: 0.563443\n",
      "epoch 60; iter: 0; batch classifier loss: 0.529046; batch adversarial loss: 0.571037\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383801; batch adversarial loss: 0.546572\n",
      "epoch 62; iter: 0; batch classifier loss: 0.383996; batch adversarial loss: 0.493532\n",
      "epoch 63; iter: 0; batch classifier loss: 0.474570; batch adversarial loss: 0.521602\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449119; batch adversarial loss: 0.555769\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369739; batch adversarial loss: 0.599223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.506840; batch adversarial loss: 0.544410\n",
      "epoch 67; iter: 0; batch classifier loss: 0.347513; batch adversarial loss: 0.509155\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447878; batch adversarial loss: 0.588805\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451464; batch adversarial loss: 0.598953\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455880; batch adversarial loss: 0.588581\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409227; batch adversarial loss: 0.485503\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390657; batch adversarial loss: 0.499482\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417462; batch adversarial loss: 0.490746\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403435; batch adversarial loss: 0.536417\n",
      "epoch 75; iter: 0; batch classifier loss: 0.466409; batch adversarial loss: 0.630943\n",
      "epoch 76; iter: 0; batch classifier loss: 0.321060; batch adversarial loss: 0.561879\n",
      "epoch 77; iter: 0; batch classifier loss: 0.311985; batch adversarial loss: 0.623460\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366850; batch adversarial loss: 0.614944\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437825; batch adversarial loss: 0.579430\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356125; batch adversarial loss: 0.506740\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429047; batch adversarial loss: 0.589245\n",
      "epoch 82; iter: 0; batch classifier loss: 0.468954; batch adversarial loss: 0.544960\n",
      "epoch 83; iter: 0; batch classifier loss: 0.537231; batch adversarial loss: 0.597550\n",
      "epoch 84; iter: 0; batch classifier loss: 0.425039; batch adversarial loss: 0.581567\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398331; batch adversarial loss: 0.527718\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395014; batch adversarial loss: 0.512843\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364326; batch adversarial loss: 0.483465\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352249; batch adversarial loss: 0.564192\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394912; batch adversarial loss: 0.547005\n",
      "epoch 90; iter: 0; batch classifier loss: 0.527024; batch adversarial loss: 0.564364\n",
      "epoch 91; iter: 0; batch classifier loss: 0.457082; batch adversarial loss: 0.484319\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370346; batch adversarial loss: 0.529125\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418393; batch adversarial loss: 0.579054\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406140; batch adversarial loss: 0.543300\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417735; batch adversarial loss: 0.694232\n",
      "epoch 96; iter: 0; batch classifier loss: 0.465537; batch adversarial loss: 0.471233\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425092; batch adversarial loss: 0.589559\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385278; batch adversarial loss: 0.520534\n",
      "epoch 99; iter: 0; batch classifier loss: 0.455921; batch adversarial loss: 0.528501\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400214; batch adversarial loss: 0.579144\n",
      "epoch 101; iter: 0; batch classifier loss: 0.450788; batch adversarial loss: 0.613404\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380993; batch adversarial loss: 0.484276\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363656; batch adversarial loss: 0.500434\n",
      "epoch 104; iter: 0; batch classifier loss: 0.355172; batch adversarial loss: 0.553777\n",
      "epoch 105; iter: 0; batch classifier loss: 0.460965; batch adversarial loss: 0.570640\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335800; batch adversarial loss: 0.607010\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351091; batch adversarial loss: 0.562297\n",
      "epoch 108; iter: 0; batch classifier loss: 0.346297; batch adversarial loss: 0.544200\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357198; batch adversarial loss: 0.543894\n",
      "epoch 110; iter: 0; batch classifier loss: 0.450155; batch adversarial loss: 0.509032\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361905; batch adversarial loss: 0.500210\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403616; batch adversarial loss: 0.510571\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419333; batch adversarial loss: 0.561931\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382983; batch adversarial loss: 0.587485\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388144; batch adversarial loss: 0.518607\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368441; batch adversarial loss: 0.529139\n",
      "epoch 117; iter: 0; batch classifier loss: 0.397577; batch adversarial loss: 0.528879\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389900; batch adversarial loss: 0.551330\n",
      "epoch 119; iter: 0; batch classifier loss: 0.471163; batch adversarial loss: 0.545439\n",
      "epoch 120; iter: 0; batch classifier loss: 0.404874; batch adversarial loss: 0.597104\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351793; batch adversarial loss: 0.563341\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330643; batch adversarial loss: 0.588838\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401271; batch adversarial loss: 0.554932\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348670; batch adversarial loss: 0.634091\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376741; batch adversarial loss: 0.544795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363208; batch adversarial loss: 0.533703\n",
      "epoch 127; iter: 0; batch classifier loss: 0.430696; batch adversarial loss: 0.480554\n",
      "epoch 128; iter: 0; batch classifier loss: 0.468302; batch adversarial loss: 0.509107\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428472; batch adversarial loss: 0.620780\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382541; batch adversarial loss: 0.509733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.379692; batch adversarial loss: 0.533630\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395082; batch adversarial loss: 0.519546\n",
      "epoch 133; iter: 0; batch classifier loss: 0.435920; batch adversarial loss: 0.553629\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377575; batch adversarial loss: 0.570559\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378817; batch adversarial loss: 0.560999\n",
      "epoch 136; iter: 0; batch classifier loss: 0.344833; batch adversarial loss: 0.482916\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344248; batch adversarial loss: 0.542352\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348671; batch adversarial loss: 0.616266\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397490; batch adversarial loss: 0.508620\n",
      "epoch 140; iter: 0; batch classifier loss: 0.433805; batch adversarial loss: 0.556736\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366186; batch adversarial loss: 0.546947\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363516; batch adversarial loss: 0.542945\n",
      "epoch 143; iter: 0; batch classifier loss: 0.441768; batch adversarial loss: 0.559419\n",
      "epoch 144; iter: 0; batch classifier loss: 0.328687; batch adversarial loss: 0.581036\n",
      "epoch 145; iter: 0; batch classifier loss: 0.449513; batch adversarial loss: 0.473183\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384982; batch adversarial loss: 0.517372\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383721; batch adversarial loss: 0.571561\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335175; batch adversarial loss: 0.542188\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353880; batch adversarial loss: 0.578729\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350457; batch adversarial loss: 0.486207\n",
      "epoch 151; iter: 0; batch classifier loss: 0.435163; batch adversarial loss: 0.613932\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405886; batch adversarial loss: 0.589210\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360568; batch adversarial loss: 0.519056\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394846; batch adversarial loss: 0.475313\n",
      "epoch 155; iter: 0; batch classifier loss: 0.402509; batch adversarial loss: 0.635516\n",
      "epoch 156; iter: 0; batch classifier loss: 0.389750; batch adversarial loss: 0.551786\n",
      "epoch 157; iter: 0; batch classifier loss: 0.343219; batch adversarial loss: 0.578976\n",
      "epoch 158; iter: 0; batch classifier loss: 0.480799; batch adversarial loss: 0.508651\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379807; batch adversarial loss: 0.525936\n",
      "epoch 160; iter: 0; batch classifier loss: 0.483722; batch adversarial loss: 0.518242\n",
      "epoch 161; iter: 0; batch classifier loss: 0.371005; batch adversarial loss: 0.604355\n",
      "epoch 162; iter: 0; batch classifier loss: 0.290035; batch adversarial loss: 0.537397\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385504; batch adversarial loss: 0.577212\n",
      "epoch 164; iter: 0; batch classifier loss: 0.433579; batch adversarial loss: 0.569949\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346885; batch adversarial loss: 0.571315\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389240; batch adversarial loss: 0.495359\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390614; batch adversarial loss: 0.552279\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318999; batch adversarial loss: 0.560802\n",
      "epoch 169; iter: 0; batch classifier loss: 0.310367; batch adversarial loss: 0.563136\n",
      "epoch 170; iter: 0; batch classifier loss: 0.406680; batch adversarial loss: 0.516750\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325132; batch adversarial loss: 0.499534\n",
      "epoch 172; iter: 0; batch classifier loss: 0.285026; batch adversarial loss: 0.544614\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381221; batch adversarial loss: 0.563358\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385803; batch adversarial loss: 0.591977\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400130; batch adversarial loss: 0.579449\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397177; batch adversarial loss: 0.597667\n",
      "epoch 177; iter: 0; batch classifier loss: 0.459043; batch adversarial loss: 0.615817\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326435; batch adversarial loss: 0.500631\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389943; batch adversarial loss: 0.505425\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346818; batch adversarial loss: 0.517781\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350000; batch adversarial loss: 0.573217\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368268; batch adversarial loss: 0.571436\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356497; batch adversarial loss: 0.553163\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366563; batch adversarial loss: 0.552818\n",
      "epoch 185; iter: 0; batch classifier loss: 0.285683; batch adversarial loss: 0.553233\n",
      "epoch 186; iter: 0; batch classifier loss: 0.301422; batch adversarial loss: 0.499515\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360355; batch adversarial loss: 0.579442\n",
      "epoch 188; iter: 0; batch classifier loss: 0.467136; batch adversarial loss: 0.571199\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379609; batch adversarial loss: 0.535147\n",
      "epoch 190; iter: 0; batch classifier loss: 0.348099; batch adversarial loss: 0.491141\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306548; batch adversarial loss: 0.623855\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356861; batch adversarial loss: 0.580587\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387095; batch adversarial loss: 0.517231\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395981; batch adversarial loss: 0.574271\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368011; batch adversarial loss: 0.528468\n",
      "epoch 196; iter: 0; batch classifier loss: 0.467844; batch adversarial loss: 0.615094\n",
      "epoch 197; iter: 0; batch classifier loss: 0.399645; batch adversarial loss: 0.533420\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389845; batch adversarial loss: 0.658098\n",
      "epoch 199; iter: 0; batch classifier loss: 0.292997; batch adversarial loss: 0.508488\n",
      "epoch 0; iter: 0; batch classifier loss: 0.796515; batch adversarial loss: 0.656240\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605686; batch adversarial loss: 0.657795\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587601; batch adversarial loss: 0.593970\n",
      "epoch 3; iter: 0; batch classifier loss: 0.495280; batch adversarial loss: 0.672719\n",
      "epoch 4; iter: 0; batch classifier loss: 0.622654; batch adversarial loss: 0.629117\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534087; batch adversarial loss: 0.632373\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535805; batch adversarial loss: 0.627312\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532413; batch adversarial loss: 0.650897\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513978; batch adversarial loss: 0.693033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578467; batch adversarial loss: 0.595304\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548480; batch adversarial loss: 0.535509\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512016; batch adversarial loss: 0.507436\n",
      "epoch 12; iter: 0; batch classifier loss: 0.585673; batch adversarial loss: 0.595029\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559973; batch adversarial loss: 0.571781\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545392; batch adversarial loss: 0.524608\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503342; batch adversarial loss: 0.537833\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492087; batch adversarial loss: 0.593472\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491590; batch adversarial loss: 0.571624\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482182; batch adversarial loss: 0.508241\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551856; batch adversarial loss: 0.558165\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488619; batch adversarial loss: 0.572837\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501861; batch adversarial loss: 0.541052\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451499; batch adversarial loss: 0.532017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489860; batch adversarial loss: 0.557549\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494273; batch adversarial loss: 0.612781\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468072; batch adversarial loss: 0.537879\n",
      "epoch 26; iter: 0; batch classifier loss: 0.380039; batch adversarial loss: 0.625116\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503894; batch adversarial loss: 0.597963\n",
      "epoch 28; iter: 0; batch classifier loss: 0.449567; batch adversarial loss: 0.551565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.441987; batch adversarial loss: 0.620633\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457298; batch adversarial loss: 0.527007\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432705; batch adversarial loss: 0.671438\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479284; batch adversarial loss: 0.635991\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460987; batch adversarial loss: 0.563844\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447151; batch adversarial loss: 0.587613\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444400; batch adversarial loss: 0.510434\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450357; batch adversarial loss: 0.606739\n",
      "epoch 37; iter: 0; batch classifier loss: 0.501101; batch adversarial loss: 0.509675\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437350; batch adversarial loss: 0.491670\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477726; batch adversarial loss: 0.428091\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428358; batch adversarial loss: 0.535677\n",
      "epoch 41; iter: 0; batch classifier loss: 0.543304; batch adversarial loss: 0.589689\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422576; batch adversarial loss: 0.599091\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439252; batch adversarial loss: 0.572530\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469949; batch adversarial loss: 0.526447\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458218; batch adversarial loss: 0.590219\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460630; batch adversarial loss: 0.544288\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429537; batch adversarial loss: 0.544612\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434836; batch adversarial loss: 0.525666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430033; batch adversarial loss: 0.526120\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457380; batch adversarial loss: 0.525756\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466345; batch adversarial loss: 0.516160\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382582; batch adversarial loss: 0.581702\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409110; batch adversarial loss: 0.544722\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405634; batch adversarial loss: 0.609017\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468686; batch adversarial loss: 0.461761\n",
      "epoch 56; iter: 0; batch classifier loss: 0.318165; batch adversarial loss: 0.554063\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409555; batch adversarial loss: 0.516742\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469134; batch adversarial loss: 0.507454\n",
      "epoch 59; iter: 0; batch classifier loss: 0.359641; batch adversarial loss: 0.580967\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376894; batch adversarial loss: 0.544757\n",
      "epoch 61; iter: 0; batch classifier loss: 0.462648; batch adversarial loss: 0.535920\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423308; batch adversarial loss: 0.489316\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448126; batch adversarial loss: 0.526146\n",
      "epoch 64; iter: 0; batch classifier loss: 0.456903; batch adversarial loss: 0.581488\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442123; batch adversarial loss: 0.619209\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433274; batch adversarial loss: 0.535310\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408409; batch adversarial loss: 0.470035\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396092; batch adversarial loss: 0.573132\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358386; batch adversarial loss: 0.535244\n",
      "epoch 70; iter: 0; batch classifier loss: 0.334394; batch adversarial loss: 0.497622\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437004; batch adversarial loss: 0.581801\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414555; batch adversarial loss: 0.618590\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438748; batch adversarial loss: 0.618357\n",
      "epoch 74; iter: 0; batch classifier loss: 0.442114; batch adversarial loss: 0.554580\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426018; batch adversarial loss: 0.516557\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459790; batch adversarial loss: 0.516419\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406979; batch adversarial loss: 0.553918\n",
      "epoch 78; iter: 0; batch classifier loss: 0.476473; batch adversarial loss: 0.517074\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406206; batch adversarial loss: 0.534674\n",
      "epoch 80; iter: 0; batch classifier loss: 0.386946; batch adversarial loss: 0.601072\n",
      "epoch 81; iter: 0; batch classifier loss: 0.466238; batch adversarial loss: 0.535638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422055; batch adversarial loss: 0.545092\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376713; batch adversarial loss: 0.599306\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390661; batch adversarial loss: 0.617411\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363398; batch adversarial loss: 0.507351\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394390; batch adversarial loss: 0.516454\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455741; batch adversarial loss: 0.553684\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354808; batch adversarial loss: 0.525833\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391334; batch adversarial loss: 0.497493\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434667; batch adversarial loss: 0.535648\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441547; batch adversarial loss: 0.489302\n",
      "epoch 92; iter: 0; batch classifier loss: 0.409187; batch adversarial loss: 0.516967\n",
      "epoch 93; iter: 0; batch classifier loss: 0.408432; batch adversarial loss: 0.516033\n",
      "epoch 94; iter: 0; batch classifier loss: 0.450515; batch adversarial loss: 0.563874\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358118; batch adversarial loss: 0.498911\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425985; batch adversarial loss: 0.563016\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400485; batch adversarial loss: 0.627374\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438004; batch adversarial loss: 0.573003\n",
      "epoch 99; iter: 0; batch classifier loss: 0.432792; batch adversarial loss: 0.581954\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403498; batch adversarial loss: 0.591275\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390620; batch adversarial loss: 0.572613\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389584; batch adversarial loss: 0.535910\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389105; batch adversarial loss: 0.497891\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393129; batch adversarial loss: 0.525841\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368532; batch adversarial loss: 0.488972\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.488339\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387415; batch adversarial loss: 0.526522\n",
      "epoch 108; iter: 0; batch classifier loss: 0.453197; batch adversarial loss: 0.657913\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401159; batch adversarial loss: 0.488550\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442872; batch adversarial loss: 0.479203\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362655; batch adversarial loss: 0.591544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.393116; batch adversarial loss: 0.544980\n",
      "epoch 113; iter: 0; batch classifier loss: 0.432956; batch adversarial loss: 0.516937\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369884; batch adversarial loss: 0.636969\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381546; batch adversarial loss: 0.498854\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368289; batch adversarial loss: 0.561823\n",
      "epoch 117; iter: 0; batch classifier loss: 0.504431; batch adversarial loss: 0.536276\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383938; batch adversarial loss: 0.480026\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344819; batch adversarial loss: 0.470648\n",
      "epoch 120; iter: 0; batch classifier loss: 0.431348; batch adversarial loss: 0.507397\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368222; batch adversarial loss: 0.554271\n",
      "epoch 122; iter: 0; batch classifier loss: 0.411845; batch adversarial loss: 0.507210\n",
      "epoch 123; iter: 0; batch classifier loss: 0.358769; batch adversarial loss: 0.545240\n",
      "epoch 124; iter: 0; batch classifier loss: 0.455428; batch adversarial loss: 0.610293\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343847; batch adversarial loss: 0.571993\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384626; batch adversarial loss: 0.544375\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395169; batch adversarial loss: 0.489646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.392623; batch adversarial loss: 0.563814\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361460; batch adversarial loss: 0.572560\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321609; batch adversarial loss: 0.480386\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398789; batch adversarial loss: 0.543971\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404609; batch adversarial loss: 0.497090\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390403; batch adversarial loss: 0.498037\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401594; batch adversarial loss: 0.507261\n",
      "epoch 135; iter: 0; batch classifier loss: 0.419697; batch adversarial loss: 0.572936\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.526193\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392967; batch adversarial loss: 0.562962\n",
      "epoch 138; iter: 0; batch classifier loss: 0.484255; batch adversarial loss: 0.590356\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408069; batch adversarial loss: 0.534924\n",
      "epoch 140; iter: 0; batch classifier loss: 0.414382; batch adversarial loss: 0.627591\n",
      "epoch 141; iter: 0; batch classifier loss: 0.299984; batch adversarial loss: 0.479447\n",
      "epoch 142; iter: 0; batch classifier loss: 0.407436; batch adversarial loss: 0.489158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.458760; batch adversarial loss: 0.636738\n",
      "epoch 144; iter: 0; batch classifier loss: 0.407543; batch adversarial loss: 0.498948\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418484; batch adversarial loss: 0.580702\n",
      "epoch 146; iter: 0; batch classifier loss: 0.402327; batch adversarial loss: 0.572488\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387404; batch adversarial loss: 0.536316\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344367; batch adversarial loss: 0.572972\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391150; batch adversarial loss: 0.553871\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369210; batch adversarial loss: 0.637114\n",
      "epoch 151; iter: 0; batch classifier loss: 0.451119; batch adversarial loss: 0.599739\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326432; batch adversarial loss: 0.524858\n",
      "epoch 153; iter: 0; batch classifier loss: 0.326367; batch adversarial loss: 0.581039\n",
      "epoch 154; iter: 0; batch classifier loss: 0.326677; batch adversarial loss: 0.497600\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373302; batch adversarial loss: 0.542916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380094; batch adversarial loss: 0.619136\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384285; batch adversarial loss: 0.515571\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382964; batch adversarial loss: 0.526130\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290634; batch adversarial loss: 0.609435\n",
      "epoch 160; iter: 0; batch classifier loss: 0.421975; batch adversarial loss: 0.608647\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344516; batch adversarial loss: 0.517496\n",
      "epoch 162; iter: 0; batch classifier loss: 0.391418; batch adversarial loss: 0.581642\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379893; batch adversarial loss: 0.572113\n",
      "epoch 164; iter: 0; batch classifier loss: 0.412943; batch adversarial loss: 0.543789\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321919; batch adversarial loss: 0.478455\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335808; batch adversarial loss: 0.516425\n",
      "epoch 167; iter: 0; batch classifier loss: 0.405801; batch adversarial loss: 0.507950\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370216; batch adversarial loss: 0.572317\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322641; batch adversarial loss: 0.517150\n",
      "epoch 170; iter: 0; batch classifier loss: 0.466493; batch adversarial loss: 0.508993\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395497; batch adversarial loss: 0.552544\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372133; batch adversarial loss: 0.544091\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430034; batch adversarial loss: 0.591181\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336457; batch adversarial loss: 0.581780\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369193; batch adversarial loss: 0.554630\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370658; batch adversarial loss: 0.479304\n",
      "epoch 177; iter: 0; batch classifier loss: 0.400664; batch adversarial loss: 0.498201\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358329; batch adversarial loss: 0.525986\n",
      "epoch 179; iter: 0; batch classifier loss: 0.376831; batch adversarial loss: 0.507166\n",
      "epoch 180; iter: 0; batch classifier loss: 0.398084; batch adversarial loss: 0.563799\n",
      "epoch 181; iter: 0; batch classifier loss: 0.431499; batch adversarial loss: 0.535326\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337349; batch adversarial loss: 0.582141\n",
      "epoch 183; iter: 0; batch classifier loss: 0.383748; batch adversarial loss: 0.525538\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370408; batch adversarial loss: 0.554116\n",
      "epoch 185; iter: 0; batch classifier loss: 0.406508; batch adversarial loss: 0.508007\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299356; batch adversarial loss: 0.506533\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359351; batch adversarial loss: 0.600099\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361280; batch adversarial loss: 0.554862\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373142; batch adversarial loss: 0.553892\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333038; batch adversarial loss: 0.525768\n",
      "epoch 191; iter: 0; batch classifier loss: 0.457059; batch adversarial loss: 0.525746\n",
      "epoch 192; iter: 0; batch classifier loss: 0.309786; batch adversarial loss: 0.553834\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326575; batch adversarial loss: 0.489627\n",
      "epoch 194; iter: 0; batch classifier loss: 0.406089; batch adversarial loss: 0.460316\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329357; batch adversarial loss: 0.480101\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387268; batch adversarial loss: 0.480144\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372671; batch adversarial loss: 0.414664\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383252; batch adversarial loss: 0.470353\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347181; batch adversarial loss: 0.498467\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714856; batch adversarial loss: 0.704182\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591568; batch adversarial loss: 0.674665\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527388; batch adversarial loss: 0.641614\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609566; batch adversarial loss: 0.621160\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538800; batch adversarial loss: 0.611242\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589526; batch adversarial loss: 0.619635\n",
      "epoch 6; iter: 0; batch classifier loss: 0.634794; batch adversarial loss: 0.573560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530634; batch adversarial loss: 0.582964\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553845; batch adversarial loss: 0.545570\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545793; batch adversarial loss: 0.564770\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568623; batch adversarial loss: 0.563676\n",
      "epoch 11; iter: 0; batch classifier loss: 0.485364; batch adversarial loss: 0.629951\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557417; batch adversarial loss: 0.559718\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483835; batch adversarial loss: 0.608101\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518444; batch adversarial loss: 0.603713\n",
      "epoch 15; iter: 0; batch classifier loss: 0.608537; batch adversarial loss: 0.630032\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531369; batch adversarial loss: 0.604641\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529541; batch adversarial loss: 0.552982\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506474; batch adversarial loss: 0.549856\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498047; batch adversarial loss: 0.596866\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468165; batch adversarial loss: 0.510519\n",
      "epoch 21; iter: 0; batch classifier loss: 0.445401; batch adversarial loss: 0.605748\n",
      "epoch 22; iter: 0; batch classifier loss: 0.550502; batch adversarial loss: 0.563078\n",
      "epoch 23; iter: 0; batch classifier loss: 0.416529; batch adversarial loss: 0.532852\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476614; batch adversarial loss: 0.537971\n",
      "epoch 25; iter: 0; batch classifier loss: 0.469000; batch adversarial loss: 0.522071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.501057; batch adversarial loss: 0.555879\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460668; batch adversarial loss: 0.463102\n",
      "epoch 28; iter: 0; batch classifier loss: 0.420743; batch adversarial loss: 0.561574\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431647; batch adversarial loss: 0.562903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.423794; batch adversarial loss: 0.475602\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475453; batch adversarial loss: 0.563301\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460433; batch adversarial loss: 0.508978\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409919; batch adversarial loss: 0.546091\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470985; batch adversarial loss: 0.527104\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460949; batch adversarial loss: 0.554328\n",
      "epoch 36; iter: 0; batch classifier loss: 0.527748; batch adversarial loss: 0.536107\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454169; batch adversarial loss: 0.561901\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463204; batch adversarial loss: 0.636366\n",
      "epoch 39; iter: 0; batch classifier loss: 0.426532; batch adversarial loss: 0.571451\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495974; batch adversarial loss: 0.672166\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448826; batch adversarial loss: 0.544221\n",
      "epoch 42; iter: 0; batch classifier loss: 0.520264; batch adversarial loss: 0.452162\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483016; batch adversarial loss: 0.544180\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429635; batch adversarial loss: 0.544406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425514; batch adversarial loss: 0.534895\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406242; batch adversarial loss: 0.601632\n",
      "epoch 47; iter: 0; batch classifier loss: 0.376646; batch adversarial loss: 0.588986\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410377; batch adversarial loss: 0.532406\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463798; batch adversarial loss: 0.585391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457728; batch adversarial loss: 0.560182\n",
      "epoch 51; iter: 0; batch classifier loss: 0.351401; batch adversarial loss: 0.483501\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415307; batch adversarial loss: 0.503233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480496; batch adversarial loss: 0.512135\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428075; batch adversarial loss: 0.578305\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466945; batch adversarial loss: 0.551401\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449683; batch adversarial loss: 0.629950\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472422; batch adversarial loss: 0.543920\n",
      "epoch 58; iter: 0; batch classifier loss: 0.477443; batch adversarial loss: 0.573790\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407903; batch adversarial loss: 0.535628\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400512; batch adversarial loss: 0.518146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439097; batch adversarial loss: 0.562949\n",
      "epoch 62; iter: 0; batch classifier loss: 0.334098; batch adversarial loss: 0.516288\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429755; batch adversarial loss: 0.453543\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406831; batch adversarial loss: 0.480576\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455120; batch adversarial loss: 0.580756\n",
      "epoch 66; iter: 0; batch classifier loss: 0.394505; batch adversarial loss: 0.489054\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403251; batch adversarial loss: 0.628128\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471796; batch adversarial loss: 0.489126\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438550; batch adversarial loss: 0.580799\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393957; batch adversarial loss: 0.506331\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432212; batch adversarial loss: 0.533267\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408029; batch adversarial loss: 0.607641\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396062; batch adversarial loss: 0.600523\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415592; batch adversarial loss: 0.497756\n",
      "epoch 75; iter: 0; batch classifier loss: 0.363845; batch adversarial loss: 0.515071\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413425; batch adversarial loss: 0.503470\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421075; batch adversarial loss: 0.582699\n",
      "epoch 78; iter: 0; batch classifier loss: 0.446034; batch adversarial loss: 0.525859\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377521; batch adversarial loss: 0.486334\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439326; batch adversarial loss: 0.555512\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435355; batch adversarial loss: 0.537446\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411838; batch adversarial loss: 0.543880\n",
      "epoch 83; iter: 0; batch classifier loss: 0.482516; batch adversarial loss: 0.566628\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352768; batch adversarial loss: 0.563407\n",
      "epoch 85; iter: 0; batch classifier loss: 0.495830; batch adversarial loss: 0.490235\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409935; batch adversarial loss: 0.599209\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398165; batch adversarial loss: 0.545147\n",
      "epoch 88; iter: 0; batch classifier loss: 0.500268; batch adversarial loss: 0.543381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.455229; batch adversarial loss: 0.554210\n",
      "epoch 90; iter: 0; batch classifier loss: 0.341232; batch adversarial loss: 0.554127\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390661; batch adversarial loss: 0.563820\n",
      "epoch 92; iter: 0; batch classifier loss: 0.504365; batch adversarial loss: 0.527001\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385716; batch adversarial loss: 0.525213\n",
      "epoch 94; iter: 0; batch classifier loss: 0.466488; batch adversarial loss: 0.514292\n",
      "epoch 95; iter: 0; batch classifier loss: 0.436678; batch adversarial loss: 0.590718\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384187; batch adversarial loss: 0.581413\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382297; batch adversarial loss: 0.478165\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381157; batch adversarial loss: 0.506176\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355950; batch adversarial loss: 0.535022\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409219; batch adversarial loss: 0.515557\n",
      "epoch 101; iter: 0; batch classifier loss: 0.343974; batch adversarial loss: 0.553418\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398912; batch adversarial loss: 0.551468\n",
      "epoch 103; iter: 0; batch classifier loss: 0.445936; batch adversarial loss: 0.554021\n",
      "epoch 104; iter: 0; batch classifier loss: 0.445486; batch adversarial loss: 0.517227\n",
      "epoch 105; iter: 0; batch classifier loss: 0.402107; batch adversarial loss: 0.563913\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409272; batch adversarial loss: 0.506679\n",
      "epoch 107; iter: 0; batch classifier loss: 0.426187; batch adversarial loss: 0.601369\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353711; batch adversarial loss: 0.536060\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358356; batch adversarial loss: 0.516211\n",
      "epoch 110; iter: 0; batch classifier loss: 0.360234; batch adversarial loss: 0.479226\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416662; batch adversarial loss: 0.462621\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351484; batch adversarial loss: 0.496358\n",
      "epoch 113; iter: 0; batch classifier loss: 0.475957; batch adversarial loss: 0.480342\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426318; batch adversarial loss: 0.509518\n",
      "epoch 115; iter: 0; batch classifier loss: 0.490823; batch adversarial loss: 0.461693\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379179; batch adversarial loss: 0.499670\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369738; batch adversarial loss: 0.617911\n",
      "epoch 118; iter: 0; batch classifier loss: 0.416511; batch adversarial loss: 0.555117\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377285; batch adversarial loss: 0.488435\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416346; batch adversarial loss: 0.508310\n",
      "epoch 121; iter: 0; batch classifier loss: 0.407871; batch adversarial loss: 0.495899\n",
      "epoch 122; iter: 0; batch classifier loss: 0.440310; batch adversarial loss: 0.507049\n",
      "epoch 123; iter: 0; batch classifier loss: 0.410051; batch adversarial loss: 0.562273\n",
      "epoch 124; iter: 0; batch classifier loss: 0.466774; batch adversarial loss: 0.580271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.390116; batch adversarial loss: 0.637886\n",
      "epoch 126; iter: 0; batch classifier loss: 0.342556; batch adversarial loss: 0.534981\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419397; batch adversarial loss: 0.506033\n",
      "epoch 128; iter: 0; batch classifier loss: 0.306495; batch adversarial loss: 0.543369\n",
      "epoch 129; iter: 0; batch classifier loss: 0.418845; batch adversarial loss: 0.468508\n",
      "epoch 130; iter: 0; batch classifier loss: 0.450820; batch adversarial loss: 0.506608\n",
      "epoch 131; iter: 0; batch classifier loss: 0.342657; batch adversarial loss: 0.554995\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373124; batch adversarial loss: 0.620462\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402211; batch adversarial loss: 0.553723\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395649; batch adversarial loss: 0.524502\n",
      "epoch 135; iter: 0; batch classifier loss: 0.392611; batch adversarial loss: 0.460000\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363677; batch adversarial loss: 0.496413\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390939; batch adversarial loss: 0.534326\n",
      "epoch 138; iter: 0; batch classifier loss: 0.459771; batch adversarial loss: 0.506350\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342685; batch adversarial loss: 0.525410\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403161; batch adversarial loss: 0.524708\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403931; batch adversarial loss: 0.544984\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324187; batch adversarial loss: 0.505621\n",
      "epoch 143; iter: 0; batch classifier loss: 0.426427; batch adversarial loss: 0.479496\n",
      "epoch 144; iter: 0; batch classifier loss: 0.535454; batch adversarial loss: 0.480158\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370364; batch adversarial loss: 0.479359\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353758; batch adversarial loss: 0.551872\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310370; batch adversarial loss: 0.628836\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363897; batch adversarial loss: 0.645315\n",
      "epoch 149; iter: 0; batch classifier loss: 0.480963; batch adversarial loss: 0.553790\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384930; batch adversarial loss: 0.534547\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422636; batch adversarial loss: 0.514612\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338900; batch adversarial loss: 0.543860\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374118; batch adversarial loss: 0.562656\n",
      "epoch 154; iter: 0; batch classifier loss: 0.407619; batch adversarial loss: 0.636855\n",
      "epoch 155; iter: 0; batch classifier loss: 0.375404; batch adversarial loss: 0.487868\n",
      "epoch 156; iter: 0; batch classifier loss: 0.324477; batch adversarial loss: 0.525574\n",
      "epoch 157; iter: 0; batch classifier loss: 0.412378; batch adversarial loss: 0.582417\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365376; batch adversarial loss: 0.572520\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323925; batch adversarial loss: 0.450584\n",
      "epoch 160; iter: 0; batch classifier loss: 0.434035; batch adversarial loss: 0.573475\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411747; batch adversarial loss: 0.591361\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363843; batch adversarial loss: 0.526026\n",
      "epoch 163; iter: 0; batch classifier loss: 0.426998; batch adversarial loss: 0.517750\n",
      "epoch 164; iter: 0; batch classifier loss: 0.416448; batch adversarial loss: 0.581910\n",
      "epoch 165; iter: 0; batch classifier loss: 0.378682; batch adversarial loss: 0.607779\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330719; batch adversarial loss: 0.525159\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367712; batch adversarial loss: 0.553755\n",
      "epoch 168; iter: 0; batch classifier loss: 0.409868; batch adversarial loss: 0.552330\n",
      "epoch 169; iter: 0; batch classifier loss: 0.460695; batch adversarial loss: 0.563570\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361375; batch adversarial loss: 0.598884\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420351; batch adversarial loss: 0.507210\n",
      "epoch 172; iter: 0; batch classifier loss: 0.428784; batch adversarial loss: 0.534913\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357297; batch adversarial loss: 0.517384\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339728; batch adversarial loss: 0.543607\n",
      "epoch 175; iter: 0; batch classifier loss: 0.374410; batch adversarial loss: 0.526004\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334922; batch adversarial loss: 0.610051\n",
      "epoch 177; iter: 0; batch classifier loss: 0.379596; batch adversarial loss: 0.514384\n",
      "epoch 178; iter: 0; batch classifier loss: 0.414592; batch adversarial loss: 0.506895\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371562; batch adversarial loss: 0.582888\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338665; batch adversarial loss: 0.590224\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382109; batch adversarial loss: 0.515751\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367748; batch adversarial loss: 0.526721\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382610; batch adversarial loss: 0.648741\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401430; batch adversarial loss: 0.599618\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389560; batch adversarial loss: 0.479479\n",
      "epoch 186; iter: 0; batch classifier loss: 0.391500; batch adversarial loss: 0.544620\n",
      "epoch 187; iter: 0; batch classifier loss: 0.423588; batch adversarial loss: 0.571654\n",
      "epoch 188; iter: 0; batch classifier loss: 0.293646; batch adversarial loss: 0.527155\n",
      "epoch 189; iter: 0; batch classifier loss: 0.427413; batch adversarial loss: 0.535038\n",
      "epoch 190; iter: 0; batch classifier loss: 0.418948; batch adversarial loss: 0.581696\n",
      "epoch 191; iter: 0; batch classifier loss: 0.398283; batch adversarial loss: 0.495805\n",
      "epoch 192; iter: 0; batch classifier loss: 0.325531; batch adversarial loss: 0.535556\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336121; batch adversarial loss: 0.505967\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349790; batch adversarial loss: 0.573247\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339297; batch adversarial loss: 0.545078\n",
      "epoch 196; iter: 0; batch classifier loss: 0.259378; batch adversarial loss: 0.590722\n",
      "epoch 197; iter: 0; batch classifier loss: 0.426031; batch adversarial loss: 0.572958\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317785; batch adversarial loss: 0.518452\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385709; batch adversarial loss: 0.571890\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684465; batch adversarial loss: 0.818219\n",
      "epoch 1; iter: 0; batch classifier loss: 0.817280; batch adversarial loss: 1.166624\n",
      "epoch 2; iter: 0; batch classifier loss: 0.856289; batch adversarial loss: 1.191974\n",
      "epoch 3; iter: 0; batch classifier loss: 0.952426; batch adversarial loss: 1.118353\n",
      "epoch 4; iter: 0; batch classifier loss: 0.928633; batch adversarial loss: 1.004874\n",
      "epoch 5; iter: 0; batch classifier loss: 0.909490; batch adversarial loss: 0.883693\n",
      "epoch 6; iter: 0; batch classifier loss: 0.877890; batch adversarial loss: 0.796496\n",
      "epoch 7; iter: 0; batch classifier loss: 0.691028; batch adversarial loss: 0.761924\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618436; batch adversarial loss: 0.708214\n",
      "epoch 9; iter: 0; batch classifier loss: 0.594022; batch adversarial loss: 0.662226\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542231; batch adversarial loss: 0.647637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543431; batch adversarial loss: 0.642384\n",
      "epoch 12; iter: 0; batch classifier loss: 0.588558; batch adversarial loss: 0.585150\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558986; batch adversarial loss: 0.595457\n",
      "epoch 14; iter: 0; batch classifier loss: 0.460232; batch adversarial loss: 0.609332\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497344; batch adversarial loss: 0.566963\n",
      "epoch 16; iter: 0; batch classifier loss: 0.576347; batch adversarial loss: 0.576393\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493892; batch adversarial loss: 0.553461\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497875; batch adversarial loss: 0.611413\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485670; batch adversarial loss: 0.526806\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502341; batch adversarial loss: 0.537214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.468976; batch adversarial loss: 0.513445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.567345; batch adversarial loss: 0.568976\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457037; batch adversarial loss: 0.606975\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497596; batch adversarial loss: 0.580573\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517796; batch adversarial loss: 0.591427\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452973; batch adversarial loss: 0.569321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507594; batch adversarial loss: 0.559434\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453803; batch adversarial loss: 0.552391\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474387; batch adversarial loss: 0.504194\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466741; batch adversarial loss: 0.575864\n",
      "epoch 31; iter: 0; batch classifier loss: 0.510849; batch adversarial loss: 0.528360\n",
      "epoch 32; iter: 0; batch classifier loss: 0.455098; batch adversarial loss: 0.540773\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486928; batch adversarial loss: 0.540327\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449311; batch adversarial loss: 0.525660\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481758; batch adversarial loss: 0.557719\n",
      "epoch 36; iter: 0; batch classifier loss: 0.513771; batch adversarial loss: 0.570734\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460777; batch adversarial loss: 0.555289\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418163; batch adversarial loss: 0.552510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463596; batch adversarial loss: 0.597321\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447386; batch adversarial loss: 0.499827\n",
      "epoch 41; iter: 0; batch classifier loss: 0.531968; batch adversarial loss: 0.566863\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450304; batch adversarial loss: 0.547182\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421007; batch adversarial loss: 0.533119\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460405; batch adversarial loss: 0.576243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419807; batch adversarial loss: 0.542051\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476783; batch adversarial loss: 0.682622\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465233; batch adversarial loss: 0.587044\n",
      "epoch 48; iter: 0; batch classifier loss: 0.508188; batch adversarial loss: 0.548245\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404048; batch adversarial loss: 0.596799\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429260; batch adversarial loss: 0.559292\n",
      "epoch 51; iter: 0; batch classifier loss: 0.354403; batch adversarial loss: 0.553132\n",
      "epoch 52; iter: 0; batch classifier loss: 0.376686; batch adversarial loss: 0.527059\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468460; batch adversarial loss: 0.473487\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416580; batch adversarial loss: 0.583674\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382548; batch adversarial loss: 0.533216\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457113; batch adversarial loss: 0.568688\n",
      "epoch 57; iter: 0; batch classifier loss: 0.469595; batch adversarial loss: 0.499712\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426671; batch adversarial loss: 0.584738\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467982; batch adversarial loss: 0.590358\n",
      "epoch 60; iter: 0; batch classifier loss: 0.438798; batch adversarial loss: 0.462001\n",
      "epoch 61; iter: 0; batch classifier loss: 0.479889; batch adversarial loss: 0.498355\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376749; batch adversarial loss: 0.589370\n",
      "epoch 63; iter: 0; batch classifier loss: 0.351666; batch adversarial loss: 0.551862\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422619; batch adversarial loss: 0.562824\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428406; batch adversarial loss: 0.580159\n",
      "epoch 66; iter: 0; batch classifier loss: 0.450273; batch adversarial loss: 0.532617\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392306; batch adversarial loss: 0.584607\n",
      "epoch 68; iter: 0; batch classifier loss: 0.372070; batch adversarial loss: 0.581114\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382447; batch adversarial loss: 0.572936\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413343; batch adversarial loss: 0.601762\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351737; batch adversarial loss: 0.549083\n",
      "epoch 72; iter: 0; batch classifier loss: 0.426666; batch adversarial loss: 0.536342\n",
      "epoch 73; iter: 0; batch classifier loss: 0.323241; batch adversarial loss: 0.536871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432277; batch adversarial loss: 0.596896\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424558; batch adversarial loss: 0.537209\n",
      "epoch 76; iter: 0; batch classifier loss: 0.445846; batch adversarial loss: 0.524768\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389583; batch adversarial loss: 0.584361\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368264; batch adversarial loss: 0.493905\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396024; batch adversarial loss: 0.507683\n",
      "epoch 80; iter: 0; batch classifier loss: 0.326926; batch adversarial loss: 0.470402\n",
      "epoch 81; iter: 0; batch classifier loss: 0.354484; batch adversarial loss: 0.532367\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362430; batch adversarial loss: 0.547533\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424655; batch adversarial loss: 0.527414\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378650; batch adversarial loss: 0.597870\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390856; batch adversarial loss: 0.528550\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369093; batch adversarial loss: 0.549162\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399549; batch adversarial loss: 0.579412\n",
      "epoch 88; iter: 0; batch classifier loss: 0.347493; batch adversarial loss: 0.561877\n",
      "epoch 89; iter: 0; batch classifier loss: 0.333351; batch adversarial loss: 0.495517\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380324; batch adversarial loss: 0.574924\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419111; batch adversarial loss: 0.591182\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344142; batch adversarial loss: 0.579054\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363417; batch adversarial loss: 0.524895\n",
      "epoch 94; iter: 0; batch classifier loss: 0.330238; batch adversarial loss: 0.631061\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368712; batch adversarial loss: 0.566118\n",
      "epoch 96; iter: 0; batch classifier loss: 0.348204; batch adversarial loss: 0.586967\n",
      "epoch 97; iter: 0; batch classifier loss: 0.464168; batch adversarial loss: 0.570798\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401137; batch adversarial loss: 0.535316\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358813; batch adversarial loss: 0.528532\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421423; batch adversarial loss: 0.538107\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413161; batch adversarial loss: 0.571350\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362390; batch adversarial loss: 0.612281\n",
      "epoch 103; iter: 0; batch classifier loss: 0.463857; batch adversarial loss: 0.499505\n",
      "epoch 104; iter: 0; batch classifier loss: 0.355014; batch adversarial loss: 0.527845\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415118; batch adversarial loss: 0.553752\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404955; batch adversarial loss: 0.492546\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382527; batch adversarial loss: 0.570712\n",
      "epoch 108; iter: 0; batch classifier loss: 0.343316; batch adversarial loss: 0.569356\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360205; batch adversarial loss: 0.563407\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370149; batch adversarial loss: 0.506154\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366086; batch adversarial loss: 0.554773\n",
      "epoch 112; iter: 0; batch classifier loss: 0.350579; batch adversarial loss: 0.544414\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377320; batch adversarial loss: 0.607629\n",
      "epoch 114; iter: 0; batch classifier loss: 0.462905; batch adversarial loss: 0.536172\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364371; batch adversarial loss: 0.500721\n",
      "epoch 116; iter: 0; batch classifier loss: 0.397256; batch adversarial loss: 0.525697\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391576; batch adversarial loss: 0.456088\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341419; batch adversarial loss: 0.526514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.341785; batch adversarial loss: 0.491536\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352386; batch adversarial loss: 0.500021\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362750; batch adversarial loss: 0.576931\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326165; batch adversarial loss: 0.606180\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.640779\n",
      "epoch 124; iter: 0; batch classifier loss: 0.292018; batch adversarial loss: 0.532398\n",
      "epoch 125; iter: 0; batch classifier loss: 0.312107; batch adversarial loss: 0.566312\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369180; batch adversarial loss: 0.600593\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348406; batch adversarial loss: 0.599675\n",
      "epoch 128; iter: 0; batch classifier loss: 0.374283; batch adversarial loss: 0.607668\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371328; batch adversarial loss: 0.558152\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384743; batch adversarial loss: 0.554292\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354943; batch adversarial loss: 0.605171\n",
      "epoch 132; iter: 0; batch classifier loss: 0.386520; batch adversarial loss: 0.590526\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394297; batch adversarial loss: 0.623195\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365148; batch adversarial loss: 0.546479\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336197; batch adversarial loss: 0.543559\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395926; batch adversarial loss: 0.558926\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375418; batch adversarial loss: 0.473016\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383082; batch adversarial loss: 0.580680\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384303; batch adversarial loss: 0.526699\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332141; batch adversarial loss: 0.483154\n",
      "epoch 141; iter: 0; batch classifier loss: 0.393390; batch adversarial loss: 0.505287\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375805; batch adversarial loss: 0.482718\n",
      "epoch 143; iter: 0; batch classifier loss: 0.270167; batch adversarial loss: 0.591241\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345025; batch adversarial loss: 0.492672\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379903; batch adversarial loss: 0.492812\n",
      "epoch 146; iter: 0; batch classifier loss: 0.311321; batch adversarial loss: 0.527001\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328294; batch adversarial loss: 0.578633\n",
      "epoch 148; iter: 0; batch classifier loss: 0.322510; batch adversarial loss: 0.582770\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371436; batch adversarial loss: 0.602716\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356448; batch adversarial loss: 0.555521\n",
      "epoch 151; iter: 0; batch classifier loss: 0.332143; batch adversarial loss: 0.516048\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352947; batch adversarial loss: 0.489554\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371208; batch adversarial loss: 0.555538\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316146; batch adversarial loss: 0.524981\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325251; batch adversarial loss: 0.603445\n",
      "epoch 156; iter: 0; batch classifier loss: 0.426048; batch adversarial loss: 0.535318\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341444; batch adversarial loss: 0.499384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353192; batch adversarial loss: 0.605684\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324621; batch adversarial loss: 0.622791\n",
      "epoch 160; iter: 0; batch classifier loss: 0.282805; batch adversarial loss: 0.545450\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346346; batch adversarial loss: 0.509071\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337303; batch adversarial loss: 0.617549\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384007; batch adversarial loss: 0.531684\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392557; batch adversarial loss: 0.553493\n",
      "epoch 165; iter: 0; batch classifier loss: 0.320819; batch adversarial loss: 0.546535\n",
      "epoch 166; iter: 0; batch classifier loss: 0.386849; batch adversarial loss: 0.537239\n",
      "epoch 167; iter: 0; batch classifier loss: 0.419691; batch adversarial loss: 0.526914\n",
      "epoch 168; iter: 0; batch classifier loss: 0.300423; batch adversarial loss: 0.589180\n",
      "epoch 169; iter: 0; batch classifier loss: 0.301577; batch adversarial loss: 0.553177\n",
      "epoch 170; iter: 0; batch classifier loss: 0.381396; batch adversarial loss: 0.500228\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343015; batch adversarial loss: 0.613769\n",
      "epoch 172; iter: 0; batch classifier loss: 0.310383; batch adversarial loss: 0.553951\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403685; batch adversarial loss: 0.497235\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353922; batch adversarial loss: 0.642350\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338504; batch adversarial loss: 0.568689\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330251; batch adversarial loss: 0.479374\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433754; batch adversarial loss: 0.523845\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332315; batch adversarial loss: 0.544680\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369185; batch adversarial loss: 0.577427\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339126; batch adversarial loss: 0.552487\n",
      "epoch 181; iter: 0; batch classifier loss: 0.298108; batch adversarial loss: 0.503768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.428316; batch adversarial loss: 0.604195\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344782; batch adversarial loss: 0.586606\n",
      "epoch 184; iter: 0; batch classifier loss: 0.435433; batch adversarial loss: 0.600977\n",
      "epoch 185; iter: 0; batch classifier loss: 0.350256; batch adversarial loss: 0.560161\n",
      "epoch 186; iter: 0; batch classifier loss: 0.352994; batch adversarial loss: 0.453607\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348874; batch adversarial loss: 0.527223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.278964; batch adversarial loss: 0.526127\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348208; batch adversarial loss: 0.579764\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404814; batch adversarial loss: 0.553352\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359483; batch adversarial loss: 0.509019\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319717; batch adversarial loss: 0.516332\n",
      "epoch 193; iter: 0; batch classifier loss: 0.304940; batch adversarial loss: 0.625809\n",
      "epoch 194; iter: 0; batch classifier loss: 0.286226; batch adversarial loss: 0.491616\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317652; batch adversarial loss: 0.595007\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305183; batch adversarial loss: 0.647744\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337839; batch adversarial loss: 0.560062\n",
      "epoch 198; iter: 0; batch classifier loss: 0.345947; batch adversarial loss: 0.605733\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365040; batch adversarial loss: 0.555632\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723349; batch adversarial loss: 1.049288\n",
      "epoch 1; iter: 0; batch classifier loss: 0.896078; batch adversarial loss: 1.262288\n",
      "epoch 2; iter: 0; batch classifier loss: 1.066052; batch adversarial loss: 1.238702\n",
      "epoch 3; iter: 0; batch classifier loss: 1.086347; batch adversarial loss: 1.146686\n",
      "epoch 4; iter: 0; batch classifier loss: 1.135637; batch adversarial loss: 1.042708\n",
      "epoch 5; iter: 0; batch classifier loss: 1.258864; batch adversarial loss: 0.964592\n",
      "epoch 6; iter: 0; batch classifier loss: 1.157219; batch adversarial loss: 0.891811\n",
      "epoch 7; iter: 0; batch classifier loss: 1.289846; batch adversarial loss: 0.846678\n",
      "epoch 8; iter: 0; batch classifier loss: 1.131468; batch adversarial loss: 0.778537\n",
      "epoch 9; iter: 0; batch classifier loss: 1.037759; batch adversarial loss: 0.713326\n",
      "epoch 10; iter: 0; batch classifier loss: 0.994734; batch adversarial loss: 0.674316\n",
      "epoch 11; iter: 0; batch classifier loss: 0.858397; batch adversarial loss: 0.629780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.627307; batch adversarial loss: 0.630086\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583120; batch adversarial loss: 0.614789\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578827; batch adversarial loss: 0.592262\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552077; batch adversarial loss: 0.606000\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484569; batch adversarial loss: 0.565859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.497437; batch adversarial loss: 0.589376\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526453; batch adversarial loss: 0.591751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535638; batch adversarial loss: 0.623871\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512484; batch adversarial loss: 0.562068\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480512; batch adversarial loss: 0.580139\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472786; batch adversarial loss: 0.583245\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507132; batch adversarial loss: 0.569857\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488665; batch adversarial loss: 0.501376\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497617; batch adversarial loss: 0.574314\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467147; batch adversarial loss: 0.534584\n",
      "epoch 27; iter: 0; batch classifier loss: 0.435094; batch adversarial loss: 0.598570\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481517; batch adversarial loss: 0.563691\n",
      "epoch 29; iter: 0; batch classifier loss: 0.427235; batch adversarial loss: 0.570992\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421382; batch adversarial loss: 0.536407\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435051; batch adversarial loss: 0.548068\n",
      "epoch 32; iter: 0; batch classifier loss: 0.540531; batch adversarial loss: 0.541384\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473680; batch adversarial loss: 0.521336\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522865; batch adversarial loss: 0.573619\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390921; batch adversarial loss: 0.534621\n",
      "epoch 36; iter: 0; batch classifier loss: 0.383358; batch adversarial loss: 0.587929\n",
      "epoch 37; iter: 0; batch classifier loss: 0.513235; batch adversarial loss: 0.542559\n",
      "epoch 38; iter: 0; batch classifier loss: 0.503294; batch adversarial loss: 0.535879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.538400; batch adversarial loss: 0.584458\n",
      "epoch 40; iter: 0; batch classifier loss: 0.482386; batch adversarial loss: 0.516511\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449944; batch adversarial loss: 0.506053\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470533; batch adversarial loss: 0.536149\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418164; batch adversarial loss: 0.517990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457514; batch adversarial loss: 0.604277\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471491; batch adversarial loss: 0.579813\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411068; batch adversarial loss: 0.602606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446472; batch adversarial loss: 0.610688\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379976; batch adversarial loss: 0.628198\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410701; batch adversarial loss: 0.614213\n",
      "epoch 50; iter: 0; batch classifier loss: 0.383003; batch adversarial loss: 0.595874\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441558; batch adversarial loss: 0.527683\n",
      "epoch 52; iter: 0; batch classifier loss: 0.454406; batch adversarial loss: 0.490766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418411; batch adversarial loss: 0.582129\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408774; batch adversarial loss: 0.529661\n",
      "epoch 55; iter: 0; batch classifier loss: 0.374661; batch adversarial loss: 0.524897\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387882; batch adversarial loss: 0.552454\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411241; batch adversarial loss: 0.525745\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460693; batch adversarial loss: 0.580539\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417983; batch adversarial loss: 0.518001\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426450; batch adversarial loss: 0.553038\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400793; batch adversarial loss: 0.517863\n",
      "epoch 62; iter: 0; batch classifier loss: 0.473416; batch adversarial loss: 0.526717\n",
      "epoch 63; iter: 0; batch classifier loss: 0.481278; batch adversarial loss: 0.607555\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348974; batch adversarial loss: 0.499710\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444142; batch adversarial loss: 0.535538\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414931; batch adversarial loss: 0.490288\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363283; batch adversarial loss: 0.643923\n",
      "epoch 68; iter: 0; batch classifier loss: 0.360308; batch adversarial loss: 0.545112\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355502; batch adversarial loss: 0.544133\n",
      "epoch 70; iter: 0; batch classifier loss: 0.454154; batch adversarial loss: 0.580474\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403075; batch adversarial loss: 0.561869\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391199; batch adversarial loss: 0.544969\n",
      "epoch 73; iter: 0; batch classifier loss: 0.336254; batch adversarial loss: 0.499387\n",
      "epoch 74; iter: 0; batch classifier loss: 0.336202; batch adversarial loss: 0.553096\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426081; batch adversarial loss: 0.517335\n",
      "epoch 76; iter: 0; batch classifier loss: 0.330143; batch adversarial loss: 0.535754\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338357; batch adversarial loss: 0.534596\n",
      "epoch 78; iter: 0; batch classifier loss: 0.317113; batch adversarial loss: 0.543491\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380652; batch adversarial loss: 0.517510\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429688; batch adversarial loss: 0.543487\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424337; batch adversarial loss: 0.519219\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365077; batch adversarial loss: 0.553035\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430226; batch adversarial loss: 0.589541\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367471; batch adversarial loss: 0.571129\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347474; batch adversarial loss: 0.607397\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378647; batch adversarial loss: 0.552596\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399638; batch adversarial loss: 0.481878\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369204; batch adversarial loss: 0.496905\n",
      "epoch 89; iter: 0; batch classifier loss: 0.326688; batch adversarial loss: 0.590833\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371406; batch adversarial loss: 0.471169\n",
      "epoch 91; iter: 0; batch classifier loss: 0.343417; batch adversarial loss: 0.516719\n",
      "epoch 92; iter: 0; batch classifier loss: 0.257172; batch adversarial loss: 0.562521\n",
      "epoch 93; iter: 0; batch classifier loss: 0.314368; batch adversarial loss: 0.489946\n",
      "epoch 94; iter: 0; batch classifier loss: 0.330246; batch adversarial loss: 0.481081\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402094; batch adversarial loss: 0.581545\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420327; batch adversarial loss: 0.497224\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374478; batch adversarial loss: 0.559673\n",
      "epoch 98; iter: 0; batch classifier loss: 0.345271; batch adversarial loss: 0.568883\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341404; batch adversarial loss: 0.561461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412130; batch adversarial loss: 0.545252\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358687; batch adversarial loss: 0.489417\n",
      "epoch 102; iter: 0; batch classifier loss: 0.510343; batch adversarial loss: 0.525482\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394457; batch adversarial loss: 0.550367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.318970; batch adversarial loss: 0.609023\n",
      "epoch 105; iter: 0; batch classifier loss: 0.447647; batch adversarial loss: 0.580361\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356099; batch adversarial loss: 0.610193\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358493; batch adversarial loss: 0.573027\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406107; batch adversarial loss: 0.498030\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376236; batch adversarial loss: 0.502025\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352946; batch adversarial loss: 0.564041\n",
      "epoch 111; iter: 0; batch classifier loss: 0.402671; batch adversarial loss: 0.505204\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336448; batch adversarial loss: 0.579778\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345928; batch adversarial loss: 0.495194\n",
      "epoch 114; iter: 0; batch classifier loss: 0.331079; batch adversarial loss: 0.491545\n",
      "epoch 115; iter: 0; batch classifier loss: 0.301241; batch adversarial loss: 0.651950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.435262; batch adversarial loss: 0.638798\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350709; batch adversarial loss: 0.603799\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390526; batch adversarial loss: 0.536171\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407463; batch adversarial loss: 0.577061\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420387; batch adversarial loss: 0.582072\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379274; batch adversarial loss: 0.529866\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350002; batch adversarial loss: 0.590554\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343700; batch adversarial loss: 0.601843\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353926; batch adversarial loss: 0.640241\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397226; batch adversarial loss: 0.602536\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367905; batch adversarial loss: 0.546332\n",
      "epoch 127; iter: 0; batch classifier loss: 0.437723; batch adversarial loss: 0.580057\n",
      "epoch 128; iter: 0; batch classifier loss: 0.417474; batch adversarial loss: 0.559841\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334573; batch adversarial loss: 0.510383\n",
      "epoch 130; iter: 0; batch classifier loss: 0.245437; batch adversarial loss: 0.462388\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405526; batch adversarial loss: 0.506013\n",
      "epoch 132; iter: 0; batch classifier loss: 0.437436; batch adversarial loss: 0.547075\n",
      "epoch 133; iter: 0; batch classifier loss: 0.282626; batch adversarial loss: 0.503688\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357258; batch adversarial loss: 0.555993\n",
      "epoch 135; iter: 0; batch classifier loss: 0.298734; batch adversarial loss: 0.478362\n",
      "epoch 136; iter: 0; batch classifier loss: 0.400380; batch adversarial loss: 0.592789\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359349; batch adversarial loss: 0.549092\n",
      "epoch 138; iter: 0; batch classifier loss: 0.332772; batch adversarial loss: 0.552827\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365403; batch adversarial loss: 0.496184\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338963; batch adversarial loss: 0.485419\n",
      "epoch 141; iter: 0; batch classifier loss: 0.289511; batch adversarial loss: 0.556275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381359; batch adversarial loss: 0.606780\n",
      "epoch 143; iter: 0; batch classifier loss: 0.317575; batch adversarial loss: 0.559046\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352520; batch adversarial loss: 0.585705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.325903; batch adversarial loss: 0.606591\n",
      "epoch 146; iter: 0; batch classifier loss: 0.335569; batch adversarial loss: 0.562887\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368652; batch adversarial loss: 0.536196\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368271; batch adversarial loss: 0.547748\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333641; batch adversarial loss: 0.529109\n",
      "epoch 150; iter: 0; batch classifier loss: 0.298238; batch adversarial loss: 0.602525\n",
      "epoch 151; iter: 0; batch classifier loss: 0.307860; batch adversarial loss: 0.561756\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363468; batch adversarial loss: 0.469539\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353039; batch adversarial loss: 0.525864\n",
      "epoch 154; iter: 0; batch classifier loss: 0.437181; batch adversarial loss: 0.548416\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394939; batch adversarial loss: 0.550554\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321662; batch adversarial loss: 0.494194\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363381; batch adversarial loss: 0.626780\n",
      "epoch 158; iter: 0; batch classifier loss: 0.302889; batch adversarial loss: 0.483496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354238; batch adversarial loss: 0.546024\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339056; batch adversarial loss: 0.497389\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350710; batch adversarial loss: 0.560886\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410719; batch adversarial loss: 0.472589\n",
      "epoch 163; iter: 0; batch classifier loss: 0.282034; batch adversarial loss: 0.497385\n",
      "epoch 164; iter: 0; batch classifier loss: 0.290586; batch adversarial loss: 0.605876\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303658; batch adversarial loss: 0.531812\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332968; batch adversarial loss: 0.551335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.284061; batch adversarial loss: 0.528308\n",
      "epoch 168; iter: 0; batch classifier loss: 0.287081; batch adversarial loss: 0.564531\n",
      "epoch 169; iter: 0; batch classifier loss: 0.328070; batch adversarial loss: 0.528318\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410556; batch adversarial loss: 0.506590\n",
      "epoch 171; iter: 0; batch classifier loss: 0.241040; batch adversarial loss: 0.574435\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360314; batch adversarial loss: 0.500244\n",
      "epoch 173; iter: 0; batch classifier loss: 0.326629; batch adversarial loss: 0.542442\n",
      "epoch 174; iter: 0; batch classifier loss: 0.329874; batch adversarial loss: 0.597301\n",
      "epoch 175; iter: 0; batch classifier loss: 0.421015; batch adversarial loss: 0.497165\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393600; batch adversarial loss: 0.556651\n",
      "epoch 177; iter: 0; batch classifier loss: 0.277828; batch adversarial loss: 0.543961\n",
      "epoch 178; iter: 0; batch classifier loss: 0.423781; batch adversarial loss: 0.607698\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364151; batch adversarial loss: 0.487075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.421842; batch adversarial loss: 0.495179\n",
      "epoch 181; iter: 0; batch classifier loss: 0.403626; batch adversarial loss: 0.563086\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318383; batch adversarial loss: 0.560244\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353895; batch adversarial loss: 0.543512\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389005; batch adversarial loss: 0.516692\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392950; batch adversarial loss: 0.576208\n",
      "epoch 186; iter: 0; batch classifier loss: 0.303060; batch adversarial loss: 0.535689\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345707; batch adversarial loss: 0.544527\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396598; batch adversarial loss: 0.553503\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368153; batch adversarial loss: 0.537283\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339137; batch adversarial loss: 0.571683\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356914; batch adversarial loss: 0.581013\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315445; batch adversarial loss: 0.526313\n",
      "epoch 193; iter: 0; batch classifier loss: 0.328551; batch adversarial loss: 0.581064\n",
      "epoch 194; iter: 0; batch classifier loss: 0.337822; batch adversarial loss: 0.635101\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334450; batch adversarial loss: 0.461202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328129; batch adversarial loss: 0.537707\n",
      "epoch 197; iter: 0; batch classifier loss: 0.334924; batch adversarial loss: 0.543906\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363633; batch adversarial loss: 0.562369\n",
      "epoch 199; iter: 0; batch classifier loss: 0.346026; batch adversarial loss: 0.553898\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751206; batch adversarial loss: 0.873978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.675919; batch adversarial loss: 0.826380\n",
      "epoch 2; iter: 0; batch classifier loss: 0.714182; batch adversarial loss: 0.778895\n",
      "epoch 3; iter: 0; batch classifier loss: 0.599815; batch adversarial loss: 0.704347\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556995; batch adversarial loss: 0.665846\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556210; batch adversarial loss: 0.635502\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575699; batch adversarial loss: 0.643458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492066; batch adversarial loss: 0.640266\n",
      "epoch 8; iter: 0; batch classifier loss: 0.625755; batch adversarial loss: 0.607827\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479532; batch adversarial loss: 0.613104\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557623; batch adversarial loss: 0.577902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502733; batch adversarial loss: 0.571356\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475904; batch adversarial loss: 0.581305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.450128; batch adversarial loss: 0.554081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.415484; batch adversarial loss: 0.529679\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516631; batch adversarial loss: 0.536900\n",
      "epoch 16; iter: 0; batch classifier loss: 0.406098; batch adversarial loss: 0.531640\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568763; batch adversarial loss: 0.582205\n",
      "epoch 18; iter: 0; batch classifier loss: 0.516696; batch adversarial loss: 0.648561\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489343; batch adversarial loss: 0.595566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495498; batch adversarial loss: 0.536404\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511540; batch adversarial loss: 0.576729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485764; batch adversarial loss: 0.528856\n",
      "epoch 23; iter: 0; batch classifier loss: 0.566318; batch adversarial loss: 0.563547\n",
      "epoch 24; iter: 0; batch classifier loss: 0.437628; batch adversarial loss: 0.495562\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553849; batch adversarial loss: 0.511594\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475105; batch adversarial loss: 0.501356\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457689; batch adversarial loss: 0.469758\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474068; batch adversarial loss: 0.545004\n",
      "epoch 29; iter: 0; batch classifier loss: 0.530317; batch adversarial loss: 0.482829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469524; batch adversarial loss: 0.528838\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437023; batch adversarial loss: 0.463820\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435639; batch adversarial loss: 0.538687\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437904; batch adversarial loss: 0.504749\n",
      "epoch 34; iter: 0; batch classifier loss: 0.366650; batch adversarial loss: 0.531103\n",
      "epoch 35; iter: 0; batch classifier loss: 0.339860; batch adversarial loss: 0.588780\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502060; batch adversarial loss: 0.520727\n",
      "epoch 37; iter: 0; batch classifier loss: 0.502429; batch adversarial loss: 0.528969\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442955; batch adversarial loss: 0.675706\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452937; batch adversarial loss: 0.553750\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446172; batch adversarial loss: 0.589649\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426098; batch adversarial loss: 0.509895\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460242; batch adversarial loss: 0.536627\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478991; batch adversarial loss: 0.457028\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432513; batch adversarial loss: 0.553927\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411369; batch adversarial loss: 0.562294\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412822; batch adversarial loss: 0.499070\n",
      "epoch 47; iter: 0; batch classifier loss: 0.546163; batch adversarial loss: 0.535767\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440083; batch adversarial loss: 0.617600\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404471; batch adversarial loss: 0.562451\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414202; batch adversarial loss: 0.471165\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392699; batch adversarial loss: 0.516628\n",
      "epoch 52; iter: 0; batch classifier loss: 0.397607; batch adversarial loss: 0.580386\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421902; batch adversarial loss: 0.507913\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406611; batch adversarial loss: 0.654825\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437599; batch adversarial loss: 0.471660\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450496; batch adversarial loss: 0.507468\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457865; batch adversarial loss: 0.470692\n",
      "epoch 58; iter: 0; batch classifier loss: 0.366909; batch adversarial loss: 0.488738\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402170; batch adversarial loss: 0.553768\n",
      "epoch 60; iter: 0; batch classifier loss: 0.408226; batch adversarial loss: 0.544688\n",
      "epoch 61; iter: 0; batch classifier loss: 0.393398; batch adversarial loss: 0.507604\n",
      "epoch 62; iter: 0; batch classifier loss: 0.328030; batch adversarial loss: 0.507340\n",
      "epoch 63; iter: 0; batch classifier loss: 0.353180; batch adversarial loss: 0.506950\n",
      "epoch 64; iter: 0; batch classifier loss: 0.494259; batch adversarial loss: 0.608390\n",
      "epoch 65; iter: 0; batch classifier loss: 0.320849; batch adversarial loss: 0.563103\n",
      "epoch 66; iter: 0; batch classifier loss: 0.482821; batch adversarial loss: 0.544713\n",
      "epoch 67; iter: 0; batch classifier loss: 0.438764; batch adversarial loss: 0.564387\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426046; batch adversarial loss: 0.516358\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366076; batch adversarial loss: 0.544428\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421328; batch adversarial loss: 0.544031\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351311; batch adversarial loss: 0.488687\n",
      "epoch 72; iter: 0; batch classifier loss: 0.350084; batch adversarial loss: 0.590876\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395351; batch adversarial loss: 0.553288\n",
      "epoch 74; iter: 0; batch classifier loss: 0.342588; batch adversarial loss: 0.505763\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416457; batch adversarial loss: 0.618211\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462092; batch adversarial loss: 0.517964\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402468; batch adversarial loss: 0.535323\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413150; batch adversarial loss: 0.609807\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439615; batch adversarial loss: 0.488672\n",
      "epoch 80; iter: 0; batch classifier loss: 0.379624; batch adversarial loss: 0.563755\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356574; batch adversarial loss: 0.544498\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443002; batch adversarial loss: 0.553535\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376964; batch adversarial loss: 0.590093\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411047; batch adversarial loss: 0.572068\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433751; batch adversarial loss: 0.516623\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418450; batch adversarial loss: 0.581718\n",
      "epoch 87; iter: 0; batch classifier loss: 0.464267; batch adversarial loss: 0.498539\n",
      "epoch 88; iter: 0; batch classifier loss: 0.337870; batch adversarial loss: 0.562339\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383278; batch adversarial loss: 0.580082\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410391; batch adversarial loss: 0.533542\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386470; batch adversarial loss: 0.535715\n",
      "epoch 92; iter: 0; batch classifier loss: 0.346244; batch adversarial loss: 0.544270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400660; batch adversarial loss: 0.599446\n",
      "epoch 94; iter: 0; batch classifier loss: 0.319322; batch adversarial loss: 0.581218\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425479; batch adversarial loss: 0.534482\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347210; batch adversarial loss: 0.525815\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344668; batch adversarial loss: 0.591246\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412718; batch adversarial loss: 0.627811\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454153; batch adversarial loss: 0.543626\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415018; batch adversarial loss: 0.581268\n",
      "epoch 101; iter: 0; batch classifier loss: 0.471870; batch adversarial loss: 0.571732\n",
      "epoch 102; iter: 0; batch classifier loss: 0.419199; batch adversarial loss: 0.562427\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391374; batch adversarial loss: 0.525220\n",
      "epoch 104; iter: 0; batch classifier loss: 0.381982; batch adversarial loss: 0.571942\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372713; batch adversarial loss: 0.452284\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428405; batch adversarial loss: 0.571613\n",
      "epoch 107; iter: 0; batch classifier loss: 0.487044; batch adversarial loss: 0.508874\n",
      "epoch 108; iter: 0; batch classifier loss: 0.347189; batch adversarial loss: 0.526122\n",
      "epoch 109; iter: 0; batch classifier loss: 0.311661; batch adversarial loss: 0.469778\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398633; batch adversarial loss: 0.591097\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391209; batch adversarial loss: 0.535033\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358773; batch adversarial loss: 0.572935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.342737; batch adversarial loss: 0.554750\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350771; batch adversarial loss: 0.498595\n",
      "epoch 115; iter: 0; batch classifier loss: 0.315160; batch adversarial loss: 0.563882\n",
      "epoch 116; iter: 0; batch classifier loss: 0.468604; batch adversarial loss: 0.526945\n",
      "epoch 117; iter: 0; batch classifier loss: 0.304104; batch adversarial loss: 0.533593\n",
      "epoch 118; iter: 0; batch classifier loss: 0.299950; batch adversarial loss: 0.498578\n",
      "epoch 119; iter: 0; batch classifier loss: 0.416263; batch adversarial loss: 0.506690\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356998; batch adversarial loss: 0.536454\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369271; batch adversarial loss: 0.561510\n",
      "epoch 122; iter: 0; batch classifier loss: 0.460642; batch adversarial loss: 0.581681\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331712; batch adversarial loss: 0.590817\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329359; batch adversarial loss: 0.507832\n",
      "epoch 125; iter: 0; batch classifier loss: 0.299527; batch adversarial loss: 0.545610\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386796; batch adversarial loss: 0.535772\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417506; batch adversarial loss: 0.488292\n",
      "epoch 128; iter: 0; batch classifier loss: 0.378273; batch adversarial loss: 0.554465\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397454; batch adversarial loss: 0.609468\n",
      "epoch 130; iter: 0; batch classifier loss: 0.435106; batch adversarial loss: 0.572549\n",
      "epoch 131; iter: 0; batch classifier loss: 0.329827; batch adversarial loss: 0.609165\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335719; batch adversarial loss: 0.535908\n",
      "epoch 133; iter: 0; batch classifier loss: 0.300598; batch adversarial loss: 0.608199\n",
      "epoch 134; iter: 0; batch classifier loss: 0.296371; batch adversarial loss: 0.525904\n",
      "epoch 135; iter: 0; batch classifier loss: 0.391600; batch adversarial loss: 0.562546\n",
      "epoch 136; iter: 0; batch classifier loss: 0.431771; batch adversarial loss: 0.591637\n",
      "epoch 137; iter: 0; batch classifier loss: 0.282090; batch adversarial loss: 0.533977\n",
      "epoch 138; iter: 0; batch classifier loss: 0.401575; batch adversarial loss: 0.536256\n",
      "epoch 139; iter: 0; batch classifier loss: 0.318413; batch adversarial loss: 0.523673\n",
      "epoch 140; iter: 0; batch classifier loss: 0.312077; batch adversarial loss: 0.634803\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370071; batch adversarial loss: 0.564576\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363411; batch adversarial loss: 0.534732\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339531; batch adversarial loss: 0.433556\n",
      "epoch 144; iter: 0; batch classifier loss: 0.402434; batch adversarial loss: 0.508547\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400952; batch adversarial loss: 0.506992\n",
      "epoch 146; iter: 0; batch classifier loss: 0.328629; batch adversarial loss: 0.580609\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303471; batch adversarial loss: 0.488822\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346339; batch adversarial loss: 0.589556\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317014; batch adversarial loss: 0.553742\n",
      "epoch 150; iter: 0; batch classifier loss: 0.316155; batch adversarial loss: 0.626314\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375729; batch adversarial loss: 0.525756\n",
      "epoch 152; iter: 0; batch classifier loss: 0.361263; batch adversarial loss: 0.571821\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365632; batch adversarial loss: 0.526273\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329205; batch adversarial loss: 0.553674\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392145; batch adversarial loss: 0.498580\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383885; batch adversarial loss: 0.517267\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394130; batch adversarial loss: 0.514341\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425515; batch adversarial loss: 0.517007\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361024; batch adversarial loss: 0.459607\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384021; batch adversarial loss: 0.535577\n",
      "epoch 161; iter: 0; batch classifier loss: 0.295480; batch adversarial loss: 0.526120\n",
      "epoch 162; iter: 0; batch classifier loss: 0.298234; batch adversarial loss: 0.507637\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392661; batch adversarial loss: 0.489234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.444516; batch adversarial loss: 0.619276\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375920; batch adversarial loss: 0.572828\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368941; batch adversarial loss: 0.618223\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373745; batch adversarial loss: 0.637102\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406494; batch adversarial loss: 0.554373\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321240; batch adversarial loss: 0.608654\n",
      "epoch 170; iter: 0; batch classifier loss: 0.396471; batch adversarial loss: 0.525710\n",
      "epoch 171; iter: 0; batch classifier loss: 0.315048; batch adversarial loss: 0.525451\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349602; batch adversarial loss: 0.552668\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341078; batch adversarial loss: 0.480066\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338750; batch adversarial loss: 0.581532\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331330; batch adversarial loss: 0.527543\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363943; batch adversarial loss: 0.553327\n",
      "epoch 177; iter: 0; batch classifier loss: 0.325574; batch adversarial loss: 0.498650\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376521; batch adversarial loss: 0.434647\n",
      "epoch 179; iter: 0; batch classifier loss: 0.360316; batch adversarial loss: 0.525972\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382649; batch adversarial loss: 0.564075\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386097; batch adversarial loss: 0.552015\n",
      "epoch 182; iter: 0; batch classifier loss: 0.271319; batch adversarial loss: 0.571741\n",
      "epoch 183; iter: 0; batch classifier loss: 0.292580; batch adversarial loss: 0.544490\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404421; batch adversarial loss: 0.534732\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397726; batch adversarial loss: 0.516295\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385744; batch adversarial loss: 0.478953\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375938; batch adversarial loss: 0.562700\n",
      "epoch 188; iter: 0; batch classifier loss: 0.399055; batch adversarial loss: 0.488998\n",
      "epoch 189; iter: 0; batch classifier loss: 0.398629; batch adversarial loss: 0.543896\n",
      "epoch 190; iter: 0; batch classifier loss: 0.362893; batch adversarial loss: 0.453267\n",
      "epoch 191; iter: 0; batch classifier loss: 0.385756; batch adversarial loss: 0.628954\n",
      "epoch 192; iter: 0; batch classifier loss: 0.372075; batch adversarial loss: 0.442155\n",
      "epoch 193; iter: 0; batch classifier loss: 0.334926; batch adversarial loss: 0.572329\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308528; batch adversarial loss: 0.525370\n",
      "epoch 195; iter: 0; batch classifier loss: 0.440183; batch adversarial loss: 0.636500\n",
      "epoch 196; iter: 0; batch classifier loss: 0.415616; batch adversarial loss: 0.516176\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351361; batch adversarial loss: 0.480538\n",
      "epoch 198; iter: 0; batch classifier loss: 0.327881; batch adversarial loss: 0.563532\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352842; batch adversarial loss: 0.488987\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729704; batch adversarial loss: 0.594233\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587644; batch adversarial loss: 0.643517\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585929; batch adversarial loss: 0.628437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566587; batch adversarial loss: 0.679779\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539478; batch adversarial loss: 0.648543\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524357; batch adversarial loss: 0.620082\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538468; batch adversarial loss: 0.607484\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536736; batch adversarial loss: 0.599677\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486180; batch adversarial loss: 0.590072\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506419; batch adversarial loss: 0.558821\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524963; batch adversarial loss: 0.595606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.478049; batch adversarial loss: 0.631213\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455455; batch adversarial loss: 0.561499\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542519; batch adversarial loss: 0.566427\n",
      "epoch 14; iter: 0; batch classifier loss: 0.615008; batch adversarial loss: 0.551568\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578157; batch adversarial loss: 0.585048\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571771; batch adversarial loss: 0.539607\n",
      "epoch 17; iter: 0; batch classifier loss: 0.447480; batch adversarial loss: 0.529291\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559391; batch adversarial loss: 0.518627\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492121; batch adversarial loss: 0.580177\n",
      "epoch 20; iter: 0; batch classifier loss: 0.464954; batch adversarial loss: 0.549528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502798; batch adversarial loss: 0.570480\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514396; batch adversarial loss: 0.572259\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507360; batch adversarial loss: 0.561963\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507782; batch adversarial loss: 0.550603\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484748; batch adversarial loss: 0.535711\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446169; batch adversarial loss: 0.578510\n",
      "epoch 27; iter: 0; batch classifier loss: 0.502043; batch adversarial loss: 0.616739\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464180; batch adversarial loss: 0.545428\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508783; batch adversarial loss: 0.521133\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474275; batch adversarial loss: 0.576732\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485962; batch adversarial loss: 0.516570\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422092; batch adversarial loss: 0.561485\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464202; batch adversarial loss: 0.437751\n",
      "epoch 34; iter: 0; batch classifier loss: 0.370344; batch adversarial loss: 0.535220\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461052; batch adversarial loss: 0.536542\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427574; batch adversarial loss: 0.562464\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489537; batch adversarial loss: 0.544484\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488224; batch adversarial loss: 0.572564\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422557; batch adversarial loss: 0.498725\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522593; batch adversarial loss: 0.508555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476181; batch adversarial loss: 0.490603\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461397; batch adversarial loss: 0.607345\n",
      "epoch 43; iter: 0; batch classifier loss: 0.503447; batch adversarial loss: 0.607677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415714; batch adversarial loss: 0.627458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438244; batch adversarial loss: 0.653774\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418744; batch adversarial loss: 0.580003\n",
      "epoch 47; iter: 0; batch classifier loss: 0.518892; batch adversarial loss: 0.590134\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381333; batch adversarial loss: 0.480825\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382997; batch adversarial loss: 0.562818\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462063; batch adversarial loss: 0.481294\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392482; batch adversarial loss: 0.634718\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440152; batch adversarial loss: 0.572126\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461225; batch adversarial loss: 0.508423\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461914; batch adversarial loss: 0.553811\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445460; batch adversarial loss: 0.508265\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439132; batch adversarial loss: 0.580376\n",
      "epoch 57; iter: 0; batch classifier loss: 0.388853; batch adversarial loss: 0.571796\n",
      "epoch 58; iter: 0; batch classifier loss: 0.470150; batch adversarial loss: 0.508776\n",
      "epoch 59; iter: 0; batch classifier loss: 0.543186; batch adversarial loss: 0.572019\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401315; batch adversarial loss: 0.526501\n",
      "epoch 61; iter: 0; batch classifier loss: 0.511287; batch adversarial loss: 0.444274\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400994; batch adversarial loss: 0.498879\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433717; batch adversarial loss: 0.571617\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454786; batch adversarial loss: 0.598562\n",
      "epoch 65; iter: 0; batch classifier loss: 0.494753; batch adversarial loss: 0.516910\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436161; batch adversarial loss: 0.481857\n",
      "epoch 67; iter: 0; batch classifier loss: 0.364584; batch adversarial loss: 0.607126\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383727; batch adversarial loss: 0.482744\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415013; batch adversarial loss: 0.679331\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415051; batch adversarial loss: 0.536155\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426573; batch adversarial loss: 0.516787\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397767; batch adversarial loss: 0.581718\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408485; batch adversarial loss: 0.572437\n",
      "epoch 74; iter: 0; batch classifier loss: 0.336955; batch adversarial loss: 0.535087\n",
      "epoch 75; iter: 0; batch classifier loss: 0.442350; batch adversarial loss: 0.570989\n",
      "epoch 76; iter: 0; batch classifier loss: 0.362036; batch adversarial loss: 0.525073\n",
      "epoch 77; iter: 0; batch classifier loss: 0.328087; batch adversarial loss: 0.489476\n",
      "epoch 78; iter: 0; batch classifier loss: 0.410698; batch adversarial loss: 0.591723\n",
      "epoch 79; iter: 0; batch classifier loss: 0.460192; batch adversarial loss: 0.517576\n",
      "epoch 80; iter: 0; batch classifier loss: 0.327896; batch adversarial loss: 0.508500\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374969; batch adversarial loss: 0.533698\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405862; batch adversarial loss: 0.563258\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417934; batch adversarial loss: 0.536283\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444752; batch adversarial loss: 0.489750\n",
      "epoch 85; iter: 0; batch classifier loss: 0.417936; batch adversarial loss: 0.519279\n",
      "epoch 86; iter: 0; batch classifier loss: 0.441474; batch adversarial loss: 0.544058\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423335; batch adversarial loss: 0.535422\n",
      "epoch 88; iter: 0; batch classifier loss: 0.471910; batch adversarial loss: 0.563357\n",
      "epoch 89; iter: 0; batch classifier loss: 0.269211; batch adversarial loss: 0.473406\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362363; batch adversarial loss: 0.571074\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381973; batch adversarial loss: 0.589604\n",
      "epoch 92; iter: 0; batch classifier loss: 0.438147; batch adversarial loss: 0.553881\n",
      "epoch 93; iter: 0; batch classifier loss: 0.428125; batch adversarial loss: 0.571689\n",
      "epoch 94; iter: 0; batch classifier loss: 0.471973; batch adversarial loss: 0.544455\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414831; batch adversarial loss: 0.653827\n",
      "epoch 96; iter: 0; batch classifier loss: 0.483755; batch adversarial loss: 0.562312\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404081; batch adversarial loss: 0.508321\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383652; batch adversarial loss: 0.498282\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384389; batch adversarial loss: 0.553872\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390526; batch adversarial loss: 0.598611\n",
      "epoch 101; iter: 0; batch classifier loss: 0.451161; batch adversarial loss: 0.525978\n",
      "epoch 102; iter: 0; batch classifier loss: 0.430598; batch adversarial loss: 0.597349\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376086; batch adversarial loss: 0.535147\n",
      "epoch 104; iter: 0; batch classifier loss: 0.492046; batch adversarial loss: 0.544623\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380176; batch adversarial loss: 0.464110\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385153; batch adversarial loss: 0.625614\n",
      "epoch 107; iter: 0; batch classifier loss: 0.427198; batch adversarial loss: 0.463030\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392341; batch adversarial loss: 0.562371\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407341; batch adversarial loss: 0.526628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.495404; batch adversarial loss: 0.553642\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431545; batch adversarial loss: 0.626783\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379965; batch adversarial loss: 0.563236\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417973; batch adversarial loss: 0.562982\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363456; batch adversarial loss: 0.544716\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381044; batch adversarial loss: 0.535664\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391781; batch adversarial loss: 0.544661\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399637; batch adversarial loss: 0.489677\n",
      "epoch 118; iter: 0; batch classifier loss: 0.344098; batch adversarial loss: 0.580666\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384857; batch adversarial loss: 0.571715\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416830; batch adversarial loss: 0.490035\n",
      "epoch 121; iter: 0; batch classifier loss: 0.457456; batch adversarial loss: 0.625968\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376107; batch adversarial loss: 0.581336\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423421; batch adversarial loss: 0.526537\n",
      "epoch 124; iter: 0; batch classifier loss: 0.394630; batch adversarial loss: 0.562351\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373430; batch adversarial loss: 0.608348\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402998; batch adversarial loss: 0.553636\n",
      "epoch 127; iter: 0; batch classifier loss: 0.398371; batch adversarial loss: 0.544676\n",
      "epoch 128; iter: 0; batch classifier loss: 0.250831; batch adversarial loss: 0.571753\n",
      "epoch 129; iter: 0; batch classifier loss: 0.332563; batch adversarial loss: 0.562743\n",
      "epoch 130; iter: 0; batch classifier loss: 0.430734; batch adversarial loss: 0.589553\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407476; batch adversarial loss: 0.480990\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339509; batch adversarial loss: 0.471859\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426740; batch adversarial loss: 0.598709\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350181; batch adversarial loss: 0.462914\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368647; batch adversarial loss: 0.617367\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360954; batch adversarial loss: 0.490107\n",
      "epoch 137; iter: 0; batch classifier loss: 0.387825; batch adversarial loss: 0.563085\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411401; batch adversarial loss: 0.598563\n",
      "epoch 139; iter: 0; batch classifier loss: 0.387811; batch adversarial loss: 0.580939\n",
      "epoch 140; iter: 0; batch classifier loss: 0.331375; batch adversarial loss: 0.508512\n",
      "epoch 141; iter: 0; batch classifier loss: 0.450685; batch adversarial loss: 0.525944\n",
      "epoch 142; iter: 0; batch classifier loss: 0.444678; batch adversarial loss: 0.571732\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378177; batch adversarial loss: 0.571629\n",
      "epoch 144; iter: 0; batch classifier loss: 0.281380; batch adversarial loss: 0.544632\n",
      "epoch 145; iter: 0; batch classifier loss: 0.361481; batch adversarial loss: 0.453904\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404902; batch adversarial loss: 0.534971\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348863; batch adversarial loss: 0.598726\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373872; batch adversarial loss: 0.508258\n",
      "epoch 149; iter: 0; batch classifier loss: 0.447672; batch adversarial loss: 0.636303\n",
      "epoch 150; iter: 0; batch classifier loss: 0.408803; batch adversarial loss: 0.490303\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398829; batch adversarial loss: 0.571721\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338699; batch adversarial loss: 0.553639\n",
      "epoch 153; iter: 0; batch classifier loss: 0.395846; batch adversarial loss: 0.499843\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358035; batch adversarial loss: 0.580206\n",
      "epoch 155; iter: 0; batch classifier loss: 0.454224; batch adversarial loss: 0.635454\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352442; batch adversarial loss: 0.508469\n",
      "epoch 157; iter: 0; batch classifier loss: 0.420407; batch adversarial loss: 0.526073\n",
      "epoch 158; iter: 0; batch classifier loss: 0.430574; batch adversarial loss: 0.553765\n",
      "epoch 159; iter: 0; batch classifier loss: 0.420572; batch adversarial loss: 0.543555\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382373; batch adversarial loss: 0.554189\n",
      "epoch 161; iter: 0; batch classifier loss: 0.435744; batch adversarial loss: 0.508506\n",
      "epoch 162; iter: 0; batch classifier loss: 0.330945; batch adversarial loss: 0.634837\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360662; batch adversarial loss: 0.527020\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376329; batch adversarial loss: 0.480928\n",
      "epoch 165; iter: 0; batch classifier loss: 0.420901; batch adversarial loss: 0.590189\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330287; batch adversarial loss: 0.608335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342468; batch adversarial loss: 0.526266\n",
      "epoch 168; iter: 0; batch classifier loss: 0.295703; batch adversarial loss: 0.544300\n",
      "epoch 169; iter: 0; batch classifier loss: 0.487847; batch adversarial loss: 0.571990\n",
      "epoch 170; iter: 0; batch classifier loss: 0.316578; batch adversarial loss: 0.599555\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313299; batch adversarial loss: 0.589216\n",
      "epoch 172; iter: 0; batch classifier loss: 0.321068; batch adversarial loss: 0.589500\n",
      "epoch 173; iter: 0; batch classifier loss: 0.258813; batch adversarial loss: 0.498999\n",
      "epoch 174; iter: 0; batch classifier loss: 0.327604; batch adversarial loss: 0.517074\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373518; batch adversarial loss: 0.554131\n",
      "epoch 176; iter: 0; batch classifier loss: 0.309755; batch adversarial loss: 0.536156\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369470; batch adversarial loss: 0.590642\n",
      "epoch 178; iter: 0; batch classifier loss: 0.476518; batch adversarial loss: 0.544739\n",
      "epoch 179; iter: 0; batch classifier loss: 0.302491; batch adversarial loss: 0.553406\n",
      "epoch 180; iter: 0; batch classifier loss: 0.461245; batch adversarial loss: 0.508191\n",
      "epoch 181; iter: 0; batch classifier loss: 0.385104; batch adversarial loss: 0.617399\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376128; batch adversarial loss: 0.562832\n",
      "epoch 183; iter: 0; batch classifier loss: 0.439170; batch adversarial loss: 0.553033\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344835; batch adversarial loss: 0.617210\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351519; batch adversarial loss: 0.644862\n",
      "epoch 186; iter: 0; batch classifier loss: 0.378998; batch adversarial loss: 0.608762\n",
      "epoch 187; iter: 0; batch classifier loss: 0.289973; batch adversarial loss: 0.426596\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395675; batch adversarial loss: 0.689860\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328723; batch adversarial loss: 0.516898\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347021; batch adversarial loss: 0.553203\n",
      "epoch 191; iter: 0; batch classifier loss: 0.401177; batch adversarial loss: 0.526993\n",
      "epoch 192; iter: 0; batch classifier loss: 0.324271; batch adversarial loss: 0.590626\n",
      "epoch 193; iter: 0; batch classifier loss: 0.411716; batch adversarial loss: 0.526741\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340917; batch adversarial loss: 0.645423\n",
      "epoch 195; iter: 0; batch classifier loss: 0.407490; batch adversarial loss: 0.544393\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386999; batch adversarial loss: 0.516711\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381856; batch adversarial loss: 0.517244\n",
      "epoch 198; iter: 0; batch classifier loss: 0.295923; batch adversarial loss: 0.581295\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393065; batch adversarial loss: 0.581376\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664208; batch adversarial loss: 0.704051\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556085; batch adversarial loss: 0.684015\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599955; batch adversarial loss: 0.673248\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551257; batch adversarial loss: 0.661490\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530360; batch adversarial loss: 0.618618\n",
      "epoch 5; iter: 0; batch classifier loss: 0.622081; batch adversarial loss: 0.588349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.560520; batch adversarial loss: 0.556589\n",
      "epoch 7; iter: 0; batch classifier loss: 0.572739; batch adversarial loss: 0.560216\n",
      "epoch 8; iter: 0; batch classifier loss: 0.502353; batch adversarial loss: 0.564924\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496794; batch adversarial loss: 0.630327\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501061; batch adversarial loss: 0.563342\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557124; batch adversarial loss: 0.559797\n",
      "epoch 12; iter: 0; batch classifier loss: 0.486650; batch adversarial loss: 0.583535\n",
      "epoch 13; iter: 0; batch classifier loss: 0.458937; batch adversarial loss: 0.548171\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545339; batch adversarial loss: 0.575245\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516982; batch adversarial loss: 0.551974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452065; batch adversarial loss: 0.554387\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497984; batch adversarial loss: 0.570451\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539116; batch adversarial loss: 0.603989\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532533; batch adversarial loss: 0.523346\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522887; batch adversarial loss: 0.560143\n",
      "epoch 21; iter: 0; batch classifier loss: 0.506716; batch adversarial loss: 0.480047\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470985; batch adversarial loss: 0.617371\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430582; batch adversarial loss: 0.520934\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461517; batch adversarial loss: 0.595012\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478500; batch adversarial loss: 0.559247\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493289; batch adversarial loss: 0.558988\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427457; batch adversarial loss: 0.516714\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414819; batch adversarial loss: 0.606170\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484963; batch adversarial loss: 0.539571\n",
      "epoch 30; iter: 0; batch classifier loss: 0.447426; batch adversarial loss: 0.530203\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430973; batch adversarial loss: 0.554930\n",
      "epoch 32; iter: 0; batch classifier loss: 0.559056; batch adversarial loss: 0.519872\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468916; batch adversarial loss: 0.553992\n",
      "epoch 34; iter: 0; batch classifier loss: 0.385457; batch adversarial loss: 0.440287\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489566; batch adversarial loss: 0.581424\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474801; batch adversarial loss: 0.491881\n",
      "epoch 37; iter: 0; batch classifier loss: 0.413347; batch adversarial loss: 0.509724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.537637; batch adversarial loss: 0.598628\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411059; batch adversarial loss: 0.553587\n",
      "epoch 40; iter: 0; batch classifier loss: 0.402466; batch adversarial loss: 0.562477\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406834; batch adversarial loss: 0.590472\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420543; batch adversarial loss: 0.581163\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469538; batch adversarial loss: 0.498121\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433961; batch adversarial loss: 0.517200\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459403; batch adversarial loss: 0.590691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370270; batch adversarial loss: 0.535327\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428291; batch adversarial loss: 0.554522\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367140; batch adversarial loss: 0.608474\n",
      "epoch 49; iter: 0; batch classifier loss: 0.488914; batch adversarial loss: 0.581889\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445586; batch adversarial loss: 0.515830\n",
      "epoch 51; iter: 0; batch classifier loss: 0.375354; batch adversarial loss: 0.554531\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418074; batch adversarial loss: 0.534520\n",
      "epoch 53; iter: 0; batch classifier loss: 0.426215; batch adversarial loss: 0.553963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.386782; batch adversarial loss: 0.517217\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397169; batch adversarial loss: 0.609049\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415455; batch adversarial loss: 0.535434\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382224; batch adversarial loss: 0.470518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.343281; batch adversarial loss: 0.590767\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394497; batch adversarial loss: 0.554466\n",
      "epoch 60; iter: 0; batch classifier loss: 0.371263; batch adversarial loss: 0.525888\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400301; batch adversarial loss: 0.581922\n",
      "epoch 62; iter: 0; batch classifier loss: 0.413901; batch adversarial loss: 0.507234\n",
      "epoch 63; iter: 0; batch classifier loss: 0.482136; batch adversarial loss: 0.562954\n",
      "epoch 64; iter: 0; batch classifier loss: 0.350843; batch adversarial loss: 0.523846\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448108; batch adversarial loss: 0.581363\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431394; batch adversarial loss: 0.526285\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428426; batch adversarial loss: 0.536448\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388847; batch adversarial loss: 0.553972\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386707; batch adversarial loss: 0.443519\n",
      "epoch 70; iter: 0; batch classifier loss: 0.363259; batch adversarial loss: 0.599970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.464006; batch adversarial loss: 0.478881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.370642; batch adversarial loss: 0.627996\n",
      "epoch 73; iter: 0; batch classifier loss: 0.347459; batch adversarial loss: 0.562714\n",
      "epoch 74; iter: 0; batch classifier loss: 0.551727; batch adversarial loss: 0.619065\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443635; batch adversarial loss: 0.618066\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383611; batch adversarial loss: 0.581060\n",
      "epoch 77; iter: 0; batch classifier loss: 0.340791; batch adversarial loss: 0.537838\n",
      "epoch 78; iter: 0; batch classifier loss: 0.384176; batch adversarial loss: 0.573365\n",
      "epoch 79; iter: 0; batch classifier loss: 0.320943; batch adversarial loss: 0.506245\n",
      "epoch 80; iter: 0; batch classifier loss: 0.290758; batch adversarial loss: 0.525494\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417209; batch adversarial loss: 0.525083\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423283; batch adversarial loss: 0.582426\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367902; batch adversarial loss: 0.563862\n",
      "epoch 84; iter: 0; batch classifier loss: 0.350150; batch adversarial loss: 0.562722\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424102; batch adversarial loss: 0.553743\n",
      "epoch 86; iter: 0; batch classifier loss: 0.475801; batch adversarial loss: 0.495275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.333475; batch adversarial loss: 0.506280\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373065; batch adversarial loss: 0.572818\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368585; batch adversarial loss: 0.591170\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407385; batch adversarial loss: 0.544232\n",
      "epoch 91; iter: 0; batch classifier loss: 0.355876; batch adversarial loss: 0.535375\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417548; batch adversarial loss: 0.480587\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399053; batch adversarial loss: 0.469689\n",
      "epoch 94; iter: 0; batch classifier loss: 0.418269; batch adversarial loss: 0.526708\n",
      "epoch 95; iter: 0; batch classifier loss: 0.383659; batch adversarial loss: 0.599672\n",
      "epoch 96; iter: 0; batch classifier loss: 0.434116; batch adversarial loss: 0.488376\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388831; batch adversarial loss: 0.572639\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411652; batch adversarial loss: 0.572741\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404821; batch adversarial loss: 0.583186\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364923; batch adversarial loss: 0.545634\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359440; batch adversarial loss: 0.574082\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410529; batch adversarial loss: 0.570808\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352264; batch adversarial loss: 0.544733\n",
      "epoch 104; iter: 0; batch classifier loss: 0.284315; batch adversarial loss: 0.497538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.384031; batch adversarial loss: 0.543866\n",
      "epoch 106; iter: 0; batch classifier loss: 0.327294; batch adversarial loss: 0.554795\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371970; batch adversarial loss: 0.535291\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369134; batch adversarial loss: 0.506205\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359440; batch adversarial loss: 0.582409\n",
      "epoch 110; iter: 0; batch classifier loss: 0.321188; batch adversarial loss: 0.601175\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344812; batch adversarial loss: 0.486729\n",
      "epoch 112; iter: 0; batch classifier loss: 0.426101; batch adversarial loss: 0.546107\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375515; batch adversarial loss: 0.544441\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365247; batch adversarial loss: 0.579813\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356875; batch adversarial loss: 0.543834\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388350; batch adversarial loss: 0.481194\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319007; batch adversarial loss: 0.534557\n",
      "epoch 118; iter: 0; batch classifier loss: 0.442294; batch adversarial loss: 0.639414\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417304; batch adversarial loss: 0.676040\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367006; batch adversarial loss: 0.598408\n",
      "epoch 121; iter: 0; batch classifier loss: 0.333036; batch adversarial loss: 0.564711\n",
      "epoch 122; iter: 0; batch classifier loss: 0.331623; batch adversarial loss: 0.573710\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367354; batch adversarial loss: 0.532697\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322210; batch adversarial loss: 0.517459\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380485; batch adversarial loss: 0.526550\n",
      "epoch 126; iter: 0; batch classifier loss: 0.473469; batch adversarial loss: 0.601034\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358164; batch adversarial loss: 0.498516\n",
      "epoch 128; iter: 0; batch classifier loss: 0.378677; batch adversarial loss: 0.497997\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398152; batch adversarial loss: 0.574722\n",
      "epoch 130; iter: 0; batch classifier loss: 0.450984; batch adversarial loss: 0.527242\n",
      "epoch 131; iter: 0; batch classifier loss: 0.412250; batch adversarial loss: 0.583308\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323096; batch adversarial loss: 0.607797\n",
      "epoch 133; iter: 0; batch classifier loss: 0.318852; batch adversarial loss: 0.647443\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348801; batch adversarial loss: 0.450749\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424841; batch adversarial loss: 0.655567\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389590; batch adversarial loss: 0.535331\n",
      "epoch 137; iter: 0; batch classifier loss: 0.417294; batch adversarial loss: 0.573170\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387484; batch adversarial loss: 0.598274\n",
      "epoch 139; iter: 0; batch classifier loss: 0.315881; batch adversarial loss: 0.562641\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373615; batch adversarial loss: 0.571349\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326352; batch adversarial loss: 0.590623\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355074; batch adversarial loss: 0.550745\n",
      "epoch 143; iter: 0; batch classifier loss: 0.333963; batch adversarial loss: 0.500910\n",
      "epoch 144; iter: 0; batch classifier loss: 0.433182; batch adversarial loss: 0.591654\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363581; batch adversarial loss: 0.573992\n",
      "epoch 146; iter: 0; batch classifier loss: 0.303148; batch adversarial loss: 0.562193\n",
      "epoch 147; iter: 0; batch classifier loss: 0.357399; batch adversarial loss: 0.468293\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366593; batch adversarial loss: 0.615355\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328455; batch adversarial loss: 0.535351\n",
      "epoch 150; iter: 0; batch classifier loss: 0.393905; batch adversarial loss: 0.543720\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341541; batch adversarial loss: 0.555534\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327554; batch adversarial loss: 0.526497\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368268; batch adversarial loss: 0.554619\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335378; batch adversarial loss: 0.571560\n",
      "epoch 155; iter: 0; batch classifier loss: 0.292076; batch adversarial loss: 0.583677\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392761; batch adversarial loss: 0.524431\n",
      "epoch 157; iter: 0; batch classifier loss: 0.427880; batch adversarial loss: 0.480836\n",
      "epoch 158; iter: 0; batch classifier loss: 0.443331; batch adversarial loss: 0.619963\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338796; batch adversarial loss: 0.514433\n",
      "epoch 160; iter: 0; batch classifier loss: 0.450389; batch adversarial loss: 0.530469\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375199; batch adversarial loss: 0.598699\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380158; batch adversarial loss: 0.590451\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351302; batch adversarial loss: 0.516915\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344846; batch adversarial loss: 0.539703\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424773; batch adversarial loss: 0.626119\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308556; batch adversarial loss: 0.522652\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366298; batch adversarial loss: 0.583297\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338709; batch adversarial loss: 0.597798\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350387; batch adversarial loss: 0.432313\n",
      "epoch 170; iter: 0; batch classifier loss: 0.423176; batch adversarial loss: 0.593691\n",
      "epoch 171; iter: 0; batch classifier loss: 0.418356; batch adversarial loss: 0.544163\n",
      "epoch 172; iter: 0; batch classifier loss: 0.266725; batch adversarial loss: 0.535376\n",
      "epoch 173; iter: 0; batch classifier loss: 0.289792; batch adversarial loss: 0.479690\n",
      "epoch 174; iter: 0; batch classifier loss: 0.402550; batch adversarial loss: 0.545537\n",
      "epoch 175; iter: 0; batch classifier loss: 0.410381; batch adversarial loss: 0.526640\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336001; batch adversarial loss: 0.555731\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321836; batch adversarial loss: 0.543737\n",
      "epoch 178; iter: 0; batch classifier loss: 0.300661; batch adversarial loss: 0.433919\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303175; batch adversarial loss: 0.518231\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355531; batch adversarial loss: 0.545956\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345848; batch adversarial loss: 0.508377\n",
      "epoch 182; iter: 0; batch classifier loss: 0.312038; batch adversarial loss: 0.618220\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391853; batch adversarial loss: 0.513984\n",
      "epoch 184; iter: 0; batch classifier loss: 0.314653; batch adversarial loss: 0.487327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.429025; batch adversarial loss: 0.506920\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327219; batch adversarial loss: 0.487186\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341293; batch adversarial loss: 0.543284\n",
      "epoch 188; iter: 0; batch classifier loss: 0.293703; batch adversarial loss: 0.555483\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341732; batch adversarial loss: 0.571381\n",
      "epoch 190; iter: 0; batch classifier loss: 0.303241; batch adversarial loss: 0.507105\n",
      "epoch 191; iter: 0; batch classifier loss: 0.278412; batch adversarial loss: 0.561501\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403936; batch adversarial loss: 0.561080\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350500; batch adversarial loss: 0.554711\n",
      "epoch 194; iter: 0; batch classifier loss: 0.411236; batch adversarial loss: 0.495111\n",
      "epoch 195; iter: 0; batch classifier loss: 0.305422; batch adversarial loss: 0.441103\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334544; batch adversarial loss: 0.488270\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373846; batch adversarial loss: 0.556516\n",
      "epoch 198; iter: 0; batch classifier loss: 0.445810; batch adversarial loss: 0.561591\n",
      "epoch 199; iter: 0; batch classifier loss: 0.305614; batch adversarial loss: 0.609793\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682053; batch adversarial loss: 0.934959\n",
      "epoch 1; iter: 0; batch classifier loss: 0.927511; batch adversarial loss: 1.180307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 1.004750; batch adversarial loss: 1.128082\n",
      "epoch 3; iter: 0; batch classifier loss: 1.178341; batch adversarial loss: 1.095338\n",
      "epoch 4; iter: 0; batch classifier loss: 1.218745; batch adversarial loss: 0.947925\n",
      "epoch 5; iter: 0; batch classifier loss: 1.173369; batch adversarial loss: 0.889039\n",
      "epoch 6; iter: 0; batch classifier loss: 1.150270; batch adversarial loss: 0.824082\n",
      "epoch 7; iter: 0; batch classifier loss: 1.138988; batch adversarial loss: 0.766878\n",
      "epoch 8; iter: 0; batch classifier loss: 1.226027; batch adversarial loss: 0.724362\n",
      "epoch 9; iter: 0; batch classifier loss: 0.810203; batch adversarial loss: 0.664459\n",
      "epoch 10; iter: 0; batch classifier loss: 0.688517; batch adversarial loss: 0.612011\n",
      "epoch 11; iter: 0; batch classifier loss: 0.602288; batch adversarial loss: 0.587392\n",
      "epoch 12; iter: 0; batch classifier loss: 0.651422; batch adversarial loss: 0.577007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524689; batch adversarial loss: 0.578802\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526144; batch adversarial loss: 0.559946\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562692; batch adversarial loss: 0.570368\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507776; batch adversarial loss: 0.603954\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487802; batch adversarial loss: 0.629108\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506990; batch adversarial loss: 0.541217\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557093; batch adversarial loss: 0.568561\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499070; batch adversarial loss: 0.557131\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486700; batch adversarial loss: 0.534890\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555772; batch adversarial loss: 0.539391\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459491; batch adversarial loss: 0.544931\n",
      "epoch 24; iter: 0; batch classifier loss: 0.513519; batch adversarial loss: 0.526536\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566897; batch adversarial loss: 0.517437\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451250; batch adversarial loss: 0.521008\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414826; batch adversarial loss: 0.530439\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523062; batch adversarial loss: 0.515631\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487522; batch adversarial loss: 0.574915\n",
      "epoch 30; iter: 0; batch classifier loss: 0.549822; batch adversarial loss: 0.566322\n",
      "epoch 31; iter: 0; batch classifier loss: 0.503733; batch adversarial loss: 0.556093\n",
      "epoch 32; iter: 0; batch classifier loss: 0.367540; batch adversarial loss: 0.532483\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498785; batch adversarial loss: 0.462506\n",
      "epoch 34; iter: 0; batch classifier loss: 0.546989; batch adversarial loss: 0.530182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.557706; batch adversarial loss: 0.533344\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502116; batch adversarial loss: 0.505720\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495690; batch adversarial loss: 0.521225\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457734; batch adversarial loss: 0.535339\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455229; batch adversarial loss: 0.485307\n",
      "epoch 40; iter: 0; batch classifier loss: 0.503603; batch adversarial loss: 0.571321\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481355; batch adversarial loss: 0.454518\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465745; batch adversarial loss: 0.525701\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443424; batch adversarial loss: 0.540404\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473554; batch adversarial loss: 0.656994\n",
      "epoch 45; iter: 0; batch classifier loss: 0.526741; batch adversarial loss: 0.580612\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482856; batch adversarial loss: 0.588874\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497720; batch adversarial loss: 0.499692\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438911; batch adversarial loss: 0.521842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.485305; batch adversarial loss: 0.596150\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422192; batch adversarial loss: 0.498804\n",
      "epoch 51; iter: 0; batch classifier loss: 0.527453; batch adversarial loss: 0.487180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422275; batch adversarial loss: 0.477117\n",
      "epoch 53; iter: 0; batch classifier loss: 0.475288; batch adversarial loss: 0.525309\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448968; batch adversarial loss: 0.563982\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384537; batch adversarial loss: 0.534232\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383339; batch adversarial loss: 0.584198\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382846; batch adversarial loss: 0.546448\n",
      "epoch 58; iter: 0; batch classifier loss: 0.353466; batch adversarial loss: 0.564912\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376240; batch adversarial loss: 0.553314\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414732; batch adversarial loss: 0.509486\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389087; batch adversarial loss: 0.598593\n",
      "epoch 62; iter: 0; batch classifier loss: 0.470093; batch adversarial loss: 0.562143\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424335; batch adversarial loss: 0.544610\n",
      "epoch 64; iter: 0; batch classifier loss: 0.446866; batch adversarial loss: 0.608314\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417735; batch adversarial loss: 0.499124\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454474; batch adversarial loss: 0.534960\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410811; batch adversarial loss: 0.544649\n",
      "epoch 68; iter: 0; batch classifier loss: 0.336053; batch adversarial loss: 0.645517\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412185; batch adversarial loss: 0.544314\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407160; batch adversarial loss: 0.497291\n",
      "epoch 71; iter: 0; batch classifier loss: 0.379293; batch adversarial loss: 0.552803\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414443; batch adversarial loss: 0.554290\n",
      "epoch 73; iter: 0; batch classifier loss: 0.458076; batch adversarial loss: 0.507474\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388995; batch adversarial loss: 0.618070\n",
      "epoch 75; iter: 0; batch classifier loss: 0.350363; batch adversarial loss: 0.571781\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406560; batch adversarial loss: 0.561520\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411330; batch adversarial loss: 0.499299\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392540; batch adversarial loss: 0.544461\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421651; batch adversarial loss: 0.600960\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395714; batch adversarial loss: 0.498871\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378851; batch adversarial loss: 0.609599\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366990; batch adversarial loss: 0.542793\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422856; batch adversarial loss: 0.553029\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403321; batch adversarial loss: 0.498322\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361871; batch adversarial loss: 0.553532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378451; batch adversarial loss: 0.498798\n",
      "epoch 87; iter: 0; batch classifier loss: 0.449233; batch adversarial loss: 0.488283\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422113; batch adversarial loss: 0.537509\n",
      "epoch 89; iter: 0; batch classifier loss: 0.497101; batch adversarial loss: 0.564006\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355503; batch adversarial loss: 0.520719\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438512; batch adversarial loss: 0.619261\n",
      "epoch 92; iter: 0; batch classifier loss: 0.315801; batch adversarial loss: 0.571733\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337366; batch adversarial loss: 0.589394\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423104; batch adversarial loss: 0.506646\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375549; batch adversarial loss: 0.499567\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417263; batch adversarial loss: 0.590864\n",
      "epoch 97; iter: 0; batch classifier loss: 0.325038; batch adversarial loss: 0.506401\n",
      "epoch 98; iter: 0; batch classifier loss: 0.352819; batch adversarial loss: 0.553591\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396842; batch adversarial loss: 0.494639\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348202; batch adversarial loss: 0.561996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.355712; batch adversarial loss: 0.525104\n",
      "epoch 102; iter: 0; batch classifier loss: 0.336291; batch adversarial loss: 0.497681\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386197; batch adversarial loss: 0.555320\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376676; batch adversarial loss: 0.584097\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385608; batch adversarial loss: 0.544542\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362039; batch adversarial loss: 0.488568\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436407; batch adversarial loss: 0.526758\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355383; batch adversarial loss: 0.459164\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430150; batch adversarial loss: 0.514820\n",
      "epoch 110; iter: 0; batch classifier loss: 0.320339; batch adversarial loss: 0.496571\n",
      "epoch 111; iter: 0; batch classifier loss: 0.396944; batch adversarial loss: 0.581908\n",
      "epoch 112; iter: 0; batch classifier loss: 0.449137; batch adversarial loss: 0.544985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.331277; batch adversarial loss: 0.497407\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340276; batch adversarial loss: 0.525519\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381339; batch adversarial loss: 0.616940\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392724; batch adversarial loss: 0.647234\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399517; batch adversarial loss: 0.562405\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404626; batch adversarial loss: 0.488091\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385426; batch adversarial loss: 0.601357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.435006; batch adversarial loss: 0.572493\n",
      "epoch 121; iter: 0; batch classifier loss: 0.363994; batch adversarial loss: 0.518062\n",
      "epoch 122; iter: 0; batch classifier loss: 0.322576; batch adversarial loss: 0.563434\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359926; batch adversarial loss: 0.514739\n",
      "epoch 124; iter: 0; batch classifier loss: 0.461597; batch adversarial loss: 0.618356\n",
      "epoch 125; iter: 0; batch classifier loss: 0.335842; batch adversarial loss: 0.536457\n",
      "epoch 126; iter: 0; batch classifier loss: 0.341127; batch adversarial loss: 0.585840\n",
      "epoch 127; iter: 0; batch classifier loss: 0.303706; batch adversarial loss: 0.648597\n",
      "epoch 128; iter: 0; batch classifier loss: 0.336156; batch adversarial loss: 0.536372\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434311; batch adversarial loss: 0.508319\n",
      "epoch 130; iter: 0; batch classifier loss: 0.329969; batch adversarial loss: 0.517757\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360733; batch adversarial loss: 0.563766\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349455; batch adversarial loss: 0.590489\n",
      "epoch 133; iter: 0; batch classifier loss: 0.401487; batch adversarial loss: 0.423349\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396891; batch adversarial loss: 0.525389\n",
      "epoch 135; iter: 0; batch classifier loss: 0.316256; batch adversarial loss: 0.488867\n",
      "epoch 136; iter: 0; batch classifier loss: 0.318137; batch adversarial loss: 0.536043\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367617; batch adversarial loss: 0.542643\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383924; batch adversarial loss: 0.538208\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338694; batch adversarial loss: 0.543632\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335671; batch adversarial loss: 0.624794\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328106; batch adversarial loss: 0.515577\n",
      "epoch 142; iter: 0; batch classifier loss: 0.323557; batch adversarial loss: 0.628947\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358613; batch adversarial loss: 0.559389\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318795; batch adversarial loss: 0.576258\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350874; batch adversarial loss: 0.606595\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425871; batch adversarial loss: 0.588485\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349499; batch adversarial loss: 0.515460\n",
      "epoch 148; iter: 0; batch classifier loss: 0.293605; batch adversarial loss: 0.511055\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353055; batch adversarial loss: 0.534957\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373946; batch adversarial loss: 0.609644\n",
      "epoch 151; iter: 0; batch classifier loss: 0.306919; batch adversarial loss: 0.516702\n",
      "epoch 152; iter: 0; batch classifier loss: 0.414705; batch adversarial loss: 0.569224\n",
      "epoch 153; iter: 0; batch classifier loss: 0.382613; batch adversarial loss: 0.550693\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320833; batch adversarial loss: 0.544429\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433260; batch adversarial loss: 0.637656\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352458; batch adversarial loss: 0.563971\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319139; batch adversarial loss: 0.478113\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365662; batch adversarial loss: 0.579438\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374672; batch adversarial loss: 0.498925\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319736; batch adversarial loss: 0.580271\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339775; batch adversarial loss: 0.573842\n",
      "epoch 162; iter: 0; batch classifier loss: 0.338306; batch adversarial loss: 0.510712\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354853; batch adversarial loss: 0.516094\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353830; batch adversarial loss: 0.593348\n",
      "epoch 165; iter: 0; batch classifier loss: 0.263534; batch adversarial loss: 0.610740\n",
      "epoch 166; iter: 0; batch classifier loss: 0.414007; batch adversarial loss: 0.621895\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341142; batch adversarial loss: 0.583481\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307133; batch adversarial loss: 0.553493\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380740; batch adversarial loss: 0.537758\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345991; batch adversarial loss: 0.629177\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382137; batch adversarial loss: 0.619788\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394919; batch adversarial loss: 0.525548\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313510; batch adversarial loss: 0.589784\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364468; batch adversarial loss: 0.490942\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311342; batch adversarial loss: 0.515950\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334547; batch adversarial loss: 0.553812\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303605; batch adversarial loss: 0.470893\n",
      "epoch 178; iter: 0; batch classifier loss: 0.277988; batch adversarial loss: 0.553221\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330307; batch adversarial loss: 0.499806\n",
      "epoch 180; iter: 0; batch classifier loss: 0.266372; batch adversarial loss: 0.486714\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358470; batch adversarial loss: 0.581929\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366498; batch adversarial loss: 0.518072\n",
      "epoch 183; iter: 0; batch classifier loss: 0.299618; batch adversarial loss: 0.496571\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413713; batch adversarial loss: 0.470874\n",
      "epoch 185; iter: 0; batch classifier loss: 0.275404; batch adversarial loss: 0.572636\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331354; batch adversarial loss: 0.561124\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358007; batch adversarial loss: 0.543896\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382773; batch adversarial loss: 0.480335\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315496; batch adversarial loss: 0.564468\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321629; batch adversarial loss: 0.497815\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381337; batch adversarial loss: 0.524071\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367894; batch adversarial loss: 0.516506\n",
      "epoch 193; iter: 0; batch classifier loss: 0.297160; batch adversarial loss: 0.531944\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340186; batch adversarial loss: 0.523465\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331369; batch adversarial loss: 0.577224\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331357; batch adversarial loss: 0.466876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.334026; batch adversarial loss: 0.523361\n",
      "epoch 198; iter: 0; batch classifier loss: 0.299603; batch adversarial loss: 0.524883\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339561; batch adversarial loss: 0.548311\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669488; batch adversarial loss: 0.678815\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593927; batch adversarial loss: 0.645604\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602900; batch adversarial loss: 0.627217\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598759; batch adversarial loss: 0.627677\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557926; batch adversarial loss: 0.602840\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552782; batch adversarial loss: 0.648120\n",
      "epoch 6; iter: 0; batch classifier loss: 0.505835; batch adversarial loss: 0.614325\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557224; batch adversarial loss: 0.562890\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542152; batch adversarial loss: 0.613042\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487568; batch adversarial loss: 0.504690\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533539; batch adversarial loss: 0.565988\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464536; batch adversarial loss: 0.615665\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569232; batch adversarial loss: 0.614344\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526231; batch adversarial loss: 0.636037\n",
      "epoch 14; iter: 0; batch classifier loss: 0.570856; batch adversarial loss: 0.525154\n",
      "epoch 15; iter: 0; batch classifier loss: 0.581472; batch adversarial loss: 0.573746\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547100; batch adversarial loss: 0.550855\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592935; batch adversarial loss: 0.643883\n",
      "epoch 18; iter: 0; batch classifier loss: 0.606530; batch adversarial loss: 0.575897\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506253; batch adversarial loss: 0.529625\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529143; batch adversarial loss: 0.513073\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543674; batch adversarial loss: 0.621967\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452504; batch adversarial loss: 0.572354\n",
      "epoch 23; iter: 0; batch classifier loss: 0.552110; batch adversarial loss: 0.564573\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499719; batch adversarial loss: 0.562702\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432303; batch adversarial loss: 0.604837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527640; batch adversarial loss: 0.552836\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500243; batch adversarial loss: 0.462004\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472962; batch adversarial loss: 0.511158\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474518; batch adversarial loss: 0.458914\n",
      "epoch 30; iter: 0; batch classifier loss: 0.614063; batch adversarial loss: 0.544527\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484349; batch adversarial loss: 0.561013\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460993; batch adversarial loss: 0.484223\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471308; batch adversarial loss: 0.562835\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488599; batch adversarial loss: 0.492938\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406804; batch adversarial loss: 0.571447\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461497; batch adversarial loss: 0.562979\n",
      "epoch 37; iter: 0; batch classifier loss: 0.535388; batch adversarial loss: 0.518087\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497768; batch adversarial loss: 0.580568\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483444; batch adversarial loss: 0.498953\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413465; batch adversarial loss: 0.590175\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438036; batch adversarial loss: 0.590296\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449017; batch adversarial loss: 0.554030\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475830; batch adversarial loss: 0.508500\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466924; batch adversarial loss: 0.526383\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435535; batch adversarial loss: 0.553888\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406757; batch adversarial loss: 0.581766\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435424; batch adversarial loss: 0.571770\n",
      "epoch 48; iter: 0; batch classifier loss: 0.557824; batch adversarial loss: 0.490031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420802; batch adversarial loss: 0.562593\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435510; batch adversarial loss: 0.554084\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449224; batch adversarial loss: 0.579621\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.526600\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451358; batch adversarial loss: 0.482817\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447779; batch adversarial loss: 0.508250\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487516; batch adversarial loss: 0.553701\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433282; batch adversarial loss: 0.550141\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425636; batch adversarial loss: 0.571340\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412085; batch adversarial loss: 0.588706\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375803; batch adversarial loss: 0.525990\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434731; batch adversarial loss: 0.526378\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433286; batch adversarial loss: 0.563492\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448608; batch adversarial loss: 0.515988\n",
      "epoch 63; iter: 0; batch classifier loss: 0.532118; batch adversarial loss: 0.585625\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413633; batch adversarial loss: 0.542881\n",
      "epoch 65; iter: 0; batch classifier loss: 0.508106; batch adversarial loss: 0.524140\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384384; batch adversarial loss: 0.511533\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393237; batch adversarial loss: 0.597984\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411355; batch adversarial loss: 0.546473\n",
      "epoch 69; iter: 0; batch classifier loss: 0.470901; batch adversarial loss: 0.499189\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458739; batch adversarial loss: 0.587502\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423881; batch adversarial loss: 0.601730\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373612; batch adversarial loss: 0.491156\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421125; batch adversarial loss: 0.564258\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413251; batch adversarial loss: 0.584154\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427683; batch adversarial loss: 0.452491\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413881; batch adversarial loss: 0.687637\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411139; batch adversarial loss: 0.610801\n",
      "epoch 78; iter: 0; batch classifier loss: 0.495961; batch adversarial loss: 0.571984\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397029; batch adversarial loss: 0.516662\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376142; batch adversarial loss: 0.516431\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400615; batch adversarial loss: 0.517096\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389512; batch adversarial loss: 0.581150\n",
      "epoch 83; iter: 0; batch classifier loss: 0.347218; batch adversarial loss: 0.545168\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434810; batch adversarial loss: 0.526689\n",
      "epoch 85; iter: 0; batch classifier loss: 0.325358; batch adversarial loss: 0.508331\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427359; batch adversarial loss: 0.543773\n",
      "epoch 87; iter: 0; batch classifier loss: 0.449548; batch adversarial loss: 0.571893\n",
      "epoch 88; iter: 0; batch classifier loss: 0.339525; batch adversarial loss: 0.552801\n",
      "epoch 89; iter: 0; batch classifier loss: 0.448654; batch adversarial loss: 0.562841\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374360; batch adversarial loss: 0.488109\n",
      "epoch 91; iter: 0; batch classifier loss: 0.418468; batch adversarial loss: 0.552651\n",
      "epoch 92; iter: 0; batch classifier loss: 0.433418; batch adversarial loss: 0.525501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370478; batch adversarial loss: 0.590138\n",
      "epoch 94; iter: 0; batch classifier loss: 0.359187; batch adversarial loss: 0.535791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.294676; batch adversarial loss: 0.545463\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358389; batch adversarial loss: 0.553525\n",
      "epoch 97; iter: 0; batch classifier loss: 0.449880; batch adversarial loss: 0.580398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365214; batch adversarial loss: 0.498401\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378798; batch adversarial loss: 0.463766\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377755; batch adversarial loss: 0.525065\n",
      "epoch 101; iter: 0; batch classifier loss: 0.354702; batch adversarial loss: 0.517466\n",
      "epoch 102; iter: 0; batch classifier loss: 0.431785; batch adversarial loss: 0.534985\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417650; batch adversarial loss: 0.509254\n",
      "epoch 104; iter: 0; batch classifier loss: 0.405692; batch adversarial loss: 0.507536\n",
      "epoch 105; iter: 0; batch classifier loss: 0.440179; batch adversarial loss: 0.525922\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362634; batch adversarial loss: 0.561366\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421833; batch adversarial loss: 0.581361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394357; batch adversarial loss: 0.506920\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383921; batch adversarial loss: 0.453425\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365613; batch adversarial loss: 0.581093\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389448; batch adversarial loss: 0.534987\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372074; batch adversarial loss: 0.526726\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355390; batch adversarial loss: 0.480832\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420779; batch adversarial loss: 0.599029\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350326; batch adversarial loss: 0.544171\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377657; batch adversarial loss: 0.535462\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389637; batch adversarial loss: 0.552697\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395333; batch adversarial loss: 0.544011\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342721; batch adversarial loss: 0.480660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.389636; batch adversarial loss: 0.507163\n",
      "epoch 121; iter: 0; batch classifier loss: 0.340614; batch adversarial loss: 0.443054\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382334; batch adversarial loss: 0.527417\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379752; batch adversarial loss: 0.469986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358142; batch adversarial loss: 0.526893\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373334; batch adversarial loss: 0.552937\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366775; batch adversarial loss: 0.563867\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410802; batch adversarial loss: 0.535023\n",
      "epoch 128; iter: 0; batch classifier loss: 0.302552; batch adversarial loss: 0.580460\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395904; batch adversarial loss: 0.517049\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354167; batch adversarial loss: 0.571619\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364511; batch adversarial loss: 0.570874\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381901; batch adversarial loss: 0.499939\n",
      "epoch 133; iter: 0; batch classifier loss: 0.418273; batch adversarial loss: 0.563657\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415852; batch adversarial loss: 0.599804\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370222; batch adversarial loss: 0.597105\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427345; batch adversarial loss: 0.479538\n",
      "epoch 137; iter: 0; batch classifier loss: 0.435266; batch adversarial loss: 0.552809\n",
      "epoch 138; iter: 0; batch classifier loss: 0.301764; batch adversarial loss: 0.554248\n",
      "epoch 139; iter: 0; batch classifier loss: 0.426758; batch adversarial loss: 0.490877\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367224; batch adversarial loss: 0.562249\n",
      "epoch 141; iter: 0; batch classifier loss: 0.460623; batch adversarial loss: 0.625632\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341885; batch adversarial loss: 0.580762\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386665; batch adversarial loss: 0.534982\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409758; batch adversarial loss: 0.561171\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368739; batch adversarial loss: 0.506362\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332620; batch adversarial loss: 0.462134\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327511; batch adversarial loss: 0.461661\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356059; batch adversarial loss: 0.580074\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417933; batch adversarial loss: 0.554243\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353567; batch adversarial loss: 0.517558\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408630; batch adversarial loss: 0.525572\n",
      "epoch 152; iter: 0; batch classifier loss: 0.443233; batch adversarial loss: 0.481783\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361384; batch adversarial loss: 0.535028\n",
      "epoch 154; iter: 0; batch classifier loss: 0.330489; batch adversarial loss: 0.443560\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342686; batch adversarial loss: 0.544969\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383592; batch adversarial loss: 0.554534\n",
      "epoch 157; iter: 0; batch classifier loss: 0.395538; batch adversarial loss: 0.588843\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332482; batch adversarial loss: 0.461743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348901; batch adversarial loss: 0.591579\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390967; batch adversarial loss: 0.579634\n",
      "epoch 161; iter: 0; batch classifier loss: 0.297108; batch adversarial loss: 0.590150\n",
      "epoch 162; iter: 0; batch classifier loss: 0.406623; batch adversarial loss: 0.581488\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373753; batch adversarial loss: 0.654786\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369428; batch adversarial loss: 0.462891\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344468; batch adversarial loss: 0.517939\n",
      "epoch 166; iter: 0; batch classifier loss: 0.410084; batch adversarial loss: 0.598224\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369475; batch adversarial loss: 0.618566\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330169; batch adversarial loss: 0.507863\n",
      "epoch 169; iter: 0; batch classifier loss: 0.416533; batch adversarial loss: 0.508380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324564; batch adversarial loss: 0.525951\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330135; batch adversarial loss: 0.563089\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407049; batch adversarial loss: 0.505877\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382311; batch adversarial loss: 0.628338\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372833; batch adversarial loss: 0.516426\n",
      "epoch 175; iter: 0; batch classifier loss: 0.431534; batch adversarial loss: 0.591619\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320254; batch adversarial loss: 0.590376\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369262; batch adversarial loss: 0.600822\n",
      "epoch 178; iter: 0; batch classifier loss: 0.447396; batch adversarial loss: 0.573254\n",
      "epoch 179; iter: 0; batch classifier loss: 0.425681; batch adversarial loss: 0.616690\n",
      "epoch 180; iter: 0; batch classifier loss: 0.443324; batch adversarial loss: 0.508688\n",
      "epoch 181; iter: 0; batch classifier loss: 0.402261; batch adversarial loss: 0.562439\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352155; batch adversarial loss: 0.526390\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365267; batch adversarial loss: 0.554555\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309807; batch adversarial loss: 0.506221\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392876; batch adversarial loss: 0.497911\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376396; batch adversarial loss: 0.535157\n",
      "epoch 187; iter: 0; batch classifier loss: 0.453897; batch adversarial loss: 0.573360\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363942; batch adversarial loss: 0.573639\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350337; batch adversarial loss: 0.525352\n",
      "epoch 190; iter: 0; batch classifier loss: 0.425450; batch adversarial loss: 0.508830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.458502; batch adversarial loss: 0.489514\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407576; batch adversarial loss: 0.608798\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381033; batch adversarial loss: 0.619166\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330628; batch adversarial loss: 0.480467\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379748; batch adversarial loss: 0.571380\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400315; batch adversarial loss: 0.598083\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394014; batch adversarial loss: 0.573329\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336181; batch adversarial loss: 0.471673\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349538; batch adversarial loss: 0.598945\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694326; batch adversarial loss: 0.783569\n",
      "epoch 1; iter: 0; batch classifier loss: 0.894576; batch adversarial loss: 1.144731\n",
      "epoch 2; iter: 0; batch classifier loss: 0.855041; batch adversarial loss: 1.180828\n",
      "epoch 3; iter: 0; batch classifier loss: 0.984838; batch adversarial loss: 1.125064\n",
      "epoch 4; iter: 0; batch classifier loss: 0.995864; batch adversarial loss: 1.022325\n",
      "epoch 5; iter: 0; batch classifier loss: 0.973705; batch adversarial loss: 0.931409\n",
      "epoch 6; iter: 0; batch classifier loss: 0.886556; batch adversarial loss: 0.858481\n",
      "epoch 7; iter: 0; batch classifier loss: 0.970702; batch adversarial loss: 0.788256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.715065; batch adversarial loss: 0.762044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604850; batch adversarial loss: 0.687636\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543859; batch adversarial loss: 0.619345\n",
      "epoch 11; iter: 0; batch classifier loss: 0.451277; batch adversarial loss: 0.621643\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554757; batch adversarial loss: 0.618707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551873; batch adversarial loss: 0.604729\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554909; batch adversarial loss: 0.638193\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514964; batch adversarial loss: 0.561215\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523928; batch adversarial loss: 0.604488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535041; batch adversarial loss: 0.556130\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515104; batch adversarial loss: 0.577393\n",
      "epoch 19; iter: 0; batch classifier loss: 0.595072; batch adversarial loss: 0.621251\n",
      "epoch 20; iter: 0; batch classifier loss: 0.561955; batch adversarial loss: 0.567588\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494615; batch adversarial loss: 0.618373\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485113; batch adversarial loss: 0.586146\n",
      "epoch 23; iter: 0; batch classifier loss: 0.447336; batch adversarial loss: 0.497148\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463045; batch adversarial loss: 0.521838\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508873; batch adversarial loss: 0.551708\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510000; batch adversarial loss: 0.531040\n",
      "epoch 27; iter: 0; batch classifier loss: 0.577224; batch adversarial loss: 0.526999\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441582; batch adversarial loss: 0.545157\n",
      "epoch 29; iter: 0; batch classifier loss: 0.416286; batch adversarial loss: 0.569849\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483481; batch adversarial loss: 0.520549\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441020; batch adversarial loss: 0.593147\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460375; batch adversarial loss: 0.593746\n",
      "epoch 33; iter: 0; batch classifier loss: 0.512429; batch adversarial loss: 0.541198\n",
      "epoch 34; iter: 0; batch classifier loss: 0.519132; batch adversarial loss: 0.592711\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465377; batch adversarial loss: 0.514254\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461200; batch adversarial loss: 0.553117\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448043; batch adversarial loss: 0.556505\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438310; batch adversarial loss: 0.533898\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425620; batch adversarial loss: 0.623843\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444657; batch adversarial loss: 0.594789\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454806; batch adversarial loss: 0.559886\n",
      "epoch 42; iter: 0; batch classifier loss: 0.386142; batch adversarial loss: 0.608763\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431917; batch adversarial loss: 0.483411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.544004; batch adversarial loss: 0.548581\n",
      "epoch 45; iter: 0; batch classifier loss: 0.447760; batch adversarial loss: 0.611784\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447859; batch adversarial loss: 0.551087\n",
      "epoch 47; iter: 0; batch classifier loss: 0.502734; batch adversarial loss: 0.555950\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415423; batch adversarial loss: 0.490620\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454830; batch adversarial loss: 0.601558\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434060; batch adversarial loss: 0.541728\n",
      "epoch 51; iter: 0; batch classifier loss: 0.452132; batch adversarial loss: 0.490673\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390200; batch adversarial loss: 0.445664\n",
      "epoch 53; iter: 0; batch classifier loss: 0.435691; batch adversarial loss: 0.551389\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379462; batch adversarial loss: 0.535244\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396296; batch adversarial loss: 0.523718\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403322; batch adversarial loss: 0.540182\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395693; batch adversarial loss: 0.614985\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394898; batch adversarial loss: 0.577873\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467747; batch adversarial loss: 0.570783\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379227; batch adversarial loss: 0.650849\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449077; batch adversarial loss: 0.590308\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408415; batch adversarial loss: 0.526427\n",
      "epoch 63; iter: 0; batch classifier loss: 0.475935; batch adversarial loss: 0.597588\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385719; batch adversarial loss: 0.481816\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394198; batch adversarial loss: 0.590470\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414113; batch adversarial loss: 0.562441\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392249; batch adversarial loss: 0.508519\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375249; batch adversarial loss: 0.608282\n",
      "epoch 69; iter: 0; batch classifier loss: 0.462330; batch adversarial loss: 0.498368\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396310; batch adversarial loss: 0.533824\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409336; batch adversarial loss: 0.598352\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371610; batch adversarial loss: 0.492128\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447691; batch adversarial loss: 0.509731\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478852; batch adversarial loss: 0.614804\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407592; batch adversarial loss: 0.544974\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374157; batch adversarial loss: 0.608596\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395355; batch adversarial loss: 0.642526\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428333; batch adversarial loss: 0.508003\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453471; batch adversarial loss: 0.554412\n",
      "epoch 80; iter: 0; batch classifier loss: 0.533550; batch adversarial loss: 0.519147\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389657; batch adversarial loss: 0.580846\n",
      "epoch 82; iter: 0; batch classifier loss: 0.429072; batch adversarial loss: 0.481977\n",
      "epoch 83; iter: 0; batch classifier loss: 0.462435; batch adversarial loss: 0.588601\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435163; batch adversarial loss: 0.527668\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428411; batch adversarial loss: 0.535820\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367590; batch adversarial loss: 0.463827\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383849; batch adversarial loss: 0.535700\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420161; batch adversarial loss: 0.518833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.348179; batch adversarial loss: 0.562018\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413471; batch adversarial loss: 0.527162\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423082; batch adversarial loss: 0.545147\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414885; batch adversarial loss: 0.589362\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375361; batch adversarial loss: 0.526718\n",
      "epoch 94; iter: 0; batch classifier loss: 0.465229; batch adversarial loss: 0.607029\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358560; batch adversarial loss: 0.571443\n",
      "epoch 96; iter: 0; batch classifier loss: 0.437498; batch adversarial loss: 0.579943\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389672; batch adversarial loss: 0.518462\n",
      "epoch 98; iter: 0; batch classifier loss: 0.468641; batch adversarial loss: 0.490647\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373531; batch adversarial loss: 0.518258\n",
      "epoch 100; iter: 0; batch classifier loss: 0.497315; batch adversarial loss: 0.535638\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368104; batch adversarial loss: 0.509445\n",
      "epoch 102; iter: 0; batch classifier loss: 0.445262; batch adversarial loss: 0.499974\n",
      "epoch 103; iter: 0; batch classifier loss: 0.392712; batch adversarial loss: 0.562016\n",
      "epoch 104; iter: 0; batch classifier loss: 0.425278; batch adversarial loss: 0.517768\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337780; batch adversarial loss: 0.615509\n",
      "epoch 106; iter: 0; batch classifier loss: 0.340156; batch adversarial loss: 0.607692\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377078; batch adversarial loss: 0.562091\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351178; batch adversarial loss: 0.562265\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387473; batch adversarial loss: 0.606454\n",
      "epoch 110; iter: 0; batch classifier loss: 0.303433; batch adversarial loss: 0.616363\n",
      "epoch 111; iter: 0; batch classifier loss: 0.464889; batch adversarial loss: 0.508562\n",
      "epoch 112; iter: 0; batch classifier loss: 0.436821; batch adversarial loss: 0.562245\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383446; batch adversarial loss: 0.553508\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350466; batch adversarial loss: 0.543932\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369219; batch adversarial loss: 0.499968\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375067; batch adversarial loss: 0.571167\n",
      "epoch 117; iter: 0; batch classifier loss: 0.425003; batch adversarial loss: 0.517683\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354383; batch adversarial loss: 0.589820\n",
      "epoch 119; iter: 0; batch classifier loss: 0.332432; batch adversarial loss: 0.535791\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436221; batch adversarial loss: 0.633693\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397341; batch adversarial loss: 0.571230\n",
      "epoch 122; iter: 0; batch classifier loss: 0.329129; batch adversarial loss: 0.571500\n",
      "epoch 123; iter: 0; batch classifier loss: 0.324454; batch adversarial loss: 0.562312\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334757; batch adversarial loss: 0.473526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.477524; batch adversarial loss: 0.562561\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373284; batch adversarial loss: 0.500181\n",
      "epoch 127; iter: 0; batch classifier loss: 0.323950; batch adversarial loss: 0.544785\n",
      "epoch 128; iter: 0; batch classifier loss: 0.337348; batch adversarial loss: 0.509080\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391556; batch adversarial loss: 0.589758\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350208; batch adversarial loss: 0.571442\n",
      "epoch 131; iter: 0; batch classifier loss: 0.304637; batch adversarial loss: 0.642846\n",
      "epoch 132; iter: 0; batch classifier loss: 0.397677; batch adversarial loss: 0.598478\n",
      "epoch 133; iter: 0; batch classifier loss: 0.312534; batch adversarial loss: 0.616888\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337523; batch adversarial loss: 0.509836\n",
      "epoch 135; iter: 0; batch classifier loss: 0.396820; batch adversarial loss: 0.509684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.320581; batch adversarial loss: 0.456174\n",
      "epoch 137; iter: 0; batch classifier loss: 0.333865; batch adversarial loss: 0.518010\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357428; batch adversarial loss: 0.518118\n",
      "epoch 139; iter: 0; batch classifier loss: 0.474452; batch adversarial loss: 0.562506\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335866; batch adversarial loss: 0.508800\n",
      "epoch 141; iter: 0; batch classifier loss: 0.378524; batch adversarial loss: 0.553885\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381658; batch adversarial loss: 0.697256\n",
      "epoch 143; iter: 0; batch classifier loss: 0.434895; batch adversarial loss: 0.572591\n",
      "epoch 144; iter: 0; batch classifier loss: 0.460547; batch adversarial loss: 0.517579\n",
      "epoch 145; iter: 0; batch classifier loss: 0.440539; batch adversarial loss: 0.606649\n",
      "epoch 146; iter: 0; batch classifier loss: 0.406846; batch adversarial loss: 0.633664\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397069; batch adversarial loss: 0.545197\n",
      "epoch 148; iter: 0; batch classifier loss: 0.440682; batch adversarial loss: 0.482372\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336129; batch adversarial loss: 0.491109\n",
      "epoch 150; iter: 0; batch classifier loss: 0.324269; batch adversarial loss: 0.536019\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361671; batch adversarial loss: 0.624184\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338712; batch adversarial loss: 0.642877\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339108; batch adversarial loss: 0.536183\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390584; batch adversarial loss: 0.526803\n",
      "epoch 155; iter: 0; batch classifier loss: 0.407582; batch adversarial loss: 0.562089\n",
      "epoch 156; iter: 0; batch classifier loss: 0.471757; batch adversarial loss: 0.563021\n",
      "epoch 157; iter: 0; batch classifier loss: 0.438291; batch adversarial loss: 0.535242\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376434; batch adversarial loss: 0.553417\n",
      "epoch 159; iter: 0; batch classifier loss: 0.405537; batch adversarial loss: 0.598097\n",
      "epoch 160; iter: 0; batch classifier loss: 0.438960; batch adversarial loss: 0.651627\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330139; batch adversarial loss: 0.490601\n",
      "epoch 162; iter: 0; batch classifier loss: 0.324648; batch adversarial loss: 0.508952\n",
      "epoch 163; iter: 0; batch classifier loss: 0.390105; batch adversarial loss: 0.544677\n",
      "epoch 164; iter: 0; batch classifier loss: 0.317555; batch adversarial loss: 0.561983\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380334; batch adversarial loss: 0.616262\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324827; batch adversarial loss: 0.562554\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344227; batch adversarial loss: 0.508618\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376970; batch adversarial loss: 0.570219\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321345; batch adversarial loss: 0.580901\n",
      "epoch 170; iter: 0; batch classifier loss: 0.316640; batch adversarial loss: 0.526646\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373938; batch adversarial loss: 0.579269\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374864; batch adversarial loss: 0.581145\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324546; batch adversarial loss: 0.536341\n",
      "epoch 174; iter: 0; batch classifier loss: 0.313418; batch adversarial loss: 0.606393\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306976; batch adversarial loss: 0.544602\n",
      "epoch 176; iter: 0; batch classifier loss: 0.457466; batch adversarial loss: 0.536376\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327870; batch adversarial loss: 0.517907\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309875; batch adversarial loss: 0.553305\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329249; batch adversarial loss: 0.553572\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340922; batch adversarial loss: 0.561901\n",
      "epoch 181; iter: 0; batch classifier loss: 0.270061; batch adversarial loss: 0.473697\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357564; batch adversarial loss: 0.499972\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348610; batch adversarial loss: 0.561917\n",
      "epoch 184; iter: 0; batch classifier loss: 0.415673; batch adversarial loss: 0.553062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.383252; batch adversarial loss: 0.572578\n",
      "epoch 186; iter: 0; batch classifier loss: 0.321029; batch adversarial loss: 0.518244\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341823; batch adversarial loss: 0.508740\n",
      "epoch 188; iter: 0; batch classifier loss: 0.408715; batch adversarial loss: 0.606895\n",
      "epoch 189; iter: 0; batch classifier loss: 0.287369; batch adversarial loss: 0.517505\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338998; batch adversarial loss: 0.544334\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350129; batch adversarial loss: 0.518281\n",
      "epoch 192; iter: 0; batch classifier loss: 0.321288; batch adversarial loss: 0.562645\n",
      "epoch 193; iter: 0; batch classifier loss: 0.268387; batch adversarial loss: 0.544665\n",
      "epoch 194; iter: 0; batch classifier loss: 0.302123; batch adversarial loss: 0.465006\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382963; batch adversarial loss: 0.465278\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358766; batch adversarial loss: 0.518143\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313321; batch adversarial loss: 0.686769\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350875; batch adversarial loss: 0.571840\n",
      "epoch 199; iter: 0; batch classifier loss: 0.266080; batch adversarial loss: 0.579993\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696570; batch adversarial loss: 0.665511\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629120; batch adversarial loss: 0.657545\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587864; batch adversarial loss: 0.653093\n",
      "epoch 3; iter: 0; batch classifier loss: 0.522869; batch adversarial loss: 0.620050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.593288; batch adversarial loss: 0.624832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.606124; batch adversarial loss: 0.658794\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555229; batch adversarial loss: 0.574449\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592889; batch adversarial loss: 0.563652\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585719; batch adversarial loss: 0.658832\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563181; batch adversarial loss: 0.617537\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533346; batch adversarial loss: 0.592900\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501870; batch adversarial loss: 0.619135\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554573; batch adversarial loss: 0.565035\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560027; batch adversarial loss: 0.589930\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507288; batch adversarial loss: 0.539565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.635971; batch adversarial loss: 0.595061\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527785; batch adversarial loss: 0.586274\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542021; batch adversarial loss: 0.535713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508453; batch adversarial loss: 0.597661\n",
      "epoch 19; iter: 0; batch classifier loss: 0.573303; batch adversarial loss: 0.558268\n",
      "epoch 20; iter: 0; batch classifier loss: 0.545033; batch adversarial loss: 0.552595\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504399; batch adversarial loss: 0.563873\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456000; batch adversarial loss: 0.564116\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493801; batch adversarial loss: 0.538722\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458577; batch adversarial loss: 0.525680\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493809; batch adversarial loss: 0.506331\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464203; batch adversarial loss: 0.523258\n",
      "epoch 27; iter: 0; batch classifier loss: 0.498277; batch adversarial loss: 0.500004\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532655; batch adversarial loss: 0.541876\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496539; batch adversarial loss: 0.553293\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492560; batch adversarial loss: 0.546459\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469415; batch adversarial loss: 0.461670\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504735; batch adversarial loss: 0.589307\n",
      "epoch 33; iter: 0; batch classifier loss: 0.539026; batch adversarial loss: 0.575070\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511708; batch adversarial loss: 0.581931\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515811; batch adversarial loss: 0.573801\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481373; batch adversarial loss: 0.519371\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470791; batch adversarial loss: 0.582707\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408108; batch adversarial loss: 0.480937\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382210; batch adversarial loss: 0.544436\n",
      "epoch 40; iter: 0; batch classifier loss: 0.366199; batch adversarial loss: 0.520725\n",
      "epoch 41; iter: 0; batch classifier loss: 0.510780; batch adversarial loss: 0.605984\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438100; batch adversarial loss: 0.533438\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418724; batch adversarial loss: 0.599283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446983; batch adversarial loss: 0.538567\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419932; batch adversarial loss: 0.547020\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408547; batch adversarial loss: 0.483806\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377515; batch adversarial loss: 0.434464\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447823; batch adversarial loss: 0.588757\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474851; batch adversarial loss: 0.545532\n",
      "epoch 50; iter: 0; batch classifier loss: 0.436916; batch adversarial loss: 0.571066\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433558; batch adversarial loss: 0.658988\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407800; batch adversarial loss: 0.598077\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429685; batch adversarial loss: 0.588882\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381317; batch adversarial loss: 0.498410\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447235; batch adversarial loss: 0.563163\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385789; batch adversarial loss: 0.488341\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445788; batch adversarial loss: 0.589080\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358682; batch adversarial loss: 0.563250\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425155; batch adversarial loss: 0.554047\n",
      "epoch 60; iter: 0; batch classifier loss: 0.387272; batch adversarial loss: 0.562731\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397862; batch adversarial loss: 0.544190\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439765; batch adversarial loss: 0.644704\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395874; batch adversarial loss: 0.453211\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473742; batch adversarial loss: 0.690128\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449794; batch adversarial loss: 0.598346\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398039; batch adversarial loss: 0.599740\n",
      "epoch 67; iter: 0; batch classifier loss: 0.459544; batch adversarial loss: 0.562870\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386415; batch adversarial loss: 0.480561\n",
      "epoch 69; iter: 0; batch classifier loss: 0.354019; batch adversarial loss: 0.535196\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422693; batch adversarial loss: 0.544658\n",
      "epoch 71; iter: 0; batch classifier loss: 0.361024; batch adversarial loss: 0.515074\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390123; batch adversarial loss: 0.579702\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425921; batch adversarial loss: 0.561046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.338333; batch adversarial loss: 0.581988\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427143; batch adversarial loss: 0.436451\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366398; batch adversarial loss: 0.598497\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393415; batch adversarial loss: 0.599123\n",
      "epoch 78; iter: 0; batch classifier loss: 0.470567; batch adversarial loss: 0.544925\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372361; batch adversarial loss: 0.563323\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426506; batch adversarial loss: 0.616794\n",
      "epoch 81; iter: 0; batch classifier loss: 0.337503; batch adversarial loss: 0.535588\n",
      "epoch 82; iter: 0; batch classifier loss: 0.432272; batch adversarial loss: 0.616791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.402984; batch adversarial loss: 0.598240\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443905; batch adversarial loss: 0.569996\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377211; batch adversarial loss: 0.560764\n",
      "epoch 86; iter: 0; batch classifier loss: 0.376985; batch adversarial loss: 0.580211\n",
      "epoch 87; iter: 0; batch classifier loss: 0.328693; batch adversarial loss: 0.471372\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383175; batch adversarial loss: 0.601746\n",
      "epoch 89; iter: 0; batch classifier loss: 0.443312; batch adversarial loss: 0.508602\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425336; batch adversarial loss: 0.554044\n",
      "epoch 91; iter: 0; batch classifier loss: 0.426915; batch adversarial loss: 0.562722\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355266; batch adversarial loss: 0.553531\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349951; batch adversarial loss: 0.463776\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363791; batch adversarial loss: 0.536294\n",
      "epoch 95; iter: 0; batch classifier loss: 0.353280; batch adversarial loss: 0.590353\n",
      "epoch 96; iter: 0; batch classifier loss: 0.465176; batch adversarial loss: 0.571368\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405479; batch adversarial loss: 0.580673\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386692; batch adversarial loss: 0.573025\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385578; batch adversarial loss: 0.599599\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410419; batch adversarial loss: 0.563369\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371268; batch adversarial loss: 0.598648\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366020; batch adversarial loss: 0.563439\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358822; batch adversarial loss: 0.535665\n",
      "epoch 104; iter: 0; batch classifier loss: 0.485618; batch adversarial loss: 0.526994\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404017; batch adversarial loss: 0.562416\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372191; batch adversarial loss: 0.624988\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366331; batch adversarial loss: 0.544246\n",
      "epoch 108; iter: 0; batch classifier loss: 0.349325; batch adversarial loss: 0.526845\n",
      "epoch 109; iter: 0; batch classifier loss: 0.389484; batch adversarial loss: 0.472439\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348396; batch adversarial loss: 0.517303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368131; batch adversarial loss: 0.590340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370997; batch adversarial loss: 0.471434\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360882; batch adversarial loss: 0.488736\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389353; batch adversarial loss: 0.607920\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334138; batch adversarial loss: 0.582206\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381596; batch adversarial loss: 0.589939\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354440; batch adversarial loss: 0.597979\n",
      "epoch 118; iter: 0; batch classifier loss: 0.348638; batch adversarial loss: 0.518115\n",
      "epoch 119; iter: 0; batch classifier loss: 0.452557; batch adversarial loss: 0.553469\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340559; batch adversarial loss: 0.562634\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345624; batch adversarial loss: 0.544058\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404664; batch adversarial loss: 0.489624\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353203; batch adversarial loss: 0.544255\n",
      "epoch 124; iter: 0; batch classifier loss: 0.429164; batch adversarial loss: 0.562127\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399141; batch adversarial loss: 0.589707\n",
      "epoch 126; iter: 0; batch classifier loss: 0.352529; batch adversarial loss: 0.535975\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371176; batch adversarial loss: 0.507259\n",
      "epoch 128; iter: 0; batch classifier loss: 0.413148; batch adversarial loss: 0.535618\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346167; batch adversarial loss: 0.536977\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362557; batch adversarial loss: 0.536635\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367649; batch adversarial loss: 0.498096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.299361; batch adversarial loss: 0.582077\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377105; batch adversarial loss: 0.553705\n",
      "epoch 134; iter: 0; batch classifier loss: 0.422987; batch adversarial loss: 0.554941\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402496; batch adversarial loss: 0.563930\n",
      "epoch 136; iter: 0; batch classifier loss: 0.455304; batch adversarial loss: 0.544922\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353743; batch adversarial loss: 0.554756\n",
      "epoch 138; iter: 0; batch classifier loss: 0.354473; batch adversarial loss: 0.571945\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379423; batch adversarial loss: 0.607301\n",
      "epoch 140; iter: 0; batch classifier loss: 0.388317; batch adversarial loss: 0.589238\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358404; batch adversarial loss: 0.598790\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369442; batch adversarial loss: 0.453175\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331959; batch adversarial loss: 0.578840\n",
      "epoch 144; iter: 0; batch classifier loss: 0.305084; batch adversarial loss: 0.623499\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403677; batch adversarial loss: 0.554043\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375638; batch adversarial loss: 0.572105\n",
      "epoch 147; iter: 0; batch classifier loss: 0.296181; batch adversarial loss: 0.571432\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354331; batch adversarial loss: 0.519809\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400640; batch adversarial loss: 0.472922\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361739; batch adversarial loss: 0.499711\n",
      "epoch 151; iter: 0; batch classifier loss: 0.420645; batch adversarial loss: 0.546478\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356389; batch adversarial loss: 0.544888\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363397; batch adversarial loss: 0.642603\n",
      "epoch 154; iter: 0; batch classifier loss: 0.371880; batch adversarial loss: 0.463880\n",
      "epoch 155; iter: 0; batch classifier loss: 0.405448; batch adversarial loss: 0.517367\n",
      "epoch 156; iter: 0; batch classifier loss: 0.309296; batch adversarial loss: 0.571479\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373007; batch adversarial loss: 0.598851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.307900; batch adversarial loss: 0.562469\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329873; batch adversarial loss: 0.544403\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387494; batch adversarial loss: 0.535487\n",
      "epoch 161; iter: 0; batch classifier loss: 0.415060; batch adversarial loss: 0.499619\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376288; batch adversarial loss: 0.597961\n",
      "epoch 163; iter: 0; batch classifier loss: 0.298109; batch adversarial loss: 0.571527\n",
      "epoch 164; iter: 0; batch classifier loss: 0.382093; batch adversarial loss: 0.571550\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389666; batch adversarial loss: 0.589824\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353120; batch adversarial loss: 0.526233\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379428; batch adversarial loss: 0.598851\n",
      "epoch 168; iter: 0; batch classifier loss: 0.300157; batch adversarial loss: 0.653612\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333940; batch adversarial loss: 0.544318\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393400; batch adversarial loss: 0.481051\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344697; batch adversarial loss: 0.598942\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346146; batch adversarial loss: 0.553583\n",
      "epoch 173; iter: 0; batch classifier loss: 0.314597; batch adversarial loss: 0.508419\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347336; batch adversarial loss: 0.508470\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331064; batch adversarial loss: 0.498668\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344114; batch adversarial loss: 0.489611\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355457; batch adversarial loss: 0.544267\n",
      "epoch 178; iter: 0; batch classifier loss: 0.448889; batch adversarial loss: 0.508198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.337196; batch adversarial loss: 0.606636\n",
      "epoch 180; iter: 0; batch classifier loss: 0.380281; batch adversarial loss: 0.599061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.287679; batch adversarial loss: 0.564310\n",
      "epoch 182; iter: 0; batch classifier loss: 0.302242; batch adversarial loss: 0.554265\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351827; batch adversarial loss: 0.544531\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330826; batch adversarial loss: 0.553395\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379832; batch adversarial loss: 0.535660\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357090; batch adversarial loss: 0.517873\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326703; batch adversarial loss: 0.562605\n",
      "epoch 188; iter: 0; batch classifier loss: 0.271367; batch adversarial loss: 0.598439\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329234; batch adversarial loss: 0.535583\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369984; batch adversarial loss: 0.517590\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344924; batch adversarial loss: 0.661664\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344552; batch adversarial loss: 0.562282\n",
      "epoch 193; iter: 0; batch classifier loss: 0.324556; batch adversarial loss: 0.571151\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335870; batch adversarial loss: 0.606985\n",
      "epoch 195; iter: 0; batch classifier loss: 0.427703; batch adversarial loss: 0.607080\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315860; batch adversarial loss: 0.535970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336676; batch adversarial loss: 0.562891\n",
      "epoch 198; iter: 0; batch classifier loss: 0.267244; batch adversarial loss: 0.481534\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371297; batch adversarial loss: 0.509028\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673997; batch adversarial loss: 0.814568\n",
      "epoch 1; iter: 0; batch classifier loss: 0.810682; batch adversarial loss: 1.022020\n",
      "epoch 2; iter: 0; batch classifier loss: 1.086171; batch adversarial loss: 1.019483\n",
      "epoch 3; iter: 0; batch classifier loss: 1.094343; batch adversarial loss: 0.915987\n",
      "epoch 4; iter: 0; batch classifier loss: 0.941387; batch adversarial loss: 0.822276\n",
      "epoch 5; iter: 0; batch classifier loss: 0.951272; batch adversarial loss: 0.757419\n",
      "epoch 6; iter: 0; batch classifier loss: 0.871922; batch adversarial loss: 0.709609\n",
      "epoch 7; iter: 0; batch classifier loss: 0.666787; batch adversarial loss: 0.657653\n",
      "epoch 8; iter: 0; batch classifier loss: 0.589011; batch adversarial loss: 0.631856\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568242; batch adversarial loss: 0.597448\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538578; batch adversarial loss: 0.558358\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565720; batch adversarial loss: 0.596236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547122; batch adversarial loss: 0.591221\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534613; batch adversarial loss: 0.543480\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549635; batch adversarial loss: 0.544388\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555584; batch adversarial loss: 0.589956\n",
      "epoch 16; iter: 0; batch classifier loss: 0.565661; batch adversarial loss: 0.568700\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506735; batch adversarial loss: 0.588122\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506150; batch adversarial loss: 0.641160\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496154; batch adversarial loss: 0.587685\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436528; batch adversarial loss: 0.565480\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510834; batch adversarial loss: 0.546946\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482329; batch adversarial loss: 0.541363\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519128; batch adversarial loss: 0.536517\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512193; batch adversarial loss: 0.581987\n",
      "epoch 25; iter: 0; batch classifier loss: 0.514801; batch adversarial loss: 0.550046\n",
      "epoch 26; iter: 0; batch classifier loss: 0.634663; batch adversarial loss: 0.494156\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463407; batch adversarial loss: 0.564208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479462; batch adversarial loss: 0.620726\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433801; batch adversarial loss: 0.604223\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458020; batch adversarial loss: 0.528570\n",
      "epoch 31; iter: 0; batch classifier loss: 0.535084; batch adversarial loss: 0.554676\n",
      "epoch 32; iter: 0; batch classifier loss: 0.486421; batch adversarial loss: 0.560776\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467808; batch adversarial loss: 0.592889\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496104; batch adversarial loss: 0.515682\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484333; batch adversarial loss: 0.517228\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430888; batch adversarial loss: 0.489564\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417498; batch adversarial loss: 0.530080\n",
      "epoch 38; iter: 0; batch classifier loss: 0.411331; batch adversarial loss: 0.544747\n",
      "epoch 39; iter: 0; batch classifier loss: 0.532336; batch adversarial loss: 0.540580\n",
      "epoch 40; iter: 0; batch classifier loss: 0.550533; batch adversarial loss: 0.535779\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432486; batch adversarial loss: 0.554426\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447180; batch adversarial loss: 0.569112\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390526; batch adversarial loss: 0.577903\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439262; batch adversarial loss: 0.495403\n",
      "epoch 45; iter: 0; batch classifier loss: 0.495253; batch adversarial loss: 0.579614\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458548; batch adversarial loss: 0.539493\n",
      "epoch 47; iter: 0; batch classifier loss: 0.387024; batch adversarial loss: 0.525350\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404499; batch adversarial loss: 0.515029\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442925; batch adversarial loss: 0.590453\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408644; batch adversarial loss: 0.574314\n",
      "epoch 51; iter: 0; batch classifier loss: 0.356041; batch adversarial loss: 0.559840\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422570; batch adversarial loss: 0.508099\n",
      "epoch 53; iter: 0; batch classifier loss: 0.365255; batch adversarial loss: 0.443397\n",
      "epoch 54; iter: 0; batch classifier loss: 0.319912; batch adversarial loss: 0.499669\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407728; batch adversarial loss: 0.552524\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429265; batch adversarial loss: 0.498225\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403016; batch adversarial loss: 0.601112\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421115; batch adversarial loss: 0.526698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.403291; batch adversarial loss: 0.508156\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410320; batch adversarial loss: 0.544800\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408356; batch adversarial loss: 0.517033\n",
      "epoch 62; iter: 0; batch classifier loss: 0.330286; batch adversarial loss: 0.489435\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403467; batch adversarial loss: 0.489329\n",
      "epoch 64; iter: 0; batch classifier loss: 0.503765; batch adversarial loss: 0.534813\n",
      "epoch 65; iter: 0; batch classifier loss: 0.371441; batch adversarial loss: 0.572342\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397175; batch adversarial loss: 0.610469\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410778; batch adversarial loss: 0.535647\n",
      "epoch 68; iter: 0; batch classifier loss: 0.366015; batch adversarial loss: 0.497353\n",
      "epoch 69; iter: 0; batch classifier loss: 0.470917; batch adversarial loss: 0.525921\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408013; batch adversarial loss: 0.554766\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389637; batch adversarial loss: 0.461257\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427608; batch adversarial loss: 0.592974\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353093; batch adversarial loss: 0.496478\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405337; batch adversarial loss: 0.469146\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386755; batch adversarial loss: 0.534556\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390483; batch adversarial loss: 0.599970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.451197; batch adversarial loss: 0.478462\n",
      "epoch 78; iter: 0; batch classifier loss: 0.333368; batch adversarial loss: 0.515971\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394103; batch adversarial loss: 0.544035\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356930; batch adversarial loss: 0.612112\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371340; batch adversarial loss: 0.555340\n",
      "epoch 82; iter: 0; batch classifier loss: 0.335245; batch adversarial loss: 0.570765\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406625; batch adversarial loss: 0.544491\n",
      "epoch 84; iter: 0; batch classifier loss: 0.314661; batch adversarial loss: 0.573186\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396217; batch adversarial loss: 0.612300\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377411; batch adversarial loss: 0.533981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377964; batch adversarial loss: 0.565408\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374549; batch adversarial loss: 0.555429\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368768; batch adversarial loss: 0.546001\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413051; batch adversarial loss: 0.543575\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419204; batch adversarial loss: 0.618681\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413278; batch adversarial loss: 0.573129\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359424; batch adversarial loss: 0.562623\n",
      "epoch 94; iter: 0; batch classifier loss: 0.409156; batch adversarial loss: 0.526135\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357490; batch adversarial loss: 0.535424\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394062; batch adversarial loss: 0.553955\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390435; batch adversarial loss: 0.489442\n",
      "epoch 98; iter: 0; batch classifier loss: 0.333917; batch adversarial loss: 0.487595\n",
      "epoch 99; iter: 0; batch classifier loss: 0.353263; batch adversarial loss: 0.498270\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346397; batch adversarial loss: 0.489893\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414761; batch adversarial loss: 0.609297\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412282; batch adversarial loss: 0.542352\n",
      "epoch 103; iter: 0; batch classifier loss: 0.433819; batch adversarial loss: 0.616414\n",
      "epoch 104; iter: 0; batch classifier loss: 0.381111; batch adversarial loss: 0.611662\n",
      "epoch 105; iter: 0; batch classifier loss: 0.335622; batch adversarial loss: 0.505608\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379203; batch adversarial loss: 0.478503\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404795; batch adversarial loss: 0.534029\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403344; batch adversarial loss: 0.494488\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419375; batch adversarial loss: 0.542970\n",
      "epoch 110; iter: 0; batch classifier loss: 0.318626; batch adversarial loss: 0.506228\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348732; batch adversarial loss: 0.480397\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397490; batch adversarial loss: 0.551354\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373683; batch adversarial loss: 0.607343\n",
      "epoch 114; iter: 0; batch classifier loss: 0.322483; batch adversarial loss: 0.523954\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363828; batch adversarial loss: 0.625286\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350426; batch adversarial loss: 0.554825\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368775; batch adversarial loss: 0.563232\n",
      "epoch 118; iter: 0; batch classifier loss: 0.281499; batch adversarial loss: 0.571001\n",
      "epoch 119; iter: 0; batch classifier loss: 0.460713; batch adversarial loss: 0.508307\n",
      "epoch 120; iter: 0; batch classifier loss: 0.286896; batch adversarial loss: 0.515751\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351363; batch adversarial loss: 0.550254\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361895; batch adversarial loss: 0.489589\n",
      "epoch 123; iter: 0; batch classifier loss: 0.278787; batch adversarial loss: 0.561434\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373337; batch adversarial loss: 0.573553\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350362; batch adversarial loss: 0.514422\n",
      "epoch 126; iter: 0; batch classifier loss: 0.415729; batch adversarial loss: 0.515389\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384097; batch adversarial loss: 0.524183\n",
      "epoch 128; iter: 0; batch classifier loss: 0.393464; batch adversarial loss: 0.515047\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364046; batch adversarial loss: 0.573391\n",
      "epoch 130; iter: 0; batch classifier loss: 0.330023; batch adversarial loss: 0.515450\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359780; batch adversarial loss: 0.484690\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375763; batch adversarial loss: 0.488463\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379917; batch adversarial loss: 0.498266\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391606; batch adversarial loss: 0.526646\n",
      "epoch 135; iter: 0; batch classifier loss: 0.445645; batch adversarial loss: 0.534224\n",
      "epoch 136; iter: 0; batch classifier loss: 0.362514; batch adversarial loss: 0.497579\n",
      "epoch 137; iter: 0; batch classifier loss: 0.338213; batch adversarial loss: 0.562810\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358495; batch adversarial loss: 0.574606\n",
      "epoch 139; iter: 0; batch classifier loss: 0.310634; batch adversarial loss: 0.565990\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419147; batch adversarial loss: 0.524477\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353371; batch adversarial loss: 0.450926\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318966; batch adversarial loss: 0.514202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.362596; batch adversarial loss: 0.571144\n",
      "epoch 144; iter: 0; batch classifier loss: 0.317443; batch adversarial loss: 0.496732\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350559; batch adversarial loss: 0.494025\n",
      "epoch 146; iter: 0; batch classifier loss: 0.362088; batch adversarial loss: 0.668122\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373819; batch adversarial loss: 0.581462\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350500; batch adversarial loss: 0.527414\n",
      "epoch 149; iter: 0; batch classifier loss: 0.327572; batch adversarial loss: 0.596556\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320701; batch adversarial loss: 0.588771\n",
      "epoch 151; iter: 0; batch classifier loss: 0.333214; batch adversarial loss: 0.524934\n",
      "epoch 152; iter: 0; batch classifier loss: 0.291425; batch adversarial loss: 0.497869\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364144; batch adversarial loss: 0.582489\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374977; batch adversarial loss: 0.487758\n",
      "epoch 155; iter: 0; batch classifier loss: 0.277551; batch adversarial loss: 0.553622\n",
      "epoch 156; iter: 0; batch classifier loss: 0.292542; batch adversarial loss: 0.523994\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334642; batch adversarial loss: 0.601033\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344347; batch adversarial loss: 0.534417\n",
      "epoch 159; iter: 0; batch classifier loss: 0.275674; batch adversarial loss: 0.584032\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340038; batch adversarial loss: 0.553697\n",
      "epoch 161; iter: 0; batch classifier loss: 0.317309; batch adversarial loss: 0.527449\n",
      "epoch 162; iter: 0; batch classifier loss: 0.299064; batch adversarial loss: 0.553083\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341020; batch adversarial loss: 0.526561\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305821; batch adversarial loss: 0.543258\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339320; batch adversarial loss: 0.525299\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329017; batch adversarial loss: 0.547323\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340456; batch adversarial loss: 0.488576\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332099; batch adversarial loss: 0.542454\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356374; batch adversarial loss: 0.517078\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344306; batch adversarial loss: 0.534139\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317001; batch adversarial loss: 0.576411\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346927; batch adversarial loss: 0.543969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.307393; batch adversarial loss: 0.620454\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341680; batch adversarial loss: 0.450026\n",
      "epoch 175; iter: 0; batch classifier loss: 0.309453; batch adversarial loss: 0.468448\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360040; batch adversarial loss: 0.543299\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336864; batch adversarial loss: 0.543144\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395330; batch adversarial loss: 0.518417\n",
      "epoch 179; iter: 0; batch classifier loss: 0.328407; batch adversarial loss: 0.514845\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360352; batch adversarial loss: 0.518340\n",
      "epoch 181; iter: 0; batch classifier loss: 0.458779; batch adversarial loss: 0.600409\n",
      "epoch 182; iter: 0; batch classifier loss: 0.238182; batch adversarial loss: 0.592884\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337586; batch adversarial loss: 0.522914\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348335; batch adversarial loss: 0.532036\n",
      "epoch 185; iter: 0; batch classifier loss: 0.324160; batch adversarial loss: 0.544636\n",
      "epoch 186; iter: 0; batch classifier loss: 0.289663; batch adversarial loss: 0.579272\n",
      "epoch 187; iter: 0; batch classifier loss: 0.286251; batch adversarial loss: 0.488514\n",
      "epoch 188; iter: 0; batch classifier loss: 0.309733; batch adversarial loss: 0.524478\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346645; batch adversarial loss: 0.525206\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344110; batch adversarial loss: 0.579991\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340819; batch adversarial loss: 0.648290\n",
      "epoch 192; iter: 0; batch classifier loss: 0.278898; batch adversarial loss: 0.591657\n",
      "epoch 193; iter: 0; batch classifier loss: 0.281451; batch adversarial loss: 0.600146\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312513; batch adversarial loss: 0.544764\n",
      "epoch 195; iter: 0; batch classifier loss: 0.429257; batch adversarial loss: 0.469561\n",
      "epoch 196; iter: 0; batch classifier loss: 0.242261; batch adversarial loss: 0.504741\n",
      "epoch 197; iter: 0; batch classifier loss: 0.338543; batch adversarial loss: 0.591605\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363608; batch adversarial loss: 0.480507\n",
      "epoch 199; iter: 0; batch classifier loss: 0.377216; batch adversarial loss: 0.531655\n",
      "epoch 0; iter: 0; batch classifier loss: 0.755569; batch adversarial loss: 0.810652\n",
      "epoch 1; iter: 0; batch classifier loss: 0.796179; batch adversarial loss: 0.890091\n",
      "epoch 2; iter: 0; batch classifier loss: 0.972235; batch adversarial loss: 0.850597\n",
      "epoch 3; iter: 0; batch classifier loss: 0.922550; batch adversarial loss: 0.760549\n",
      "epoch 4; iter: 0; batch classifier loss: 0.764900; batch adversarial loss: 0.695020\n",
      "epoch 5; iter: 0; batch classifier loss: 0.705184; batch adversarial loss: 0.647086\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568061; batch adversarial loss: 0.600579\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519989; batch adversarial loss: 0.598413\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570150; batch adversarial loss: 0.582686\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554852; batch adversarial loss: 0.556710\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541617; batch adversarial loss: 0.581047\n",
      "epoch 11; iter: 0; batch classifier loss: 0.594441; batch adversarial loss: 0.601193\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560296; batch adversarial loss: 0.552335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.468728; batch adversarial loss: 0.548508\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519305; batch adversarial loss: 0.597298\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498626; batch adversarial loss: 0.602696\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505812; batch adversarial loss: 0.545221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552446; batch adversarial loss: 0.541697\n",
      "epoch 18; iter: 0; batch classifier loss: 0.599888; batch adversarial loss: 0.585220\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532251; batch adversarial loss: 0.580097\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502814; batch adversarial loss: 0.587388\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491050; batch adversarial loss: 0.491664\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525947; batch adversarial loss: 0.510423\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456225; batch adversarial loss: 0.600458\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514891; batch adversarial loss: 0.522401\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476625; batch adversarial loss: 0.590870\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486361; batch adversarial loss: 0.576917\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517100; batch adversarial loss: 0.575121\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480980; batch adversarial loss: 0.495991\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461953; batch adversarial loss: 0.574320\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483347; batch adversarial loss: 0.576212\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505021; batch adversarial loss: 0.569424\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472860; batch adversarial loss: 0.528754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.436498; batch adversarial loss: 0.577656\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473384; batch adversarial loss: 0.536617\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503911; batch adversarial loss: 0.538880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502795; batch adversarial loss: 0.490483\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424846; batch adversarial loss: 0.503076\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441960; batch adversarial loss: 0.539140\n",
      "epoch 39; iter: 0; batch classifier loss: 0.381932; batch adversarial loss: 0.654836\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422358; batch adversarial loss: 0.566791\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437075; batch adversarial loss: 0.668682\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459687; batch adversarial loss: 0.501822\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422457; batch adversarial loss: 0.553864\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425407; batch adversarial loss: 0.535579\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420604; batch adversarial loss: 0.454152\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500854; batch adversarial loss: 0.472775\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421060; batch adversarial loss: 0.526872\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396235; batch adversarial loss: 0.581065\n",
      "epoch 49; iter: 0; batch classifier loss: 0.547590; batch adversarial loss: 0.553465\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453211; batch adversarial loss: 0.526388\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462889; batch adversarial loss: 0.463425\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437698; batch adversarial loss: 0.587844\n",
      "epoch 53; iter: 0; batch classifier loss: 0.482104; batch adversarial loss: 0.543387\n",
      "epoch 54; iter: 0; batch classifier loss: 0.372203; batch adversarial loss: 0.606471\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486585; batch adversarial loss: 0.576262\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415686; batch adversarial loss: 0.553463\n",
      "epoch 57; iter: 0; batch classifier loss: 0.365121; batch adversarial loss: 0.496595\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430483; batch adversarial loss: 0.460408\n",
      "epoch 59; iter: 0; batch classifier loss: 0.469483; batch adversarial loss: 0.546738\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421696; batch adversarial loss: 0.526436\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432803; batch adversarial loss: 0.533119\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450978; batch adversarial loss: 0.549534\n",
      "epoch 63; iter: 0; batch classifier loss: 0.364220; batch adversarial loss: 0.567315\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375691; batch adversarial loss: 0.640904\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400280; batch adversarial loss: 0.563093\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410381; batch adversarial loss: 0.504969\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384154; batch adversarial loss: 0.555622\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390912; batch adversarial loss: 0.533267\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406446; batch adversarial loss: 0.468145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.428191; batch adversarial loss: 0.555155\n",
      "epoch 71; iter: 0; batch classifier loss: 0.439855; batch adversarial loss: 0.553808\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358556; batch adversarial loss: 0.584311\n",
      "epoch 73; iter: 0; batch classifier loss: 0.338537; batch adversarial loss: 0.522722\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396890; batch adversarial loss: 0.534995\n",
      "epoch 75; iter: 0; batch classifier loss: 0.468704; batch adversarial loss: 0.608966\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387735; batch adversarial loss: 0.480532\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421981; batch adversarial loss: 0.618541\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389192; batch adversarial loss: 0.571240\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343506; batch adversarial loss: 0.497219\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427454; batch adversarial loss: 0.521876\n",
      "epoch 81; iter: 0; batch classifier loss: 0.317084; batch adversarial loss: 0.551244\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348405; batch adversarial loss: 0.629983\n",
      "epoch 83; iter: 0; batch classifier loss: 0.454570; batch adversarial loss: 0.550496\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431409; batch adversarial loss: 0.495771\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392388; batch adversarial loss: 0.566776\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365599; batch adversarial loss: 0.547211\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418027; batch adversarial loss: 0.595021\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423279; batch adversarial loss: 0.515404\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403258; batch adversarial loss: 0.608402\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392025; batch adversarial loss: 0.463320\n",
      "epoch 91; iter: 0; batch classifier loss: 0.298952; batch adversarial loss: 0.516279\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375879; batch adversarial loss: 0.498472\n",
      "epoch 93; iter: 0; batch classifier loss: 0.434446; batch adversarial loss: 0.506581\n",
      "epoch 94; iter: 0; batch classifier loss: 0.491197; batch adversarial loss: 0.643716\n",
      "epoch 95; iter: 0; batch classifier loss: 0.434473; batch adversarial loss: 0.498821\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388179; batch adversarial loss: 0.559662\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346036; batch adversarial loss: 0.516863\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387844; batch adversarial loss: 0.584574\n",
      "epoch 99; iter: 0; batch classifier loss: 0.465238; batch adversarial loss: 0.509724\n",
      "epoch 100; iter: 0; batch classifier loss: 0.313603; batch adversarial loss: 0.441855\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382667; batch adversarial loss: 0.542294\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435018; batch adversarial loss: 0.564414\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378550; batch adversarial loss: 0.523693\n",
      "epoch 104; iter: 0; batch classifier loss: 0.322316; batch adversarial loss: 0.505128\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401011; batch adversarial loss: 0.582001\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330206; batch adversarial loss: 0.574729\n",
      "epoch 107; iter: 0; batch classifier loss: 0.332679; batch adversarial loss: 0.563454\n",
      "epoch 108; iter: 0; batch classifier loss: 0.304982; batch adversarial loss: 0.517543\n",
      "epoch 109; iter: 0; batch classifier loss: 0.378810; batch adversarial loss: 0.666482\n",
      "epoch 110; iter: 0; batch classifier loss: 0.337349; batch adversarial loss: 0.555825\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355979; batch adversarial loss: 0.573457\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390131; batch adversarial loss: 0.581570\n",
      "epoch 113; iter: 0; batch classifier loss: 0.336399; batch adversarial loss: 0.563863\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377126; batch adversarial loss: 0.469941\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336088; batch adversarial loss: 0.596273\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356590; batch adversarial loss: 0.432805\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392102; batch adversarial loss: 0.503804\n",
      "epoch 118; iter: 0; batch classifier loss: 0.291386; batch adversarial loss: 0.566440\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347310; batch adversarial loss: 0.528143\n",
      "epoch 120; iter: 0; batch classifier loss: 0.445534; batch adversarial loss: 0.506438\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387277; batch adversarial loss: 0.548143\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351191; batch adversarial loss: 0.563681\n",
      "epoch 123; iter: 0; batch classifier loss: 0.374202; batch adversarial loss: 0.440490\n",
      "epoch 124; iter: 0; batch classifier loss: 0.425643; batch adversarial loss: 0.552730\n",
      "epoch 125; iter: 0; batch classifier loss: 0.306701; batch adversarial loss: 0.548910\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348762; batch adversarial loss: 0.572041\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330012; batch adversarial loss: 0.606747\n",
      "epoch 128; iter: 0; batch classifier loss: 0.335220; batch adversarial loss: 0.466859\n",
      "epoch 129; iter: 0; batch classifier loss: 0.321280; batch adversarial loss: 0.514266\n",
      "epoch 130; iter: 0; batch classifier loss: 0.289049; batch adversarial loss: 0.541193\n",
      "epoch 131; iter: 0; batch classifier loss: 0.410049; batch adversarial loss: 0.534970\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310243; batch adversarial loss: 0.532593\n",
      "epoch 133; iter: 0; batch classifier loss: 0.296764; batch adversarial loss: 0.541378\n",
      "epoch 134; iter: 0; batch classifier loss: 0.359748; batch adversarial loss: 0.470161\n",
      "epoch 135; iter: 0; batch classifier loss: 0.404401; batch adversarial loss: 0.636188\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365809; batch adversarial loss: 0.498316\n",
      "epoch 137; iter: 0; batch classifier loss: 0.387972; batch adversarial loss: 0.610363\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355970; batch adversarial loss: 0.568700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342002; batch adversarial loss: 0.468041\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335338; batch adversarial loss: 0.590133\n",
      "epoch 141; iter: 0; batch classifier loss: 0.479414; batch adversarial loss: 0.545614\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347454; batch adversarial loss: 0.494221\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375566; batch adversarial loss: 0.533909\n",
      "epoch 144; iter: 0; batch classifier loss: 0.364343; batch adversarial loss: 0.494275\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348735; batch adversarial loss: 0.479065\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394898; batch adversarial loss: 0.535664\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360591; batch adversarial loss: 0.528950\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323136; batch adversarial loss: 0.507310\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353160; batch adversarial loss: 0.565480\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351943; batch adversarial loss: 0.549292\n",
      "epoch 151; iter: 0; batch classifier loss: 0.434998; batch adversarial loss: 0.566044\n",
      "epoch 152; iter: 0; batch classifier loss: 0.270352; batch adversarial loss: 0.596822\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345549; batch adversarial loss: 0.533786\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366834; batch adversarial loss: 0.510638\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374453; batch adversarial loss: 0.480746\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395339; batch adversarial loss: 0.490358\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409816; batch adversarial loss: 0.579893\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355632; batch adversarial loss: 0.566462\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333395; batch adversarial loss: 0.547262\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327326; batch adversarial loss: 0.570351\n",
      "epoch 161; iter: 0; batch classifier loss: 0.313428; batch adversarial loss: 0.515033\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379808; batch adversarial loss: 0.508926\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397389; batch adversarial loss: 0.452022\n",
      "epoch 164; iter: 0; batch classifier loss: 0.370763; batch adversarial loss: 0.555762\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330518; batch adversarial loss: 0.534494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.418085; batch adversarial loss: 0.478227\n",
      "epoch 167; iter: 0; batch classifier loss: 0.317048; batch adversarial loss: 0.483290\n",
      "epoch 168; iter: 0; batch classifier loss: 0.374847; batch adversarial loss: 0.551344\n",
      "epoch 169; iter: 0; batch classifier loss: 0.261023; batch adversarial loss: 0.544000\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360985; batch adversarial loss: 0.475321\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353769; batch adversarial loss: 0.454111\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385760; batch adversarial loss: 0.539125\n",
      "epoch 173; iter: 0; batch classifier loss: 0.312658; batch adversarial loss: 0.470685\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394839; batch adversarial loss: 0.516059\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336337; batch adversarial loss: 0.624035\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328306; batch adversarial loss: 0.578294\n",
      "epoch 177; iter: 0; batch classifier loss: 0.359077; batch adversarial loss: 0.556189\n",
      "epoch 178; iter: 0; batch classifier loss: 0.406339; batch adversarial loss: 0.535578\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322648; batch adversarial loss: 0.591104\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340786; batch adversarial loss: 0.536225\n",
      "epoch 181; iter: 0; batch classifier loss: 0.291871; batch adversarial loss: 0.562418\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370826; batch adversarial loss: 0.647396\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332249; batch adversarial loss: 0.537296\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359622; batch adversarial loss: 0.564442\n",
      "epoch 185; iter: 0; batch classifier loss: 0.404779; batch adversarial loss: 0.552337\n",
      "epoch 186; iter: 0; batch classifier loss: 0.277669; batch adversarial loss: 0.580872\n",
      "epoch 187; iter: 0; batch classifier loss: 0.397267; batch adversarial loss: 0.542008\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362496; batch adversarial loss: 0.556902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397321; batch adversarial loss: 0.512322\n",
      "epoch 190; iter: 0; batch classifier loss: 0.399603; batch adversarial loss: 0.559535\n",
      "epoch 191; iter: 0; batch classifier loss: 0.275838; batch adversarial loss: 0.511843\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318819; batch adversarial loss: 0.444003\n",
      "epoch 193; iter: 0; batch classifier loss: 0.328537; batch adversarial loss: 0.486323\n",
      "epoch 194; iter: 0; batch classifier loss: 0.444184; batch adversarial loss: 0.591261\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327190; batch adversarial loss: 0.536000\n",
      "epoch 196; iter: 0; batch classifier loss: 0.249306; batch adversarial loss: 0.558660\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317524; batch adversarial loss: 0.579143\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387916; batch adversarial loss: 0.474804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381614; batch adversarial loss: 0.536965\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681238; batch adversarial loss: 0.683157\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600040; batch adversarial loss: 0.646152\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562097; batch adversarial loss: 0.616450\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621165; batch adversarial loss: 0.587611\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529784; batch adversarial loss: 0.611225\n",
      "epoch 5; iter: 0; batch classifier loss: 0.498324; batch adversarial loss: 0.620536\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578279; batch adversarial loss: 0.585574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523075; batch adversarial loss: 0.608394\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534312; batch adversarial loss: 0.610357\n",
      "epoch 9; iter: 0; batch classifier loss: 0.632021; batch adversarial loss: 0.556398\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472547; batch adversarial loss: 0.641960\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538778; batch adversarial loss: 0.576909\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539832; batch adversarial loss: 0.608127\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509586; batch adversarial loss: 0.627205\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534176; batch adversarial loss: 0.576487\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489832; batch adversarial loss: 0.571604\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554866; batch adversarial loss: 0.570874\n",
      "epoch 17; iter: 0; batch classifier loss: 0.572192; batch adversarial loss: 0.604331\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525870; batch adversarial loss: 0.504514\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470157; batch adversarial loss: 0.578885\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465934; batch adversarial loss: 0.604870\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504529; batch adversarial loss: 0.586988\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503824; batch adversarial loss: 0.557342\n",
      "epoch 23; iter: 0; batch classifier loss: 0.587547; batch adversarial loss: 0.569501\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505480; batch adversarial loss: 0.559068\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500522; batch adversarial loss: 0.537690\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472291; batch adversarial loss: 0.535063\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461251; batch adversarial loss: 0.523163\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499283; batch adversarial loss: 0.530238\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465027; batch adversarial loss: 0.632978\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482987; batch adversarial loss: 0.598824\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416837; batch adversarial loss: 0.555185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442838; batch adversarial loss: 0.555443\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408404; batch adversarial loss: 0.519346\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408881; batch adversarial loss: 0.537267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.533528; batch adversarial loss: 0.554919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.542242; batch adversarial loss: 0.588030\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454529; batch adversarial loss: 0.616298\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432121; batch adversarial loss: 0.545382\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451378; batch adversarial loss: 0.597774\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423245; batch adversarial loss: 0.570737\n",
      "epoch 41; iter: 0; batch classifier loss: 0.551087; batch adversarial loss: 0.607610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.504560; batch adversarial loss: 0.572484\n",
      "epoch 43; iter: 0; batch classifier loss: 0.417605; batch adversarial loss: 0.580890\n",
      "epoch 44; iter: 0; batch classifier loss: 0.498392; batch adversarial loss: 0.518166\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458480; batch adversarial loss: 0.579426\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374265; batch adversarial loss: 0.543853\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426554; batch adversarial loss: 0.500654\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436588; batch adversarial loss: 0.526363\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440066; batch adversarial loss: 0.652224\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438579; batch adversarial loss: 0.563195\n",
      "epoch 51; iter: 0; batch classifier loss: 0.388915; batch adversarial loss: 0.625776\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415929; batch adversarial loss: 0.562299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.495434; batch adversarial loss: 0.580516\n",
      "epoch 54; iter: 0; batch classifier loss: 0.363993; batch adversarial loss: 0.544029\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411490; batch adversarial loss: 0.544947\n",
      "epoch 56; iter: 0; batch classifier loss: 0.479750; batch adversarial loss: 0.481683\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428509; batch adversarial loss: 0.590019\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456551; batch adversarial loss: 0.599184\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417931; batch adversarial loss: 0.616850\n",
      "epoch 60; iter: 0; batch classifier loss: 0.497013; batch adversarial loss: 0.517413\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413234; batch adversarial loss: 0.498913\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445971; batch adversarial loss: 0.535460\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435422; batch adversarial loss: 0.508153\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457454; batch adversarial loss: 0.572213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.453625; batch adversarial loss: 0.562913\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422887; batch adversarial loss: 0.553617\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380928; batch adversarial loss: 0.526055\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460113; batch adversarial loss: 0.571975\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375486; batch adversarial loss: 0.653235\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433163; batch adversarial loss: 0.599054\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420380; batch adversarial loss: 0.444437\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408446; batch adversarial loss: 0.499101\n",
      "epoch 73; iter: 0; batch classifier loss: 0.365812; batch adversarial loss: 0.535371\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441291; batch adversarial loss: 0.572011\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382696; batch adversarial loss: 0.544594\n",
      "epoch 76; iter: 0; batch classifier loss: 0.497607; batch adversarial loss: 0.481318\n",
      "epoch 77; iter: 0; batch classifier loss: 0.451331; batch adversarial loss: 0.499822\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419287; batch adversarial loss: 0.580471\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428747; batch adversarial loss: 0.571802\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387639; batch adversarial loss: 0.562824\n",
      "epoch 81; iter: 0; batch classifier loss: 0.538679; batch adversarial loss: 0.526239\n",
      "epoch 82; iter: 0; batch classifier loss: 0.360610; batch adversarial loss: 0.526287\n",
      "epoch 83; iter: 0; batch classifier loss: 0.363330; batch adversarial loss: 0.599324\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386686; batch adversarial loss: 0.553475\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428095; batch adversarial loss: 0.488410\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353231; batch adversarial loss: 0.552997\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360646; batch adversarial loss: 0.525757\n",
      "epoch 88; iter: 0; batch classifier loss: 0.324852; batch adversarial loss: 0.554165\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.627083\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417474; batch adversarial loss: 0.544924\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452769; batch adversarial loss: 0.554077\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390574; batch adversarial loss: 0.580078\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386608; batch adversarial loss: 0.508407\n",
      "epoch 94; iter: 0; batch classifier loss: 0.335904; batch adversarial loss: 0.571381\n",
      "epoch 95; iter: 0; batch classifier loss: 0.355365; batch adversarial loss: 0.625977\n",
      "epoch 96; iter: 0; batch classifier loss: 0.348254; batch adversarial loss: 0.580070\n",
      "epoch 97; iter: 0; batch classifier loss: 0.448444; batch adversarial loss: 0.489832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.502029; batch adversarial loss: 0.526554\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365424; batch adversarial loss: 0.626078\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415658; batch adversarial loss: 0.616995\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384758; batch adversarial loss: 0.498843\n",
      "epoch 102; iter: 0; batch classifier loss: 0.420119; batch adversarial loss: 0.607806\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352533; batch adversarial loss: 0.571357\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415375; batch adversarial loss: 0.489371\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340539; batch adversarial loss: 0.516992\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352266; batch adversarial loss: 0.581325\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379204; batch adversarial loss: 0.545361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.447812; batch adversarial loss: 0.481092\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369275; batch adversarial loss: 0.561464\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389277; batch adversarial loss: 0.590862\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415032; batch adversarial loss: 0.617892\n",
      "epoch 112; iter: 0; batch classifier loss: 0.317781; batch adversarial loss: 0.591426\n",
      "epoch 113; iter: 0; batch classifier loss: 0.341977; batch adversarial loss: 0.508256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362946; batch adversarial loss: 0.563160\n",
      "epoch 115; iter: 0; batch classifier loss: 0.439795; batch adversarial loss: 0.554251\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390787; batch adversarial loss: 0.519472\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401587; batch adversarial loss: 0.479755\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343270; batch adversarial loss: 0.535699\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334090; batch adversarial loss: 0.526257\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374344; batch adversarial loss: 0.626226\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391829; batch adversarial loss: 0.543845\n",
      "epoch 122; iter: 0; batch classifier loss: 0.317150; batch adversarial loss: 0.572016\n",
      "epoch 123; iter: 0; batch classifier loss: 0.324070; batch adversarial loss: 0.536221\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387283; batch adversarial loss: 0.534714\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409456; batch adversarial loss: 0.563324\n",
      "epoch 126; iter: 0; batch classifier loss: 0.430138; batch adversarial loss: 0.581480\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360331; batch adversarial loss: 0.579926\n",
      "epoch 128; iter: 0; batch classifier loss: 0.417874; batch adversarial loss: 0.526936\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402162; batch adversarial loss: 0.562255\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414178; batch adversarial loss: 0.526256\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348206; batch adversarial loss: 0.599318\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403887; batch adversarial loss: 0.525754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402269; batch adversarial loss: 0.499401\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390653; batch adversarial loss: 0.553718\n",
      "epoch 135; iter: 0; batch classifier loss: 0.446214; batch adversarial loss: 0.555278\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363562; batch adversarial loss: 0.599177\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366854; batch adversarial loss: 0.590137\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386225; batch adversarial loss: 0.598824\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347513; batch adversarial loss: 0.435417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391532; batch adversarial loss: 0.525433\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353796; batch adversarial loss: 0.526033\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391335; batch adversarial loss: 0.524294\n",
      "epoch 143; iter: 0; batch classifier loss: 0.462414; batch adversarial loss: 0.546151\n",
      "epoch 144; iter: 0; batch classifier loss: 0.375884; batch adversarial loss: 0.581871\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363597; batch adversarial loss: 0.563632\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363871; batch adversarial loss: 0.562518\n",
      "epoch 147; iter: 0; batch classifier loss: 0.254634; batch adversarial loss: 0.528095\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353485; batch adversarial loss: 0.626432\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342488; batch adversarial loss: 0.580649\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391358; batch adversarial loss: 0.537038\n",
      "epoch 151; iter: 0; batch classifier loss: 0.448007; batch adversarial loss: 0.508813\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405882; batch adversarial loss: 0.480820\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387014; batch adversarial loss: 0.524760\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393681; batch adversarial loss: 0.548027\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.553466\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344540; batch adversarial loss: 0.570856\n",
      "epoch 157; iter: 0; batch classifier loss: 0.421863; batch adversarial loss: 0.516304\n",
      "epoch 158; iter: 0; batch classifier loss: 0.414861; batch adversarial loss: 0.552553\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380918; batch adversarial loss: 0.545767\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337806; batch adversarial loss: 0.544807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.405858; batch adversarial loss: 0.489442\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410368; batch adversarial loss: 0.534714\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350522; batch adversarial loss: 0.536648\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375156; batch adversarial loss: 0.544851\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351292; batch adversarial loss: 0.497874\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373886; batch adversarial loss: 0.473208\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343668; batch adversarial loss: 0.525717\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377663; batch adversarial loss: 0.532056\n",
      "epoch 169; iter: 0; batch classifier loss: 0.279427; batch adversarial loss: 0.572211\n",
      "epoch 170; iter: 0; batch classifier loss: 0.392507; batch adversarial loss: 0.607525\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355458; batch adversarial loss: 0.498425\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343062; batch adversarial loss: 0.508727\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403652; batch adversarial loss: 0.556869\n",
      "epoch 174; iter: 0; batch classifier loss: 0.466542; batch adversarial loss: 0.544848\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369185; batch adversarial loss: 0.587489\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334006; batch adversarial loss: 0.498344\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375782; batch adversarial loss: 0.554096\n",
      "epoch 178; iter: 0; batch classifier loss: 0.444339; batch adversarial loss: 0.564788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366837; batch adversarial loss: 0.545011\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386126; batch adversarial loss: 0.459062\n",
      "epoch 181; iter: 0; batch classifier loss: 0.326146; batch adversarial loss: 0.564368\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338513; batch adversarial loss: 0.562271\n",
      "epoch 183; iter: 0; batch classifier loss: 0.454221; batch adversarial loss: 0.544694\n",
      "epoch 184; iter: 0; batch classifier loss: 0.408460; batch adversarial loss: 0.571464\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378222; batch adversarial loss: 0.565230\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367452; batch adversarial loss: 0.535935\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368421; batch adversarial loss: 0.572510\n",
      "epoch 188; iter: 0; batch classifier loss: 0.393307; batch adversarial loss: 0.554312\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375011; batch adversarial loss: 0.534760\n",
      "epoch 190; iter: 0; batch classifier loss: 0.381485; batch adversarial loss: 0.500049\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359472; batch adversarial loss: 0.525473\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334584; batch adversarial loss: 0.589146\n",
      "epoch 193; iter: 0; batch classifier loss: 0.396639; batch adversarial loss: 0.517529\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343243; batch adversarial loss: 0.589683\n",
      "epoch 195; iter: 0; batch classifier loss: 0.377059; batch adversarial loss: 0.546259\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392118; batch adversarial loss: 0.518046\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381726; batch adversarial loss: 0.553665\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382951; batch adversarial loss: 0.591099\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367777; batch adversarial loss: 0.525125\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694104; batch adversarial loss: 0.641755\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643191; batch adversarial loss: 0.657071\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586728; batch adversarial loss: 0.611657\n",
      "epoch 3; iter: 0; batch classifier loss: 0.606720; batch adversarial loss: 0.626690\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529661; batch adversarial loss: 0.635402\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537352; batch adversarial loss: 0.598300\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576066; batch adversarial loss: 0.671124\n",
      "epoch 7; iter: 0; batch classifier loss: 0.466614; batch adversarial loss: 0.595675\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547637; batch adversarial loss: 0.626271\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522513; batch adversarial loss: 0.586734\n",
      "epoch 10; iter: 0; batch classifier loss: 0.603420; batch adversarial loss: 0.565619\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532853; batch adversarial loss: 0.527846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469679; batch adversarial loss: 0.532865\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502823; batch adversarial loss: 0.610030\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473436; batch adversarial loss: 0.618444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520662; batch adversarial loss: 0.547469\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516755; batch adversarial loss: 0.539725\n",
      "epoch 17; iter: 0; batch classifier loss: 0.458309; batch adversarial loss: 0.528462\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531913; batch adversarial loss: 0.582037\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522179; batch adversarial loss: 0.500217\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461302; batch adversarial loss: 0.648129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475861; batch adversarial loss: 0.559278\n",
      "epoch 22; iter: 0; batch classifier loss: 0.559488; batch adversarial loss: 0.606212\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467579; batch adversarial loss: 0.545157\n",
      "epoch 24; iter: 0; batch classifier loss: 0.552777; batch adversarial loss: 0.523272\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508267; batch adversarial loss: 0.529424\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473896; batch adversarial loss: 0.607162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445016; batch adversarial loss: 0.506445\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421362; batch adversarial loss: 0.579394\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445130; batch adversarial loss: 0.541267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540197; batch adversarial loss: 0.549204\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506885; batch adversarial loss: 0.539279\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444830; batch adversarial loss: 0.579366\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414814; batch adversarial loss: 0.579928\n",
      "epoch 34; iter: 0; batch classifier loss: 0.403211; batch adversarial loss: 0.513586\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458175; batch adversarial loss: 0.535844\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512662; batch adversarial loss: 0.491634\n",
      "epoch 37; iter: 0; batch classifier loss: 0.478878; batch adversarial loss: 0.501007\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389601; batch adversarial loss: 0.570214\n",
      "epoch 39; iter: 0; batch classifier loss: 0.472102; batch adversarial loss: 0.517193\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441373; batch adversarial loss: 0.508379\n",
      "epoch 41; iter: 0; batch classifier loss: 0.387750; batch adversarial loss: 0.443769\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505805; batch adversarial loss: 0.582199\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477633; batch adversarial loss: 0.626662\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456758; batch adversarial loss: 0.627603\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430738; batch adversarial loss: 0.517080\n",
      "epoch 46; iter: 0; batch classifier loss: 0.530854; batch adversarial loss: 0.518153\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473372; batch adversarial loss: 0.535567\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427871; batch adversarial loss: 0.463385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444724; batch adversarial loss: 0.562501\n",
      "epoch 50; iter: 0; batch classifier loss: 0.499654; batch adversarial loss: 0.544726\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415924; batch adversarial loss: 0.535746\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405287; batch adversarial loss: 0.544822\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429520; batch adversarial loss: 0.562131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437411; batch adversarial loss: 0.589536\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401824; batch adversarial loss: 0.498656\n",
      "epoch 56; iter: 0; batch classifier loss: 0.406813; batch adversarial loss: 0.479903\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420082; batch adversarial loss: 0.535079\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401567; batch adversarial loss: 0.535767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.463771; batch adversarial loss: 0.462966\n",
      "epoch 60; iter: 0; batch classifier loss: 0.342055; batch adversarial loss: 0.635758\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402896; batch adversarial loss: 0.480682\n",
      "epoch 62; iter: 0; batch classifier loss: 0.346236; batch adversarial loss: 0.553768\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409197; batch adversarial loss: 0.461746\n",
      "epoch 64; iter: 0; batch classifier loss: 0.444454; batch adversarial loss: 0.498644\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395230; batch adversarial loss: 0.672533\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440866; batch adversarial loss: 0.562968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387527; batch adversarial loss: 0.590364\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419810; batch adversarial loss: 0.517106\n",
      "epoch 69; iter: 0; batch classifier loss: 0.421113; batch adversarial loss: 0.572278\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407903; batch adversarial loss: 0.598637\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484469; batch adversarial loss: 0.544644\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457238; batch adversarial loss: 0.517592\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430620; batch adversarial loss: 0.507248\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464413; batch adversarial loss: 0.553712\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455035; batch adversarial loss: 0.628434\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408862; batch adversarial loss: 0.489677\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406682; batch adversarial loss: 0.508874\n",
      "epoch 78; iter: 0; batch classifier loss: 0.443263; batch adversarial loss: 0.563818\n",
      "epoch 79; iter: 0; batch classifier loss: 0.310848; batch adversarial loss: 0.608223\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418279; batch adversarial loss: 0.543522\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434173; batch adversarial loss: 0.517760\n",
      "epoch 82; iter: 0; batch classifier loss: 0.427940; batch adversarial loss: 0.654092\n",
      "epoch 83; iter: 0; batch classifier loss: 0.460037; batch adversarial loss: 0.552682\n",
      "epoch 84; iter: 0; batch classifier loss: 0.493557; batch adversarial loss: 0.626544\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402624; batch adversarial loss: 0.562697\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379051; batch adversarial loss: 0.563391\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404570; batch adversarial loss: 0.497898\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373895; batch adversarial loss: 0.599595\n",
      "epoch 89; iter: 0; batch classifier loss: 0.424661; batch adversarial loss: 0.489280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430452; batch adversarial loss: 0.563182\n",
      "epoch 91; iter: 0; batch classifier loss: 0.449571; batch adversarial loss: 0.599228\n",
      "epoch 92; iter: 0; batch classifier loss: 0.466278; batch adversarial loss: 0.626768\n",
      "epoch 93; iter: 0; batch classifier loss: 0.333432; batch adversarial loss: 0.571330\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401525; batch adversarial loss: 0.561733\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423474; batch adversarial loss: 0.527086\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404385; batch adversarial loss: 0.599366\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368258; batch adversarial loss: 0.517243\n",
      "epoch 98; iter: 0; batch classifier loss: 0.353449; batch adversarial loss: 0.480424\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398775; batch adversarial loss: 0.563352\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353899; batch adversarial loss: 0.535058\n",
      "epoch 101; iter: 0; batch classifier loss: 0.435534; batch adversarial loss: 0.508136\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380852; batch adversarial loss: 0.507642\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379895; batch adversarial loss: 0.517229\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395109; batch adversarial loss: 0.580860\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370869; batch adversarial loss: 0.526217\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404110; batch adversarial loss: 0.627084\n",
      "epoch 107; iter: 0; batch classifier loss: 0.471712; batch adversarial loss: 0.481162\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348366; batch adversarial loss: 0.488789\n",
      "epoch 109; iter: 0; batch classifier loss: 0.457127; batch adversarial loss: 0.553267\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385324; batch adversarial loss: 0.589229\n",
      "epoch 111; iter: 0; batch classifier loss: 0.413233; batch adversarial loss: 0.507093\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355086; batch adversarial loss: 0.572061\n",
      "epoch 113; iter: 0; batch classifier loss: 0.455515; batch adversarial loss: 0.535882\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394590; batch adversarial loss: 0.534604\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375971; batch adversarial loss: 0.479896\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339459; batch adversarial loss: 0.534968\n",
      "epoch 117; iter: 0; batch classifier loss: 0.453928; batch adversarial loss: 0.580526\n",
      "epoch 118; iter: 0; batch classifier loss: 0.353244; batch adversarial loss: 0.590071\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373272; batch adversarial loss: 0.562823\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400181; batch adversarial loss: 0.544821\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404174; batch adversarial loss: 0.453606\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335535; batch adversarial loss: 0.554970\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376821; batch adversarial loss: 0.590460\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326571; batch adversarial loss: 0.562123\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343005; batch adversarial loss: 0.609698\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413096; batch adversarial loss: 0.571877\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368775; batch adversarial loss: 0.545065\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409315; batch adversarial loss: 0.527027\n",
      "epoch 129; iter: 0; batch classifier loss: 0.351682; batch adversarial loss: 0.526166\n",
      "epoch 130; iter: 0; batch classifier loss: 0.437596; batch adversarial loss: 0.562986\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391977; batch adversarial loss: 0.562883\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313812; batch adversarial loss: 0.499150\n",
      "epoch 133; iter: 0; batch classifier loss: 0.423218; batch adversarial loss: 0.599480\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403114; batch adversarial loss: 0.544271\n",
      "epoch 135; iter: 0; batch classifier loss: 0.281875; batch adversarial loss: 0.599936\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371281; batch adversarial loss: 0.599176\n",
      "epoch 137; iter: 0; batch classifier loss: 0.446540; batch adversarial loss: 0.489564\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356344; batch adversarial loss: 0.526249\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407851; batch adversarial loss: 0.517294\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413123; batch adversarial loss: 0.580814\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381257; batch adversarial loss: 0.572023\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351396; batch adversarial loss: 0.599529\n",
      "epoch 143; iter: 0; batch classifier loss: 0.357653; batch adversarial loss: 0.562937\n",
      "epoch 144; iter: 0; batch classifier loss: 0.425149; batch adversarial loss: 0.525828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331132; batch adversarial loss: 0.517827\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346831; batch adversarial loss: 0.562974\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374297; batch adversarial loss: 0.506878\n",
      "epoch 148; iter: 0; batch classifier loss: 0.422053; batch adversarial loss: 0.498056\n",
      "epoch 149; iter: 0; batch classifier loss: 0.381550; batch adversarial loss: 0.572134\n",
      "epoch 150; iter: 0; batch classifier loss: 0.489306; batch adversarial loss: 0.535517\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356994; batch adversarial loss: 0.443741\n",
      "epoch 152; iter: 0; batch classifier loss: 0.424385; batch adversarial loss: 0.507888\n",
      "epoch 153; iter: 0; batch classifier loss: 0.377419; batch adversarial loss: 0.553792\n",
      "epoch 154; iter: 0; batch classifier loss: 0.455350; batch adversarial loss: 0.544280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.429221; batch adversarial loss: 0.544111\n",
      "epoch 156; iter: 0; batch classifier loss: 0.360686; batch adversarial loss: 0.571257\n",
      "epoch 157; iter: 0; batch classifier loss: 0.422807; batch adversarial loss: 0.544763\n",
      "epoch 158; iter: 0; batch classifier loss: 0.311112; batch adversarial loss: 0.572075\n",
      "epoch 159; iter: 0; batch classifier loss: 0.455967; batch adversarial loss: 0.608699\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368659; batch adversarial loss: 0.526847\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366458; batch adversarial loss: 0.526408\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326631; batch adversarial loss: 0.554113\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344151; batch adversarial loss: 0.607987\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353859; batch adversarial loss: 0.525528\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424772; batch adversarial loss: 0.544214\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322012; batch adversarial loss: 0.526688\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355076; batch adversarial loss: 0.535503\n",
      "epoch 168; iter: 0; batch classifier loss: 0.490041; batch adversarial loss: 0.544569\n",
      "epoch 169; iter: 0; batch classifier loss: 0.431689; batch adversarial loss: 0.599684\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376511; batch adversarial loss: 0.590123\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388221; batch adversarial loss: 0.553969\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388347; batch adversarial loss: 0.544820\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385312; batch adversarial loss: 0.535352\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364829; batch adversarial loss: 0.554072\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323741; batch adversarial loss: 0.590922\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395536; batch adversarial loss: 0.479873\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355233; batch adversarial loss: 0.636090\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347723; batch adversarial loss: 0.516731\n",
      "epoch 179; iter: 0; batch classifier loss: 0.409658; batch adversarial loss: 0.451998\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353673; batch adversarial loss: 0.572140\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328467; batch adversarial loss: 0.634900\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337405; batch adversarial loss: 0.544694\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355204; batch adversarial loss: 0.599422\n",
      "epoch 184; iter: 0; batch classifier loss: 0.426588; batch adversarial loss: 0.554567\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388328; batch adversarial loss: 0.488590\n",
      "epoch 186; iter: 0; batch classifier loss: 0.339705; batch adversarial loss: 0.452756\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389581; batch adversarial loss: 0.572263\n",
      "epoch 188; iter: 0; batch classifier loss: 0.400253; batch adversarial loss: 0.581169\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309650; batch adversarial loss: 0.525821\n",
      "epoch 190; iter: 0; batch classifier loss: 0.423663; batch adversarial loss: 0.581285\n",
      "epoch 191; iter: 0; batch classifier loss: 0.450481; batch adversarial loss: 0.498122\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340091; batch adversarial loss: 0.508378\n",
      "epoch 193; iter: 0; batch classifier loss: 0.415919; batch adversarial loss: 0.516249\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379247; batch adversarial loss: 0.600137\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359973; batch adversarial loss: 0.581908\n",
      "epoch 196; iter: 0; batch classifier loss: 0.430465; batch adversarial loss: 0.506936\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358291; batch adversarial loss: 0.599420\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390436; batch adversarial loss: 0.525952\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386601; batch adversarial loss: 0.498866\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728710; batch adversarial loss: 0.757146\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575272; batch adversarial loss: 0.697577\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561670; batch adversarial loss: 0.623552\n",
      "epoch 3; iter: 0; batch classifier loss: 0.554955; batch adversarial loss: 0.633067\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535093; batch adversarial loss: 0.592209\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527443; batch adversarial loss: 0.596696\n",
      "epoch 6; iter: 0; batch classifier loss: 0.610638; batch adversarial loss: 0.603835\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491010; batch adversarial loss: 0.568016\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519027; batch adversarial loss: 0.591098\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575918; batch adversarial loss: 0.660605\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466779; batch adversarial loss: 0.626714\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549394; batch adversarial loss: 0.577116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487654; batch adversarial loss: 0.637737\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491348; batch adversarial loss: 0.523338\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542209; batch adversarial loss: 0.629224\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488744; batch adversarial loss: 0.609452\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556840; batch adversarial loss: 0.561481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507645; batch adversarial loss: 0.634991\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504852; batch adversarial loss: 0.520928\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535191; batch adversarial loss: 0.623772\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461672; batch adversarial loss: 0.556778\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520693; batch adversarial loss: 0.558439\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501082; batch adversarial loss: 0.621292\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528435; batch adversarial loss: 0.574732\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482767; batch adversarial loss: 0.554135\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455169; batch adversarial loss: 0.570708\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458584; batch adversarial loss: 0.508068\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446748; batch adversarial loss: 0.582360\n",
      "epoch 28; iter: 0; batch classifier loss: 0.521156; batch adversarial loss: 0.536725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489702; batch adversarial loss: 0.597751\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444304; batch adversarial loss: 0.549208\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390697; batch adversarial loss: 0.495216\n",
      "epoch 32; iter: 0; batch classifier loss: 0.518778; batch adversarial loss: 0.616805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426326; batch adversarial loss: 0.519192\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467531; batch adversarial loss: 0.614003\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504019; batch adversarial loss: 0.592995\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423148; batch adversarial loss: 0.533442\n",
      "epoch 37; iter: 0; batch classifier loss: 0.504638; batch adversarial loss: 0.499093\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488140; batch adversarial loss: 0.581134\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428915; batch adversarial loss: 0.526075\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486081; batch adversarial loss: 0.592356\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421935; batch adversarial loss: 0.517670\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464965; batch adversarial loss: 0.546668\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424075; batch adversarial loss: 0.554479\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488382; batch adversarial loss: 0.535644\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411009; batch adversarial loss: 0.544481\n",
      "epoch 46; iter: 0; batch classifier loss: 0.421316; batch adversarial loss: 0.517770\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472538; batch adversarial loss: 0.490082\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446949; batch adversarial loss: 0.535788\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424091; batch adversarial loss: 0.526373\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401924; batch adversarial loss: 0.562863\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418120; batch adversarial loss: 0.516947\n",
      "epoch 52; iter: 0; batch classifier loss: 0.378320; batch adversarial loss: 0.507795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.403374; batch adversarial loss: 0.526218\n",
      "epoch 54; iter: 0; batch classifier loss: 0.532329; batch adversarial loss: 0.562677\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453433; batch adversarial loss: 0.542815\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430871; batch adversarial loss: 0.562983\n",
      "epoch 57; iter: 0; batch classifier loss: 0.521282; batch adversarial loss: 0.552898\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456296; batch adversarial loss: 0.516447\n",
      "epoch 59; iter: 0; batch classifier loss: 0.389797; batch adversarial loss: 0.516664\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403529; batch adversarial loss: 0.545404\n",
      "epoch 61; iter: 0; batch classifier loss: 0.351018; batch adversarial loss: 0.571493\n",
      "epoch 62; iter: 0; batch classifier loss: 0.497367; batch adversarial loss: 0.542449\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415345; batch adversarial loss: 0.627040\n",
      "epoch 64; iter: 0; batch classifier loss: 0.495481; batch adversarial loss: 0.515614\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410183; batch adversarial loss: 0.526764\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431592; batch adversarial loss: 0.533128\n",
      "epoch 67; iter: 0; batch classifier loss: 0.332629; batch adversarial loss: 0.563692\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417807; batch adversarial loss: 0.535969\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415077; batch adversarial loss: 0.516105\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408351; batch adversarial loss: 0.535231\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438689; batch adversarial loss: 0.588339\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371313; batch adversarial loss: 0.506493\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390627; batch adversarial loss: 0.570727\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356657; batch adversarial loss: 0.499483\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390466; batch adversarial loss: 0.573553\n",
      "epoch 76; iter: 0; batch classifier loss: 0.474016; batch adversarial loss: 0.551899\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412986; batch adversarial loss: 0.514764\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373801; batch adversarial loss: 0.573191\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421163; batch adversarial loss: 0.555789\n",
      "epoch 80; iter: 0; batch classifier loss: 0.457569; batch adversarial loss: 0.574197\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463862; batch adversarial loss: 0.479652\n",
      "epoch 82; iter: 0; batch classifier loss: 0.473877; batch adversarial loss: 0.583119\n",
      "epoch 83; iter: 0; batch classifier loss: 0.354823; batch adversarial loss: 0.488309\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416370; batch adversarial loss: 0.515069\n",
      "epoch 85; iter: 0; batch classifier loss: 0.432815; batch adversarial loss: 0.600913\n",
      "epoch 86; iter: 0; batch classifier loss: 0.474258; batch adversarial loss: 0.489826\n",
      "epoch 87; iter: 0; batch classifier loss: 0.475827; batch adversarial loss: 0.536949\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423904; batch adversarial loss: 0.508144\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416240; batch adversarial loss: 0.562052\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398538; batch adversarial loss: 0.600070\n",
      "epoch 91; iter: 0; batch classifier loss: 0.420378; batch adversarial loss: 0.507526\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391430; batch adversarial loss: 0.535537\n",
      "epoch 93; iter: 0; batch classifier loss: 0.459852; batch adversarial loss: 0.572611\n",
      "epoch 94; iter: 0; batch classifier loss: 0.409579; batch adversarial loss: 0.507501\n",
      "epoch 95; iter: 0; batch classifier loss: 0.449352; batch adversarial loss: 0.581266\n",
      "epoch 96; iter: 0; batch classifier loss: 0.363333; batch adversarial loss: 0.517344\n",
      "epoch 97; iter: 0; batch classifier loss: 0.426148; batch adversarial loss: 0.480953\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377224; batch adversarial loss: 0.535013\n",
      "epoch 99; iter: 0; batch classifier loss: 0.383913; batch adversarial loss: 0.544158\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408920; batch adversarial loss: 0.498653\n",
      "epoch 101; iter: 0; batch classifier loss: 0.361593; batch adversarial loss: 0.582320\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413236; batch adversarial loss: 0.655384\n",
      "epoch 103; iter: 0; batch classifier loss: 0.490899; batch adversarial loss: 0.444186\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419684; batch adversarial loss: 0.480979\n",
      "epoch 105; iter: 0; batch classifier loss: 0.443422; batch adversarial loss: 0.590687\n",
      "epoch 106; iter: 0; batch classifier loss: 0.495048; batch adversarial loss: 0.525535\n",
      "epoch 107; iter: 0; batch classifier loss: 0.466577; batch adversarial loss: 0.601277\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407245; batch adversarial loss: 0.526594\n",
      "epoch 109; iter: 0; batch classifier loss: 0.501435; batch adversarial loss: 0.543144\n",
      "epoch 110; iter: 0; batch classifier loss: 0.422573; batch adversarial loss: 0.508282\n",
      "epoch 111; iter: 0; batch classifier loss: 0.481775; batch adversarial loss: 0.516148\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384071; batch adversarial loss: 0.488110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.435788; batch adversarial loss: 0.471057\n",
      "epoch 114; iter: 0; batch classifier loss: 0.413951; batch adversarial loss: 0.561847\n",
      "epoch 115; iter: 0; batch classifier loss: 0.309525; batch adversarial loss: 0.525314\n",
      "epoch 116; iter: 0; batch classifier loss: 0.322607; batch adversarial loss: 0.563774\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408725; batch adversarial loss: 0.580697\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402413; batch adversarial loss: 0.535340\n",
      "epoch 119; iter: 0; batch classifier loss: 0.303582; batch adversarial loss: 0.516708\n",
      "epoch 120; iter: 0; batch classifier loss: 0.440019; batch adversarial loss: 0.525788\n",
      "epoch 121; iter: 0; batch classifier loss: 0.517248; batch adversarial loss: 0.636549\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403839; batch adversarial loss: 0.525726\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401774; batch adversarial loss: 0.545313\n",
      "epoch 124; iter: 0; batch classifier loss: 0.300666; batch adversarial loss: 0.526517\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418733; batch adversarial loss: 0.552684\n",
      "epoch 126; iter: 0; batch classifier loss: 0.409130; batch adversarial loss: 0.535459\n",
      "epoch 127; iter: 0; batch classifier loss: 0.447988; batch adversarial loss: 0.636400\n",
      "epoch 128; iter: 0; batch classifier loss: 0.393788; batch adversarial loss: 0.535637\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365754; batch adversarial loss: 0.580626\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380148; batch adversarial loss: 0.471738\n",
      "epoch 131; iter: 0; batch classifier loss: 0.404326; batch adversarial loss: 0.481958\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394756; batch adversarial loss: 0.472266\n",
      "epoch 133; iter: 0; batch classifier loss: 0.526002; batch adversarial loss: 0.663136\n",
      "epoch 134; iter: 0; batch classifier loss: 0.429015; batch adversarial loss: 0.554230\n",
      "epoch 135; iter: 0; batch classifier loss: 0.452964; batch adversarial loss: 0.487120\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336309; batch adversarial loss: 0.628114\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383625; batch adversarial loss: 0.543908\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388534; batch adversarial loss: 0.560180\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336109; batch adversarial loss: 0.463250\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396648; batch adversarial loss: 0.580292\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365172; batch adversarial loss: 0.600179\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338278; batch adversarial loss: 0.498361\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401908; batch adversarial loss: 0.561180\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398517; batch adversarial loss: 0.693186\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375821; batch adversarial loss: 0.554524\n",
      "epoch 146; iter: 0; batch classifier loss: 0.420194; batch adversarial loss: 0.571972\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344674; batch adversarial loss: 0.497063\n",
      "epoch 148; iter: 0; batch classifier loss: 0.426768; batch adversarial loss: 0.601980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.396347; batch adversarial loss: 0.507483\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359951; batch adversarial loss: 0.562844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387727; batch adversarial loss: 0.526824\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335293; batch adversarial loss: 0.572129\n",
      "epoch 153; iter: 0; batch classifier loss: 0.392266; batch adversarial loss: 0.515789\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335622; batch adversarial loss: 0.497657\n",
      "epoch 155; iter: 0; batch classifier loss: 0.399804; batch adversarial loss: 0.461142\n",
      "epoch 156; iter: 0; batch classifier loss: 0.394510; batch adversarial loss: 0.554928\n",
      "epoch 157; iter: 0; batch classifier loss: 0.426339; batch adversarial loss: 0.581057\n",
      "epoch 158; iter: 0; batch classifier loss: 0.415598; batch adversarial loss: 0.498939\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407067; batch adversarial loss: 0.545116\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372712; batch adversarial loss: 0.526449\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380725; batch adversarial loss: 0.535234\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355836; batch adversarial loss: 0.637285\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416877; batch adversarial loss: 0.535053\n",
      "epoch 164; iter: 0; batch classifier loss: 0.327407; batch adversarial loss: 0.563864\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365185; batch adversarial loss: 0.526732\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395814; batch adversarial loss: 0.553848\n",
      "epoch 167; iter: 0; batch classifier loss: 0.325704; batch adversarial loss: 0.591017\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353497; batch adversarial loss: 0.544435\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332014; batch adversarial loss: 0.563391\n",
      "epoch 170; iter: 0; batch classifier loss: 0.424416; batch adversarial loss: 0.478462\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326062; batch adversarial loss: 0.498772\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392894; batch adversarial loss: 0.489082\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338959; batch adversarial loss: 0.553842\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373643; batch adversarial loss: 0.543691\n",
      "epoch 175; iter: 0; batch classifier loss: 0.423128; batch adversarial loss: 0.535015\n",
      "epoch 176; iter: 0; batch classifier loss: 0.293338; batch adversarial loss: 0.517339\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369602; batch adversarial loss: 0.554479\n",
      "epoch 178; iter: 0; batch classifier loss: 0.438108; batch adversarial loss: 0.553871\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389564; batch adversarial loss: 0.544079\n",
      "epoch 180; iter: 0; batch classifier loss: 0.419116; batch adversarial loss: 0.599616\n",
      "epoch 181; iter: 0; batch classifier loss: 0.440023; batch adversarial loss: 0.507756\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368739; batch adversarial loss: 0.525881\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376583; batch adversarial loss: 0.516523\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358353; batch adversarial loss: 0.617490\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345175; batch adversarial loss: 0.664502\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356121; batch adversarial loss: 0.590022\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333627; batch adversarial loss: 0.526682\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365062; batch adversarial loss: 0.544952\n",
      "epoch 189; iter: 0; batch classifier loss: 0.387479; batch adversarial loss: 0.618002\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371820; batch adversarial loss: 0.479303\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339885; batch adversarial loss: 0.516805\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386759; batch adversarial loss: 0.580734\n",
      "epoch 193; iter: 0; batch classifier loss: 0.394884; batch adversarial loss: 0.609944\n",
      "epoch 194; iter: 0; batch classifier loss: 0.375116; batch adversarial loss: 0.497955\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327833; batch adversarial loss: 0.479404\n",
      "epoch 196; iter: 0; batch classifier loss: 0.413752; batch adversarial loss: 0.525972\n",
      "epoch 197; iter: 0; batch classifier loss: 0.380395; batch adversarial loss: 0.535218\n",
      "epoch 198; iter: 0; batch classifier loss: 0.422946; batch adversarial loss: 0.497443\n",
      "epoch 199; iter: 0; batch classifier loss: 0.402263; batch adversarial loss: 0.498589\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715856; batch adversarial loss: 1.013548\n",
      "epoch 1; iter: 0; batch classifier loss: 0.820172; batch adversarial loss: 1.143907\n",
      "epoch 2; iter: 0; batch classifier loss: 1.055718; batch adversarial loss: 1.169550\n",
      "epoch 3; iter: 0; batch classifier loss: 1.034860; batch adversarial loss: 1.059862\n",
      "epoch 4; iter: 0; batch classifier loss: 1.062148; batch adversarial loss: 0.986004\n",
      "epoch 5; iter: 0; batch classifier loss: 1.105392; batch adversarial loss: 0.902145\n",
      "epoch 6; iter: 0; batch classifier loss: 1.117664; batch adversarial loss: 0.832380\n",
      "epoch 7; iter: 0; batch classifier loss: 1.098480; batch adversarial loss: 0.762270\n",
      "epoch 8; iter: 0; batch classifier loss: 1.067906; batch adversarial loss: 0.714967\n",
      "epoch 9; iter: 0; batch classifier loss: 1.069757; batch adversarial loss: 0.672139\n",
      "epoch 10; iter: 0; batch classifier loss: 0.987392; batch adversarial loss: 0.647010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.999903; batch adversarial loss: 0.596194\n",
      "epoch 12; iter: 0; batch classifier loss: 0.870466; batch adversarial loss: 0.607098\n",
      "epoch 13; iter: 0; batch classifier loss: 0.812678; batch adversarial loss: 0.527950\n",
      "epoch 14; iter: 0; batch classifier loss: 0.778638; batch adversarial loss: 0.591801\n",
      "epoch 15; iter: 0; batch classifier loss: 0.731515; batch adversarial loss: 0.543130\n",
      "epoch 16; iter: 0; batch classifier loss: 0.685830; batch adversarial loss: 0.500255\n",
      "epoch 17; iter: 0; batch classifier loss: 0.629540; batch adversarial loss: 0.504545\n",
      "epoch 18; iter: 0; batch classifier loss: 0.609187; batch adversarial loss: 0.508586\n",
      "epoch 19; iter: 0; batch classifier loss: 0.633880; batch adversarial loss: 0.501809\n",
      "epoch 20; iter: 0; batch classifier loss: 0.591910; batch adversarial loss: 0.521282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542687; batch adversarial loss: 0.573471\n",
      "epoch 22; iter: 0; batch classifier loss: 0.539834; batch adversarial loss: 0.500504\n",
      "epoch 23; iter: 0; batch classifier loss: 0.549306; batch adversarial loss: 0.570938\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509611; batch adversarial loss: 0.531004\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443089; batch adversarial loss: 0.489268\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483762; batch adversarial loss: 0.515550\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446360; batch adversarial loss: 0.554717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489276; batch adversarial loss: 0.489932\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431461; batch adversarial loss: 0.535204\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446701; batch adversarial loss: 0.533021\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419653; batch adversarial loss: 0.572136\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465643; batch adversarial loss: 0.597631\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432869; batch adversarial loss: 0.614611\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416868; batch adversarial loss: 0.542025\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435864; batch adversarial loss: 0.532278\n",
      "epoch 36; iter: 0; batch classifier loss: 0.556714; batch adversarial loss: 0.505897\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469573; batch adversarial loss: 0.546575\n",
      "epoch 38; iter: 0; batch classifier loss: 0.559406; batch adversarial loss: 0.517635\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465839; batch adversarial loss: 0.545951\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449887; batch adversarial loss: 0.567741\n",
      "epoch 41; iter: 0; batch classifier loss: 0.512216; batch adversarial loss: 0.563421\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453682; batch adversarial loss: 0.559638\n",
      "epoch 43; iter: 0; batch classifier loss: 0.488494; batch adversarial loss: 0.528687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454892; batch adversarial loss: 0.559269\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451815; batch adversarial loss: 0.568117\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436977; batch adversarial loss: 0.558719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.397398; batch adversarial loss: 0.489105\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437132; batch adversarial loss: 0.479870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397455; batch adversarial loss: 0.529939\n",
      "epoch 50; iter: 0; batch classifier loss: 0.494692; batch adversarial loss: 0.565201\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464940; batch adversarial loss: 0.598086\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385589; batch adversarial loss: 0.502049\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408572; batch adversarial loss: 0.475672\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392944; batch adversarial loss: 0.562561\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390049; batch adversarial loss: 0.571287\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426819; batch adversarial loss: 0.544588\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435512; batch adversarial loss: 0.562564\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455871; batch adversarial loss: 0.517374\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388535; batch adversarial loss: 0.606642\n",
      "epoch 60; iter: 0; batch classifier loss: 0.387896; batch adversarial loss: 0.508606\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426304; batch adversarial loss: 0.499008\n",
      "epoch 62; iter: 0; batch classifier loss: 0.307832; batch adversarial loss: 0.599591\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411807; batch adversarial loss: 0.526734\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409018; batch adversarial loss: 0.472078\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412797; batch adversarial loss: 0.535243\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401938; batch adversarial loss: 0.561863\n",
      "epoch 67; iter: 0; batch classifier loss: 0.469662; batch adversarial loss: 0.499390\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417865; batch adversarial loss: 0.534998\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403173; batch adversarial loss: 0.572200\n",
      "epoch 70; iter: 0; batch classifier loss: 0.339406; batch adversarial loss: 0.506789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463440; batch adversarial loss: 0.527806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.313942; batch adversarial loss: 0.544758\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388222; batch adversarial loss: 0.499141\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395413; batch adversarial loss: 0.626974\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381218; batch adversarial loss: 0.588725\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374397; batch adversarial loss: 0.609440\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396264; batch adversarial loss: 0.517016\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413381; batch adversarial loss: 0.570188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385683; batch adversarial loss: 0.617221\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388541; batch adversarial loss: 0.553548\n",
      "epoch 81; iter: 0; batch classifier loss: 0.497394; batch adversarial loss: 0.544420\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399644; batch adversarial loss: 0.536543\n",
      "epoch 83; iter: 0; batch classifier loss: 0.323567; batch adversarial loss: 0.488862\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401551; batch adversarial loss: 0.573005\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407042; batch adversarial loss: 0.562527\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368300; batch adversarial loss: 0.562819\n",
      "epoch 87; iter: 0; batch classifier loss: 0.407950; batch adversarial loss: 0.562629\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365998; batch adversarial loss: 0.564155\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378643; batch adversarial loss: 0.590042\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344871; batch adversarial loss: 0.553927\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363746; batch adversarial loss: 0.498263\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344181; batch adversarial loss: 0.471239\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441958; batch adversarial loss: 0.488752\n",
      "epoch 94; iter: 0; batch classifier loss: 0.445335; batch adversarial loss: 0.461837\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401741; batch adversarial loss: 0.599395\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398724; batch adversarial loss: 0.489675\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418914; batch adversarial loss: 0.442513\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356008; batch adversarial loss: 0.534796\n",
      "epoch 99; iter: 0; batch classifier loss: 0.277498; batch adversarial loss: 0.597402\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381522; batch adversarial loss: 0.561598\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386345; batch adversarial loss: 0.545760\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339866; batch adversarial loss: 0.563837\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345582; batch adversarial loss: 0.543467\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377364; batch adversarial loss: 0.579255\n",
      "epoch 105; iter: 0; batch classifier loss: 0.328432; batch adversarial loss: 0.525422\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397928; batch adversarial loss: 0.489074\n",
      "epoch 107; iter: 0; batch classifier loss: 0.435331; batch adversarial loss: 0.479710\n",
      "epoch 108; iter: 0; batch classifier loss: 0.307996; batch adversarial loss: 0.527025\n",
      "epoch 109; iter: 0; batch classifier loss: 0.320026; batch adversarial loss: 0.555700\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371013; batch adversarial loss: 0.532881\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369488; batch adversarial loss: 0.615903\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336368; batch adversarial loss: 0.535317\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346392; batch adversarial loss: 0.588961\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389549; batch adversarial loss: 0.598547\n",
      "epoch 115; iter: 0; batch classifier loss: 0.440477; batch adversarial loss: 0.556040\n",
      "epoch 116; iter: 0; batch classifier loss: 0.321289; batch adversarial loss: 0.498797\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379219; batch adversarial loss: 0.601007\n",
      "epoch 118; iter: 0; batch classifier loss: 0.364855; batch adversarial loss: 0.617980\n",
      "epoch 119; iter: 0; batch classifier loss: 0.325449; batch adversarial loss: 0.547232\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394616; batch adversarial loss: 0.473330\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366983; batch adversarial loss: 0.527494\n",
      "epoch 122; iter: 0; batch classifier loss: 0.474165; batch adversarial loss: 0.542779\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373249; batch adversarial loss: 0.536637\n",
      "epoch 124; iter: 0; batch classifier loss: 0.482339; batch adversarial loss: 0.609475\n",
      "epoch 125; iter: 0; batch classifier loss: 0.421167; batch adversarial loss: 0.518754\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375920; batch adversarial loss: 0.542819\n",
      "epoch 127; iter: 0; batch classifier loss: 0.393916; batch adversarial loss: 0.542501\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360270; batch adversarial loss: 0.523804\n",
      "epoch 129; iter: 0; batch classifier loss: 0.439574; batch adversarial loss: 0.537038\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387096; batch adversarial loss: 0.597294\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376395; batch adversarial loss: 0.462296\n",
      "epoch 132; iter: 0; batch classifier loss: 0.301776; batch adversarial loss: 0.508520\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351949; batch adversarial loss: 0.618445\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358155; batch adversarial loss: 0.487996\n",
      "epoch 135; iter: 0; batch classifier loss: 0.355196; batch adversarial loss: 0.505793\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398134; batch adversarial loss: 0.580581\n",
      "epoch 137; iter: 0; batch classifier loss: 0.339420; batch adversarial loss: 0.545418\n",
      "epoch 138; iter: 0; batch classifier loss: 0.331247; batch adversarial loss: 0.646761\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374729; batch adversarial loss: 0.502120\n",
      "epoch 140; iter: 0; batch classifier loss: 0.380001; batch adversarial loss: 0.535658\n",
      "epoch 141; iter: 0; batch classifier loss: 0.378814; batch adversarial loss: 0.589193\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374190; batch adversarial loss: 0.632500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.298228; batch adversarial loss: 0.581023\n",
      "epoch 144; iter: 0; batch classifier loss: 0.328682; batch adversarial loss: 0.592420\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323149; batch adversarial loss: 0.545760\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410220; batch adversarial loss: 0.619587\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340689; batch adversarial loss: 0.616358\n",
      "epoch 148; iter: 0; batch classifier loss: 0.372802; batch adversarial loss: 0.580276\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344248; batch adversarial loss: 0.598685\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400419; batch adversarial loss: 0.573725\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387073; batch adversarial loss: 0.486359\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350794; batch adversarial loss: 0.562667\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385308; batch adversarial loss: 0.498124\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390356; batch adversarial loss: 0.580706\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373308; batch adversarial loss: 0.601755\n",
      "epoch 156; iter: 0; batch classifier loss: 0.308579; batch adversarial loss: 0.545615\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308518; batch adversarial loss: 0.499873\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381020; batch adversarial loss: 0.518632\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393127; batch adversarial loss: 0.585348\n",
      "epoch 160; iter: 0; batch classifier loss: 0.302406; batch adversarial loss: 0.453023\n",
      "epoch 161; iter: 0; batch classifier loss: 0.381422; batch adversarial loss: 0.516907\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374792; batch adversarial loss: 0.615015\n",
      "epoch 163; iter: 0; batch classifier loss: 0.314003; batch adversarial loss: 0.489586\n",
      "epoch 164; iter: 0; batch classifier loss: 0.428744; batch adversarial loss: 0.564088\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387068; batch adversarial loss: 0.544748\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322365; batch adversarial loss: 0.543793\n",
      "epoch 167; iter: 0; batch classifier loss: 0.273487; batch adversarial loss: 0.479845\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351636; batch adversarial loss: 0.524690\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312823; batch adversarial loss: 0.524727\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344197; batch adversarial loss: 0.424764\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330294; batch adversarial loss: 0.597499\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373644; batch adversarial loss: 0.497753\n",
      "epoch 173; iter: 0; batch classifier loss: 0.294152; batch adversarial loss: 0.515655\n",
      "epoch 174; iter: 0; batch classifier loss: 0.329927; batch adversarial loss: 0.543377\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372155; batch adversarial loss: 0.565816\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330004; batch adversarial loss: 0.617567\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371317; batch adversarial loss: 0.470697\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364080; batch adversarial loss: 0.562592\n",
      "epoch 179; iter: 0; batch classifier loss: 0.240368; batch adversarial loss: 0.515266\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362068; batch adversarial loss: 0.562330\n",
      "epoch 181; iter: 0; batch classifier loss: 0.312872; batch adversarial loss: 0.578050\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382246; batch adversarial loss: 0.595433\n",
      "epoch 183; iter: 0; batch classifier loss: 0.271748; batch adversarial loss: 0.508695\n",
      "epoch 184; iter: 0; batch classifier loss: 0.429508; batch adversarial loss: 0.579085\n",
      "epoch 185; iter: 0; batch classifier loss: 0.275895; batch adversarial loss: 0.532936\n",
      "epoch 186; iter: 0; batch classifier loss: 0.394961; batch adversarial loss: 0.553528\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361487; batch adversarial loss: 0.536012\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382758; batch adversarial loss: 0.654284\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347816; batch adversarial loss: 0.510112\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321289; batch adversarial loss: 0.553673\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319051; batch adversarial loss: 0.535886\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305228; batch adversarial loss: 0.623554\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402816; batch adversarial loss: 0.524933\n",
      "epoch 194; iter: 0; batch classifier loss: 0.367918; batch adversarial loss: 0.563376\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319131; batch adversarial loss: 0.608532\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316677; batch adversarial loss: 0.533947\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353860; batch adversarial loss: 0.616744\n",
      "epoch 198; iter: 0; batch classifier loss: 0.285391; batch adversarial loss: 0.577708\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323208; batch adversarial loss: 0.587269\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699617; batch adversarial loss: 0.778106\n",
      "epoch 1; iter: 0; batch classifier loss: 0.674440; batch adversarial loss: 0.860646\n",
      "epoch 2; iter: 0; batch classifier loss: 0.749076; batch adversarial loss: 0.823007\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614490; batch adversarial loss: 0.754354\n",
      "epoch 4; iter: 0; batch classifier loss: 0.638444; batch adversarial loss: 0.681864\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651181; batch adversarial loss: 0.650710\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584558; batch adversarial loss: 0.635793\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567036; batch adversarial loss: 0.618619\n",
      "epoch 8; iter: 0; batch classifier loss: 0.584676; batch adversarial loss: 0.626035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.515975; batch adversarial loss: 0.600211\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557868; batch adversarial loss: 0.617996\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550289; batch adversarial loss: 0.574917\n",
      "epoch 12; iter: 0; batch classifier loss: 0.563510; batch adversarial loss: 0.576887\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483114; batch adversarial loss: 0.549507\n",
      "epoch 14; iter: 0; batch classifier loss: 0.537664; batch adversarial loss: 0.574100\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513892; batch adversarial loss: 0.586635\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496570; batch adversarial loss: 0.551944\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453531; batch adversarial loss: 0.577923\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483045; batch adversarial loss: 0.561680\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512076; batch adversarial loss: 0.533509\n",
      "epoch 20; iter: 0; batch classifier loss: 0.444796; batch adversarial loss: 0.592870\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452948; batch adversarial loss: 0.585374\n",
      "epoch 22; iter: 0; batch classifier loss: 0.544091; batch adversarial loss: 0.496732\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463335; batch adversarial loss: 0.585187\n",
      "epoch 24; iter: 0; batch classifier loss: 0.404794; batch adversarial loss: 0.533135\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476239; batch adversarial loss: 0.506067\n",
      "epoch 26; iter: 0; batch classifier loss: 0.392600; batch adversarial loss: 0.610647\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503335; batch adversarial loss: 0.533502\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498278; batch adversarial loss: 0.531523\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430259; batch adversarial loss: 0.595802\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424418; batch adversarial loss: 0.552939\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511371; batch adversarial loss: 0.589566\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471878; batch adversarial loss: 0.583591\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488340; batch adversarial loss: 0.585058\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522877; batch adversarial loss: 0.561863\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502057; batch adversarial loss: 0.611164\n",
      "epoch 36; iter: 0; batch classifier loss: 0.393192; batch adversarial loss: 0.577272\n",
      "epoch 37; iter: 0; batch classifier loss: 0.534335; batch adversarial loss: 0.526796\n",
      "epoch 38; iter: 0; batch classifier loss: 0.620375; batch adversarial loss: 0.561988\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414489; batch adversarial loss: 0.581717\n",
      "epoch 40; iter: 0; batch classifier loss: 0.551944; batch adversarial loss: 0.650733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.424678; batch adversarial loss: 0.544321\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407737; batch adversarial loss: 0.598125\n",
      "epoch 43; iter: 0; batch classifier loss: 0.363744; batch adversarial loss: 0.615457\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469906; batch adversarial loss: 0.544525\n",
      "epoch 45; iter: 0; batch classifier loss: 0.388319; batch adversarial loss: 0.510082\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391906; batch adversarial loss: 0.552743\n",
      "epoch 47; iter: 0; batch classifier loss: 0.524294; batch adversarial loss: 0.517549\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439041; batch adversarial loss: 0.551634\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448224; batch adversarial loss: 0.589584\n",
      "epoch 50; iter: 0; batch classifier loss: 0.483018; batch adversarial loss: 0.642568\n",
      "epoch 51; iter: 0; batch classifier loss: 0.366491; batch adversarial loss: 0.562236\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449903; batch adversarial loss: 0.499434\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449795; batch adversarial loss: 0.597400\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464794; batch adversarial loss: 0.474174\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448232; batch adversarial loss: 0.562901\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384739; batch adversarial loss: 0.526277\n",
      "epoch 57; iter: 0; batch classifier loss: 0.417820; batch adversarial loss: 0.563116\n",
      "epoch 58; iter: 0; batch classifier loss: 0.367769; batch adversarial loss: 0.562017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.364804; batch adversarial loss: 0.518659\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467394; batch adversarial loss: 0.563108\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406632; batch adversarial loss: 0.535092\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444544; batch adversarial loss: 0.500315\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374824; batch adversarial loss: 0.472904\n",
      "epoch 64; iter: 0; batch classifier loss: 0.367891; batch adversarial loss: 0.499943\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382288; batch adversarial loss: 0.545058\n",
      "epoch 66; iter: 0; batch classifier loss: 0.370070; batch adversarial loss: 0.481521\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379542; batch adversarial loss: 0.544519\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438713; batch adversarial loss: 0.553541\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440053; batch adversarial loss: 0.535132\n",
      "epoch 70; iter: 0; batch classifier loss: 0.472562; batch adversarial loss: 0.526078\n",
      "epoch 71; iter: 0; batch classifier loss: 0.350312; batch adversarial loss: 0.598798\n",
      "epoch 72; iter: 0; batch classifier loss: 0.406281; batch adversarial loss: 0.526125\n",
      "epoch 73; iter: 0; batch classifier loss: 0.480461; batch adversarial loss: 0.560987\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439432; batch adversarial loss: 0.534891\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401595; batch adversarial loss: 0.543417\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363994; batch adversarial loss: 0.507528\n",
      "epoch 77; iter: 0; batch classifier loss: 0.509816; batch adversarial loss: 0.586968\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458726; batch adversarial loss: 0.596167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368268; batch adversarial loss: 0.534176\n",
      "epoch 80; iter: 0; batch classifier loss: 0.310321; batch adversarial loss: 0.546393\n",
      "epoch 81; iter: 0; batch classifier loss: 0.347915; batch adversarial loss: 0.517691\n",
      "epoch 82; iter: 0; batch classifier loss: 0.427764; batch adversarial loss: 0.561957\n",
      "epoch 83; iter: 0; batch classifier loss: 0.379915; batch adversarial loss: 0.565978\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375717; batch adversarial loss: 0.537966\n",
      "epoch 85; iter: 0; batch classifier loss: 0.375972; batch adversarial loss: 0.518827\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372997; batch adversarial loss: 0.589890\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400378; batch adversarial loss: 0.571108\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401624; batch adversarial loss: 0.471089\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339838; batch adversarial loss: 0.597253\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409697; batch adversarial loss: 0.536460\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427870; batch adversarial loss: 0.516454\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434802; batch adversarial loss: 0.518238\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380076; batch adversarial loss: 0.591830\n",
      "epoch 94; iter: 0; batch classifier loss: 0.323835; batch adversarial loss: 0.543712\n",
      "epoch 95; iter: 0; batch classifier loss: 0.450000; batch adversarial loss: 0.534548\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400488; batch adversarial loss: 0.589500\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404893; batch adversarial loss: 0.546219\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375634; batch adversarial loss: 0.553300\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384798; batch adversarial loss: 0.526335\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408232; batch adversarial loss: 0.599515\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363022; batch adversarial loss: 0.572239\n",
      "epoch 102; iter: 0; batch classifier loss: 0.319709; batch adversarial loss: 0.535851\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385967; batch adversarial loss: 0.426290\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422245; batch adversarial loss: 0.490321\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361991; batch adversarial loss: 0.526341\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394666; batch adversarial loss: 0.535196\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397618; batch adversarial loss: 0.598622\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385934; batch adversarial loss: 0.580586\n",
      "epoch 109; iter: 0; batch classifier loss: 0.442068; batch adversarial loss: 0.544301\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382812; batch adversarial loss: 0.544151\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348593; batch adversarial loss: 0.615158\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378532; batch adversarial loss: 0.660495\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413316; batch adversarial loss: 0.677359\n",
      "epoch 114; iter: 0; batch classifier loss: 0.479393; batch adversarial loss: 0.562112\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390834; batch adversarial loss: 0.524768\n",
      "epoch 116; iter: 0; batch classifier loss: 0.432857; batch adversarial loss: 0.517724\n",
      "epoch 117; iter: 0; batch classifier loss: 0.299650; batch adversarial loss: 0.518773\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391521; batch adversarial loss: 0.598185\n",
      "epoch 119; iter: 0; batch classifier loss: 0.430346; batch adversarial loss: 0.563816\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333030; batch adversarial loss: 0.526152\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361567; batch adversarial loss: 0.508216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330052; batch adversarial loss: 0.489756\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357813; batch adversarial loss: 0.535350\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370235; batch adversarial loss: 0.499724\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383099; batch adversarial loss: 0.535878\n",
      "epoch 126; iter: 0; batch classifier loss: 0.370051; batch adversarial loss: 0.490589\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391706; batch adversarial loss: 0.562673\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340855; batch adversarial loss: 0.524976\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412999; batch adversarial loss: 0.596662\n",
      "epoch 130; iter: 0; batch classifier loss: 0.310879; batch adversarial loss: 0.528444\n",
      "epoch 131; iter: 0; batch classifier loss: 0.411539; batch adversarial loss: 0.552768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394718; batch adversarial loss: 0.605660\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361331; batch adversarial loss: 0.580167\n",
      "epoch 134; iter: 0; batch classifier loss: 0.466366; batch adversarial loss: 0.624222\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340939; batch adversarial loss: 0.527081\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405538; batch adversarial loss: 0.563626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.427427; batch adversarial loss: 0.498011\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368298; batch adversarial loss: 0.499417\n",
      "epoch 139; iter: 0; batch classifier loss: 0.387863; batch adversarial loss: 0.544693\n",
      "epoch 140; iter: 0; batch classifier loss: 0.468158; batch adversarial loss: 0.617250\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364235; batch adversarial loss: 0.599126\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384050; batch adversarial loss: 0.535704\n",
      "epoch 143; iter: 0; batch classifier loss: 0.321851; batch adversarial loss: 0.580815\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405856; batch adversarial loss: 0.643841\n",
      "epoch 145; iter: 0; batch classifier loss: 0.313690; batch adversarial loss: 0.616958\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374319; batch adversarial loss: 0.517508\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369717; batch adversarial loss: 0.481808\n",
      "epoch 148; iter: 0; batch classifier loss: 0.355316; batch adversarial loss: 0.562793\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373141; batch adversarial loss: 0.634702\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387727; batch adversarial loss: 0.571851\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378481; batch adversarial loss: 0.571224\n",
      "epoch 152; iter: 0; batch classifier loss: 0.294243; batch adversarial loss: 0.571279\n",
      "epoch 153; iter: 0; batch classifier loss: 0.439504; batch adversarial loss: 0.490875\n",
      "epoch 154; iter: 0; batch classifier loss: 0.368290; batch adversarial loss: 0.544660\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350438; batch adversarial loss: 0.472422\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370916; batch adversarial loss: 0.597515\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391967; batch adversarial loss: 0.518055\n",
      "epoch 158; iter: 0; batch classifier loss: 0.426948; batch adversarial loss: 0.553473\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389389; batch adversarial loss: 0.544578\n",
      "epoch 160; iter: 0; batch classifier loss: 0.275823; batch adversarial loss: 0.571058\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319154; batch adversarial loss: 0.499890\n",
      "epoch 162; iter: 0; batch classifier loss: 0.293276; batch adversarial loss: 0.643328\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417348; batch adversarial loss: 0.580985\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373158; batch adversarial loss: 0.571602\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355343; batch adversarial loss: 0.607736\n",
      "epoch 166; iter: 0; batch classifier loss: 0.394894; batch adversarial loss: 0.490804\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399549; batch adversarial loss: 0.571818\n",
      "epoch 168; iter: 0; batch classifier loss: 0.293513; batch adversarial loss: 0.527056\n",
      "epoch 169; iter: 0; batch classifier loss: 0.393914; batch adversarial loss: 0.536089\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364595; batch adversarial loss: 0.598650\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343298; batch adversarial loss: 0.473529\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361261; batch adversarial loss: 0.545322\n",
      "epoch 173; iter: 0; batch classifier loss: 0.291276; batch adversarial loss: 0.563344\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310733; batch adversarial loss: 0.580106\n",
      "epoch 175; iter: 0; batch classifier loss: 0.374546; batch adversarial loss: 0.633585\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373174; batch adversarial loss: 0.473227\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343055; batch adversarial loss: 0.535501\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372050; batch adversarial loss: 0.535847\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407731; batch adversarial loss: 0.553917\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363155; batch adversarial loss: 0.544460\n",
      "epoch 181; iter: 0; batch classifier loss: 0.396733; batch adversarial loss: 0.553460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.392099; batch adversarial loss: 0.562467\n",
      "epoch 183; iter: 0; batch classifier loss: 0.314135; batch adversarial loss: 0.616592\n",
      "epoch 184; iter: 0; batch classifier loss: 0.510060; batch adversarial loss: 0.597793\n",
      "epoch 185; iter: 0; batch classifier loss: 0.289116; batch adversarial loss: 0.615577\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338516; batch adversarial loss: 0.544543\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361314; batch adversarial loss: 0.526689\n",
      "epoch 188; iter: 0; batch classifier loss: 0.432021; batch adversarial loss: 0.571227\n",
      "epoch 189; iter: 0; batch classifier loss: 0.243252; batch adversarial loss: 0.544511\n",
      "epoch 190; iter: 0; batch classifier loss: 0.337327; batch adversarial loss: 0.526402\n",
      "epoch 191; iter: 0; batch classifier loss: 0.385054; batch adversarial loss: 0.572016\n",
      "epoch 192; iter: 0; batch classifier loss: 0.301986; batch adversarial loss: 0.626078\n",
      "epoch 193; iter: 0; batch classifier loss: 0.288400; batch adversarial loss: 0.554009\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374763; batch adversarial loss: 0.544552\n",
      "epoch 195; iter: 0; batch classifier loss: 0.395645; batch adversarial loss: 0.553123\n",
      "epoch 196; iter: 0; batch classifier loss: 0.361126; batch adversarial loss: 0.570640\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393432; batch adversarial loss: 0.535644\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349326; batch adversarial loss: 0.544766\n",
      "epoch 199; iter: 0; batch classifier loss: 0.271037; batch adversarial loss: 0.588961\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699122; batch adversarial loss: 0.567763\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571188; batch adversarial loss: 0.682100\n",
      "epoch 2; iter: 0; batch classifier loss: 0.671427; batch adversarial loss: 0.716407\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576383; batch adversarial loss: 0.693034\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546168; batch adversarial loss: 0.630433\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585215; batch adversarial loss: 0.631804\n",
      "epoch 6; iter: 0; batch classifier loss: 0.566966; batch adversarial loss: 0.600887\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607296; batch adversarial loss: 0.658173\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501860; batch adversarial loss: 0.655719\n",
      "epoch 9; iter: 0; batch classifier loss: 0.629680; batch adversarial loss: 0.560874\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572336; batch adversarial loss: 0.649119\n",
      "epoch 11; iter: 0; batch classifier loss: 0.589900; batch adversarial loss: 0.579416\n",
      "epoch 12; iter: 0; batch classifier loss: 0.622112; batch adversarial loss: 0.590037\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553826; batch adversarial loss: 0.571628\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578448; batch adversarial loss: 0.583075\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462574; batch adversarial loss: 0.594776\n",
      "epoch 16; iter: 0; batch classifier loss: 0.557331; batch adversarial loss: 0.498775\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531358; batch adversarial loss: 0.533873\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515993; batch adversarial loss: 0.611246\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523655; batch adversarial loss: 0.573500\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553792; batch adversarial loss: 0.636381\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536837; batch adversarial loss: 0.555278\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423301; batch adversarial loss: 0.536147\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516760; batch adversarial loss: 0.526932\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527303; batch adversarial loss: 0.579746\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442209; batch adversarial loss: 0.539557\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482693; batch adversarial loss: 0.561939\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443203; batch adversarial loss: 0.571643\n",
      "epoch 28; iter: 0; batch classifier loss: 0.508483; batch adversarial loss: 0.571453\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476406; batch adversarial loss: 0.505122\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489438; batch adversarial loss: 0.488318\n",
      "epoch 31; iter: 0; batch classifier loss: 0.503933; batch adversarial loss: 0.580382\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442447; batch adversarial loss: 0.554133\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445355; batch adversarial loss: 0.605202\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434408; batch adversarial loss: 0.613735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.527252; batch adversarial loss: 0.596497\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471057; batch adversarial loss: 0.546278\n",
      "epoch 37; iter: 0; batch classifier loss: 0.413108; batch adversarial loss: 0.485603\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441257; batch adversarial loss: 0.553370\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501833; batch adversarial loss: 0.476741\n",
      "epoch 40; iter: 0; batch classifier loss: 0.365958; batch adversarial loss: 0.578496\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465808; batch adversarial loss: 0.553096\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447352; batch adversarial loss: 0.561809\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440852; batch adversarial loss: 0.554033\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440001; batch adversarial loss: 0.562294\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440953; batch adversarial loss: 0.492691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.384975; batch adversarial loss: 0.545059\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472061; batch adversarial loss: 0.569377\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407810; batch adversarial loss: 0.612909\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422827; batch adversarial loss: 0.563161\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412168; batch adversarial loss: 0.527167\n",
      "epoch 51; iter: 0; batch classifier loss: 0.484786; batch adversarial loss: 0.510474\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446225; batch adversarial loss: 0.544272\n",
      "epoch 53; iter: 0; batch classifier loss: 0.489500; batch adversarial loss: 0.614193\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481708; batch adversarial loss: 0.511472\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446773; batch adversarial loss: 0.527904\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419188; batch adversarial loss: 0.633538\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382448; batch adversarial loss: 0.595219\n",
      "epoch 58; iter: 0; batch classifier loss: 0.489666; batch adversarial loss: 0.544859\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409295; batch adversarial loss: 0.588754\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401776; batch adversarial loss: 0.605833\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401529; batch adversarial loss: 0.579897\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397315; batch adversarial loss: 0.508073\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411960; batch adversarial loss: 0.580109\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405284; batch adversarial loss: 0.517574\n",
      "epoch 65; iter: 0; batch classifier loss: 0.461418; batch adversarial loss: 0.588796\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408120; batch adversarial loss: 0.518352\n",
      "epoch 67; iter: 0; batch classifier loss: 0.517021; batch adversarial loss: 0.545030\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380862; batch adversarial loss: 0.527457\n",
      "epoch 69; iter: 0; batch classifier loss: 0.499214; batch adversarial loss: 0.510086\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380305; batch adversarial loss: 0.571286\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416913; batch adversarial loss: 0.535389\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373970; batch adversarial loss: 0.518569\n",
      "epoch 73; iter: 0; batch classifier loss: 0.335287; batch adversarial loss: 0.562693\n",
      "epoch 74; iter: 0; batch classifier loss: 0.445854; batch adversarial loss: 0.562303\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344896; batch adversarial loss: 0.614667\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378533; batch adversarial loss: 0.570640\n",
      "epoch 77; iter: 0; batch classifier loss: 0.335367; batch adversarial loss: 0.571192\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365786; batch adversarial loss: 0.562214\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410613; batch adversarial loss: 0.518422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455890; batch adversarial loss: 0.544865\n",
      "epoch 81; iter: 0; batch classifier loss: 0.401320; batch adversarial loss: 0.614590\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387282; batch adversarial loss: 0.579788\n",
      "epoch 83; iter: 0; batch classifier loss: 0.327972; batch adversarial loss: 0.571000\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367389; batch adversarial loss: 0.518518\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390608; batch adversarial loss: 0.518180\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395207; batch adversarial loss: 0.482223\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413957; batch adversarial loss: 0.561960\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389560; batch adversarial loss: 0.544949\n",
      "epoch 89; iter: 0; batch classifier loss: 0.445987; batch adversarial loss: 0.527521\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386689; batch adversarial loss: 0.571941\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345280; batch adversarial loss: 0.519379\n",
      "epoch 92; iter: 0; batch classifier loss: 0.444466; batch adversarial loss: 0.605134\n",
      "epoch 93; iter: 0; batch classifier loss: 0.406745; batch adversarial loss: 0.570507\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362866; batch adversarial loss: 0.570422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451417; batch adversarial loss: 0.526537\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335673; batch adversarial loss: 0.649923\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416929; batch adversarial loss: 0.578701\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364762; batch adversarial loss: 0.515957\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422347; batch adversarial loss: 0.616769\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431762; batch adversarial loss: 0.587811\n",
      "epoch 101; iter: 0; batch classifier loss: 0.475474; batch adversarial loss: 0.525558\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351572; batch adversarial loss: 0.545340\n",
      "epoch 103; iter: 0; batch classifier loss: 0.460903; batch adversarial loss: 0.623076\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392865; batch adversarial loss: 0.587646\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413400; batch adversarial loss: 0.552654\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396325; batch adversarial loss: 0.518500\n",
      "epoch 107; iter: 0; batch classifier loss: 0.327719; batch adversarial loss: 0.511100\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334617; batch adversarial loss: 0.501688\n",
      "epoch 109; iter: 0; batch classifier loss: 0.343701; batch adversarial loss: 0.570578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.440846; batch adversarial loss: 0.631904\n",
      "epoch 111; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.571480\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357701; batch adversarial loss: 0.623688\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405856; batch adversarial loss: 0.544983\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433561; batch adversarial loss: 0.562184\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383098; batch adversarial loss: 0.588197\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406577; batch adversarial loss: 0.536563\n",
      "epoch 117; iter: 0; batch classifier loss: 0.435161; batch adversarial loss: 0.605030\n",
      "epoch 118; iter: 0; batch classifier loss: 0.429333; batch adversarial loss: 0.614914\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350385; batch adversarial loss: 0.536298\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409509; batch adversarial loss: 0.500896\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314798; batch adversarial loss: 0.597348\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392423; batch adversarial loss: 0.537161\n",
      "epoch 123; iter: 0; batch classifier loss: 0.299612; batch adversarial loss: 0.579790\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391170; batch adversarial loss: 0.562089\n",
      "epoch 125; iter: 0; batch classifier loss: 0.432189; batch adversarial loss: 0.545085\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403645; batch adversarial loss: 0.536247\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408908; batch adversarial loss: 0.509026\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410323; batch adversarial loss: 0.649380\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377336; batch adversarial loss: 0.570460\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375955; batch adversarial loss: 0.544828\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380508; batch adversarial loss: 0.553351\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378424; batch adversarial loss: 0.632544\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377548; batch adversarial loss: 0.527764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.389524; batch adversarial loss: 0.632521\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362940; batch adversarial loss: 0.527531\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357245; batch adversarial loss: 0.545858\n",
      "epoch 137; iter: 0; batch classifier loss: 0.364991; batch adversarial loss: 0.640866\n",
      "epoch 138; iter: 0; batch classifier loss: 0.316422; batch adversarial loss: 0.579777\n",
      "epoch 139; iter: 0; batch classifier loss: 0.455061; batch adversarial loss: 0.527270\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332010; batch adversarial loss: 0.632261\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420153; batch adversarial loss: 0.562995\n",
      "epoch 142; iter: 0; batch classifier loss: 0.482778; batch adversarial loss: 0.650139\n",
      "epoch 143; iter: 0; batch classifier loss: 0.427711; batch adversarial loss: 0.562830\n",
      "epoch 144; iter: 0; batch classifier loss: 0.307652; batch adversarial loss: 0.562043\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346279; batch adversarial loss: 0.544962\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330769; batch adversarial loss: 0.466448\n",
      "epoch 147; iter: 0; batch classifier loss: 0.409152; batch adversarial loss: 0.579752\n",
      "epoch 148; iter: 0; batch classifier loss: 0.430439; batch adversarial loss: 0.623927\n",
      "epoch 149; iter: 0; batch classifier loss: 0.411198; batch adversarial loss: 0.614314\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377142; batch adversarial loss: 0.474678\n",
      "epoch 151; iter: 0; batch classifier loss: 0.414863; batch adversarial loss: 0.606118\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369993; batch adversarial loss: 0.597972\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327767; batch adversarial loss: 0.597562\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347148; batch adversarial loss: 0.501591\n",
      "epoch 155; iter: 0; batch classifier loss: 0.313967; batch adversarial loss: 0.562119\n",
      "epoch 156; iter: 0; batch classifier loss: 0.409683; batch adversarial loss: 0.519308\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385233; batch adversarial loss: 0.527337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354915; batch adversarial loss: 0.597737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.491085; batch adversarial loss: 0.544548\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352952; batch adversarial loss: 0.597514\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385549; batch adversarial loss: 0.561857\n",
      "epoch 162; iter: 0; batch classifier loss: 0.399524; batch adversarial loss: 0.570554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382566; batch adversarial loss: 0.632059\n",
      "epoch 164; iter: 0; batch classifier loss: 0.294890; batch adversarial loss: 0.492349\n",
      "epoch 165; iter: 0; batch classifier loss: 0.311136; batch adversarial loss: 0.501620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353673; batch adversarial loss: 0.536054\n",
      "epoch 167; iter: 0; batch classifier loss: 0.464276; batch adversarial loss: 0.571832\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329960; batch adversarial loss: 0.553485\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380698; batch adversarial loss: 0.561870\n",
      "epoch 170; iter: 0; batch classifier loss: 0.432343; batch adversarial loss: 0.632727\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388603; batch adversarial loss: 0.588143\n",
      "epoch 172; iter: 0; batch classifier loss: 0.352072; batch adversarial loss: 0.597270\n",
      "epoch 173; iter: 0; batch classifier loss: 0.328020; batch adversarial loss: 0.562501\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393355; batch adversarial loss: 0.622590\n",
      "epoch 175; iter: 0; batch classifier loss: 0.408269; batch adversarial loss: 0.526950\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366925; batch adversarial loss: 0.571179\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309552; batch adversarial loss: 0.553608\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368926; batch adversarial loss: 0.544487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.324650; batch adversarial loss: 0.580103\n",
      "epoch 180; iter: 0; batch classifier loss: 0.412423; batch adversarial loss: 0.518624\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339092; batch adversarial loss: 0.554179\n",
      "epoch 182; iter: 0; batch classifier loss: 0.326103; batch adversarial loss: 0.579917\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351116; batch adversarial loss: 0.502770\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329337; batch adversarial loss: 0.527571\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345268; batch adversarial loss: 0.545137\n",
      "epoch 186; iter: 0; batch classifier loss: 0.464997; batch adversarial loss: 0.589134\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343408; batch adversarial loss: 0.553853\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395394; batch adversarial loss: 0.587869\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315997; batch adversarial loss: 0.588467\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322739; batch adversarial loss: 0.562701\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366293; batch adversarial loss: 0.588577\n",
      "epoch 192; iter: 0; batch classifier loss: 0.294856; batch adversarial loss: 0.527606\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389020; batch adversarial loss: 0.588498\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358695; batch adversarial loss: 0.492357\n",
      "epoch 195; iter: 0; batch classifier loss: 0.324071; batch adversarial loss: 0.537183\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341614; batch adversarial loss: 0.518997\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407947; batch adversarial loss: 0.509687\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378998; batch adversarial loss: 0.553566\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366006; batch adversarial loss: 0.588059\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663428; batch adversarial loss: 0.644086\n",
      "epoch 1; iter: 0; batch classifier loss: 0.576565; batch adversarial loss: 0.649312\n",
      "epoch 2; iter: 0; batch classifier loss: 0.645917; batch adversarial loss: 0.594509\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576476; batch adversarial loss: 0.606378\n",
      "epoch 4; iter: 0; batch classifier loss: 0.526535; batch adversarial loss: 0.610547\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521619; batch adversarial loss: 0.625373\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486692; batch adversarial loss: 0.617588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547477; batch adversarial loss: 0.626809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525753; batch adversarial loss: 0.639970\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578709; batch adversarial loss: 0.585151\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558330; batch adversarial loss: 0.636487\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580584; batch adversarial loss: 0.560017\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480245; batch adversarial loss: 0.580749\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584359; batch adversarial loss: 0.595446\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514180; batch adversarial loss: 0.566470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.551187; batch adversarial loss: 0.575571\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510780; batch adversarial loss: 0.607263\n",
      "epoch 17; iter: 0; batch classifier loss: 0.679364; batch adversarial loss: 0.543287\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502140; batch adversarial loss: 0.540171\n",
      "epoch 19; iter: 0; batch classifier loss: 0.578576; batch adversarial loss: 0.525713\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521222; batch adversarial loss: 0.562981\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488781; batch adversarial loss: 0.588423\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471955; batch adversarial loss: 0.589872\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522943; batch adversarial loss: 0.496727\n",
      "epoch 24; iter: 0; batch classifier loss: 0.450660; batch adversarial loss: 0.556220\n",
      "epoch 25; iter: 0; batch classifier loss: 0.543418; batch adversarial loss: 0.540440\n",
      "epoch 26; iter: 0; batch classifier loss: 0.488136; batch adversarial loss: 0.602595\n",
      "epoch 27; iter: 0; batch classifier loss: 0.438100; batch adversarial loss: 0.578188\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460888; batch adversarial loss: 0.545562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437210; batch adversarial loss: 0.554158\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482076; batch adversarial loss: 0.512589\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479128; batch adversarial loss: 0.552772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.437484; batch adversarial loss: 0.553127\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469018; batch adversarial loss: 0.526844\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462960; batch adversarial loss: 0.562832\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482250; batch adversarial loss: 0.554390\n",
      "epoch 36; iter: 0; batch classifier loss: 0.394301; batch adversarial loss: 0.511665\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414731; batch adversarial loss: 0.545600\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429602; batch adversarial loss: 0.570586\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437936; batch adversarial loss: 0.472525\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462625; batch adversarial loss: 0.617077\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404134; batch adversarial loss: 0.544071\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406588; batch adversarial loss: 0.605698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409934; batch adversarial loss: 0.525458\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485523; batch adversarial loss: 0.471268\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466345; batch adversarial loss: 0.579311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380772; batch adversarial loss: 0.635177\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415977; batch adversarial loss: 0.490254\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404937; batch adversarial loss: 0.543859\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443550; batch adversarial loss: 0.572436\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422322; batch adversarial loss: 0.599469\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446089; batch adversarial loss: 0.499893\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390367; batch adversarial loss: 0.491750\n",
      "epoch 53; iter: 0; batch classifier loss: 0.463220; batch adversarial loss: 0.455074\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423497; batch adversarial loss: 0.553196\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436710; batch adversarial loss: 0.571552\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437631; batch adversarial loss: 0.554074\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427079; batch adversarial loss: 0.544385\n",
      "epoch 58; iter: 0; batch classifier loss: 0.552212; batch adversarial loss: 0.535523\n",
      "epoch 59; iter: 0; batch classifier loss: 0.403705; batch adversarial loss: 0.553296\n",
      "epoch 60; iter: 0; batch classifier loss: 0.470485; batch adversarial loss: 0.607119\n",
      "epoch 61; iter: 0; batch classifier loss: 0.478622; batch adversarial loss: 0.562605\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427021; batch adversarial loss: 0.580672\n",
      "epoch 63; iter: 0; batch classifier loss: 0.342764; batch adversarial loss: 0.490482\n",
      "epoch 64; iter: 0; batch classifier loss: 0.446264; batch adversarial loss: 0.491045\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435228; batch adversarial loss: 0.517805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.349740; batch adversarial loss: 0.553604\n",
      "epoch 67; iter: 0; batch classifier loss: 0.457503; batch adversarial loss: 0.624282\n",
      "epoch 68; iter: 0; batch classifier loss: 0.440769; batch adversarial loss: 0.554401\n",
      "epoch 69; iter: 0; batch classifier loss: 0.345457; batch adversarial loss: 0.501160\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384067; batch adversarial loss: 0.554495\n",
      "epoch 71; iter: 0; batch classifier loss: 0.482968; batch adversarial loss: 0.544882\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382192; batch adversarial loss: 0.552449\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396319; batch adversarial loss: 0.517324\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454756; batch adversarial loss: 0.428175\n",
      "epoch 75; iter: 0; batch classifier loss: 0.487801; batch adversarial loss: 0.562405\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373038; batch adversarial loss: 0.500304\n",
      "epoch 77; iter: 0; batch classifier loss: 0.330831; batch adversarial loss: 0.515743\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389568; batch adversarial loss: 0.545065\n",
      "epoch 79; iter: 0; batch classifier loss: 0.489091; batch adversarial loss: 0.553566\n",
      "epoch 80; iter: 0; batch classifier loss: 0.362378; batch adversarial loss: 0.508391\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410407; batch adversarial loss: 0.553610\n",
      "epoch 82; iter: 0; batch classifier loss: 0.287177; batch adversarial loss: 0.562972\n",
      "epoch 83; iter: 0; batch classifier loss: 0.335370; batch adversarial loss: 0.489969\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400045; batch adversarial loss: 0.635553\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402940; batch adversarial loss: 0.499111\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428634; batch adversarial loss: 0.562511\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369106; batch adversarial loss: 0.526169\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405030; batch adversarial loss: 0.562559\n",
      "epoch 89; iter: 0; batch classifier loss: 0.305241; batch adversarial loss: 0.535456\n",
      "epoch 90; iter: 0; batch classifier loss: 0.335233; batch adversarial loss: 0.481763\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388211; batch adversarial loss: 0.599730\n",
      "epoch 92; iter: 0; batch classifier loss: 0.463046; batch adversarial loss: 0.489766\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429919; batch adversarial loss: 0.509353\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363576; batch adversarial loss: 0.587482\n",
      "epoch 95; iter: 0; batch classifier loss: 0.489528; batch adversarial loss: 0.517518\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429455; batch adversarial loss: 0.615923\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423163; batch adversarial loss: 0.526924\n",
      "epoch 98; iter: 0; batch classifier loss: 0.440038; batch adversarial loss: 0.570906\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356767; batch adversarial loss: 0.624667\n",
      "epoch 100; iter: 0; batch classifier loss: 0.437320; batch adversarial loss: 0.562389\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352495; batch adversarial loss: 0.589612\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348387; batch adversarial loss: 0.535524\n",
      "epoch 103; iter: 0; batch classifier loss: 0.421659; batch adversarial loss: 0.617986\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422528; batch adversarial loss: 0.471352\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364649; batch adversarial loss: 0.544855\n",
      "epoch 106; iter: 0; batch classifier loss: 0.313537; batch adversarial loss: 0.553609\n",
      "epoch 107; iter: 0; batch classifier loss: 0.360108; batch adversarial loss: 0.562600\n",
      "epoch 108; iter: 0; batch classifier loss: 0.482631; batch adversarial loss: 0.580888\n",
      "epoch 109; iter: 0; batch classifier loss: 0.343366; batch adversarial loss: 0.580738\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396179; batch adversarial loss: 0.526731\n",
      "epoch 111; iter: 0; batch classifier loss: 0.304865; batch adversarial loss: 0.588753\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336836; batch adversarial loss: 0.545869\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389151; batch adversarial loss: 0.562348\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412142; batch adversarial loss: 0.526291\n",
      "epoch 115; iter: 0; batch classifier loss: 0.376021; batch adversarial loss: 0.454908\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400697; batch adversarial loss: 0.580639\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392270; batch adversarial loss: 0.580397\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371130; batch adversarial loss: 0.562655\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428997; batch adversarial loss: 0.535864\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328344; batch adversarial loss: 0.581040\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374347; batch adversarial loss: 0.535512\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346445; batch adversarial loss: 0.517165\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423965; batch adversarial loss: 0.499179\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325207; batch adversarial loss: 0.535745\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410244; batch adversarial loss: 0.571761\n",
      "epoch 126; iter: 0; batch classifier loss: 0.343478; batch adversarial loss: 0.625997\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344139; batch adversarial loss: 0.499238\n",
      "epoch 128; iter: 0; batch classifier loss: 0.407471; batch adversarial loss: 0.571141\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379216; batch adversarial loss: 0.562967\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382354; batch adversarial loss: 0.607490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.387932; batch adversarial loss: 0.535165\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400088; batch adversarial loss: 0.526514\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326310; batch adversarial loss: 0.589677\n",
      "epoch 134; iter: 0; batch classifier loss: 0.451957; batch adversarial loss: 0.453236\n",
      "epoch 135; iter: 0; batch classifier loss: 0.396507; batch adversarial loss: 0.580258\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387726; batch adversarial loss: 0.562922\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357995; batch adversarial loss: 0.545034\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.580355\n",
      "epoch 139; iter: 0; batch classifier loss: 0.337849; batch adversarial loss: 0.563417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.465509; batch adversarial loss: 0.500232\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358408; batch adversarial loss: 0.634819\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400444; batch adversarial loss: 0.545214\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363897; batch adversarial loss: 0.499688\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408172; batch adversarial loss: 0.597636\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331577; batch adversarial loss: 0.553090\n",
      "epoch 146; iter: 0; batch classifier loss: 0.322883; batch adversarial loss: 0.535587\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373247; batch adversarial loss: 0.562718\n",
      "epoch 148; iter: 0; batch classifier loss: 0.428842; batch adversarial loss: 0.599590\n",
      "epoch 149; iter: 0; batch classifier loss: 0.434124; batch adversarial loss: 0.544153\n",
      "epoch 150; iter: 0; batch classifier loss: 0.328032; batch adversarial loss: 0.535727\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374632; batch adversarial loss: 0.589683\n",
      "epoch 152; iter: 0; batch classifier loss: 0.392493; batch adversarial loss: 0.517253\n",
      "epoch 153; iter: 0; batch classifier loss: 0.429564; batch adversarial loss: 0.553527\n",
      "epoch 154; iter: 0; batch classifier loss: 0.411891; batch adversarial loss: 0.579958\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373934; batch adversarial loss: 0.562961\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387309; batch adversarial loss: 0.489749\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331730; batch adversarial loss: 0.525938\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333870; batch adversarial loss: 0.525948\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339611; batch adversarial loss: 0.580279\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374179; batch adversarial loss: 0.544354\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319320; batch adversarial loss: 0.589247\n",
      "epoch 162; iter: 0; batch classifier loss: 0.396431; batch adversarial loss: 0.526337\n",
      "epoch 163; iter: 0; batch classifier loss: 0.294636; batch adversarial loss: 0.535889\n",
      "epoch 164; iter: 0; batch classifier loss: 0.281044; batch adversarial loss: 0.526166\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346072; batch adversarial loss: 0.590386\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349942; batch adversarial loss: 0.508468\n",
      "epoch 167; iter: 0; batch classifier loss: 0.322419; batch adversarial loss: 0.616669\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356362; batch adversarial loss: 0.517479\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407821; batch adversarial loss: 0.653808\n",
      "epoch 170; iter: 0; batch classifier loss: 0.277072; batch adversarial loss: 0.562952\n",
      "epoch 171; iter: 0; batch classifier loss: 0.350486; batch adversarial loss: 0.499555\n",
      "epoch 172; iter: 0; batch classifier loss: 0.434918; batch adversarial loss: 0.499408\n",
      "epoch 173; iter: 0; batch classifier loss: 0.408251; batch adversarial loss: 0.563402\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365244; batch adversarial loss: 0.580458\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330635; batch adversarial loss: 0.563213\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316278; batch adversarial loss: 0.535457\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321900; batch adversarial loss: 0.517433\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361596; batch adversarial loss: 0.563151\n",
      "epoch 179; iter: 0; batch classifier loss: 0.393559; batch adversarial loss: 0.526004\n",
      "epoch 180; iter: 0; batch classifier loss: 0.410463; batch adversarial loss: 0.526566\n",
      "epoch 181; iter: 0; batch classifier loss: 0.417248; batch adversarial loss: 0.526443\n",
      "epoch 182; iter: 0; batch classifier loss: 0.323085; batch adversarial loss: 0.499249\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367000; batch adversarial loss: 0.544540\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390408; batch adversarial loss: 0.580908\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281689; batch adversarial loss: 0.634627\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347349; batch adversarial loss: 0.544898\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359295; batch adversarial loss: 0.608100\n",
      "epoch 188; iter: 0; batch classifier loss: 0.403721; batch adversarial loss: 0.572184\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292043; batch adversarial loss: 0.571169\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400168; batch adversarial loss: 0.481726\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362185; batch adversarial loss: 0.490231\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384933; batch adversarial loss: 0.535199\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318207; batch adversarial loss: 0.526768\n",
      "epoch 194; iter: 0; batch classifier loss: 0.294166; batch adversarial loss: 0.544208\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374119; batch adversarial loss: 0.463068\n",
      "epoch 196; iter: 0; batch classifier loss: 0.295975; batch adversarial loss: 0.535697\n",
      "epoch 197; iter: 0; batch classifier loss: 0.299444; batch adversarial loss: 0.482042\n",
      "epoch 198; iter: 0; batch classifier loss: 0.373486; batch adversarial loss: 0.544634\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366888; batch adversarial loss: 0.498766\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667690; batch adversarial loss: 0.851116\n",
      "epoch 1; iter: 0; batch classifier loss: 0.939254; batch adversarial loss: 1.224383\n",
      "epoch 2; iter: 0; batch classifier loss: 0.983649; batch adversarial loss: 1.149366\n",
      "epoch 3; iter: 0; batch classifier loss: 1.219196; batch adversarial loss: 1.078985\n",
      "epoch 4; iter: 0; batch classifier loss: 1.091454; batch adversarial loss: 0.980963\n",
      "epoch 5; iter: 0; batch classifier loss: 1.198186; batch adversarial loss: 0.921875\n",
      "epoch 6; iter: 0; batch classifier loss: 1.276740; batch adversarial loss: 0.862043\n",
      "epoch 7; iter: 0; batch classifier loss: 1.050770; batch adversarial loss: 0.783043\n",
      "epoch 8; iter: 0; batch classifier loss: 1.102632; batch adversarial loss: 0.739206\n",
      "epoch 9; iter: 0; batch classifier loss: 1.039673; batch adversarial loss: 0.694897\n",
      "epoch 10; iter: 0; batch classifier loss: 0.823986; batch adversarial loss: 0.664306\n",
      "epoch 11; iter: 0; batch classifier loss: 0.720460; batch adversarial loss: 0.619601\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590267; batch adversarial loss: 0.573387\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533052; batch adversarial loss: 0.611096\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530425; batch adversarial loss: 0.585844\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490668; batch adversarial loss: 0.584649\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552160; batch adversarial loss: 0.581196\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514250; batch adversarial loss: 0.594808\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532974; batch adversarial loss: 0.598110\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513953; batch adversarial loss: 0.594331\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572241; batch adversarial loss: 0.529174\n",
      "epoch 21; iter: 0; batch classifier loss: 0.506269; batch adversarial loss: 0.555233\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474639; batch adversarial loss: 0.551441\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475819; batch adversarial loss: 0.550546\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481530; batch adversarial loss: 0.542382\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465318; batch adversarial loss: 0.589750\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502036; batch adversarial loss: 0.549354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.432401; batch adversarial loss: 0.549454\n",
      "epoch 28; iter: 0; batch classifier loss: 0.545588; batch adversarial loss: 0.539746\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460569; batch adversarial loss: 0.485072\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514386; batch adversarial loss: 0.601305\n",
      "epoch 31; iter: 0; batch classifier loss: 0.530298; batch adversarial loss: 0.541983\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536782; batch adversarial loss: 0.528761\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514465; batch adversarial loss: 0.523125\n",
      "epoch 34; iter: 0; batch classifier loss: 0.512514; batch adversarial loss: 0.518462\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445853; batch adversarial loss: 0.570849\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450775; batch adversarial loss: 0.491275\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412641; batch adversarial loss: 0.494583\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454736; batch adversarial loss: 0.550021\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404762; batch adversarial loss: 0.459884\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456432; batch adversarial loss: 0.542816\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418880; batch adversarial loss: 0.518910\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461918; batch adversarial loss: 0.599799\n",
      "epoch 43; iter: 0; batch classifier loss: 0.525807; batch adversarial loss: 0.507994\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488972; batch adversarial loss: 0.565187\n",
      "epoch 45; iter: 0; batch classifier loss: 0.345249; batch adversarial loss: 0.521048\n",
      "epoch 46; iter: 0; batch classifier loss: 0.365561; batch adversarial loss: 0.548215\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419930; batch adversarial loss: 0.600591\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447310; batch adversarial loss: 0.589987\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404439; batch adversarial loss: 0.596105\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422896; batch adversarial loss: 0.531576\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397697; batch adversarial loss: 0.608122\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417646; batch adversarial loss: 0.521261\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450938; batch adversarial loss: 0.564200\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457048; batch adversarial loss: 0.581773\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482847; batch adversarial loss: 0.535790\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412862; batch adversarial loss: 0.536124\n",
      "epoch 57; iter: 0; batch classifier loss: 0.492017; batch adversarial loss: 0.508606\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400877; batch adversarial loss: 0.472390\n",
      "epoch 59; iter: 0; batch classifier loss: 0.393484; batch adversarial loss: 0.526275\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427464; batch adversarial loss: 0.588221\n",
      "epoch 61; iter: 0; batch classifier loss: 0.359440; batch adversarial loss: 0.546811\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378835; batch adversarial loss: 0.609326\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397195; batch adversarial loss: 0.573210\n",
      "epoch 64; iter: 0; batch classifier loss: 0.495222; batch adversarial loss: 0.537329\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457647; batch adversarial loss: 0.436546\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403492; batch adversarial loss: 0.626811\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401225; batch adversarial loss: 0.499508\n",
      "epoch 68; iter: 0; batch classifier loss: 0.338208; batch adversarial loss: 0.588836\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387664; batch adversarial loss: 0.536930\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369298; batch adversarial loss: 0.533940\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406211; batch adversarial loss: 0.550918\n",
      "epoch 72; iter: 0; batch classifier loss: 0.465095; batch adversarial loss: 0.499030\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385164; batch adversarial loss: 0.532936\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393822; batch adversarial loss: 0.542284\n",
      "epoch 75; iter: 0; batch classifier loss: 0.336778; batch adversarial loss: 0.573371\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373175; batch adversarial loss: 0.552399\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360903; batch adversarial loss: 0.569432\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387010; batch adversarial loss: 0.489850\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353781; batch adversarial loss: 0.493916\n",
      "epoch 80; iter: 0; batch classifier loss: 0.448456; batch adversarial loss: 0.632360\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430395; batch adversarial loss: 0.506990\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401148; batch adversarial loss: 0.563416\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396541; batch adversarial loss: 0.578768\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355624; batch adversarial loss: 0.548557\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403610; batch adversarial loss: 0.525606\n",
      "epoch 86; iter: 0; batch classifier loss: 0.375919; batch adversarial loss: 0.499079\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398211; batch adversarial loss: 0.603341\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398808; batch adversarial loss: 0.569739\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366603; batch adversarial loss: 0.483253\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369192; batch adversarial loss: 0.622941\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348813; batch adversarial loss: 0.621482\n",
      "epoch 92; iter: 0; batch classifier loss: 0.416838; batch adversarial loss: 0.582358\n",
      "epoch 93; iter: 0; batch classifier loss: 0.360267; batch adversarial loss: 0.518097\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372390; batch adversarial loss: 0.571712\n",
      "epoch 95; iter: 0; batch classifier loss: 0.385617; batch adversarial loss: 0.576872\n",
      "epoch 96; iter: 0; batch classifier loss: 0.437700; batch adversarial loss: 0.528438\n",
      "epoch 97; iter: 0; batch classifier loss: 0.465056; batch adversarial loss: 0.598380\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365498; batch adversarial loss: 0.515040\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429913; batch adversarial loss: 0.533742\n",
      "epoch 100; iter: 0; batch classifier loss: 0.435166; batch adversarial loss: 0.607826\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387224; batch adversarial loss: 0.570529\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413854; batch adversarial loss: 0.491884\n",
      "epoch 103; iter: 0; batch classifier loss: 0.428084; batch adversarial loss: 0.488817\n",
      "epoch 104; iter: 0; batch classifier loss: 0.360023; batch adversarial loss: 0.562942\n",
      "epoch 105; iter: 0; batch classifier loss: 0.386246; batch adversarial loss: 0.543900\n",
      "epoch 106; iter: 0; batch classifier loss: 0.332099; batch adversarial loss: 0.597846\n",
      "epoch 107; iter: 0; batch classifier loss: 0.437747; batch adversarial loss: 0.615147\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363939; batch adversarial loss: 0.510013\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422597; batch adversarial loss: 0.628792\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379830; batch adversarial loss: 0.613707\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431804; batch adversarial loss: 0.552143\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367437; batch adversarial loss: 0.542924\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357797; batch adversarial loss: 0.489448\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327227; batch adversarial loss: 0.546239\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407286; batch adversarial loss: 0.592300\n",
      "epoch 116; iter: 0; batch classifier loss: 0.306238; batch adversarial loss: 0.560754\n",
      "epoch 117; iter: 0; batch classifier loss: 0.260137; batch adversarial loss: 0.606999\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399058; batch adversarial loss: 0.509100\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368185; batch adversarial loss: 0.534756\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379067; batch adversarial loss: 0.568135\n",
      "epoch 121; iter: 0; batch classifier loss: 0.280188; batch adversarial loss: 0.500960\n",
      "epoch 122; iter: 0; batch classifier loss: 0.274942; batch adversarial loss: 0.580551\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363947; batch adversarial loss: 0.501094\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359411; batch adversarial loss: 0.498770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.338987; batch adversarial loss: 0.558704\n",
      "epoch 126; iter: 0; batch classifier loss: 0.371163; batch adversarial loss: 0.498803\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371474; batch adversarial loss: 0.551363\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342339; batch adversarial loss: 0.633704\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329250; batch adversarial loss: 0.616183\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370248; batch adversarial loss: 0.582569\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374054; batch adversarial loss: 0.471433\n",
      "epoch 132; iter: 0; batch classifier loss: 0.314420; batch adversarial loss: 0.619880\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376310; batch adversarial loss: 0.653282\n",
      "epoch 134; iter: 0; batch classifier loss: 0.432643; batch adversarial loss: 0.536273\n",
      "epoch 135; iter: 0; batch classifier loss: 0.329149; batch adversarial loss: 0.473774\n",
      "epoch 136; iter: 0; batch classifier loss: 0.298109; batch adversarial loss: 0.525032\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366303; batch adversarial loss: 0.503080\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344969; batch adversarial loss: 0.554503\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350303; batch adversarial loss: 0.560050\n",
      "epoch 140; iter: 0; batch classifier loss: 0.307219; batch adversarial loss: 0.562611\n",
      "epoch 141; iter: 0; batch classifier loss: 0.320181; batch adversarial loss: 0.556995\n",
      "epoch 142; iter: 0; batch classifier loss: 0.315609; batch adversarial loss: 0.473875\n",
      "epoch 143; iter: 0; batch classifier loss: 0.292887; batch adversarial loss: 0.519920\n",
      "epoch 144; iter: 0; batch classifier loss: 0.242552; batch adversarial loss: 0.580130\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347859; batch adversarial loss: 0.560573\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343891; batch adversarial loss: 0.525716\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338380; batch adversarial loss: 0.626972\n",
      "epoch 148; iter: 0; batch classifier loss: 0.475701; batch adversarial loss: 0.534646\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326678; batch adversarial loss: 0.562130\n",
      "epoch 150; iter: 0; batch classifier loss: 0.321580; batch adversarial loss: 0.534246\n",
      "epoch 151; iter: 0; batch classifier loss: 0.315647; batch adversarial loss: 0.516429\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368101; batch adversarial loss: 0.533464\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316872; batch adversarial loss: 0.581422\n",
      "epoch 154; iter: 0; batch classifier loss: 0.312761; batch adversarial loss: 0.606306\n",
      "epoch 155; iter: 0; batch classifier loss: 0.287124; batch adversarial loss: 0.526896\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314772; batch adversarial loss: 0.544264\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342901; batch adversarial loss: 0.453269\n",
      "epoch 158; iter: 0; batch classifier loss: 0.302083; batch adversarial loss: 0.497684\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332347; batch adversarial loss: 0.544089\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369446; batch adversarial loss: 0.620804\n",
      "epoch 161; iter: 0; batch classifier loss: 0.254382; batch adversarial loss: 0.563252\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356821; batch adversarial loss: 0.589861\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334000; batch adversarial loss: 0.498988\n",
      "epoch 164; iter: 0; batch classifier loss: 0.325404; batch adversarial loss: 0.559350\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371451; batch adversarial loss: 0.506420\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395467; batch adversarial loss: 0.553899\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390380; batch adversarial loss: 0.572678\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361720; batch adversarial loss: 0.591050\n",
      "epoch 169; iter: 0; batch classifier loss: 0.294755; batch adversarial loss: 0.508282\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329508; batch adversarial loss: 0.526819\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316746; batch adversarial loss: 0.604109\n",
      "epoch 172; iter: 0; batch classifier loss: 0.390200; batch adversarial loss: 0.581346\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344728; batch adversarial loss: 0.498562\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362070; batch adversarial loss: 0.572005\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331002; batch adversarial loss: 0.498740\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340521; batch adversarial loss: 0.509381\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.527269\n",
      "epoch 178; iter: 0; batch classifier loss: 0.291064; batch adversarial loss: 0.509175\n",
      "epoch 179; iter: 0; batch classifier loss: 0.299036; batch adversarial loss: 0.554943\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355685; batch adversarial loss: 0.509682\n",
      "epoch 181; iter: 0; batch classifier loss: 0.302529; batch adversarial loss: 0.606186\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391542; batch adversarial loss: 0.507704\n",
      "epoch 183; iter: 0; batch classifier loss: 0.309492; batch adversarial loss: 0.618385\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386634; batch adversarial loss: 0.554421\n",
      "epoch 185; iter: 0; batch classifier loss: 0.297647; batch adversarial loss: 0.518679\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393680; batch adversarial loss: 0.598909\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382787; batch adversarial loss: 0.410827\n",
      "epoch 188; iter: 0; batch classifier loss: 0.457769; batch adversarial loss: 0.516001\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331763; batch adversarial loss: 0.545072\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379314; batch adversarial loss: 0.506464\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334155; batch adversarial loss: 0.588008\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355498; batch adversarial loss: 0.435724\n",
      "epoch 193; iter: 0; batch classifier loss: 0.323384; batch adversarial loss: 0.562145\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393931; batch adversarial loss: 0.506857\n",
      "epoch 195; iter: 0; batch classifier loss: 0.324325; batch adversarial loss: 0.614911\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328338; batch adversarial loss: 0.535211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.310297; batch adversarial loss: 0.551010\n",
      "epoch 198; iter: 0; batch classifier loss: 0.295091; batch adversarial loss: 0.604809\n",
      "epoch 199; iter: 0; batch classifier loss: 0.320731; batch adversarial loss: 0.573429\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711436; batch adversarial loss: 0.673169\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572634; batch adversarial loss: 0.664203\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574134; batch adversarial loss: 0.659281\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619625; batch adversarial loss: 0.615561\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538731; batch adversarial loss: 0.601447\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573506; batch adversarial loss: 0.630475\n",
      "epoch 6; iter: 0; batch classifier loss: 0.461184; batch adversarial loss: 0.607440\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492902; batch adversarial loss: 0.546665\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538572; batch adversarial loss: 0.615094\n",
      "epoch 9; iter: 0; batch classifier loss: 0.619476; batch adversarial loss: 0.588764\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519852; batch adversarial loss: 0.589280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490229; batch adversarial loss: 0.566142\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572181; batch adversarial loss: 0.597567\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481447; batch adversarial loss: 0.567303\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505655; batch adversarial loss: 0.598412\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442431; batch adversarial loss: 0.573183\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533794; batch adversarial loss: 0.546084\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472920; batch adversarial loss: 0.572792\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489286; batch adversarial loss: 0.573213\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499442; batch adversarial loss: 0.512848\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529995; batch adversarial loss: 0.523573\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475501; batch adversarial loss: 0.561240\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529257; batch adversarial loss: 0.551467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.508682; batch adversarial loss: 0.527073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448428; batch adversarial loss: 0.587252\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504870; batch adversarial loss: 0.571901\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472238; batch adversarial loss: 0.490570\n",
      "epoch 27; iter: 0; batch classifier loss: 0.378767; batch adversarial loss: 0.580228\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450715; batch adversarial loss: 0.536243\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461123; batch adversarial loss: 0.493557\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457626; batch adversarial loss: 0.579542\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433059; batch adversarial loss: 0.552684\n",
      "epoch 32; iter: 0; batch classifier loss: 0.508277; batch adversarial loss: 0.545025\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462468; batch adversarial loss: 0.536581\n",
      "epoch 34; iter: 0; batch classifier loss: 0.388493; batch adversarial loss: 0.580742\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449561; batch adversarial loss: 0.562514\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445360; batch adversarial loss: 0.518134\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445154; batch adversarial loss: 0.553043\n",
      "epoch 38; iter: 0; batch classifier loss: 0.487437; batch adversarial loss: 0.652083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491554; batch adversarial loss: 0.534042\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476711; batch adversarial loss: 0.564475\n",
      "epoch 41; iter: 0; batch classifier loss: 0.387935; batch adversarial loss: 0.581883\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478066; batch adversarial loss: 0.543574\n",
      "epoch 43; iter: 0; batch classifier loss: 0.497276; batch adversarial loss: 0.596712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406665; batch adversarial loss: 0.528268\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461390; batch adversarial loss: 0.542965\n",
      "epoch 46; iter: 0; batch classifier loss: 0.520178; batch adversarial loss: 0.515865\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407124; batch adversarial loss: 0.572886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392862; batch adversarial loss: 0.535128\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431736; batch adversarial loss: 0.556506\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462221; batch adversarial loss: 0.587290\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454043; batch adversarial loss: 0.588036\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465696; batch adversarial loss: 0.523940\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412088; batch adversarial loss: 0.542101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385344; batch adversarial loss: 0.546087\n",
      "epoch 55; iter: 0; batch classifier loss: 0.456084; batch adversarial loss: 0.553528\n",
      "epoch 56; iter: 0; batch classifier loss: 0.406658; batch adversarial loss: 0.527987\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453130; batch adversarial loss: 0.607927\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399034; batch adversarial loss: 0.499873\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383316; batch adversarial loss: 0.509782\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432552; batch adversarial loss: 0.549463\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400151; batch adversarial loss: 0.609522\n",
      "epoch 62; iter: 0; batch classifier loss: 0.317135; batch adversarial loss: 0.564545\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378280; batch adversarial loss: 0.576135\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428130; batch adversarial loss: 0.543786\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466262; batch adversarial loss: 0.594234\n",
      "epoch 66; iter: 0; batch classifier loss: 0.492569; batch adversarial loss: 0.482725\n",
      "epoch 67; iter: 0; batch classifier loss: 0.473030; batch adversarial loss: 0.560282\n",
      "epoch 68; iter: 0; batch classifier loss: 0.367786; batch adversarial loss: 0.526572\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414017; batch adversarial loss: 0.568134\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425600; batch adversarial loss: 0.529888\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358343; batch adversarial loss: 0.621459\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372704; batch adversarial loss: 0.543988\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369921; batch adversarial loss: 0.506053\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454199; batch adversarial loss: 0.645312\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401269; batch adversarial loss: 0.518412\n",
      "epoch 76; iter: 0; batch classifier loss: 0.329904; batch adversarial loss: 0.579359\n",
      "epoch 77; iter: 0; batch classifier loss: 0.320414; batch adversarial loss: 0.636103\n",
      "epoch 78; iter: 0; batch classifier loss: 0.499255; batch adversarial loss: 0.598671\n",
      "epoch 79; iter: 0; batch classifier loss: 0.441983; batch adversarial loss: 0.506202\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447803; batch adversarial loss: 0.522562\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384850; batch adversarial loss: 0.550909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413738; batch adversarial loss: 0.480127\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402767; batch adversarial loss: 0.530244\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429162; batch adversarial loss: 0.488901\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347784; batch adversarial loss: 0.579794\n",
      "epoch 86; iter: 0; batch classifier loss: 0.306190; batch adversarial loss: 0.570343\n",
      "epoch 87; iter: 0; batch classifier loss: 0.478065; batch adversarial loss: 0.545859\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367608; batch adversarial loss: 0.524790\n",
      "epoch 89; iter: 0; batch classifier loss: 0.303066; batch adversarial loss: 0.555818\n",
      "epoch 90; iter: 0; batch classifier loss: 0.332667; batch adversarial loss: 0.562945\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345808; batch adversarial loss: 0.560903\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385146; batch adversarial loss: 0.574769\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450559; batch adversarial loss: 0.505595\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446848; batch adversarial loss: 0.528891\n",
      "epoch 95; iter: 0; batch classifier loss: 0.483532; batch adversarial loss: 0.525484\n",
      "epoch 96; iter: 0; batch classifier loss: 0.466117; batch adversarial loss: 0.558647\n",
      "epoch 97; iter: 0; batch classifier loss: 0.316199; batch adversarial loss: 0.541701\n",
      "epoch 98; iter: 0; batch classifier loss: 0.363344; batch adversarial loss: 0.561753\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363720; batch adversarial loss: 0.544276\n",
      "epoch 100; iter: 0; batch classifier loss: 0.378670; batch adversarial loss: 0.623806\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376503; batch adversarial loss: 0.517731\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414057; batch adversarial loss: 0.543048\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413487; batch adversarial loss: 0.615837\n",
      "epoch 104; iter: 0; batch classifier loss: 0.332654; batch adversarial loss: 0.526929\n",
      "epoch 105; iter: 0; batch classifier loss: 0.393274; batch adversarial loss: 0.436658\n",
      "epoch 106; iter: 0; batch classifier loss: 0.453445; batch adversarial loss: 0.556302\n",
      "epoch 107; iter: 0; batch classifier loss: 0.420745; batch adversarial loss: 0.505613\n",
      "epoch 108; iter: 0; batch classifier loss: 0.333765; batch adversarial loss: 0.509245\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416772; batch adversarial loss: 0.522054\n",
      "epoch 110; iter: 0; batch classifier loss: 0.449570; batch adversarial loss: 0.563443\n",
      "epoch 111; iter: 0; batch classifier loss: 0.279351; batch adversarial loss: 0.518150\n",
      "epoch 112; iter: 0; batch classifier loss: 0.334356; batch adversarial loss: 0.589951\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337055; batch adversarial loss: 0.569023\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364318; batch adversarial loss: 0.482216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356492; batch adversarial loss: 0.554534\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385533; batch adversarial loss: 0.625562\n",
      "epoch 117; iter: 0; batch classifier loss: 0.287251; batch adversarial loss: 0.567112\n",
      "epoch 118; iter: 0; batch classifier loss: 0.438381; batch adversarial loss: 0.473342\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404241; batch adversarial loss: 0.482066\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354460; batch adversarial loss: 0.543801\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344891; batch adversarial loss: 0.525652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.357825; batch adversarial loss: 0.541589\n",
      "epoch 123; iter: 0; batch classifier loss: 0.460007; batch adversarial loss: 0.577608\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340866; batch adversarial loss: 0.572010\n",
      "epoch 125; iter: 0; batch classifier loss: 0.304311; batch adversarial loss: 0.469658\n",
      "epoch 126; iter: 0; batch classifier loss: 0.364775; batch adversarial loss: 0.485551\n",
      "epoch 127; iter: 0; batch classifier loss: 0.487586; batch adversarial loss: 0.499528\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401280; batch adversarial loss: 0.506849\n",
      "epoch 129; iter: 0; batch classifier loss: 0.333476; batch adversarial loss: 0.592795\n",
      "epoch 130; iter: 0; batch classifier loss: 0.432103; batch adversarial loss: 0.498386\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405650; batch adversarial loss: 0.569026\n",
      "epoch 132; iter: 0; batch classifier loss: 0.409298; batch adversarial loss: 0.578065\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329770; batch adversarial loss: 0.555001\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374820; batch adversarial loss: 0.479115\n",
      "epoch 135; iter: 0; batch classifier loss: 0.342301; batch adversarial loss: 0.525266\n",
      "epoch 136; iter: 0; batch classifier loss: 0.284714; batch adversarial loss: 0.516697\n",
      "epoch 137; iter: 0; batch classifier loss: 0.286797; batch adversarial loss: 0.527847\n",
      "epoch 138; iter: 0; batch classifier loss: 0.286060; batch adversarial loss: 0.509834\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332372; batch adversarial loss: 0.544888\n",
      "epoch 140; iter: 0; batch classifier loss: 0.427388; batch adversarial loss: 0.536355\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343504; batch adversarial loss: 0.575517\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426185; batch adversarial loss: 0.470023\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364562; batch adversarial loss: 0.490672\n",
      "epoch 144; iter: 0; batch classifier loss: 0.326237; batch adversarial loss: 0.573744\n",
      "epoch 145; iter: 0; batch classifier loss: 0.320371; batch adversarial loss: 0.546147\n",
      "epoch 146; iter: 0; batch classifier loss: 0.402141; batch adversarial loss: 0.585256\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391321; batch adversarial loss: 0.556546\n",
      "epoch 148; iter: 0; batch classifier loss: 0.438273; batch adversarial loss: 0.580989\n",
      "epoch 149; iter: 0; batch classifier loss: 0.272997; batch adversarial loss: 0.514108\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330376; batch adversarial loss: 0.554100\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365016; batch adversarial loss: 0.535217\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397428; batch adversarial loss: 0.516478\n",
      "epoch 153; iter: 0; batch classifier loss: 0.283665; batch adversarial loss: 0.552932\n",
      "epoch 154; iter: 0; batch classifier loss: 0.420060; batch adversarial loss: 0.543220\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338611; batch adversarial loss: 0.557140\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387672; batch adversarial loss: 0.579575\n",
      "epoch 157; iter: 0; batch classifier loss: 0.332168; batch adversarial loss: 0.622390\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397182; batch adversarial loss: 0.617349\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396676; batch adversarial loss: 0.536101\n",
      "epoch 160; iter: 0; batch classifier loss: 0.393675; batch adversarial loss: 0.493247\n",
      "epoch 161; iter: 0; batch classifier loss: 0.421138; batch adversarial loss: 0.543040\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359070; batch adversarial loss: 0.619058\n",
      "epoch 163; iter: 0; batch classifier loss: 0.431508; batch adversarial loss: 0.562075\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366016; batch adversarial loss: 0.557538\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385228; batch adversarial loss: 0.581383\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387050; batch adversarial loss: 0.499261\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374641; batch adversarial loss: 0.617119\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332970; batch adversarial loss: 0.600192\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384965; batch adversarial loss: 0.442285\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342469; batch adversarial loss: 0.505477\n",
      "epoch 171; iter: 0; batch classifier loss: 0.287421; batch adversarial loss: 0.498726\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375476; batch adversarial loss: 0.575325\n",
      "epoch 173; iter: 0; batch classifier loss: 0.308718; batch adversarial loss: 0.490240\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381534; batch adversarial loss: 0.551035\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360836; batch adversarial loss: 0.611146\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397790; batch adversarial loss: 0.535267\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355038; batch adversarial loss: 0.541310\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287574; batch adversarial loss: 0.482219\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372455; batch adversarial loss: 0.518685\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362971; batch adversarial loss: 0.628006\n",
      "epoch 181; iter: 0; batch classifier loss: 0.440185; batch adversarial loss: 0.537561\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374955; batch adversarial loss: 0.572551\n",
      "epoch 183; iter: 0; batch classifier loss: 0.253513; batch adversarial loss: 0.527320\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313766; batch adversarial loss: 0.512793\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328786; batch adversarial loss: 0.526312\n",
      "epoch 186; iter: 0; batch classifier loss: 0.260762; batch adversarial loss: 0.448646\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372091; batch adversarial loss: 0.472810\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387392; batch adversarial loss: 0.511501\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336414; batch adversarial loss: 0.508726\n",
      "epoch 190; iter: 0; batch classifier loss: 0.370582; batch adversarial loss: 0.494755\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359071; batch adversarial loss: 0.457602\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345997; batch adversarial loss: 0.534394\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333233; batch adversarial loss: 0.584460\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347883; batch adversarial loss: 0.475610\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308197; batch adversarial loss: 0.617338\n",
      "epoch 196; iter: 0; batch classifier loss: 0.465848; batch adversarial loss: 0.620078\n",
      "epoch 197; iter: 0; batch classifier loss: 0.244799; batch adversarial loss: 0.487514\n",
      "epoch 198; iter: 0; batch classifier loss: 0.290356; batch adversarial loss: 0.555817\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388776; batch adversarial loss: 0.537598\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732180; batch adversarial loss: 0.695062\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594813; batch adversarial loss: 0.659025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575803; batch adversarial loss: 0.638732\n",
      "epoch 3; iter: 0; batch classifier loss: 0.670445; batch adversarial loss: 0.645702\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581737; batch adversarial loss: 0.653504\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521759; batch adversarial loss: 0.625484\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597523; batch adversarial loss: 0.607393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548358; batch adversarial loss: 0.612781\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581329; batch adversarial loss: 0.544398\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539510; batch adversarial loss: 0.574069\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565954; batch adversarial loss: 0.573215\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492673; batch adversarial loss: 0.551992\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558371; batch adversarial loss: 0.617499\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503033; batch adversarial loss: 0.586349\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505320; batch adversarial loss: 0.581313\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512026; batch adversarial loss: 0.555639\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528249; batch adversarial loss: 0.542653\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459702; batch adversarial loss: 0.596709\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461789; batch adversarial loss: 0.517900\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507212; batch adversarial loss: 0.542756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.571738; batch adversarial loss: 0.562008\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513383; batch adversarial loss: 0.537382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458270; batch adversarial loss: 0.539808\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505302; batch adversarial loss: 0.549033\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477362; batch adversarial loss: 0.581564\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439060; batch adversarial loss: 0.515936\n",
      "epoch 26; iter: 0; batch classifier loss: 0.533276; batch adversarial loss: 0.514819\n",
      "epoch 27; iter: 0; batch classifier loss: 0.527323; batch adversarial loss: 0.519396\n",
      "epoch 28; iter: 0; batch classifier loss: 0.531213; batch adversarial loss: 0.506047\n",
      "epoch 29; iter: 0; batch classifier loss: 0.546584; batch adversarial loss: 0.544413\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499186; batch adversarial loss: 0.584767\n",
      "epoch 31; iter: 0; batch classifier loss: 0.570448; batch adversarial loss: 0.471215\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512149; batch adversarial loss: 0.556670\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504047; batch adversarial loss: 0.496193\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473971; batch adversarial loss: 0.553772\n",
      "epoch 35; iter: 0; batch classifier loss: 0.510688; batch adversarial loss: 0.527599\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485522; batch adversarial loss: 0.501420\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471471; batch adversarial loss: 0.544902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483189; batch adversarial loss: 0.508558\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420584; batch adversarial loss: 0.626192\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428292; batch adversarial loss: 0.562722\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419831; batch adversarial loss: 0.562831\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462932; batch adversarial loss: 0.553638\n",
      "epoch 43; iter: 0; batch classifier loss: 0.514515; batch adversarial loss: 0.562835\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461283; batch adversarial loss: 0.534782\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465279; batch adversarial loss: 0.563152\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477453; batch adversarial loss: 0.536660\n",
      "epoch 47; iter: 0; batch classifier loss: 0.510843; batch adversarial loss: 0.553700\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448945; batch adversarial loss: 0.600769\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425454; batch adversarial loss: 0.638250\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374641; batch adversarial loss: 0.572863\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421621; batch adversarial loss: 0.535099\n",
      "epoch 52; iter: 0; batch classifier loss: 0.381715; batch adversarial loss: 0.516910\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461304; batch adversarial loss: 0.618454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416995; batch adversarial loss: 0.535053\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397844; batch adversarial loss: 0.562559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.375702; batch adversarial loss: 0.572551\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475320; batch adversarial loss: 0.525732\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420407; batch adversarial loss: 0.572684\n",
      "epoch 59; iter: 0; batch classifier loss: 0.497376; batch adversarial loss: 0.563112\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457847; batch adversarial loss: 0.637266\n",
      "epoch 61; iter: 0; batch classifier loss: 0.478350; batch adversarial loss: 0.516399\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445539; batch adversarial loss: 0.564495\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403223; batch adversarial loss: 0.553833\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397814; batch adversarial loss: 0.533495\n",
      "epoch 65; iter: 0; batch classifier loss: 0.418621; batch adversarial loss: 0.508115\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422084; batch adversarial loss: 0.571351\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376127; batch adversarial loss: 0.497784\n",
      "epoch 68; iter: 0; batch classifier loss: 0.457436; batch adversarial loss: 0.665568\n",
      "epoch 69; iter: 0; batch classifier loss: 0.489621; batch adversarial loss: 0.507683\n",
      "epoch 70; iter: 0; batch classifier loss: 0.395878; batch adversarial loss: 0.545309\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437092; batch adversarial loss: 0.583280\n",
      "epoch 72; iter: 0; batch classifier loss: 0.469056; batch adversarial loss: 0.497990\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422933; batch adversarial loss: 0.497868\n",
      "epoch 74; iter: 0; batch classifier loss: 0.365620; batch adversarial loss: 0.563258\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422441; batch adversarial loss: 0.609832\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419510; batch adversarial loss: 0.525531\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437047; batch adversarial loss: 0.487172\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401975; batch adversarial loss: 0.610602\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406954; batch adversarial loss: 0.535132\n",
      "epoch 80; iter: 0; batch classifier loss: 0.362520; batch adversarial loss: 0.573146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390569; batch adversarial loss: 0.508329\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389007; batch adversarial loss: 0.515504\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405659; batch adversarial loss: 0.542559\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443994; batch adversarial loss: 0.525087\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393733; batch adversarial loss: 0.507300\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401442; batch adversarial loss: 0.479270\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364986; batch adversarial loss: 0.601434\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431454; batch adversarial loss: 0.525807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371381; batch adversarial loss: 0.620678\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407100; batch adversarial loss: 0.545103\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421454; batch adversarial loss: 0.554322\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390711; batch adversarial loss: 0.580516\n",
      "epoch 93; iter: 0; batch classifier loss: 0.376396; batch adversarial loss: 0.554225\n",
      "epoch 94; iter: 0; batch classifier loss: 0.510902; batch adversarial loss: 0.630380\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387746; batch adversarial loss: 0.582134\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373477; batch adversarial loss: 0.478472\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377113; batch adversarial loss: 0.553484\n",
      "epoch 98; iter: 0; batch classifier loss: 0.299485; batch adversarial loss: 0.480877\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398125; batch adversarial loss: 0.619289\n",
      "epoch 100; iter: 0; batch classifier loss: 0.340086; batch adversarial loss: 0.535875\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434797; batch adversarial loss: 0.507482\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342692; batch adversarial loss: 0.630480\n",
      "epoch 103; iter: 0; batch classifier loss: 0.437487; batch adversarial loss: 0.516243\n",
      "epoch 104; iter: 0; batch classifier loss: 0.359049; batch adversarial loss: 0.535282\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398285; batch adversarial loss: 0.441107\n",
      "epoch 106; iter: 0; batch classifier loss: 0.429119; batch adversarial loss: 0.552859\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430941; batch adversarial loss: 0.497402\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381898; batch adversarial loss: 0.582352\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391885; batch adversarial loss: 0.545654\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344840; batch adversarial loss: 0.609192\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393333; batch adversarial loss: 0.584002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.331448; batch adversarial loss: 0.488456\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333787; batch adversarial loss: 0.563666\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.450531\n",
      "epoch 115; iter: 0; batch classifier loss: 0.429114; batch adversarial loss: 0.479218\n",
      "epoch 116; iter: 0; batch classifier loss: 0.331451; batch adversarial loss: 0.562593\n",
      "epoch 117; iter: 0; batch classifier loss: 0.425684; batch adversarial loss: 0.562520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.413584; batch adversarial loss: 0.555790\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364557; batch adversarial loss: 0.566266\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385842; batch adversarial loss: 0.544609\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419362; batch adversarial loss: 0.571502\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379583; batch adversarial loss: 0.554521\n",
      "epoch 123; iter: 0; batch classifier loss: 0.411567; batch adversarial loss: 0.591646\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357673; batch adversarial loss: 0.543966\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408936; batch adversarial loss: 0.469434\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351009; batch adversarial loss: 0.551702\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381291; batch adversarial loss: 0.562728\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395230; batch adversarial loss: 0.628779\n",
      "epoch 129; iter: 0; batch classifier loss: 0.321620; batch adversarial loss: 0.553528\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413828; batch adversarial loss: 0.450166\n",
      "epoch 131; iter: 0; batch classifier loss: 0.409283; batch adversarial loss: 0.580986\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421836; batch adversarial loss: 0.552489\n",
      "epoch 133; iter: 0; batch classifier loss: 0.454276; batch adversarial loss: 0.572987\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381571; batch adversarial loss: 0.578671\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340702; batch adversarial loss: 0.543334\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365003; batch adversarial loss: 0.525913\n",
      "epoch 137; iter: 0; batch classifier loss: 0.322024; batch adversarial loss: 0.565169\n",
      "epoch 138; iter: 0; batch classifier loss: 0.260568; batch adversarial loss: 0.580308\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389679; batch adversarial loss: 0.490465\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348532; batch adversarial loss: 0.477485\n",
      "epoch 141; iter: 0; batch classifier loss: 0.327587; batch adversarial loss: 0.563857\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356704; batch adversarial loss: 0.523380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351464; batch adversarial loss: 0.563231\n",
      "epoch 144; iter: 0; batch classifier loss: 0.438888; batch adversarial loss: 0.608287\n",
      "epoch 145; iter: 0; batch classifier loss: 0.269571; batch adversarial loss: 0.573449\n",
      "epoch 146; iter: 0; batch classifier loss: 0.448280; batch adversarial loss: 0.636177\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326948; batch adversarial loss: 0.569939\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358052; batch adversarial loss: 0.579446\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314304; batch adversarial loss: 0.451163\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371374; batch adversarial loss: 0.572180\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422609; batch adversarial loss: 0.602279\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339706; batch adversarial loss: 0.561727\n",
      "epoch 153; iter: 0; batch classifier loss: 0.431886; batch adversarial loss: 0.544500\n",
      "epoch 154; iter: 0; batch classifier loss: 0.420755; batch adversarial loss: 0.582891\n",
      "epoch 155; iter: 0; batch classifier loss: 0.312354; batch adversarial loss: 0.543864\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384733; batch adversarial loss: 0.525474\n",
      "epoch 157; iter: 0; batch classifier loss: 0.423350; batch adversarial loss: 0.506973\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353788; batch adversarial loss: 0.544373\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331120; batch adversarial loss: 0.619298\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387099; batch adversarial loss: 0.598889\n",
      "epoch 161; iter: 0; batch classifier loss: 0.352624; batch adversarial loss: 0.532826\n",
      "epoch 162; iter: 0; batch classifier loss: 0.473370; batch adversarial loss: 0.554938\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402600; batch adversarial loss: 0.619283\n",
      "epoch 164; iter: 0; batch classifier loss: 0.485328; batch adversarial loss: 0.534931\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303088; batch adversarial loss: 0.517506\n",
      "epoch 166; iter: 0; batch classifier loss: 0.430516; batch adversarial loss: 0.572274\n",
      "epoch 167; iter: 0; batch classifier loss: 0.429880; batch adversarial loss: 0.657296\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397643; batch adversarial loss: 0.469642\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344337; batch adversarial loss: 0.553341\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352078; batch adversarial loss: 0.488510\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378443; batch adversarial loss: 0.580938\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391305; batch adversarial loss: 0.488543\n",
      "epoch 173; iter: 0; batch classifier loss: 0.449269; batch adversarial loss: 0.508204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362054; batch adversarial loss: 0.524371\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335591; batch adversarial loss: 0.553575\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392550; batch adversarial loss: 0.487084\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387619; batch adversarial loss: 0.497266\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367736; batch adversarial loss: 0.564575\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386567; batch adversarial loss: 0.525151\n",
      "epoch 180; iter: 0; batch classifier loss: 0.417381; batch adversarial loss: 0.505756\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332228; batch adversarial loss: 0.534909\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377245; batch adversarial loss: 0.544866\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387248; batch adversarial loss: 0.609499\n",
      "epoch 184; iter: 0; batch classifier loss: 0.308503; batch adversarial loss: 0.545838\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364659; batch adversarial loss: 0.554141\n",
      "epoch 186; iter: 0; batch classifier loss: 0.442522; batch adversarial loss: 0.551869\n",
      "epoch 187; iter: 0; batch classifier loss: 0.391492; batch adversarial loss: 0.620039\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336498; batch adversarial loss: 0.600096\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371769; batch adversarial loss: 0.544510\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314742; batch adversarial loss: 0.572872\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377961; batch adversarial loss: 0.534732\n",
      "epoch 192; iter: 0; batch classifier loss: 0.350924; batch adversarial loss: 0.460239\n",
      "epoch 193; iter: 0; batch classifier loss: 0.289790; batch adversarial loss: 0.572653\n",
      "epoch 194; iter: 0; batch classifier loss: 0.346304; batch adversarial loss: 0.581649\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332812; batch adversarial loss: 0.496793\n",
      "epoch 196; iter: 0; batch classifier loss: 0.457398; batch adversarial loss: 0.515366\n",
      "epoch 197; iter: 0; batch classifier loss: 0.431965; batch adversarial loss: 0.562409\n",
      "epoch 198; iter: 0; batch classifier loss: 0.440427; batch adversarial loss: 0.589810\n",
      "epoch 199; iter: 0; batch classifier loss: 0.302684; batch adversarial loss: 0.593219\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719301; batch adversarial loss: 0.780864\n",
      "epoch 1; iter: 0; batch classifier loss: 0.561223; batch adversarial loss: 0.776319\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610321; batch adversarial loss: 0.713634\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534673; batch adversarial loss: 0.690553\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521208; batch adversarial loss: 0.710842\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539932; batch adversarial loss: 0.670705\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539466; batch adversarial loss: 0.612310\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536252; batch adversarial loss: 0.618739\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543056; batch adversarial loss: 0.616934\n",
      "epoch 9; iter: 0; batch classifier loss: 0.483054; batch adversarial loss: 0.581255\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535775; batch adversarial loss: 0.599833\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552757; batch adversarial loss: 0.598184\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528772; batch adversarial loss: 0.553165\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471666; batch adversarial loss: 0.582728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.539895; batch adversarial loss: 0.591942\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525946; batch adversarial loss: 0.555890\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550360; batch adversarial loss: 0.544722\n",
      "epoch 17; iter: 0; batch classifier loss: 0.585306; batch adversarial loss: 0.612404\n",
      "epoch 18; iter: 0; batch classifier loss: 0.516003; batch adversarial loss: 0.557570\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508124; batch adversarial loss: 0.608723\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503416; batch adversarial loss: 0.570282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481080; batch adversarial loss: 0.482397\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464748; batch adversarial loss: 0.574965\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588766; batch adversarial loss: 0.549632\n",
      "epoch 24; iter: 0; batch classifier loss: 0.546118; batch adversarial loss: 0.592776\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484420; batch adversarial loss: 0.570971\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492529; batch adversarial loss: 0.569992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436388; batch adversarial loss: 0.554269\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516246; batch adversarial loss: 0.540438\n",
      "epoch 29; iter: 0; batch classifier loss: 0.540438; batch adversarial loss: 0.506220\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490883; batch adversarial loss: 0.580452\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475087; batch adversarial loss: 0.579290\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477654; batch adversarial loss: 0.511728\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409607; batch adversarial loss: 0.510494\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492766; batch adversarial loss: 0.535906\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471241; batch adversarial loss: 0.587894\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444575; batch adversarial loss: 0.512344\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443694; batch adversarial loss: 0.597857\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484617; batch adversarial loss: 0.545331\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460267; batch adversarial loss: 0.617669\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460788; batch adversarial loss: 0.629348\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436935; batch adversarial loss: 0.529478\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474062; batch adversarial loss: 0.500890\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425925; batch adversarial loss: 0.492505\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423304; batch adversarial loss: 0.639100\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441276; batch adversarial loss: 0.550565\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459027; batch adversarial loss: 0.535379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458641; batch adversarial loss: 0.564541\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483218; batch adversarial loss: 0.511500\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357113; batch adversarial loss: 0.581871\n",
      "epoch 50; iter: 0; batch classifier loss: 0.502680; batch adversarial loss: 0.560723\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441052; batch adversarial loss: 0.572095\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419656; batch adversarial loss: 0.501786\n",
      "epoch 53; iter: 0; batch classifier loss: 0.473039; batch adversarial loss: 0.555013\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486348; batch adversarial loss: 0.547046\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426172; batch adversarial loss: 0.486171\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427974; batch adversarial loss: 0.559845\n",
      "epoch 57; iter: 0; batch classifier loss: 0.493039; batch adversarial loss: 0.510763\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404110; batch adversarial loss: 0.478555\n",
      "epoch 59; iter: 0; batch classifier loss: 0.453789; batch adversarial loss: 0.558875\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436889; batch adversarial loss: 0.482619\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449800; batch adversarial loss: 0.598526\n",
      "epoch 62; iter: 0; batch classifier loss: 0.437845; batch adversarial loss: 0.510096\n",
      "epoch 63; iter: 0; batch classifier loss: 0.361754; batch adversarial loss: 0.526659\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419753; batch adversarial loss: 0.529319\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420590; batch adversarial loss: 0.560948\n",
      "epoch 66; iter: 0; batch classifier loss: 0.468614; batch adversarial loss: 0.606823\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417239; batch adversarial loss: 0.544089\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.554485\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384067; batch adversarial loss: 0.568949\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443242; batch adversarial loss: 0.520401\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431006; batch adversarial loss: 0.591670\n",
      "epoch 72; iter: 0; batch classifier loss: 0.335200; batch adversarial loss: 0.478493\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395559; batch adversarial loss: 0.546511\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403467; batch adversarial loss: 0.508770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384946; batch adversarial loss: 0.550497\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363180; batch adversarial loss: 0.552705\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436689; batch adversarial loss: 0.560141\n",
      "epoch 78; iter: 0; batch classifier loss: 0.357768; batch adversarial loss: 0.518164\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395338; batch adversarial loss: 0.618415\n",
      "epoch 80; iter: 0; batch classifier loss: 0.368835; batch adversarial loss: 0.556648\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437208; batch adversarial loss: 0.502267\n",
      "epoch 82; iter: 0; batch classifier loss: 0.469779; batch adversarial loss: 0.544505\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391500; batch adversarial loss: 0.482740\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444480; batch adversarial loss: 0.504570\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434157; batch adversarial loss: 0.594493\n",
      "epoch 86; iter: 0; batch classifier loss: 0.404423; batch adversarial loss: 0.554129\n",
      "epoch 87; iter: 0; batch classifier loss: 0.447457; batch adversarial loss: 0.509066\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389185; batch adversarial loss: 0.669817\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436265; batch adversarial loss: 0.677785\n",
      "epoch 90; iter: 0; batch classifier loss: 0.338902; batch adversarial loss: 0.564915\n",
      "epoch 91; iter: 0; batch classifier loss: 0.447752; batch adversarial loss: 0.606652\n",
      "epoch 92; iter: 0; batch classifier loss: 0.478768; batch adversarial loss: 0.597915\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424540; batch adversarial loss: 0.598412\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358237; batch adversarial loss: 0.554089\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427672; batch adversarial loss: 0.537284\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422332; batch adversarial loss: 0.545782\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411177; batch adversarial loss: 0.501245\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369515; batch adversarial loss: 0.553513\n",
      "epoch 99; iter: 0; batch classifier loss: 0.432778; batch adversarial loss: 0.562497\n",
      "epoch 100; iter: 0; batch classifier loss: 0.437015; batch adversarial loss: 0.598670\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377663; batch adversarial loss: 0.536827\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379238; batch adversarial loss: 0.517457\n",
      "epoch 103; iter: 0; batch classifier loss: 0.474299; batch adversarial loss: 0.515282\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390651; batch adversarial loss: 0.508753\n",
      "epoch 105; iter: 0; batch classifier loss: 0.354852; batch adversarial loss: 0.534723\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363204; batch adversarial loss: 0.630121\n",
      "epoch 107; iter: 0; batch classifier loss: 0.420326; batch adversarial loss: 0.668560\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406151; batch adversarial loss: 0.543481\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365715; batch adversarial loss: 0.657759\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442337; batch adversarial loss: 0.591769\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409295; batch adversarial loss: 0.571635\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353542; batch adversarial loss: 0.543757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.437786; batch adversarial loss: 0.453836\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360747; batch adversarial loss: 0.511018\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362983; batch adversarial loss: 0.595131\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396890; batch adversarial loss: 0.581026\n",
      "epoch 117; iter: 0; batch classifier loss: 0.448149; batch adversarial loss: 0.546244\n",
      "epoch 118; iter: 0; batch classifier loss: 0.475475; batch adversarial loss: 0.554974\n",
      "epoch 119; iter: 0; batch classifier loss: 0.439759; batch adversarial loss: 0.598831\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356551; batch adversarial loss: 0.559932\n",
      "epoch 121; iter: 0; batch classifier loss: 0.436808; batch adversarial loss: 0.594812\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395750; batch adversarial loss: 0.547118\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339709; batch adversarial loss: 0.556690\n",
      "epoch 124; iter: 0; batch classifier loss: 0.394355; batch adversarial loss: 0.535667\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369879; batch adversarial loss: 0.566320\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438659; batch adversarial loss: 0.643317\n",
      "epoch 127; iter: 0; batch classifier loss: 0.424777; batch adversarial loss: 0.581341\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325529; batch adversarial loss: 0.500085\n",
      "epoch 129; iter: 0; batch classifier loss: 0.396956; batch adversarial loss: 0.607136\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398659; batch adversarial loss: 0.605845\n",
      "epoch 131; iter: 0; batch classifier loss: 0.306875; batch adversarial loss: 0.499201\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363554; batch adversarial loss: 0.569997\n",
      "epoch 133; iter: 0; batch classifier loss: 0.306338; batch adversarial loss: 0.514459\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387154; batch adversarial loss: 0.534111\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353161; batch adversarial loss: 0.485325\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340259; batch adversarial loss: 0.563960\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367420; batch adversarial loss: 0.515602\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359408; batch adversarial loss: 0.588800\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394661; batch adversarial loss: 0.593338\n",
      "epoch 140; iter: 0; batch classifier loss: 0.438308; batch adversarial loss: 0.490618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.397271; batch adversarial loss: 0.587709\n",
      "epoch 142; iter: 0; batch classifier loss: 0.436061; batch adversarial loss: 0.588863\n",
      "epoch 143; iter: 0; batch classifier loss: 0.307563; batch adversarial loss: 0.567877\n",
      "epoch 144; iter: 0; batch classifier loss: 0.383409; batch adversarial loss: 0.496608\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368456; batch adversarial loss: 0.484179\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396810; batch adversarial loss: 0.604463\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312224; batch adversarial loss: 0.505962\n",
      "epoch 148; iter: 0; batch classifier loss: 0.439563; batch adversarial loss: 0.594450\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362525; batch adversarial loss: 0.544712\n",
      "epoch 150; iter: 0; batch classifier loss: 0.408467; batch adversarial loss: 0.608152\n",
      "epoch 151; iter: 0; batch classifier loss: 0.306034; batch adversarial loss: 0.591665\n",
      "epoch 152; iter: 0; batch classifier loss: 0.404256; batch adversarial loss: 0.599049\n",
      "epoch 153; iter: 0; batch classifier loss: 0.440926; batch adversarial loss: 0.607331\n",
      "epoch 154; iter: 0; batch classifier loss: 0.439274; batch adversarial loss: 0.532655\n",
      "epoch 155; iter: 0; batch classifier loss: 0.429732; batch adversarial loss: 0.524371\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350655; batch adversarial loss: 0.480137\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371430; batch adversarial loss: 0.550042\n",
      "epoch 158; iter: 0; batch classifier loss: 0.394665; batch adversarial loss: 0.545231\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379865; batch adversarial loss: 0.538600\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406562; batch adversarial loss: 0.509052\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383986; batch adversarial loss: 0.517859\n",
      "epoch 162; iter: 0; batch classifier loss: 0.451781; batch adversarial loss: 0.553750\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311380; batch adversarial loss: 0.519723\n",
      "epoch 164; iter: 0; batch classifier loss: 0.440924; batch adversarial loss: 0.520578\n",
      "epoch 165; iter: 0; batch classifier loss: 0.407171; batch adversarial loss: 0.535716\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362271; batch adversarial loss: 0.641355\n",
      "epoch 167; iter: 0; batch classifier loss: 0.457871; batch adversarial loss: 0.577460\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380825; batch adversarial loss: 0.551465\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341556; batch adversarial loss: 0.544294\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344043; batch adversarial loss: 0.606396\n",
      "epoch 171; iter: 0; batch classifier loss: 0.365662; batch adversarial loss: 0.571452\n",
      "epoch 172; iter: 0; batch classifier loss: 0.418196; batch adversarial loss: 0.519252\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375878; batch adversarial loss: 0.534284\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372521; batch adversarial loss: 0.570002\n",
      "epoch 175; iter: 0; batch classifier loss: 0.454176; batch adversarial loss: 0.544231\n",
      "epoch 176; iter: 0; batch classifier loss: 0.386483; batch adversarial loss: 0.532047\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376791; batch adversarial loss: 0.507522\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353186; batch adversarial loss: 0.598522\n",
      "epoch 179; iter: 0; batch classifier loss: 0.309774; batch adversarial loss: 0.498607\n",
      "epoch 180; iter: 0; batch classifier loss: 0.311112; batch adversarial loss: 0.534452\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375590; batch adversarial loss: 0.550866\n",
      "epoch 182; iter: 0; batch classifier loss: 0.395097; batch adversarial loss: 0.636796\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310634; batch adversarial loss: 0.553216\n",
      "epoch 184; iter: 0; batch classifier loss: 0.421864; batch adversarial loss: 0.506814\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364475; batch adversarial loss: 0.550571\n",
      "epoch 186; iter: 0; batch classifier loss: 0.462593; batch adversarial loss: 0.551825\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372624; batch adversarial loss: 0.548876\n",
      "epoch 188; iter: 0; batch classifier loss: 0.284971; batch adversarial loss: 0.561950\n",
      "epoch 189; iter: 0; batch classifier loss: 0.388785; batch adversarial loss: 0.628218\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329961; batch adversarial loss: 0.637925\n",
      "epoch 191; iter: 0; batch classifier loss: 0.371379; batch adversarial loss: 0.544962\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386803; batch adversarial loss: 0.532477\n",
      "epoch 193; iter: 0; batch classifier loss: 0.431151; batch adversarial loss: 0.566611\n",
      "epoch 194; iter: 0; batch classifier loss: 0.326342; batch adversarial loss: 0.630816\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337849; batch adversarial loss: 0.580896\n",
      "epoch 196; iter: 0; batch classifier loss: 0.447788; batch adversarial loss: 0.542555\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387260; batch adversarial loss: 0.525668\n",
      "epoch 198; iter: 0; batch classifier loss: 0.409264; batch adversarial loss: 0.519756\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357957; batch adversarial loss: 0.599499\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741090; batch adversarial loss: 0.581606\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528808; batch adversarial loss: 0.625082\n",
      "epoch 2; iter: 0; batch classifier loss: 0.536234; batch adversarial loss: 0.676012\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537614; batch adversarial loss: 0.661797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549545; batch adversarial loss: 0.643058\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549795; batch adversarial loss: 0.638623\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576969; batch adversarial loss: 0.628977\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521253; batch adversarial loss: 0.598130\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613973; batch adversarial loss: 0.580316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545994; batch adversarial loss: 0.562433\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577362; batch adversarial loss: 0.561120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.534862; batch adversarial loss: 0.578554\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538615; batch adversarial loss: 0.544772\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496323; batch adversarial loss: 0.570387\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538561; batch adversarial loss: 0.553711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514368; batch adversarial loss: 0.551176\n",
      "epoch 16; iter: 0; batch classifier loss: 0.568561; batch adversarial loss: 0.561833\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489884; batch adversarial loss: 0.576794\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458840; batch adversarial loss: 0.624746\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475892; batch adversarial loss: 0.528379\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539038; batch adversarial loss: 0.503368\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501022; batch adversarial loss: 0.537894\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516129; batch adversarial loss: 0.591858\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449464; batch adversarial loss: 0.495985\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453427; batch adversarial loss: 0.597719\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481746; batch adversarial loss: 0.571251\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470603; batch adversarial loss: 0.582608\n",
      "epoch 27; iter: 0; batch classifier loss: 0.528037; batch adversarial loss: 0.562213\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429946; batch adversarial loss: 0.641514\n",
      "epoch 29; iter: 0; batch classifier loss: 0.536542; batch adversarial loss: 0.528247\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496857; batch adversarial loss: 0.562732\n",
      "epoch 31; iter: 0; batch classifier loss: 0.399988; batch adversarial loss: 0.519189\n",
      "epoch 32; iter: 0; batch classifier loss: 0.404177; batch adversarial loss: 0.509486\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430705; batch adversarial loss: 0.580534\n",
      "epoch 34; iter: 0; batch classifier loss: 0.524261; batch adversarial loss: 0.526121\n",
      "epoch 35; iter: 0; batch classifier loss: 0.539987; batch adversarial loss: 0.635986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450839; batch adversarial loss: 0.536285\n",
      "epoch 37; iter: 0; batch classifier loss: 0.530466; batch adversarial loss: 0.582214\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431331; batch adversarial loss: 0.554618\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464202; batch adversarial loss: 0.489061\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465019; batch adversarial loss: 0.637614\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377508; batch adversarial loss: 0.582370\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459592; batch adversarial loss: 0.563717\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424846; batch adversarial loss: 0.541592\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483062; batch adversarial loss: 0.588450\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426244; batch adversarial loss: 0.477912\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452313; batch adversarial loss: 0.587853\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401445; batch adversarial loss: 0.563631\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443022; batch adversarial loss: 0.537295\n",
      "epoch 49; iter: 0; batch classifier loss: 0.479257; batch adversarial loss: 0.555255\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455017; batch adversarial loss: 0.512205\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417153; batch adversarial loss: 0.526817\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403516; batch adversarial loss: 0.581233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441320; batch adversarial loss: 0.555069\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442872; batch adversarial loss: 0.470264\n",
      "epoch 55; iter: 0; batch classifier loss: 0.380982; batch adversarial loss: 0.601398\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439533; batch adversarial loss: 0.532290\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370837; batch adversarial loss: 0.534571\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384520; batch adversarial loss: 0.535023\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406637; batch adversarial loss: 0.559898\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379709; batch adversarial loss: 0.553258\n",
      "epoch 61; iter: 0; batch classifier loss: 0.513294; batch adversarial loss: 0.498959\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421022; batch adversarial loss: 0.533615\n",
      "epoch 63; iter: 0; batch classifier loss: 0.526042; batch adversarial loss: 0.541056\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436012; batch adversarial loss: 0.532373\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419915; batch adversarial loss: 0.491238\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406902; batch adversarial loss: 0.608780\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435166; batch adversarial loss: 0.487924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.398467; batch adversarial loss: 0.506056\n",
      "epoch 69; iter: 0; batch classifier loss: 0.362896; batch adversarial loss: 0.556336\n",
      "epoch 70; iter: 0; batch classifier loss: 0.475499; batch adversarial loss: 0.591992\n",
      "epoch 71; iter: 0; batch classifier loss: 0.359537; batch adversarial loss: 0.662725\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435002; batch adversarial loss: 0.595304\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410215; batch adversarial loss: 0.616350\n",
      "epoch 74; iter: 0; batch classifier loss: 0.429911; batch adversarial loss: 0.553451\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372711; batch adversarial loss: 0.536088\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397820; batch adversarial loss: 0.580353\n",
      "epoch 77; iter: 0; batch classifier loss: 0.432742; batch adversarial loss: 0.541970\n",
      "epoch 78; iter: 0; batch classifier loss: 0.403208; batch adversarial loss: 0.581121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462605; batch adversarial loss: 0.532176\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418333; batch adversarial loss: 0.467822\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373341; batch adversarial loss: 0.624122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375590; batch adversarial loss: 0.590362\n",
      "epoch 83; iter: 0; batch classifier loss: 0.437718; batch adversarial loss: 0.550106\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373475; batch adversarial loss: 0.551692\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392863; batch adversarial loss: 0.544736\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407692; batch adversarial loss: 0.600556\n",
      "epoch 87; iter: 0; batch classifier loss: 0.337528; batch adversarial loss: 0.598474\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424550; batch adversarial loss: 0.552839\n",
      "epoch 89; iter: 0; batch classifier loss: 0.515832; batch adversarial loss: 0.551115\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376620; batch adversarial loss: 0.608802\n",
      "epoch 91; iter: 0; batch classifier loss: 0.304737; batch adversarial loss: 0.508872\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384076; batch adversarial loss: 0.548248\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375311; batch adversarial loss: 0.445311\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356369; batch adversarial loss: 0.521627\n",
      "epoch 95; iter: 0; batch classifier loss: 0.462829; batch adversarial loss: 0.525567\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361174; batch adversarial loss: 0.541045\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439078; batch adversarial loss: 0.555237\n",
      "epoch 98; iter: 0; batch classifier loss: 0.332469; batch adversarial loss: 0.404127\n",
      "epoch 99; iter: 0; batch classifier loss: 0.340692; batch adversarial loss: 0.477809\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381996; batch adversarial loss: 0.571856\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342452; batch adversarial loss: 0.516618\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345201; batch adversarial loss: 0.553746\n",
      "epoch 103; iter: 0; batch classifier loss: 0.436082; batch adversarial loss: 0.463809\n",
      "epoch 104; iter: 0; batch classifier loss: 0.432206; batch adversarial loss: 0.519461\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337985; batch adversarial loss: 0.553536\n",
      "epoch 106; iter: 0; batch classifier loss: 0.508580; batch adversarial loss: 0.561841\n",
      "epoch 107; iter: 0; batch classifier loss: 0.333295; batch adversarial loss: 0.530896\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421608; batch adversarial loss: 0.526225\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366491; batch adversarial loss: 0.562453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.357885; batch adversarial loss: 0.525896\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426742; batch adversarial loss: 0.545180\n",
      "epoch 112; iter: 0; batch classifier loss: 0.416002; batch adversarial loss: 0.551908\n",
      "epoch 113; iter: 0; batch classifier loss: 0.440692; batch adversarial loss: 0.526241\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405405; batch adversarial loss: 0.569462\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398456; batch adversarial loss: 0.459553\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355512; batch adversarial loss: 0.506770\n",
      "epoch 117; iter: 0; batch classifier loss: 0.418772; batch adversarial loss: 0.470654\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373606; batch adversarial loss: 0.502258\n",
      "epoch 119; iter: 0; batch classifier loss: 0.329724; batch adversarial loss: 0.563109\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374232; batch adversarial loss: 0.564625\n",
      "epoch 121; iter: 0; batch classifier loss: 0.399572; batch adversarial loss: 0.612467\n",
      "epoch 122; iter: 0; batch classifier loss: 0.332016; batch adversarial loss: 0.598030\n",
      "epoch 123; iter: 0; batch classifier loss: 0.419484; batch adversarial loss: 0.615750\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382837; batch adversarial loss: 0.453506\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413239; batch adversarial loss: 0.470216\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402472; batch adversarial loss: 0.523066\n",
      "epoch 127; iter: 0; batch classifier loss: 0.413618; batch adversarial loss: 0.486785\n",
      "epoch 128; iter: 0; batch classifier loss: 0.341798; batch adversarial loss: 0.569530\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362903; batch adversarial loss: 0.533390\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386416; batch adversarial loss: 0.526185\n",
      "epoch 131; iter: 0; batch classifier loss: 0.417927; batch adversarial loss: 0.489964\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392610; batch adversarial loss: 0.556176\n",
      "epoch 133; iter: 0; batch classifier loss: 0.453159; batch adversarial loss: 0.460521\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369380; batch adversarial loss: 0.497687\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385355; batch adversarial loss: 0.597740\n",
      "epoch 136; iter: 0; batch classifier loss: 0.297543; batch adversarial loss: 0.508024\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402402; batch adversarial loss: 0.526874\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344608; batch adversarial loss: 0.572391\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368821; batch adversarial loss: 0.515074\n",
      "epoch 140; iter: 0; batch classifier loss: 0.434482; batch adversarial loss: 0.556329\n",
      "epoch 141; iter: 0; batch classifier loss: 0.248989; batch adversarial loss: 0.440668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393933; batch adversarial loss: 0.519519\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375093; batch adversarial loss: 0.544817\n",
      "epoch 144; iter: 0; batch classifier loss: 0.364277; batch adversarial loss: 0.443380\n",
      "epoch 145; iter: 0; batch classifier loss: 0.297004; batch adversarial loss: 0.581100\n",
      "epoch 146; iter: 0; batch classifier loss: 0.309719; batch adversarial loss: 0.470757\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379693; batch adversarial loss: 0.534723\n",
      "epoch 148; iter: 0; batch classifier loss: 0.321541; batch adversarial loss: 0.489647\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388433; batch adversarial loss: 0.496176\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317344; batch adversarial loss: 0.559282\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322162; batch adversarial loss: 0.525824\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388181; batch adversarial loss: 0.574499\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369669; batch adversarial loss: 0.514771\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354351; batch adversarial loss: 0.581963\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380424; batch adversarial loss: 0.476389\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418136; batch adversarial loss: 0.525045\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416962; batch adversarial loss: 0.601275\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321052; batch adversarial loss: 0.478507\n",
      "epoch 159; iter: 0; batch classifier loss: 0.419569; batch adversarial loss: 0.581919\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413777; batch adversarial loss: 0.479023\n",
      "epoch 161; iter: 0; batch classifier loss: 0.419237; batch adversarial loss: 0.556599\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358854; batch adversarial loss: 0.541179\n",
      "epoch 163; iter: 0; batch classifier loss: 0.332095; batch adversarial loss: 0.508894\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378090; batch adversarial loss: 0.588855\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398587; batch adversarial loss: 0.519224\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360825; batch adversarial loss: 0.495466\n",
      "epoch 167; iter: 0; batch classifier loss: 0.315891; batch adversarial loss: 0.562979\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317424; batch adversarial loss: 0.552927\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304650; batch adversarial loss: 0.553432\n",
      "epoch 170; iter: 0; batch classifier loss: 0.423838; batch adversarial loss: 0.583550\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347182; batch adversarial loss: 0.518077\n",
      "epoch 172; iter: 0; batch classifier loss: 0.437430; batch adversarial loss: 0.500993\n",
      "epoch 173; iter: 0; batch classifier loss: 0.294066; batch adversarial loss: 0.564664\n",
      "epoch 174; iter: 0; batch classifier loss: 0.483613; batch adversarial loss: 0.550707\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365234; batch adversarial loss: 0.508275\n",
      "epoch 176; iter: 0; batch classifier loss: 0.317632; batch adversarial loss: 0.497305\n",
      "epoch 177; iter: 0; batch classifier loss: 0.382318; batch adversarial loss: 0.574329\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339860; batch adversarial loss: 0.525183\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334639; batch adversarial loss: 0.550740\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336199; batch adversarial loss: 0.498236\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365636; batch adversarial loss: 0.525639\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388361; batch adversarial loss: 0.480564\n",
      "epoch 183; iter: 0; batch classifier loss: 0.451578; batch adversarial loss: 0.545956\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413185; batch adversarial loss: 0.571816\n",
      "epoch 185; iter: 0; batch classifier loss: 0.414455; batch adversarial loss: 0.583663\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375106; batch adversarial loss: 0.565853\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315960; batch adversarial loss: 0.496877\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359995; batch adversarial loss: 0.549886\n",
      "epoch 189; iter: 0; batch classifier loss: 0.420663; batch adversarial loss: 0.534032\n",
      "epoch 190; iter: 0; batch classifier loss: 0.287070; batch adversarial loss: 0.570167\n",
      "epoch 191; iter: 0; batch classifier loss: 0.388239; batch adversarial loss: 0.552389\n",
      "epoch 192; iter: 0; batch classifier loss: 0.295309; batch adversarial loss: 0.560475\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381844; batch adversarial loss: 0.564627\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377721; batch adversarial loss: 0.533273\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340318; batch adversarial loss: 0.552661\n",
      "epoch 196; iter: 0; batch classifier loss: 0.485612; batch adversarial loss: 0.601895\n",
      "epoch 197; iter: 0; batch classifier loss: 0.302158; batch adversarial loss: 0.570807\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301141; batch adversarial loss: 0.589597\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353565; batch adversarial loss: 0.598184\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714382; batch adversarial loss: 0.578451\n",
      "epoch 1; iter: 0; batch classifier loss: 0.549372; batch adversarial loss: 0.635144\n",
      "epoch 2; iter: 0; batch classifier loss: 0.559223; batch adversarial loss: 0.636512\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586667; batch adversarial loss: 0.655805\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591623; batch adversarial loss: 0.629536\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601186; batch adversarial loss: 0.605484\n",
      "epoch 6; iter: 0; batch classifier loss: 0.449592; batch adversarial loss: 0.569541\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583788; batch adversarial loss: 0.597481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.554985; batch adversarial loss: 0.564429\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490759; batch adversarial loss: 0.568422\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489134; batch adversarial loss: 0.576418\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548155; batch adversarial loss: 0.570246\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510735; batch adversarial loss: 0.545590\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517139; batch adversarial loss: 0.571302\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498620; batch adversarial loss: 0.562860\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556363; batch adversarial loss: 0.558504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.596229; batch adversarial loss: 0.554260\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459214; batch adversarial loss: 0.538962\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509415; batch adversarial loss: 0.510864\n",
      "epoch 19; iter: 0; batch classifier loss: 0.449580; batch adversarial loss: 0.528267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508256; batch adversarial loss: 0.587640\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479462; batch adversarial loss: 0.577451\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476189; batch adversarial loss: 0.569361\n",
      "epoch 23; iter: 0; batch classifier loss: 0.542335; batch adversarial loss: 0.555802\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475022; batch adversarial loss: 0.554348\n",
      "epoch 25; iter: 0; batch classifier loss: 0.554365; batch adversarial loss: 0.560915\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467259; batch adversarial loss: 0.539034\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463063; batch adversarial loss: 0.519166\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465156; batch adversarial loss: 0.560541\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465508; batch adversarial loss: 0.578504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459753; batch adversarial loss: 0.598974\n",
      "epoch 31; iter: 0; batch classifier loss: 0.412967; batch adversarial loss: 0.580373\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446614; batch adversarial loss: 0.600346\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469883; batch adversarial loss: 0.569663\n",
      "epoch 34; iter: 0; batch classifier loss: 0.516580; batch adversarial loss: 0.552247\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442227; batch adversarial loss: 0.490520\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478139; batch adversarial loss: 0.536541\n",
      "epoch 37; iter: 0; batch classifier loss: 0.384903; batch adversarial loss: 0.599115\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483049; batch adversarial loss: 0.516377\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431713; batch adversarial loss: 0.482420\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444177; batch adversarial loss: 0.519170\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459355; batch adversarial loss: 0.508601\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498887; batch adversarial loss: 0.554302\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486956; batch adversarial loss: 0.590121\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483099; batch adversarial loss: 0.536126\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449066; batch adversarial loss: 0.552116\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474689; batch adversarial loss: 0.519926\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383477; batch adversarial loss: 0.561585\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435053; batch adversarial loss: 0.509384\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441253; batch adversarial loss: 0.553881\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393786; batch adversarial loss: 0.624616\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409927; batch adversarial loss: 0.606867\n",
      "epoch 52; iter: 0; batch classifier loss: 0.343196; batch adversarial loss: 0.562295\n",
      "epoch 53; iter: 0; batch classifier loss: 0.475538; batch adversarial loss: 0.624147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424102; batch adversarial loss: 0.606941\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402636; batch adversarial loss: 0.571977\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388477; batch adversarial loss: 0.552221\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420828; batch adversarial loss: 0.599297\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443316; batch adversarial loss: 0.554017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370551; batch adversarial loss: 0.508524\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466554; batch adversarial loss: 0.480185\n",
      "epoch 61; iter: 0; batch classifier loss: 0.365728; batch adversarial loss: 0.581548\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479010; batch adversarial loss: 0.516539\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447470; batch adversarial loss: 0.497322\n",
      "epoch 64; iter: 0; batch classifier loss: 0.490603; batch adversarial loss: 0.589913\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364079; batch adversarial loss: 0.544241\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441856; batch adversarial loss: 0.591746\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392193; batch adversarial loss: 0.536296\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381867; batch adversarial loss: 0.506765\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392450; batch adversarial loss: 0.580244\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422915; batch adversarial loss: 0.600514\n",
      "epoch 71; iter: 0; batch classifier loss: 0.379080; batch adversarial loss: 0.480764\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386222; batch adversarial loss: 0.528774\n",
      "epoch 73; iter: 0; batch classifier loss: 0.469767; batch adversarial loss: 0.507155\n",
      "epoch 74; iter: 0; batch classifier loss: 0.362895; batch adversarial loss: 0.507923\n",
      "epoch 75; iter: 0; batch classifier loss: 0.499799; batch adversarial loss: 0.624253\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359758; batch adversarial loss: 0.530004\n",
      "epoch 77; iter: 0; batch classifier loss: 0.485839; batch adversarial loss: 0.530291\n",
      "epoch 78; iter: 0; batch classifier loss: 0.436195; batch adversarial loss: 0.554934\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375367; batch adversarial loss: 0.528099\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374260; batch adversarial loss: 0.574196\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375059; batch adversarial loss: 0.509343\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388438; batch adversarial loss: 0.500947\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396697; batch adversarial loss: 0.616577\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399292; batch adversarial loss: 0.642675\n",
      "epoch 85; iter: 0; batch classifier loss: 0.460887; batch adversarial loss: 0.535881\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381282; batch adversarial loss: 0.562065\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366367; batch adversarial loss: 0.526987\n",
      "epoch 88; iter: 0; batch classifier loss: 0.350000; batch adversarial loss: 0.490164\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339414; batch adversarial loss: 0.473436\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382235; batch adversarial loss: 0.534792\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441006; batch adversarial loss: 0.571434\n",
      "epoch 92; iter: 0; batch classifier loss: 0.380218; batch adversarial loss: 0.572703\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398432; batch adversarial loss: 0.544713\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390460; batch adversarial loss: 0.554047\n",
      "epoch 95; iter: 0; batch classifier loss: 0.411821; batch adversarial loss: 0.581893\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416273; batch adversarial loss: 0.571415\n",
      "epoch 97; iter: 0; batch classifier loss: 0.431163; batch adversarial loss: 0.598961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388527; batch adversarial loss: 0.490207\n",
      "epoch 99; iter: 0; batch classifier loss: 0.309143; batch adversarial loss: 0.571163\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423195; batch adversarial loss: 0.517531\n",
      "epoch 101; iter: 0; batch classifier loss: 0.431550; batch adversarial loss: 0.561479\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417988; batch adversarial loss: 0.579787\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399210; batch adversarial loss: 0.563738\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370002; batch adversarial loss: 0.527025\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369436; batch adversarial loss: 0.545663\n",
      "epoch 106; iter: 0; batch classifier loss: 0.436655; batch adversarial loss: 0.489492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.352727; batch adversarial loss: 0.436912\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395275; batch adversarial loss: 0.581764\n",
      "epoch 109; iter: 0; batch classifier loss: 0.431309; batch adversarial loss: 0.525523\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408586; batch adversarial loss: 0.544083\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391631; batch adversarial loss: 0.551807\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326434; batch adversarial loss: 0.561980\n",
      "epoch 113; iter: 0; batch classifier loss: 0.336186; batch adversarial loss: 0.553025\n",
      "epoch 114; iter: 0; batch classifier loss: 0.315362; batch adversarial loss: 0.501250\n",
      "epoch 115; iter: 0; batch classifier loss: 0.503484; batch adversarial loss: 0.619976\n",
      "epoch 116; iter: 0; batch classifier loss: 0.421939; batch adversarial loss: 0.582103\n",
      "epoch 117; iter: 0; batch classifier loss: 0.352249; batch adversarial loss: 0.500160\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376547; batch adversarial loss: 0.545264\n",
      "epoch 119; iter: 0; batch classifier loss: 0.409847; batch adversarial loss: 0.526543\n",
      "epoch 120; iter: 0; batch classifier loss: 0.345866; batch adversarial loss: 0.590959\n",
      "epoch 121; iter: 0; batch classifier loss: 0.411251; batch adversarial loss: 0.561010\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364102; batch adversarial loss: 0.545771\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384705; batch adversarial loss: 0.544969\n",
      "epoch 124; iter: 0; batch classifier loss: 0.457156; batch adversarial loss: 0.561759\n",
      "epoch 125; iter: 0; batch classifier loss: 0.299453; batch adversarial loss: 0.508124\n",
      "epoch 126; iter: 0; batch classifier loss: 0.427141; batch adversarial loss: 0.599264\n",
      "epoch 127; iter: 0; batch classifier loss: 0.338047; batch adversarial loss: 0.614389\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364905; batch adversarial loss: 0.581231\n",
      "epoch 129; iter: 0; batch classifier loss: 0.304085; batch adversarial loss: 0.551417\n",
      "epoch 130; iter: 0; batch classifier loss: 0.318272; batch adversarial loss: 0.606998\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375186; batch adversarial loss: 0.511484\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333345; batch adversarial loss: 0.573292\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412127; batch adversarial loss: 0.554296\n",
      "epoch 134; iter: 0; batch classifier loss: 0.317065; batch adversarial loss: 0.527510\n",
      "epoch 135; iter: 0; batch classifier loss: 0.333608; batch adversarial loss: 0.545949\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346128; batch adversarial loss: 0.571389\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305715; batch adversarial loss: 0.482616\n",
      "epoch 138; iter: 0; batch classifier loss: 0.398266; batch adversarial loss: 0.515092\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398747; batch adversarial loss: 0.543659\n",
      "epoch 140; iter: 0; batch classifier loss: 0.443582; batch adversarial loss: 0.580447\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391633; batch adversarial loss: 0.545558\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324546; batch adversarial loss: 0.507347\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387345; batch adversarial loss: 0.488372\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361559; batch adversarial loss: 0.545933\n",
      "epoch 145; iter: 0; batch classifier loss: 0.260264; batch adversarial loss: 0.552883\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403276; batch adversarial loss: 0.536177\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376725; batch adversarial loss: 0.588866\n",
      "epoch 148; iter: 0; batch classifier loss: 0.424331; batch adversarial loss: 0.609709\n",
      "epoch 149; iter: 0; batch classifier loss: 0.455826; batch adversarial loss: 0.579586\n",
      "epoch 150; iter: 0; batch classifier loss: 0.417184; batch adversarial loss: 0.545489\n",
      "epoch 151; iter: 0; batch classifier loss: 0.418396; batch adversarial loss: 0.562950\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403462; batch adversarial loss: 0.534212\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393353; batch adversarial loss: 0.597461\n",
      "epoch 154; iter: 0; batch classifier loss: 0.388968; batch adversarial loss: 0.572426\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343723; batch adversarial loss: 0.463923\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387100; batch adversarial loss: 0.561368\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411351; batch adversarial loss: 0.564384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344965; batch adversarial loss: 0.561764\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347032; batch adversarial loss: 0.535192\n",
      "epoch 160; iter: 0; batch classifier loss: 0.403120; batch adversarial loss: 0.554290\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350295; batch adversarial loss: 0.489867\n",
      "epoch 162; iter: 0; batch classifier loss: 0.425176; batch adversarial loss: 0.606627\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328506; batch adversarial loss: 0.561886\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335185; batch adversarial loss: 0.499444\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344822; batch adversarial loss: 0.606729\n",
      "epoch 166; iter: 0; batch classifier loss: 0.439721; batch adversarial loss: 0.653189\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374746; batch adversarial loss: 0.535367\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390221; batch adversarial loss: 0.572424\n",
      "epoch 169; iter: 0; batch classifier loss: 0.437910; batch adversarial loss: 0.579399\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374515; batch adversarial loss: 0.534848\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295950; batch adversarial loss: 0.581041\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317412; batch adversarial loss: 0.625843\n",
      "epoch 173; iter: 0; batch classifier loss: 0.374098; batch adversarial loss: 0.571699\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355733; batch adversarial loss: 0.535523\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363436; batch adversarial loss: 0.607444\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373070; batch adversarial loss: 0.578029\n",
      "epoch 177; iter: 0; batch classifier loss: 0.359848; batch adversarial loss: 0.589914\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354126; batch adversarial loss: 0.544466\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369318; batch adversarial loss: 0.525766\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352010; batch adversarial loss: 0.587589\n",
      "epoch 181; iter: 0; batch classifier loss: 0.329871; batch adversarial loss: 0.543664\n",
      "epoch 182; iter: 0; batch classifier loss: 0.459452; batch adversarial loss: 0.544647\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384871; batch adversarial loss: 0.501245\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386327; batch adversarial loss: 0.570602\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393660; batch adversarial loss: 0.499830\n",
      "epoch 186; iter: 0; batch classifier loss: 0.395327; batch adversarial loss: 0.517287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387467; batch adversarial loss: 0.471842\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363762; batch adversarial loss: 0.526214\n",
      "epoch 189; iter: 0; batch classifier loss: 0.434244; batch adversarial loss: 0.617154\n",
      "epoch 190; iter: 0; batch classifier loss: 0.422440; batch adversarial loss: 0.590326\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325113; batch adversarial loss: 0.580995\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357465; batch adversarial loss: 0.608648\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398303; batch adversarial loss: 0.562344\n",
      "epoch 194; iter: 0; batch classifier loss: 0.415496; batch adversarial loss: 0.499812\n",
      "epoch 195; iter: 0; batch classifier loss: 0.348209; batch adversarial loss: 0.483516\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327209; batch adversarial loss: 0.580488\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386405; batch adversarial loss: 0.588002\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357921; batch adversarial loss: 0.597934\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401864; batch adversarial loss: 0.588215\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727574; batch adversarial loss: 0.587346\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622731; batch adversarial loss: 0.625688\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572001; batch adversarial loss: 0.613090\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576226; batch adversarial loss: 0.623517\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595394; batch adversarial loss: 0.601936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.555867; batch adversarial loss: 0.650865\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612084; batch adversarial loss: 0.570254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546137; batch adversarial loss: 0.690445\n",
      "epoch 8; iter: 0; batch classifier loss: 0.597945; batch adversarial loss: 0.577408\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443559; batch adversarial loss: 0.557894\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561759; batch adversarial loss: 0.607269\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500786; batch adversarial loss: 0.542640\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545864; batch adversarial loss: 0.593881\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512647; batch adversarial loss: 0.596964\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509762; batch adversarial loss: 0.533889\n",
      "epoch 15; iter: 0; batch classifier loss: 0.545965; batch adversarial loss: 0.580237\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512407; batch adversarial loss: 0.552706\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480526; batch adversarial loss: 0.515077\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490299; batch adversarial loss: 0.591899\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538096; batch adversarial loss: 0.506867\n",
      "epoch 20; iter: 0; batch classifier loss: 0.455832; batch adversarial loss: 0.611363\n",
      "epoch 21; iter: 0; batch classifier loss: 0.419865; batch adversarial loss: 0.604608\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455916; batch adversarial loss: 0.526675\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414318; batch adversarial loss: 0.540642\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497525; batch adversarial loss: 0.585375\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424807; batch adversarial loss: 0.586836\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449167; batch adversarial loss: 0.540061\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427757; batch adversarial loss: 0.562806\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484302; batch adversarial loss: 0.486004\n",
      "epoch 29; iter: 0; batch classifier loss: 0.567250; batch adversarial loss: 0.519614\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473253; batch adversarial loss: 0.527917\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444857; batch adversarial loss: 0.579728\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497307; batch adversarial loss: 0.579845\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465164; batch adversarial loss: 0.610559\n",
      "epoch 34; iter: 0; batch classifier loss: 0.498200; batch adversarial loss: 0.592965\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443978; batch adversarial loss: 0.535074\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415041; batch adversarial loss: 0.616445\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388933; batch adversarial loss: 0.521764\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453404; batch adversarial loss: 0.560977\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481657; batch adversarial loss: 0.531104\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500822; batch adversarial loss: 0.537485\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450650; batch adversarial loss: 0.560344\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445366; batch adversarial loss: 0.553452\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425928; batch adversarial loss: 0.567171\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395476; batch adversarial loss: 0.536750\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432291; batch adversarial loss: 0.524636\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462724; batch adversarial loss: 0.549955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440792; batch adversarial loss: 0.620068\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418262; batch adversarial loss: 0.629711\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373533; batch adversarial loss: 0.563462\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390416; batch adversarial loss: 0.527931\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442967; batch adversarial loss: 0.553316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406693; batch adversarial loss: 0.567247\n",
      "epoch 53; iter: 0; batch classifier loss: 0.398692; batch adversarial loss: 0.514338\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384225; batch adversarial loss: 0.599885\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430863; batch adversarial loss: 0.554905\n",
      "epoch 56; iter: 0; batch classifier loss: 0.512249; batch adversarial loss: 0.505157\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443278; batch adversarial loss: 0.591728\n",
      "epoch 58; iter: 0; batch classifier loss: 0.482035; batch adversarial loss: 0.450740\n",
      "epoch 59; iter: 0; batch classifier loss: 0.358400; batch adversarial loss: 0.536858\n",
      "epoch 60; iter: 0; batch classifier loss: 0.453312; batch adversarial loss: 0.549672\n",
      "epoch 61; iter: 0; batch classifier loss: 0.503231; batch adversarial loss: 0.495579\n",
      "epoch 62; iter: 0; batch classifier loss: 0.361771; batch adversarial loss: 0.609812\n",
      "epoch 63; iter: 0; batch classifier loss: 0.481970; batch adversarial loss: 0.597094\n",
      "epoch 64; iter: 0; batch classifier loss: 0.519824; batch adversarial loss: 0.457225\n",
      "epoch 65; iter: 0; batch classifier loss: 0.339894; batch adversarial loss: 0.516937\n",
      "epoch 66; iter: 0; batch classifier loss: 0.364893; batch adversarial loss: 0.587767\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412750; batch adversarial loss: 0.531519\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397044; batch adversarial loss: 0.574598\n",
      "epoch 69; iter: 0; batch classifier loss: 0.484225; batch adversarial loss: 0.560560\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417950; batch adversarial loss: 0.625926\n",
      "epoch 71; iter: 0; batch classifier loss: 0.430139; batch adversarial loss: 0.559495\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414345; batch adversarial loss: 0.596854\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420754; batch adversarial loss: 0.562607\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408407; batch adversarial loss: 0.504442\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381012; batch adversarial loss: 0.544348\n",
      "epoch 76; iter: 0; batch classifier loss: 0.401251; batch adversarial loss: 0.418709\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371748; batch adversarial loss: 0.611337\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352205; batch adversarial loss: 0.589081\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401394; batch adversarial loss: 0.572269\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389959; batch adversarial loss: 0.551134\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423344; batch adversarial loss: 0.542341\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388389; batch adversarial loss: 0.556241\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428466; batch adversarial loss: 0.486397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383393; batch adversarial loss: 0.553643\n",
      "epoch 85; iter: 0; batch classifier loss: 0.504037; batch adversarial loss: 0.542097\n",
      "epoch 86; iter: 0; batch classifier loss: 0.464998; batch adversarial loss: 0.500676\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363278; batch adversarial loss: 0.501503\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376179; batch adversarial loss: 0.593349\n",
      "epoch 89; iter: 0; batch classifier loss: 0.418980; batch adversarial loss: 0.572644\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450070; batch adversarial loss: 0.624575\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460398; batch adversarial loss: 0.546260\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424824; batch adversarial loss: 0.518001\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413542; batch adversarial loss: 0.508175\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434914; batch adversarial loss: 0.583604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.363592; batch adversarial loss: 0.554738\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425375; batch adversarial loss: 0.625524\n",
      "epoch 97; iter: 0; batch classifier loss: 0.429056; batch adversarial loss: 0.544207\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358361; batch adversarial loss: 0.539348\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366698; batch adversarial loss: 0.540227\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373487; batch adversarial loss: 0.567074\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364953; batch adversarial loss: 0.530283\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340269; batch adversarial loss: 0.518392\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418728; batch adversarial loss: 0.600876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.359470; batch adversarial loss: 0.551349\n",
      "epoch 105; iter: 0; batch classifier loss: 0.336411; batch adversarial loss: 0.550484\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331992; batch adversarial loss: 0.527967\n",
      "epoch 107; iter: 0; batch classifier loss: 0.411218; batch adversarial loss: 0.502277\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379767; batch adversarial loss: 0.548900\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355677; batch adversarial loss: 0.574878\n",
      "epoch 110; iter: 0; batch classifier loss: 0.415634; batch adversarial loss: 0.561640\n",
      "epoch 111; iter: 0; batch classifier loss: 0.449723; batch adversarial loss: 0.483454\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414156; batch adversarial loss: 0.582691\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413711; batch adversarial loss: 0.482779\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372566; batch adversarial loss: 0.540404\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364825; batch adversarial loss: 0.517939\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417807; batch adversarial loss: 0.474014\n",
      "epoch 117; iter: 0; batch classifier loss: 0.434179; batch adversarial loss: 0.556774\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435045; batch adversarial loss: 0.545055\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344631; batch adversarial loss: 0.563828\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354254; batch adversarial loss: 0.552268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.332974; batch adversarial loss: 0.587484\n",
      "epoch 122; iter: 0; batch classifier loss: 0.458649; batch adversarial loss: 0.627435\n",
      "epoch 123; iter: 0; batch classifier loss: 0.452176; batch adversarial loss: 0.572008\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426793; batch adversarial loss: 0.512783\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408276; batch adversarial loss: 0.541625\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334329; batch adversarial loss: 0.562194\n",
      "epoch 127; iter: 0; batch classifier loss: 0.357831; batch adversarial loss: 0.499586\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334305; batch adversarial loss: 0.550515\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370988; batch adversarial loss: 0.523146\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345128; batch adversarial loss: 0.500922\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335318; batch adversarial loss: 0.592672\n",
      "epoch 132; iter: 0; batch classifier loss: 0.336943; batch adversarial loss: 0.542119\n",
      "epoch 133; iter: 0; batch classifier loss: 0.449897; batch adversarial loss: 0.534897\n",
      "epoch 134; iter: 0; batch classifier loss: 0.347660; batch adversarial loss: 0.566649\n",
      "epoch 135; iter: 0; batch classifier loss: 0.393205; batch adversarial loss: 0.572938\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324467; batch adversarial loss: 0.520821\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407419; batch adversarial loss: 0.518639\n",
      "epoch 138; iter: 0; batch classifier loss: 0.325392; batch adversarial loss: 0.586062\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343565; batch adversarial loss: 0.562509\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374703; batch adversarial loss: 0.538715\n",
      "epoch 141; iter: 0; batch classifier loss: 0.309341; batch adversarial loss: 0.622752\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428725; batch adversarial loss: 0.501956\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397589; batch adversarial loss: 0.544931\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392452; batch adversarial loss: 0.600318\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407307; batch adversarial loss: 0.562443\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375797; batch adversarial loss: 0.531868\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359362; batch adversarial loss: 0.544638\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368979; batch adversarial loss: 0.563220\n",
      "epoch 149; iter: 0; batch classifier loss: 0.412291; batch adversarial loss: 0.541914\n",
      "epoch 150; iter: 0; batch classifier loss: 0.300280; batch adversarial loss: 0.523012\n",
      "epoch 151; iter: 0; batch classifier loss: 0.454066; batch adversarial loss: 0.509706\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339018; batch adversarial loss: 0.600340\n",
      "epoch 153; iter: 0; batch classifier loss: 0.450311; batch adversarial loss: 0.532402\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362413; batch adversarial loss: 0.527515\n",
      "epoch 155; iter: 0; batch classifier loss: 0.361462; batch adversarial loss: 0.568265\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373729; batch adversarial loss: 0.510328\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368957; batch adversarial loss: 0.489038\n",
      "epoch 158; iter: 0; batch classifier loss: 0.446247; batch adversarial loss: 0.505434\n",
      "epoch 159; iter: 0; batch classifier loss: 0.456959; batch adversarial loss: 0.508388\n",
      "epoch 160; iter: 0; batch classifier loss: 0.420344; batch adversarial loss: 0.583566\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350139; batch adversarial loss: 0.552524\n",
      "epoch 162; iter: 0; batch classifier loss: 0.339195; batch adversarial loss: 0.497554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.264320; batch adversarial loss: 0.714660\n",
      "epoch 164; iter: 0; batch classifier loss: 0.433553; batch adversarial loss: 0.564342\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377131; batch adversarial loss: 0.459346\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406221; batch adversarial loss: 0.552071\n",
      "epoch 167; iter: 0; batch classifier loss: 0.330372; batch adversarial loss: 0.540152\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402757; batch adversarial loss: 0.499871\n",
      "epoch 169; iter: 0; batch classifier loss: 0.397716; batch adversarial loss: 0.519042\n",
      "epoch 170; iter: 0; batch classifier loss: 0.295998; batch adversarial loss: 0.465997\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340801; batch adversarial loss: 0.572886\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354738; batch adversarial loss: 0.578684\n",
      "epoch 173; iter: 0; batch classifier loss: 0.445941; batch adversarial loss: 0.608190\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373343; batch adversarial loss: 0.520108\n",
      "epoch 175; iter: 0; batch classifier loss: 0.305108; batch adversarial loss: 0.596720\n",
      "epoch 176; iter: 0; batch classifier loss: 0.402106; batch adversarial loss: 0.500123\n",
      "epoch 177; iter: 0; batch classifier loss: 0.320637; batch adversarial loss: 0.507121\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345044; batch adversarial loss: 0.644994\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321413; batch adversarial loss: 0.583911\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392132; batch adversarial loss: 0.513514\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364670; batch adversarial loss: 0.558531\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390224; batch adversarial loss: 0.598167\n",
      "epoch 183; iter: 0; batch classifier loss: 0.377400; batch adversarial loss: 0.493328\n",
      "epoch 184; iter: 0; batch classifier loss: 0.439350; batch adversarial loss: 0.514712\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367699; batch adversarial loss: 0.506052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327491; batch adversarial loss: 0.534312\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353559; batch adversarial loss: 0.480676\n",
      "epoch 188; iter: 0; batch classifier loss: 0.419535; batch adversarial loss: 0.469873\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323814; batch adversarial loss: 0.592318\n",
      "epoch 190; iter: 0; batch classifier loss: 0.467608; batch adversarial loss: 0.530182\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360986; batch adversarial loss: 0.454851\n",
      "epoch 192; iter: 0; batch classifier loss: 0.445462; batch adversarial loss: 0.611196\n",
      "epoch 193; iter: 0; batch classifier loss: 0.281031; batch adversarial loss: 0.552012\n",
      "epoch 194; iter: 0; batch classifier loss: 0.400092; batch adversarial loss: 0.543248\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384039; batch adversarial loss: 0.524698\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332172; batch adversarial loss: 0.517384\n",
      "epoch 197; iter: 0; batch classifier loss: 0.371972; batch adversarial loss: 0.554672\n",
      "epoch 198; iter: 0; batch classifier loss: 0.416410; batch adversarial loss: 0.536042\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364635; batch adversarial loss: 0.532637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.705663; batch adversarial loss: 0.632261\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544703; batch adversarial loss: 0.621731\n",
      "epoch 2; iter: 0; batch classifier loss: 0.638924; batch adversarial loss: 0.653630\n",
      "epoch 3; iter: 0; batch classifier loss: 0.595962; batch adversarial loss: 0.601643\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549419; batch adversarial loss: 0.582885\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516931; batch adversarial loss: 0.607864\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608715; batch adversarial loss: 0.582706\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546332; batch adversarial loss: 0.574435\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580048; batch adversarial loss: 0.579820\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527854; batch adversarial loss: 0.578539\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554007; batch adversarial loss: 0.543207\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564569; batch adversarial loss: 0.621809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499653; batch adversarial loss: 0.594370\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495209; batch adversarial loss: 0.570491\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541681; batch adversarial loss: 0.518725\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511761; batch adversarial loss: 0.572572\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500967; batch adversarial loss: 0.537018\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552515; batch adversarial loss: 0.577126\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491878; batch adversarial loss: 0.528107\n",
      "epoch 19; iter: 0; batch classifier loss: 0.570663; batch adversarial loss: 0.561737\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430235; batch adversarial loss: 0.557759\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504192; batch adversarial loss: 0.565327\n",
      "epoch 22; iter: 0; batch classifier loss: 0.461524; batch adversarial loss: 0.535239\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508527; batch adversarial loss: 0.546255\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481400; batch adversarial loss: 0.557843\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479137; batch adversarial loss: 0.498723\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506780; batch adversarial loss: 0.628061\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459438; batch adversarial loss: 0.470216\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523985; batch adversarial loss: 0.588819\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494587; batch adversarial loss: 0.570619\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443543; batch adversarial loss: 0.543109\n",
      "epoch 31; iter: 0; batch classifier loss: 0.386966; batch adversarial loss: 0.498101\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443174; batch adversarial loss: 0.549590\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483485; batch adversarial loss: 0.601365\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427117; batch adversarial loss: 0.588217\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436016; batch adversarial loss: 0.571939\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436689; batch adversarial loss: 0.563807\n",
      "epoch 37; iter: 0; batch classifier loss: 0.507613; batch adversarial loss: 0.575376\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476004; batch adversarial loss: 0.465487\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473023; batch adversarial loss: 0.484496\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439558; batch adversarial loss: 0.561965\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506812; batch adversarial loss: 0.543272\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481132; batch adversarial loss: 0.584743\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473343; batch adversarial loss: 0.441546\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408999; batch adversarial loss: 0.509918\n",
      "epoch 45; iter: 0; batch classifier loss: 0.517313; batch adversarial loss: 0.481011\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402146; batch adversarial loss: 0.523127\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366725; batch adversarial loss: 0.552230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424901; batch adversarial loss: 0.562395\n",
      "epoch 49; iter: 0; batch classifier loss: 0.485904; batch adversarial loss: 0.546894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463067; batch adversarial loss: 0.508759\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483403; batch adversarial loss: 0.595768\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438912; batch adversarial loss: 0.616342\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437805; batch adversarial loss: 0.517946\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447847; batch adversarial loss: 0.562548\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440606; batch adversarial loss: 0.545064\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425333; batch adversarial loss: 0.554413\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468913; batch adversarial loss: 0.608952\n",
      "epoch 58; iter: 0; batch classifier loss: 0.406679; batch adversarial loss: 0.609323\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412767; batch adversarial loss: 0.563209\n",
      "epoch 60; iter: 0; batch classifier loss: 0.486435; batch adversarial loss: 0.516945\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459529; batch adversarial loss: 0.480420\n",
      "epoch 62; iter: 0; batch classifier loss: 0.461553; batch adversarial loss: 0.535176\n",
      "epoch 63; iter: 0; batch classifier loss: 0.360554; batch adversarial loss: 0.618201\n",
      "epoch 64; iter: 0; batch classifier loss: 0.338357; batch adversarial loss: 0.526190\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393121; batch adversarial loss: 0.599714\n",
      "epoch 66; iter: 0; batch classifier loss: 0.332696; batch adversarial loss: 0.562948\n",
      "epoch 67; iter: 0; batch classifier loss: 0.469765; batch adversarial loss: 0.517392\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455206; batch adversarial loss: 0.571768\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430582; batch adversarial loss: 0.562805\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416112; batch adversarial loss: 0.517300\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444186; batch adversarial loss: 0.535615\n",
      "epoch 72; iter: 0; batch classifier loss: 0.460243; batch adversarial loss: 0.555508\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433627; batch adversarial loss: 0.581213\n",
      "epoch 74; iter: 0; batch classifier loss: 0.336986; batch adversarial loss: 0.507599\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420887; batch adversarial loss: 0.590399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394045; batch adversarial loss: 0.635333\n",
      "epoch 77; iter: 0; batch classifier loss: 0.358518; batch adversarial loss: 0.607809\n",
      "epoch 78; iter: 0; batch classifier loss: 0.443913; batch adversarial loss: 0.553447\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452096; batch adversarial loss: 0.554270\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420082; batch adversarial loss: 0.634323\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369996; batch adversarial loss: 0.489649\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411247; batch adversarial loss: 0.534845\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423089; batch adversarial loss: 0.552959\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403753; batch adversarial loss: 0.498492\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383819; batch adversarial loss: 0.553692\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374112; batch adversarial loss: 0.544402\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403083; batch adversarial loss: 0.653744\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370877; batch adversarial loss: 0.562248\n",
      "epoch 89; iter: 0; batch classifier loss: 0.420610; batch adversarial loss: 0.544156\n",
      "epoch 90; iter: 0; batch classifier loss: 0.453243; batch adversarial loss: 0.507914\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395371; batch adversarial loss: 0.572132\n",
      "epoch 92; iter: 0; batch classifier loss: 0.452477; batch adversarial loss: 0.517666\n",
      "epoch 93; iter: 0; batch classifier loss: 0.458327; batch adversarial loss: 0.562876\n",
      "epoch 94; iter: 0; batch classifier loss: 0.403473; batch adversarial loss: 0.608162\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395000; batch adversarial loss: 0.526097\n",
      "epoch 96; iter: 0; batch classifier loss: 0.446602; batch adversarial loss: 0.507237\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436779; batch adversarial loss: 0.508307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.372324; batch adversarial loss: 0.607000\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405842; batch adversarial loss: 0.517862\n",
      "epoch 100; iter: 0; batch classifier loss: 0.440379; batch adversarial loss: 0.517857\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376597; batch adversarial loss: 0.571292\n",
      "epoch 102; iter: 0; batch classifier loss: 0.419056; batch adversarial loss: 0.480873\n",
      "epoch 103; iter: 0; batch classifier loss: 0.454400; batch adversarial loss: 0.526125\n",
      "epoch 104; iter: 0; batch classifier loss: 0.345936; batch adversarial loss: 0.581420\n",
      "epoch 105; iter: 0; batch classifier loss: 0.316252; batch adversarial loss: 0.553336\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369407; batch adversarial loss: 0.500605\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410595; batch adversarial loss: 0.517153\n",
      "epoch 108; iter: 0; batch classifier loss: 0.521636; batch adversarial loss: 0.598359\n",
      "epoch 109; iter: 0; batch classifier loss: 0.460654; batch adversarial loss: 0.517348\n",
      "epoch 110; iter: 0; batch classifier loss: 0.444144; batch adversarial loss: 0.536186\n",
      "epoch 111; iter: 0; batch classifier loss: 0.419914; batch adversarial loss: 0.561868\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409524; batch adversarial loss: 0.589432\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343251; batch adversarial loss: 0.481645\n",
      "epoch 114; iter: 0; batch classifier loss: 0.462049; batch adversarial loss: 0.499384\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423752; batch adversarial loss: 0.507284\n",
      "epoch 116; iter: 0; batch classifier loss: 0.270235; batch adversarial loss: 0.552408\n",
      "epoch 117; iter: 0; batch classifier loss: 0.464932; batch adversarial loss: 0.481932\n",
      "epoch 118; iter: 0; batch classifier loss: 0.349895; batch adversarial loss: 0.662783\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402694; batch adversarial loss: 0.562595\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343470; batch adversarial loss: 0.562789\n",
      "epoch 121; iter: 0; batch classifier loss: 0.429871; batch adversarial loss: 0.489670\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424184; batch adversarial loss: 0.527444\n",
      "epoch 123; iter: 0; batch classifier loss: 0.405124; batch adversarial loss: 0.543176\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372694; batch adversarial loss: 0.535529\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372513; batch adversarial loss: 0.526349\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394225; batch adversarial loss: 0.553512\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388390; batch adversarial loss: 0.600329\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350395; batch adversarial loss: 0.563184\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406040; batch adversarial loss: 0.472837\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.533070\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384102; batch adversarial loss: 0.544621\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394941; batch adversarial loss: 0.535344\n",
      "epoch 133; iter: 0; batch classifier loss: 0.439378; batch adversarial loss: 0.570895\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440478; batch adversarial loss: 0.534145\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400390; batch adversarial loss: 0.516497\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312168; batch adversarial loss: 0.518234\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347152; batch adversarial loss: 0.535410\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360748; batch adversarial loss: 0.581328\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416503; batch adversarial loss: 0.562245\n",
      "epoch 140; iter: 0; batch classifier loss: 0.454173; batch adversarial loss: 0.609331\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363788; batch adversarial loss: 0.570799\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371471; batch adversarial loss: 0.608263\n",
      "epoch 143; iter: 0; batch classifier loss: 0.470555; batch adversarial loss: 0.508012\n",
      "epoch 144; iter: 0; batch classifier loss: 0.443410; batch adversarial loss: 0.598874\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377473; batch adversarial loss: 0.581079\n",
      "epoch 146; iter: 0; batch classifier loss: 0.433729; batch adversarial loss: 0.617483\n",
      "epoch 147; iter: 0; batch classifier loss: 0.481794; batch adversarial loss: 0.446066\n",
      "epoch 148; iter: 0; batch classifier loss: 0.421950; batch adversarial loss: 0.571776\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319623; batch adversarial loss: 0.634656\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379878; batch adversarial loss: 0.490498\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417193; batch adversarial loss: 0.535585\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352365; batch adversarial loss: 0.560845\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355951; batch adversarial loss: 0.534193\n",
      "epoch 154; iter: 0; batch classifier loss: 0.523025; batch adversarial loss: 0.553384\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389328; batch adversarial loss: 0.608310\n",
      "epoch 156; iter: 0; batch classifier loss: 0.441307; batch adversarial loss: 0.608010\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393489; batch adversarial loss: 0.542743\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390101; batch adversarial loss: 0.598387\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387749; batch adversarial loss: 0.545904\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323645; batch adversarial loss: 0.527038\n",
      "epoch 161; iter: 0; batch classifier loss: 0.320644; batch adversarial loss: 0.554320\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386514; batch adversarial loss: 0.697737\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328475; batch adversarial loss: 0.472313\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387695; batch adversarial loss: 0.482318\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393872; batch adversarial loss: 0.534979\n",
      "epoch 166; iter: 0; batch classifier loss: 0.386929; batch adversarial loss: 0.552115\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362334; batch adversarial loss: 0.526860\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398899; batch adversarial loss: 0.564488\n",
      "epoch 169; iter: 0; batch classifier loss: 0.437259; batch adversarial loss: 0.525949\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410339; batch adversarial loss: 0.508662\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323978; batch adversarial loss: 0.617936\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343744; batch adversarial loss: 0.526165\n",
      "epoch 173; iter: 0; batch classifier loss: 0.290676; batch adversarial loss: 0.571226\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302772; batch adversarial loss: 0.517569\n",
      "epoch 175; iter: 0; batch classifier loss: 0.367704; batch adversarial loss: 0.515848\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346485; batch adversarial loss: 0.535806\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356197; batch adversarial loss: 0.490917\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372446; batch adversarial loss: 0.572125\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348785; batch adversarial loss: 0.553084\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371204; batch adversarial loss: 0.588742\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379689; batch adversarial loss: 0.500387\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351190; batch adversarial loss: 0.506032\n",
      "epoch 183; iter: 0; batch classifier loss: 0.288978; batch adversarial loss: 0.491185\n",
      "epoch 184; iter: 0; batch classifier loss: 0.432292; batch adversarial loss: 0.635876\n",
      "epoch 185; iter: 0; batch classifier loss: 0.314534; batch adversarial loss: 0.589812\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357636; batch adversarial loss: 0.517130\n",
      "epoch 187; iter: 0; batch classifier loss: 0.320942; batch adversarial loss: 0.553625\n",
      "epoch 188; iter: 0; batch classifier loss: 0.320155; batch adversarial loss: 0.563083\n",
      "epoch 189; iter: 0; batch classifier loss: 0.436898; batch adversarial loss: 0.527295\n",
      "epoch 190; iter: 0; batch classifier loss: 0.348539; batch adversarial loss: 0.543872\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391943; batch adversarial loss: 0.535817\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397204; batch adversarial loss: 0.624508\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335310; batch adversarial loss: 0.608859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.358169; batch adversarial loss: 0.653790\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358551; batch adversarial loss: 0.653164\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345056; batch adversarial loss: 0.517760\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405007; batch adversarial loss: 0.463695\n",
      "epoch 198; iter: 0; batch classifier loss: 0.385377; batch adversarial loss: 0.519278\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347781; batch adversarial loss: 0.525352\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743061; batch adversarial loss: 0.761182\n",
      "epoch 1; iter: 0; batch classifier loss: 0.719843; batch adversarial loss: 0.719495\n",
      "epoch 2; iter: 0; batch classifier loss: 0.714750; batch adversarial loss: 0.666639\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583558; batch adversarial loss: 0.646740\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550478; batch adversarial loss: 0.620896\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578665; batch adversarial loss: 0.605512\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553827; batch adversarial loss: 0.609821\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554586; batch adversarial loss: 0.619863\n",
      "epoch 8; iter: 0; batch classifier loss: 0.603885; batch adversarial loss: 0.575737\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527095; batch adversarial loss: 0.588646\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574464; batch adversarial loss: 0.597244\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509407; batch adversarial loss: 0.577216\n",
      "epoch 12; iter: 0; batch classifier loss: 0.592032; batch adversarial loss: 0.605703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580089; batch adversarial loss: 0.556332\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503463; batch adversarial loss: 0.568377\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482803; batch adversarial loss: 0.543977\n",
      "epoch 16; iter: 0; batch classifier loss: 0.555466; batch adversarial loss: 0.548067\n",
      "epoch 17; iter: 0; batch classifier loss: 0.593403; batch adversarial loss: 0.623879\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518774; batch adversarial loss: 0.570289\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441854; batch adversarial loss: 0.604409\n",
      "epoch 20; iter: 0; batch classifier loss: 0.549657; batch adversarial loss: 0.549610\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498971; batch adversarial loss: 0.536369\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488917; batch adversarial loss: 0.594982\n",
      "epoch 23; iter: 0; batch classifier loss: 0.553099; batch adversarial loss: 0.572797\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498828; batch adversarial loss: 0.602886\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524390; batch adversarial loss: 0.672592\n",
      "epoch 26; iter: 0; batch classifier loss: 0.588588; batch adversarial loss: 0.558434\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450210; batch adversarial loss: 0.582673\n",
      "epoch 28; iter: 0; batch classifier loss: 0.466427; batch adversarial loss: 0.555165\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476656; batch adversarial loss: 0.540313\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509831; batch adversarial loss: 0.570901\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454167; batch adversarial loss: 0.522636\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466414; batch adversarial loss: 0.595984\n",
      "epoch 33; iter: 0; batch classifier loss: 0.541518; batch adversarial loss: 0.595312\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439683; batch adversarial loss: 0.521045\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444847; batch adversarial loss: 0.587478\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448693; batch adversarial loss: 0.503036\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503723; batch adversarial loss: 0.562351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463808; batch adversarial loss: 0.579641\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410472; batch adversarial loss: 0.544971\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469260; batch adversarial loss: 0.553375\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425821; batch adversarial loss: 0.561948\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427135; batch adversarial loss: 0.570331\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480113; batch adversarial loss: 0.623520\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366506; batch adversarial loss: 0.596445\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451244; batch adversarial loss: 0.596878\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496618; batch adversarial loss: 0.570722\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440066; batch adversarial loss: 0.589148\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405318; batch adversarial loss: 0.604488\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471208; batch adversarial loss: 0.588944\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460267; batch adversarial loss: 0.482307\n",
      "epoch 51; iter: 0; batch classifier loss: 0.352077; batch adversarial loss: 0.509846\n",
      "epoch 52; iter: 0; batch classifier loss: 0.358381; batch adversarial loss: 0.550934\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422328; batch adversarial loss: 0.570663\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440645; batch adversarial loss: 0.569891\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439500; batch adversarial loss: 0.615674\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443411; batch adversarial loss: 0.568010\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429841; batch adversarial loss: 0.544394\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422599; batch adversarial loss: 0.578273\n",
      "epoch 59; iter: 0; batch classifier loss: 0.389056; batch adversarial loss: 0.559877\n",
      "epoch 60; iter: 0; batch classifier loss: 0.459698; batch adversarial loss: 0.562031\n",
      "epoch 61; iter: 0; batch classifier loss: 0.365675; batch adversarial loss: 0.528440\n",
      "epoch 62; iter: 0; batch classifier loss: 0.363694; batch adversarial loss: 0.571483\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403705; batch adversarial loss: 0.669348\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407452; batch adversarial loss: 0.518604\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375149; batch adversarial loss: 0.581255\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425562; batch adversarial loss: 0.584080\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430768; batch adversarial loss: 0.586557\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399830; batch adversarial loss: 0.539165\n",
      "epoch 69; iter: 0; batch classifier loss: 0.520223; batch adversarial loss: 0.517248\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430769; batch adversarial loss: 0.606147\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425169; batch adversarial loss: 0.593650\n",
      "epoch 72; iter: 0; batch classifier loss: 0.426055; batch adversarial loss: 0.512481\n",
      "epoch 73; iter: 0; batch classifier loss: 0.460814; batch adversarial loss: 0.605838\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367126; batch adversarial loss: 0.564430\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408661; batch adversarial loss: 0.518300\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410974; batch adversarial loss: 0.635458\n",
      "epoch 77; iter: 0; batch classifier loss: 0.347268; batch adversarial loss: 0.544801\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438597; batch adversarial loss: 0.606696\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390041; batch adversarial loss: 0.630073\n",
      "epoch 80; iter: 0; batch classifier loss: 0.488968; batch adversarial loss: 0.608498\n",
      "epoch 81; iter: 0; batch classifier loss: 0.486170; batch adversarial loss: 0.500790\n",
      "epoch 82; iter: 0; batch classifier loss: 0.429411; batch adversarial loss: 0.598564\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407185; batch adversarial loss: 0.527367\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404226; batch adversarial loss: 0.558642\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435904; batch adversarial loss: 0.587565\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393428; batch adversarial loss: 0.531842\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369317; batch adversarial loss: 0.465806\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348572; batch adversarial loss: 0.582438\n",
      "epoch 89; iter: 0; batch classifier loss: 0.331240; batch adversarial loss: 0.541500\n",
      "epoch 90; iter: 0; batch classifier loss: 0.436484; batch adversarial loss: 0.464308\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372122; batch adversarial loss: 0.541632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.431606; batch adversarial loss: 0.572206\n",
      "epoch 93; iter: 0; batch classifier loss: 0.293955; batch adversarial loss: 0.563913\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402840; batch adversarial loss: 0.536926\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395810; batch adversarial loss: 0.560474\n",
      "epoch 96; iter: 0; batch classifier loss: 0.362870; batch adversarial loss: 0.563295\n",
      "epoch 97; iter: 0; batch classifier loss: 0.353575; batch adversarial loss: 0.618948\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402055; batch adversarial loss: 0.518229\n",
      "epoch 99; iter: 0; batch classifier loss: 0.323696; batch adversarial loss: 0.543829\n",
      "epoch 100; iter: 0; batch classifier loss: 0.480456; batch adversarial loss: 0.527916\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356656; batch adversarial loss: 0.506467\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417244; batch adversarial loss: 0.553445\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402708; batch adversarial loss: 0.528365\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375246; batch adversarial loss: 0.538980\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406006; batch adversarial loss: 0.617022\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360864; batch adversarial loss: 0.550795\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428950; batch adversarial loss: 0.646941\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371255; batch adversarial loss: 0.549685\n",
      "epoch 109; iter: 0; batch classifier loss: 0.467194; batch adversarial loss: 0.509721\n",
      "epoch 110; iter: 0; batch classifier loss: 0.335161; batch adversarial loss: 0.517153\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375187; batch adversarial loss: 0.570226\n",
      "epoch 112; iter: 0; batch classifier loss: 0.340153; batch adversarial loss: 0.577840\n",
      "epoch 113; iter: 0; batch classifier loss: 0.447977; batch adversarial loss: 0.515921\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403599; batch adversarial loss: 0.581996\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388814; batch adversarial loss: 0.551945\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373006; batch adversarial loss: 0.615044\n",
      "epoch 117; iter: 0; batch classifier loss: 0.451854; batch adversarial loss: 0.630201\n",
      "epoch 118; iter: 0; batch classifier loss: 0.423509; batch adversarial loss: 0.567928\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399698; batch adversarial loss: 0.502136\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400409; batch adversarial loss: 0.589296\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369977; batch adversarial loss: 0.581867\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410489; batch adversarial loss: 0.463098\n",
      "epoch 123; iter: 0; batch classifier loss: 0.471387; batch adversarial loss: 0.532202\n",
      "epoch 124; iter: 0; batch classifier loss: 0.421939; batch adversarial loss: 0.516895\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392875; batch adversarial loss: 0.457993\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351274; batch adversarial loss: 0.520259\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360107; batch adversarial loss: 0.573605\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403363; batch adversarial loss: 0.554573\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373653; batch adversarial loss: 0.582363\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356377; batch adversarial loss: 0.617191\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368732; batch adversarial loss: 0.585290\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313931; batch adversarial loss: 0.538631\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415754; batch adversarial loss: 0.603993\n",
      "epoch 134; iter: 0; batch classifier loss: 0.318970; batch adversarial loss: 0.623694\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352772; batch adversarial loss: 0.581793\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368705; batch adversarial loss: 0.576642\n",
      "epoch 137; iter: 0; batch classifier loss: 0.300000; batch adversarial loss: 0.553333\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418848; batch adversarial loss: 0.601440\n",
      "epoch 139; iter: 0; batch classifier loss: 0.480421; batch adversarial loss: 0.572474\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381636; batch adversarial loss: 0.550144\n",
      "epoch 141; iter: 0; batch classifier loss: 0.312319; batch adversarial loss: 0.582778\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346605; batch adversarial loss: 0.571817\n",
      "epoch 143; iter: 0; batch classifier loss: 0.300929; batch adversarial loss: 0.596889\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342113; batch adversarial loss: 0.582410\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347245; batch adversarial loss: 0.482207\n",
      "epoch 146; iter: 0; batch classifier loss: 0.308171; batch adversarial loss: 0.472964\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363169; batch adversarial loss: 0.622090\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403069; batch adversarial loss: 0.569717\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396010; batch adversarial loss: 0.624025\n",
      "epoch 150; iter: 0; batch classifier loss: 0.322738; batch adversarial loss: 0.571301\n",
      "epoch 151; iter: 0; batch classifier loss: 0.406223; batch adversarial loss: 0.554865\n",
      "epoch 152; iter: 0; batch classifier loss: 0.421963; batch adversarial loss: 0.589188\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361167; batch adversarial loss: 0.517408\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321726; batch adversarial loss: 0.564112\n",
      "epoch 155; iter: 0; batch classifier loss: 0.400772; batch adversarial loss: 0.599732\n",
      "epoch 156; iter: 0; batch classifier loss: 0.310016; batch adversarial loss: 0.596464\n",
      "epoch 157; iter: 0; batch classifier loss: 0.390135; batch adversarial loss: 0.467136\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339940; batch adversarial loss: 0.544631\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364274; batch adversarial loss: 0.511022\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325217; batch adversarial loss: 0.673199\n",
      "epoch 161; iter: 0; batch classifier loss: 0.481202; batch adversarial loss: 0.513672\n",
      "epoch 162; iter: 0; batch classifier loss: 0.322134; batch adversarial loss: 0.566080\n",
      "epoch 163; iter: 0; batch classifier loss: 0.405316; batch adversarial loss: 0.589644\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376067; batch adversarial loss: 0.565652\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342120; batch adversarial loss: 0.519893\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409506; batch adversarial loss: 0.590851\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365338; batch adversarial loss: 0.497173\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336072; batch adversarial loss: 0.591357\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384046; batch adversarial loss: 0.533527\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393517; batch adversarial loss: 0.605920\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384418; batch adversarial loss: 0.524593\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350113; batch adversarial loss: 0.501214\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367167; batch adversarial loss: 0.595090\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335421; batch adversarial loss: 0.555947\n",
      "epoch 175; iter: 0; batch classifier loss: 0.428866; batch adversarial loss: 0.598784\n",
      "epoch 176; iter: 0; batch classifier loss: 0.421838; batch adversarial loss: 0.553383\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352195; batch adversarial loss: 0.544469\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347802; batch adversarial loss: 0.600410\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383800; batch adversarial loss: 0.496847\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400006; batch adversarial loss: 0.594289\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395531; batch adversarial loss: 0.529125\n",
      "epoch 182; iter: 0; batch classifier loss: 0.312055; batch adversarial loss: 0.492545\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321730; batch adversarial loss: 0.598258\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404701; batch adversarial loss: 0.596802\n",
      "epoch 185; iter: 0; batch classifier loss: 0.337846; batch adversarial loss: 0.525193\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323296; batch adversarial loss: 0.508886\n",
      "epoch 187; iter: 0; batch classifier loss: 0.284208; batch adversarial loss: 0.508973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.344043; batch adversarial loss: 0.501747\n",
      "epoch 189; iter: 0; batch classifier loss: 0.353674; batch adversarial loss: 0.533633\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344015; batch adversarial loss: 0.565219\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372790; batch adversarial loss: 0.549575\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306077; batch adversarial loss: 0.623526\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388368; batch adversarial loss: 0.586231\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356922; batch adversarial loss: 0.549138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338146; batch adversarial loss: 0.512046\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359641; batch adversarial loss: 0.482203\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387665; batch adversarial loss: 0.622815\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332908; batch adversarial loss: 0.569925\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352820; batch adversarial loss: 0.631401\n",
      "epoch 0; iter: 0; batch classifier loss: 0.761130; batch adversarial loss: 0.724627\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613043; batch adversarial loss: 0.674296\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577070; batch adversarial loss: 0.632680\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609687; batch adversarial loss: 0.622872\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574997; batch adversarial loss: 0.642817\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496287; batch adversarial loss: 0.626171\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547438; batch adversarial loss: 0.588110\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603840; batch adversarial loss: 0.630146\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526941; batch adversarial loss: 0.590903\n",
      "epoch 9; iter: 0; batch classifier loss: 0.605122; batch adversarial loss: 0.571010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529175; batch adversarial loss: 0.576662\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551437; batch adversarial loss: 0.634214\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496731; batch adversarial loss: 0.604254\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559414; batch adversarial loss: 0.576402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.577818; batch adversarial loss: 0.569880\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498776; batch adversarial loss: 0.558700\n",
      "epoch 16; iter: 0; batch classifier loss: 0.576333; batch adversarial loss: 0.486712\n",
      "epoch 17; iter: 0; batch classifier loss: 0.578490; batch adversarial loss: 0.508555\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540324; batch adversarial loss: 0.604371\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491925; batch adversarial loss: 0.565644\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485796; batch adversarial loss: 0.555165\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474751; batch adversarial loss: 0.599097\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519078; batch adversarial loss: 0.564645\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452788; batch adversarial loss: 0.552002\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518297; batch adversarial loss: 0.591805\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513387; batch adversarial loss: 0.579060\n",
      "epoch 26; iter: 0; batch classifier loss: 0.547241; batch adversarial loss: 0.568124\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493093; batch adversarial loss: 0.548993\n",
      "epoch 28; iter: 0; batch classifier loss: 0.501099; batch adversarial loss: 0.514582\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503677; batch adversarial loss: 0.540790\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523940; batch adversarial loss: 0.597794\n",
      "epoch 31; iter: 0; batch classifier loss: 0.388073; batch adversarial loss: 0.506388\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425136; batch adversarial loss: 0.561149\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481377; batch adversarial loss: 0.614759\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496629; batch adversarial loss: 0.587867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.501476; batch adversarial loss: 0.558326\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420521; batch adversarial loss: 0.500858\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439340; batch adversarial loss: 0.534918\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471218; batch adversarial loss: 0.468862\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451914; batch adversarial loss: 0.513055\n",
      "epoch 40; iter: 0; batch classifier loss: 0.360539; batch adversarial loss: 0.556254\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460338; batch adversarial loss: 0.520001\n",
      "epoch 42; iter: 0; batch classifier loss: 0.491530; batch adversarial loss: 0.503284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422760; batch adversarial loss: 0.468679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479384; batch adversarial loss: 0.553430\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444977; batch adversarial loss: 0.545549\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500902; batch adversarial loss: 0.575370\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408276; batch adversarial loss: 0.525836\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430873; batch adversarial loss: 0.610551\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455116; batch adversarial loss: 0.605663\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459621; batch adversarial loss: 0.499923\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416342; batch adversarial loss: 0.525618\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414154; batch adversarial loss: 0.525519\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381263; batch adversarial loss: 0.508851\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428413; batch adversarial loss: 0.507113\n",
      "epoch 55; iter: 0; batch classifier loss: 0.503354; batch adversarial loss: 0.542334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467401; batch adversarial loss: 0.589453\n",
      "epoch 57; iter: 0; batch classifier loss: 0.479751; batch adversarial loss: 0.553489\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437811; batch adversarial loss: 0.582728\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420981; batch adversarial loss: 0.470979\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370334; batch adversarial loss: 0.506850\n",
      "epoch 61; iter: 0; batch classifier loss: 0.456276; batch adversarial loss: 0.600444\n",
      "epoch 62; iter: 0; batch classifier loss: 0.342213; batch adversarial loss: 0.488890\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401838; batch adversarial loss: 0.572496\n",
      "epoch 64; iter: 0; batch classifier loss: 0.496834; batch adversarial loss: 0.516703\n",
      "epoch 65; iter: 0; batch classifier loss: 0.521288; batch adversarial loss: 0.544774\n",
      "epoch 66; iter: 0; batch classifier loss: 0.371829; batch adversarial loss: 0.534967\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435972; batch adversarial loss: 0.608005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.370387; batch adversarial loss: 0.562268\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405552; batch adversarial loss: 0.580633\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447093; batch adversarial loss: 0.580373\n",
      "epoch 71; iter: 0; batch classifier loss: 0.478241; batch adversarial loss: 0.516351\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382408; batch adversarial loss: 0.590100\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394440; batch adversarial loss: 0.516396\n",
      "epoch 74; iter: 0; batch classifier loss: 0.477048; batch adversarial loss: 0.507444\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418138; batch adversarial loss: 0.553930\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430064; batch adversarial loss: 0.571399\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372066; batch adversarial loss: 0.460555\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401000; batch adversarial loss: 0.516705\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378989; batch adversarial loss: 0.536036\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449920; batch adversarial loss: 0.563496\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351621; batch adversarial loss: 0.498710\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365348; batch adversarial loss: 0.582445\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441657; batch adversarial loss: 0.471611\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364751; batch adversarial loss: 0.543474\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380749; batch adversarial loss: 0.610238\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395025; batch adversarial loss: 0.571613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.374768; batch adversarial loss: 0.589634\n",
      "epoch 88; iter: 0; batch classifier loss: 0.502627; batch adversarial loss: 0.508799\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398255; batch adversarial loss: 0.516691\n",
      "epoch 90; iter: 0; batch classifier loss: 0.439433; batch adversarial loss: 0.600965\n",
      "epoch 91; iter: 0; batch classifier loss: 0.316274; batch adversarial loss: 0.589711\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382098; batch adversarial loss: 0.537485\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344017; batch adversarial loss: 0.519985\n",
      "epoch 94; iter: 0; batch classifier loss: 0.476389; batch adversarial loss: 0.598083\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362972; batch adversarial loss: 0.635607\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401170; batch adversarial loss: 0.582529\n",
      "epoch 97; iter: 0; batch classifier loss: 0.303839; batch adversarial loss: 0.509260\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388213; batch adversarial loss: 0.508601\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398582; batch adversarial loss: 0.561933\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385971; batch adversarial loss: 0.436666\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378605; batch adversarial loss: 0.498110\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366522; batch adversarial loss: 0.544373\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375175; batch adversarial loss: 0.544843\n",
      "epoch 104; iter: 0; batch classifier loss: 0.470232; batch adversarial loss: 0.544704\n",
      "epoch 105; iter: 0; batch classifier loss: 0.338068; batch adversarial loss: 0.544107\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428142; batch adversarial loss: 0.443238\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386054; batch adversarial loss: 0.570054\n",
      "epoch 108; iter: 0; batch classifier loss: 0.345802; batch adversarial loss: 0.554257\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388488; batch adversarial loss: 0.544771\n",
      "epoch 110; iter: 0; batch classifier loss: 0.320589; batch adversarial loss: 0.573120\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381484; batch adversarial loss: 0.554081\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368423; batch adversarial loss: 0.526966\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369989; batch adversarial loss: 0.481589\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329837; batch adversarial loss: 0.544229\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357326; batch adversarial loss: 0.607679\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391743; batch adversarial loss: 0.533783\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410836; batch adversarial loss: 0.571104\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386893; batch adversarial loss: 0.553220\n",
      "epoch 119; iter: 0; batch classifier loss: 0.393781; batch adversarial loss: 0.544858\n",
      "epoch 120; iter: 0; batch classifier loss: 0.433308; batch adversarial loss: 0.544826\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339384; batch adversarial loss: 0.526520\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421181; batch adversarial loss: 0.543380\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343051; batch adversarial loss: 0.572780\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385716; batch adversarial loss: 0.554582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365535; batch adversarial loss: 0.507531\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392258; batch adversarial loss: 0.535625\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354348; batch adversarial loss: 0.581309\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383712; batch adversarial loss: 0.552368\n",
      "epoch 129; iter: 0; batch classifier loss: 0.384927; batch adversarial loss: 0.498763\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383959; batch adversarial loss: 0.598654\n",
      "epoch 131; iter: 0; batch classifier loss: 0.432008; batch adversarial loss: 0.535248\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401294; batch adversarial loss: 0.536609\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388790; batch adversarial loss: 0.590768\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341697; batch adversarial loss: 0.451889\n",
      "epoch 135; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.544097\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405730; batch adversarial loss: 0.507556\n",
      "epoch 137; iter: 0; batch classifier loss: 0.322033; batch adversarial loss: 0.544075\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328249; batch adversarial loss: 0.498626\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388492; batch adversarial loss: 0.588931\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405677; batch adversarial loss: 0.508081\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400334; batch adversarial loss: 0.583438\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369544; batch adversarial loss: 0.516962\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395850; batch adversarial loss: 0.525963\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408044; batch adversarial loss: 0.544523\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350186; batch adversarial loss: 0.479625\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325423; batch adversarial loss: 0.481922\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394882; batch adversarial loss: 0.554871\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384563; batch adversarial loss: 0.527395\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417617; batch adversarial loss: 0.472543\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388338; batch adversarial loss: 0.534891\n",
      "epoch 151; iter: 0; batch classifier loss: 0.335574; batch adversarial loss: 0.534463\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368507; batch adversarial loss: 0.610224\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369996; batch adversarial loss: 0.608251\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343779; batch adversarial loss: 0.508273\n",
      "epoch 155; iter: 0; batch classifier loss: 0.409348; batch adversarial loss: 0.526069\n",
      "epoch 156; iter: 0; batch classifier loss: 0.441741; batch adversarial loss: 0.571617\n",
      "epoch 157; iter: 0; batch classifier loss: 0.431453; batch adversarial loss: 0.589968\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363940; batch adversarial loss: 0.590033\n",
      "epoch 159; iter: 0; batch classifier loss: 0.336215; batch adversarial loss: 0.553257\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380101; batch adversarial loss: 0.545515\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368791; batch adversarial loss: 0.509027\n",
      "epoch 162; iter: 0; batch classifier loss: 0.336093; batch adversarial loss: 0.561428\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359909; batch adversarial loss: 0.572077\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363587; batch adversarial loss: 0.625628\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361774; batch adversarial loss: 0.552634\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318662; batch adversarial loss: 0.517272\n",
      "epoch 167; iter: 0; batch classifier loss: 0.403058; batch adversarial loss: 0.561538\n",
      "epoch 168; iter: 0; batch classifier loss: 0.425695; batch adversarial loss: 0.507775\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334373; batch adversarial loss: 0.526906\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299530; batch adversarial loss: 0.552658\n",
      "epoch 171; iter: 0; batch classifier loss: 0.391998; batch adversarial loss: 0.609600\n",
      "epoch 172; iter: 0; batch classifier loss: 0.426697; batch adversarial loss: 0.461310\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392346; batch adversarial loss: 0.544653\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424288; batch adversarial loss: 0.508699\n",
      "epoch 175; iter: 0; batch classifier loss: 0.386658; batch adversarial loss: 0.544875\n",
      "epoch 176; iter: 0; batch classifier loss: 0.314620; batch adversarial loss: 0.553932\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384428; batch adversarial loss: 0.535865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390007; batch adversarial loss: 0.517846\n",
      "epoch 179; iter: 0; batch classifier loss: 0.405815; batch adversarial loss: 0.533590\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345700; batch adversarial loss: 0.573636\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347912; batch adversarial loss: 0.562334\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358149; batch adversarial loss: 0.544270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.401644; batch adversarial loss: 0.562259\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354226; batch adversarial loss: 0.481219\n",
      "epoch 185; iter: 0; batch classifier loss: 0.340143; batch adversarial loss: 0.509481\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349954; batch adversarial loss: 0.581342\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343844; batch adversarial loss: 0.552779\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348660; batch adversarial loss: 0.615706\n",
      "epoch 189; iter: 0; batch classifier loss: 0.441708; batch adversarial loss: 0.506679\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358604; batch adversarial loss: 0.534802\n",
      "epoch 191; iter: 0; batch classifier loss: 0.408847; batch adversarial loss: 0.573283\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336085; batch adversarial loss: 0.498244\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403857; batch adversarial loss: 0.479478\n",
      "epoch 194; iter: 0; batch classifier loss: 0.355811; batch adversarial loss: 0.516280\n",
      "epoch 195; iter: 0; batch classifier loss: 0.409643; batch adversarial loss: 0.580824\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355869; batch adversarial loss: 0.562496\n",
      "epoch 197; iter: 0; batch classifier loss: 0.243873; batch adversarial loss: 0.555072\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377932; batch adversarial loss: 0.527071\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362215; batch adversarial loss: 0.516505\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726166; batch adversarial loss: 0.711181\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565975; batch adversarial loss: 0.677090\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527739; batch adversarial loss: 0.659042\n",
      "epoch 3; iter: 0; batch classifier loss: 0.528130; batch adversarial loss: 0.632628\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552422; batch adversarial loss: 0.603834\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551693; batch adversarial loss: 0.593638\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558674; batch adversarial loss: 0.612412\n",
      "epoch 7; iter: 0; batch classifier loss: 0.515344; batch adversarial loss: 0.569564\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533085; batch adversarial loss: 0.566593\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554874; batch adversarial loss: 0.575354\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568631; batch adversarial loss: 0.590152\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459832; batch adversarial loss: 0.600215\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492428; batch adversarial loss: 0.583602\n",
      "epoch 13; iter: 0; batch classifier loss: 0.475417; batch adversarial loss: 0.571896\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497383; batch adversarial loss: 0.642710\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483531; batch adversarial loss: 0.545816\n",
      "epoch 16; iter: 0; batch classifier loss: 0.544950; batch adversarial loss: 0.611434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536458; batch adversarial loss: 0.588688\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479534; batch adversarial loss: 0.604991\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497958; batch adversarial loss: 0.577203\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483941; batch adversarial loss: 0.583894\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469803; batch adversarial loss: 0.580688\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510354; batch adversarial loss: 0.594721\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486385; batch adversarial loss: 0.446791\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444524; batch adversarial loss: 0.570032\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467445; batch adversarial loss: 0.559694\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479611; batch adversarial loss: 0.611203\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481617; batch adversarial loss: 0.503844\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402741; batch adversarial loss: 0.552513\n",
      "epoch 29; iter: 0; batch classifier loss: 0.410179; batch adversarial loss: 0.582341\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421756; batch adversarial loss: 0.532337\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433589; batch adversarial loss: 0.567999\n",
      "epoch 32; iter: 0; batch classifier loss: 0.526443; batch adversarial loss: 0.577444\n",
      "epoch 33; iter: 0; batch classifier loss: 0.505611; batch adversarial loss: 0.568976\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501403; batch adversarial loss: 0.582295\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426455; batch adversarial loss: 0.528659\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419915; batch adversarial loss: 0.580443\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383153; batch adversarial loss: 0.587719\n",
      "epoch 38; iter: 0; batch classifier loss: 0.366708; batch adversarial loss: 0.541034\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488337; batch adversarial loss: 0.534279\n",
      "epoch 40; iter: 0; batch classifier loss: 0.376632; batch adversarial loss: 0.563620\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385010; batch adversarial loss: 0.601047\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453188; batch adversarial loss: 0.525938\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433524; batch adversarial loss: 0.472829\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455112; batch adversarial loss: 0.522850\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423668; batch adversarial loss: 0.498656\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430643; batch adversarial loss: 0.557091\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460956; batch adversarial loss: 0.526114\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428517; batch adversarial loss: 0.517743\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435215; batch adversarial loss: 0.533612\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458160; batch adversarial loss: 0.589136\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428289; batch adversarial loss: 0.600599\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451124; batch adversarial loss: 0.562956\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391985; batch adversarial loss: 0.488688\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448865; batch adversarial loss: 0.590900\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390429; batch adversarial loss: 0.562715\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430289; batch adversarial loss: 0.565319\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458750; batch adversarial loss: 0.569509\n",
      "epoch 58; iter: 0; batch classifier loss: 0.385558; batch adversarial loss: 0.626167\n",
      "epoch 59; iter: 0; batch classifier loss: 0.493957; batch adversarial loss: 0.508430\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385962; batch adversarial loss: 0.581028\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467811; batch adversarial loss: 0.545465\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479792; batch adversarial loss: 0.569188\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463005; batch adversarial loss: 0.543330\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388729; batch adversarial loss: 0.534052\n",
      "epoch 65; iter: 0; batch classifier loss: 0.462592; batch adversarial loss: 0.525746\n",
      "epoch 66; iter: 0; batch classifier loss: 0.463130; batch adversarial loss: 0.568145\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460664; batch adversarial loss: 0.527713\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342762; batch adversarial loss: 0.553146\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407612; batch adversarial loss: 0.516718\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387073; batch adversarial loss: 0.525246\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378740; batch adversarial loss: 0.608056\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360003; batch adversarial loss: 0.535902\n",
      "epoch 73; iter: 0; batch classifier loss: 0.316143; batch adversarial loss: 0.562839\n",
      "epoch 74; iter: 0; batch classifier loss: 0.342357; batch adversarial loss: 0.590705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424481; batch adversarial loss: 0.516529\n",
      "epoch 76; iter: 0; batch classifier loss: 0.328444; batch adversarial loss: 0.471992\n",
      "epoch 77; iter: 0; batch classifier loss: 0.288844; batch adversarial loss: 0.544504\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458430; batch adversarial loss: 0.509012\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380531; batch adversarial loss: 0.543202\n",
      "epoch 80; iter: 0; batch classifier loss: 0.368426; batch adversarial loss: 0.589574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.462310; batch adversarial loss: 0.517274\n",
      "epoch 82; iter: 0; batch classifier loss: 0.340062; batch adversarial loss: 0.525177\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409303; batch adversarial loss: 0.572187\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360621; batch adversarial loss: 0.452682\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408195; batch adversarial loss: 0.506643\n",
      "epoch 86; iter: 0; batch classifier loss: 0.335866; batch adversarial loss: 0.543997\n",
      "epoch 87; iter: 0; batch classifier loss: 0.459505; batch adversarial loss: 0.526209\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365630; batch adversarial loss: 0.590541\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422977; batch adversarial loss: 0.552400\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353751; batch adversarial loss: 0.600737\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408601; batch adversarial loss: 0.488936\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411703; batch adversarial loss: 0.514808\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384393; batch adversarial loss: 0.510766\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437155; batch adversarial loss: 0.543422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424085; batch adversarial loss: 0.590417\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384142; batch adversarial loss: 0.487860\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415019; batch adversarial loss: 0.570308\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372102; batch adversarial loss: 0.559815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394513; batch adversarial loss: 0.544010\n",
      "epoch 100; iter: 0; batch classifier loss: 0.313440; batch adversarial loss: 0.498446\n",
      "epoch 101; iter: 0; batch classifier loss: 0.328324; batch adversarial loss: 0.534382\n",
      "epoch 102; iter: 0; batch classifier loss: 0.378491; batch adversarial loss: 0.460401\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413100; batch adversarial loss: 0.525303\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413421; batch adversarial loss: 0.470742\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413448; batch adversarial loss: 0.564008\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380064; batch adversarial loss: 0.516719\n",
      "epoch 107; iter: 0; batch classifier loss: 0.324626; batch adversarial loss: 0.599703\n",
      "epoch 108; iter: 0; batch classifier loss: 0.428508; batch adversarial loss: 0.534375\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371694; batch adversarial loss: 0.571129\n",
      "epoch 110; iter: 0; batch classifier loss: 0.313294; batch adversarial loss: 0.515057\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356657; batch adversarial loss: 0.551492\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351716; batch adversarial loss: 0.554029\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395065; batch adversarial loss: 0.545264\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391386; batch adversarial loss: 0.552911\n",
      "epoch 115; iter: 0; batch classifier loss: 0.347768; batch adversarial loss: 0.534375\n",
      "epoch 116; iter: 0; batch classifier loss: 0.349764; batch adversarial loss: 0.554398\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375067; batch adversarial loss: 0.533375\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326991; batch adversarial loss: 0.471226\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357389; batch adversarial loss: 0.508821\n",
      "epoch 120; iter: 0; batch classifier loss: 0.328587; batch adversarial loss: 0.580965\n",
      "epoch 121; iter: 0; batch classifier loss: 0.454217; batch adversarial loss: 0.478359\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362649; batch adversarial loss: 0.505485\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372273; batch adversarial loss: 0.498914\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397192; batch adversarial loss: 0.599358\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329638; batch adversarial loss: 0.543376\n",
      "epoch 126; iter: 0; batch classifier loss: 0.433943; batch adversarial loss: 0.591591\n",
      "epoch 127; iter: 0; batch classifier loss: 0.294781; batch adversarial loss: 0.461276\n",
      "epoch 128; iter: 0; batch classifier loss: 0.405134; batch adversarial loss: 0.564036\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398260; batch adversarial loss: 0.536242\n",
      "epoch 130; iter: 0; batch classifier loss: 0.521432; batch adversarial loss: 0.552899\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375833; batch adversarial loss: 0.498807\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333281; batch adversarial loss: 0.572401\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387652; batch adversarial loss: 0.590141\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378683; batch adversarial loss: 0.481027\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389953; batch adversarial loss: 0.552987\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363124; batch adversarial loss: 0.572050\n",
      "epoch 137; iter: 0; batch classifier loss: 0.433004; batch adversarial loss: 0.590062\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309109; batch adversarial loss: 0.506703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367172; batch adversarial loss: 0.544657\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357950; batch adversarial loss: 0.553795\n",
      "epoch 141; iter: 0; batch classifier loss: 0.289163; batch adversarial loss: 0.534445\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392208; batch adversarial loss: 0.452103\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395429; batch adversarial loss: 0.551360\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376506; batch adversarial loss: 0.562988\n",
      "epoch 145; iter: 0; batch classifier loss: 0.361998; batch adversarial loss: 0.451548\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317760; batch adversarial loss: 0.535879\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363404; batch adversarial loss: 0.535273\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350132; batch adversarial loss: 0.563247\n",
      "epoch 149; iter: 0; batch classifier loss: 0.429754; batch adversarial loss: 0.526175\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367845; batch adversarial loss: 0.544798\n",
      "epoch 151; iter: 0; batch classifier loss: 0.318669; batch adversarial loss: 0.507268\n",
      "epoch 152; iter: 0; batch classifier loss: 0.301903; batch adversarial loss: 0.488563\n",
      "epoch 153; iter: 0; batch classifier loss: 0.398125; batch adversarial loss: 0.544645\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350247; batch adversarial loss: 0.572040\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351645; batch adversarial loss: 0.545453\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328360; batch adversarial loss: 0.692017\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336730; batch adversarial loss: 0.617589\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396951; batch adversarial loss: 0.552667\n",
      "epoch 159; iter: 0; batch classifier loss: 0.450115; batch adversarial loss: 0.570632\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380830; batch adversarial loss: 0.489631\n",
      "epoch 161; iter: 0; batch classifier loss: 0.417289; batch adversarial loss: 0.618615\n",
      "epoch 162; iter: 0; batch classifier loss: 0.307650; batch adversarial loss: 0.590857\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369686; batch adversarial loss: 0.460335\n",
      "epoch 164; iter: 0; batch classifier loss: 0.327423; batch adversarial loss: 0.527203\n",
      "epoch 165; iter: 0; batch classifier loss: 0.299463; batch adversarial loss: 0.490237\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312855; batch adversarial loss: 0.599594\n",
      "epoch 167; iter: 0; batch classifier loss: 0.388704; batch adversarial loss: 0.479210\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361769; batch adversarial loss: 0.618092\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392810; batch adversarial loss: 0.610159\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314252; batch adversarial loss: 0.571047\n",
      "epoch 171; iter: 0; batch classifier loss: 0.360792; batch adversarial loss: 0.498274\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348847; batch adversarial loss: 0.543552\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387473; batch adversarial loss: 0.545890\n",
      "epoch 174; iter: 0; batch classifier loss: 0.286937; batch adversarial loss: 0.544377\n",
      "epoch 175; iter: 0; batch classifier loss: 0.334511; batch adversarial loss: 0.479195\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331199; batch adversarial loss: 0.535195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.344313; batch adversarial loss: 0.536221\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384485; batch adversarial loss: 0.562823\n",
      "epoch 179; iter: 0; batch classifier loss: 0.430758; batch adversarial loss: 0.534854\n",
      "epoch 180; iter: 0; batch classifier loss: 0.297759; batch adversarial loss: 0.590061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332425; batch adversarial loss: 0.506927\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337768; batch adversarial loss: 0.488721\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366027; batch adversarial loss: 0.508187\n",
      "epoch 184; iter: 0; batch classifier loss: 0.392324; batch adversarial loss: 0.544890\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326593; batch adversarial loss: 0.544708\n",
      "epoch 186; iter: 0; batch classifier loss: 0.290586; batch adversarial loss: 0.535034\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361527; batch adversarial loss: 0.553387\n",
      "epoch 188; iter: 0; batch classifier loss: 0.427922; batch adversarial loss: 0.554095\n",
      "epoch 189; iter: 0; batch classifier loss: 0.394737; batch adversarial loss: 0.582082\n",
      "epoch 190; iter: 0; batch classifier loss: 0.259731; batch adversarial loss: 0.524146\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373279; batch adversarial loss: 0.535726\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336460; batch adversarial loss: 0.535598\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320583; batch adversarial loss: 0.644783\n",
      "epoch 194; iter: 0; batch classifier loss: 0.216123; batch adversarial loss: 0.572039\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364010; batch adversarial loss: 0.526389\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326534; batch adversarial loss: 0.525814\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326500; batch adversarial loss: 0.553562\n",
      "epoch 198; iter: 0; batch classifier loss: 0.435976; batch adversarial loss: 0.526390\n",
      "epoch 199; iter: 0; batch classifier loss: 0.411828; batch adversarial loss: 0.461202\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726846; batch adversarial loss: 0.721849\n",
      "epoch 1; iter: 0; batch classifier loss: 0.620812; batch adversarial loss: 0.681172\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624521; batch adversarial loss: 0.667995\n",
      "epoch 3; iter: 0; batch classifier loss: 0.554094; batch adversarial loss: 0.628194\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519270; batch adversarial loss: 0.614835\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585061; batch adversarial loss: 0.630846\n",
      "epoch 6; iter: 0; batch classifier loss: 0.481917; batch adversarial loss: 0.601326\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496089; batch adversarial loss: 0.601563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559255; batch adversarial loss: 0.592655\n",
      "epoch 9; iter: 0; batch classifier loss: 0.482442; batch adversarial loss: 0.573064\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558486; batch adversarial loss: 0.595862\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470333; batch adversarial loss: 0.554973\n",
      "epoch 12; iter: 0; batch classifier loss: 0.482082; batch adversarial loss: 0.559986\n",
      "epoch 13; iter: 0; batch classifier loss: 0.629919; batch adversarial loss: 0.598163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517889; batch adversarial loss: 0.546342\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491048; batch adversarial loss: 0.611219\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545677; batch adversarial loss: 0.623137\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504943; batch adversarial loss: 0.584124\n",
      "epoch 18; iter: 0; batch classifier loss: 0.587623; batch adversarial loss: 0.533829\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461403; batch adversarial loss: 0.575492\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507395; batch adversarial loss: 0.518784\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507504; batch adversarial loss: 0.596886\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484010; batch adversarial loss: 0.519696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452427; batch adversarial loss: 0.562502\n",
      "epoch 24; iter: 0; batch classifier loss: 0.582856; batch adversarial loss: 0.509272\n",
      "epoch 25; iter: 0; batch classifier loss: 0.450216; batch adversarial loss: 0.548451\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492146; batch adversarial loss: 0.594087\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447516; batch adversarial loss: 0.596234\n",
      "epoch 28; iter: 0; batch classifier loss: 0.525527; batch adversarial loss: 0.598203\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454422; batch adversarial loss: 0.623830\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466359; batch adversarial loss: 0.484558\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441378; batch adversarial loss: 0.598364\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420673; batch adversarial loss: 0.565555\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494687; batch adversarial loss: 0.458789\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429395; batch adversarial loss: 0.529837\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400232; batch adversarial loss: 0.550172\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426099; batch adversarial loss: 0.527870\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394382; batch adversarial loss: 0.496973\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486604; batch adversarial loss: 0.503408\n",
      "epoch 39; iter: 0; batch classifier loss: 0.475266; batch adversarial loss: 0.624846\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429415; batch adversarial loss: 0.562368\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437977; batch adversarial loss: 0.537863\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411299; batch adversarial loss: 0.553238\n",
      "epoch 43; iter: 0; batch classifier loss: 0.417722; batch adversarial loss: 0.571093\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423970; batch adversarial loss: 0.587931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441556; batch adversarial loss: 0.632181\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508323; batch adversarial loss: 0.525380\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399456; batch adversarial loss: 0.552887\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446940; batch adversarial loss: 0.553268\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380676; batch adversarial loss: 0.544693\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423963; batch adversarial loss: 0.679567\n",
      "epoch 51; iter: 0; batch classifier loss: 0.306324; batch adversarial loss: 0.500392\n",
      "epoch 52; iter: 0; batch classifier loss: 0.356245; batch adversarial loss: 0.633734\n",
      "epoch 53; iter: 0; batch classifier loss: 0.378729; batch adversarial loss: 0.508382\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430267; batch adversarial loss: 0.517420\n",
      "epoch 55; iter: 0; batch classifier loss: 0.385455; batch adversarial loss: 0.500060\n",
      "epoch 56; iter: 0; batch classifier loss: 0.334988; batch adversarial loss: 0.562407\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434680; batch adversarial loss: 0.545064\n",
      "epoch 58; iter: 0; batch classifier loss: 0.361151; batch adversarial loss: 0.589401\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409903; batch adversarial loss: 0.490122\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409448; batch adversarial loss: 0.499329\n",
      "epoch 61; iter: 0; batch classifier loss: 0.364960; batch adversarial loss: 0.607265\n",
      "epoch 62; iter: 0; batch classifier loss: 0.357918; batch adversarial loss: 0.535799\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398797; batch adversarial loss: 0.562914\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465367; batch adversarial loss: 0.544096\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421305; batch adversarial loss: 0.464165\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397869; batch adversarial loss: 0.482679\n",
      "epoch 67; iter: 0; batch classifier loss: 0.375394; batch adversarial loss: 0.554171\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379118; batch adversarial loss: 0.580357\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429272; batch adversarial loss: 0.462943\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391040; batch adversarial loss: 0.554096\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414888; batch adversarial loss: 0.562412\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379614; batch adversarial loss: 0.526406\n",
      "epoch 73; iter: 0; batch classifier loss: 0.359583; batch adversarial loss: 0.572381\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390263; batch adversarial loss: 0.616105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.418569; batch adversarial loss: 0.507343\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399925; batch adversarial loss: 0.590797\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382236; batch adversarial loss: 0.526273\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376187; batch adversarial loss: 0.553847\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407493; batch adversarial loss: 0.526267\n",
      "epoch 80; iter: 0; batch classifier loss: 0.457809; batch adversarial loss: 0.553967\n",
      "epoch 81; iter: 0; batch classifier loss: 0.353973; batch adversarial loss: 0.571549\n",
      "epoch 82; iter: 0; batch classifier loss: 0.319016; batch adversarial loss: 0.599862\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410437; batch adversarial loss: 0.579058\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412138; batch adversarial loss: 0.579352\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376041; batch adversarial loss: 0.527853\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331580; batch adversarial loss: 0.579181\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440210; batch adversarial loss: 0.515105\n",
      "epoch 88; iter: 0; batch classifier loss: 0.331260; batch adversarial loss: 0.596785\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461733; batch adversarial loss: 0.620041\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432622; batch adversarial loss: 0.581778\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411281; batch adversarial loss: 0.609211\n",
      "epoch 92; iter: 0; batch classifier loss: 0.464268; batch adversarial loss: 0.508677\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325959; batch adversarial loss: 0.563075\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377774; batch adversarial loss: 0.471315\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415638; batch adversarial loss: 0.581996\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410258; batch adversarial loss: 0.580332\n",
      "epoch 97; iter: 0; batch classifier loss: 0.331372; batch adversarial loss: 0.560217\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410095; batch adversarial loss: 0.561158\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350129; batch adversarial loss: 0.526188\n",
      "epoch 100; iter: 0; batch classifier loss: 0.359736; batch adversarial loss: 0.589249\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410967; batch adversarial loss: 0.538215\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385263; batch adversarial loss: 0.543381\n",
      "epoch 103; iter: 0; batch classifier loss: 0.422055; batch adversarial loss: 0.608969\n",
      "epoch 104; iter: 0; batch classifier loss: 0.404357; batch adversarial loss: 0.614961\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370834; batch adversarial loss: 0.490762\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354989; batch adversarial loss: 0.626403\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357334; batch adversarial loss: 0.561785\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422217; batch adversarial loss: 0.553508\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408011; batch adversarial loss: 0.580793\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390021; batch adversarial loss: 0.563979\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354159; batch adversarial loss: 0.566237\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409568; batch adversarial loss: 0.521514\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350817; batch adversarial loss: 0.535074\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350238; batch adversarial loss: 0.582927\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409457; batch adversarial loss: 0.564159\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359133; batch adversarial loss: 0.629152\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326141; batch adversarial loss: 0.581961\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386494; batch adversarial loss: 0.544473\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363438; batch adversarial loss: 0.574195\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419676; batch adversarial loss: 0.580423\n",
      "epoch 121; iter: 0; batch classifier loss: 0.438522; batch adversarial loss: 0.544908\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415880; batch adversarial loss: 0.553961\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344840; batch adversarial loss: 0.497986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386516; batch adversarial loss: 0.507253\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401139; batch adversarial loss: 0.553287\n",
      "epoch 126; iter: 0; batch classifier loss: 0.443460; batch adversarial loss: 0.497651\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356878; batch adversarial loss: 0.544727\n",
      "epoch 128; iter: 0; batch classifier loss: 0.427277; batch adversarial loss: 0.580173\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377740; batch adversarial loss: 0.526837\n",
      "epoch 130; iter: 0; batch classifier loss: 0.411888; batch adversarial loss: 0.517505\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372176; batch adversarial loss: 0.536091\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392563; batch adversarial loss: 0.642185\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341837; batch adversarial loss: 0.572515\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357497; batch adversarial loss: 0.545864\n",
      "epoch 135; iter: 0; batch classifier loss: 0.434293; batch adversarial loss: 0.581099\n",
      "epoch 136; iter: 0; batch classifier loss: 0.413046; batch adversarial loss: 0.580135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395700; batch adversarial loss: 0.619112\n",
      "epoch 138; iter: 0; batch classifier loss: 0.433771; batch adversarial loss: 0.489955\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416367; batch adversarial loss: 0.463713\n",
      "epoch 140; iter: 0; batch classifier loss: 0.282260; batch adversarial loss: 0.552993\n",
      "epoch 141; iter: 0; batch classifier loss: 0.276864; batch adversarial loss: 0.554659\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371496; batch adversarial loss: 0.576837\n",
      "epoch 143; iter: 0; batch classifier loss: 0.340140; batch adversarial loss: 0.642514\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356164; batch adversarial loss: 0.624003\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373142; batch adversarial loss: 0.579200\n",
      "epoch 146; iter: 0; batch classifier loss: 0.351673; batch adversarial loss: 0.498062\n",
      "epoch 147; iter: 0; batch classifier loss: 0.443030; batch adversarial loss: 0.518064\n",
      "epoch 148; iter: 0; batch classifier loss: 0.313372; batch adversarial loss: 0.600118\n",
      "epoch 149; iter: 0; batch classifier loss: 0.275299; batch adversarial loss: 0.516677\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397658; batch adversarial loss: 0.573079\n",
      "epoch 151; iter: 0; batch classifier loss: 0.306558; batch adversarial loss: 0.545095\n",
      "epoch 152; iter: 0; batch classifier loss: 0.436193; batch adversarial loss: 0.500956\n",
      "epoch 153; iter: 0; batch classifier loss: 0.266532; batch adversarial loss: 0.516133\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316328; batch adversarial loss: 0.563325\n",
      "epoch 155; iter: 0; batch classifier loss: 0.420982; batch adversarial loss: 0.518571\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402997; batch adversarial loss: 0.528141\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.598430\n",
      "epoch 158; iter: 0; batch classifier loss: 0.409067; batch adversarial loss: 0.622619\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347797; batch adversarial loss: 0.526178\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347394; batch adversarial loss: 0.573817\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363112; batch adversarial loss: 0.498600\n",
      "epoch 162; iter: 0; batch classifier loss: 0.406324; batch adversarial loss: 0.570840\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366851; batch adversarial loss: 0.600392\n",
      "epoch 164; iter: 0; batch classifier loss: 0.446016; batch adversarial loss: 0.517220\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365810; batch adversarial loss: 0.517701\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360036; batch adversarial loss: 0.562984\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342533; batch adversarial loss: 0.599286\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333558; batch adversarial loss: 0.517167\n",
      "epoch 169; iter: 0; batch classifier loss: 0.290842; batch adversarial loss: 0.515335\n",
      "epoch 170; iter: 0; batch classifier loss: 0.424678; batch adversarial loss: 0.644723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.299160; batch adversarial loss: 0.554735\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367032; batch adversarial loss: 0.662379\n",
      "epoch 173; iter: 0; batch classifier loss: 0.376850; batch adversarial loss: 0.473259\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336701; batch adversarial loss: 0.490288\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355423; batch adversarial loss: 0.441267\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351169; batch adversarial loss: 0.572541\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338913; batch adversarial loss: 0.528191\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381968; batch adversarial loss: 0.525006\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384852; batch adversarial loss: 0.507971\n",
      "epoch 180; iter: 0; batch classifier loss: 0.321314; batch adversarial loss: 0.527132\n",
      "epoch 181; iter: 0; batch classifier loss: 0.419280; batch adversarial loss: 0.536561\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336719; batch adversarial loss: 0.571185\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409976; batch adversarial loss: 0.571249\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353269; batch adversarial loss: 0.643053\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331268; batch adversarial loss: 0.496400\n",
      "epoch 186; iter: 0; batch classifier loss: 0.298942; batch adversarial loss: 0.561647\n",
      "epoch 187; iter: 0; batch classifier loss: 0.391252; batch adversarial loss: 0.492253\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341818; batch adversarial loss: 0.471820\n",
      "epoch 189; iter: 0; batch classifier loss: 0.466629; batch adversarial loss: 0.518283\n",
      "epoch 190; iter: 0; batch classifier loss: 0.286263; batch adversarial loss: 0.645378\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366481; batch adversarial loss: 0.499580\n",
      "epoch 192; iter: 0; batch classifier loss: 0.428343; batch adversarial loss: 0.618038\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347828; batch adversarial loss: 0.610101\n",
      "epoch 194; iter: 0; batch classifier loss: 0.319299; batch adversarial loss: 0.589071\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399787; batch adversarial loss: 0.553637\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335522; batch adversarial loss: 0.481126\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392403; batch adversarial loss: 0.571702\n",
      "epoch 198; iter: 0; batch classifier loss: 0.409321; batch adversarial loss: 0.562547\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353652; batch adversarial loss: 0.535973\n",
      "epoch 0; iter: 0; batch classifier loss: 0.810652; batch adversarial loss: 0.822613\n",
      "epoch 1; iter: 0; batch classifier loss: 0.650183; batch adversarial loss: 0.707875\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553064; batch adversarial loss: 0.689494\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597601; batch adversarial loss: 0.660164\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595293; batch adversarial loss: 0.632100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621061; batch adversarial loss: 0.629128\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598008; batch adversarial loss: 0.625406\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509991; batch adversarial loss: 0.579242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.563633; batch adversarial loss: 0.556720\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490468; batch adversarial loss: 0.530501\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492929; batch adversarial loss: 0.583217\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525000; batch adversarial loss: 0.498936\n",
      "epoch 12; iter: 0; batch classifier loss: 0.611455; batch adversarial loss: 0.592284\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557806; batch adversarial loss: 0.562541\n",
      "epoch 14; iter: 0; batch classifier loss: 0.555075; batch adversarial loss: 0.548810\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530694; batch adversarial loss: 0.492198\n",
      "epoch 16; iter: 0; batch classifier loss: 0.582027; batch adversarial loss: 0.533663\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546614; batch adversarial loss: 0.567448\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527184; batch adversarial loss: 0.632888\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523818; batch adversarial loss: 0.575809\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525398; batch adversarial loss: 0.549232\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454100; batch adversarial loss: 0.495053\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582961; batch adversarial loss: 0.531114\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475208; batch adversarial loss: 0.477431\n",
      "epoch 24; iter: 0; batch classifier loss: 0.573144; batch adversarial loss: 0.570994\n",
      "epoch 25; iter: 0; batch classifier loss: 0.392603; batch adversarial loss: 0.523133\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500880; batch adversarial loss: 0.516383\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495414; batch adversarial loss: 0.543552\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442251; batch adversarial loss: 0.516448\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446114; batch adversarial loss: 0.503258\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454117; batch adversarial loss: 0.590984\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466370; batch adversarial loss: 0.513135\n",
      "epoch 32; iter: 0; batch classifier loss: 0.480049; batch adversarial loss: 0.516964\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443171; batch adversarial loss: 0.521607\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451320; batch adversarial loss: 0.591901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.536462; batch adversarial loss: 0.573247\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463350; batch adversarial loss: 0.563258\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471187; batch adversarial loss: 0.538827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431951; batch adversarial loss: 0.501431\n",
      "epoch 39; iter: 0; batch classifier loss: 0.475559; batch adversarial loss: 0.518279\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443523; batch adversarial loss: 0.563751\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426924; batch adversarial loss: 0.491152\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446019; batch adversarial loss: 0.526546\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464595; batch adversarial loss: 0.572243\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428550; batch adversarial loss: 0.480507\n",
      "epoch 45; iter: 0; batch classifier loss: 0.378222; batch adversarial loss: 0.534809\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462161; batch adversarial loss: 0.544598\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399970; batch adversarial loss: 0.523802\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443490; batch adversarial loss: 0.551830\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402331; batch adversarial loss: 0.484467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468298; batch adversarial loss: 0.474788\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414811; batch adversarial loss: 0.609294\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462413; batch adversarial loss: 0.525413\n",
      "epoch 53; iter: 0; batch classifier loss: 0.434768; batch adversarial loss: 0.498067\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411867; batch adversarial loss: 0.454621\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430634; batch adversarial loss: 0.519953\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423318; batch adversarial loss: 0.527366\n",
      "epoch 57; iter: 0; batch classifier loss: 0.419573; batch adversarial loss: 0.462026\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380070; batch adversarial loss: 0.510172\n",
      "epoch 59; iter: 0; batch classifier loss: 0.373692; batch adversarial loss: 0.507395\n",
      "epoch 60; iter: 0; batch classifier loss: 0.325448; batch adversarial loss: 0.621939\n",
      "epoch 61; iter: 0; batch classifier loss: 0.530338; batch adversarial loss: 0.574390\n",
      "epoch 62; iter: 0; batch classifier loss: 0.458124; batch adversarial loss: 0.581551\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450514; batch adversarial loss: 0.572518\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423509; batch adversarial loss: 0.508228\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411061; batch adversarial loss: 0.552880\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404934; batch adversarial loss: 0.607177\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425141; batch adversarial loss: 0.544188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.467383; batch adversarial loss: 0.482383\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444626; batch adversarial loss: 0.581612\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368857; batch adversarial loss: 0.564543\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372004; batch adversarial loss: 0.545704\n",
      "epoch 72; iter: 0; batch classifier loss: 0.342573; batch adversarial loss: 0.668529\n",
      "epoch 73; iter: 0; batch classifier loss: 0.444312; batch adversarial loss: 0.563621\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389795; batch adversarial loss: 0.448943\n",
      "epoch 75; iter: 0; batch classifier loss: 0.437556; batch adversarial loss: 0.553638\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399467; batch adversarial loss: 0.582652\n",
      "epoch 77; iter: 0; batch classifier loss: 0.444130; batch adversarial loss: 0.572174\n",
      "epoch 78; iter: 0; batch classifier loss: 0.434632; batch adversarial loss: 0.516004\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428791; batch adversarial loss: 0.517240\n",
      "epoch 80; iter: 0; batch classifier loss: 0.472254; batch adversarial loss: 0.516281\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415228; batch adversarial loss: 0.601633\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359505; batch adversarial loss: 0.554297\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397913; batch adversarial loss: 0.449765\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449999; batch adversarial loss: 0.554870\n",
      "epoch 85; iter: 0; batch classifier loss: 0.335382; batch adversarial loss: 0.581523\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430297; batch adversarial loss: 0.592420\n",
      "epoch 87; iter: 0; batch classifier loss: 0.497524; batch adversarial loss: 0.563206\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395082; batch adversarial loss: 0.621787\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358689; batch adversarial loss: 0.553464\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386873; batch adversarial loss: 0.610669\n",
      "epoch 91; iter: 0; batch classifier loss: 0.418304; batch adversarial loss: 0.525835\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399601; batch adversarial loss: 0.543562\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394265; batch adversarial loss: 0.563784\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397781; batch adversarial loss: 0.497382\n",
      "epoch 95; iter: 0; batch classifier loss: 0.432443; batch adversarial loss: 0.609877\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396539; batch adversarial loss: 0.515797\n",
      "epoch 97; iter: 0; batch classifier loss: 0.454917; batch adversarial loss: 0.563559\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356524; batch adversarial loss: 0.581871\n",
      "epoch 99; iter: 0; batch classifier loss: 0.464535; batch adversarial loss: 0.517297\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384462; batch adversarial loss: 0.639358\n",
      "epoch 101; iter: 0; batch classifier loss: 0.361235; batch adversarial loss: 0.563463\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418029; batch adversarial loss: 0.544387\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407470; batch adversarial loss: 0.563285\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399180; batch adversarial loss: 0.591397\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391535; batch adversarial loss: 0.553560\n",
      "epoch 106; iter: 0; batch classifier loss: 0.475321; batch adversarial loss: 0.544573\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404875; batch adversarial loss: 0.630432\n",
      "epoch 108; iter: 0; batch classifier loss: 0.508702; batch adversarial loss: 0.554136\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353140; batch adversarial loss: 0.478492\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383290; batch adversarial loss: 0.563186\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336386; batch adversarial loss: 0.506869\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382828; batch adversarial loss: 0.582413\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392770; batch adversarial loss: 0.534839\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428210; batch adversarial loss: 0.554329\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409138; batch adversarial loss: 0.515643\n",
      "epoch 116; iter: 0; batch classifier loss: 0.469224; batch adversarial loss: 0.507158\n",
      "epoch 117; iter: 0; batch classifier loss: 0.398420; batch adversarial loss: 0.601419\n",
      "epoch 118; iter: 0; batch classifier loss: 0.448808; batch adversarial loss: 0.525510\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425402; batch adversarial loss: 0.621012\n",
      "epoch 120; iter: 0; batch classifier loss: 0.331436; batch adversarial loss: 0.619632\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346063; batch adversarial loss: 0.506854\n",
      "epoch 122; iter: 0; batch classifier loss: 0.430265; batch adversarial loss: 0.619333\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379426; batch adversarial loss: 0.544552\n",
      "epoch 124; iter: 0; batch classifier loss: 0.369994; batch adversarial loss: 0.600903\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360631; batch adversarial loss: 0.535430\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379317; batch adversarial loss: 0.525245\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400408; batch adversarial loss: 0.563304\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399158; batch adversarial loss: 0.459260\n",
      "epoch 129; iter: 0; batch classifier loss: 0.520623; batch adversarial loss: 0.601337\n",
      "epoch 130; iter: 0; batch classifier loss: 0.411678; batch adversarial loss: 0.572907\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386680; batch adversarial loss: 0.573265\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378898; batch adversarial loss: 0.611577\n",
      "epoch 133; iter: 0; batch classifier loss: 0.254842; batch adversarial loss: 0.544287\n",
      "epoch 134; iter: 0; batch classifier loss: 0.448390; batch adversarial loss: 0.507603\n",
      "epoch 135; iter: 0; batch classifier loss: 0.484168; batch adversarial loss: 0.526526\n",
      "epoch 136; iter: 0; batch classifier loss: 0.323538; batch adversarial loss: 0.554245\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405247; batch adversarial loss: 0.517236\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411286; batch adversarial loss: 0.526115\n",
      "epoch 139; iter: 0; batch classifier loss: 0.266611; batch adversarial loss: 0.544724\n",
      "epoch 140; iter: 0; batch classifier loss: 0.428196; batch adversarial loss: 0.516604\n",
      "epoch 141; iter: 0; batch classifier loss: 0.451100; batch adversarial loss: 0.526006\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350592; batch adversarial loss: 0.544087\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355919; batch adversarial loss: 0.487026\n",
      "epoch 144; iter: 0; batch classifier loss: 0.432175; batch adversarial loss: 0.524857\n",
      "epoch 145; iter: 0; batch classifier loss: 0.388803; batch adversarial loss: 0.506083\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382299; batch adversarial loss: 0.506809\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381449; batch adversarial loss: 0.534897\n",
      "epoch 148; iter: 0; batch classifier loss: 0.411399; batch adversarial loss: 0.562654\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359950; batch adversarial loss: 0.553986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389252; batch adversarial loss: 0.629430\n",
      "epoch 151; iter: 0; batch classifier loss: 0.413021; batch adversarial loss: 0.487609\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395148; batch adversarial loss: 0.535210\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362718; batch adversarial loss: 0.478624\n",
      "epoch 154; iter: 0; batch classifier loss: 0.399121; batch adversarial loss: 0.430958\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388029; batch adversarial loss: 0.506918\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416742; batch adversarial loss: 0.487589\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388776; batch adversarial loss: 0.563172\n",
      "epoch 158; iter: 0; batch classifier loss: 0.415270; batch adversarial loss: 0.563191\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339587; batch adversarial loss: 0.506640\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353548; batch adversarial loss: 0.544632\n",
      "epoch 161; iter: 0; batch classifier loss: 0.449039; batch adversarial loss: 0.535125\n",
      "epoch 162; iter: 0; batch classifier loss: 0.426287; batch adversarial loss: 0.554763\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348019; batch adversarial loss: 0.544705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.359909; batch adversarial loss: 0.562693\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361734; batch adversarial loss: 0.506569\n",
      "epoch 166; iter: 0; batch classifier loss: 0.415401; batch adversarial loss: 0.591471\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384811; batch adversarial loss: 0.582149\n",
      "epoch 168; iter: 0; batch classifier loss: 0.385735; batch adversarial loss: 0.582698\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380066; batch adversarial loss: 0.544695\n",
      "epoch 170; iter: 0; batch classifier loss: 0.415504; batch adversarial loss: 0.630037\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353823; batch adversarial loss: 0.553977\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349425; batch adversarial loss: 0.543811\n",
      "epoch 173; iter: 0; batch classifier loss: 0.352157; batch adversarial loss: 0.553345\n",
      "epoch 174; iter: 0; batch classifier loss: 0.423495; batch adversarial loss: 0.600595\n",
      "epoch 175; iter: 0; batch classifier loss: 0.444484; batch adversarial loss: 0.496247\n",
      "epoch 176; iter: 0; batch classifier loss: 0.286912; batch adversarial loss: 0.496200\n",
      "epoch 177; iter: 0; batch classifier loss: 0.516756; batch adversarial loss: 0.584378\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390762; batch adversarial loss: 0.573222\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322349; batch adversarial loss: 0.534812\n",
      "epoch 180; iter: 0; batch classifier loss: 0.407591; batch adversarial loss: 0.497398\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344112; batch adversarial loss: 0.564982\n",
      "epoch 182; iter: 0; batch classifier loss: 0.315209; batch adversarial loss: 0.562531\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372398; batch adversarial loss: 0.560829\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330613; batch adversarial loss: 0.534420\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379208; batch adversarial loss: 0.469402\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367046; batch adversarial loss: 0.489918\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341237; batch adversarial loss: 0.555100\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363672; batch adversarial loss: 0.515285\n",
      "epoch 189; iter: 0; batch classifier loss: 0.360017; batch adversarial loss: 0.481339\n",
      "epoch 190; iter: 0; batch classifier loss: 0.273393; batch adversarial loss: 0.563537\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316188; batch adversarial loss: 0.646337\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306116; batch adversarial loss: 0.553468\n",
      "epoch 193; iter: 0; batch classifier loss: 0.464679; batch adversarial loss: 0.544388\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386910; batch adversarial loss: 0.516395\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347717; batch adversarial loss: 0.563493\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355502; batch adversarial loss: 0.441131\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323057; batch adversarial loss: 0.544575\n",
      "epoch 198; iter: 0; batch classifier loss: 0.288043; batch adversarial loss: 0.544259\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337217; batch adversarial loss: 0.469079\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697762; batch adversarial loss: 0.779725\n",
      "epoch 1; iter: 0; batch classifier loss: 0.625125; batch adversarial loss: 0.741033\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605800; batch adversarial loss: 0.686437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559722; batch adversarial loss: 0.645988\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572609; batch adversarial loss: 0.642359\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585053; batch adversarial loss: 0.623474\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549624; batch adversarial loss: 0.608799\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481687; batch adversarial loss: 0.621414\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522604; batch adversarial loss: 0.556895\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549481; batch adversarial loss: 0.566234\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477293; batch adversarial loss: 0.581786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491982; batch adversarial loss: 0.500278\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510654; batch adversarial loss: 0.550505\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516583; batch adversarial loss: 0.564650\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516686; batch adversarial loss: 0.589179\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525691; batch adversarial loss: 0.558720\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537938; batch adversarial loss: 0.545167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.571715; batch adversarial loss: 0.528461\n",
      "epoch 18; iter: 0; batch classifier loss: 0.564173; batch adversarial loss: 0.550823\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530158; batch adversarial loss: 0.542782\n",
      "epoch 20; iter: 0; batch classifier loss: 0.537161; batch adversarial loss: 0.622353\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469229; batch adversarial loss: 0.568936\n",
      "epoch 22; iter: 0; batch classifier loss: 0.552896; batch adversarial loss: 0.580352\n",
      "epoch 23; iter: 0; batch classifier loss: 0.585103; batch adversarial loss: 0.561368\n",
      "epoch 24; iter: 0; batch classifier loss: 0.534534; batch adversarial loss: 0.586983\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519282; batch adversarial loss: 0.571135\n",
      "epoch 26; iter: 0; batch classifier loss: 0.559106; batch adversarial loss: 0.475571\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529807; batch adversarial loss: 0.563429\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491632; batch adversarial loss: 0.516379\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398844; batch adversarial loss: 0.490184\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470447; batch adversarial loss: 0.553920\n",
      "epoch 31; iter: 0; batch classifier loss: 0.540550; batch adversarial loss: 0.616493\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473159; batch adversarial loss: 0.511094\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427724; batch adversarial loss: 0.519291\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434992; batch adversarial loss: 0.493453\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468154; batch adversarial loss: 0.657543\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483203; batch adversarial loss: 0.580116\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456926; batch adversarial loss: 0.536629\n",
      "epoch 38; iter: 0; batch classifier loss: 0.533068; batch adversarial loss: 0.552394\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440534; batch adversarial loss: 0.563861\n",
      "epoch 40; iter: 0; batch classifier loss: 0.502016; batch adversarial loss: 0.536437\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448429; batch adversarial loss: 0.525851\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431752; batch adversarial loss: 0.543837\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462320; batch adversarial loss: 0.544501\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409667; batch adversarial loss: 0.443983\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435034; batch adversarial loss: 0.582946\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385759; batch adversarial loss: 0.516153\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403880; batch adversarial loss: 0.545138\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447334; batch adversarial loss: 0.498323\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416893; batch adversarial loss: 0.589987\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400772; batch adversarial loss: 0.581030\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470449; batch adversarial loss: 0.545332\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414981; batch adversarial loss: 0.480021\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464902; batch adversarial loss: 0.526147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437191; batch adversarial loss: 0.469669\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436207; batch adversarial loss: 0.497537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438057; batch adversarial loss: 0.526485\n",
      "epoch 57; iter: 0; batch classifier loss: 0.474273; batch adversarial loss: 0.590325\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409951; batch adversarial loss: 0.545856\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409391; batch adversarial loss: 0.499022\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426879; batch adversarial loss: 0.544369\n",
      "epoch 61; iter: 0; batch classifier loss: 0.370915; batch adversarial loss: 0.572752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.377939; batch adversarial loss: 0.535107\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428301; batch adversarial loss: 0.562613\n",
      "epoch 64; iter: 0; batch classifier loss: 0.464033; batch adversarial loss: 0.586925\n",
      "epoch 65; iter: 0; batch classifier loss: 0.530982; batch adversarial loss: 0.496010\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409723; batch adversarial loss: 0.534902\n",
      "epoch 67; iter: 0; batch classifier loss: 0.367138; batch adversarial loss: 0.636729\n",
      "epoch 68; iter: 0; batch classifier loss: 0.499219; batch adversarial loss: 0.544364\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435279; batch adversarial loss: 0.509613\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388927; batch adversarial loss: 0.647842\n",
      "epoch 71; iter: 0; batch classifier loss: 0.531350; batch adversarial loss: 0.554703\n",
      "epoch 72; iter: 0; batch classifier loss: 0.337256; batch adversarial loss: 0.516401\n",
      "epoch 73; iter: 0; batch classifier loss: 0.348297; batch adversarial loss: 0.535431\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395733; batch adversarial loss: 0.459424\n",
      "epoch 75; iter: 0; batch classifier loss: 0.450888; batch adversarial loss: 0.537338\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454276; batch adversarial loss: 0.571754\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434788; batch adversarial loss: 0.572495\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391924; batch adversarial loss: 0.544895\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426243; batch adversarial loss: 0.525655\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423705; batch adversarial loss: 0.441216\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413586; batch adversarial loss: 0.488157\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441388; batch adversarial loss: 0.469744\n",
      "epoch 83; iter: 0; batch classifier loss: 0.491203; batch adversarial loss: 0.582008\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368283; batch adversarial loss: 0.498057\n",
      "epoch 85; iter: 0; batch classifier loss: 0.440010; batch adversarial loss: 0.525717\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427496; batch adversarial loss: 0.535213\n",
      "epoch 87; iter: 0; batch classifier loss: 0.425691; batch adversarial loss: 0.591365\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389563; batch adversarial loss: 0.507150\n",
      "epoch 89; iter: 0; batch classifier loss: 0.434126; batch adversarial loss: 0.544768\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367952; batch adversarial loss: 0.508066\n",
      "epoch 91; iter: 0; batch classifier loss: 0.368885; batch adversarial loss: 0.554030\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389893; batch adversarial loss: 0.544623\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398505; batch adversarial loss: 0.562020\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434479; batch adversarial loss: 0.600186\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377953; batch adversarial loss: 0.507961\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410205; batch adversarial loss: 0.506030\n",
      "epoch 97; iter: 0; batch classifier loss: 0.326851; batch adversarial loss: 0.572489\n",
      "epoch 98; iter: 0; batch classifier loss: 0.429487; batch adversarial loss: 0.490770\n",
      "epoch 99; iter: 0; batch classifier loss: 0.333301; batch adversarial loss: 0.479016\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400991; batch adversarial loss: 0.601107\n",
      "epoch 101; iter: 0; batch classifier loss: 0.485658; batch adversarial loss: 0.592362\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392803; batch adversarial loss: 0.544660\n",
      "epoch 103; iter: 0; batch classifier loss: 0.461961; batch adversarial loss: 0.506730\n",
      "epoch 104; iter: 0; batch classifier loss: 0.309356; batch adversarial loss: 0.572628\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410138; batch adversarial loss: 0.450720\n",
      "epoch 106; iter: 0; batch classifier loss: 0.403246; batch adversarial loss: 0.516526\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401660; batch adversarial loss: 0.544542\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403424; batch adversarial loss: 0.489130\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342121; batch adversarial loss: 0.451875\n",
      "epoch 110; iter: 0; batch classifier loss: 0.298630; batch adversarial loss: 0.516862\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389642; batch adversarial loss: 0.516841\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384577; batch adversarial loss: 0.525974\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406170; batch adversarial loss: 0.609538\n",
      "epoch 114; iter: 0; batch classifier loss: 0.440445; batch adversarial loss: 0.479551\n",
      "epoch 115; iter: 0; batch classifier loss: 0.421932; batch adversarial loss: 0.479980\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323424; batch adversarial loss: 0.479616\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407001; batch adversarial loss: 0.488553\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391186; batch adversarial loss: 0.497532\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353420; batch adversarial loss: 0.600590\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401224; batch adversarial loss: 0.507196\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374259; batch adversarial loss: 0.479491\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413709; batch adversarial loss: 0.544370\n",
      "epoch 123; iter: 0; batch classifier loss: 0.420998; batch adversarial loss: 0.516982\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348893; batch adversarial loss: 0.581102\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374827; batch adversarial loss: 0.498620\n",
      "epoch 126; iter: 0; batch classifier loss: 0.420284; batch adversarial loss: 0.553719\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366126; batch adversarial loss: 0.517409\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381734; batch adversarial loss: 0.543938\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395627; batch adversarial loss: 0.480566\n",
      "epoch 130; iter: 0; batch classifier loss: 0.287657; batch adversarial loss: 0.535432\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384144; batch adversarial loss: 0.590768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331760; batch adversarial loss: 0.592571\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388260; batch adversarial loss: 0.572409\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399151; batch adversarial loss: 0.563322\n",
      "epoch 135; iter: 0; batch classifier loss: 0.422650; batch adversarial loss: 0.526232\n",
      "epoch 136; iter: 0; batch classifier loss: 0.394338; batch adversarial loss: 0.572574\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328117; batch adversarial loss: 0.591569\n",
      "epoch 138; iter: 0; batch classifier loss: 0.433987; batch adversarial loss: 0.535197\n",
      "epoch 139; iter: 0; batch classifier loss: 0.446457; batch adversarial loss: 0.581939\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328462; batch adversarial loss: 0.601115\n",
      "epoch 141; iter: 0; batch classifier loss: 0.414914; batch adversarial loss: 0.600086\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395482; batch adversarial loss: 0.535299\n",
      "epoch 143; iter: 0; batch classifier loss: 0.290471; batch adversarial loss: 0.516265\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377448; batch adversarial loss: 0.525947\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364265; batch adversarial loss: 0.526216\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.497947\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391343; batch adversarial loss: 0.553278\n",
      "epoch 148; iter: 0; batch classifier loss: 0.429430; batch adversarial loss: 0.507615\n",
      "epoch 149; iter: 0; batch classifier loss: 0.429102; batch adversarial loss: 0.599875\n",
      "epoch 150; iter: 0; batch classifier loss: 0.450464; batch adversarial loss: 0.535038\n",
      "epoch 151; iter: 0; batch classifier loss: 0.483938; batch adversarial loss: 0.572839\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362500; batch adversarial loss: 0.572157\n",
      "epoch 153; iter: 0; batch classifier loss: 0.416799; batch adversarial loss: 0.526536\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313299; batch adversarial loss: 0.534783\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373721; batch adversarial loss: 0.591296\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371603; batch adversarial loss: 0.581595\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368808; batch adversarial loss: 0.544746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.416536; batch adversarial loss: 0.572377\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390261; batch adversarial loss: 0.544842\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357043; batch adversarial loss: 0.572298\n",
      "epoch 161; iter: 0; batch classifier loss: 0.328960; batch adversarial loss: 0.535215\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350017; batch adversarial loss: 0.563432\n",
      "epoch 163; iter: 0; batch classifier loss: 0.390051; batch adversarial loss: 0.526202\n",
      "epoch 164; iter: 0; batch classifier loss: 0.343066; batch adversarial loss: 0.599830\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405622; batch adversarial loss: 0.498466\n",
      "epoch 166; iter: 0; batch classifier loss: 0.276961; batch adversarial loss: 0.580693\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380480; batch adversarial loss: 0.571070\n",
      "epoch 168; iter: 0; batch classifier loss: 0.374418; batch adversarial loss: 0.581696\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322977; batch adversarial loss: 0.572169\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364208; batch adversarial loss: 0.479500\n",
      "epoch 171; iter: 0; batch classifier loss: 0.412548; batch adversarial loss: 0.553825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.463876; batch adversarial loss: 0.563386\n",
      "epoch 173; iter: 0; batch classifier loss: 0.443356; batch adversarial loss: 0.637495\n",
      "epoch 174; iter: 0; batch classifier loss: 0.426738; batch adversarial loss: 0.534926\n",
      "epoch 175; iter: 0; batch classifier loss: 0.440015; batch adversarial loss: 0.544350\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355324; batch adversarial loss: 0.498013\n",
      "epoch 177; iter: 0; batch classifier loss: 0.367888; batch adversarial loss: 0.516974\n",
      "epoch 178; iter: 0; batch classifier loss: 0.399101; batch adversarial loss: 0.488003\n",
      "epoch 179; iter: 0; batch classifier loss: 0.430877; batch adversarial loss: 0.563381\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368393; batch adversarial loss: 0.618352\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336078; batch adversarial loss: 0.516386\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372984; batch adversarial loss: 0.591153\n",
      "epoch 183; iter: 0; batch classifier loss: 0.459236; batch adversarial loss: 0.535408\n",
      "epoch 184; iter: 0; batch classifier loss: 0.304825; batch adversarial loss: 0.553087\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346376; batch adversarial loss: 0.461362\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324127; batch adversarial loss: 0.618216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376581; batch adversarial loss: 0.525390\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404854; batch adversarial loss: 0.525531\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358062; batch adversarial loss: 0.553078\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341305; batch adversarial loss: 0.608228\n",
      "epoch 191; iter: 0; batch classifier loss: 0.418051; batch adversarial loss: 0.489309\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353017; batch adversarial loss: 0.498820\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360110; batch adversarial loss: 0.443652\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395891; batch adversarial loss: 0.498614\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339547; batch adversarial loss: 0.544676\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339256; batch adversarial loss: 0.562177\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332342; batch adversarial loss: 0.609517\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370703; batch adversarial loss: 0.405529\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355391; batch adversarial loss: 0.516750\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687080; batch adversarial loss: 0.720472\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569620; batch adversarial loss: 0.687797\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547372; batch adversarial loss: 0.661630\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568577; batch adversarial loss: 0.640562\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553848; batch adversarial loss: 0.628515\n",
      "epoch 5; iter: 0; batch classifier loss: 0.488129; batch adversarial loss: 0.603360\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496450; batch adversarial loss: 0.558698\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546394; batch adversarial loss: 0.571870\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511666; batch adversarial loss: 0.572642\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528338; batch adversarial loss: 0.590675\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509079; batch adversarial loss: 0.572066\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531355; batch adversarial loss: 0.629352\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586424; batch adversarial loss: 0.587018\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603208; batch adversarial loss: 0.525164\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515090; batch adversarial loss: 0.558446\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512634; batch adversarial loss: 0.610456\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556480; batch adversarial loss: 0.591429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487235; batch adversarial loss: 0.513422\n",
      "epoch 18; iter: 0; batch classifier loss: 0.586854; batch adversarial loss: 0.607000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554775; batch adversarial loss: 0.594476\n",
      "epoch 20; iter: 0; batch classifier loss: 0.564478; batch adversarial loss: 0.568420\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486191; batch adversarial loss: 0.576229\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437156; batch adversarial loss: 0.510679\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531473; batch adversarial loss: 0.568674\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504790; batch adversarial loss: 0.558240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566569; batch adversarial loss: 0.556284\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543849; batch adversarial loss: 0.495704\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476564; batch adversarial loss: 0.485696\n",
      "epoch 28; iter: 0; batch classifier loss: 0.497548; batch adversarial loss: 0.609900\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425149; batch adversarial loss: 0.569151\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496197; batch adversarial loss: 0.520585\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460704; batch adversarial loss: 0.537140\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484201; batch adversarial loss: 0.536648\n",
      "epoch 33; iter: 0; batch classifier loss: 0.394807; batch adversarial loss: 0.613091\n",
      "epoch 34; iter: 0; batch classifier loss: 0.504415; batch adversarial loss: 0.502549\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480452; batch adversarial loss: 0.536109\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430999; batch adversarial loss: 0.552823\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464915; batch adversarial loss: 0.500096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414967; batch adversarial loss: 0.544873\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498828; batch adversarial loss: 0.501245\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454467; batch adversarial loss: 0.561798\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467129; batch adversarial loss: 0.561164\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505486; batch adversarial loss: 0.605391\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473528; batch adversarial loss: 0.569415\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400851; batch adversarial loss: 0.623514\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409554; batch adversarial loss: 0.560467\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462768; batch adversarial loss: 0.545094\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434662; batch adversarial loss: 0.562963\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423267; batch adversarial loss: 0.560807\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436026; batch adversarial loss: 0.535646\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401134; batch adversarial loss: 0.536968\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434194; batch adversarial loss: 0.544836\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435765; batch adversarial loss: 0.573596\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379031; batch adversarial loss: 0.571921\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427496; batch adversarial loss: 0.535180\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454819; batch adversarial loss: 0.571205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.391721; batch adversarial loss: 0.562864\n",
      "epoch 57; iter: 0; batch classifier loss: 0.462042; batch adversarial loss: 0.561520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412005; batch adversarial loss: 0.607899\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428827; batch adversarial loss: 0.590044\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429164; batch adversarial loss: 0.544022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430334; batch adversarial loss: 0.517393\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394714; batch adversarial loss: 0.607673\n",
      "epoch 63; iter: 0; batch classifier loss: 0.478246; batch adversarial loss: 0.572476\n",
      "epoch 64; iter: 0; batch classifier loss: 0.483503; batch adversarial loss: 0.616224\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437932; batch adversarial loss: 0.542834\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400311; batch adversarial loss: 0.528478\n",
      "epoch 67; iter: 0; batch classifier loss: 0.538008; batch adversarial loss: 0.606627\n",
      "epoch 68; iter: 0; batch classifier loss: 0.387260; batch adversarial loss: 0.552980\n",
      "epoch 69; iter: 0; batch classifier loss: 0.494896; batch adversarial loss: 0.545191\n",
      "epoch 70; iter: 0; batch classifier loss: 0.495150; batch adversarial loss: 0.518193\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446274; batch adversarial loss: 0.552530\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365902; batch adversarial loss: 0.588728\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383668; batch adversarial loss: 0.527985\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367125; batch adversarial loss: 0.589784\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398150; batch adversarial loss: 0.599599\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402181; batch adversarial loss: 0.588885\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391677; batch adversarial loss: 0.638255\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355080; batch adversarial loss: 0.553538\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386081; batch adversarial loss: 0.552947\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439719; batch adversarial loss: 0.569559\n",
      "epoch 81; iter: 0; batch classifier loss: 0.457939; batch adversarial loss: 0.590286\n",
      "epoch 82; iter: 0; batch classifier loss: 0.469038; batch adversarial loss: 0.498967\n",
      "epoch 83; iter: 0; batch classifier loss: 0.432067; batch adversarial loss: 0.597925\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400284; batch adversarial loss: 0.544231\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438898; batch adversarial loss: 0.435039\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402633; batch adversarial loss: 0.581732\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398907; batch adversarial loss: 0.500689\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377998; batch adversarial loss: 0.613885\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416230; batch adversarial loss: 0.598015\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362860; batch adversarial loss: 0.571198\n",
      "epoch 91; iter: 0; batch classifier loss: 0.392128; batch adversarial loss: 0.536421\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396513; batch adversarial loss: 0.638981\n",
      "epoch 93; iter: 0; batch classifier loss: 0.434047; batch adversarial loss: 0.613236\n",
      "epoch 94; iter: 0; batch classifier loss: 0.400844; batch adversarial loss: 0.554174\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424763; batch adversarial loss: 0.580866\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416802; batch adversarial loss: 0.545802\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439604; batch adversarial loss: 0.500297\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400504; batch adversarial loss: 0.553753\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386535; batch adversarial loss: 0.498093\n",
      "epoch 100; iter: 0; batch classifier loss: 0.490185; batch adversarial loss: 0.524299\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392283; batch adversarial loss: 0.481255\n",
      "epoch 102; iter: 0; batch classifier loss: 0.304966; batch adversarial loss: 0.502785\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390131; batch adversarial loss: 0.585092\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368132; batch adversarial loss: 0.465160\n",
      "epoch 105; iter: 0; batch classifier loss: 0.450735; batch adversarial loss: 0.462250\n",
      "epoch 106; iter: 0; batch classifier loss: 0.462651; batch adversarial loss: 0.507091\n",
      "epoch 107; iter: 0; batch classifier loss: 0.383135; batch adversarial loss: 0.602108\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388329; batch adversarial loss: 0.590047\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383807; batch adversarial loss: 0.562725\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365575; batch adversarial loss: 0.562102\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406541; batch adversarial loss: 0.537515\n",
      "epoch 112; iter: 0; batch classifier loss: 0.342868; batch adversarial loss: 0.453988\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358357; batch adversarial loss: 0.491122\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389412; batch adversarial loss: 0.626527\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420313; batch adversarial loss: 0.600195\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382096; batch adversarial loss: 0.608032\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394362; batch adversarial loss: 0.564279\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338136; batch adversarial loss: 0.525694\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385252; batch adversarial loss: 0.481859\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361361; batch adversarial loss: 0.469893\n",
      "epoch 121; iter: 0; batch classifier loss: 0.405308; batch adversarial loss: 0.544708\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410749; batch adversarial loss: 0.525559\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416901; batch adversarial loss: 0.536230\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395103; batch adversarial loss: 0.516790\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403346; batch adversarial loss: 0.535298\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346364; batch adversarial loss: 0.588696\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370970; batch adversarial loss: 0.625905\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399870; batch adversarial loss: 0.524700\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388490; batch adversarial loss: 0.545230\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406872; batch adversarial loss: 0.534245\n",
      "epoch 131; iter: 0; batch classifier loss: 0.329974; batch adversarial loss: 0.613841\n",
      "epoch 132; iter: 0; batch classifier loss: 0.348744; batch adversarial loss: 0.597681\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388158; batch adversarial loss: 0.535640\n",
      "epoch 134; iter: 0; batch classifier loss: 0.418442; batch adversarial loss: 0.471044\n",
      "epoch 135; iter: 0; batch classifier loss: 0.300455; batch adversarial loss: 0.552940\n",
      "epoch 136; iter: 0; batch classifier loss: 0.434916; batch adversarial loss: 0.602861\n",
      "epoch 137; iter: 0; batch classifier loss: 0.364400; batch adversarial loss: 0.517666\n",
      "epoch 138; iter: 0; batch classifier loss: 0.372098; batch adversarial loss: 0.607463\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415993; batch adversarial loss: 0.590073\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374196; batch adversarial loss: 0.538043\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344813; batch adversarial loss: 0.563354\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353340; batch adversarial loss: 0.518049\n",
      "epoch 143; iter: 0; batch classifier loss: 0.347318; batch adversarial loss: 0.553852\n",
      "epoch 144; iter: 0; batch classifier loss: 0.397703; batch adversarial loss: 0.543466\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376416; batch adversarial loss: 0.562053\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338081; batch adversarial loss: 0.535210\n",
      "epoch 147; iter: 0; batch classifier loss: 0.407562; batch adversarial loss: 0.545186\n",
      "epoch 148; iter: 0; batch classifier loss: 0.442147; batch adversarial loss: 0.518855\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387402; batch adversarial loss: 0.590022\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318506; batch adversarial loss: 0.498507\n",
      "epoch 151; iter: 0; batch classifier loss: 0.411497; batch adversarial loss: 0.553027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.351787; batch adversarial loss: 0.528149\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350364; batch adversarial loss: 0.608181\n",
      "epoch 154; iter: 0; batch classifier loss: 0.398712; batch adversarial loss: 0.571087\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369586; batch adversarial loss: 0.554163\n",
      "epoch 156; iter: 0; batch classifier loss: 0.316428; batch adversarial loss: 0.673548\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403365; batch adversarial loss: 0.453996\n",
      "epoch 158; iter: 0; batch classifier loss: 0.322324; batch adversarial loss: 0.553548\n",
      "epoch 159; iter: 0; batch classifier loss: 0.392812; batch adversarial loss: 0.537447\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372349; batch adversarial loss: 0.561312\n",
      "epoch 161; iter: 0; batch classifier loss: 0.426866; batch adversarial loss: 0.463369\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360991; batch adversarial loss: 0.533589\n",
      "epoch 163; iter: 0; batch classifier loss: 0.443466; batch adversarial loss: 0.550636\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409030; batch adversarial loss: 0.572429\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353205; batch adversarial loss: 0.563720\n",
      "epoch 166; iter: 0; batch classifier loss: 0.509358; batch adversarial loss: 0.482554\n",
      "epoch 167; iter: 0; batch classifier loss: 0.378524; batch adversarial loss: 0.536250\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320330; batch adversarial loss: 0.508431\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351245; batch adversarial loss: 0.498683\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384300; batch adversarial loss: 0.554291\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333542; batch adversarial loss: 0.507751\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351946; batch adversarial loss: 0.646577\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349394; batch adversarial loss: 0.552986\n",
      "epoch 174; iter: 0; batch classifier loss: 0.454953; batch adversarial loss: 0.680530\n",
      "epoch 175; iter: 0; batch classifier loss: 0.318031; batch adversarial loss: 0.472406\n",
      "epoch 176; iter: 0; batch classifier loss: 0.345897; batch adversarial loss: 0.599979\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349152; batch adversarial loss: 0.579346\n",
      "epoch 178; iter: 0; batch classifier loss: 0.397400; batch adversarial loss: 0.516883\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330277; batch adversarial loss: 0.526348\n",
      "epoch 180; iter: 0; batch classifier loss: 0.416799; batch adversarial loss: 0.535768\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375124; batch adversarial loss: 0.572618\n",
      "epoch 182; iter: 0; batch classifier loss: 0.312594; batch adversarial loss: 0.644621\n",
      "epoch 183; iter: 0; batch classifier loss: 0.407368; batch adversarial loss: 0.536095\n",
      "epoch 184; iter: 0; batch classifier loss: 0.435386; batch adversarial loss: 0.543962\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315878; batch adversarial loss: 0.490147\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366096; batch adversarial loss: 0.518912\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354407; batch adversarial loss: 0.581271\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328845; batch adversarial loss: 0.562484\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331303; batch adversarial loss: 0.617846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365583; batch adversarial loss: 0.589383\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373598; batch adversarial loss: 0.519127\n",
      "epoch 192; iter: 0; batch classifier loss: 0.322331; batch adversarial loss: 0.508777\n",
      "epoch 193; iter: 0; batch classifier loss: 0.268388; batch adversarial loss: 0.619428\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333260; batch adversarial loss: 0.535888\n",
      "epoch 195; iter: 0; batch classifier loss: 0.410926; batch adversarial loss: 0.534266\n",
      "epoch 196; iter: 0; batch classifier loss: 0.469478; batch adversarial loss: 0.580965\n",
      "epoch 197; iter: 0; batch classifier loss: 0.485021; batch adversarial loss: 0.500538\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369282; batch adversarial loss: 0.563181\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330879; batch adversarial loss: 0.564071\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693535; batch adversarial loss: 0.590758\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595104; batch adversarial loss: 0.595640\n",
      "epoch 2; iter: 0; batch classifier loss: 0.656434; batch adversarial loss: 0.662344\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618838; batch adversarial loss: 0.585993\n",
      "epoch 4; iter: 0; batch classifier loss: 0.516962; batch adversarial loss: 0.650362\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553658; batch adversarial loss: 0.573363\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527951; batch adversarial loss: 0.507034\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571116; batch adversarial loss: 0.636293\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582080; batch adversarial loss: 0.574594\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551655; batch adversarial loss: 0.614074\n",
      "epoch 10; iter: 0; batch classifier loss: 0.591805; batch adversarial loss: 0.589141\n",
      "epoch 11; iter: 0; batch classifier loss: 0.583730; batch adversarial loss: 0.519582\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557664; batch adversarial loss: 0.569879\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522047; batch adversarial loss: 0.550271\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442732; batch adversarial loss: 0.616506\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478088; batch adversarial loss: 0.506926\n",
      "epoch 16; iter: 0; batch classifier loss: 0.599729; batch adversarial loss: 0.526698\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568787; batch adversarial loss: 0.582589\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471641; batch adversarial loss: 0.564795\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478701; batch adversarial loss: 0.544948\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519237; batch adversarial loss: 0.590008\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520939; batch adversarial loss: 0.614892\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472334; batch adversarial loss: 0.539798\n",
      "epoch 23; iter: 0; batch classifier loss: 0.437166; batch adversarial loss: 0.610758\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524706; batch adversarial loss: 0.539068\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476581; batch adversarial loss: 0.497608\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458897; batch adversarial loss: 0.523825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511321; batch adversarial loss: 0.536690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488780; batch adversarial loss: 0.576498\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488392; batch adversarial loss: 0.555108\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439859; batch adversarial loss: 0.538288\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426449; batch adversarial loss: 0.494969\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420903; batch adversarial loss: 0.545637\n",
      "epoch 33; iter: 0; batch classifier loss: 0.533726; batch adversarial loss: 0.502088\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466092; batch adversarial loss: 0.491942\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456448; batch adversarial loss: 0.519264\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436329; batch adversarial loss: 0.642613\n",
      "epoch 37; iter: 0; batch classifier loss: 0.512509; batch adversarial loss: 0.526836\n",
      "epoch 38; iter: 0; batch classifier loss: 0.513218; batch adversarial loss: 0.474187\n",
      "epoch 39; iter: 0; batch classifier loss: 0.444313; batch adversarial loss: 0.509572\n",
      "epoch 40; iter: 0; batch classifier loss: 0.511443; batch adversarial loss: 0.580391\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499149; batch adversarial loss: 0.616658\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446913; batch adversarial loss: 0.553510\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441254; batch adversarial loss: 0.562431\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429768; batch adversarial loss: 0.580667\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514468; batch adversarial loss: 0.526661\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374269; batch adversarial loss: 0.543671\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435494; batch adversarial loss: 0.587934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.397124; batch adversarial loss: 0.491259\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452750; batch adversarial loss: 0.559486\n",
      "epoch 50; iter: 0; batch classifier loss: 0.480369; batch adversarial loss: 0.561944\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482877; batch adversarial loss: 0.505545\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415565; batch adversarial loss: 0.650955\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408255; batch adversarial loss: 0.585733\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467032; batch adversarial loss: 0.643987\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388638; batch adversarial loss: 0.544579\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436817; batch adversarial loss: 0.582959\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398138; batch adversarial loss: 0.547149\n",
      "epoch 58; iter: 0; batch classifier loss: 0.474940; batch adversarial loss: 0.656162\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456615; batch adversarial loss: 0.572345\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444315; batch adversarial loss: 0.517533\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408147; batch adversarial loss: 0.525527\n",
      "epoch 62; iter: 0; batch classifier loss: 0.437061; batch adversarial loss: 0.525696\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422639; batch adversarial loss: 0.543862\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410898; batch adversarial loss: 0.544867\n",
      "epoch 65; iter: 0; batch classifier loss: 0.359108; batch adversarial loss: 0.508295\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438099; batch adversarial loss: 0.525655\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447451; batch adversarial loss: 0.481165\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441132; batch adversarial loss: 0.562977\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411893; batch adversarial loss: 0.415189\n",
      "epoch 70; iter: 0; batch classifier loss: 0.454623; batch adversarial loss: 0.599417\n",
      "epoch 71; iter: 0; batch classifier loss: 0.371992; batch adversarial loss: 0.499571\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430512; batch adversarial loss: 0.498589\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401837; batch adversarial loss: 0.529193\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414929; batch adversarial loss: 0.571330\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423237; batch adversarial loss: 0.570459\n",
      "epoch 76; iter: 0; batch classifier loss: 0.432288; batch adversarial loss: 0.527525\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344107; batch adversarial loss: 0.553835\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397995; batch adversarial loss: 0.534593\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406108; batch adversarial loss: 0.571406\n",
      "epoch 80; iter: 0; batch classifier loss: 0.357907; batch adversarial loss: 0.553196\n",
      "epoch 81; iter: 0; batch classifier loss: 0.466093; batch adversarial loss: 0.618568\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359375; batch adversarial loss: 0.589881\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377239; batch adversarial loss: 0.535650\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369703; batch adversarial loss: 0.525448\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360888; batch adversarial loss: 0.625983\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390041; batch adversarial loss: 0.480380\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357135; batch adversarial loss: 0.508011\n",
      "epoch 88; iter: 0; batch classifier loss: 0.467782; batch adversarial loss: 0.654163\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407047; batch adversarial loss: 0.535479\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366880; batch adversarial loss: 0.516289\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422913; batch adversarial loss: 0.481908\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407206; batch adversarial loss: 0.581390\n",
      "epoch 93; iter: 0; batch classifier loss: 0.430225; batch adversarial loss: 0.546094\n",
      "epoch 94; iter: 0; batch classifier loss: 0.465842; batch adversarial loss: 0.498397\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382510; batch adversarial loss: 0.573707\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383785; batch adversarial loss: 0.444021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376078; batch adversarial loss: 0.551496\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370032; batch adversarial loss: 0.527186\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393805; batch adversarial loss: 0.481194\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360567; batch adversarial loss: 0.536136\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381983; batch adversarial loss: 0.517331\n",
      "epoch 102; iter: 0; batch classifier loss: 0.344137; batch adversarial loss: 0.488515\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365668; batch adversarial loss: 0.617585\n",
      "epoch 104; iter: 0; batch classifier loss: 0.447458; batch adversarial loss: 0.462778\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361654; batch adversarial loss: 0.527062\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371107; batch adversarial loss: 0.589560\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386176; batch adversarial loss: 0.562564\n",
      "epoch 108; iter: 0; batch classifier loss: 0.474481; batch adversarial loss: 0.489585\n",
      "epoch 109; iter: 0; batch classifier loss: 0.349336; batch adversarial loss: 0.545100\n",
      "epoch 110; iter: 0; batch classifier loss: 0.374653; batch adversarial loss: 0.580609\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335811; batch adversarial loss: 0.553720\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394477; batch adversarial loss: 0.572047\n",
      "epoch 113; iter: 0; batch classifier loss: 0.436520; batch adversarial loss: 0.498337\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359664; batch adversarial loss: 0.544770\n",
      "epoch 115; iter: 0; batch classifier loss: 0.414457; batch adversarial loss: 0.618074\n",
      "epoch 116; iter: 0; batch classifier loss: 0.334167; batch adversarial loss: 0.552810\n",
      "epoch 117; iter: 0; batch classifier loss: 0.419503; batch adversarial loss: 0.582407\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368459; batch adversarial loss: 0.535658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404258; batch adversarial loss: 0.554305\n",
      "epoch 120; iter: 0; batch classifier loss: 0.424586; batch adversarial loss: 0.571185\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398725; batch adversarial loss: 0.581774\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373619; batch adversarial loss: 0.525755\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401826; batch adversarial loss: 0.526888\n",
      "epoch 124; iter: 0; batch classifier loss: 0.428593; batch adversarial loss: 0.509738\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359160; batch adversarial loss: 0.471887\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376450; batch adversarial loss: 0.544509\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358457; batch adversarial loss: 0.544369\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381477; batch adversarial loss: 0.562219\n",
      "epoch 129; iter: 0; batch classifier loss: 0.345864; batch adversarial loss: 0.580771\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374311; batch adversarial loss: 0.526449\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372779; batch adversarial loss: 0.515420\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390295; batch adversarial loss: 0.564064\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386779; batch adversarial loss: 0.599062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365608; batch adversarial loss: 0.545594\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395136; batch adversarial loss: 0.532990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341016; batch adversarial loss: 0.499400\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424666; batch adversarial loss: 0.563816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405649; batch adversarial loss: 0.572105\n",
      "epoch 139; iter: 0; batch classifier loss: 0.400829; batch adversarial loss: 0.526215\n",
      "epoch 140; iter: 0; batch classifier loss: 0.408414; batch adversarial loss: 0.499139\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373099; batch adversarial loss: 0.608611\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393058; batch adversarial loss: 0.569800\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412753; batch adversarial loss: 0.543873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.349913; batch adversarial loss: 0.470824\n",
      "epoch 145; iter: 0; batch classifier loss: 0.269133; batch adversarial loss: 0.509518\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333173; batch adversarial loss: 0.517325\n",
      "epoch 147; iter: 0; batch classifier loss: 0.396746; batch adversarial loss: 0.553464\n",
      "epoch 148; iter: 0; batch classifier loss: 0.306685; batch adversarial loss: 0.526008\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316261; batch adversarial loss: 0.562679\n",
      "epoch 150; iter: 0; batch classifier loss: 0.288585; batch adversarial loss: 0.563074\n",
      "epoch 151; iter: 0; batch classifier loss: 0.410339; batch adversarial loss: 0.508480\n",
      "epoch 152; iter: 0; batch classifier loss: 0.411570; batch adversarial loss: 0.498264\n",
      "epoch 153; iter: 0; batch classifier loss: 0.394634; batch adversarial loss: 0.526026\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353901; batch adversarial loss: 0.516616\n",
      "epoch 155; iter: 0; batch classifier loss: 0.326864; batch adversarial loss: 0.545497\n",
      "epoch 156; iter: 0; batch classifier loss: 0.489656; batch adversarial loss: 0.543483\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314457; batch adversarial loss: 0.564905\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338640; batch adversarial loss: 0.472167\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366142; batch adversarial loss: 0.582209\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358199; batch adversarial loss: 0.554686\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376293; batch adversarial loss: 0.627743\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357919; batch adversarial loss: 0.571262\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340221; batch adversarial loss: 0.562595\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386649; batch adversarial loss: 0.645730\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356260; batch adversarial loss: 0.471679\n",
      "epoch 166; iter: 0; batch classifier loss: 0.443941; batch adversarial loss: 0.543863\n",
      "epoch 167; iter: 0; batch classifier loss: 0.412021; batch adversarial loss: 0.469749\n",
      "epoch 168; iter: 0; batch classifier loss: 0.368134; batch adversarial loss: 0.615795\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375748; batch adversarial loss: 0.506436\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351722; batch adversarial loss: 0.508260\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375843; batch adversarial loss: 0.591624\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334270; batch adversarial loss: 0.598717\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362701; batch adversarial loss: 0.542878\n",
      "epoch 174; iter: 0; batch classifier loss: 0.305400; batch adversarial loss: 0.581513\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379487; batch adversarial loss: 0.561845\n",
      "epoch 176; iter: 0; batch classifier loss: 0.398091; batch adversarial loss: 0.489467\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329585; batch adversarial loss: 0.453256\n",
      "epoch 178; iter: 0; batch classifier loss: 0.421154; batch adversarial loss: 0.542644\n",
      "epoch 179; iter: 0; batch classifier loss: 0.316991; batch adversarial loss: 0.554473\n",
      "epoch 180; iter: 0; batch classifier loss: 0.397409; batch adversarial loss: 0.489710\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363666; batch adversarial loss: 0.480584\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408781; batch adversarial loss: 0.555451\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340168; batch adversarial loss: 0.507404\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424410; batch adversarial loss: 0.508385\n",
      "epoch 185; iter: 0; batch classifier loss: 0.386421; batch adversarial loss: 0.553211\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376119; batch adversarial loss: 0.460782\n",
      "epoch 187; iter: 0; batch classifier loss: 0.289999; batch adversarial loss: 0.536307\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368915; batch adversarial loss: 0.571267\n",
      "epoch 189; iter: 0; batch classifier loss: 0.425474; batch adversarial loss: 0.536035\n",
      "epoch 190; iter: 0; batch classifier loss: 0.393772; batch adversarial loss: 0.480104\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345994; batch adversarial loss: 0.488426\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388880; batch adversarial loss: 0.516095\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390522; batch adversarial loss: 0.544387\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419004; batch adversarial loss: 0.552927\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330015; batch adversarial loss: 0.599432\n",
      "epoch 196; iter: 0; batch classifier loss: 0.497886; batch adversarial loss: 0.580636\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344604; batch adversarial loss: 0.598970\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317657; batch adversarial loss: 0.580310\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360678; batch adversarial loss: 0.544057\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668747; batch adversarial loss: 0.603394\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593219; batch adversarial loss: 0.645460\n",
      "epoch 2; iter: 0; batch classifier loss: 0.503578; batch adversarial loss: 0.632207\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582377; batch adversarial loss: 0.716977\n",
      "epoch 4; iter: 0; batch classifier loss: 0.604981; batch adversarial loss: 0.649641\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538943; batch adversarial loss: 0.595685\n",
      "epoch 6; iter: 0; batch classifier loss: 0.503572; batch adversarial loss: 0.691537\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542246; batch adversarial loss: 0.622885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556819; batch adversarial loss: 0.591689\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547494; batch adversarial loss: 0.621905\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549161; batch adversarial loss: 0.656840\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491747; batch adversarial loss: 0.592791\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547212; batch adversarial loss: 0.585721\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480061; batch adversarial loss: 0.587171\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512907; batch adversarial loss: 0.497954\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529332; batch adversarial loss: 0.579667\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542113; batch adversarial loss: 0.578884\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532939; batch adversarial loss: 0.574885\n",
      "epoch 18; iter: 0; batch classifier loss: 0.596199; batch adversarial loss: 0.550018\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492781; batch adversarial loss: 0.513529\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477818; batch adversarial loss: 0.531719\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545183; batch adversarial loss: 0.545581\n",
      "epoch 22; iter: 0; batch classifier loss: 0.537302; batch adversarial loss: 0.552834\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508973; batch adversarial loss: 0.583423\n",
      "epoch 24; iter: 0; batch classifier loss: 0.559299; batch adversarial loss: 0.599152\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474046; batch adversarial loss: 0.589714\n",
      "epoch 26; iter: 0; batch classifier loss: 0.524689; batch adversarial loss: 0.556574\n",
      "epoch 27; iter: 0; batch classifier loss: 0.571391; batch adversarial loss: 0.496194\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437691; batch adversarial loss: 0.478783\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460453; batch adversarial loss: 0.604871\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460680; batch adversarial loss: 0.553528\n",
      "epoch 31; iter: 0; batch classifier loss: 0.519602; batch adversarial loss: 0.553708\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529897; batch adversarial loss: 0.553209\n",
      "epoch 33; iter: 0; batch classifier loss: 0.399155; batch adversarial loss: 0.614963\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509837; batch adversarial loss: 0.580094\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453248; batch adversarial loss: 0.553910\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468203; batch adversarial loss: 0.616735\n",
      "epoch 37; iter: 0; batch classifier loss: 0.574390; batch adversarial loss: 0.624380\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424990; batch adversarial loss: 0.571068\n",
      "epoch 39; iter: 0; batch classifier loss: 0.507357; batch adversarial loss: 0.517060\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440882; batch adversarial loss: 0.599188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.427402; batch adversarial loss: 0.571048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452810; batch adversarial loss: 0.598580\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453054; batch adversarial loss: 0.526630\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421600; batch adversarial loss: 0.498543\n",
      "epoch 45; iter: 0; batch classifier loss: 0.503750; batch adversarial loss: 0.625910\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505672; batch adversarial loss: 0.571994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461222; batch adversarial loss: 0.481408\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401358; batch adversarial loss: 0.463585\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432083; batch adversarial loss: 0.526514\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402274; batch adversarial loss: 0.535447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482240; batch adversarial loss: 0.526294\n",
      "epoch 52; iter: 0; batch classifier loss: 0.473958; batch adversarial loss: 0.607762\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441180; batch adversarial loss: 0.526876\n",
      "epoch 54; iter: 0; batch classifier loss: 0.391023; batch adversarial loss: 0.481354\n",
      "epoch 55; iter: 0; batch classifier loss: 0.383927; batch adversarial loss: 0.517275\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415038; batch adversarial loss: 0.580676\n",
      "epoch 57; iter: 0; batch classifier loss: 0.356374; batch adversarial loss: 0.535438\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389799; batch adversarial loss: 0.562526\n",
      "epoch 59; iter: 0; batch classifier loss: 0.524072; batch adversarial loss: 0.535558\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444780; batch adversarial loss: 0.625854\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444967; batch adversarial loss: 0.598067\n",
      "epoch 62; iter: 0; batch classifier loss: 0.359281; batch adversarial loss: 0.553575\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403854; batch adversarial loss: 0.498992\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375037; batch adversarial loss: 0.546297\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433822; batch adversarial loss: 0.499361\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415599; batch adversarial loss: 0.555059\n",
      "epoch 67; iter: 0; batch classifier loss: 0.454039; batch adversarial loss: 0.600149\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425550; batch adversarial loss: 0.562742\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438863; batch adversarial loss: 0.525499\n",
      "epoch 70; iter: 0; batch classifier loss: 0.519764; batch adversarial loss: 0.498084\n",
      "epoch 71; iter: 0; batch classifier loss: 0.496376; batch adversarial loss: 0.617738\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409248; batch adversarial loss: 0.581175\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426389; batch adversarial loss: 0.535260\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443562; batch adversarial loss: 0.471741\n",
      "epoch 75; iter: 0; batch classifier loss: 0.419716; batch adversarial loss: 0.535649\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443231; batch adversarial loss: 0.436312\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360025; batch adversarial loss: 0.553716\n",
      "epoch 78; iter: 0; batch classifier loss: 0.469304; batch adversarial loss: 0.525131\n",
      "epoch 79; iter: 0; batch classifier loss: 0.450212; batch adversarial loss: 0.526762\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422919; batch adversarial loss: 0.545278\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437335; batch adversarial loss: 0.491634\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440608; batch adversarial loss: 0.634843\n",
      "epoch 83; iter: 0; batch classifier loss: 0.379866; batch adversarial loss: 0.553361\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348599; batch adversarial loss: 0.498454\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398220; batch adversarial loss: 0.607693\n",
      "epoch 86; iter: 0; batch classifier loss: 0.496459; batch adversarial loss: 0.562640\n",
      "epoch 87; iter: 0; batch classifier loss: 0.424438; batch adversarial loss: 0.524704\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348931; batch adversarial loss: 0.537979\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385946; batch adversarial loss: 0.526521\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395333; batch adversarial loss: 0.480955\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377755; batch adversarial loss: 0.598870\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340129; batch adversarial loss: 0.554185\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439133; batch adversarial loss: 0.544226\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392220; batch adversarial loss: 0.488876\n",
      "epoch 95; iter: 0; batch classifier loss: 0.385511; batch adversarial loss: 0.562980\n",
      "epoch 96; iter: 0; batch classifier loss: 0.462073; batch adversarial loss: 0.553813\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402763; batch adversarial loss: 0.544526\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372305; batch adversarial loss: 0.526269\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393017; batch adversarial loss: 0.526198\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413851; batch adversarial loss: 0.517803\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396109; batch adversarial loss: 0.581079\n",
      "epoch 102; iter: 0; batch classifier loss: 0.474814; batch adversarial loss: 0.553652\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385879; batch adversarial loss: 0.471281\n",
      "epoch 104; iter: 0; batch classifier loss: 0.442287; batch adversarial loss: 0.489939\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372902; batch adversarial loss: 0.571917\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373547; batch adversarial loss: 0.526482\n",
      "epoch 107; iter: 0; batch classifier loss: 0.418207; batch adversarial loss: 0.644438\n",
      "epoch 108; iter: 0; batch classifier loss: 0.410471; batch adversarial loss: 0.526308\n",
      "epoch 109; iter: 0; batch classifier loss: 0.312224; batch adversarial loss: 0.535275\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356410; batch adversarial loss: 0.635400\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409089; batch adversarial loss: 0.526612\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361244; batch adversarial loss: 0.617727\n",
      "epoch 113; iter: 0; batch classifier loss: 0.471171; batch adversarial loss: 0.553383\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381865; batch adversarial loss: 0.480620\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362604; batch adversarial loss: 0.518119\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423325; batch adversarial loss: 0.563049\n",
      "epoch 117; iter: 0; batch classifier loss: 0.313865; batch adversarial loss: 0.499454\n",
      "epoch 118; iter: 0; batch classifier loss: 0.299965; batch adversarial loss: 0.517427\n",
      "epoch 119; iter: 0; batch classifier loss: 0.444097; batch adversarial loss: 0.572255\n",
      "epoch 120; iter: 0; batch classifier loss: 0.345183; batch adversarial loss: 0.517437\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394804; batch adversarial loss: 0.598377\n",
      "epoch 122; iter: 0; batch classifier loss: 0.337819; batch adversarial loss: 0.561992\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403464; batch adversarial loss: 0.525894\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390290; batch adversarial loss: 0.499235\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408195; batch adversarial loss: 0.626144\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323685; batch adversarial loss: 0.626189\n",
      "epoch 127; iter: 0; batch classifier loss: 0.325060; batch adversarial loss: 0.553795\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308118; batch adversarial loss: 0.562467\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350286; batch adversarial loss: 0.471563\n",
      "epoch 130; iter: 0; batch classifier loss: 0.465227; batch adversarial loss: 0.599273\n",
      "epoch 131; iter: 0; batch classifier loss: 0.443231; batch adversarial loss: 0.499104\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388830; batch adversarial loss: 0.489990\n",
      "epoch 133; iter: 0; batch classifier loss: 0.318155; batch adversarial loss: 0.563262\n",
      "epoch 134; iter: 0; batch classifier loss: 0.454609; batch adversarial loss: 0.562578\n",
      "epoch 135; iter: 0; batch classifier loss: 0.449451; batch adversarial loss: 0.526688\n",
      "epoch 136; iter: 0; batch classifier loss: 0.419145; batch adversarial loss: 0.562330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.408339; batch adversarial loss: 0.599221\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350114; batch adversarial loss: 0.553543\n",
      "epoch 139; iter: 0; batch classifier loss: 0.420479; batch adversarial loss: 0.535433\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373634; batch adversarial loss: 0.544760\n",
      "epoch 141; iter: 0; batch classifier loss: 0.392381; batch adversarial loss: 0.489425\n",
      "epoch 142; iter: 0; batch classifier loss: 0.385642; batch adversarial loss: 0.462712\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349421; batch adversarial loss: 0.471673\n",
      "epoch 144; iter: 0; batch classifier loss: 0.378523; batch adversarial loss: 0.526378\n",
      "epoch 145; iter: 0; batch classifier loss: 0.476711; batch adversarial loss: 0.499577\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361109; batch adversarial loss: 0.580600\n",
      "epoch 147; iter: 0; batch classifier loss: 0.458074; batch adversarial loss: 0.454092\n",
      "epoch 148; iter: 0; batch classifier loss: 0.348933; batch adversarial loss: 0.554271\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338970; batch adversarial loss: 0.544281\n",
      "epoch 150; iter: 0; batch classifier loss: 0.366690; batch adversarial loss: 0.481340\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382841; batch adversarial loss: 0.635704\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354309; batch adversarial loss: 0.526792\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380379; batch adversarial loss: 0.561462\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350257; batch adversarial loss: 0.499506\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317835; batch adversarial loss: 0.572438\n",
      "epoch 156; iter: 0; batch classifier loss: 0.423416; batch adversarial loss: 0.507870\n",
      "epoch 157; iter: 0; batch classifier loss: 0.407160; batch adversarial loss: 0.545165\n",
      "epoch 158; iter: 0; batch classifier loss: 0.385910; batch adversarial loss: 0.562141\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350566; batch adversarial loss: 0.553817\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368669; batch adversarial loss: 0.525967\n",
      "epoch 161; iter: 0; batch classifier loss: 0.404692; batch adversarial loss: 0.645719\n",
      "epoch 162; iter: 0; batch classifier loss: 0.438977; batch adversarial loss: 0.544459\n",
      "epoch 163; iter: 0; batch classifier loss: 0.438628; batch adversarial loss: 0.544480\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377690; batch adversarial loss: 0.571934\n",
      "epoch 165; iter: 0; batch classifier loss: 0.463737; batch adversarial loss: 0.580552\n",
      "epoch 166; iter: 0; batch classifier loss: 0.363902; batch adversarial loss: 0.680839\n",
      "epoch 167; iter: 0; batch classifier loss: 0.430532; batch adversarial loss: 0.553420\n",
      "epoch 168; iter: 0; batch classifier loss: 0.384826; batch adversarial loss: 0.545693\n",
      "epoch 169; iter: 0; batch classifier loss: 0.456899; batch adversarial loss: 0.544639\n",
      "epoch 170; iter: 0; batch classifier loss: 0.411079; batch adversarial loss: 0.553144\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374342; batch adversarial loss: 0.471493\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378553; batch adversarial loss: 0.562318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.366526; batch adversarial loss: 0.543935\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392370; batch adversarial loss: 0.526590\n",
      "epoch 175; iter: 0; batch classifier loss: 0.283885; batch adversarial loss: 0.498641\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388029; batch adversarial loss: 0.535361\n",
      "epoch 177; iter: 0; batch classifier loss: 0.278952; batch adversarial loss: 0.635071\n",
      "epoch 178; iter: 0; batch classifier loss: 0.373030; batch adversarial loss: 0.571787\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389988; batch adversarial loss: 0.572002\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356050; batch adversarial loss: 0.499297\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347076; batch adversarial loss: 0.507711\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351014; batch adversarial loss: 0.499615\n",
      "epoch 183; iter: 0; batch classifier loss: 0.368098; batch adversarial loss: 0.489137\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339739; batch adversarial loss: 0.563330\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328421; batch adversarial loss: 0.544236\n",
      "epoch 186; iter: 0; batch classifier loss: 0.291064; batch adversarial loss: 0.545718\n",
      "epoch 187; iter: 0; batch classifier loss: 0.337676; batch adversarial loss: 0.581332\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358748; batch adversarial loss: 0.563481\n",
      "epoch 189; iter: 0; batch classifier loss: 0.319906; batch adversarial loss: 0.498704\n",
      "epoch 190; iter: 0; batch classifier loss: 0.460638; batch adversarial loss: 0.526339\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360891; batch adversarial loss: 0.581112\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364586; batch adversarial loss: 0.563400\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392666; batch adversarial loss: 0.526413\n",
      "epoch 194; iter: 0; batch classifier loss: 0.300492; batch adversarial loss: 0.580045\n",
      "epoch 195; iter: 0; batch classifier loss: 0.396243; batch adversarial loss: 0.543952\n",
      "epoch 196; iter: 0; batch classifier loss: 0.282323; batch adversarial loss: 0.499397\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352163; batch adversarial loss: 0.536133\n",
      "epoch 198; iter: 0; batch classifier loss: 0.439293; batch adversarial loss: 0.608088\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316776; batch adversarial loss: 0.581558\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668164; batch adversarial loss: 0.774534\n",
      "epoch 1; iter: 0; batch classifier loss: 0.793246; batch adversarial loss: 0.881381\n",
      "epoch 2; iter: 0; batch classifier loss: 0.820469; batch adversarial loss: 0.827199\n",
      "epoch 3; iter: 0; batch classifier loss: 0.858780; batch adversarial loss: 0.767171\n",
      "epoch 4; iter: 0; batch classifier loss: 0.695906; batch adversarial loss: 0.683000\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597940; batch adversarial loss: 0.640597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580138; batch adversarial loss: 0.625723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575079; batch adversarial loss: 0.610702\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541437; batch adversarial loss: 0.613688\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591558; batch adversarial loss: 0.587823\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559567; batch adversarial loss: 0.581711\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502144; batch adversarial loss: 0.619592\n",
      "epoch 12; iter: 0; batch classifier loss: 0.493127; batch adversarial loss: 0.596608\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499824; batch adversarial loss: 0.589772\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516751; batch adversarial loss: 0.570648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505354; batch adversarial loss: 0.572157\n",
      "epoch 16; iter: 0; batch classifier loss: 0.474777; batch adversarial loss: 0.636079\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491434; batch adversarial loss: 0.588223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478884; batch adversarial loss: 0.570964\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511539; batch adversarial loss: 0.516168\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474675; batch adversarial loss: 0.552140\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481865; batch adversarial loss: 0.586246\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530146; batch adversarial loss: 0.626773\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454125; batch adversarial loss: 0.495252\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445909; batch adversarial loss: 0.593052\n",
      "epoch 25; iter: 0; batch classifier loss: 0.534043; batch adversarial loss: 0.582828\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522839; batch adversarial loss: 0.569390\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495059; batch adversarial loss: 0.524719\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469983; batch adversarial loss: 0.555783\n",
      "epoch 29; iter: 0; batch classifier loss: 0.540577; batch adversarial loss: 0.635330\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517390; batch adversarial loss: 0.519455\n",
      "epoch 31; iter: 0; batch classifier loss: 0.478701; batch adversarial loss: 0.639113\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478973; batch adversarial loss: 0.532785\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460158; batch adversarial loss: 0.538396\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438634; batch adversarial loss: 0.501006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.389789; batch adversarial loss: 0.677892\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515257; batch adversarial loss: 0.491755\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470650; batch adversarial loss: 0.578825\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432030; batch adversarial loss: 0.554756\n",
      "epoch 39; iter: 0; batch classifier loss: 0.547574; batch adversarial loss: 0.579468\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450270; batch adversarial loss: 0.502290\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440846; batch adversarial loss: 0.495630\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443817; batch adversarial loss: 0.520645\n",
      "epoch 43; iter: 0; batch classifier loss: 0.343456; batch adversarial loss: 0.494107\n",
      "epoch 44; iter: 0; batch classifier loss: 0.355953; batch adversarial loss: 0.564070\n",
      "epoch 45; iter: 0; batch classifier loss: 0.462032; batch adversarial loss: 0.605464\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459817; batch adversarial loss: 0.474779\n",
      "epoch 47; iter: 0; batch classifier loss: 0.489644; batch adversarial loss: 0.555018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461354; batch adversarial loss: 0.601080\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405881; batch adversarial loss: 0.533872\n",
      "epoch 50; iter: 0; batch classifier loss: 0.584976; batch adversarial loss: 0.554310\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418115; batch adversarial loss: 0.615797\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437500; batch adversarial loss: 0.571775\n",
      "epoch 53; iter: 0; batch classifier loss: 0.337007; batch adversarial loss: 0.510651\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394620; batch adversarial loss: 0.553603\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416096; batch adversarial loss: 0.597829\n",
      "epoch 56; iter: 0; batch classifier loss: 0.374688; batch adversarial loss: 0.491057\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401393; batch adversarial loss: 0.535236\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463706; batch adversarial loss: 0.536457\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382267; batch adversarial loss: 0.535519\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388955; batch adversarial loss: 0.589640\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395716; batch adversarial loss: 0.570821\n",
      "epoch 62; iter: 0; batch classifier loss: 0.418856; batch adversarial loss: 0.571322\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371996; batch adversarial loss: 0.536001\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390624; batch adversarial loss: 0.607851\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365714; batch adversarial loss: 0.517653\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431948; batch adversarial loss: 0.580504\n",
      "epoch 67; iter: 0; batch classifier loss: 0.373010; batch adversarial loss: 0.508555\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377893; batch adversarial loss: 0.670206\n",
      "epoch 69; iter: 0; batch classifier loss: 0.336577; batch adversarial loss: 0.553654\n",
      "epoch 70; iter: 0; batch classifier loss: 0.334721; batch adversarial loss: 0.544531\n",
      "epoch 71; iter: 0; batch classifier loss: 0.304806; batch adversarial loss: 0.499790\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382409; batch adversarial loss: 0.536050\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394823; batch adversarial loss: 0.589832\n",
      "epoch 74; iter: 0; batch classifier loss: 0.333128; batch adversarial loss: 0.535088\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429509; batch adversarial loss: 0.570572\n",
      "epoch 76; iter: 0; batch classifier loss: 0.451426; batch adversarial loss: 0.562882\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338885; batch adversarial loss: 0.490273\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386559; batch adversarial loss: 0.509569\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415645; batch adversarial loss: 0.643348\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385840; batch adversarial loss: 0.518335\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408841; batch adversarial loss: 0.597463\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388912; batch adversarial loss: 0.545215\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391524; batch adversarial loss: 0.570827\n",
      "epoch 84; iter: 0; batch classifier loss: 0.387161; batch adversarial loss: 0.518063\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433743; batch adversarial loss: 0.572476\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379689; batch adversarial loss: 0.562922\n",
      "epoch 87; iter: 0; batch classifier loss: 0.351261; batch adversarial loss: 0.526237\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374314; batch adversarial loss: 0.633727\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403348; batch adversarial loss: 0.562238\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424859; batch adversarial loss: 0.535437\n",
      "epoch 91; iter: 0; batch classifier loss: 0.285115; batch adversarial loss: 0.560769\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420513; batch adversarial loss: 0.553862\n",
      "epoch 93; iter: 0; batch classifier loss: 0.321179; batch adversarial loss: 0.546226\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345561; batch adversarial loss: 0.588808\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333328; batch adversarial loss: 0.660579\n",
      "epoch 96; iter: 0; batch classifier loss: 0.454408; batch adversarial loss: 0.510102\n",
      "epoch 97; iter: 0; batch classifier loss: 0.340737; batch adversarial loss: 0.589101\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393304; batch adversarial loss: 0.499500\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360764; batch adversarial loss: 0.562529\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387627; batch adversarial loss: 0.597938\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382553; batch adversarial loss: 0.527515\n",
      "epoch 102; iter: 0; batch classifier loss: 0.378010; batch adversarial loss: 0.563326\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414172; batch adversarial loss: 0.508459\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363507; batch adversarial loss: 0.520292\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408357; batch adversarial loss: 0.562927\n",
      "epoch 106; iter: 0; batch classifier loss: 0.320770; batch adversarial loss: 0.508204\n",
      "epoch 107; iter: 0; batch classifier loss: 0.336695; batch adversarial loss: 0.579023\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362218; batch adversarial loss: 0.553253\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407180; batch adversarial loss: 0.563199\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367522; batch adversarial loss: 0.570336\n",
      "epoch 111; iter: 0; batch classifier loss: 0.419173; batch adversarial loss: 0.564733\n",
      "epoch 112; iter: 0; batch classifier loss: 0.302568; batch adversarial loss: 0.535647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383815; batch adversarial loss: 0.623596\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364880; batch adversarial loss: 0.597494\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339946; batch adversarial loss: 0.626014\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373658; batch adversarial loss: 0.616529\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314251; batch adversarial loss: 0.615075\n",
      "epoch 118; iter: 0; batch classifier loss: 0.422043; batch adversarial loss: 0.500680\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387024; batch adversarial loss: 0.538237\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348592; batch adversarial loss: 0.626838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391375; batch adversarial loss: 0.517888\n",
      "epoch 122; iter: 0; batch classifier loss: 0.337466; batch adversarial loss: 0.580083\n",
      "epoch 123; iter: 0; batch classifier loss: 0.487074; batch adversarial loss: 0.500477\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371923; batch adversarial loss: 0.602205\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403834; batch adversarial loss: 0.579107\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380749; batch adversarial loss: 0.562358\n",
      "epoch 127; iter: 0; batch classifier loss: 0.351055; batch adversarial loss: 0.527762\n",
      "epoch 128; iter: 0; batch classifier loss: 0.280448; batch adversarial loss: 0.537621\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388605; batch adversarial loss: 0.625587\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408659; batch adversarial loss: 0.587343\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371768; batch adversarial loss: 0.622083\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389324; batch adversarial loss: 0.508750\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364245; batch adversarial loss: 0.536729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.348495; batch adversarial loss: 0.490086\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388023; batch adversarial loss: 0.506240\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326208; batch adversarial loss: 0.591783\n",
      "epoch 137; iter: 0; batch classifier loss: 0.373555; batch adversarial loss: 0.535504\n",
      "epoch 138; iter: 0; batch classifier loss: 0.308735; batch adversarial loss: 0.617237\n",
      "epoch 139; iter: 0; batch classifier loss: 0.471727; batch adversarial loss: 0.562469\n",
      "epoch 140; iter: 0; batch classifier loss: 0.304569; batch adversarial loss: 0.643673\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337692; batch adversarial loss: 0.596896\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367154; batch adversarial loss: 0.625524\n",
      "epoch 143; iter: 0; batch classifier loss: 0.357151; batch adversarial loss: 0.467270\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349663; batch adversarial loss: 0.570146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385381; batch adversarial loss: 0.648974\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327949; batch adversarial loss: 0.575737\n",
      "epoch 147; iter: 0; batch classifier loss: 0.301184; batch adversarial loss: 0.587439\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336108; batch adversarial loss: 0.579335\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370589; batch adversarial loss: 0.626557\n",
      "epoch 150; iter: 0; batch classifier loss: 0.309354; batch adversarial loss: 0.573141\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310447; batch adversarial loss: 0.555867\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362519; batch adversarial loss: 0.533787\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349258; batch adversarial loss: 0.523710\n",
      "epoch 154; iter: 0; batch classifier loss: 0.292865; batch adversarial loss: 0.469280\n",
      "epoch 155; iter: 0; batch classifier loss: 0.295736; batch adversarial loss: 0.619610\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362782; batch adversarial loss: 0.570189\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367881; batch adversarial loss: 0.632232\n",
      "epoch 158; iter: 0; batch classifier loss: 0.416854; batch adversarial loss: 0.511941\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352952; batch adversarial loss: 0.555974\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319444; batch adversarial loss: 0.500274\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358155; batch adversarial loss: 0.487730\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392356; batch adversarial loss: 0.544752\n",
      "epoch 163; iter: 0; batch classifier loss: 0.312885; batch adversarial loss: 0.544189\n",
      "epoch 164; iter: 0; batch classifier loss: 0.295584; batch adversarial loss: 0.519397\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318201; batch adversarial loss: 0.562792\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373252; batch adversarial loss: 0.552327\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382304; batch adversarial loss: 0.498468\n",
      "epoch 168; iter: 0; batch classifier loss: 0.399489; batch adversarial loss: 0.499226\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407350; batch adversarial loss: 0.644170\n",
      "epoch 170; iter: 0; batch classifier loss: 0.310368; batch adversarial loss: 0.597529\n",
      "epoch 171; iter: 0; batch classifier loss: 0.324103; batch adversarial loss: 0.580157\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328875; batch adversarial loss: 0.526507\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356301; batch adversarial loss: 0.572321\n",
      "epoch 174; iter: 0; batch classifier loss: 0.314387; batch adversarial loss: 0.581206\n",
      "epoch 175; iter: 0; batch classifier loss: 0.367821; batch adversarial loss: 0.550098\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364895; batch adversarial loss: 0.581838\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386803; batch adversarial loss: 0.589060\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340265; batch adversarial loss: 0.562089\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318659; batch adversarial loss: 0.546143\n",
      "epoch 180; iter: 0; batch classifier loss: 0.398190; batch adversarial loss: 0.510037\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383154; batch adversarial loss: 0.545390\n",
      "epoch 182; iter: 0; batch classifier loss: 0.308498; batch adversarial loss: 0.554444\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342773; batch adversarial loss: 0.537768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.303945; batch adversarial loss: 0.598910\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361118; batch adversarial loss: 0.581296\n",
      "epoch 186; iter: 0; batch classifier loss: 0.270432; batch adversarial loss: 0.617267\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364862; batch adversarial loss: 0.490286\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338642; batch adversarial loss: 0.571211\n",
      "epoch 189; iter: 0; batch classifier loss: 0.421270; batch adversarial loss: 0.563467\n",
      "epoch 190; iter: 0; batch classifier loss: 0.417954; batch adversarial loss: 0.506966\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370184; batch adversarial loss: 0.509214\n",
      "epoch 192; iter: 0; batch classifier loss: 0.321024; batch adversarial loss: 0.534195\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327268; batch adversarial loss: 0.544306\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379356; batch adversarial loss: 0.544976\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341713; batch adversarial loss: 0.561493\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305240; batch adversarial loss: 0.616050\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372968; batch adversarial loss: 0.526633\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347084; batch adversarial loss: 0.543790\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351057; batch adversarial loss: 0.498455\n",
      "epoch 0; iter: 0; batch classifier loss: 0.836744; batch adversarial loss: 0.758937\n",
      "epoch 1; iter: 0; batch classifier loss: 0.547493; batch adversarial loss: 0.675138\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571627; batch adversarial loss: 0.658284\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578882; batch adversarial loss: 0.685668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559067; batch adversarial loss: 0.615854\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555337; batch adversarial loss: 0.577240\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567082; batch adversarial loss: 0.571372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598277; batch adversarial loss: 0.594706\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466408; batch adversarial loss: 0.595689\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627615; batch adversarial loss: 0.574686\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519197; batch adversarial loss: 0.562458\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555049; batch adversarial loss: 0.620230\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542997; batch adversarial loss: 0.560150\n",
      "epoch 13; iter: 0; batch classifier loss: 0.588714; batch adversarial loss: 0.518770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.590370; batch adversarial loss: 0.545864\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510421; batch adversarial loss: 0.514663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491443; batch adversarial loss: 0.510370\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527289; batch adversarial loss: 0.589686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485669; batch adversarial loss: 0.554464\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537351; batch adversarial loss: 0.508253\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518510; batch adversarial loss: 0.497361\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455344; batch adversarial loss: 0.557773\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490822; batch adversarial loss: 0.529552\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445851; batch adversarial loss: 0.609086\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475897; batch adversarial loss: 0.549640\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480179; batch adversarial loss: 0.539498\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473017; batch adversarial loss: 0.473162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.547016; batch adversarial loss: 0.594326\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482789; batch adversarial loss: 0.559959\n",
      "epoch 29; iter: 0; batch classifier loss: 0.368711; batch adversarial loss: 0.573780\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479118; batch adversarial loss: 0.513951\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410360; batch adversarial loss: 0.600263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.570648; batch adversarial loss: 0.550152\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487725; batch adversarial loss: 0.545714\n",
      "epoch 34; iter: 0; batch classifier loss: 0.516768; batch adversarial loss: 0.534678\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496186; batch adversarial loss: 0.554634\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446330; batch adversarial loss: 0.543445\n",
      "epoch 37; iter: 0; batch classifier loss: 0.558902; batch adversarial loss: 0.605361\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415612; batch adversarial loss: 0.485531\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488668; batch adversarial loss: 0.483092\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457229; batch adversarial loss: 0.483152\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493120; batch adversarial loss: 0.554897\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440150; batch adversarial loss: 0.638094\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456389; batch adversarial loss: 0.485180\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464527; batch adversarial loss: 0.599668\n",
      "epoch 45; iter: 0; batch classifier loss: 0.521375; batch adversarial loss: 0.508889\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409880; batch adversarial loss: 0.589179\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468325; batch adversarial loss: 0.580634\n",
      "epoch 48; iter: 0; batch classifier loss: 0.350115; batch adversarial loss: 0.497817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411366; batch adversarial loss: 0.589685\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408193; batch adversarial loss: 0.462575\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469243; batch adversarial loss: 0.473521\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442968; batch adversarial loss: 0.564374\n",
      "epoch 53; iter: 0; batch classifier loss: 0.533369; batch adversarial loss: 0.497749\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423583; batch adversarial loss: 0.501341\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445437; batch adversarial loss: 0.499649\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422513; batch adversarial loss: 0.572518\n",
      "epoch 57; iter: 0; batch classifier loss: 0.380652; batch adversarial loss: 0.572801\n",
      "epoch 58; iter: 0; batch classifier loss: 0.490025; batch adversarial loss: 0.535428\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387838; batch adversarial loss: 0.526553\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418540; batch adversarial loss: 0.561423\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449112; batch adversarial loss: 0.606841\n",
      "epoch 62; iter: 0; batch classifier loss: 0.344233; batch adversarial loss: 0.534253\n",
      "epoch 63; iter: 0; batch classifier loss: 0.494962; batch adversarial loss: 0.552629\n",
      "epoch 64; iter: 0; batch classifier loss: 0.373786; batch adversarial loss: 0.544223\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467348; batch adversarial loss: 0.589911\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392853; batch adversarial loss: 0.525086\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392992; batch adversarial loss: 0.592924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.436524; batch adversarial loss: 0.533635\n",
      "epoch 69; iter: 0; batch classifier loss: 0.380699; batch adversarial loss: 0.590970\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445866; batch adversarial loss: 0.510411\n",
      "epoch 71; iter: 0; batch classifier loss: 0.327417; batch adversarial loss: 0.600029\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438249; batch adversarial loss: 0.478105\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411319; batch adversarial loss: 0.537149\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426681; batch adversarial loss: 0.590821\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362541; batch adversarial loss: 0.608510\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347437; batch adversarial loss: 0.571942\n",
      "epoch 77; iter: 0; batch classifier loss: 0.365157; batch adversarial loss: 0.517722\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458354; batch adversarial loss: 0.535345\n",
      "epoch 79; iter: 0; batch classifier loss: 0.443609; batch adversarial loss: 0.526412\n",
      "epoch 80; iter: 0; batch classifier loss: 0.415072; batch adversarial loss: 0.480550\n",
      "epoch 81; iter: 0; batch classifier loss: 0.456245; batch adversarial loss: 0.516173\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396625; batch adversarial loss: 0.581053\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421804; batch adversarial loss: 0.562823\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370016; batch adversarial loss: 0.507417\n",
      "epoch 85; iter: 0; batch classifier loss: 0.473987; batch adversarial loss: 0.526600\n",
      "epoch 86; iter: 0; batch classifier loss: 0.388130; batch adversarial loss: 0.553322\n",
      "epoch 87; iter: 0; batch classifier loss: 0.449238; batch adversarial loss: 0.516956\n",
      "epoch 88; iter: 0; batch classifier loss: 0.347992; batch adversarial loss: 0.563532\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427452; batch adversarial loss: 0.553352\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377575; batch adversarial loss: 0.516728\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402314; batch adversarial loss: 0.479914\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382039; batch adversarial loss: 0.563084\n",
      "epoch 93; iter: 0; batch classifier loss: 0.454823; batch adversarial loss: 0.508430\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379975; batch adversarial loss: 0.599756\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365475; batch adversarial loss: 0.553580\n",
      "epoch 96; iter: 0; batch classifier loss: 0.474891; batch adversarial loss: 0.581218\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405741; batch adversarial loss: 0.516055\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399079; batch adversarial loss: 0.505002\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395445; batch adversarial loss: 0.457790\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427768; batch adversarial loss: 0.588504\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417618; batch adversarial loss: 0.596585\n",
      "epoch 102; iter: 0; batch classifier loss: 0.296579; batch adversarial loss: 0.552797\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365758; batch adversarial loss: 0.553207\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413916; batch adversarial loss: 0.473839\n",
      "epoch 105; iter: 0; batch classifier loss: 0.435184; batch adversarial loss: 0.467337\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397616; batch adversarial loss: 0.488658\n",
      "epoch 107; iter: 0; batch classifier loss: 0.390351; batch adversarial loss: 0.559518\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378041; batch adversarial loss: 0.594125\n",
      "epoch 109; iter: 0; batch classifier loss: 0.442653; batch adversarial loss: 0.556851\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409895; batch adversarial loss: 0.573041\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386183; batch adversarial loss: 0.500582\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378853; batch adversarial loss: 0.490472\n",
      "epoch 113; iter: 0; batch classifier loss: 0.423301; batch adversarial loss: 0.599485\n",
      "epoch 114; iter: 0; batch classifier loss: 0.443953; batch adversarial loss: 0.573519\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418880; batch adversarial loss: 0.574900\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380053; batch adversarial loss: 0.438316\n",
      "epoch 117; iter: 0; batch classifier loss: 0.450201; batch adversarial loss: 0.481862\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406211; batch adversarial loss: 0.544660\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415110; batch adversarial loss: 0.525949\n",
      "epoch 120; iter: 0; batch classifier loss: 0.342798; batch adversarial loss: 0.562575\n",
      "epoch 121; iter: 0; batch classifier loss: 0.424982; batch adversarial loss: 0.562762\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377538; batch adversarial loss: 0.617937\n",
      "epoch 123; iter: 0; batch classifier loss: 0.432895; batch adversarial loss: 0.682181\n",
      "epoch 124; iter: 0; batch classifier loss: 0.305019; batch adversarial loss: 0.534403\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367951; batch adversarial loss: 0.572054\n",
      "epoch 126; iter: 0; batch classifier loss: 0.267261; batch adversarial loss: 0.580938\n",
      "epoch 127; iter: 0; batch classifier loss: 0.480461; batch adversarial loss: 0.516351\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379779; batch adversarial loss: 0.516986\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403280; batch adversarial loss: 0.535058\n",
      "epoch 130; iter: 0; batch classifier loss: 0.457215; batch adversarial loss: 0.479628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.373435; batch adversarial loss: 0.498409\n",
      "epoch 132; iter: 0; batch classifier loss: 0.420417; batch adversarial loss: 0.554316\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376222; batch adversarial loss: 0.525691\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351897; batch adversarial loss: 0.580795\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377842; batch adversarial loss: 0.508202\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383958; batch adversarial loss: 0.544929\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389608; batch adversarial loss: 0.580711\n",
      "epoch 138; iter: 0; batch classifier loss: 0.395688; batch adversarial loss: 0.497622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401077; batch adversarial loss: 0.573235\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340511; batch adversarial loss: 0.525113\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387580; batch adversarial loss: 0.573293\n",
      "epoch 142; iter: 0; batch classifier loss: 0.433875; batch adversarial loss: 0.553983\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369781; batch adversarial loss: 0.534247\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409858; batch adversarial loss: 0.517436\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374047; batch adversarial loss: 0.535723\n",
      "epoch 146; iter: 0; batch classifier loss: 0.312279; batch adversarial loss: 0.573401\n",
      "epoch 147; iter: 0; batch classifier loss: 0.283362; batch adversarial loss: 0.571217\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357323; batch adversarial loss: 0.571957\n",
      "epoch 149; iter: 0; batch classifier loss: 0.411625; batch adversarial loss: 0.506559\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326644; batch adversarial loss: 0.563069\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363733; batch adversarial loss: 0.571423\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390872; batch adversarial loss: 0.504987\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351947; batch adversarial loss: 0.582151\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317451; batch adversarial loss: 0.507929\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327074; batch adversarial loss: 0.544232\n",
      "epoch 156; iter: 0; batch classifier loss: 0.467846; batch adversarial loss: 0.524943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312201; batch adversarial loss: 0.518848\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315417; batch adversarial loss: 0.534971\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370411; batch adversarial loss: 0.526438\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360192; batch adversarial loss: 0.574877\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318262; batch adversarial loss: 0.579893\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372284; batch adversarial loss: 0.571853\n",
      "epoch 163; iter: 0; batch classifier loss: 0.472701; batch adversarial loss: 0.564379\n",
      "epoch 164; iter: 0; batch classifier loss: 0.417179; batch adversarial loss: 0.544181\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366884; batch adversarial loss: 0.515629\n",
      "epoch 166; iter: 0; batch classifier loss: 0.442151; batch adversarial loss: 0.535778\n",
      "epoch 167; iter: 0; batch classifier loss: 0.351372; batch adversarial loss: 0.481080\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332836; batch adversarial loss: 0.580934\n",
      "epoch 169; iter: 0; batch classifier loss: 0.389352; batch adversarial loss: 0.519424\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351580; batch adversarial loss: 0.453654\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330534; batch adversarial loss: 0.563524\n",
      "epoch 172; iter: 0; batch classifier loss: 0.468351; batch adversarial loss: 0.527199\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355786; batch adversarial loss: 0.545267\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364223; batch adversarial loss: 0.625957\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314834; batch adversarial loss: 0.525674\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382476; batch adversarial loss: 0.490530\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378535; batch adversarial loss: 0.508712\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364821; batch adversarial loss: 0.598670\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370311; batch adversarial loss: 0.472242\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363840; batch adversarial loss: 0.499092\n",
      "epoch 181; iter: 0; batch classifier loss: 0.446557; batch adversarial loss: 0.544792\n",
      "epoch 182; iter: 0; batch classifier loss: 0.386719; batch adversarial loss: 0.617376\n",
      "epoch 183; iter: 0; batch classifier loss: 0.455531; batch adversarial loss: 0.526125\n",
      "epoch 184; iter: 0; batch classifier loss: 0.475404; batch adversarial loss: 0.553559\n",
      "epoch 185; iter: 0; batch classifier loss: 0.235322; batch adversarial loss: 0.498766\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365687; batch adversarial loss: 0.627361\n",
      "epoch 187; iter: 0; batch classifier loss: 0.440783; batch adversarial loss: 0.488538\n",
      "epoch 188; iter: 0; batch classifier loss: 0.390343; batch adversarial loss: 0.545832\n",
      "epoch 189; iter: 0; batch classifier loss: 0.261553; batch adversarial loss: 0.552131\n",
      "epoch 190; iter: 0; batch classifier loss: 0.417254; batch adversarial loss: 0.587963\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353064; batch adversarial loss: 0.527198\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386634; batch adversarial loss: 0.551131\n",
      "epoch 193; iter: 0; batch classifier loss: 0.391331; batch adversarial loss: 0.500614\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385697; batch adversarial loss: 0.476382\n",
      "epoch 195; iter: 0; batch classifier loss: 0.412714; batch adversarial loss: 0.582949\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315612; batch adversarial loss: 0.573881\n",
      "epoch 197; iter: 0; batch classifier loss: 0.433394; batch adversarial loss: 0.527540\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347832; batch adversarial loss: 0.592999\n",
      "epoch 199; iter: 0; batch classifier loss: 0.313560; batch adversarial loss: 0.554053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698606; batch adversarial loss: 0.755348\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613722; batch adversarial loss: 0.711345\n",
      "epoch 2; iter: 0; batch classifier loss: 0.673827; batch adversarial loss: 0.671743\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565536; batch adversarial loss: 0.655475\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575529; batch adversarial loss: 0.642955\n",
      "epoch 5; iter: 0; batch classifier loss: 0.504492; batch adversarial loss: 0.604983\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528168; batch adversarial loss: 0.602112\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611817; batch adversarial loss: 0.595645\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533769; batch adversarial loss: 0.573373\n",
      "epoch 9; iter: 0; batch classifier loss: 0.491978; batch adversarial loss: 0.653726\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574205; batch adversarial loss: 0.575381\n",
      "epoch 11; iter: 0; batch classifier loss: 0.610225; batch adversarial loss: 0.605168\n",
      "epoch 12; iter: 0; batch classifier loss: 0.437647; batch adversarial loss: 0.588405\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528822; batch adversarial loss: 0.529946\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534039; batch adversarial loss: 0.557495\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497466; batch adversarial loss: 0.576283\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500056; batch adversarial loss: 0.583262\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467151; batch adversarial loss: 0.563036\n",
      "epoch 18; iter: 0; batch classifier loss: 0.537663; batch adversarial loss: 0.610735\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550360; batch adversarial loss: 0.593466\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463419; batch adversarial loss: 0.584039\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513444; batch adversarial loss: 0.542482\n",
      "epoch 22; iter: 0; batch classifier loss: 0.417008; batch adversarial loss: 0.558968\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529136; batch adversarial loss: 0.571727\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484266; batch adversarial loss: 0.630724\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420276; batch adversarial loss: 0.487547\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480256; batch adversarial loss: 0.619906\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473748; batch adversarial loss: 0.523788\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489267; batch adversarial loss: 0.513472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.427956; batch adversarial loss: 0.522741\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439366; batch adversarial loss: 0.529989\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446246; batch adversarial loss: 0.505106\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527102; batch adversarial loss: 0.579490\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434736; batch adversarial loss: 0.512574\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463923; batch adversarial loss: 0.544929\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473804; batch adversarial loss: 0.579453\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439214; batch adversarial loss: 0.605538\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423138; batch adversarial loss: 0.613416\n",
      "epoch 38; iter: 0; batch classifier loss: 0.365300; batch adversarial loss: 0.501023\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435636; batch adversarial loss: 0.474553\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447338; batch adversarial loss: 0.597501\n",
      "epoch 41; iter: 0; batch classifier loss: 0.399679; batch adversarial loss: 0.562757\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460013; batch adversarial loss: 0.508913\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377192; batch adversarial loss: 0.590195\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426454; batch adversarial loss: 0.553512\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405120; batch adversarial loss: 0.617528\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403424; batch adversarial loss: 0.480927\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461247; batch adversarial loss: 0.561180\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375937; batch adversarial loss: 0.599305\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464146; batch adversarial loss: 0.572194\n",
      "epoch 50; iter: 0; batch classifier loss: 0.467197; batch adversarial loss: 0.535230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.478723; batch adversarial loss: 0.500756\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430231; batch adversarial loss: 0.562290\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428602; batch adversarial loss: 0.616316\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385038; batch adversarial loss: 0.545023\n",
      "epoch 55; iter: 0; batch classifier loss: 0.504009; batch adversarial loss: 0.617256\n",
      "epoch 56; iter: 0; batch classifier loss: 0.381424; batch adversarial loss: 0.571404\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374915; batch adversarial loss: 0.645367\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409367; batch adversarial loss: 0.581963\n",
      "epoch 59; iter: 0; batch classifier loss: 0.351650; batch adversarial loss: 0.609554\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473053; batch adversarial loss: 0.479783\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412504; batch adversarial loss: 0.543086\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445677; batch adversarial loss: 0.572769\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.527829\n",
      "epoch 64; iter: 0; batch classifier loss: 0.342247; batch adversarial loss: 0.634375\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426003; batch adversarial loss: 0.471813\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396012; batch adversarial loss: 0.553077\n",
      "epoch 67; iter: 0; batch classifier loss: 0.482492; batch adversarial loss: 0.489213\n",
      "epoch 68; iter: 0; batch classifier loss: 0.461009; batch adversarial loss: 0.527028\n",
      "epoch 69; iter: 0; batch classifier loss: 0.381850; batch adversarial loss: 0.562092\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391113; batch adversarial loss: 0.506176\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394797; batch adversarial loss: 0.535375\n",
      "epoch 72; iter: 0; batch classifier loss: 0.446651; batch adversarial loss: 0.618063\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384771; batch adversarial loss: 0.607231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390993; batch adversarial loss: 0.569535\n",
      "epoch 75; iter: 0; batch classifier loss: 0.439113; batch adversarial loss: 0.599686\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400010; batch adversarial loss: 0.545276\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345297; batch adversarial loss: 0.580207\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399081; batch adversarial loss: 0.517463\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436250; batch adversarial loss: 0.522529\n",
      "epoch 80; iter: 0; batch classifier loss: 0.335595; batch adversarial loss: 0.578326\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378225; batch adversarial loss: 0.545851\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393628; batch adversarial loss: 0.443938\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392692; batch adversarial loss: 0.670725\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446584; batch adversarial loss: 0.572826\n",
      "epoch 85; iter: 0; batch classifier loss: 0.474770; batch adversarial loss: 0.581147\n",
      "epoch 86; iter: 0; batch classifier loss: 0.324988; batch adversarial loss: 0.595680\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340405; batch adversarial loss: 0.536911\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348558; batch adversarial loss: 0.536644\n",
      "epoch 89; iter: 0; batch classifier loss: 0.435323; batch adversarial loss: 0.591157\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417441; batch adversarial loss: 0.542332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354404; batch adversarial loss: 0.615718\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354185; batch adversarial loss: 0.510192\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410329; batch adversarial loss: 0.546279\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406801; batch adversarial loss: 0.565005\n",
      "epoch 95; iter: 0; batch classifier loss: 0.461596; batch adversarial loss: 0.625962\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350029; batch adversarial loss: 0.535338\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382278; batch adversarial loss: 0.517701\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358163; batch adversarial loss: 0.563171\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398584; batch adversarial loss: 0.508216\n",
      "epoch 100; iter: 0; batch classifier loss: 0.356279; batch adversarial loss: 0.592976\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406039; batch adversarial loss: 0.578301\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340225; batch adversarial loss: 0.543223\n",
      "epoch 103; iter: 0; batch classifier loss: 0.348885; batch adversarial loss: 0.491079\n",
      "epoch 104; iter: 0; batch classifier loss: 0.412294; batch adversarial loss: 0.573392\n",
      "epoch 105; iter: 0; batch classifier loss: 0.457611; batch adversarial loss: 0.591137\n",
      "epoch 106; iter: 0; batch classifier loss: 0.342768; batch adversarial loss: 0.553961\n",
      "epoch 107; iter: 0; batch classifier loss: 0.449376; batch adversarial loss: 0.644723\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363892; batch adversarial loss: 0.572432\n",
      "epoch 109; iter: 0; batch classifier loss: 0.424142; batch adversarial loss: 0.524465\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375888; batch adversarial loss: 0.553187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.446101; batch adversarial loss: 0.562824\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361062; batch adversarial loss: 0.564828\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354447; batch adversarial loss: 0.528147\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388028; batch adversarial loss: 0.562671\n",
      "epoch 115; iter: 0; batch classifier loss: 0.302655; batch adversarial loss: 0.527747\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351434; batch adversarial loss: 0.571025\n",
      "epoch 117; iter: 0; batch classifier loss: 0.403719; batch adversarial loss: 0.544329\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387884; batch adversarial loss: 0.480194\n",
      "epoch 119; iter: 0; batch classifier loss: 0.430934; batch adversarial loss: 0.454379\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394361; batch adversarial loss: 0.454057\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345478; batch adversarial loss: 0.601801\n",
      "epoch 122; iter: 0; batch classifier loss: 0.374264; batch adversarial loss: 0.505463\n",
      "epoch 123; iter: 0; batch classifier loss: 0.317679; batch adversarial loss: 0.542288\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339271; batch adversarial loss: 0.499335\n",
      "epoch 125; iter: 0; batch classifier loss: 0.381657; batch adversarial loss: 0.528912\n",
      "epoch 126; iter: 0; batch classifier loss: 0.313506; batch adversarial loss: 0.516984\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358458; batch adversarial loss: 0.463193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.391266; batch adversarial loss: 0.533847\n",
      "epoch 129; iter: 0; batch classifier loss: 0.411075; batch adversarial loss: 0.580523\n",
      "epoch 130; iter: 0; batch classifier loss: 0.400365; batch adversarial loss: 0.537115\n",
      "epoch 131; iter: 0; batch classifier loss: 0.425541; batch adversarial loss: 0.582611\n",
      "epoch 132; iter: 0; batch classifier loss: 0.397038; batch adversarial loss: 0.506724\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346921; batch adversarial loss: 0.533339\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385042; batch adversarial loss: 0.589153\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380096; batch adversarial loss: 0.536808\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361693; batch adversarial loss: 0.579059\n",
      "epoch 137; iter: 0; batch classifier loss: 0.461711; batch adversarial loss: 0.543812\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381348; batch adversarial loss: 0.582181\n",
      "epoch 139; iter: 0; batch classifier loss: 0.502163; batch adversarial loss: 0.563296\n",
      "epoch 140; iter: 0; batch classifier loss: 0.427243; batch adversarial loss: 0.507294\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353468; batch adversarial loss: 0.528988\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393503; batch adversarial loss: 0.499136\n",
      "epoch 143; iter: 0; batch classifier loss: 0.455314; batch adversarial loss: 0.582122\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424330; batch adversarial loss: 0.482553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397786; batch adversarial loss: 0.573010\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360745; batch adversarial loss: 0.623505\n",
      "epoch 147; iter: 0; batch classifier loss: 0.385961; batch adversarial loss: 0.491720\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342227; batch adversarial loss: 0.563461\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360757; batch adversarial loss: 0.485777\n",
      "epoch 150; iter: 0; batch classifier loss: 0.410544; batch adversarial loss: 0.525486\n",
      "epoch 151; iter: 0; batch classifier loss: 0.388301; batch adversarial loss: 0.595467\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379351; batch adversarial loss: 0.489035\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361953; batch adversarial loss: 0.546900\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370463; batch adversarial loss: 0.525699\n",
      "epoch 155; iter: 0; batch classifier loss: 0.405515; batch adversarial loss: 0.481483\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325451; batch adversarial loss: 0.553936\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372274; batch adversarial loss: 0.562894\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337958; batch adversarial loss: 0.607957\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387286; batch adversarial loss: 0.562636\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356863; batch adversarial loss: 0.517407\n",
      "epoch 161; iter: 0; batch classifier loss: 0.433044; batch adversarial loss: 0.526047\n",
      "epoch 162; iter: 0; batch classifier loss: 0.300357; batch adversarial loss: 0.605751\n",
      "epoch 163; iter: 0; batch classifier loss: 0.436954; batch adversarial loss: 0.551710\n",
      "epoch 164; iter: 0; batch classifier loss: 0.318489; batch adversarial loss: 0.563953\n",
      "epoch 165; iter: 0; batch classifier loss: 0.396597; batch adversarial loss: 0.574927\n",
      "epoch 166; iter: 0; batch classifier loss: 0.300301; batch adversarial loss: 0.514438\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409350; batch adversarial loss: 0.555013\n",
      "epoch 168; iter: 0; batch classifier loss: 0.405989; batch adversarial loss: 0.480605\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327406; batch adversarial loss: 0.490301\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362810; batch adversarial loss: 0.451303\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370734; batch adversarial loss: 0.542830\n",
      "epoch 172; iter: 0; batch classifier loss: 0.338691; batch adversarial loss: 0.442500\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350620; batch adversarial loss: 0.590928\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321253; batch adversarial loss: 0.501704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.394652; batch adversarial loss: 0.538342\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382165; batch adversarial loss: 0.552900\n",
      "epoch 177; iter: 0; batch classifier loss: 0.307858; batch adversarial loss: 0.528583\n",
      "epoch 178; iter: 0; batch classifier loss: 0.277810; batch adversarial loss: 0.555838\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303893; batch adversarial loss: 0.590227\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396884; batch adversarial loss: 0.589312\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339136; batch adversarial loss: 0.565573\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337929; batch adversarial loss: 0.613011\n",
      "epoch 183; iter: 0; batch classifier loss: 0.407362; batch adversarial loss: 0.525572\n",
      "epoch 184; iter: 0; batch classifier loss: 0.411238; batch adversarial loss: 0.589032\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326775; batch adversarial loss: 0.533386\n",
      "epoch 186; iter: 0; batch classifier loss: 0.277794; batch adversarial loss: 0.481102\n",
      "epoch 187; iter: 0; batch classifier loss: 0.307342; batch adversarial loss: 0.562775\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381232; batch adversarial loss: 0.490502\n",
      "epoch 189; iter: 0; batch classifier loss: 0.452140; batch adversarial loss: 0.463965\n",
      "epoch 190; iter: 0; batch classifier loss: 0.429145; batch adversarial loss: 0.518693\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368613; batch adversarial loss: 0.546110\n",
      "epoch 192; iter: 0; batch classifier loss: 0.395104; batch adversarial loss: 0.452599\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349065; batch adversarial loss: 0.561401\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399685; batch adversarial loss: 0.536772\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354257; batch adversarial loss: 0.515931\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343520; batch adversarial loss: 0.564640\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317752; batch adversarial loss: 0.572750\n",
      "epoch 198; iter: 0; batch classifier loss: 0.344314; batch adversarial loss: 0.525663\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312695; batch adversarial loss: 0.554298\n",
      "epoch 0; iter: 0; batch classifier loss: 0.767536; batch adversarial loss: 0.774650\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615505; batch adversarial loss: 0.718933\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590294; batch adversarial loss: 0.716894\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583296; batch adversarial loss: 0.643918\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501416; batch adversarial loss: 0.661226\n",
      "epoch 5; iter: 0; batch classifier loss: 0.641864; batch adversarial loss: 0.617905\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570212; batch adversarial loss: 0.601064\n",
      "epoch 7; iter: 0; batch classifier loss: 0.621189; batch adversarial loss: 0.587063\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633043; batch adversarial loss: 0.596585\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506931; batch adversarial loss: 0.590960\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515415; batch adversarial loss: 0.531901\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548921; batch adversarial loss: 0.525964\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525738; batch adversarial loss: 0.580876\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550738; batch adversarial loss: 0.591062\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539248; batch adversarial loss: 0.547460\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558408; batch adversarial loss: 0.624120\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536150; batch adversarial loss: 0.569731\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547130; batch adversarial loss: 0.602674\n",
      "epoch 18; iter: 0; batch classifier loss: 0.573013; batch adversarial loss: 0.580590\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508289; batch adversarial loss: 0.617911\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461633; batch adversarial loss: 0.589649\n",
      "epoch 21; iter: 0; batch classifier loss: 0.461475; batch adversarial loss: 0.527975\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516239; batch adversarial loss: 0.545224\n",
      "epoch 23; iter: 0; batch classifier loss: 0.607651; batch adversarial loss: 0.572467\n",
      "epoch 24; iter: 0; batch classifier loss: 0.539832; batch adversarial loss: 0.560307\n",
      "epoch 25; iter: 0; batch classifier loss: 0.430745; batch adversarial loss: 0.547227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.511066; batch adversarial loss: 0.464749\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447147; batch adversarial loss: 0.593484\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439657; batch adversarial loss: 0.502980\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437811; batch adversarial loss: 0.540181\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471526; batch adversarial loss: 0.555515\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453134; batch adversarial loss: 0.548084\n",
      "epoch 32; iter: 0; batch classifier loss: 0.521139; batch adversarial loss: 0.506293\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453402; batch adversarial loss: 0.530921\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496145; batch adversarial loss: 0.564155\n",
      "epoch 35; iter: 0; batch classifier loss: 0.379255; batch adversarial loss: 0.537319\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469202; batch adversarial loss: 0.520417\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529400; batch adversarial loss: 0.605325\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420232; batch adversarial loss: 0.562162\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467706; batch adversarial loss: 0.527551\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407883; batch adversarial loss: 0.571317\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389423; batch adversarial loss: 0.615089\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439889; batch adversarial loss: 0.571173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412315; batch adversarial loss: 0.543508\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414827; batch adversarial loss: 0.580702\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471073; batch adversarial loss: 0.589155\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405306; batch adversarial loss: 0.506219\n",
      "epoch 47; iter: 0; batch classifier loss: 0.392011; batch adversarial loss: 0.515392\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457926; batch adversarial loss: 0.644426\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392781; batch adversarial loss: 0.544535\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448349; batch adversarial loss: 0.480295\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441761; batch adversarial loss: 0.500909\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437763; batch adversarial loss: 0.644368\n",
      "epoch 53; iter: 0; batch classifier loss: 0.514523; batch adversarial loss: 0.562705\n",
      "epoch 54; iter: 0; batch classifier loss: 0.371584; batch adversarial loss: 0.580740\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400182; batch adversarial loss: 0.481999\n",
      "epoch 56; iter: 0; batch classifier loss: 0.472457; batch adversarial loss: 0.562570\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374685; batch adversarial loss: 0.553856\n",
      "epoch 58; iter: 0; batch classifier loss: 0.483629; batch adversarial loss: 0.580986\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428470; batch adversarial loss: 0.580702\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467499; batch adversarial loss: 0.535931\n",
      "epoch 61; iter: 0; batch classifier loss: 0.431314; batch adversarial loss: 0.544465\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398437; batch adversarial loss: 0.581529\n",
      "epoch 63; iter: 0; batch classifier loss: 0.427540; batch adversarial loss: 0.562303\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410981; batch adversarial loss: 0.544651\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410887; batch adversarial loss: 0.643837\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398456; batch adversarial loss: 0.571035\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384700; batch adversarial loss: 0.544389\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389540; batch adversarial loss: 0.580507\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377217; batch adversarial loss: 0.544639\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388400; batch adversarial loss: 0.490268\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419848; batch adversarial loss: 0.607915\n",
      "epoch 72; iter: 0; batch classifier loss: 0.475614; batch adversarial loss: 0.617411\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379077; batch adversarial loss: 0.499348\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422048; batch adversarial loss: 0.526529\n",
      "epoch 75; iter: 0; batch classifier loss: 0.383904; batch adversarial loss: 0.653322\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407866; batch adversarial loss: 0.525898\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416495; batch adversarial loss: 0.526259\n",
      "epoch 78; iter: 0; batch classifier loss: 0.348259; batch adversarial loss: 0.563367\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405423; batch adversarial loss: 0.526457\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389057; batch adversarial loss: 0.553328\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394309; batch adversarial loss: 0.545061\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405845; batch adversarial loss: 0.535509\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375384; batch adversarial loss: 0.526656\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367837; batch adversarial loss: 0.507475\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385941; batch adversarial loss: 0.535199\n",
      "epoch 86; iter: 0; batch classifier loss: 0.287648; batch adversarial loss: 0.571683\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385283; batch adversarial loss: 0.562800\n",
      "epoch 88; iter: 0; batch classifier loss: 0.485419; batch adversarial loss: 0.535917\n",
      "epoch 89; iter: 0; batch classifier loss: 0.352514; batch adversarial loss: 0.481750\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444421; batch adversarial loss: 0.526105\n",
      "epoch 91; iter: 0; batch classifier loss: 0.471443; batch adversarial loss: 0.608424\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413271; batch adversarial loss: 0.544476\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402364; batch adversarial loss: 0.526091\n",
      "epoch 94; iter: 0; batch classifier loss: 0.399023; batch adversarial loss: 0.499493\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395825; batch adversarial loss: 0.544603\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414240; batch adversarial loss: 0.544739\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382704; batch adversarial loss: 0.554409\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397767; batch adversarial loss: 0.517207\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388409; batch adversarial loss: 0.508506\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386866; batch adversarial loss: 0.580560\n",
      "epoch 101; iter: 0; batch classifier loss: 0.420876; batch adversarial loss: 0.526394\n",
      "epoch 102; iter: 0; batch classifier loss: 0.411772; batch adversarial loss: 0.526259\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417258; batch adversarial loss: 0.571591\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367835; batch adversarial loss: 0.553318\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347979; batch adversarial loss: 0.517337\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343235; batch adversarial loss: 0.535526\n",
      "epoch 107; iter: 0; batch classifier loss: 0.448498; batch adversarial loss: 0.545566\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354767; batch adversarial loss: 0.535373\n",
      "epoch 109; iter: 0; batch classifier loss: 0.464777; batch adversarial loss: 0.580466\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398843; batch adversarial loss: 0.598662\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336432; batch adversarial loss: 0.526277\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406780; batch adversarial loss: 0.535658\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392644; batch adversarial loss: 0.516980\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386158; batch adversarial loss: 0.517497\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338174; batch adversarial loss: 0.590542\n",
      "epoch 116; iter: 0; batch classifier loss: 0.327133; batch adversarial loss: 0.526643\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369515; batch adversarial loss: 0.525768\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387716; batch adversarial loss: 0.499061\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356573; batch adversarial loss: 0.598676\n",
      "epoch 120; iter: 0; batch classifier loss: 0.334510; batch adversarial loss: 0.562056\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382792; batch adversarial loss: 0.525969\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383700; batch adversarial loss: 0.472439\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339304; batch adversarial loss: 0.571965\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338194; batch adversarial loss: 0.534997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.340749; batch adversarial loss: 0.616701\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394627; batch adversarial loss: 0.463191\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389207; batch adversarial loss: 0.572194\n",
      "epoch 128; iter: 0; batch classifier loss: 0.319747; batch adversarial loss: 0.599318\n",
      "epoch 129; iter: 0; batch classifier loss: 0.457884; batch adversarial loss: 0.599055\n",
      "epoch 130; iter: 0; batch classifier loss: 0.400893; batch adversarial loss: 0.544990\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384562; batch adversarial loss: 0.498605\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396721; batch adversarial loss: 0.589715\n",
      "epoch 133; iter: 0; batch classifier loss: 0.442259; batch adversarial loss: 0.473128\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400664; batch adversarial loss: 0.472703\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325301; batch adversarial loss: 0.608781\n",
      "epoch 136; iter: 0; batch classifier loss: 0.417337; batch adversarial loss: 0.572375\n",
      "epoch 137; iter: 0; batch classifier loss: 0.330299; batch adversarial loss: 0.544130\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350063; batch adversarial loss: 0.634978\n",
      "epoch 139; iter: 0; batch classifier loss: 0.337638; batch adversarial loss: 0.571454\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386721; batch adversarial loss: 0.463045\n",
      "epoch 141; iter: 0; batch classifier loss: 0.438449; batch adversarial loss: 0.526816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371320; batch adversarial loss: 0.562340\n",
      "epoch 143; iter: 0; batch classifier loss: 0.291601; batch adversarial loss: 0.571847\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409454; batch adversarial loss: 0.580613\n",
      "epoch 145; iter: 0; batch classifier loss: 0.430802; batch adversarial loss: 0.426935\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325374; batch adversarial loss: 0.643798\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346163; batch adversarial loss: 0.590290\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412196; batch adversarial loss: 0.526545\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374398; batch adversarial loss: 0.590266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.407748; batch adversarial loss: 0.544865\n",
      "epoch 151; iter: 0; batch classifier loss: 0.402841; batch adversarial loss: 0.553637\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351154; batch adversarial loss: 0.589344\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407056; batch adversarial loss: 0.580926\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395754; batch adversarial loss: 0.490095\n",
      "epoch 155; iter: 0; batch classifier loss: 0.473731; batch adversarial loss: 0.553412\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354343; batch adversarial loss: 0.653213\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382190; batch adversarial loss: 0.580339\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356341; batch adversarial loss: 0.616621\n",
      "epoch 159; iter: 0; batch classifier loss: 0.443236; batch adversarial loss: 0.580224\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352919; batch adversarial loss: 0.544627\n",
      "epoch 161; iter: 0; batch classifier loss: 0.382658; batch adversarial loss: 0.609038\n",
      "epoch 162; iter: 0; batch classifier loss: 0.335137; batch adversarial loss: 0.526072\n",
      "epoch 163; iter: 0; batch classifier loss: 0.313874; batch adversarial loss: 0.516978\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386211; batch adversarial loss: 0.499003\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405257; batch adversarial loss: 0.499002\n",
      "epoch 166; iter: 0; batch classifier loss: 0.394364; batch adversarial loss: 0.535380\n",
      "epoch 167; iter: 0; batch classifier loss: 0.411808; batch adversarial loss: 0.545175\n",
      "epoch 168; iter: 0; batch classifier loss: 0.291904; batch adversarial loss: 0.581248\n",
      "epoch 169; iter: 0; batch classifier loss: 0.359982; batch adversarial loss: 0.589736\n",
      "epoch 170; iter: 0; batch classifier loss: 0.402038; batch adversarial loss: 0.535357\n",
      "epoch 171; iter: 0; batch classifier loss: 0.450658; batch adversarial loss: 0.508400\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326095; batch adversarial loss: 0.499099\n",
      "epoch 173; iter: 0; batch classifier loss: 0.402336; batch adversarial loss: 0.516815\n",
      "epoch 174; iter: 0; batch classifier loss: 0.264481; batch adversarial loss: 0.571717\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348434; batch adversarial loss: 0.517396\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366831; batch adversarial loss: 0.535666\n",
      "epoch 177; iter: 0; batch classifier loss: 0.370315; batch adversarial loss: 0.517332\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317557; batch adversarial loss: 0.535711\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379578; batch adversarial loss: 0.562413\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367918; batch adversarial loss: 0.589796\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319913; batch adversarial loss: 0.598682\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387605; batch adversarial loss: 0.535537\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355141; batch adversarial loss: 0.535635\n",
      "epoch 184; iter: 0; batch classifier loss: 0.394362; batch adversarial loss: 0.508067\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313439; batch adversarial loss: 0.544611\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359722; batch adversarial loss: 0.553617\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348124; batch adversarial loss: 0.644141\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404245; batch adversarial loss: 0.608113\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365476; batch adversarial loss: 0.562697\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376165; batch adversarial loss: 0.535579\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352680; batch adversarial loss: 0.571591\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343311; batch adversarial loss: 0.544614\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296378; batch adversarial loss: 0.608351\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390653; batch adversarial loss: 0.535637\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365798; batch adversarial loss: 0.571964\n",
      "epoch 196; iter: 0; batch classifier loss: 0.324477; batch adversarial loss: 0.589546\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323708; batch adversarial loss: 0.535300\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309833; batch adversarial loss: 0.517397\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316312; batch adversarial loss: 0.517289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701464; batch adversarial loss: 0.586978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573557; batch adversarial loss: 0.658976\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556779; batch adversarial loss: 0.728188\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559734; batch adversarial loss: 0.684344\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610624; batch adversarial loss: 0.696808\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582336; batch adversarial loss: 0.637523\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548524; batch adversarial loss: 0.676405\n",
      "epoch 7; iter: 0; batch classifier loss: 0.620796; batch adversarial loss: 0.623820\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530242; batch adversarial loss: 0.567226\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554241; batch adversarial loss: 0.602702\n",
      "epoch 10; iter: 0; batch classifier loss: 0.605347; batch adversarial loss: 0.615875\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557253; batch adversarial loss: 0.571109\n",
      "epoch 12; iter: 0; batch classifier loss: 0.584644; batch adversarial loss: 0.604349\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535664; batch adversarial loss: 0.605213\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461010; batch adversarial loss: 0.560483\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490197; batch adversarial loss: 0.569899\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527661; batch adversarial loss: 0.582299\n",
      "epoch 17; iter: 0; batch classifier loss: 0.610016; batch adversarial loss: 0.633698\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505596; batch adversarial loss: 0.626622\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537674; batch adversarial loss: 0.543144\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437519; batch adversarial loss: 0.542605\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473482; batch adversarial loss: 0.565016\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441853; batch adversarial loss: 0.535712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.462886; batch adversarial loss: 0.637259\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466367; batch adversarial loss: 0.549771\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442207; batch adversarial loss: 0.553273\n",
      "epoch 26; iter: 0; batch classifier loss: 0.535221; batch adversarial loss: 0.581919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.528976; batch adversarial loss: 0.562966\n",
      "epoch 28; iter: 0; batch classifier loss: 0.502425; batch adversarial loss: 0.497429\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448744; batch adversarial loss: 0.531177\n",
      "epoch 30; iter: 0; batch classifier loss: 0.498281; batch adversarial loss: 0.604319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.383030; batch adversarial loss: 0.555300\n",
      "epoch 32; iter: 0; batch classifier loss: 0.526908; batch adversarial loss: 0.504786\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400403; batch adversarial loss: 0.599465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.525327; batch adversarial loss: 0.614147\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448879; batch adversarial loss: 0.560820\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458843; batch adversarial loss: 0.472258\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427108; batch adversarial loss: 0.493585\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480332; batch adversarial loss: 0.479129\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437157; batch adversarial loss: 0.445585\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417100; batch adversarial loss: 0.580339\n",
      "epoch 41; iter: 0; batch classifier loss: 0.550727; batch adversarial loss: 0.547799\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457676; batch adversarial loss: 0.622093\n",
      "epoch 43; iter: 0; batch classifier loss: 0.452029; batch adversarial loss: 0.547276\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395470; batch adversarial loss: 0.563187\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454414; batch adversarial loss: 0.570667\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452956; batch adversarial loss: 0.545899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.372058; batch adversarial loss: 0.579129\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377182; batch adversarial loss: 0.545470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396086; batch adversarial loss: 0.630115\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400256; batch adversarial loss: 0.520182\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449283; batch adversarial loss: 0.519710\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401808; batch adversarial loss: 0.603162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405221; batch adversarial loss: 0.634913\n",
      "epoch 54; iter: 0; batch classifier loss: 0.362831; batch adversarial loss: 0.571039\n",
      "epoch 55; iter: 0; batch classifier loss: 0.456387; batch adversarial loss: 0.587157\n",
      "epoch 56; iter: 0; batch classifier loss: 0.367219; batch adversarial loss: 0.595465\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415472; batch adversarial loss: 0.553644\n",
      "epoch 58; iter: 0; batch classifier loss: 0.346881; batch adversarial loss: 0.597608\n",
      "epoch 59; iter: 0; batch classifier loss: 0.486429; batch adversarial loss: 0.676333\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432807; batch adversarial loss: 0.544775\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458176; batch adversarial loss: 0.510091\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442943; batch adversarial loss: 0.493130\n",
      "epoch 63; iter: 0; batch classifier loss: 0.358736; batch adversarial loss: 0.500584\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348815; batch adversarial loss: 0.509676\n",
      "epoch 65; iter: 0; batch classifier loss: 0.507488; batch adversarial loss: 0.502170\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428836; batch adversarial loss: 0.543177\n",
      "epoch 67; iter: 0; batch classifier loss: 0.545038; batch adversarial loss: 0.485116\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426482; batch adversarial loss: 0.597037\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415561; batch adversarial loss: 0.544970\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392447; batch adversarial loss: 0.501510\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373682; batch adversarial loss: 0.614689\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403334; batch adversarial loss: 0.536476\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366001; batch adversarial loss: 0.527555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372649; batch adversarial loss: 0.614012\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405734; batch adversarial loss: 0.501864\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388439; batch adversarial loss: 0.511065\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368734; batch adversarial loss: 0.596804\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386313; batch adversarial loss: 0.631908\n",
      "epoch 79; iter: 0; batch classifier loss: 0.458769; batch adversarial loss: 0.528182\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360752; batch adversarial loss: 0.570293\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409156; batch adversarial loss: 0.527307\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410135; batch adversarial loss: 0.562285\n",
      "epoch 83; iter: 0; batch classifier loss: 0.346623; batch adversarial loss: 0.553705\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393120; batch adversarial loss: 0.579102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343940; batch adversarial loss: 0.623269\n",
      "epoch 86; iter: 0; batch classifier loss: 0.448068; batch adversarial loss: 0.597183\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363413; batch adversarial loss: 0.502314\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426865; batch adversarial loss: 0.579912\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334266; batch adversarial loss: 0.587781\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419975; batch adversarial loss: 0.519927\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359504; batch adversarial loss: 0.536699\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385435; batch adversarial loss: 0.579251\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371274; batch adversarial loss: 0.510500\n",
      "epoch 94; iter: 0; batch classifier loss: 0.470902; batch adversarial loss: 0.510785\n",
      "epoch 95; iter: 0; batch classifier loss: 0.313931; batch adversarial loss: 0.578694\n",
      "epoch 96; iter: 0; batch classifier loss: 0.434405; batch adversarial loss: 0.511113\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375464; batch adversarial loss: 0.519173\n",
      "epoch 98; iter: 0; batch classifier loss: 0.450502; batch adversarial loss: 0.544555\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446498; batch adversarial loss: 0.622595\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381386; batch adversarial loss: 0.536754\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391943; batch adversarial loss: 0.580195\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377830; batch adversarial loss: 0.580169\n",
      "epoch 103; iter: 0; batch classifier loss: 0.431265; batch adversarial loss: 0.536238\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370690; batch adversarial loss: 0.528261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365035; batch adversarial loss: 0.510456\n",
      "epoch 106; iter: 0; batch classifier loss: 0.423877; batch adversarial loss: 0.562387\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412588; batch adversarial loss: 0.553895\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351370; batch adversarial loss: 0.459018\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351611; batch adversarial loss: 0.545871\n",
      "epoch 110; iter: 0; batch classifier loss: 0.418951; batch adversarial loss: 0.561194\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416346; batch adversarial loss: 0.579507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412204; batch adversarial loss: 0.562132\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377362; batch adversarial loss: 0.623225\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329961; batch adversarial loss: 0.527903\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381671; batch adversarial loss: 0.588069\n",
      "epoch 116; iter: 0; batch classifier loss: 0.447851; batch adversarial loss: 0.528529\n",
      "epoch 117; iter: 0; batch classifier loss: 0.481313; batch adversarial loss: 0.562718\n",
      "epoch 118; iter: 0; batch classifier loss: 0.372818; batch adversarial loss: 0.527943\n",
      "epoch 119; iter: 0; batch classifier loss: 0.421164; batch adversarial loss: 0.596467\n",
      "epoch 120; iter: 0; batch classifier loss: 0.365450; batch adversarial loss: 0.588150\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350479; batch adversarial loss: 0.613425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.401671; batch adversarial loss: 0.554042\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352169; batch adversarial loss: 0.484276\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347192; batch adversarial loss: 0.502588\n",
      "epoch 125; iter: 0; batch classifier loss: 0.348945; batch adversarial loss: 0.596695\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366260; batch adversarial loss: 0.561691\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443407; batch adversarial loss: 0.570676\n",
      "epoch 128; iter: 0; batch classifier loss: 0.327078; batch adversarial loss: 0.597065\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416492; batch adversarial loss: 0.562461\n",
      "epoch 130; iter: 0; batch classifier loss: 0.412214; batch adversarial loss: 0.502076\n",
      "epoch 131; iter: 0; batch classifier loss: 0.442510; batch adversarial loss: 0.570688\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415330; batch adversarial loss: 0.562110\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344691; batch adversarial loss: 0.536888\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395163; batch adversarial loss: 0.501740\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364989; batch adversarial loss: 0.476554\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386691; batch adversarial loss: 0.518619\n",
      "epoch 137; iter: 0; batch classifier loss: 0.326711; batch adversarial loss: 0.450789\n",
      "epoch 138; iter: 0; batch classifier loss: 0.326039; batch adversarial loss: 0.570926\n",
      "epoch 139; iter: 0; batch classifier loss: 0.296662; batch adversarial loss: 0.596442\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359135; batch adversarial loss: 0.562591\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400652; batch adversarial loss: 0.528149\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395589; batch adversarial loss: 0.545344\n",
      "epoch 143; iter: 0; batch classifier loss: 0.430066; batch adversarial loss: 0.580246\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350618; batch adversarial loss: 0.588483\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350914; batch adversarial loss: 0.604880\n",
      "epoch 146; iter: 0; batch classifier loss: 0.428969; batch adversarial loss: 0.571053\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397636; batch adversarial loss: 0.639602\n",
      "epoch 148; iter: 0; batch classifier loss: 0.400669; batch adversarial loss: 0.527568\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383067; batch adversarial loss: 0.597039\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359601; batch adversarial loss: 0.622571\n",
      "epoch 151; iter: 0; batch classifier loss: 0.479887; batch adversarial loss: 0.614194\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330450; batch adversarial loss: 0.527920\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407542; batch adversarial loss: 0.588121\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350385; batch adversarial loss: 0.604414\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380916; batch adversarial loss: 0.554381\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330647; batch adversarial loss: 0.518979\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403090; batch adversarial loss: 0.571240\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383895; batch adversarial loss: 0.537092\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387116; batch adversarial loss: 0.622442\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385841; batch adversarial loss: 0.544527\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388506; batch adversarial loss: 0.589742\n",
      "epoch 162; iter: 0; batch classifier loss: 0.418145; batch adversarial loss: 0.578882\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399809; batch adversarial loss: 0.588887\n",
      "epoch 164; iter: 0; batch classifier loss: 0.384385; batch adversarial loss: 0.562177\n",
      "epoch 165; iter: 0; batch classifier loss: 0.419104; batch adversarial loss: 0.527596\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330128; batch adversarial loss: 0.622517\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349702; batch adversarial loss: 0.605623\n",
      "epoch 168; iter: 0; batch classifier loss: 0.440447; batch adversarial loss: 0.562361\n",
      "epoch 169; iter: 0; batch classifier loss: 0.338660; batch adversarial loss: 0.596790\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379794; batch adversarial loss: 0.614199\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326528; batch adversarial loss: 0.614416\n",
      "epoch 172; iter: 0; batch classifier loss: 0.382444; batch adversarial loss: 0.527963\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324716; batch adversarial loss: 0.588601\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370899; batch adversarial loss: 0.588040\n",
      "epoch 175; iter: 0; batch classifier loss: 0.320112; batch adversarial loss: 0.622217\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379939; batch adversarial loss: 0.519391\n",
      "epoch 177; iter: 0; batch classifier loss: 0.412393; batch adversarial loss: 0.519537\n",
      "epoch 178; iter: 0; batch classifier loss: 0.397340; batch adversarial loss: 0.640232\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366444; batch adversarial loss: 0.570554\n",
      "epoch 180; iter: 0; batch classifier loss: 0.417076; batch adversarial loss: 0.545498\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330957; batch adversarial loss: 0.588455\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377438; batch adversarial loss: 0.562993\n",
      "epoch 183; iter: 0; batch classifier loss: 0.406481; batch adversarial loss: 0.536306\n",
      "epoch 184; iter: 0; batch classifier loss: 0.457385; batch adversarial loss: 0.596644\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398272; batch adversarial loss: 0.605341\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382863; batch adversarial loss: 0.587977\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369474; batch adversarial loss: 0.613138\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381936; batch adversarial loss: 0.571087\n",
      "epoch 189; iter: 0; batch classifier loss: 0.363154; batch adversarial loss: 0.605519\n",
      "epoch 190; iter: 0; batch classifier loss: 0.447695; batch adversarial loss: 0.570812\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403266; batch adversarial loss: 0.501517\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332138; batch adversarial loss: 0.587439\n",
      "epoch 193; iter: 0; batch classifier loss: 0.357013; batch adversarial loss: 0.570310\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398505; batch adversarial loss: 0.596296\n",
      "epoch 195; iter: 0; batch classifier loss: 0.425086; batch adversarial loss: 0.588415\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337847; batch adversarial loss: 0.579412\n",
      "epoch 197; iter: 0; batch classifier loss: 0.389865; batch adversarial loss: 0.622746\n",
      "epoch 198; iter: 0; batch classifier loss: 0.290022; batch adversarial loss: 0.571271\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365207; batch adversarial loss: 0.545227\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687295; batch adversarial loss: 0.754755\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638654; batch adversarial loss: 0.656794\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591490; batch adversarial loss: 0.637656\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556207; batch adversarial loss: 0.631196\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561299; batch adversarial loss: 0.637053\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582011; batch adversarial loss: 0.616530\n",
      "epoch 6; iter: 0; batch classifier loss: 0.650804; batch adversarial loss: 0.654313\n",
      "epoch 7; iter: 0; batch classifier loss: 0.477632; batch adversarial loss: 0.634311\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521921; batch adversarial loss: 0.609684\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462255; batch adversarial loss: 0.635665\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567970; batch adversarial loss: 0.547715\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499538; batch adversarial loss: 0.547827\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485919; batch adversarial loss: 0.594174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.608050; batch adversarial loss: 0.622275\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530416; batch adversarial loss: 0.553810\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564290; batch adversarial loss: 0.524998\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561023; batch adversarial loss: 0.492449\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522647; batch adversarial loss: 0.546055\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511205; batch adversarial loss: 0.573801\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481892; batch adversarial loss: 0.567069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.496267; batch adversarial loss: 0.493494\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478775; batch adversarial loss: 0.537051\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517189; batch adversarial loss: 0.534235\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532893; batch adversarial loss: 0.557724\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474383; batch adversarial loss: 0.604711\n",
      "epoch 25; iter: 0; batch classifier loss: 0.538078; batch adversarial loss: 0.468078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487027; batch adversarial loss: 0.593813\n",
      "epoch 27; iter: 0; batch classifier loss: 0.527766; batch adversarial loss: 0.569606\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434724; batch adversarial loss: 0.517296\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514674; batch adversarial loss: 0.613366\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424347; batch adversarial loss: 0.511507\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500868; batch adversarial loss: 0.572264\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471829; batch adversarial loss: 0.477147\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412690; batch adversarial loss: 0.574118\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484148; batch adversarial loss: 0.580121\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428121; batch adversarial loss: 0.507578\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419608; batch adversarial loss: 0.593418\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477711; batch adversarial loss: 0.590607\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507669; batch adversarial loss: 0.572204\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493273; batch adversarial loss: 0.509305\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441728; batch adversarial loss: 0.509469\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421907; batch adversarial loss: 0.619865\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422726; batch adversarial loss: 0.599301\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409253; batch adversarial loss: 0.517483\n",
      "epoch 44; iter: 0; batch classifier loss: 0.548398; batch adversarial loss: 0.534794\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427650; batch adversarial loss: 0.524945\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447795; batch adversarial loss: 0.526650\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485108; batch adversarial loss: 0.572895\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486256; batch adversarial loss: 0.581171\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458920; batch adversarial loss: 0.516866\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381079; batch adversarial loss: 0.562820\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470443; batch adversarial loss: 0.452706\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475409; batch adversarial loss: 0.552698\n",
      "epoch 53; iter: 0; batch classifier loss: 0.357888; batch adversarial loss: 0.506597\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420679; batch adversarial loss: 0.578825\n",
      "epoch 55; iter: 0; batch classifier loss: 0.514207; batch adversarial loss: 0.585921\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389436; batch adversarial loss: 0.505852\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432252; batch adversarial loss: 0.476600\n",
      "epoch 58; iter: 0; batch classifier loss: 0.473132; batch adversarial loss: 0.628591\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382704; batch adversarial loss: 0.513332\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363374; batch adversarial loss: 0.580937\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427589; batch adversarial loss: 0.589124\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424522; batch adversarial loss: 0.565196\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473217; batch adversarial loss: 0.514185\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401052; batch adversarial loss: 0.523657\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375422; batch adversarial loss: 0.449105\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404205; batch adversarial loss: 0.573667\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423053; batch adversarial loss: 0.516925\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418873; batch adversarial loss: 0.631862\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400166; batch adversarial loss: 0.554484\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406388; batch adversarial loss: 0.565089\n",
      "epoch 71; iter: 0; batch classifier loss: 0.455329; batch adversarial loss: 0.676412\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364800; batch adversarial loss: 0.578603\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353272; batch adversarial loss: 0.554177\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410751; batch adversarial loss: 0.466290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388935; batch adversarial loss: 0.530240\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373959; batch adversarial loss: 0.535800\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409501; batch adversarial loss: 0.513760\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401471; batch adversarial loss: 0.503611\n",
      "epoch 79; iter: 0; batch classifier loss: 0.476674; batch adversarial loss: 0.538543\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330744; batch adversarial loss: 0.532506\n",
      "epoch 81; iter: 0; batch classifier loss: 0.380661; batch adversarial loss: 0.528850\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376989; batch adversarial loss: 0.473743\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452287; batch adversarial loss: 0.535356\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421558; batch adversarial loss: 0.476370\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383262; batch adversarial loss: 0.588998\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420199; batch adversarial loss: 0.530302\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417252; batch adversarial loss: 0.645203\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386006; batch adversarial loss: 0.582815\n",
      "epoch 89; iter: 0; batch classifier loss: 0.316230; batch adversarial loss: 0.551964\n",
      "epoch 90; iter: 0; batch classifier loss: 0.308867; batch adversarial loss: 0.515368\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363946; batch adversarial loss: 0.539780\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421709; batch adversarial loss: 0.609627\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374711; batch adversarial loss: 0.466770\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452644; batch adversarial loss: 0.595302\n",
      "epoch 95; iter: 0; batch classifier loss: 0.342238; batch adversarial loss: 0.502365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.340406; batch adversarial loss: 0.488436\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368984; batch adversarial loss: 0.533726\n",
      "epoch 98; iter: 0; batch classifier loss: 0.414438; batch adversarial loss: 0.583194\n",
      "epoch 99; iter: 0; batch classifier loss: 0.428748; batch adversarial loss: 0.572406\n",
      "epoch 100; iter: 0; batch classifier loss: 0.449390; batch adversarial loss: 0.592539\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395389; batch adversarial loss: 0.508267\n",
      "epoch 102; iter: 0; batch classifier loss: 0.360113; batch adversarial loss: 0.496242\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395742; batch adversarial loss: 0.469774\n",
      "epoch 104; iter: 0; batch classifier loss: 0.339156; batch adversarial loss: 0.616970\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400854; batch adversarial loss: 0.560392\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384517; batch adversarial loss: 0.498293\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410959; batch adversarial loss: 0.649626\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408480; batch adversarial loss: 0.438673\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368721; batch adversarial loss: 0.489856\n",
      "epoch 110; iter: 0; batch classifier loss: 0.331961; batch adversarial loss: 0.501906\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394290; batch adversarial loss: 0.525798\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363768; batch adversarial loss: 0.471629\n",
      "epoch 113; iter: 0; batch classifier loss: 0.441185; batch adversarial loss: 0.546414\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380583; batch adversarial loss: 0.581923\n",
      "epoch 115; iter: 0; batch classifier loss: 0.473409; batch adversarial loss: 0.526489\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401718; batch adversarial loss: 0.477420\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365835; batch adversarial loss: 0.509369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.441703; batch adversarial loss: 0.498032\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406816; batch adversarial loss: 0.555097\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327145; batch adversarial loss: 0.532051\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351026; batch adversarial loss: 0.666300\n",
      "epoch 122; iter: 0; batch classifier loss: 0.508752; batch adversarial loss: 0.514115\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381818; batch adversarial loss: 0.571283\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385213; batch adversarial loss: 0.682511\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390742; batch adversarial loss: 0.573604\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336846; batch adversarial loss: 0.532152\n",
      "epoch 127; iter: 0; batch classifier loss: 0.331839; batch adversarial loss: 0.459158\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379251; batch adversarial loss: 0.554020\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350889; batch adversarial loss: 0.525333\n",
      "epoch 130; iter: 0; batch classifier loss: 0.401774; batch adversarial loss: 0.555092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385817; batch adversarial loss: 0.544970\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323401; batch adversarial loss: 0.559663\n",
      "epoch 133; iter: 0; batch classifier loss: 0.320616; batch adversarial loss: 0.573498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.448910; batch adversarial loss: 0.554879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.404666; batch adversarial loss: 0.469342\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403462; batch adversarial loss: 0.622980\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378962; batch adversarial loss: 0.526020\n",
      "epoch 138; iter: 0; batch classifier loss: 0.372867; batch adversarial loss: 0.544093\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379896; batch adversarial loss: 0.472052\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349126; batch adversarial loss: 0.603695\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373460; batch adversarial loss: 0.438312\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417043; batch adversarial loss: 0.448740\n",
      "epoch 143; iter: 0; batch classifier loss: 0.437913; batch adversarial loss: 0.572586\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361015; batch adversarial loss: 0.544005\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347675; batch adversarial loss: 0.561971\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410616; batch adversarial loss: 0.526698\n",
      "epoch 147; iter: 0; batch classifier loss: 0.421071; batch adversarial loss: 0.480143\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370246; batch adversarial loss: 0.543870\n",
      "epoch 149; iter: 0; batch classifier loss: 0.282173; batch adversarial loss: 0.503765\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354314; batch adversarial loss: 0.574243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.400437; batch adversarial loss: 0.553063\n",
      "epoch 152; iter: 0; batch classifier loss: 0.401172; batch adversarial loss: 0.553712\n",
      "epoch 153; iter: 0; batch classifier loss: 0.406365; batch adversarial loss: 0.580958\n",
      "epoch 154; iter: 0; batch classifier loss: 0.399577; batch adversarial loss: 0.632963\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376203; batch adversarial loss: 0.439064\n",
      "epoch 156; iter: 0; batch classifier loss: 0.375475; batch adversarial loss: 0.553235\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326098; batch adversarial loss: 0.551402\n",
      "epoch 158; iter: 0; batch classifier loss: 0.413515; batch adversarial loss: 0.506241\n",
      "epoch 159; iter: 0; batch classifier loss: 0.291070; batch adversarial loss: 0.515757\n",
      "epoch 160; iter: 0; batch classifier loss: 0.436347; batch adversarial loss: 0.508525\n",
      "epoch 161; iter: 0; batch classifier loss: 0.428684; batch adversarial loss: 0.545622\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328653; batch adversarial loss: 0.621466\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363953; batch adversarial loss: 0.548386\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414245; batch adversarial loss: 0.505539\n",
      "epoch 165; iter: 0; batch classifier loss: 0.307945; batch adversarial loss: 0.531695\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395177; batch adversarial loss: 0.478689\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362475; batch adversarial loss: 0.558713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336564; batch adversarial loss: 0.514891\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386233; batch adversarial loss: 0.555623\n",
      "epoch 170; iter: 0; batch classifier loss: 0.273200; batch adversarial loss: 0.575544\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333064; batch adversarial loss: 0.597941\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358506; batch adversarial loss: 0.469925\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340681; batch adversarial loss: 0.610472\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344712; batch adversarial loss: 0.507698\n",
      "epoch 175; iter: 0; batch classifier loss: 0.452709; batch adversarial loss: 0.522975\n",
      "epoch 176; iter: 0; batch classifier loss: 0.273362; batch adversarial loss: 0.535811\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309830; batch adversarial loss: 0.493577\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347472; batch adversarial loss: 0.617840\n",
      "epoch 179; iter: 0; batch classifier loss: 0.376766; batch adversarial loss: 0.533902\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378163; batch adversarial loss: 0.601413\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349295; batch adversarial loss: 0.555059\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377032; batch adversarial loss: 0.542196\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369194; batch adversarial loss: 0.488185\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342309; batch adversarial loss: 0.547721\n",
      "epoch 185; iter: 0; batch classifier loss: 0.335190; batch adversarial loss: 0.485253\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382225; batch adversarial loss: 0.527530\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343657; batch adversarial loss: 0.533025\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355237; batch adversarial loss: 0.575093\n",
      "epoch 189; iter: 0; batch classifier loss: 0.393574; batch adversarial loss: 0.545027\n",
      "epoch 190; iter: 0; batch classifier loss: 0.410581; batch adversarial loss: 0.528153\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389651; batch adversarial loss: 0.548666\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352542; batch adversarial loss: 0.553398\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348035; batch adversarial loss: 0.555422\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325874; batch adversarial loss: 0.494553\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366895; batch adversarial loss: 0.540796\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345427; batch adversarial loss: 0.534690\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394036; batch adversarial loss: 0.598749\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354440; batch adversarial loss: 0.613333\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350908; batch adversarial loss: 0.524735\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747575; batch adversarial loss: 0.950567\n",
      "epoch 1; iter: 0; batch classifier loss: 0.831877; batch adversarial loss: 0.998898\n",
      "epoch 2; iter: 0; batch classifier loss: 0.972167; batch adversarial loss: 0.957650\n",
      "epoch 3; iter: 0; batch classifier loss: 1.099794; batch adversarial loss: 0.880170\n",
      "epoch 4; iter: 0; batch classifier loss: 0.939605; batch adversarial loss: 0.794851\n",
      "epoch 5; iter: 0; batch classifier loss: 1.033810; batch adversarial loss: 0.755417\n",
      "epoch 6; iter: 0; batch classifier loss: 0.881194; batch adversarial loss: 0.681111\n",
      "epoch 7; iter: 0; batch classifier loss: 0.690110; batch adversarial loss: 0.621076\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600143; batch adversarial loss: 0.586764\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584414; batch adversarial loss: 0.587713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.585021; batch adversarial loss: 0.570387\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547525; batch adversarial loss: 0.538033\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540605; batch adversarial loss: 0.575728\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528840; batch adversarial loss: 0.587784\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498201; batch adversarial loss: 0.511211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.502761; batch adversarial loss: 0.562043\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460002; batch adversarial loss: 0.553621\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522253; batch adversarial loss: 0.592805\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501986; batch adversarial loss: 0.486350\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504398; batch adversarial loss: 0.570829\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435554; batch adversarial loss: 0.570543\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526723; batch adversarial loss: 0.519954\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483102; batch adversarial loss: 0.503342\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523726; batch adversarial loss: 0.608331\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476612; batch adversarial loss: 0.527891\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524752; batch adversarial loss: 0.614707\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497658; batch adversarial loss: 0.524414\n",
      "epoch 27; iter: 0; batch classifier loss: 0.426960; batch adversarial loss: 0.589524\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452749; batch adversarial loss: 0.580281\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443232; batch adversarial loss: 0.545728\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523745; batch adversarial loss: 0.523561\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489627; batch adversarial loss: 0.499776\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451907; batch adversarial loss: 0.555941\n",
      "epoch 33; iter: 0; batch classifier loss: 0.493924; batch adversarial loss: 0.523226\n",
      "epoch 34; iter: 0; batch classifier loss: 0.410173; batch adversarial loss: 0.606850\n",
      "epoch 35; iter: 0; batch classifier loss: 0.377170; batch adversarial loss: 0.597682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449365; batch adversarial loss: 0.461067\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456126; batch adversarial loss: 0.650587\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455421; batch adversarial loss: 0.530029\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476740; batch adversarial loss: 0.516467\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474831; batch adversarial loss: 0.572048\n",
      "epoch 41; iter: 0; batch classifier loss: 0.571163; batch adversarial loss: 0.543096\n",
      "epoch 42; iter: 0; batch classifier loss: 0.384060; batch adversarial loss: 0.527573\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403603; batch adversarial loss: 0.534131\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369181; batch adversarial loss: 0.550635\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469781; batch adversarial loss: 0.543059\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462744; batch adversarial loss: 0.599219\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421490; batch adversarial loss: 0.516008\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451631; batch adversarial loss: 0.448921\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385083; batch adversarial loss: 0.485798\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441402; batch adversarial loss: 0.615139\n",
      "epoch 51; iter: 0; batch classifier loss: 0.547346; batch adversarial loss: 0.492070\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414241; batch adversarial loss: 0.527457\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446092; batch adversarial loss: 0.454368\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449975; batch adversarial loss: 0.526529\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406848; batch adversarial loss: 0.592915\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413184; batch adversarial loss: 0.446438\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421784; batch adversarial loss: 0.508526\n",
      "epoch 58; iter: 0; batch classifier loss: 0.482611; batch adversarial loss: 0.550686\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467688; batch adversarial loss: 0.537790\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428629; batch adversarial loss: 0.527697\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358737; batch adversarial loss: 0.592607\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387453; batch adversarial loss: 0.601004\n",
      "epoch 63; iter: 0; batch classifier loss: 0.511369; batch adversarial loss: 0.525724\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438294; batch adversarial loss: 0.544909\n",
      "epoch 65; iter: 0; batch classifier loss: 0.358105; batch adversarial loss: 0.563360\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408264; batch adversarial loss: 0.644975\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442539; batch adversarial loss: 0.544619\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394461; batch adversarial loss: 0.553512\n",
      "epoch 69; iter: 0; batch classifier loss: 0.372072; batch adversarial loss: 0.507304\n",
      "epoch 70; iter: 0; batch classifier loss: 0.360239; batch adversarial loss: 0.563784\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403143; batch adversarial loss: 0.517194\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414044; batch adversarial loss: 0.599597\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382953; batch adversarial loss: 0.480492\n",
      "epoch 74; iter: 0; batch classifier loss: 0.324407; batch adversarial loss: 0.526229\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422146; batch adversarial loss: 0.570250\n",
      "epoch 76; iter: 0; batch classifier loss: 0.317152; batch adversarial loss: 0.617986\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372043; batch adversarial loss: 0.572051\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366103; batch adversarial loss: 0.478297\n",
      "epoch 79; iter: 0; batch classifier loss: 0.351007; batch adversarial loss: 0.560565\n",
      "epoch 80; iter: 0; batch classifier loss: 0.364074; batch adversarial loss: 0.525605\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384573; batch adversarial loss: 0.573103\n",
      "epoch 82; iter: 0; batch classifier loss: 0.444694; batch adversarial loss: 0.552429\n",
      "epoch 83; iter: 0; batch classifier loss: 0.342219; batch adversarial loss: 0.477906\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447665; batch adversarial loss: 0.619947\n",
      "epoch 85; iter: 0; batch classifier loss: 0.487088; batch adversarial loss: 0.507539\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409325; batch adversarial loss: 0.563661\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386382; batch adversarial loss: 0.593270\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412276; batch adversarial loss: 0.553714\n",
      "epoch 89; iter: 0; batch classifier loss: 0.347761; batch adversarial loss: 0.573556\n",
      "epoch 90; iter: 0; batch classifier loss: 0.326528; batch adversarial loss: 0.516160\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421022; batch adversarial loss: 0.676101\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373835; batch adversarial loss: 0.544076\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395364; batch adversarial loss: 0.488314\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392046; batch adversarial loss: 0.451065\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352843; batch adversarial loss: 0.591109\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399402; batch adversarial loss: 0.525840\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415955; batch adversarial loss: 0.553850\n",
      "epoch 98; iter: 0; batch classifier loss: 0.458095; batch adversarial loss: 0.572635\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365856; batch adversarial loss: 0.507188\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406772; batch adversarial loss: 0.516567\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376864; batch adversarial loss: 0.441770\n",
      "epoch 102; iter: 0; batch classifier loss: 0.300383; batch adversarial loss: 0.535062\n",
      "epoch 103; iter: 0; batch classifier loss: 0.421218; batch adversarial loss: 0.516676\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398990; batch adversarial loss: 0.507321\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418620; batch adversarial loss: 0.544215\n",
      "epoch 106; iter: 0; batch classifier loss: 0.368413; batch adversarial loss: 0.525979\n",
      "epoch 107; iter: 0; batch classifier loss: 0.324078; batch adversarial loss: 0.563134\n",
      "epoch 108; iter: 0; batch classifier loss: 0.299618; batch adversarial loss: 0.526176\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377905; batch adversarial loss: 0.535499\n",
      "epoch 110; iter: 0; batch classifier loss: 0.326176; batch adversarial loss: 0.590928\n",
      "epoch 111; iter: 0; batch classifier loss: 0.297552; batch adversarial loss: 0.618988\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366228; batch adversarial loss: 0.469999\n",
      "epoch 113; iter: 0; batch classifier loss: 0.297501; batch adversarial loss: 0.535005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.368931; batch adversarial loss: 0.535354\n",
      "epoch 115; iter: 0; batch classifier loss: 0.441334; batch adversarial loss: 0.451400\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347595; batch adversarial loss: 0.535051\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415179; batch adversarial loss: 0.554023\n",
      "epoch 118; iter: 0; batch classifier loss: 0.353549; batch adversarial loss: 0.563528\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428486; batch adversarial loss: 0.572424\n",
      "epoch 120; iter: 0; batch classifier loss: 0.376000; batch adversarial loss: 0.526064\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385399; batch adversarial loss: 0.497673\n",
      "epoch 122; iter: 0; batch classifier loss: 0.303231; batch adversarial loss: 0.488422\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366636; batch adversarial loss: 0.553970\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376062; batch adversarial loss: 0.572429\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372445; batch adversarial loss: 0.535156\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379103; batch adversarial loss: 0.516488\n",
      "epoch 127; iter: 0; batch classifier loss: 0.437835; batch adversarial loss: 0.526060\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328598; batch adversarial loss: 0.591043\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340511; batch adversarial loss: 0.553830\n",
      "epoch 130; iter: 0; batch classifier loss: 0.282292; batch adversarial loss: 0.627695\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373632; batch adversarial loss: 0.507516\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347106; batch adversarial loss: 0.553793\n",
      "epoch 133; iter: 0; batch classifier loss: 0.269636; batch adversarial loss: 0.516207\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337222; batch adversarial loss: 0.488948\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376750; batch adversarial loss: 0.582207\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334752; batch adversarial loss: 0.554202\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321045; batch adversarial loss: 0.507744\n",
      "epoch 138; iter: 0; batch classifier loss: 0.424192; batch adversarial loss: 0.451314\n",
      "epoch 139; iter: 0; batch classifier loss: 0.380010; batch adversarial loss: 0.498174\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400720; batch adversarial loss: 0.525761\n",
      "epoch 141; iter: 0; batch classifier loss: 0.320256; batch adversarial loss: 0.517020\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347345; batch adversarial loss: 0.553453\n",
      "epoch 143; iter: 0; batch classifier loss: 0.254043; batch adversarial loss: 0.543519\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398594; batch adversarial loss: 0.543811\n",
      "epoch 145; iter: 0; batch classifier loss: 0.330817; batch adversarial loss: 0.646659\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349567; batch adversarial loss: 0.554476\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319927; batch adversarial loss: 0.544933\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363335; batch adversarial loss: 0.441344\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418556; batch adversarial loss: 0.544119\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371159; batch adversarial loss: 0.544653\n",
      "epoch 151; iter: 0; batch classifier loss: 0.295360; batch adversarial loss: 0.497716\n",
      "epoch 152; iter: 0; batch classifier loss: 0.345691; batch adversarial loss: 0.554555\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358535; batch adversarial loss: 0.563123\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369815; batch adversarial loss: 0.425366\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357976; batch adversarial loss: 0.552767\n",
      "epoch 156; iter: 0; batch classifier loss: 0.285398; batch adversarial loss: 0.637499\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336980; batch adversarial loss: 0.609187\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343560; batch adversarial loss: 0.598703\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352788; batch adversarial loss: 0.478400\n",
      "epoch 160; iter: 0; batch classifier loss: 0.309999; batch adversarial loss: 0.537461\n",
      "epoch 161; iter: 0; batch classifier loss: 0.305238; batch adversarial loss: 0.525980\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392271; batch adversarial loss: 0.536125\n",
      "epoch 163; iter: 0; batch classifier loss: 0.284692; batch adversarial loss: 0.507110\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342208; batch adversarial loss: 0.506742\n",
      "epoch 165; iter: 0; batch classifier loss: 0.286201; batch adversarial loss: 0.581944\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378288; batch adversarial loss: 0.450901\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347104; batch adversarial loss: 0.516719\n",
      "epoch 168; iter: 0; batch classifier loss: 0.291457; batch adversarial loss: 0.525698\n",
      "epoch 169; iter: 0; batch classifier loss: 0.313012; batch adversarial loss: 0.507654\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335744; batch adversarial loss: 0.535284\n",
      "epoch 171; iter: 0; batch classifier loss: 0.405880; batch adversarial loss: 0.572774\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402374; batch adversarial loss: 0.535160\n",
      "epoch 173; iter: 0; batch classifier loss: 0.453954; batch adversarial loss: 0.534975\n",
      "epoch 174; iter: 0; batch classifier loss: 0.293878; batch adversarial loss: 0.497606\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369337; batch adversarial loss: 0.498187\n",
      "epoch 176; iter: 0; batch classifier loss: 0.357900; batch adversarial loss: 0.497912\n",
      "epoch 177; iter: 0; batch classifier loss: 0.281858; batch adversarial loss: 0.637369\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387855; batch adversarial loss: 0.526234\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319991; batch adversarial loss: 0.544670\n",
      "epoch 180; iter: 0; batch classifier loss: 0.298191; batch adversarial loss: 0.525876\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333377; batch adversarial loss: 0.544471\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313201; batch adversarial loss: 0.628649\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384946; batch adversarial loss: 0.563237\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329405; batch adversarial loss: 0.544509\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383203; batch adversarial loss: 0.497818\n",
      "epoch 186; iter: 0; batch classifier loss: 0.378152; batch adversarial loss: 0.609580\n",
      "epoch 187; iter: 0; batch classifier loss: 0.289281; batch adversarial loss: 0.525899\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337940; batch adversarial loss: 0.535102\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384399; batch adversarial loss: 0.470037\n",
      "epoch 190; iter: 0; batch classifier loss: 0.325746; batch adversarial loss: 0.516265\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397612; batch adversarial loss: 0.591655\n",
      "epoch 192; iter: 0; batch classifier loss: 0.360548; batch adversarial loss: 0.600801\n",
      "epoch 193; iter: 0; batch classifier loss: 0.286137; batch adversarial loss: 0.553294\n",
      "epoch 194; iter: 0; batch classifier loss: 0.292826; batch adversarial loss: 0.600695\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379716; batch adversarial loss: 0.544755\n",
      "epoch 196; iter: 0; batch classifier loss: 0.289466; batch adversarial loss: 0.525420\n",
      "epoch 197; iter: 0; batch classifier loss: 0.403370; batch adversarial loss: 0.489703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.402098; batch adversarial loss: 0.497925\n",
      "epoch 199; iter: 0; batch classifier loss: 0.243058; batch adversarial loss: 0.516640\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682117; batch adversarial loss: 0.670933\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608193; batch adversarial loss: 0.675975\n",
      "epoch 2; iter: 0; batch classifier loss: 0.618654; batch adversarial loss: 0.692920\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570628; batch adversarial loss: 0.651202\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543368; batch adversarial loss: 0.613969\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530576; batch adversarial loss: 0.632324\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535872; batch adversarial loss: 0.610407\n",
      "epoch 7; iter: 0; batch classifier loss: 0.444118; batch adversarial loss: 0.580053\n",
      "epoch 8; iter: 0; batch classifier loss: 0.592208; batch adversarial loss: 0.553742\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461280; batch adversarial loss: 0.575293\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612660; batch adversarial loss: 0.618984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.600486; batch adversarial loss: 0.625807\n",
      "epoch 12; iter: 0; batch classifier loss: 0.580233; batch adversarial loss: 0.598560\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578956; batch adversarial loss: 0.639168\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471084; batch adversarial loss: 0.562254\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528458; batch adversarial loss: 0.575382\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500713; batch adversarial loss: 0.537771\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463867; batch adversarial loss: 0.659761\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532167; batch adversarial loss: 0.597896\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487975; batch adversarial loss: 0.543265\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515900; batch adversarial loss: 0.551214\n",
      "epoch 21; iter: 0; batch classifier loss: 0.585586; batch adversarial loss: 0.521455\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479312; batch adversarial loss: 0.592217\n",
      "epoch 23; iter: 0; batch classifier loss: 0.533158; batch adversarial loss: 0.592850\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503368; batch adversarial loss: 0.530485\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439113; batch adversarial loss: 0.639183\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496776; batch adversarial loss: 0.559598\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454454; batch adversarial loss: 0.644354\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437741; batch adversarial loss: 0.640942\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466487; batch adversarial loss: 0.560738\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432903; batch adversarial loss: 0.512602\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446285; batch adversarial loss: 0.561826\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469704; batch adversarial loss: 0.688228\n",
      "epoch 33; iter: 0; batch classifier loss: 0.524650; batch adversarial loss: 0.547245\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419738; batch adversarial loss: 0.520589\n",
      "epoch 35; iter: 0; batch classifier loss: 0.386079; batch adversarial loss: 0.506827\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425089; batch adversarial loss: 0.476043\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481525; batch adversarial loss: 0.523749\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469283; batch adversarial loss: 0.591605\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451609; batch adversarial loss: 0.551434\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427526; batch adversarial loss: 0.577289\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437655; batch adversarial loss: 0.598092\n",
      "epoch 42; iter: 0; batch classifier loss: 0.473711; batch adversarial loss: 0.581866\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465110; batch adversarial loss: 0.624380\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454198; batch adversarial loss: 0.554993\n",
      "epoch 45; iter: 0; batch classifier loss: 0.482111; batch adversarial loss: 0.570016\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401594; batch adversarial loss: 0.517544\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427923; batch adversarial loss: 0.579600\n",
      "epoch 48; iter: 0; batch classifier loss: 0.523655; batch adversarial loss: 0.592602\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421442; batch adversarial loss: 0.518178\n",
      "epoch 50; iter: 0; batch classifier loss: 0.478282; batch adversarial loss: 0.589860\n",
      "epoch 51; iter: 0; batch classifier loss: 0.488761; batch adversarial loss: 0.509714\n",
      "epoch 52; iter: 0; batch classifier loss: 0.566820; batch adversarial loss: 0.510494\n",
      "epoch 53; iter: 0; batch classifier loss: 0.482630; batch adversarial loss: 0.515260\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381098; batch adversarial loss: 0.536264\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398398; batch adversarial loss: 0.598352\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447982; batch adversarial loss: 0.617530\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440779; batch adversarial loss: 0.524889\n",
      "epoch 58; iter: 0; batch classifier loss: 0.459405; batch adversarial loss: 0.560914\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449763; batch adversarial loss: 0.609540\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390644; batch adversarial loss: 0.598522\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407485; batch adversarial loss: 0.551265\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405883; batch adversarial loss: 0.510186\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430250; batch adversarial loss: 0.587322\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428087; batch adversarial loss: 0.633988\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425753; batch adversarial loss: 0.553929\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420408; batch adversarial loss: 0.527096\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411666; batch adversarial loss: 0.579243\n",
      "epoch 68; iter: 0; batch classifier loss: 0.398075; batch adversarial loss: 0.607462\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418398; batch adversarial loss: 0.544620\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420235; batch adversarial loss: 0.571811\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407845; batch adversarial loss: 0.580881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428154; batch adversarial loss: 0.599683\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431125; batch adversarial loss: 0.471440\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454958; batch adversarial loss: 0.500595\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385543; batch adversarial loss: 0.561650\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364060; batch adversarial loss: 0.625141\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374200; batch adversarial loss: 0.543120\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431492; batch adversarial loss: 0.454623\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391016; batch adversarial loss: 0.626937\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447493; batch adversarial loss: 0.545606\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424665; batch adversarial loss: 0.558963\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386558; batch adversarial loss: 0.563035\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423232; batch adversarial loss: 0.572146\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373468; batch adversarial loss: 0.517959\n",
      "epoch 85; iter: 0; batch classifier loss: 0.422603; batch adversarial loss: 0.597829\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426688; batch adversarial loss: 0.516791\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413803; batch adversarial loss: 0.570448\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377491; batch adversarial loss: 0.525326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402800; batch adversarial loss: 0.436386\n",
      "epoch 90; iter: 0; batch classifier loss: 0.346997; batch adversarial loss: 0.608410\n",
      "epoch 91; iter: 0; batch classifier loss: 0.475522; batch adversarial loss: 0.535858\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397375; batch adversarial loss: 0.606939\n",
      "epoch 93; iter: 0; batch classifier loss: 0.408835; batch adversarial loss: 0.491046\n",
      "epoch 94; iter: 0; batch classifier loss: 0.448444; batch adversarial loss: 0.498624\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368447; batch adversarial loss: 0.641866\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414216; batch adversarial loss: 0.533846\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411669; batch adversarial loss: 0.592134\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404723; batch adversarial loss: 0.608184\n",
      "epoch 99; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.474111\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385119; batch adversarial loss: 0.545625\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379069; batch adversarial loss: 0.543349\n",
      "epoch 102; iter: 0; batch classifier loss: 0.458793; batch adversarial loss: 0.560715\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412296; batch adversarial loss: 0.508109\n",
      "epoch 104; iter: 0; batch classifier loss: 0.432379; batch adversarial loss: 0.537280\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372045; batch adversarial loss: 0.561681\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330345; batch adversarial loss: 0.578293\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364789; batch adversarial loss: 0.497641\n",
      "epoch 108; iter: 0; batch classifier loss: 0.452663; batch adversarial loss: 0.605941\n",
      "epoch 109; iter: 0; batch classifier loss: 0.373815; batch adversarial loss: 0.542011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.411586; batch adversarial loss: 0.579889\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403500; batch adversarial loss: 0.562738\n",
      "epoch 112; iter: 0; batch classifier loss: 0.444248; batch adversarial loss: 0.524232\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417338; batch adversarial loss: 0.526430\n",
      "epoch 114; iter: 0; batch classifier loss: 0.306596; batch adversarial loss: 0.607384\n",
      "epoch 115; iter: 0; batch classifier loss: 0.318245; batch adversarial loss: 0.571461\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381063; batch adversarial loss: 0.572027\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381778; batch adversarial loss: 0.579575\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373821; batch adversarial loss: 0.547005\n",
      "epoch 119; iter: 0; batch classifier loss: 0.436786; batch adversarial loss: 0.677505\n",
      "epoch 120; iter: 0; batch classifier loss: 0.450296; batch adversarial loss: 0.541806\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412434; batch adversarial loss: 0.533134\n",
      "epoch 122; iter: 0; batch classifier loss: 0.434194; batch adversarial loss: 0.580157\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421266; batch adversarial loss: 0.534599\n",
      "epoch 124; iter: 0; batch classifier loss: 0.434494; batch adversarial loss: 0.563449\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353444; batch adversarial loss: 0.608297\n",
      "epoch 126; iter: 0; batch classifier loss: 0.327306; batch adversarial loss: 0.515497\n",
      "epoch 127; iter: 0; batch classifier loss: 0.409502; batch adversarial loss: 0.569658\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375643; batch adversarial loss: 0.533029\n",
      "epoch 129; iter: 0; batch classifier loss: 0.326926; batch adversarial loss: 0.462853\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340313; batch adversarial loss: 0.625919\n",
      "epoch 131; iter: 0; batch classifier loss: 0.303525; batch adversarial loss: 0.508960\n",
      "epoch 132; iter: 0; batch classifier loss: 0.336876; batch adversarial loss: 0.581920\n",
      "epoch 133; iter: 0; batch classifier loss: 0.418086; batch adversarial loss: 0.491981\n",
      "epoch 134; iter: 0; batch classifier loss: 0.347348; batch adversarial loss: 0.597978\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353292; batch adversarial loss: 0.535128\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319086; batch adversarial loss: 0.544546\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413936; batch adversarial loss: 0.489817\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383612; batch adversarial loss: 0.561556\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371147; batch adversarial loss: 0.555640\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371009; batch adversarial loss: 0.516051\n",
      "epoch 141; iter: 0; batch classifier loss: 0.455273; batch adversarial loss: 0.486389\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362386; batch adversarial loss: 0.518497\n",
      "epoch 143; iter: 0; batch classifier loss: 0.284788; batch adversarial loss: 0.596657\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392058; batch adversarial loss: 0.517045\n",
      "epoch 145; iter: 0; batch classifier loss: 0.330870; batch adversarial loss: 0.605274\n",
      "epoch 146; iter: 0; batch classifier loss: 0.423066; batch adversarial loss: 0.545246\n",
      "epoch 147; iter: 0; batch classifier loss: 0.437181; batch adversarial loss: 0.517504\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335680; batch adversarial loss: 0.479249\n",
      "epoch 149; iter: 0; batch classifier loss: 0.407918; batch adversarial loss: 0.481740\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339900; batch adversarial loss: 0.579234\n",
      "epoch 151; iter: 0; batch classifier loss: 0.453525; batch adversarial loss: 0.572289\n",
      "epoch 152; iter: 0; batch classifier loss: 0.484253; batch adversarial loss: 0.571683\n",
      "epoch 153; iter: 0; batch classifier loss: 0.420561; batch adversarial loss: 0.500855\n",
      "epoch 154; iter: 0; batch classifier loss: 0.308721; batch adversarial loss: 0.519087\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392209; batch adversarial loss: 0.571495\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358582; batch adversarial loss: 0.499392\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360664; batch adversarial loss: 0.497833\n",
      "epoch 158; iter: 0; batch classifier loss: 0.419917; batch adversarial loss: 0.590082\n",
      "epoch 159; iter: 0; batch classifier loss: 0.358061; batch adversarial loss: 0.552578\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373784; batch adversarial loss: 0.544616\n",
      "epoch 161; iter: 0; batch classifier loss: 0.326736; batch adversarial loss: 0.544907\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372389; batch adversarial loss: 0.543426\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420302; batch adversarial loss: 0.591068\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395455; batch adversarial loss: 0.491214\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397617; batch adversarial loss: 0.526551\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319596; batch adversarial loss: 0.470734\n",
      "epoch 167; iter: 0; batch classifier loss: 0.354138; batch adversarial loss: 0.571271\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380792; batch adversarial loss: 0.510371\n",
      "epoch 169; iter: 0; batch classifier loss: 0.445343; batch adversarial loss: 0.553568\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322775; batch adversarial loss: 0.486738\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390879; batch adversarial loss: 0.581609\n",
      "epoch 172; iter: 0; batch classifier loss: 0.457614; batch adversarial loss: 0.599290\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375261; batch adversarial loss: 0.543729\n",
      "epoch 174; iter: 0; batch classifier loss: 0.398584; batch adversarial loss: 0.499095\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347324; batch adversarial loss: 0.508292\n",
      "epoch 176; iter: 0; batch classifier loss: 0.417845; batch adversarial loss: 0.644717\n",
      "epoch 177; iter: 0; batch classifier loss: 0.397200; batch adversarial loss: 0.509671\n",
      "epoch 178; iter: 0; batch classifier loss: 0.366706; batch adversarial loss: 0.573629\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303990; batch adversarial loss: 0.497353\n",
      "epoch 180; iter: 0; batch classifier loss: 0.399292; batch adversarial loss: 0.526560\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313559; batch adversarial loss: 0.527797\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380844; batch adversarial loss: 0.554638\n",
      "epoch 183; iter: 0; batch classifier loss: 0.412718; batch adversarial loss: 0.586160\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386079; batch adversarial loss: 0.560239\n",
      "epoch 185; iter: 0; batch classifier loss: 0.400097; batch adversarial loss: 0.562752\n",
      "epoch 186; iter: 0; batch classifier loss: 0.387312; batch adversarial loss: 0.559575\n",
      "epoch 187; iter: 0; batch classifier loss: 0.403080; batch adversarial loss: 0.550767\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371629; batch adversarial loss: 0.534705\n",
      "epoch 189; iter: 0; batch classifier loss: 0.390034; batch adversarial loss: 0.543730\n",
      "epoch 190; iter: 0; batch classifier loss: 0.300719; batch adversarial loss: 0.545991\n",
      "epoch 191; iter: 0; batch classifier loss: 0.522269; batch adversarial loss: 0.553279\n",
      "epoch 192; iter: 0; batch classifier loss: 0.360524; batch adversarial loss: 0.508343\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344472; batch adversarial loss: 0.573329\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372116; batch adversarial loss: 0.552217\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390895; batch adversarial loss: 0.527830\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322278; batch adversarial loss: 0.529090\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362551; batch adversarial loss: 0.563276\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317264; batch adversarial loss: 0.551197\n",
      "epoch 199; iter: 0; batch classifier loss: 0.383047; batch adversarial loss: 0.516193\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752566; batch adversarial loss: 0.679540\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573500; batch adversarial loss: 0.643380\n",
      "epoch 2; iter: 0; batch classifier loss: 0.532475; batch adversarial loss: 0.647012\n",
      "epoch 3; iter: 0; batch classifier loss: 0.554489; batch adversarial loss: 0.636209\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519000; batch adversarial loss: 0.588717\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532540; batch adversarial loss: 0.582963\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547703; batch adversarial loss: 0.616129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488622; batch adversarial loss: 0.594751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.557086; batch adversarial loss: 0.601228\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586285; batch adversarial loss: 0.584553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523962; batch adversarial loss: 0.597971\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576834; batch adversarial loss: 0.595052\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560705; batch adversarial loss: 0.586860\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556890; batch adversarial loss: 0.526948\n",
      "epoch 14; iter: 0; batch classifier loss: 0.555478; batch adversarial loss: 0.515764\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549730; batch adversarial loss: 0.565458\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506991; batch adversarial loss: 0.567913\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592527; batch adversarial loss: 0.586392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548925; batch adversarial loss: 0.594687\n",
      "epoch 19; iter: 0; batch classifier loss: 0.577910; batch adversarial loss: 0.524344\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495738; batch adversarial loss: 0.540165\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511028; batch adversarial loss: 0.617628\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476510; batch adversarial loss: 0.522528\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516841; batch adversarial loss: 0.571298\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485973; batch adversarial loss: 0.476914\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535516; batch adversarial loss: 0.520959\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505148; batch adversarial loss: 0.521775\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394035; batch adversarial loss: 0.546786\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480492; batch adversarial loss: 0.538130\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412332; batch adversarial loss: 0.546288\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463584; batch adversarial loss: 0.516058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486781; batch adversarial loss: 0.544352\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491619; batch adversarial loss: 0.488321\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489504; batch adversarial loss: 0.517692\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476485; batch adversarial loss: 0.527154\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482003; batch adversarial loss: 0.542798\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486681; batch adversarial loss: 0.572840\n",
      "epoch 37; iter: 0; batch classifier loss: 0.511719; batch adversarial loss: 0.487109\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373806; batch adversarial loss: 0.516695\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443470; batch adversarial loss: 0.540097\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501000; batch adversarial loss: 0.544615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426141; batch adversarial loss: 0.476787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456978; batch adversarial loss: 0.488293\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432234; batch adversarial loss: 0.526230\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455521; batch adversarial loss: 0.566509\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364014; batch adversarial loss: 0.637504\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419004; batch adversarial loss: 0.450275\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505581; batch adversarial loss: 0.651009\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371764; batch adversarial loss: 0.565532\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433218; batch adversarial loss: 0.507624\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493391; batch adversarial loss: 0.563218\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440771; batch adversarial loss: 0.533938\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462980; batch adversarial loss: 0.592373\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401284; batch adversarial loss: 0.478179\n",
      "epoch 54; iter: 0; batch classifier loss: 0.538690; batch adversarial loss: 0.505770\n",
      "epoch 55; iter: 0; batch classifier loss: 0.452306; batch adversarial loss: 0.545845\n",
      "epoch 56; iter: 0; batch classifier loss: 0.402517; batch adversarial loss: 0.592443\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466303; batch adversarial loss: 0.515822\n",
      "epoch 58; iter: 0; batch classifier loss: 0.453061; batch adversarial loss: 0.458267\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415254; batch adversarial loss: 0.447036\n",
      "epoch 60; iter: 0; batch classifier loss: 0.448818; batch adversarial loss: 0.409385\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401803; batch adversarial loss: 0.515815\n",
      "epoch 62; iter: 0; batch classifier loss: 0.355638; batch adversarial loss: 0.516326\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415431; batch adversarial loss: 0.525393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365767; batch adversarial loss: 0.477381\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419225; batch adversarial loss: 0.563896\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401603; batch adversarial loss: 0.467646\n",
      "epoch 67; iter: 0; batch classifier loss: 0.356224; batch adversarial loss: 0.429345\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393004; batch adversarial loss: 0.505872\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432747; batch adversarial loss: 0.524974\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432809; batch adversarial loss: 0.525606\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380204; batch adversarial loss: 0.466973\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400007; batch adversarial loss: 0.486060\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382967; batch adversarial loss: 0.477097\n",
      "epoch 74; iter: 0; batch classifier loss: 0.515611; batch adversarial loss: 0.641431\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415578; batch adversarial loss: 0.525361\n",
      "epoch 76; iter: 0; batch classifier loss: 0.360688; batch adversarial loss: 0.554414\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345097; batch adversarial loss: 0.467429\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427827; batch adversarial loss: 0.534884\n",
      "epoch 79; iter: 0; batch classifier loss: 0.315691; batch adversarial loss: 0.573550\n",
      "epoch 80; iter: 0; batch classifier loss: 0.379593; batch adversarial loss: 0.496011\n",
      "epoch 81; iter: 0; batch classifier loss: 0.459346; batch adversarial loss: 0.486776\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410839; batch adversarial loss: 0.593672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.294446; batch adversarial loss: 0.525562\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390185; batch adversarial loss: 0.466947\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387881; batch adversarial loss: 0.466192\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370363; batch adversarial loss: 0.535097\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413546; batch adversarial loss: 0.455519\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405720; batch adversarial loss: 0.534381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381545; batch adversarial loss: 0.572181\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365100; batch adversarial loss: 0.544110\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408261; batch adversarial loss: 0.545961\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370750; batch adversarial loss: 0.525319\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358082; batch adversarial loss: 0.534724\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391340; batch adversarial loss: 0.506550\n",
      "epoch 95; iter: 0; batch classifier loss: 0.385863; batch adversarial loss: 0.516375\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392993; batch adversarial loss: 0.599905\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384872; batch adversarial loss: 0.545520\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401337; batch adversarial loss: 0.649919\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365324; batch adversarial loss: 0.552994\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361543; batch adversarial loss: 0.544484\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426609; batch adversarial loss: 0.580550\n",
      "epoch 102; iter: 0; batch classifier loss: 0.343773; batch adversarial loss: 0.533977\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374866; batch adversarial loss: 0.603174\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419383; batch adversarial loss: 0.467362\n",
      "epoch 105; iter: 0; batch classifier loss: 0.369725; batch adversarial loss: 0.487447\n",
      "epoch 106; iter: 0; batch classifier loss: 0.411345; batch adversarial loss: 0.456426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.413696; batch adversarial loss: 0.554322\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352729; batch adversarial loss: 0.545410\n",
      "epoch 109; iter: 0; batch classifier loss: 0.321823; batch adversarial loss: 0.545545\n",
      "epoch 110; iter: 0; batch classifier loss: 0.323454; batch adversarial loss: 0.505585\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379490; batch adversarial loss: 0.525581\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396234; batch adversarial loss: 0.487031\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392749; batch adversarial loss: 0.515428\n",
      "epoch 114; iter: 0; batch classifier loss: 0.432611; batch adversarial loss: 0.515716\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373141; batch adversarial loss: 0.466724\n",
      "epoch 116; iter: 0; batch classifier loss: 0.312791; batch adversarial loss: 0.545275\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372982; batch adversarial loss: 0.573640\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391623; batch adversarial loss: 0.574190\n",
      "epoch 119; iter: 0; batch classifier loss: 0.452509; batch adversarial loss: 0.554503\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383375; batch adversarial loss: 0.574272\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385388; batch adversarial loss: 0.525254\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352503; batch adversarial loss: 0.563623\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394386; batch adversarial loss: 0.516252\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410448; batch adversarial loss: 0.467530\n",
      "epoch 125; iter: 0; batch classifier loss: 0.327357; batch adversarial loss: 0.593553\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362226; batch adversarial loss: 0.496547\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340457; batch adversarial loss: 0.476170\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392952; batch adversarial loss: 0.622793\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389382; batch adversarial loss: 0.582502\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354200; batch adversarial loss: 0.496319\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377260; batch adversarial loss: 0.545017\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382676; batch adversarial loss: 0.505107\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390181; batch adversarial loss: 0.496677\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399482; batch adversarial loss: 0.514956\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420504; batch adversarial loss: 0.554940\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334946; batch adversarial loss: 0.525711\n",
      "epoch 137; iter: 0; batch classifier loss: 0.320080; batch adversarial loss: 0.486486\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355831; batch adversarial loss: 0.467043\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403543; batch adversarial loss: 0.476955\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387077; batch adversarial loss: 0.583587\n",
      "epoch 141; iter: 0; batch classifier loss: 0.444840; batch adversarial loss: 0.534640\n",
      "epoch 142; iter: 0; batch classifier loss: 0.452637; batch adversarial loss: 0.525156\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366730; batch adversarial loss: 0.467171\n",
      "epoch 144; iter: 0; batch classifier loss: 0.317377; batch adversarial loss: 0.544145\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340295; batch adversarial loss: 0.515480\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338839; batch adversarial loss: 0.505703\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334885; batch adversarial loss: 0.516739\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330227; batch adversarial loss: 0.563740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354604; batch adversarial loss: 0.555379\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345122; batch adversarial loss: 0.563788\n",
      "epoch 151; iter: 0; batch classifier loss: 0.315044; batch adversarial loss: 0.486522\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348550; batch adversarial loss: 0.642137\n",
      "epoch 153; iter: 0; batch classifier loss: 0.428257; batch adversarial loss: 0.525242\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332420; batch adversarial loss: 0.535644\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344291; batch adversarial loss: 0.583753\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372032; batch adversarial loss: 0.603085\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404405; batch adversarial loss: 0.467867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.271058; batch adversarial loss: 0.495970\n",
      "epoch 159; iter: 0; batch classifier loss: 0.424851; batch adversarial loss: 0.497685\n",
      "epoch 160; iter: 0; batch classifier loss: 0.436638; batch adversarial loss: 0.496968\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378961; batch adversarial loss: 0.535092\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359529; batch adversarial loss: 0.613455\n",
      "epoch 163; iter: 0; batch classifier loss: 0.449034; batch adversarial loss: 0.544880\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409708; batch adversarial loss: 0.475871\n",
      "epoch 165; iter: 0; batch classifier loss: 0.454999; batch adversarial loss: 0.525839\n",
      "epoch 166; iter: 0; batch classifier loss: 0.425011; batch adversarial loss: 0.564401\n",
      "epoch 167; iter: 0; batch classifier loss: 0.441509; batch adversarial loss: 0.602229\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349737; batch adversarial loss: 0.496068\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353055; batch adversarial loss: 0.467826\n",
      "epoch 170; iter: 0; batch classifier loss: 0.306014; batch adversarial loss: 0.476217\n",
      "epoch 171; iter: 0; batch classifier loss: 0.488458; batch adversarial loss: 0.621413\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366077; batch adversarial loss: 0.563667\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348594; batch adversarial loss: 0.467519\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365496; batch adversarial loss: 0.525249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388148; batch adversarial loss: 0.534810\n",
      "epoch 176; iter: 0; batch classifier loss: 0.391301; batch adversarial loss: 0.584593\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319900; batch adversarial loss: 0.536142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.373831; batch adversarial loss: 0.458179\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357285; batch adversarial loss: 0.535333\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371964; batch adversarial loss: 0.544172\n",
      "epoch 181; iter: 0; batch classifier loss: 0.321559; batch adversarial loss: 0.573596\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356592; batch adversarial loss: 0.555116\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313653; batch adversarial loss: 0.515392\n",
      "epoch 184; iter: 0; batch classifier loss: 0.407379; batch adversarial loss: 0.506473\n",
      "epoch 185; iter: 0; batch classifier loss: 0.295846; batch adversarial loss: 0.439137\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371009; batch adversarial loss: 0.467817\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353962; batch adversarial loss: 0.428389\n",
      "epoch 188; iter: 0; batch classifier loss: 0.418514; batch adversarial loss: 0.457698\n",
      "epoch 189; iter: 0; batch classifier loss: 0.394224; batch adversarial loss: 0.447258\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336911; batch adversarial loss: 0.554651\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381543; batch adversarial loss: 0.487322\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333333; batch adversarial loss: 0.505954\n",
      "epoch 193; iter: 0; batch classifier loss: 0.374262; batch adversarial loss: 0.554136\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364315; batch adversarial loss: 0.535197\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343831; batch adversarial loss: 0.457099\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372595; batch adversarial loss: 0.524252\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335654; batch adversarial loss: 0.505189\n",
      "epoch 198; iter: 0; batch classifier loss: 0.429180; batch adversarial loss: 0.448416\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355297; batch adversarial loss: 0.447138\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668433; batch adversarial loss: 0.670310\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630841; batch adversarial loss: 0.647878\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558419; batch adversarial loss: 0.646829\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572455; batch adversarial loss: 0.630583\n",
      "epoch 4; iter: 0; batch classifier loss: 0.514096; batch adversarial loss: 0.635743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.551919; batch adversarial loss: 0.652896\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512140; batch adversarial loss: 0.604028\n",
      "epoch 7; iter: 0; batch classifier loss: 0.641375; batch adversarial loss: 0.570489\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506380; batch adversarial loss: 0.621104\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523041; batch adversarial loss: 0.576496\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581290; batch adversarial loss: 0.515965\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498768; batch adversarial loss: 0.573755\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566795; batch adversarial loss: 0.566393\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514400; batch adversarial loss: 0.618871\n",
      "epoch 14; iter: 0; batch classifier loss: 0.567892; batch adversarial loss: 0.594991\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523071; batch adversarial loss: 0.582549\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524526; batch adversarial loss: 0.568805\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509990; batch adversarial loss: 0.527956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555533; batch adversarial loss: 0.605263\n",
      "epoch 19; iter: 0; batch classifier loss: 0.559976; batch adversarial loss: 0.545663\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556571; batch adversarial loss: 0.577698\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475522; batch adversarial loss: 0.499421\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486742; batch adversarial loss: 0.577034\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462685; batch adversarial loss: 0.548156\n",
      "epoch 24; iter: 0; batch classifier loss: 0.410038; batch adversarial loss: 0.593412\n",
      "epoch 25; iter: 0; batch classifier loss: 0.572540; batch adversarial loss: 0.585056\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450371; batch adversarial loss: 0.639502\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437470; batch adversarial loss: 0.535446\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507259; batch adversarial loss: 0.567643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461228; batch adversarial loss: 0.545110\n",
      "epoch 30; iter: 0; batch classifier loss: 0.532097; batch adversarial loss: 0.526794\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465252; batch adversarial loss: 0.543341\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512366; batch adversarial loss: 0.525925\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464200; batch adversarial loss: 0.547080\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448878; batch adversarial loss: 0.512936\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466165; batch adversarial loss: 0.545179\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512411; batch adversarial loss: 0.520261\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508463; batch adversarial loss: 0.627370\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439155; batch adversarial loss: 0.518654\n",
      "epoch 39; iter: 0; batch classifier loss: 0.400760; batch adversarial loss: 0.518228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434119; batch adversarial loss: 0.505310\n",
      "epoch 41; iter: 0; batch classifier loss: 0.409138; batch adversarial loss: 0.499257\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428977; batch adversarial loss: 0.534671\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403848; batch adversarial loss: 0.564491\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400022; batch adversarial loss: 0.481385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.375401; batch adversarial loss: 0.529910\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457858; batch adversarial loss: 0.589297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.500161; batch adversarial loss: 0.508273\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409792; batch adversarial loss: 0.563108\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463968; batch adversarial loss: 0.497820\n",
      "epoch 50; iter: 0; batch classifier loss: 0.369981; batch adversarial loss: 0.506800\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409084; batch adversarial loss: 0.492458\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419405; batch adversarial loss: 0.487024\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430245; batch adversarial loss: 0.563997\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446757; batch adversarial loss: 0.635111\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401130; batch adversarial loss: 0.582028\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410307; batch adversarial loss: 0.517559\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431681; batch adversarial loss: 0.546358\n",
      "epoch 58; iter: 0; batch classifier loss: 0.479859; batch adversarial loss: 0.544430\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404510; batch adversarial loss: 0.526115\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426669; batch adversarial loss: 0.525365\n",
      "epoch 61; iter: 0; batch classifier loss: 0.360355; batch adversarial loss: 0.504822\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430109; batch adversarial loss: 0.517287\n",
      "epoch 63; iter: 0; batch classifier loss: 0.445367; batch adversarial loss: 0.524661\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437263; batch adversarial loss: 0.564743\n",
      "epoch 65; iter: 0; batch classifier loss: 0.525458; batch adversarial loss: 0.599103\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377491; batch adversarial loss: 0.562883\n",
      "epoch 67; iter: 0; batch classifier loss: 0.454639; batch adversarial loss: 0.526645\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395584; batch adversarial loss: 0.534625\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412471; batch adversarial loss: 0.488572\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401397; batch adversarial loss: 0.498207\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414350; batch adversarial loss: 0.486240\n",
      "epoch 72; iter: 0; batch classifier loss: 0.468226; batch adversarial loss: 0.535489\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389395; batch adversarial loss: 0.537251\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443037; batch adversarial loss: 0.555906\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415233; batch adversarial loss: 0.606972\n",
      "epoch 76; iter: 0; batch classifier loss: 0.318060; batch adversarial loss: 0.453033\n",
      "epoch 77; iter: 0; batch classifier loss: 0.470813; batch adversarial loss: 0.563297\n",
      "epoch 78; iter: 0; batch classifier loss: 0.492016; batch adversarial loss: 0.571174\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403463; batch adversarial loss: 0.581134\n",
      "epoch 80; iter: 0; batch classifier loss: 0.478283; batch adversarial loss: 0.542279\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428871; batch adversarial loss: 0.570694\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414270; batch adversarial loss: 0.608373\n",
      "epoch 83; iter: 0; batch classifier loss: 0.470392; batch adversarial loss: 0.581843\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416649; batch adversarial loss: 0.526157\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413016; batch adversarial loss: 0.543973\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426380; batch adversarial loss: 0.506068\n",
      "epoch 87; iter: 0; batch classifier loss: 0.315056; batch adversarial loss: 0.592930\n",
      "epoch 88; iter: 0; batch classifier loss: 0.448815; batch adversarial loss: 0.496081\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369290; batch adversarial loss: 0.517883\n",
      "epoch 90; iter: 0; batch classifier loss: 0.451446; batch adversarial loss: 0.516849\n",
      "epoch 91; iter: 0; batch classifier loss: 0.328817; batch adversarial loss: 0.518344\n",
      "epoch 92; iter: 0; batch classifier loss: 0.334019; batch adversarial loss: 0.563143\n",
      "epoch 93; iter: 0; batch classifier loss: 0.473677; batch adversarial loss: 0.506385\n",
      "epoch 94; iter: 0; batch classifier loss: 0.305953; batch adversarial loss: 0.479360\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362579; batch adversarial loss: 0.497744\n",
      "epoch 96; iter: 0; batch classifier loss: 0.337502; batch adversarial loss: 0.534908\n",
      "epoch 97; iter: 0; batch classifier loss: 0.453613; batch adversarial loss: 0.525330\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415426; batch adversarial loss: 0.490551\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357086; batch adversarial loss: 0.545435\n",
      "epoch 100; iter: 0; batch classifier loss: 0.531455; batch adversarial loss: 0.555945\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386689; batch adversarial loss: 0.572964\n",
      "epoch 102; iter: 0; batch classifier loss: 0.483504; batch adversarial loss: 0.516330\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375005; batch adversarial loss: 0.552189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.414010; batch adversarial loss: 0.461734\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390116; batch adversarial loss: 0.553271\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428249; batch adversarial loss: 0.489020\n",
      "epoch 107; iter: 0; batch classifier loss: 0.344726; batch adversarial loss: 0.508710\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387276; batch adversarial loss: 0.572223\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407604; batch adversarial loss: 0.563147\n",
      "epoch 110; iter: 0; batch classifier loss: 0.410274; batch adversarial loss: 0.536210\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353111; batch adversarial loss: 0.645325\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409334; batch adversarial loss: 0.470061\n",
      "epoch 113; iter: 0; batch classifier loss: 0.440337; batch adversarial loss: 0.525508\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397926; batch adversarial loss: 0.535465\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393211; batch adversarial loss: 0.544310\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351674; batch adversarial loss: 0.525584\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342752; batch adversarial loss: 0.563900\n",
      "epoch 118; iter: 0; batch classifier loss: 0.418951; batch adversarial loss: 0.553132\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378518; batch adversarial loss: 0.507456\n",
      "epoch 120; iter: 0; batch classifier loss: 0.487156; batch adversarial loss: 0.562222\n",
      "epoch 121; iter: 0; batch classifier loss: 0.367605; batch adversarial loss: 0.553732\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378832; batch adversarial loss: 0.516858\n",
      "epoch 123; iter: 0; batch classifier loss: 0.391248; batch adversarial loss: 0.535447\n",
      "epoch 124; iter: 0; batch classifier loss: 0.428476; batch adversarial loss: 0.535146\n",
      "epoch 125; iter: 0; batch classifier loss: 0.406939; batch adversarial loss: 0.562596\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366274; batch adversarial loss: 0.518231\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417198; batch adversarial loss: 0.562420\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334049; batch adversarial loss: 0.617335\n",
      "epoch 129; iter: 0; batch classifier loss: 0.436132; batch adversarial loss: 0.543707\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388925; batch adversarial loss: 0.591154\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356739; batch adversarial loss: 0.535304\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404249; batch adversarial loss: 0.608582\n",
      "epoch 133; iter: 0; batch classifier loss: 0.428946; batch adversarial loss: 0.544300\n",
      "epoch 134; iter: 0; batch classifier loss: 0.418394; batch adversarial loss: 0.580601\n",
      "epoch 135; iter: 0; batch classifier loss: 0.437777; batch adversarial loss: 0.516602\n",
      "epoch 136; iter: 0; batch classifier loss: 0.388513; batch adversarial loss: 0.470741\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384048; batch adversarial loss: 0.573086\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344399; batch adversarial loss: 0.489193\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397944; batch adversarial loss: 0.534157\n",
      "epoch 140; iter: 0; batch classifier loss: 0.420964; batch adversarial loss: 0.563360\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377730; batch adversarial loss: 0.526210\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376075; batch adversarial loss: 0.582828\n",
      "epoch 143; iter: 0; batch classifier loss: 0.372033; batch adversarial loss: 0.581426\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318968; batch adversarial loss: 0.543934\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338484; batch adversarial loss: 0.498421\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330747; batch adversarial loss: 0.461494\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383812; batch adversarial loss: 0.563766\n",
      "epoch 148; iter: 0; batch classifier loss: 0.415375; batch adversarial loss: 0.609359\n",
      "epoch 149; iter: 0; batch classifier loss: 0.404367; batch adversarial loss: 0.506746\n",
      "epoch 150; iter: 0; batch classifier loss: 0.465180; batch adversarial loss: 0.517635\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353330; batch adversarial loss: 0.516940\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385279; batch adversarial loss: 0.479288\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376835; batch adversarial loss: 0.608727\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381751; batch adversarial loss: 0.443311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365325; batch adversarial loss: 0.598825\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396226; batch adversarial loss: 0.534995\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411436; batch adversarial loss: 0.572865\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368935; batch adversarial loss: 0.536415\n",
      "epoch 159; iter: 0; batch classifier loss: 0.437610; batch adversarial loss: 0.545182\n",
      "epoch 160; iter: 0; batch classifier loss: 0.269805; batch adversarial loss: 0.581122\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344349; batch adversarial loss: 0.554770\n",
      "epoch 162; iter: 0; batch classifier loss: 0.427258; batch adversarial loss: 0.562849\n",
      "epoch 163; iter: 0; batch classifier loss: 0.320290; batch adversarial loss: 0.563594\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358147; batch adversarial loss: 0.470736\n",
      "epoch 165; iter: 0; batch classifier loss: 0.446941; batch adversarial loss: 0.527263\n",
      "epoch 166; iter: 0; batch classifier loss: 0.414922; batch adversarial loss: 0.654929\n",
      "epoch 167; iter: 0; batch classifier loss: 0.308627; batch adversarial loss: 0.498777\n",
      "epoch 168; iter: 0; batch classifier loss: 0.404574; batch adversarial loss: 0.553864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381177; batch adversarial loss: 0.451869\n",
      "epoch 170; iter: 0; batch classifier loss: 0.347496; batch adversarial loss: 0.544575\n",
      "epoch 171; iter: 0; batch classifier loss: 0.310013; batch adversarial loss: 0.562254\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351239; batch adversarial loss: 0.516795\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329440; batch adversarial loss: 0.480243\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326187; batch adversarial loss: 0.572548\n",
      "epoch 175; iter: 0; batch classifier loss: 0.302641; batch adversarial loss: 0.608851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335569; batch adversarial loss: 0.546393\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346344; batch adversarial loss: 0.610059\n",
      "epoch 178; iter: 0; batch classifier loss: 0.315349; batch adversarial loss: 0.562015\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380989; batch adversarial loss: 0.553536\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366784; batch adversarial loss: 0.470280\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350183; batch adversarial loss: 0.534731\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356914; batch adversarial loss: 0.489269\n",
      "epoch 183; iter: 0; batch classifier loss: 0.419806; batch adversarial loss: 0.498396\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377770; batch adversarial loss: 0.562837\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397409; batch adversarial loss: 0.544257\n",
      "epoch 186; iter: 0; batch classifier loss: 0.384124; batch adversarial loss: 0.618897\n",
      "epoch 187; iter: 0; batch classifier loss: 0.419704; batch adversarial loss: 0.544681\n",
      "epoch 188; iter: 0; batch classifier loss: 0.339717; batch adversarial loss: 0.525951\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378852; batch adversarial loss: 0.535016\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344412; batch adversarial loss: 0.489492\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338400; batch adversarial loss: 0.516297\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384012; batch adversarial loss: 0.517653\n",
      "epoch 193; iter: 0; batch classifier loss: 0.445166; batch adversarial loss: 0.470728\n",
      "epoch 194; iter: 0; batch classifier loss: 0.326057; batch adversarial loss: 0.544383\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384759; batch adversarial loss: 0.507889\n",
      "epoch 196; iter: 0; batch classifier loss: 0.361923; batch adversarial loss: 0.525414\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321356; batch adversarial loss: 0.479720\n",
      "epoch 198; iter: 0; batch classifier loss: 0.284523; batch adversarial loss: 0.609368\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374386; batch adversarial loss: 0.618630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.757061; batch adversarial loss: 0.684000\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613054; batch adversarial loss: 0.695796\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604328; batch adversarial loss: 0.640531\n",
      "epoch 3; iter: 0; batch classifier loss: 0.645441; batch adversarial loss: 0.612309\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533029; batch adversarial loss: 0.610257\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575322; batch adversarial loss: 0.585308\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573436; batch adversarial loss: 0.545478\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619663; batch adversarial loss: 0.534064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587733; batch adversarial loss: 0.602369\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548401; batch adversarial loss: 0.608531\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485716; batch adversarial loss: 0.584315\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473155; batch adversarial loss: 0.585467\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520108; batch adversarial loss: 0.549620\n",
      "epoch 13; iter: 0; batch classifier loss: 0.598265; batch adversarial loss: 0.601120\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500631; batch adversarial loss: 0.649808\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477053; batch adversarial loss: 0.613443\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515562; batch adversarial loss: 0.526404\n",
      "epoch 17; iter: 0; batch classifier loss: 0.584932; batch adversarial loss: 0.636979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533735; batch adversarial loss: 0.563844\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509790; batch adversarial loss: 0.654837\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473188; batch adversarial loss: 0.587479\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520042; batch adversarial loss: 0.565243\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500223; batch adversarial loss: 0.543318\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510971; batch adversarial loss: 0.603382\n",
      "epoch 24; iter: 0; batch classifier loss: 0.558329; batch adversarial loss: 0.482078\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446382; batch adversarial loss: 0.549406\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522217; batch adversarial loss: 0.498368\n",
      "epoch 27; iter: 0; batch classifier loss: 0.540062; batch adversarial loss: 0.564898\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485945; batch adversarial loss: 0.479929\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428535; batch adversarial loss: 0.607894\n",
      "epoch 30; iter: 0; batch classifier loss: 0.526949; batch adversarial loss: 0.646374\n",
      "epoch 31; iter: 0; batch classifier loss: 0.351572; batch adversarial loss: 0.547238\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448755; batch adversarial loss: 0.528228\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440874; batch adversarial loss: 0.580566\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433409; batch adversarial loss: 0.579546\n",
      "epoch 35; iter: 0; batch classifier loss: 0.348724; batch adversarial loss: 0.536360\n",
      "epoch 36; iter: 0; batch classifier loss: 0.367181; batch adversarial loss: 0.527521\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456056; batch adversarial loss: 0.527416\n",
      "epoch 38; iter: 0; batch classifier loss: 0.508396; batch adversarial loss: 0.562420\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434552; batch adversarial loss: 0.456545\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474596; batch adversarial loss: 0.598099\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447407; batch adversarial loss: 0.580378\n",
      "epoch 42; iter: 0; batch classifier loss: 0.485452; batch adversarial loss: 0.490858\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453780; batch adversarial loss: 0.490837\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404196; batch adversarial loss: 0.544609\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485836; batch adversarial loss: 0.580829\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462377; batch adversarial loss: 0.508414\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453110; batch adversarial loss: 0.499063\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371550; batch adversarial loss: 0.525848\n",
      "epoch 49; iter: 0; batch classifier loss: 0.536836; batch adversarial loss: 0.508180\n",
      "epoch 50; iter: 0; batch classifier loss: 0.522504; batch adversarial loss: 0.625598\n",
      "epoch 51; iter: 0; batch classifier loss: 0.518610; batch adversarial loss: 0.562065\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418513; batch adversarial loss: 0.535356\n",
      "epoch 53; iter: 0; batch classifier loss: 0.398287; batch adversarial loss: 0.562934\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365927; batch adversarial loss: 0.580969\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404926; batch adversarial loss: 0.480642\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426112; batch adversarial loss: 0.581675\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453441; batch adversarial loss: 0.499254\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436408; batch adversarial loss: 0.590406\n",
      "epoch 59; iter: 0; batch classifier loss: 0.486779; batch adversarial loss: 0.500495\n",
      "epoch 60; iter: 0; batch classifier loss: 0.369203; batch adversarial loss: 0.607074\n",
      "epoch 61; iter: 0; batch classifier loss: 0.350529; batch adversarial loss: 0.613409\n",
      "epoch 62; iter: 0; batch classifier loss: 0.431290; batch adversarial loss: 0.490162\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381950; batch adversarial loss: 0.529219\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436345; batch adversarial loss: 0.517948\n",
      "epoch 65; iter: 0; batch classifier loss: 0.446508; batch adversarial loss: 0.616644\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412391; batch adversarial loss: 0.490035\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416112; batch adversarial loss: 0.571230\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407699; batch adversarial loss: 0.591456\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390240; batch adversarial loss: 0.599387\n",
      "epoch 70; iter: 0; batch classifier loss: 0.495437; batch adversarial loss: 0.586236\n",
      "epoch 71; iter: 0; batch classifier loss: 0.439918; batch adversarial loss: 0.548880\n",
      "epoch 72; iter: 0; batch classifier loss: 0.328163; batch adversarial loss: 0.495985\n",
      "epoch 73; iter: 0; batch classifier loss: 0.456795; batch adversarial loss: 0.499359\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391078; batch adversarial loss: 0.505060\n",
      "epoch 75; iter: 0; batch classifier loss: 0.437794; batch adversarial loss: 0.508836\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393822; batch adversarial loss: 0.562581\n",
      "epoch 77; iter: 0; batch classifier loss: 0.432742; batch adversarial loss: 0.542932\n",
      "epoch 78; iter: 0; batch classifier loss: 0.433634; batch adversarial loss: 0.599318\n",
      "epoch 79; iter: 0; batch classifier loss: 0.308581; batch adversarial loss: 0.453234\n",
      "epoch 80; iter: 0; batch classifier loss: 0.433382; batch adversarial loss: 0.581551\n",
      "epoch 81; iter: 0; batch classifier loss: 0.357050; batch adversarial loss: 0.573643\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400432; batch adversarial loss: 0.507707\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374712; batch adversarial loss: 0.553048\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434858; batch adversarial loss: 0.522787\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376550; batch adversarial loss: 0.552498\n",
      "epoch 86; iter: 0; batch classifier loss: 0.316964; batch adversarial loss: 0.519401\n",
      "epoch 87; iter: 0; batch classifier loss: 0.477939; batch adversarial loss: 0.625012\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400098; batch adversarial loss: 0.528218\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361581; batch adversarial loss: 0.509252\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371426; batch adversarial loss: 0.497105\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375923; batch adversarial loss: 0.535563\n",
      "epoch 92; iter: 0; batch classifier loss: 0.345589; batch adversarial loss: 0.525352\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381091; batch adversarial loss: 0.610222\n",
      "epoch 94; iter: 0; batch classifier loss: 0.462596; batch adversarial loss: 0.496749\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419999; batch adversarial loss: 0.580399\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414820; batch adversarial loss: 0.470443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.349121; batch adversarial loss: 0.525457\n",
      "epoch 98; iter: 0; batch classifier loss: 0.345760; batch adversarial loss: 0.635369\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381246; batch adversarial loss: 0.581614\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429492; batch adversarial loss: 0.535969\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402015; batch adversarial loss: 0.601257\n",
      "epoch 102; iter: 0; batch classifier loss: 0.387953; batch adversarial loss: 0.591194\n",
      "epoch 103; iter: 0; batch classifier loss: 0.304267; batch adversarial loss: 0.572891\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415248; batch adversarial loss: 0.563235\n",
      "epoch 105; iter: 0; batch classifier loss: 0.425722; batch adversarial loss: 0.600046\n",
      "epoch 106; iter: 0; batch classifier loss: 0.399763; batch adversarial loss: 0.626949\n",
      "epoch 107; iter: 0; batch classifier loss: 0.471484; batch adversarial loss: 0.526181\n",
      "epoch 108; iter: 0; batch classifier loss: 0.452580; batch adversarial loss: 0.616478\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357778; batch adversarial loss: 0.579111\n",
      "epoch 110; iter: 0; batch classifier loss: 0.475610; batch adversarial loss: 0.536563\n",
      "epoch 111; iter: 0; batch classifier loss: 0.327911; batch adversarial loss: 0.552168\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374990; batch adversarial loss: 0.597619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345363; batch adversarial loss: 0.606947\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377570; batch adversarial loss: 0.543658\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445618; batch adversarial loss: 0.613580\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371425; batch adversarial loss: 0.536895\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426345; batch adversarial loss: 0.516029\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367099; batch adversarial loss: 0.644345\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366115; batch adversarial loss: 0.544040\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352729; batch adversarial loss: 0.490040\n",
      "epoch 121; iter: 0; batch classifier loss: 0.472391; batch adversarial loss: 0.569288\n",
      "epoch 122; iter: 0; batch classifier loss: 0.393144; batch adversarial loss: 0.595748\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366872; batch adversarial loss: 0.577352\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378249; batch adversarial loss: 0.556236\n",
      "epoch 125; iter: 0; batch classifier loss: 0.341546; batch adversarial loss: 0.545677\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384627; batch adversarial loss: 0.505472\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354809; batch adversarial loss: 0.500029\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411366; batch adversarial loss: 0.582009\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354454; batch adversarial loss: 0.535085\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406634; batch adversarial loss: 0.506519\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380016; batch adversarial loss: 0.498244\n",
      "epoch 132; iter: 0; batch classifier loss: 0.435659; batch adversarial loss: 0.525002\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343725; batch adversarial loss: 0.525074\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390658; batch adversarial loss: 0.560712\n",
      "epoch 135; iter: 0; batch classifier loss: 0.329152; batch adversarial loss: 0.497667\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343446; batch adversarial loss: 0.570729\n",
      "epoch 137; iter: 0; batch classifier loss: 0.419855; batch adversarial loss: 0.556123\n",
      "epoch 138; iter: 0; batch classifier loss: 0.286080; batch adversarial loss: 0.564501\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352187; batch adversarial loss: 0.544970\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413696; batch adversarial loss: 0.497967\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381549; batch adversarial loss: 0.480903\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417687; batch adversarial loss: 0.526310\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330977; batch adversarial loss: 0.561747\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351127; batch adversarial loss: 0.526513\n",
      "epoch 145; iter: 0; batch classifier loss: 0.378045; batch adversarial loss: 0.498165\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317929; batch adversarial loss: 0.498749\n",
      "epoch 147; iter: 0; batch classifier loss: 0.325807; batch adversarial loss: 0.507339\n",
      "epoch 148; iter: 0; batch classifier loss: 0.427974; batch adversarial loss: 0.508353\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387407; batch adversarial loss: 0.517209\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342203; batch adversarial loss: 0.508490\n",
      "epoch 151; iter: 0; batch classifier loss: 0.333789; batch adversarial loss: 0.508309\n",
      "epoch 152; iter: 0; batch classifier loss: 0.404880; batch adversarial loss: 0.562207\n",
      "epoch 153; iter: 0; batch classifier loss: 0.401330; batch adversarial loss: 0.609974\n",
      "epoch 154; iter: 0; batch classifier loss: 0.326864; batch adversarial loss: 0.553202\n",
      "epoch 155; iter: 0; batch classifier loss: 0.297796; batch adversarial loss: 0.579773\n",
      "epoch 156; iter: 0; batch classifier loss: 0.429616; batch adversarial loss: 0.516137\n",
      "epoch 157; iter: 0; batch classifier loss: 0.438904; batch adversarial loss: 0.591718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330741; batch adversarial loss: 0.572792\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349154; batch adversarial loss: 0.560554\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335133; batch adversarial loss: 0.532760\n",
      "epoch 161; iter: 0; batch classifier loss: 0.426694; batch adversarial loss: 0.606678\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390259; batch adversarial loss: 0.572627\n",
      "epoch 163; iter: 0; batch classifier loss: 0.302904; batch adversarial loss: 0.506431\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344472; batch adversarial loss: 0.612962\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358683; batch adversarial loss: 0.522861\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354001; batch adversarial loss: 0.508389\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323260; batch adversarial loss: 0.560857\n",
      "epoch 168; iter: 0; batch classifier loss: 0.278546; batch adversarial loss: 0.499124\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350981; batch adversarial loss: 0.553193\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388700; batch adversarial loss: 0.506354\n",
      "epoch 171; iter: 0; batch classifier loss: 0.453366; batch adversarial loss: 0.573326\n",
      "epoch 172; iter: 0; batch classifier loss: 0.475610; batch adversarial loss: 0.552001\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337080; batch adversarial loss: 0.527998\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310998; batch adversarial loss: 0.535813\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330944; batch adversarial loss: 0.491023\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382632; batch adversarial loss: 0.555199\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340133; batch adversarial loss: 0.535183\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344297; batch adversarial loss: 0.655078\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344314; batch adversarial loss: 0.560286\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334154; batch adversarial loss: 0.551786\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397587; batch adversarial loss: 0.580624\n",
      "epoch 182; iter: 0; batch classifier loss: 0.347335; batch adversarial loss: 0.516857\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315727; batch adversarial loss: 0.534326\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376910; batch adversarial loss: 0.589056\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402963; batch adversarial loss: 0.491558\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373265; batch adversarial loss: 0.608958\n",
      "epoch 187; iter: 0; batch classifier loss: 0.306171; batch adversarial loss: 0.444787\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384544; batch adversarial loss: 0.534859\n",
      "epoch 189; iter: 0; batch classifier loss: 0.277148; batch adversarial loss: 0.570101\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400403; batch adversarial loss: 0.525246\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362855; batch adversarial loss: 0.552699\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298677; batch adversarial loss: 0.554895\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387184; batch adversarial loss: 0.500059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.402544; batch adversarial loss: 0.550618\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350501; batch adversarial loss: 0.464266\n",
      "epoch 196; iter: 0; batch classifier loss: 0.433111; batch adversarial loss: 0.538584\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355163; batch adversarial loss: 0.516978\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387596; batch adversarial loss: 0.589164\n",
      "epoch 199; iter: 0; batch classifier loss: 0.409612; batch adversarial loss: 0.556080\n",
      "epoch 0; iter: 0; batch classifier loss: 1.019020; batch adversarial loss: 0.635591\n",
      "epoch 1; iter: 0; batch classifier loss: 0.660338; batch adversarial loss: 0.627721\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610260; batch adversarial loss: 0.644561\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550890; batch adversarial loss: 0.611552\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610968; batch adversarial loss: 0.595031\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551931; batch adversarial loss: 0.649478\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531869; batch adversarial loss: 0.588349\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553374; batch adversarial loss: 0.586451\n",
      "epoch 8; iter: 0; batch classifier loss: 0.540290; batch adversarial loss: 0.604468\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587391; batch adversarial loss: 0.555305\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554035; batch adversarial loss: 0.615375\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553295; batch adversarial loss: 0.531175\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523341; batch adversarial loss: 0.598070\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542233; batch adversarial loss: 0.601482\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508865; batch adversarial loss: 0.550711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.601956; batch adversarial loss: 0.637437\n",
      "epoch 16; iter: 0; batch classifier loss: 0.466462; batch adversarial loss: 0.556068\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508675; batch adversarial loss: 0.492418\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472284; batch adversarial loss: 0.571851\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527422; batch adversarial loss: 0.590129\n",
      "epoch 20; iter: 0; batch classifier loss: 0.580047; batch adversarial loss: 0.575536\n",
      "epoch 21; iter: 0; batch classifier loss: 0.461877; batch adversarial loss: 0.621774\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512775; batch adversarial loss: 0.542444\n",
      "epoch 23; iter: 0; batch classifier loss: 0.535829; batch adversarial loss: 0.560217\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509706; batch adversarial loss: 0.483325\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531811; batch adversarial loss: 0.548027\n",
      "epoch 26; iter: 0; batch classifier loss: 0.525248; batch adversarial loss: 0.587726\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499908; batch adversarial loss: 0.512675\n",
      "epoch 28; iter: 0; batch classifier loss: 0.401103; batch adversarial loss: 0.570488\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492807; batch adversarial loss: 0.545445\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476871; batch adversarial loss: 0.588600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550058; batch adversarial loss: 0.475880\n",
      "epoch 32; iter: 0; batch classifier loss: 0.543733; batch adversarial loss: 0.483878\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433335; batch adversarial loss: 0.475969\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423923; batch adversarial loss: 0.544014\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422173; batch adversarial loss: 0.561887\n",
      "epoch 36; iter: 0; batch classifier loss: 0.531538; batch adversarial loss: 0.551942\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458758; batch adversarial loss: 0.508651\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480429; batch adversarial loss: 0.512325\n",
      "epoch 39; iter: 0; batch classifier loss: 0.516639; batch adversarial loss: 0.519224\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507969; batch adversarial loss: 0.483708\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472375; batch adversarial loss: 0.524565\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449259; batch adversarial loss: 0.480926\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478720; batch adversarial loss: 0.473698\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463778; batch adversarial loss: 0.565019\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455276; batch adversarial loss: 0.507717\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440237; batch adversarial loss: 0.516216\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473886; batch adversarial loss: 0.563836\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437277; batch adversarial loss: 0.496901\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462521; batch adversarial loss: 0.449859\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460246; batch adversarial loss: 0.488410\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442757; batch adversarial loss: 0.545397\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427870; batch adversarial loss: 0.544021\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443195; batch adversarial loss: 0.535200\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429143; batch adversarial loss: 0.553637\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377562; batch adversarial loss: 0.524960\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428057; batch adversarial loss: 0.552692\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415681; batch adversarial loss: 0.562986\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400742; batch adversarial loss: 0.616121\n",
      "epoch 59; iter: 0; batch classifier loss: 0.342480; batch adversarial loss: 0.534536\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395640; batch adversarial loss: 0.487596\n",
      "epoch 61; iter: 0; batch classifier loss: 0.357402; batch adversarial loss: 0.564308\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444690; batch adversarial loss: 0.553472\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408085; batch adversarial loss: 0.555033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.351698; batch adversarial loss: 0.509674\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414541; batch adversarial loss: 0.507982\n",
      "epoch 66; iter: 0; batch classifier loss: 0.479780; batch adversarial loss: 0.461100\n",
      "epoch 67; iter: 0; batch classifier loss: 0.463103; batch adversarial loss: 0.517923\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447115; batch adversarial loss: 0.571644\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422392; batch adversarial loss: 0.573119\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382159; batch adversarial loss: 0.558527\n",
      "epoch 71; iter: 0; batch classifier loss: 0.442963; batch adversarial loss: 0.508052\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392917; batch adversarial loss: 0.537033\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437661; batch adversarial loss: 0.516328\n",
      "epoch 74; iter: 0; batch classifier loss: 0.347029; batch adversarial loss: 0.536548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382953; batch adversarial loss: 0.564007\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391278; batch adversarial loss: 0.522965\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360477; batch adversarial loss: 0.535558\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359703; batch adversarial loss: 0.490654\n",
      "epoch 79; iter: 0; batch classifier loss: 0.455982; batch adversarial loss: 0.526390\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356452; batch adversarial loss: 0.581794\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410378; batch adversarial loss: 0.519140\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342945; batch adversarial loss: 0.505402\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405454; batch adversarial loss: 0.533437\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370635; batch adversarial loss: 0.562692\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360873; batch adversarial loss: 0.587755\n",
      "epoch 86; iter: 0; batch classifier loss: 0.437470; batch adversarial loss: 0.560637\n",
      "epoch 87; iter: 0; batch classifier loss: 0.426119; batch adversarial loss: 0.561230\n",
      "epoch 88; iter: 0; batch classifier loss: 0.453646; batch adversarial loss: 0.487573\n",
      "epoch 89; iter: 0; batch classifier loss: 0.487428; batch adversarial loss: 0.496799\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428363; batch adversarial loss: 0.539300\n",
      "epoch 91; iter: 0; batch classifier loss: 0.368388; batch adversarial loss: 0.568548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.444832; batch adversarial loss: 0.538475\n",
      "epoch 93; iter: 0; batch classifier loss: 0.416416; batch adversarial loss: 0.523616\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384041; batch adversarial loss: 0.664213\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430591; batch adversarial loss: 0.555002\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438408; batch adversarial loss: 0.546358\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446596; batch adversarial loss: 0.579788\n",
      "epoch 98; iter: 0; batch classifier loss: 0.346754; batch adversarial loss: 0.533552\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359491; batch adversarial loss: 0.546171\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358096; batch adversarial loss: 0.563385\n",
      "epoch 101; iter: 0; batch classifier loss: 0.404577; batch adversarial loss: 0.492745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.422563; batch adversarial loss: 0.536443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.338357; batch adversarial loss: 0.528398\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369455; batch adversarial loss: 0.497519\n",
      "epoch 105; iter: 0; batch classifier loss: 0.318075; batch adversarial loss: 0.471043\n",
      "epoch 106; iter: 0; batch classifier loss: 0.466781; batch adversarial loss: 0.589706\n",
      "epoch 107; iter: 0; batch classifier loss: 0.444318; batch adversarial loss: 0.543436\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352260; batch adversarial loss: 0.572156\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400718; batch adversarial loss: 0.546060\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388540; batch adversarial loss: 0.535811\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394899; batch adversarial loss: 0.480463\n",
      "epoch 112; iter: 0; batch classifier loss: 0.432858; batch adversarial loss: 0.524489\n",
      "epoch 113; iter: 0; batch classifier loss: 0.444340; batch adversarial loss: 0.585132\n",
      "epoch 114; iter: 0; batch classifier loss: 0.503141; batch adversarial loss: 0.602926\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435412; batch adversarial loss: 0.468709\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346201; batch adversarial loss: 0.570593\n",
      "epoch 117; iter: 0; batch classifier loss: 0.395117; batch adversarial loss: 0.526671\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410156; batch adversarial loss: 0.517083\n",
      "epoch 119; iter: 0; batch classifier loss: 0.361168; batch adversarial loss: 0.524439\n",
      "epoch 120; iter: 0; batch classifier loss: 0.417852; batch adversarial loss: 0.518546\n",
      "epoch 121; iter: 0; batch classifier loss: 0.431459; batch adversarial loss: 0.545647\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366501; batch adversarial loss: 0.663290\n",
      "epoch 123; iter: 0; batch classifier loss: 0.466732; batch adversarial loss: 0.545009\n",
      "epoch 124; iter: 0; batch classifier loss: 0.437094; batch adversarial loss: 0.559477\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380515; batch adversarial loss: 0.543959\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358526; batch adversarial loss: 0.479818\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368360; batch adversarial loss: 0.571318\n",
      "epoch 128; iter: 0; batch classifier loss: 0.435588; batch adversarial loss: 0.571062\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398848; batch adversarial loss: 0.556082\n",
      "epoch 130; iter: 0; batch classifier loss: 0.420211; batch adversarial loss: 0.486916\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383409; batch adversarial loss: 0.563721\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313686; batch adversarial loss: 0.577758\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358536; batch adversarial loss: 0.526429\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339552; batch adversarial loss: 0.562132\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370091; batch adversarial loss: 0.601236\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364529; batch adversarial loss: 0.570256\n",
      "epoch 137; iter: 0; batch classifier loss: 0.361945; batch adversarial loss: 0.514011\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358424; batch adversarial loss: 0.481050\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333853; batch adversarial loss: 0.531625\n",
      "epoch 140; iter: 0; batch classifier loss: 0.424197; batch adversarial loss: 0.580915\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338829; batch adversarial loss: 0.488879\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376504; batch adversarial loss: 0.575347\n",
      "epoch 143; iter: 0; batch classifier loss: 0.344542; batch adversarial loss: 0.590243\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370920; batch adversarial loss: 0.572960\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341138; batch adversarial loss: 0.599324\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395592; batch adversarial loss: 0.494575\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339893; batch adversarial loss: 0.570968\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331541; batch adversarial loss: 0.514073\n",
      "epoch 149; iter: 0; batch classifier loss: 0.436338; batch adversarial loss: 0.524996\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392066; batch adversarial loss: 0.633699\n",
      "epoch 151; iter: 0; batch classifier loss: 0.438176; batch adversarial loss: 0.491814\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369608; batch adversarial loss: 0.570647\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345663; batch adversarial loss: 0.576220\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317361; batch adversarial loss: 0.515739\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365214; batch adversarial loss: 0.579438\n",
      "epoch 156; iter: 0; batch classifier loss: 0.315862; batch adversarial loss: 0.601182\n",
      "epoch 157; iter: 0; batch classifier loss: 0.380246; batch adversarial loss: 0.558542\n",
      "epoch 158; iter: 0; batch classifier loss: 0.450150; batch adversarial loss: 0.574726\n",
      "epoch 159; iter: 0; batch classifier loss: 0.439271; batch adversarial loss: 0.619082\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405384; batch adversarial loss: 0.507188\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343271; batch adversarial loss: 0.543613\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329338; batch adversarial loss: 0.498090\n",
      "epoch 163; iter: 0; batch classifier loss: 0.317452; batch adversarial loss: 0.543641\n",
      "epoch 164; iter: 0; batch classifier loss: 0.315765; batch adversarial loss: 0.495513\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357498; batch adversarial loss: 0.452499\n",
      "epoch 166; iter: 0; batch classifier loss: 0.418482; batch adversarial loss: 0.506219\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344580; batch adversarial loss: 0.558091\n",
      "epoch 168; iter: 0; batch classifier loss: 0.437003; batch adversarial loss: 0.537933\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324878; batch adversarial loss: 0.443385\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341419; batch adversarial loss: 0.481447\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395153; batch adversarial loss: 0.545502\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389735; batch adversarial loss: 0.478176\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322068; batch adversarial loss: 0.541411\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424527; batch adversarial loss: 0.514572\n",
      "epoch 175; iter: 0; batch classifier loss: 0.391432; batch adversarial loss: 0.581670\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377534; batch adversarial loss: 0.544895\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406224; batch adversarial loss: 0.507869\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.532980\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407096; batch adversarial loss: 0.525588\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396422; batch adversarial loss: 0.565032\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315211; batch adversarial loss: 0.582491\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340536; batch adversarial loss: 0.553368\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330701; batch adversarial loss: 0.585454\n",
      "epoch 184; iter: 0; batch classifier loss: 0.333670; batch adversarial loss: 0.599895\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338615; batch adversarial loss: 0.555271\n",
      "epoch 186; iter: 0; batch classifier loss: 0.426894; batch adversarial loss: 0.489087\n",
      "epoch 187; iter: 0; batch classifier loss: 0.301345; batch adversarial loss: 0.599924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.364034; batch adversarial loss: 0.523982\n",
      "epoch 189; iter: 0; batch classifier loss: 0.349976; batch adversarial loss: 0.521690\n",
      "epoch 190; iter: 0; batch classifier loss: 0.414656; batch adversarial loss: 0.585532\n",
      "epoch 191; iter: 0; batch classifier loss: 0.450560; batch adversarial loss: 0.549835\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381132; batch adversarial loss: 0.523743\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342285; batch adversarial loss: 0.554179\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404261; batch adversarial loss: 0.496932\n",
      "epoch 195; iter: 0; batch classifier loss: 0.416203; batch adversarial loss: 0.513345\n",
      "epoch 196; iter: 0; batch classifier loss: 0.414408; batch adversarial loss: 0.525002\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366521; batch adversarial loss: 0.524724\n",
      "epoch 198; iter: 0; batch classifier loss: 0.394098; batch adversarial loss: 0.620189\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393971; batch adversarial loss: 0.568814\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713846; batch adversarial loss: 0.679389\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615806; batch adversarial loss: 0.666220\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595012; batch adversarial loss: 0.649089\n",
      "epoch 3; iter: 0; batch classifier loss: 0.509157; batch adversarial loss: 0.619611\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547791; batch adversarial loss: 0.624406\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538817; batch adversarial loss: 0.602290\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564118; batch adversarial loss: 0.622415\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530859; batch adversarial loss: 0.593838\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507695; batch adversarial loss: 0.620825\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503541; batch adversarial loss: 0.609298\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560998; batch adversarial loss: 0.591890\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544951; batch adversarial loss: 0.589033\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504448; batch adversarial loss: 0.553905\n",
      "epoch 13; iter: 0; batch classifier loss: 0.442406; batch adversarial loss: 0.546910\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573136; batch adversarial loss: 0.589652\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484259; batch adversarial loss: 0.583590\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522014; batch adversarial loss: 0.543039\n",
      "epoch 17; iter: 0; batch classifier loss: 0.475001; batch adversarial loss: 0.566960\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539008; batch adversarial loss: 0.551716\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474474; batch adversarial loss: 0.528242\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484970; batch adversarial loss: 0.543603\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512915; batch adversarial loss: 0.594295\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423465; batch adversarial loss: 0.503769\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511692; batch adversarial loss: 0.551345\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482414; batch adversarial loss: 0.500891\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473358; batch adversarial loss: 0.483851\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468723; batch adversarial loss: 0.577997\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511161; batch adversarial loss: 0.548401\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514431; batch adversarial loss: 0.603605\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474107; batch adversarial loss: 0.552480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459552; batch adversarial loss: 0.536321\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489387; batch adversarial loss: 0.537526\n",
      "epoch 32; iter: 0; batch classifier loss: 0.611878; batch adversarial loss: 0.545571\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462721; batch adversarial loss: 0.570984\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417856; batch adversarial loss: 0.587817\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435851; batch adversarial loss: 0.570979\n",
      "epoch 36; iter: 0; batch classifier loss: 0.412635; batch adversarial loss: 0.561657\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412523; batch adversarial loss: 0.587382\n",
      "epoch 38; iter: 0; batch classifier loss: 0.515583; batch adversarial loss: 0.607169\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442561; batch adversarial loss: 0.552959\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420545; batch adversarial loss: 0.628589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476307; batch adversarial loss: 0.586947\n",
      "epoch 42; iter: 0; batch classifier loss: 0.527203; batch adversarial loss: 0.534231\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395038; batch adversarial loss: 0.572114\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415342; batch adversarial loss: 0.589201\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425901; batch adversarial loss: 0.428868\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381298; batch adversarial loss: 0.517422\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413048; batch adversarial loss: 0.543177\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411111; batch adversarial loss: 0.474426\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424868; batch adversarial loss: 0.597131\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498864; batch adversarial loss: 0.533360\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382371; batch adversarial loss: 0.553286\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445908; batch adversarial loss: 0.510419\n",
      "epoch 53; iter: 0; batch classifier loss: 0.361657; batch adversarial loss: 0.585165\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460526; batch adversarial loss: 0.494768\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476251; batch adversarial loss: 0.594625\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431709; batch adversarial loss: 0.572022\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411128; batch adversarial loss: 0.601135\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440573; batch adversarial loss: 0.544735\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375458; batch adversarial loss: 0.571923\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413368; batch adversarial loss: 0.564298\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397751; batch adversarial loss: 0.517271\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386251; batch adversarial loss: 0.581694\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421968; batch adversarial loss: 0.507150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421777; batch adversarial loss: 0.543370\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381456; batch adversarial loss: 0.534524\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438702; batch adversarial loss: 0.527899\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394643; batch adversarial loss: 0.644392\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418162; batch adversarial loss: 0.489283\n",
      "epoch 69; iter: 0; batch classifier loss: 0.344615; batch adversarial loss: 0.534261\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392903; batch adversarial loss: 0.517628\n",
      "epoch 71; iter: 0; batch classifier loss: 0.347470; batch adversarial loss: 0.526313\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413928; batch adversarial loss: 0.572744\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425931; batch adversarial loss: 0.552968\n",
      "epoch 74; iter: 0; batch classifier loss: 0.375983; batch adversarial loss: 0.569496\n",
      "epoch 75; iter: 0; batch classifier loss: 0.548567; batch adversarial loss: 0.650158\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358876; batch adversarial loss: 0.555420\n",
      "epoch 77; iter: 0; batch classifier loss: 0.465099; batch adversarial loss: 0.561772\n",
      "epoch 78; iter: 0; batch classifier loss: 0.306120; batch adversarial loss: 0.597203\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376495; batch adversarial loss: 0.585477\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455344; batch adversarial loss: 0.509850\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405253; batch adversarial loss: 0.682667\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379775; batch adversarial loss: 0.599569\n",
      "epoch 83; iter: 0; batch classifier loss: 0.311466; batch adversarial loss: 0.525635\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395448; batch adversarial loss: 0.508197\n",
      "epoch 85; iter: 0; batch classifier loss: 0.451274; batch adversarial loss: 0.543761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.427762; batch adversarial loss: 0.593421\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423715; batch adversarial loss: 0.552374\n",
      "epoch 88; iter: 0; batch classifier loss: 0.454890; batch adversarial loss: 0.579017\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396092; batch adversarial loss: 0.507374\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362007; batch adversarial loss: 0.552771\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439655; batch adversarial loss: 0.538892\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348935; batch adversarial loss: 0.534786\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352133; batch adversarial loss: 0.613683\n",
      "epoch 94; iter: 0; batch classifier loss: 0.393682; batch adversarial loss: 0.492532\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368473; batch adversarial loss: 0.598427\n",
      "epoch 96; iter: 0; batch classifier loss: 0.450765; batch adversarial loss: 0.571155\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410130; batch adversarial loss: 0.608320\n",
      "epoch 98; iter: 0; batch classifier loss: 0.429257; batch adversarial loss: 0.576109\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356726; batch adversarial loss: 0.584644\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357234; batch adversarial loss: 0.535842\n",
      "epoch 101; iter: 0; batch classifier loss: 0.330698; batch adversarial loss: 0.510191\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404729; batch adversarial loss: 0.534178\n",
      "epoch 103; iter: 0; batch classifier loss: 0.464153; batch adversarial loss: 0.566897\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397906; batch adversarial loss: 0.534063\n",
      "epoch 105; iter: 0; batch classifier loss: 0.326492; batch adversarial loss: 0.588862\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379727; batch adversarial loss: 0.609170\n",
      "epoch 107; iter: 0; batch classifier loss: 0.383167; batch adversarial loss: 0.584843\n",
      "epoch 108; iter: 0; batch classifier loss: 0.490831; batch adversarial loss: 0.545316\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381751; batch adversarial loss: 0.555555\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407702; batch adversarial loss: 0.542370\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379733; batch adversarial loss: 0.595753\n",
      "epoch 112; iter: 0; batch classifier loss: 0.445349; batch adversarial loss: 0.544362\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417443; batch adversarial loss: 0.592278\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391869; batch adversarial loss: 0.583429\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346659; batch adversarial loss: 0.499782\n",
      "epoch 116; iter: 0; batch classifier loss: 0.397464; batch adversarial loss: 0.616967\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365386; batch adversarial loss: 0.498270\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406714; batch adversarial loss: 0.599443\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425466; batch adversarial loss: 0.578876\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395456; batch adversarial loss: 0.553881\n",
      "epoch 121; iter: 0; batch classifier loss: 0.332837; batch adversarial loss: 0.606632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343573; batch adversarial loss: 0.483629\n",
      "epoch 123; iter: 0; batch classifier loss: 0.441175; batch adversarial loss: 0.623333\n",
      "epoch 124; iter: 0; batch classifier loss: 0.480090; batch adversarial loss: 0.547471\n",
      "epoch 125; iter: 0; batch classifier loss: 0.288578; batch adversarial loss: 0.582667\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413622; batch adversarial loss: 0.530269\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358177; batch adversarial loss: 0.572866\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404179; batch adversarial loss: 0.492375\n",
      "epoch 129; iter: 0; batch classifier loss: 0.418692; batch adversarial loss: 0.533062\n",
      "epoch 130; iter: 0; batch classifier loss: 0.444110; batch adversarial loss: 0.629897\n",
      "epoch 131; iter: 0; batch classifier loss: 0.410967; batch adversarial loss: 0.588241\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390446; batch adversarial loss: 0.538766\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408172; batch adversarial loss: 0.506795\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415583; batch adversarial loss: 0.521191\n",
      "epoch 135; iter: 0; batch classifier loss: 0.301228; batch adversarial loss: 0.550508\n",
      "epoch 136; iter: 0; batch classifier loss: 0.308293; batch adversarial loss: 0.553348\n",
      "epoch 137; iter: 0; batch classifier loss: 0.319428; batch adversarial loss: 0.502009\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314019; batch adversarial loss: 0.527185\n",
      "epoch 139; iter: 0; batch classifier loss: 0.348166; batch adversarial loss: 0.576566\n",
      "epoch 140; iter: 0; batch classifier loss: 0.418399; batch adversarial loss: 0.525491\n",
      "epoch 141; iter: 0; batch classifier loss: 0.303330; batch adversarial loss: 0.563477\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386812; batch adversarial loss: 0.518133\n",
      "epoch 143; iter: 0; batch classifier loss: 0.494689; batch adversarial loss: 0.569593\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339381; batch adversarial loss: 0.633482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.441285; batch adversarial loss: 0.532996\n",
      "epoch 146; iter: 0; batch classifier loss: 0.310839; batch adversarial loss: 0.562512\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303395; batch adversarial loss: 0.589203\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374331; batch adversarial loss: 0.522756\n",
      "epoch 149; iter: 0; batch classifier loss: 0.414358; batch adversarial loss: 0.633849\n",
      "epoch 150; iter: 0; batch classifier loss: 0.449145; batch adversarial loss: 0.554463\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322029; batch adversarial loss: 0.519792\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344462; batch adversarial loss: 0.544332\n",
      "epoch 153; iter: 0; batch classifier loss: 0.448793; batch adversarial loss: 0.606739\n",
      "epoch 154; iter: 0; batch classifier loss: 0.459958; batch adversarial loss: 0.565545\n",
      "epoch 155; iter: 0; batch classifier loss: 0.311505; batch adversarial loss: 0.535900\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339860; batch adversarial loss: 0.635389\n",
      "epoch 157; iter: 0; batch classifier loss: 0.320682; batch adversarial loss: 0.606714\n",
      "epoch 158; iter: 0; batch classifier loss: 0.444686; batch adversarial loss: 0.498622\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383284; batch adversarial loss: 0.573059\n",
      "epoch 160; iter: 0; batch classifier loss: 0.312312; batch adversarial loss: 0.551067\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335997; batch adversarial loss: 0.606392\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349446; batch adversarial loss: 0.582411\n",
      "epoch 163; iter: 0; batch classifier loss: 0.371733; batch adversarial loss: 0.543844\n",
      "epoch 164; iter: 0; batch classifier loss: 0.298057; batch adversarial loss: 0.526300\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380396; batch adversarial loss: 0.650585\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350143; batch adversarial loss: 0.526429\n",
      "epoch 167; iter: 0; batch classifier loss: 0.408635; batch adversarial loss: 0.580070\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390436; batch adversarial loss: 0.507477\n",
      "epoch 169; iter: 0; batch classifier loss: 0.456224; batch adversarial loss: 0.527398\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354285; batch adversarial loss: 0.562912\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348727; batch adversarial loss: 0.669768\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343637; batch adversarial loss: 0.582583\n",
      "epoch 173; iter: 0; batch classifier loss: 0.424567; batch adversarial loss: 0.455763\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364554; batch adversarial loss: 0.544311\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338488; batch adversarial loss: 0.518238\n",
      "epoch 176; iter: 0; batch classifier loss: 0.419432; batch adversarial loss: 0.473712\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387739; batch adversarial loss: 0.519068\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393894; batch adversarial loss: 0.599892\n",
      "epoch 179; iter: 0; batch classifier loss: 0.440403; batch adversarial loss: 0.572969\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369708; batch adversarial loss: 0.553951\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338126; batch adversarial loss: 0.435463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.368149; batch adversarial loss: 0.542449\n",
      "epoch 183; iter: 0; batch classifier loss: 0.268792; batch adversarial loss: 0.572376\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416908; batch adversarial loss: 0.515378\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351735; batch adversarial loss: 0.597435\n",
      "epoch 186; iter: 0; batch classifier loss: 0.427368; batch adversarial loss: 0.498425\n",
      "epoch 187; iter: 0; batch classifier loss: 0.295363; batch adversarial loss: 0.614689\n",
      "epoch 188; iter: 0; batch classifier loss: 0.421058; batch adversarial loss: 0.535133\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327307; batch adversarial loss: 0.500993\n",
      "epoch 190; iter: 0; batch classifier loss: 0.424326; batch adversarial loss: 0.490845\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350318; batch adversarial loss: 0.452913\n",
      "epoch 192; iter: 0; batch classifier loss: 0.459347; batch adversarial loss: 0.483223\n",
      "epoch 193; iter: 0; batch classifier loss: 0.290871; batch adversarial loss: 0.614182\n",
      "epoch 194; iter: 0; batch classifier loss: 0.370473; batch adversarial loss: 0.600231\n",
      "epoch 195; iter: 0; batch classifier loss: 0.386053; batch adversarial loss: 0.462033\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341709; batch adversarial loss: 0.542375\n",
      "epoch 197; iter: 0; batch classifier loss: 0.302990; batch adversarial loss: 0.573260\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358236; batch adversarial loss: 0.500476\n",
      "epoch 199; iter: 0; batch classifier loss: 0.417672; batch adversarial loss: 0.488254\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687006; batch adversarial loss: 0.610684\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598182; batch adversarial loss: 0.653502\n",
      "epoch 2; iter: 0; batch classifier loss: 0.568761; batch adversarial loss: 0.653768\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629973; batch adversarial loss: 0.630245\n",
      "epoch 4; iter: 0; batch classifier loss: 0.657991; batch adversarial loss: 0.657895\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544739; batch adversarial loss: 0.672548\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543462; batch adversarial loss: 0.584864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519092; batch adversarial loss: 0.569467\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576494; batch adversarial loss: 0.607901\n",
      "epoch 9; iter: 0; batch classifier loss: 0.622312; batch adversarial loss: 0.629511\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536193; batch adversarial loss: 0.588080\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495866; batch adversarial loss: 0.565210\n",
      "epoch 12; iter: 0; batch classifier loss: 0.415980; batch adversarial loss: 0.529555\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559332; batch adversarial loss: 0.638222\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529861; batch adversarial loss: 0.523527\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483051; batch adversarial loss: 0.533173\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523876; batch adversarial loss: 0.535396\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465249; batch adversarial loss: 0.574113\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492600; batch adversarial loss: 0.561645\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504654; batch adversarial loss: 0.543043\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534272; batch adversarial loss: 0.556669\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522127; batch adversarial loss: 0.581152\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452397; batch adversarial loss: 0.499107\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481329; batch adversarial loss: 0.619404\n",
      "epoch 24; iter: 0; batch classifier loss: 0.532836; batch adversarial loss: 0.594459\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486692; batch adversarial loss: 0.554340\n",
      "epoch 26; iter: 0; batch classifier loss: 0.431950; batch adversarial loss: 0.530699\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460619; batch adversarial loss: 0.516775\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482179; batch adversarial loss: 0.580819\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496288; batch adversarial loss: 0.595265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471430; batch adversarial loss: 0.586465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422906; batch adversarial loss: 0.477215\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471288; batch adversarial loss: 0.580407\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523392; batch adversarial loss: 0.572134\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426493; batch adversarial loss: 0.511161\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437684; batch adversarial loss: 0.588417\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477276; batch adversarial loss: 0.572146\n",
      "epoch 37; iter: 0; batch classifier loss: 0.490921; batch adversarial loss: 0.570239\n",
      "epoch 38; iter: 0; batch classifier loss: 0.379958; batch adversarial loss: 0.607269\n",
      "epoch 39; iter: 0; batch classifier loss: 0.389638; batch adversarial loss: 0.543769\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418852; batch adversarial loss: 0.553932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456786; batch adversarial loss: 0.553829\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420696; batch adversarial loss: 0.507315\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439896; batch adversarial loss: 0.571858\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441915; batch adversarial loss: 0.580987\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423960; batch adversarial loss: 0.589223\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367869; batch adversarial loss: 0.580993\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426937; batch adversarial loss: 0.507734\n",
      "epoch 48; iter: 0; batch classifier loss: 0.496047; batch adversarial loss: 0.526677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457857; batch adversarial loss: 0.543109\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443828; batch adversarial loss: 0.535049\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482779; batch adversarial loss: 0.518313\n",
      "epoch 52; iter: 0; batch classifier loss: 0.367348; batch adversarial loss: 0.563211\n",
      "epoch 53; iter: 0; batch classifier loss: 0.416829; batch adversarial loss: 0.579899\n",
      "epoch 54; iter: 0; batch classifier loss: 0.401185; batch adversarial loss: 0.570993\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461046; batch adversarial loss: 0.562524\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387975; batch adversarial loss: 0.562438\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448526; batch adversarial loss: 0.571459\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429694; batch adversarial loss: 0.553825\n",
      "epoch 59; iter: 0; batch classifier loss: 0.494714; batch adversarial loss: 0.499451\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405747; batch adversarial loss: 0.625371\n",
      "epoch 61; iter: 0; batch classifier loss: 0.347173; batch adversarial loss: 0.580682\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415892; batch adversarial loss: 0.517385\n",
      "epoch 63; iter: 0; batch classifier loss: 0.525002; batch adversarial loss: 0.643461\n",
      "epoch 64; iter: 0; batch classifier loss: 0.333400; batch adversarial loss: 0.518052\n",
      "epoch 65; iter: 0; batch classifier loss: 0.486937; batch adversarial loss: 0.508329\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425995; batch adversarial loss: 0.562830\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358858; batch adversarial loss: 0.526130\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390417; batch adversarial loss: 0.580796\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420681; batch adversarial loss: 0.518090\n",
      "epoch 70; iter: 0; batch classifier loss: 0.326627; batch adversarial loss: 0.526196\n",
      "epoch 71; iter: 0; batch classifier loss: 0.507821; batch adversarial loss: 0.508471\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432171; batch adversarial loss: 0.500266\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445033; batch adversarial loss: 0.536277\n",
      "epoch 74; iter: 0; batch classifier loss: 0.458349; batch adversarial loss: 0.526163\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385832; batch adversarial loss: 0.598586\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416939; batch adversarial loss: 0.562521\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412678; batch adversarial loss: 0.598236\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424593; batch adversarial loss: 0.589708\n",
      "epoch 79; iter: 0; batch classifier loss: 0.336467; batch adversarial loss: 0.589231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.462435; batch adversarial loss: 0.526600\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400529; batch adversarial loss: 0.589432\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398244; batch adversarial loss: 0.526811\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373522; batch adversarial loss: 0.544868\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372199; batch adversarial loss: 0.554207\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412035; batch adversarial loss: 0.545170\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.534286\n",
      "epoch 87; iter: 0; batch classifier loss: 0.359611; batch adversarial loss: 0.598553\n",
      "epoch 88; iter: 0; batch classifier loss: 0.292042; batch adversarial loss: 0.490848\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436941; batch adversarial loss: 0.453563\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373753; batch adversarial loss: 0.554700\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361846; batch adversarial loss: 0.572763\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403840; batch adversarial loss: 0.580493\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405603; batch adversarial loss: 0.535497\n",
      "epoch 94; iter: 0; batch classifier loss: 0.463318; batch adversarial loss: 0.580083\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428257; batch adversarial loss: 0.526551\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391642; batch adversarial loss: 0.500228\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359561; batch adversarial loss: 0.562396\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385126; batch adversarial loss: 0.554402\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364196; batch adversarial loss: 0.536626\n",
      "epoch 100; iter: 0; batch classifier loss: 0.291019; batch adversarial loss: 0.553951\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357271; batch adversarial loss: 0.615689\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353924; batch adversarial loss: 0.526840\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360349; batch adversarial loss: 0.571918\n",
      "epoch 104; iter: 0; batch classifier loss: 0.451400; batch adversarial loss: 0.499160\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408511; batch adversarial loss: 0.661390\n",
      "epoch 106; iter: 0; batch classifier loss: 0.392648; batch adversarial loss: 0.516882\n",
      "epoch 107; iter: 0; batch classifier loss: 0.390798; batch adversarial loss: 0.598529\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395865; batch adversarial loss: 0.500525\n",
      "epoch 109; iter: 0; batch classifier loss: 0.343606; batch adversarial loss: 0.498134\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356175; batch adversarial loss: 0.543714\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385925; batch adversarial loss: 0.499688\n",
      "epoch 112; iter: 0; batch classifier loss: 0.343175; batch adversarial loss: 0.644486\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366799; batch adversarial loss: 0.480677\n",
      "epoch 114; iter: 0; batch classifier loss: 0.332817; batch adversarial loss: 0.517490\n",
      "epoch 115; iter: 0; batch classifier loss: 0.353753; batch adversarial loss: 0.572399\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420840; batch adversarial loss: 0.544480\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409352; batch adversarial loss: 0.562696\n",
      "epoch 118; iter: 0; batch classifier loss: 0.334706; batch adversarial loss: 0.590521\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353584; batch adversarial loss: 0.534662\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350839; batch adversarial loss: 0.536150\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380951; batch adversarial loss: 0.642758\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410528; batch adversarial loss: 0.581023\n",
      "epoch 123; iter: 0; batch classifier loss: 0.426666; batch adversarial loss: 0.517385\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323720; batch adversarial loss: 0.491174\n",
      "epoch 125; iter: 0; batch classifier loss: 0.305716; batch adversarial loss: 0.472402\n",
      "epoch 126; iter: 0; batch classifier loss: 0.434089; batch adversarial loss: 0.572609\n",
      "epoch 127; iter: 0; batch classifier loss: 0.436969; batch adversarial loss: 0.545596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369091; batch adversarial loss: 0.489554\n",
      "epoch 129; iter: 0; batch classifier loss: 0.320672; batch adversarial loss: 0.544437\n",
      "epoch 130; iter: 0; batch classifier loss: 0.419654; batch adversarial loss: 0.571708\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398086; batch adversarial loss: 0.517464\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364984; batch adversarial loss: 0.527439\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361991; batch adversarial loss: 0.525759\n",
      "epoch 134; iter: 0; batch classifier loss: 0.452742; batch adversarial loss: 0.570776\n",
      "epoch 135; iter: 0; batch classifier loss: 0.310117; batch adversarial loss: 0.544635\n",
      "epoch 136; iter: 0; batch classifier loss: 0.429267; batch adversarial loss: 0.588896\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347631; batch adversarial loss: 0.554860\n",
      "epoch 138; iter: 0; batch classifier loss: 0.428716; batch adversarial loss: 0.517780\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365544; batch adversarial loss: 0.524894\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379266; batch adversarial loss: 0.526412\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395220; batch adversarial loss: 0.554277\n",
      "epoch 142; iter: 0; batch classifier loss: 0.462832; batch adversarial loss: 0.552678\n",
      "epoch 143; iter: 0; batch classifier loss: 0.432861; batch adversarial loss: 0.508059\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357201; batch adversarial loss: 0.560764\n",
      "epoch 145; iter: 0; batch classifier loss: 0.317415; batch adversarial loss: 0.518446\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366994; batch adversarial loss: 0.655062\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340067; batch adversarial loss: 0.500590\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345964; batch adversarial loss: 0.579877\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367183; batch adversarial loss: 0.555197\n",
      "epoch 150; iter: 0; batch classifier loss: 0.309775; batch adversarial loss: 0.553404\n",
      "epoch 151; iter: 0; batch classifier loss: 0.453763; batch adversarial loss: 0.536354\n",
      "epoch 152; iter: 0; batch classifier loss: 0.513925; batch adversarial loss: 0.554008\n",
      "epoch 153; iter: 0; batch classifier loss: 0.341592; batch adversarial loss: 0.541915\n",
      "epoch 154; iter: 0; batch classifier loss: 0.318054; batch adversarial loss: 0.571932\n",
      "epoch 155; iter: 0; batch classifier loss: 0.470103; batch adversarial loss: 0.518110\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363682; batch adversarial loss: 0.479340\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403025; batch adversarial loss: 0.480702\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368700; batch adversarial loss: 0.517148\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382973; batch adversarial loss: 0.516838\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370722; batch adversarial loss: 0.598447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399226; batch adversarial loss: 0.508819\n",
      "epoch 162; iter: 0; batch classifier loss: 0.382223; batch adversarial loss: 0.578166\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355290; batch adversarial loss: 0.641700\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389901; batch adversarial loss: 0.544335\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375956; batch adversarial loss: 0.588085\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361285; batch adversarial loss: 0.616028\n",
      "epoch 167; iter: 0; batch classifier loss: 0.315159; batch adversarial loss: 0.517504\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376485; batch adversarial loss: 0.626208\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322567; batch adversarial loss: 0.633911\n",
      "epoch 170; iter: 0; batch classifier loss: 0.474648; batch adversarial loss: 0.590149\n",
      "epoch 171; iter: 0; batch classifier loss: 0.395443; batch adversarial loss: 0.607476\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351084; batch adversarial loss: 0.634259\n",
      "epoch 173; iter: 0; batch classifier loss: 0.399346; batch adversarial loss: 0.544441\n",
      "epoch 174; iter: 0; batch classifier loss: 0.251694; batch adversarial loss: 0.490896\n",
      "epoch 175; iter: 0; batch classifier loss: 0.305586; batch adversarial loss: 0.554221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.419028; batch adversarial loss: 0.562541\n",
      "epoch 177; iter: 0; batch classifier loss: 0.332860; batch adversarial loss: 0.542363\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379120; batch adversarial loss: 0.580067\n",
      "epoch 179; iter: 0; batch classifier loss: 0.261843; batch adversarial loss: 0.554010\n",
      "epoch 180; iter: 0; batch classifier loss: 0.349196; batch adversarial loss: 0.463043\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357483; batch adversarial loss: 0.580489\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382843; batch adversarial loss: 0.588712\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332233; batch adversarial loss: 0.563180\n",
      "epoch 184; iter: 0; batch classifier loss: 0.316542; batch adversarial loss: 0.563054\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316722; batch adversarial loss: 0.551599\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385758; batch adversarial loss: 0.516607\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369649; batch adversarial loss: 0.463396\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329841; batch adversarial loss: 0.481191\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352849; batch adversarial loss: 0.570418\n",
      "epoch 190; iter: 0; batch classifier loss: 0.283678; batch adversarial loss: 0.508563\n",
      "epoch 191; iter: 0; batch classifier loss: 0.283156; batch adversarial loss: 0.579756\n",
      "epoch 192; iter: 0; batch classifier loss: 0.322842; batch adversarial loss: 0.498934\n",
      "epoch 193; iter: 0; batch classifier loss: 0.409884; batch adversarial loss: 0.543594\n",
      "epoch 194; iter: 0; batch classifier loss: 0.389853; batch adversarial loss: 0.554993\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390639; batch adversarial loss: 0.581736\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394025; batch adversarial loss: 0.598089\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365758; batch adversarial loss: 0.554290\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317065; batch adversarial loss: 0.562886\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371143; batch adversarial loss: 0.536676\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723041; batch adversarial loss: 0.595788\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572930; batch adversarial loss: 0.642208\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576388; batch adversarial loss: 0.636639\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624670; batch adversarial loss: 0.589435\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518075; batch adversarial loss: 0.608235\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564530; batch adversarial loss: 0.665600\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561117; batch adversarial loss: 0.571849\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506310; batch adversarial loss: 0.637232\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588928; batch adversarial loss: 0.625670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502411; batch adversarial loss: 0.578026\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556341; batch adversarial loss: 0.615960\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530339; batch adversarial loss: 0.610390\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534173; batch adversarial loss: 0.573739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567346; batch adversarial loss: 0.523363\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543479; batch adversarial loss: 0.576079\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540316; batch adversarial loss: 0.590333\n",
      "epoch 16; iter: 0; batch classifier loss: 0.458748; batch adversarial loss: 0.532714\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521580; batch adversarial loss: 0.532843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504494; batch adversarial loss: 0.619566\n",
      "epoch 19; iter: 0; batch classifier loss: 0.416450; batch adversarial loss: 0.519911\n",
      "epoch 20; iter: 0; batch classifier loss: 0.458931; batch adversarial loss: 0.543170\n",
      "epoch 21; iter: 0; batch classifier loss: 0.570539; batch adversarial loss: 0.514716\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502240; batch adversarial loss: 0.517678\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526981; batch adversarial loss: 0.643609\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518677; batch adversarial loss: 0.639923\n",
      "epoch 25; iter: 0; batch classifier loss: 0.419984; batch adversarial loss: 0.554575\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499934; batch adversarial loss: 0.527628\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446326; batch adversarial loss: 0.596478\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480998; batch adversarial loss: 0.649520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.469756; batch adversarial loss: 0.632733\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480020; batch adversarial loss: 0.596956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.514628; batch adversarial loss: 0.580288\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484180; batch adversarial loss: 0.518088\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422606; batch adversarial loss: 0.491666\n",
      "epoch 34; iter: 0; batch classifier loss: 0.495459; batch adversarial loss: 0.481829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504746; batch adversarial loss: 0.598595\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420603; batch adversarial loss: 0.633928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499068; batch adversarial loss: 0.597568\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406194; batch adversarial loss: 0.508762\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451555; batch adversarial loss: 0.642428\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469124; batch adversarial loss: 0.535472\n",
      "epoch 41; iter: 0; batch classifier loss: 0.513817; batch adversarial loss: 0.588591\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432381; batch adversarial loss: 0.561605\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459773; batch adversarial loss: 0.580270\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499490; batch adversarial loss: 0.563444\n",
      "epoch 45; iter: 0; batch classifier loss: 0.488928; batch adversarial loss: 0.536246\n",
      "epoch 46; iter: 0; batch classifier loss: 0.363487; batch adversarial loss: 0.647361\n",
      "epoch 47; iter: 0; batch classifier loss: 0.474580; batch adversarial loss: 0.572335\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426763; batch adversarial loss: 0.534501\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417221; batch adversarial loss: 0.526458\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438565; batch adversarial loss: 0.618537\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421608; batch adversarial loss: 0.516072\n",
      "epoch 52; iter: 0; batch classifier loss: 0.486590; batch adversarial loss: 0.621679\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404033; batch adversarial loss: 0.487832\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440515; batch adversarial loss: 0.539808\n",
      "epoch 55; iter: 0; batch classifier loss: 0.503400; batch adversarial loss: 0.496780\n",
      "epoch 56; iter: 0; batch classifier loss: 0.358058; batch adversarial loss: 0.557988\n",
      "epoch 57; iter: 0; batch classifier loss: 0.353498; batch adversarial loss: 0.553258\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378801; batch adversarial loss: 0.606498\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415661; batch adversarial loss: 0.527786\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422692; batch adversarial loss: 0.585191\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432499; batch adversarial loss: 0.574828\n",
      "epoch 62; iter: 0; batch classifier loss: 0.366000; batch adversarial loss: 0.568288\n",
      "epoch 63; iter: 0; batch classifier loss: 0.440871; batch adversarial loss: 0.611955\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426654; batch adversarial loss: 0.525950\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455261; batch adversarial loss: 0.544650\n",
      "epoch 66; iter: 0; batch classifier loss: 0.487746; batch adversarial loss: 0.485438\n",
      "epoch 67; iter: 0; batch classifier loss: 0.478882; batch adversarial loss: 0.573484\n",
      "epoch 68; iter: 0; batch classifier loss: 0.370476; batch adversarial loss: 0.647641\n",
      "epoch 69; iter: 0; batch classifier loss: 0.441834; batch adversarial loss: 0.461046\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436296; batch adversarial loss: 0.535976\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429880; batch adversarial loss: 0.488666\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401883; batch adversarial loss: 0.563679\n",
      "epoch 73; iter: 0; batch classifier loss: 0.352252; batch adversarial loss: 0.571633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.403161; batch adversarial loss: 0.644620\n",
      "epoch 75; iter: 0; batch classifier loss: 0.445943; batch adversarial loss: 0.589580\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395836; batch adversarial loss: 0.489234\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399065; batch adversarial loss: 0.497553\n",
      "epoch 78; iter: 0; batch classifier loss: 0.327923; batch adversarial loss: 0.534424\n",
      "epoch 79; iter: 0; batch classifier loss: 0.446186; batch adversarial loss: 0.516123\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402171; batch adversarial loss: 0.517585\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421193; batch adversarial loss: 0.637499\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409490; batch adversarial loss: 0.563230\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420477; batch adversarial loss: 0.461540\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348245; batch adversarial loss: 0.471252\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427271; batch adversarial loss: 0.527524\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379603; batch adversarial loss: 0.582054\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346261; batch adversarial loss: 0.600312\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376081; batch adversarial loss: 0.534394\n",
      "epoch 89; iter: 0; batch classifier loss: 0.463899; batch adversarial loss: 0.590236\n",
      "epoch 90; iter: 0; batch classifier loss: 0.346473; batch adversarial loss: 0.534248\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380686; batch adversarial loss: 0.526586\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375511; batch adversarial loss: 0.535313\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352852; batch adversarial loss: 0.552655\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436256; batch adversarial loss: 0.571982\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345041; batch adversarial loss: 0.599365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384865; batch adversarial loss: 0.590527\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384674; batch adversarial loss: 0.635900\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372309; batch adversarial loss: 0.608412\n",
      "epoch 99; iter: 0; batch classifier loss: 0.478440; batch adversarial loss: 0.629046\n",
      "epoch 100; iter: 0; batch classifier loss: 0.407949; batch adversarial loss: 0.552585\n",
      "epoch 101; iter: 0; batch classifier loss: 0.346025; batch adversarial loss: 0.582514\n",
      "epoch 102; iter: 0; batch classifier loss: 0.438605; batch adversarial loss: 0.452291\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366420; batch adversarial loss: 0.498543\n",
      "epoch 104; iter: 0; batch classifier loss: 0.356144; batch adversarial loss: 0.536775\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359598; batch adversarial loss: 0.571226\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381399; batch adversarial loss: 0.599879\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436990; batch adversarial loss: 0.580721\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367894; batch adversarial loss: 0.443462\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421261; batch adversarial loss: 0.563230\n",
      "epoch 110; iter: 0; batch classifier loss: 0.318829; batch adversarial loss: 0.673364\n",
      "epoch 111; iter: 0; batch classifier loss: 0.425899; batch adversarial loss: 0.580072\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354333; batch adversarial loss: 0.527150\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380760; batch adversarial loss: 0.544929\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385957; batch adversarial loss: 0.478063\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358431; batch adversarial loss: 0.508165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379587; batch adversarial loss: 0.599906\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414102; batch adversarial loss: 0.581749\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376264; batch adversarial loss: 0.592592\n",
      "epoch 119; iter: 0; batch classifier loss: 0.328704; batch adversarial loss: 0.627106\n",
      "epoch 120; iter: 0; batch classifier loss: 0.459628; batch adversarial loss: 0.480361\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412476; batch adversarial loss: 0.553720\n",
      "epoch 122; iter: 0; batch classifier loss: 0.334981; batch adversarial loss: 0.572370\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381266; batch adversarial loss: 0.507695\n",
      "epoch 124; iter: 0; batch classifier loss: 0.320217; batch adversarial loss: 0.507121\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415369; batch adversarial loss: 0.480377\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338191; batch adversarial loss: 0.480512\n",
      "epoch 127; iter: 0; batch classifier loss: 0.409996; batch adversarial loss: 0.497983\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356605; batch adversarial loss: 0.544415\n",
      "epoch 129; iter: 0; batch classifier loss: 0.323245; batch adversarial loss: 0.525813\n",
      "epoch 130; iter: 0; batch classifier loss: 0.344711; batch adversarial loss: 0.542223\n",
      "epoch 131; iter: 0; batch classifier loss: 0.403977; batch adversarial loss: 0.597515\n",
      "epoch 132; iter: 0; batch classifier loss: 0.383554; batch adversarial loss: 0.498883\n",
      "epoch 133; iter: 0; batch classifier loss: 0.316773; batch adversarial loss: 0.562885\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371586; batch adversarial loss: 0.598356\n",
      "epoch 135; iter: 0; batch classifier loss: 0.280949; batch adversarial loss: 0.580252\n",
      "epoch 136; iter: 0; batch classifier loss: 0.445168; batch adversarial loss: 0.515780\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362644; batch adversarial loss: 0.582663\n",
      "epoch 138; iter: 0; batch classifier loss: 0.409499; batch adversarial loss: 0.544098\n",
      "epoch 139; iter: 0; batch classifier loss: 0.319607; batch adversarial loss: 0.525315\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387225; batch adversarial loss: 0.543835\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375426; batch adversarial loss: 0.573034\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404748; batch adversarial loss: 0.528288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.392730; batch adversarial loss: 0.526925\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389039; batch adversarial loss: 0.488153\n",
      "epoch 145; iter: 0; batch classifier loss: 0.490723; batch adversarial loss: 0.624646\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368715; batch adversarial loss: 0.515420\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383575; batch adversarial loss: 0.487029\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351799; batch adversarial loss: 0.415671\n",
      "epoch 149; iter: 0; batch classifier loss: 0.440209; batch adversarial loss: 0.562632\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392282; batch adversarial loss: 0.498298\n",
      "epoch 151; iter: 0; batch classifier loss: 0.388051; batch adversarial loss: 0.554783\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341765; batch adversarial loss: 0.508802\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348940; batch adversarial loss: 0.508602\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385266; batch adversarial loss: 0.526237\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307364; batch adversarial loss: 0.545148\n",
      "epoch 156; iter: 0; batch classifier loss: 0.438682; batch adversarial loss: 0.534550\n",
      "epoch 157; iter: 0; batch classifier loss: 0.398512; batch adversarial loss: 0.536470\n",
      "epoch 158; iter: 0; batch classifier loss: 0.413382; batch adversarial loss: 0.516142\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352258; batch adversarial loss: 0.597815\n",
      "epoch 160; iter: 0; batch classifier loss: 0.281371; batch adversarial loss: 0.571478\n",
      "epoch 161; iter: 0; batch classifier loss: 0.303145; batch adversarial loss: 0.499032\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386437; batch adversarial loss: 0.423895\n",
      "epoch 163; iter: 0; batch classifier loss: 0.304729; batch adversarial loss: 0.562209\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394811; batch adversarial loss: 0.470327\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355888; batch adversarial loss: 0.552891\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361073; batch adversarial loss: 0.543945\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301845; batch adversarial loss: 0.516966\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347499; batch adversarial loss: 0.535430\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380745; batch adversarial loss: 0.471928\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373800; batch adversarial loss: 0.543963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.391391; batch adversarial loss: 0.490127\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395708; batch adversarial loss: 0.552939\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337676; batch adversarial loss: 0.582298\n",
      "epoch 174; iter: 0; batch classifier loss: 0.301524; batch adversarial loss: 0.508905\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375763; batch adversarial loss: 0.534898\n",
      "epoch 176; iter: 0; batch classifier loss: 0.412936; batch adversarial loss: 0.578892\n",
      "epoch 177; iter: 0; batch classifier loss: 0.293017; batch adversarial loss: 0.626320\n",
      "epoch 178; iter: 0; batch classifier loss: 0.399616; batch adversarial loss: 0.490119\n",
      "epoch 179; iter: 0; batch classifier loss: 0.282556; batch adversarial loss: 0.552858\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333288; batch adversarial loss: 0.563589\n",
      "epoch 181; iter: 0; batch classifier loss: 0.462724; batch adversarial loss: 0.682404\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376572; batch adversarial loss: 0.572776\n",
      "epoch 183; iter: 0; batch classifier loss: 0.433211; batch adversarial loss: 0.572724\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339292; batch adversarial loss: 0.610059\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381647; batch adversarial loss: 0.543868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390689; batch adversarial loss: 0.575287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.386630; batch adversarial loss: 0.573294\n",
      "epoch 188; iter: 0; batch classifier loss: 0.320174; batch adversarial loss: 0.526574\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295618; batch adversarial loss: 0.536126\n",
      "epoch 190; iter: 0; batch classifier loss: 0.296069; batch adversarial loss: 0.571764\n",
      "epoch 191; iter: 0; batch classifier loss: 0.318925; batch adversarial loss: 0.526413\n",
      "epoch 192; iter: 0; batch classifier loss: 0.274996; batch adversarial loss: 0.581306\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378665; batch adversarial loss: 0.552539\n",
      "epoch 194; iter: 0; batch classifier loss: 0.389772; batch adversarial loss: 0.588857\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328956; batch adversarial loss: 0.545382\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315414; batch adversarial loss: 0.546438\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351402; batch adversarial loss: 0.526404\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321913; batch adversarial loss: 0.543631\n",
      "epoch 199; iter: 0; batch classifier loss: 0.288013; batch adversarial loss: 0.580874\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705630; batch adversarial loss: 0.701081\n",
      "epoch 1; iter: 0; batch classifier loss: 0.579156; batch adversarial loss: 0.665214\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610656; batch adversarial loss: 0.632085\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516292; batch adversarial loss: 0.635280\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535653; batch adversarial loss: 0.607830\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544540; batch adversarial loss: 0.627921\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539945; batch adversarial loss: 0.608875\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568252; batch adversarial loss: 0.595762\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485966; batch adversarial loss: 0.600874\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523329; batch adversarial loss: 0.578352\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562803; batch adversarial loss: 0.570489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535116; batch adversarial loss: 0.544549\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551220; batch adversarial loss: 0.537776\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550285; batch adversarial loss: 0.511797\n",
      "epoch 14; iter: 0; batch classifier loss: 0.603639; batch adversarial loss: 0.546427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507886; batch adversarial loss: 0.520527\n",
      "epoch 16; iter: 0; batch classifier loss: 0.568196; batch adversarial loss: 0.618639\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546418; batch adversarial loss: 0.535665\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429129; batch adversarial loss: 0.570050\n",
      "epoch 19; iter: 0; batch classifier loss: 0.558636; batch adversarial loss: 0.549194\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499172; batch adversarial loss: 0.645116\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455621; batch adversarial loss: 0.620995\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486712; batch adversarial loss: 0.534385\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522923; batch adversarial loss: 0.494941\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476692; batch adversarial loss: 0.640367\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440056; batch adversarial loss: 0.575288\n",
      "epoch 26; iter: 0; batch classifier loss: 0.530694; batch adversarial loss: 0.613691\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493402; batch adversarial loss: 0.547497\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498805; batch adversarial loss: 0.591074\n",
      "epoch 29; iter: 0; batch classifier loss: 0.586102; batch adversarial loss: 0.509870\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461966; batch adversarial loss: 0.512590\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390089; batch adversarial loss: 0.498388\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472069; batch adversarial loss: 0.584264\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414139; batch adversarial loss: 0.575132\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401281; batch adversarial loss: 0.537208\n",
      "epoch 35; iter: 0; batch classifier loss: 0.506124; batch adversarial loss: 0.537067\n",
      "epoch 36; iter: 0; batch classifier loss: 0.380983; batch adversarial loss: 0.544531\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470156; batch adversarial loss: 0.572078\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454184; batch adversarial loss: 0.518848\n",
      "epoch 39; iter: 0; batch classifier loss: 0.502914; batch adversarial loss: 0.563979\n",
      "epoch 40; iter: 0; batch classifier loss: 0.372131; batch adversarial loss: 0.470155\n",
      "epoch 41; iter: 0; batch classifier loss: 0.495554; batch adversarial loss: 0.580808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505789; batch adversarial loss: 0.609895\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407489; batch adversarial loss: 0.609367\n",
      "epoch 44; iter: 0; batch classifier loss: 0.381576; batch adversarial loss: 0.544272\n",
      "epoch 45; iter: 0; batch classifier loss: 0.497869; batch adversarial loss: 0.619688\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403694; batch adversarial loss: 0.553761\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453109; batch adversarial loss: 0.516328\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465430; batch adversarial loss: 0.460037\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503174; batch adversarial loss: 0.525679\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463240; batch adversarial loss: 0.535178\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417527; batch adversarial loss: 0.535255\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433970; batch adversarial loss: 0.479287\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438752; batch adversarial loss: 0.534909\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442128; batch adversarial loss: 0.563288\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461938; batch adversarial loss: 0.506963\n",
      "epoch 56; iter: 0; batch classifier loss: 0.482516; batch adversarial loss: 0.449433\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418337; batch adversarial loss: 0.489767\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414936; batch adversarial loss: 0.544779\n",
      "epoch 59; iter: 0; batch classifier loss: 0.494275; batch adversarial loss: 0.532305\n",
      "epoch 60; iter: 0; batch classifier loss: 0.458563; batch adversarial loss: 0.556388\n",
      "epoch 61; iter: 0; batch classifier loss: 0.450506; batch adversarial loss: 0.531794\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438813; batch adversarial loss: 0.544636\n",
      "epoch 63; iter: 0; batch classifier loss: 0.348024; batch adversarial loss: 0.478518\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382978; batch adversarial loss: 0.601490\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410646; batch adversarial loss: 0.553630\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453221; batch adversarial loss: 0.488050\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420879; batch adversarial loss: 0.524639\n",
      "epoch 68; iter: 0; batch classifier loss: 0.448481; batch adversarial loss: 0.507679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.395128; batch adversarial loss: 0.515017\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424949; batch adversarial loss: 0.542215\n",
      "epoch 71; iter: 0; batch classifier loss: 0.460013; batch adversarial loss: 0.514212\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396367; batch adversarial loss: 0.543009\n",
      "epoch 73; iter: 0; batch classifier loss: 0.470340; batch adversarial loss: 0.555325\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381433; batch adversarial loss: 0.545497\n",
      "epoch 75; iter: 0; batch classifier loss: 0.474428; batch adversarial loss: 0.581987\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415714; batch adversarial loss: 0.576598\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409268; batch adversarial loss: 0.602734\n",
      "epoch 78; iter: 0; batch classifier loss: 0.475446; batch adversarial loss: 0.478743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362026; batch adversarial loss: 0.546547\n",
      "epoch 80; iter: 0; batch classifier loss: 0.456336; batch adversarial loss: 0.600927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417859; batch adversarial loss: 0.602109\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447815; batch adversarial loss: 0.542121\n",
      "epoch 83; iter: 0; batch classifier loss: 0.343411; batch adversarial loss: 0.515675\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437719; batch adversarial loss: 0.506632\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361705; batch adversarial loss: 0.573897\n",
      "epoch 86; iter: 0; batch classifier loss: 0.366084; batch adversarial loss: 0.584476\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375942; batch adversarial loss: 0.466770\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352218; batch adversarial loss: 0.506334\n",
      "epoch 89; iter: 0; batch classifier loss: 0.347194; batch adversarial loss: 0.554702\n",
      "epoch 90; iter: 0; batch classifier loss: 0.517073; batch adversarial loss: 0.660271\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376453; batch adversarial loss: 0.448041\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392533; batch adversarial loss: 0.602502\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403072; batch adversarial loss: 0.563908\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374313; batch adversarial loss: 0.582932\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361161; batch adversarial loss: 0.629803\n",
      "epoch 96; iter: 0; batch classifier loss: 0.415675; batch adversarial loss: 0.476653\n",
      "epoch 97; iter: 0; batch classifier loss: 0.478732; batch adversarial loss: 0.592303\n",
      "epoch 98; iter: 0; batch classifier loss: 0.441130; batch adversarial loss: 0.552122\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436811; batch adversarial loss: 0.506547\n",
      "epoch 100; iter: 0; batch classifier loss: 0.483264; batch adversarial loss: 0.458630\n",
      "epoch 101; iter: 0; batch classifier loss: 0.432617; batch adversarial loss: 0.573159\n",
      "epoch 102; iter: 0; batch classifier loss: 0.356696; batch adversarial loss: 0.564169\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412008; batch adversarial loss: 0.573244\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364748; batch adversarial loss: 0.477678\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339547; batch adversarial loss: 0.482799\n",
      "epoch 106; iter: 0; batch classifier loss: 0.406392; batch adversarial loss: 0.504527\n",
      "epoch 107; iter: 0; batch classifier loss: 0.398015; batch adversarial loss: 0.458857\n",
      "epoch 108; iter: 0; batch classifier loss: 0.402064; batch adversarial loss: 0.595477\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376696; batch adversarial loss: 0.488226\n",
      "epoch 110; iter: 0; batch classifier loss: 0.485895; batch adversarial loss: 0.574749\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407181; batch adversarial loss: 0.553675\n",
      "epoch 112; iter: 0; batch classifier loss: 0.458749; batch adversarial loss: 0.525275\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389827; batch adversarial loss: 0.524552\n",
      "epoch 114; iter: 0; batch classifier loss: 0.490449; batch adversarial loss: 0.478157\n",
      "epoch 115; iter: 0; batch classifier loss: 0.349424; batch adversarial loss: 0.486407\n",
      "epoch 116; iter: 0; batch classifier loss: 0.473161; batch adversarial loss: 0.566152\n",
      "epoch 117; iter: 0; batch classifier loss: 0.436566; batch adversarial loss: 0.498626\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405603; batch adversarial loss: 0.589698\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338945; batch adversarial loss: 0.573017\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373885; batch adversarial loss: 0.525672\n",
      "epoch 121; iter: 0; batch classifier loss: 0.435458; batch adversarial loss: 0.524042\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352902; batch adversarial loss: 0.591267\n",
      "epoch 123; iter: 0; batch classifier loss: 0.426677; batch adversarial loss: 0.544472\n",
      "epoch 124; iter: 0; batch classifier loss: 0.468895; batch adversarial loss: 0.523274\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387471; batch adversarial loss: 0.508845\n",
      "epoch 126; iter: 0; batch classifier loss: 0.431808; batch adversarial loss: 0.591482\n",
      "epoch 127; iter: 0; batch classifier loss: 0.359389; batch adversarial loss: 0.526684\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422849; batch adversarial loss: 0.486777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413670; batch adversarial loss: 0.582610\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376133; batch adversarial loss: 0.515791\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383197; batch adversarial loss: 0.524994\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358128; batch adversarial loss: 0.582500\n",
      "epoch 133; iter: 0; batch classifier loss: 0.464747; batch adversarial loss: 0.591674\n",
      "epoch 134; iter: 0; batch classifier loss: 0.418278; batch adversarial loss: 0.457289\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349256; batch adversarial loss: 0.487260\n",
      "epoch 136; iter: 0; batch classifier loss: 0.351128; batch adversarial loss: 0.554316\n",
      "epoch 137; iter: 0; batch classifier loss: 0.429019; batch adversarial loss: 0.535034\n",
      "epoch 138; iter: 0; batch classifier loss: 0.398243; batch adversarial loss: 0.535325\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395828; batch adversarial loss: 0.515978\n",
      "epoch 140; iter: 0; batch classifier loss: 0.444428; batch adversarial loss: 0.591289\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422113; batch adversarial loss: 0.523919\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331683; batch adversarial loss: 0.543780\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408664; batch adversarial loss: 0.545497\n",
      "epoch 144; iter: 0; batch classifier loss: 0.324180; batch adversarial loss: 0.582903\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372330; batch adversarial loss: 0.554252\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396131; batch adversarial loss: 0.572460\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394467; batch adversarial loss: 0.544550\n",
      "epoch 148; iter: 0; batch classifier loss: 0.355488; batch adversarial loss: 0.611196\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409065; batch adversarial loss: 0.592982\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385988; batch adversarial loss: 0.486609\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359112; batch adversarial loss: 0.545485\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377880; batch adversarial loss: 0.609395\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383254; batch adversarial loss: 0.460684\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345877; batch adversarial loss: 0.542789\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411181; batch adversarial loss: 0.600385\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390322; batch adversarial loss: 0.514792\n",
      "epoch 157; iter: 0; batch classifier loss: 0.420505; batch adversarial loss: 0.584067\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325725; batch adversarial loss: 0.523742\n",
      "epoch 159; iter: 0; batch classifier loss: 0.416734; batch adversarial loss: 0.494893\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413814; batch adversarial loss: 0.431203\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383436; batch adversarial loss: 0.478386\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412372; batch adversarial loss: 0.537226\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359762; batch adversarial loss: 0.545173\n",
      "epoch 164; iter: 0; batch classifier loss: 0.417793; batch adversarial loss: 0.479107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.341711; batch adversarial loss: 0.523933\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339038; batch adversarial loss: 0.505833\n",
      "epoch 167; iter: 0; batch classifier loss: 0.282498; batch adversarial loss: 0.553602\n",
      "epoch 168; iter: 0; batch classifier loss: 0.405360; batch adversarial loss: 0.496228\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350262; batch adversarial loss: 0.535142\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326975; batch adversarial loss: 0.545470\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316174; batch adversarial loss: 0.535274\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388037; batch adversarial loss: 0.429369\n",
      "epoch 173; iter: 0; batch classifier loss: 0.368578; batch adversarial loss: 0.496668\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321554; batch adversarial loss: 0.641519\n",
      "epoch 175; iter: 0; batch classifier loss: 0.425414; batch adversarial loss: 0.515514\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366830; batch adversarial loss: 0.497015\n",
      "epoch 177; iter: 0; batch classifier loss: 0.467451; batch adversarial loss: 0.459009\n",
      "epoch 178; iter: 0; batch classifier loss: 0.378172; batch adversarial loss: 0.460649\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341349; batch adversarial loss: 0.582175\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359422; batch adversarial loss: 0.580974\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365250; batch adversarial loss: 0.574459\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394647; batch adversarial loss: 0.534277\n",
      "epoch 183; iter: 0; batch classifier loss: 0.400468; batch adversarial loss: 0.601155\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383910; batch adversarial loss: 0.555031\n",
      "epoch 185; iter: 0; batch classifier loss: 0.413765; batch adversarial loss: 0.592437\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341923; batch adversarial loss: 0.526235\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332087; batch adversarial loss: 0.507627\n",
      "epoch 188; iter: 0; batch classifier loss: 0.422483; batch adversarial loss: 0.611148\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328519; batch adversarial loss: 0.479066\n",
      "epoch 190; iter: 0; batch classifier loss: 0.311361; batch adversarial loss: 0.495350\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373941; batch adversarial loss: 0.651505\n",
      "epoch 192; iter: 0; batch classifier loss: 0.379332; batch adversarial loss: 0.478777\n",
      "epoch 193; iter: 0; batch classifier loss: 0.277483; batch adversarial loss: 0.534487\n",
      "epoch 194; iter: 0; batch classifier loss: 0.323918; batch adversarial loss: 0.593651\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397104; batch adversarial loss: 0.525946\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366237; batch adversarial loss: 0.594380\n",
      "epoch 197; iter: 0; batch classifier loss: 0.316643; batch adversarial loss: 0.570823\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322493; batch adversarial loss: 0.591925\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350988; batch adversarial loss: 0.440828\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712949; batch adversarial loss: 0.810567\n",
      "epoch 1; iter: 0; batch classifier loss: 0.783957; batch adversarial loss: 0.827513\n",
      "epoch 2; iter: 0; batch classifier loss: 0.783726; batch adversarial loss: 0.769295\n",
      "epoch 3; iter: 0; batch classifier loss: 0.686687; batch adversarial loss: 0.694427\n",
      "epoch 4; iter: 0; batch classifier loss: 0.593208; batch adversarial loss: 0.647729\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580801; batch adversarial loss: 0.636241\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597464; batch adversarial loss: 0.641444\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548705; batch adversarial loss: 0.610850\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555303; batch adversarial loss: 0.580864\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496153; batch adversarial loss: 0.636570\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521923; batch adversarial loss: 0.603310\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511553; batch adversarial loss: 0.564022\n",
      "epoch 12; iter: 0; batch classifier loss: 0.431436; batch adversarial loss: 0.591723\n",
      "epoch 13; iter: 0; batch classifier loss: 0.406945; batch adversarial loss: 0.591959\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505044; batch adversarial loss: 0.565224\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494901; batch adversarial loss: 0.611556\n",
      "epoch 16; iter: 0; batch classifier loss: 0.443190; batch adversarial loss: 0.579049\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523464; batch adversarial loss: 0.572906\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528909; batch adversarial loss: 0.563383\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511677; batch adversarial loss: 0.611117\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498059; batch adversarial loss: 0.614136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486438; batch adversarial loss: 0.472767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436189; batch adversarial loss: 0.512245\n",
      "epoch 23; iter: 0; batch classifier loss: 0.386441; batch adversarial loss: 0.562086\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469949; batch adversarial loss: 0.640876\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522742; batch adversarial loss: 0.608069\n",
      "epoch 26; iter: 0; batch classifier loss: 0.565475; batch adversarial loss: 0.533684\n",
      "epoch 27; iter: 0; batch classifier loss: 0.559217; batch adversarial loss: 0.534128\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433042; batch adversarial loss: 0.514793\n",
      "epoch 29; iter: 0; batch classifier loss: 0.549253; batch adversarial loss: 0.555098\n",
      "epoch 30; iter: 0; batch classifier loss: 0.507381; batch adversarial loss: 0.586970\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428707; batch adversarial loss: 0.604216\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513538; batch adversarial loss: 0.560949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.410373; batch adversarial loss: 0.540743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401110; batch adversarial loss: 0.506647\n",
      "epoch 35; iter: 0; batch classifier loss: 0.415577; batch adversarial loss: 0.583567\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481271; batch adversarial loss: 0.595817\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407614; batch adversarial loss: 0.574776\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478701; batch adversarial loss: 0.612709\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403122; batch adversarial loss: 0.608065\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396183; batch adversarial loss: 0.580562\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438365; batch adversarial loss: 0.699598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490827; batch adversarial loss: 0.546031\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450512; batch adversarial loss: 0.566985\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418617; batch adversarial loss: 0.579863\n",
      "epoch 45; iter: 0; batch classifier loss: 0.396179; batch adversarial loss: 0.562906\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443969; batch adversarial loss: 0.578922\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441306; batch adversarial loss: 0.580928\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431772; batch adversarial loss: 0.623857\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424730; batch adversarial loss: 0.492210\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408953; batch adversarial loss: 0.483768\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448606; batch adversarial loss: 0.483339\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406968; batch adversarial loss: 0.482527\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425758; batch adversarial loss: 0.473730\n",
      "epoch 54; iter: 0; batch classifier loss: 0.482029; batch adversarial loss: 0.561520\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478871; batch adversarial loss: 0.588361\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428384; batch adversarial loss: 0.580134\n",
      "epoch 57; iter: 0; batch classifier loss: 0.485819; batch adversarial loss: 0.570285\n",
      "epoch 58; iter: 0; batch classifier loss: 0.385701; batch adversarial loss: 0.622527\n",
      "epoch 59; iter: 0; batch classifier loss: 0.437821; batch adversarial loss: 0.518190\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390161; batch adversarial loss: 0.616974\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391382; batch adversarial loss: 0.578387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.389135; batch adversarial loss: 0.481996\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401907; batch adversarial loss: 0.517344\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460575; batch adversarial loss: 0.516990\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424203; batch adversarial loss: 0.587277\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420919; batch adversarial loss: 0.537511\n",
      "epoch 67; iter: 0; batch classifier loss: 0.476255; batch adversarial loss: 0.544799\n",
      "epoch 68; iter: 0; batch classifier loss: 0.484028; batch adversarial loss: 0.525064\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406725; batch adversarial loss: 0.499390\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359513; batch adversarial loss: 0.556440\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381138; batch adversarial loss: 0.455913\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444851; batch adversarial loss: 0.571297\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446444; batch adversarial loss: 0.510337\n",
      "epoch 74; iter: 0; batch classifier loss: 0.329803; batch adversarial loss: 0.581233\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373625; batch adversarial loss: 0.537405\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402941; batch adversarial loss: 0.561538\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458506; batch adversarial loss: 0.537487\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416437; batch adversarial loss: 0.546217\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379337; batch adversarial loss: 0.589213\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371719; batch adversarial loss: 0.562200\n",
      "epoch 81; iter: 0; batch classifier loss: 0.448463; batch adversarial loss: 0.551446\n",
      "epoch 82; iter: 0; batch classifier loss: 0.346082; batch adversarial loss: 0.592991\n",
      "epoch 83; iter: 0; batch classifier loss: 0.501478; batch adversarial loss: 0.587176\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386165; batch adversarial loss: 0.560514\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410468; batch adversarial loss: 0.507651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400402; batch adversarial loss: 0.516807\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383807; batch adversarial loss: 0.560274\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376703; batch adversarial loss: 0.606049\n",
      "epoch 89; iter: 0; batch classifier loss: 0.459737; batch adversarial loss: 0.498572\n",
      "epoch 90; iter: 0; batch classifier loss: 0.460066; batch adversarial loss: 0.616689\n",
      "epoch 91; iter: 0; batch classifier loss: 0.445354; batch adversarial loss: 0.551398\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368409; batch adversarial loss: 0.591868\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356567; batch adversarial loss: 0.515666\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377681; batch adversarial loss: 0.544633\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362037; batch adversarial loss: 0.501303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380442; batch adversarial loss: 0.510262\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386540; batch adversarial loss: 0.501450\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393714; batch adversarial loss: 0.621439\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399572; batch adversarial loss: 0.652911\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397697; batch adversarial loss: 0.570926\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377616; batch adversarial loss: 0.536195\n",
      "epoch 102; iter: 0; batch classifier loss: 0.446061; batch adversarial loss: 0.525158\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381816; batch adversarial loss: 0.561581\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363988; batch adversarial loss: 0.543199\n",
      "epoch 105; iter: 0; batch classifier loss: 0.313408; batch adversarial loss: 0.447505\n",
      "epoch 106; iter: 0; batch classifier loss: 0.435749; batch adversarial loss: 0.535112\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375908; batch adversarial loss: 0.552786\n",
      "epoch 108; iter: 0; batch classifier loss: 0.345321; batch adversarial loss: 0.480220\n",
      "epoch 109; iter: 0; batch classifier loss: 0.390835; batch adversarial loss: 0.571528\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408501; batch adversarial loss: 0.588889\n",
      "epoch 111; iter: 0; batch classifier loss: 0.327288; batch adversarial loss: 0.462635\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435242; batch adversarial loss: 0.544933\n",
      "epoch 113; iter: 0; batch classifier loss: 0.408778; batch adversarial loss: 0.571095\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380714; batch adversarial loss: 0.581847\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404625; batch adversarial loss: 0.545739\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388891; batch adversarial loss: 0.566435\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381348; batch adversarial loss: 0.573902\n",
      "epoch 118; iter: 0; batch classifier loss: 0.454028; batch adversarial loss: 0.563034\n",
      "epoch 119; iter: 0; batch classifier loss: 0.398886; batch adversarial loss: 0.552430\n",
      "epoch 120; iter: 0; batch classifier loss: 0.410720; batch adversarial loss: 0.623063\n",
      "epoch 121; iter: 0; batch classifier loss: 0.300044; batch adversarial loss: 0.586086\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362547; batch adversarial loss: 0.614391\n",
      "epoch 123; iter: 0; batch classifier loss: 0.325798; batch adversarial loss: 0.605983\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375979; batch adversarial loss: 0.599790\n",
      "epoch 125; iter: 0; batch classifier loss: 0.424310; batch adversarial loss: 0.562207\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317896; batch adversarial loss: 0.595875\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362630; batch adversarial loss: 0.562818\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351336; batch adversarial loss: 0.502302\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342384; batch adversarial loss: 0.574724\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343295; batch adversarial loss: 0.616071\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347251; batch adversarial loss: 0.511719\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377252; batch adversarial loss: 0.538344\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370378; batch adversarial loss: 0.596532\n",
      "epoch 134; iter: 0; batch classifier loss: 0.450684; batch adversarial loss: 0.517167\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312007; batch adversarial loss: 0.536780\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405145; batch adversarial loss: 0.535732\n",
      "epoch 137; iter: 0; batch classifier loss: 0.412023; batch adversarial loss: 0.536600\n",
      "epoch 138; iter: 0; batch classifier loss: 0.457051; batch adversarial loss: 0.488455\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349756; batch adversarial loss: 0.545840\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381022; batch adversarial loss: 0.534288\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403634; batch adversarial loss: 0.564366\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370355; batch adversarial loss: 0.597084\n",
      "epoch 143; iter: 0; batch classifier loss: 0.418567; batch adversarial loss: 0.537233\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351683; batch adversarial loss: 0.601253\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385540; batch adversarial loss: 0.654198\n",
      "epoch 146; iter: 0; batch classifier loss: 0.340002; batch adversarial loss: 0.525012\n",
      "epoch 147; iter: 0; batch classifier loss: 0.452973; batch adversarial loss: 0.589450\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353894; batch adversarial loss: 0.448079\n",
      "epoch 149; iter: 0; batch classifier loss: 0.332001; batch adversarial loss: 0.554054\n",
      "epoch 150; iter: 0; batch classifier loss: 0.419747; batch adversarial loss: 0.553217\n",
      "epoch 151; iter: 0; batch classifier loss: 0.420067; batch adversarial loss: 0.516229\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391401; batch adversarial loss: 0.643642\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373725; batch adversarial loss: 0.438400\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401146; batch adversarial loss: 0.526922\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433927; batch adversarial loss: 0.502160\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356683; batch adversarial loss: 0.630457\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331616; batch adversarial loss: 0.605815\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346791; batch adversarial loss: 0.553781\n",
      "epoch 159; iter: 0; batch classifier loss: 0.418315; batch adversarial loss: 0.579822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.377966; batch adversarial loss: 0.564006\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362469; batch adversarial loss: 0.625155\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371047; batch adversarial loss: 0.540226\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346787; batch adversarial loss: 0.536342\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336439; batch adversarial loss: 0.525899\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405455; batch adversarial loss: 0.481440\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346836; batch adversarial loss: 0.437833\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381842; batch adversarial loss: 0.550260\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386762; batch adversarial loss: 0.580528\n",
      "epoch 169; iter: 0; batch classifier loss: 0.416153; batch adversarial loss: 0.614711\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318936; batch adversarial loss: 0.629371\n",
      "epoch 171; iter: 0; batch classifier loss: 0.413376; batch adversarial loss: 0.537707\n",
      "epoch 172; iter: 0; batch classifier loss: 0.305326; batch adversarial loss: 0.570444\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346816; batch adversarial loss: 0.553346\n",
      "epoch 174; iter: 0; batch classifier loss: 0.414561; batch adversarial loss: 0.579448\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360660; batch adversarial loss: 0.574074\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310933; batch adversarial loss: 0.497991\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335572; batch adversarial loss: 0.613221\n",
      "epoch 178; iter: 0; batch classifier loss: 0.291745; batch adversarial loss: 0.523948\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364426; batch adversarial loss: 0.596453\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331404; batch adversarial loss: 0.614434\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336520; batch adversarial loss: 0.553880\n",
      "epoch 182; iter: 0; batch classifier loss: 0.391188; batch adversarial loss: 0.514950\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379010; batch adversarial loss: 0.581184\n",
      "epoch 184; iter: 0; batch classifier loss: 0.269744; batch adversarial loss: 0.513510\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372008; batch adversarial loss: 0.585915\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386083; batch adversarial loss: 0.473641\n",
      "epoch 187; iter: 0; batch classifier loss: 0.301904; batch adversarial loss: 0.652283\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382784; batch adversarial loss: 0.508031\n",
      "epoch 189; iter: 0; batch classifier loss: 0.398281; batch adversarial loss: 0.571550\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322377; batch adversarial loss: 0.482086\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324249; batch adversarial loss: 0.485914\n",
      "epoch 192; iter: 0; batch classifier loss: 0.400715; batch adversarial loss: 0.624675\n",
      "epoch 193; iter: 0; batch classifier loss: 0.436872; batch adversarial loss: 0.596947\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312386; batch adversarial loss: 0.583924\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392135; batch adversarial loss: 0.582462\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286761; batch adversarial loss: 0.570753\n",
      "epoch 197; iter: 0; batch classifier loss: 0.297423; batch adversarial loss: 0.573943\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353386; batch adversarial loss: 0.612859\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396314; batch adversarial loss: 0.579302\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760828; batch adversarial loss: 0.733515\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600232; batch adversarial loss: 0.655763\n",
      "epoch 2; iter: 0; batch classifier loss: 0.568363; batch adversarial loss: 0.657318\n",
      "epoch 3; iter: 0; batch classifier loss: 0.517024; batch adversarial loss: 0.638848\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564241; batch adversarial loss: 0.627830\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540319; batch adversarial loss: 0.606313\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510140; batch adversarial loss: 0.611903\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552763; batch adversarial loss: 0.633600\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557864; batch adversarial loss: 0.587184\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554347; batch adversarial loss: 0.612779\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474634; batch adversarial loss: 0.562496\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491841; batch adversarial loss: 0.545963\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552885; batch adversarial loss: 0.523245\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515720; batch adversarial loss: 0.658458\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559862; batch adversarial loss: 0.543897\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487632; batch adversarial loss: 0.541442\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480715; batch adversarial loss: 0.579878\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546193; batch adversarial loss: 0.547871\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518580; batch adversarial loss: 0.534407\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497401; batch adversarial loss: 0.557174\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434888; batch adversarial loss: 0.627420\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520719; batch adversarial loss: 0.553975\n",
      "epoch 22; iter: 0; batch classifier loss: 0.543390; batch adversarial loss: 0.620495\n",
      "epoch 23; iter: 0; batch classifier loss: 0.448831; batch adversarial loss: 0.564747\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445465; batch adversarial loss: 0.535058\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517703; batch adversarial loss: 0.542366\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467395; batch adversarial loss: 0.629012\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462658; batch adversarial loss: 0.600324\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470133; batch adversarial loss: 0.537686\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441484; batch adversarial loss: 0.497957\n",
      "epoch 30; iter: 0; batch classifier loss: 0.564667; batch adversarial loss: 0.497159\n",
      "epoch 31; iter: 0; batch classifier loss: 0.528687; batch adversarial loss: 0.532595\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433662; batch adversarial loss: 0.558630\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466648; batch adversarial loss: 0.519246\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425899; batch adversarial loss: 0.523837\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457355; batch adversarial loss: 0.533984\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405744; batch adversarial loss: 0.554682\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468142; batch adversarial loss: 0.545520\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460775; batch adversarial loss: 0.613422\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415697; batch adversarial loss: 0.649523\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437444; batch adversarial loss: 0.527731\n",
      "epoch 41; iter: 0; batch classifier loss: 0.405809; batch adversarial loss: 0.544115\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463739; batch adversarial loss: 0.554045\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441699; batch adversarial loss: 0.536992\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433908; batch adversarial loss: 0.580993\n",
      "epoch 45; iter: 0; batch classifier loss: 0.475811; batch adversarial loss: 0.489801\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381560; batch adversarial loss: 0.508458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.519568; batch adversarial loss: 0.451907\n",
      "epoch 48; iter: 0; batch classifier loss: 0.490728; batch adversarial loss: 0.489193\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470020; batch adversarial loss: 0.525794\n",
      "epoch 50; iter: 0; batch classifier loss: 0.506144; batch adversarial loss: 0.498713\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466597; batch adversarial loss: 0.589089\n",
      "epoch 52; iter: 0; batch classifier loss: 0.485709; batch adversarial loss: 0.516430\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423974; batch adversarial loss: 0.495016\n",
      "epoch 54; iter: 0; batch classifier loss: 0.508072; batch adversarial loss: 0.609438\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400420; batch adversarial loss: 0.469964\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431016; batch adversarial loss: 0.469679\n",
      "epoch 57; iter: 0; batch classifier loss: 0.470327; batch adversarial loss: 0.563637\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436299; batch adversarial loss: 0.517024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.436284; batch adversarial loss: 0.471586\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451283; batch adversarial loss: 0.508505\n",
      "epoch 61; iter: 0; batch classifier loss: 0.472834; batch adversarial loss: 0.562922\n",
      "epoch 62; iter: 0; batch classifier loss: 0.361740; batch adversarial loss: 0.562782\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435711; batch adversarial loss: 0.562960\n",
      "epoch 64; iter: 0; batch classifier loss: 0.341183; batch adversarial loss: 0.572508\n",
      "epoch 65; iter: 0; batch classifier loss: 0.463547; batch adversarial loss: 0.525120\n",
      "epoch 66; iter: 0; batch classifier loss: 0.458581; batch adversarial loss: 0.591036\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413983; batch adversarial loss: 0.488419\n",
      "epoch 68; iter: 0; batch classifier loss: 0.466927; batch adversarial loss: 0.517626\n",
      "epoch 69; iter: 0; batch classifier loss: 0.381819; batch adversarial loss: 0.553713\n",
      "epoch 70; iter: 0; batch classifier loss: 0.516353; batch adversarial loss: 0.618214\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396663; batch adversarial loss: 0.599675\n",
      "epoch 72; iter: 0; batch classifier loss: 0.446781; batch adversarial loss: 0.497880\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402538; batch adversarial loss: 0.535253\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411076; batch adversarial loss: 0.562846\n",
      "epoch 75; iter: 0; batch classifier loss: 0.345031; batch adversarial loss: 0.544463\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405177; batch adversarial loss: 0.572502\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427106; batch adversarial loss: 0.442226\n",
      "epoch 78; iter: 0; batch classifier loss: 0.503733; batch adversarial loss: 0.497704\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374485; batch adversarial loss: 0.498203\n",
      "epoch 80; iter: 0; batch classifier loss: 0.404008; batch adversarial loss: 0.516668\n",
      "epoch 81; iter: 0; batch classifier loss: 0.470537; batch adversarial loss: 0.563164\n",
      "epoch 82; iter: 0; batch classifier loss: 0.433286; batch adversarial loss: 0.572433\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398849; batch adversarial loss: 0.487807\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447031; batch adversarial loss: 0.506916\n",
      "epoch 85; iter: 0; batch classifier loss: 0.496314; batch adversarial loss: 0.433246\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387063; batch adversarial loss: 0.507403\n",
      "epoch 87; iter: 0; batch classifier loss: 0.320488; batch adversarial loss: 0.535307\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374513; batch adversarial loss: 0.563129\n",
      "epoch 89; iter: 0; batch classifier loss: 0.439017; batch adversarial loss: 0.534886\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397743; batch adversarial loss: 0.572166\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386389; batch adversarial loss: 0.525691\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450782; batch adversarial loss: 0.526779\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378555; batch adversarial loss: 0.525507\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390962; batch adversarial loss: 0.526224\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431285; batch adversarial loss: 0.525699\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336064; batch adversarial loss: 0.460844\n",
      "epoch 97; iter: 0; batch classifier loss: 0.472986; batch adversarial loss: 0.553622\n",
      "epoch 98; iter: 0; batch classifier loss: 0.300977; batch adversarial loss: 0.618774\n",
      "epoch 99; iter: 0; batch classifier loss: 0.438118; batch adversarial loss: 0.535008\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351668; batch adversarial loss: 0.506941\n",
      "epoch 101; iter: 0; batch classifier loss: 0.451382; batch adversarial loss: 0.581885\n",
      "epoch 102; iter: 0; batch classifier loss: 0.486511; batch adversarial loss: 0.610069\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384182; batch adversarial loss: 0.526089\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354188; batch adversarial loss: 0.590702\n",
      "epoch 105; iter: 0; batch classifier loss: 0.419141; batch adversarial loss: 0.563051\n",
      "epoch 106; iter: 0; batch classifier loss: 0.314898; batch adversarial loss: 0.581989\n",
      "epoch 107; iter: 0; batch classifier loss: 0.445330; batch adversarial loss: 0.609974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.346366; batch adversarial loss: 0.507968\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346217; batch adversarial loss: 0.590771\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377352; batch adversarial loss: 0.562827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379054; batch adversarial loss: 0.516611\n",
      "epoch 112; iter: 0; batch classifier loss: 0.393612; batch adversarial loss: 0.590888\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328050; batch adversarial loss: 0.600203\n",
      "epoch 114; iter: 0; batch classifier loss: 0.313397; batch adversarial loss: 0.637560\n",
      "epoch 115; iter: 0; batch classifier loss: 0.349961; batch adversarial loss: 0.553663\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388672; batch adversarial loss: 0.591031\n",
      "epoch 117; iter: 0; batch classifier loss: 0.453333; batch adversarial loss: 0.461093\n",
      "epoch 118; iter: 0; batch classifier loss: 0.299006; batch adversarial loss: 0.497898\n",
      "epoch 119; iter: 0; batch classifier loss: 0.412786; batch adversarial loss: 0.562982\n",
      "epoch 120; iter: 0; batch classifier loss: 0.476529; batch adversarial loss: 0.544238\n",
      "epoch 121; iter: 0; batch classifier loss: 0.264532; batch adversarial loss: 0.553616\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389625; batch adversarial loss: 0.581741\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368572; batch adversarial loss: 0.479464\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390045; batch adversarial loss: 0.544906\n",
      "epoch 125; iter: 0; batch classifier loss: 0.331809; batch adversarial loss: 0.562940\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346858; batch adversarial loss: 0.562868\n",
      "epoch 127; iter: 0; batch classifier loss: 0.300962; batch adversarial loss: 0.488263\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419425; batch adversarial loss: 0.573730\n",
      "epoch 129; iter: 0; batch classifier loss: 0.454998; batch adversarial loss: 0.609511\n",
      "epoch 130; iter: 0; batch classifier loss: 0.401360; batch adversarial loss: 0.479538\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356201; batch adversarial loss: 0.563107\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364626; batch adversarial loss: 0.507569\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353606; batch adversarial loss: 0.600184\n",
      "epoch 134; iter: 0; batch classifier loss: 0.296068; batch adversarial loss: 0.563006\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362759; batch adversarial loss: 0.553588\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357610; batch adversarial loss: 0.562936\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368862; batch adversarial loss: 0.553038\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362774; batch adversarial loss: 0.572680\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346112; batch adversarial loss: 0.535771\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375694; batch adversarial loss: 0.535086\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395754; batch adversarial loss: 0.636844\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343636; batch adversarial loss: 0.590771\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346520; batch adversarial loss: 0.553863\n",
      "epoch 144; iter: 0; batch classifier loss: 0.301591; batch adversarial loss: 0.525637\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348774; batch adversarial loss: 0.507370\n",
      "epoch 146; iter: 0; batch classifier loss: 0.318824; batch adversarial loss: 0.554529\n",
      "epoch 147; iter: 0; batch classifier loss: 0.465366; batch adversarial loss: 0.609842\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370037; batch adversarial loss: 0.581795\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334414; batch adversarial loss: 0.451540\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348817; batch adversarial loss: 0.582243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.342480; batch adversarial loss: 0.590962\n",
      "epoch 152; iter: 0; batch classifier loss: 0.438742; batch adversarial loss: 0.535317\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389583; batch adversarial loss: 0.553509\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346414; batch adversarial loss: 0.535595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.450045; batch adversarial loss: 0.553666\n",
      "epoch 156; iter: 0; batch classifier loss: 0.323420; batch adversarial loss: 0.552968\n",
      "epoch 157; iter: 0; batch classifier loss: 0.288325; batch adversarial loss: 0.599928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.416389; batch adversarial loss: 0.534594\n",
      "epoch 159; iter: 0; batch classifier loss: 0.365036; batch adversarial loss: 0.554360\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362603; batch adversarial loss: 0.488461\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380335; batch adversarial loss: 0.618086\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383509; batch adversarial loss: 0.656350\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349463; batch adversarial loss: 0.572838\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414902; batch adversarial loss: 0.488709\n",
      "epoch 165; iter: 0; batch classifier loss: 0.413422; batch adversarial loss: 0.591319\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328831; batch adversarial loss: 0.544451\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364559; batch adversarial loss: 0.581423\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330610; batch adversarial loss: 0.498173\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405180; batch adversarial loss: 0.553434\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360206; batch adversarial loss: 0.507020\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385997; batch adversarial loss: 0.534780\n",
      "epoch 172; iter: 0; batch classifier loss: 0.400391; batch adversarial loss: 0.581339\n",
      "epoch 173; iter: 0; batch classifier loss: 0.394649; batch adversarial loss: 0.553801\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355462; batch adversarial loss: 0.534908\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382074; batch adversarial loss: 0.516322\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408390; batch adversarial loss: 0.553517\n",
      "epoch 177; iter: 0; batch classifier loss: 0.400320; batch adversarial loss: 0.516525\n",
      "epoch 178; iter: 0; batch classifier loss: 0.301323; batch adversarial loss: 0.507321\n",
      "epoch 179; iter: 0; batch classifier loss: 0.423961; batch adversarial loss: 0.507342\n",
      "epoch 180; iter: 0; batch classifier loss: 0.431576; batch adversarial loss: 0.591535\n",
      "epoch 181; iter: 0; batch classifier loss: 0.292084; batch adversarial loss: 0.525515\n",
      "epoch 182; iter: 0; batch classifier loss: 0.432209; batch adversarial loss: 0.544955\n",
      "epoch 183; iter: 0; batch classifier loss: 0.434072; batch adversarial loss: 0.470033\n",
      "epoch 184; iter: 0; batch classifier loss: 0.412103; batch adversarial loss: 0.516597\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365064; batch adversarial loss: 0.516710\n",
      "epoch 186; iter: 0; batch classifier loss: 0.310156; batch adversarial loss: 0.516220\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363346; batch adversarial loss: 0.572079\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348232; batch adversarial loss: 0.498058\n",
      "epoch 189; iter: 0; batch classifier loss: 0.324873; batch adversarial loss: 0.581227\n",
      "epoch 190; iter: 0; batch classifier loss: 0.317160; batch adversarial loss: 0.563213\n",
      "epoch 191; iter: 0; batch classifier loss: 0.446743; batch adversarial loss: 0.525791\n",
      "epoch 192; iter: 0; batch classifier loss: 0.390712; batch adversarial loss: 0.526081\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335276; batch adversarial loss: 0.610174\n",
      "epoch 194; iter: 0; batch classifier loss: 0.352764; batch adversarial loss: 0.544392\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397473; batch adversarial loss: 0.571953\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357882; batch adversarial loss: 0.497473\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383330; batch adversarial loss: 0.572362\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372110; batch adversarial loss: 0.507269\n",
      "epoch 199; iter: 0; batch classifier loss: 0.297492; batch adversarial loss: 0.488600\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720117; batch adversarial loss: 0.945772\n",
      "epoch 1; iter: 0; batch classifier loss: 0.696405; batch adversarial loss: 0.936443\n",
      "epoch 2; iter: 0; batch classifier loss: 0.709576; batch adversarial loss: 0.865099\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580127; batch adversarial loss: 0.771893\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543406; batch adversarial loss: 0.753266\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595179; batch adversarial loss: 0.670649\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563147; batch adversarial loss: 0.672979\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516177; batch adversarial loss: 0.684526\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557987; batch adversarial loss: 0.642884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511851; batch adversarial loss: 0.623368\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510229; batch adversarial loss: 0.639977\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590144; batch adversarial loss: 0.620108\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529219; batch adversarial loss: 0.606965\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532490; batch adversarial loss: 0.567968\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520047; batch adversarial loss: 0.552274\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510357; batch adversarial loss: 0.609228\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499080; batch adversarial loss: 0.546966\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534277; batch adversarial loss: 0.588046\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463094; batch adversarial loss: 0.576854\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486510; batch adversarial loss: 0.531992\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527262; batch adversarial loss: 0.602688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.472221; batch adversarial loss: 0.587697\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469658; batch adversarial loss: 0.619356\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531448; batch adversarial loss: 0.553672\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496465; batch adversarial loss: 0.560427\n",
      "epoch 25; iter: 0; batch classifier loss: 0.559726; batch adversarial loss: 0.569559\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463424; batch adversarial loss: 0.593482\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511014; batch adversarial loss: 0.587537\n",
      "epoch 28; iter: 0; batch classifier loss: 0.576405; batch adversarial loss: 0.587516\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467529; batch adversarial loss: 0.516854\n",
      "epoch 30; iter: 0; batch classifier loss: 0.411700; batch adversarial loss: 0.538994\n",
      "epoch 31; iter: 0; batch classifier loss: 0.522062; batch adversarial loss: 0.551600\n",
      "epoch 32; iter: 0; batch classifier loss: 0.556675; batch adversarial loss: 0.531822\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489941; batch adversarial loss: 0.591648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483875; batch adversarial loss: 0.562671\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486639; batch adversarial loss: 0.509362\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424793; batch adversarial loss: 0.562775\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415981; batch adversarial loss: 0.493716\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443754; batch adversarial loss: 0.562112\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501393; batch adversarial loss: 0.495493\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518975; batch adversarial loss: 0.567792\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440624; batch adversarial loss: 0.588706\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419536; batch adversarial loss: 0.547283\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402639; batch adversarial loss: 0.515009\n",
      "epoch 44; iter: 0; batch classifier loss: 0.329510; batch adversarial loss: 0.566037\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420492; batch adversarial loss: 0.513641\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446757; batch adversarial loss: 0.472771\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430347; batch adversarial loss: 0.545736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423156; batch adversarial loss: 0.567319\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419115; batch adversarial loss: 0.520596\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394378; batch adversarial loss: 0.489106\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414251; batch adversarial loss: 0.538719\n",
      "epoch 52; iter: 0; batch classifier loss: 0.454247; batch adversarial loss: 0.531304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.377496; batch adversarial loss: 0.555250\n",
      "epoch 54; iter: 0; batch classifier loss: 0.407205; batch adversarial loss: 0.553391\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395716; batch adversarial loss: 0.470149\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371590; batch adversarial loss: 0.502205\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404097; batch adversarial loss: 0.513869\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414249; batch adversarial loss: 0.560312\n",
      "epoch 59; iter: 0; batch classifier loss: 0.492019; batch adversarial loss: 0.546304\n",
      "epoch 60; iter: 0; batch classifier loss: 0.486894; batch adversarial loss: 0.480534\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394865; batch adversarial loss: 0.524301\n",
      "epoch 62; iter: 0; batch classifier loss: 0.372800; batch adversarial loss: 0.647616\n",
      "epoch 63; iter: 0; batch classifier loss: 0.382960; batch adversarial loss: 0.518504\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439146; batch adversarial loss: 0.570288\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415255; batch adversarial loss: 0.490544\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427090; batch adversarial loss: 0.482243\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395260; batch adversarial loss: 0.553589\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409893; batch adversarial loss: 0.537580\n",
      "epoch 69; iter: 0; batch classifier loss: 0.351303; batch adversarial loss: 0.564169\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427859; batch adversarial loss: 0.490979\n",
      "epoch 71; iter: 0; batch classifier loss: 0.486812; batch adversarial loss: 0.561343\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440081; batch adversarial loss: 0.489441\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429849; batch adversarial loss: 0.506053\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446928; batch adversarial loss: 0.542300\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434316; batch adversarial loss: 0.471280\n",
      "epoch 76; iter: 0; batch classifier loss: 0.504834; batch adversarial loss: 0.541412\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441667; batch adversarial loss: 0.556173\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400180; batch adversarial loss: 0.547406\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462066; batch adversarial loss: 0.508232\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418108; batch adversarial loss: 0.481256\n",
      "epoch 81; iter: 0; batch classifier loss: 0.464625; batch adversarial loss: 0.451298\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441319; batch adversarial loss: 0.528132\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430903; batch adversarial loss: 0.528226\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376102; batch adversarial loss: 0.582502\n",
      "epoch 85; iter: 0; batch classifier loss: 0.418420; batch adversarial loss: 0.572000\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357978; batch adversarial loss: 0.564200\n",
      "epoch 87; iter: 0; batch classifier loss: 0.471261; batch adversarial loss: 0.598335\n",
      "epoch 88; iter: 0; batch classifier loss: 0.332843; batch adversarial loss: 0.616140\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402442; batch adversarial loss: 0.571896\n",
      "epoch 90; iter: 0; batch classifier loss: 0.301746; batch adversarial loss: 0.598074\n",
      "epoch 91; iter: 0; batch classifier loss: 0.547797; batch adversarial loss: 0.528063\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407356; batch adversarial loss: 0.526314\n",
      "epoch 93; iter: 0; batch classifier loss: 0.487067; batch adversarial loss: 0.574805\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431744; batch adversarial loss: 0.572438\n",
      "epoch 95; iter: 0; batch classifier loss: 0.372222; batch adversarial loss: 0.610935\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410932; batch adversarial loss: 0.641362\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350418; batch adversarial loss: 0.582846\n",
      "epoch 98; iter: 0; batch classifier loss: 0.342404; batch adversarial loss: 0.617801\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386548; batch adversarial loss: 0.481329\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420801; batch adversarial loss: 0.583089\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400156; batch adversarial loss: 0.535967\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376800; batch adversarial loss: 0.554758\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388977; batch adversarial loss: 0.635921\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391121; batch adversarial loss: 0.536535\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343885; batch adversarial loss: 0.564134\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434029; batch adversarial loss: 0.590463\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404453; batch adversarial loss: 0.500414\n",
      "epoch 108; iter: 0; batch classifier loss: 0.498326; batch adversarial loss: 0.515583\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413684; batch adversarial loss: 0.544088\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402749; batch adversarial loss: 0.536681\n",
      "epoch 111; iter: 0; batch classifier loss: 0.473966; batch adversarial loss: 0.571805\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386821; batch adversarial loss: 0.536919\n",
      "epoch 113; iter: 0; batch classifier loss: 0.330443; batch adversarial loss: 0.562539\n",
      "epoch 114; iter: 0; batch classifier loss: 0.310523; batch adversarial loss: 0.480353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358582; batch adversarial loss: 0.479456\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417801; batch adversarial loss: 0.496579\n",
      "epoch 117; iter: 0; batch classifier loss: 0.424600; batch adversarial loss: 0.577326\n",
      "epoch 118; iter: 0; batch classifier loss: 0.437937; batch adversarial loss: 0.569412\n",
      "epoch 119; iter: 0; batch classifier loss: 0.336487; batch adversarial loss: 0.506776\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408001; batch adversarial loss: 0.581170\n",
      "epoch 121; iter: 0; batch classifier loss: 0.438095; batch adversarial loss: 0.538070\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343378; batch adversarial loss: 0.628234\n",
      "epoch 123; iter: 0; batch classifier loss: 0.507563; batch adversarial loss: 0.528343\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381496; batch adversarial loss: 0.525168\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383737; batch adversarial loss: 0.424794\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376467; batch adversarial loss: 0.559577\n",
      "epoch 127; iter: 0; batch classifier loss: 0.310264; batch adversarial loss: 0.502693\n",
      "epoch 128; iter: 0; batch classifier loss: 0.444903; batch adversarial loss: 0.462865\n",
      "epoch 129; iter: 0; batch classifier loss: 0.382968; batch adversarial loss: 0.490207\n",
      "epoch 130; iter: 0; batch classifier loss: 0.417822; batch adversarial loss: 0.573474\n",
      "epoch 131; iter: 0; batch classifier loss: 0.378671; batch adversarial loss: 0.587932\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377833; batch adversarial loss: 0.483976\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342197; batch adversarial loss: 0.543237\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361925; batch adversarial loss: 0.536205\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411797; batch adversarial loss: 0.461693\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358475; batch adversarial loss: 0.535751\n",
      "epoch 137; iter: 0; batch classifier loss: 0.311465; batch adversarial loss: 0.565360\n",
      "epoch 138; iter: 0; batch classifier loss: 0.411795; batch adversarial loss: 0.537830\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328555; batch adversarial loss: 0.581342\n",
      "epoch 140; iter: 0; batch classifier loss: 0.279377; batch adversarial loss: 0.551479\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369315; batch adversarial loss: 0.652742\n",
      "epoch 142; iter: 0; batch classifier loss: 0.426109; batch adversarial loss: 0.662331\n",
      "epoch 143; iter: 0; batch classifier loss: 0.447532; batch adversarial loss: 0.505948\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310649; batch adversarial loss: 0.497857\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352405; batch adversarial loss: 0.561146\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343074; batch adversarial loss: 0.520273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334232; batch adversarial loss: 0.555803\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368999; batch adversarial loss: 0.571620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.367789; batch adversarial loss: 0.582434\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378037; batch adversarial loss: 0.633793\n",
      "epoch 151; iter: 0; batch classifier loss: 0.431054; batch adversarial loss: 0.513633\n",
      "epoch 152; iter: 0; batch classifier loss: 0.298702; batch adversarial loss: 0.540921\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354932; batch adversarial loss: 0.522515\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319844; batch adversarial loss: 0.470087\n",
      "epoch 155; iter: 0; batch classifier loss: 0.422611; batch adversarial loss: 0.592121\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404043; batch adversarial loss: 0.543808\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352568; batch adversarial loss: 0.581725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398042; batch adversarial loss: 0.485686\n",
      "epoch 159; iter: 0; batch classifier loss: 0.336712; batch adversarial loss: 0.571442\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364850; batch adversarial loss: 0.479733\n",
      "epoch 161; iter: 0; batch classifier loss: 0.321786; batch adversarial loss: 0.550639\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380364; batch adversarial loss: 0.536300\n",
      "epoch 163; iter: 0; batch classifier loss: 0.328963; batch adversarial loss: 0.535355\n",
      "epoch 164; iter: 0; batch classifier loss: 0.424468; batch adversarial loss: 0.599230\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380031; batch adversarial loss: 0.548998\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344520; batch adversarial loss: 0.543483\n",
      "epoch 167; iter: 0; batch classifier loss: 0.402316; batch adversarial loss: 0.535932\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352439; batch adversarial loss: 0.598874\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362922; batch adversarial loss: 0.495623\n",
      "epoch 170; iter: 0; batch classifier loss: 0.340619; batch adversarial loss: 0.651977\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349937; batch adversarial loss: 0.559745\n",
      "epoch 172; iter: 0; batch classifier loss: 0.432976; batch adversarial loss: 0.589454\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381886; batch adversarial loss: 0.533680\n",
      "epoch 174; iter: 0; batch classifier loss: 0.430911; batch adversarial loss: 0.553692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.408102; batch adversarial loss: 0.527887\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362261; batch adversarial loss: 0.465343\n",
      "epoch 177; iter: 0; batch classifier loss: 0.441986; batch adversarial loss: 0.527161\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347506; batch adversarial loss: 0.515804\n",
      "epoch 179; iter: 0; batch classifier loss: 0.498337; batch adversarial loss: 0.636406\n",
      "epoch 180; iter: 0; batch classifier loss: 0.434299; batch adversarial loss: 0.513891\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365678; batch adversarial loss: 0.549092\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322404; batch adversarial loss: 0.559168\n",
      "epoch 183; iter: 0; batch classifier loss: 0.449870; batch adversarial loss: 0.618274\n",
      "epoch 184; iter: 0; batch classifier loss: 0.417443; batch adversarial loss: 0.517071\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347755; batch adversarial loss: 0.560827\n",
      "epoch 186; iter: 0; batch classifier loss: 0.402199; batch adversarial loss: 0.590356\n",
      "epoch 187; iter: 0; batch classifier loss: 0.441083; batch adversarial loss: 0.512759\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359806; batch adversarial loss: 0.589597\n",
      "epoch 189; iter: 0; batch classifier loss: 0.288445; batch adversarial loss: 0.637002\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331972; batch adversarial loss: 0.508788\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387505; batch adversarial loss: 0.552673\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355426; batch adversarial loss: 0.516054\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313282; batch adversarial loss: 0.534394\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358823; batch adversarial loss: 0.564651\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309995; batch adversarial loss: 0.598586\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336970; batch adversarial loss: 0.599386\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340498; batch adversarial loss: 0.581362\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368623; batch adversarial loss: 0.579422\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348426; batch adversarial loss: 0.590103\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687658; batch adversarial loss: 0.869535\n",
      "epoch 1; iter: 0; batch classifier loss: 0.791114; batch adversarial loss: 1.019017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.858105; batch adversarial loss: 0.942481\n",
      "epoch 3; iter: 0; batch classifier loss: 0.830604; batch adversarial loss: 0.881604\n",
      "epoch 4; iter: 0; batch classifier loss: 0.784569; batch adversarial loss: 0.798518\n",
      "epoch 5; iter: 0; batch classifier loss: 0.721466; batch adversarial loss: 0.738734\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575269; batch adversarial loss: 0.679153\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563541; batch adversarial loss: 0.642360\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554344; batch adversarial loss: 0.618595\n",
      "epoch 9; iter: 0; batch classifier loss: 0.482802; batch adversarial loss: 0.605038\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536273; batch adversarial loss: 0.596060\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520848; batch adversarial loss: 0.564923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552395; batch adversarial loss: 0.575915\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518658; batch adversarial loss: 0.578399\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511252; batch adversarial loss: 0.608999\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534635; batch adversarial loss: 0.584227\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455856; batch adversarial loss: 0.588677\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485544; batch adversarial loss: 0.535869\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458745; batch adversarial loss: 0.551542\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523828; batch adversarial loss: 0.581310\n",
      "epoch 20; iter: 0; batch classifier loss: 0.410265; batch adversarial loss: 0.573783\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490619; batch adversarial loss: 0.515933\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453222; batch adversarial loss: 0.585826\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540467; batch adversarial loss: 0.525645\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463919; batch adversarial loss: 0.539427\n",
      "epoch 25; iter: 0; batch classifier loss: 0.604348; batch adversarial loss: 0.577327\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456712; batch adversarial loss: 0.590956\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517838; batch adversarial loss: 0.541171\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472049; batch adversarial loss: 0.546165\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457752; batch adversarial loss: 0.569393\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474805; batch adversarial loss: 0.528223\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476650; batch adversarial loss: 0.567320\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513232; batch adversarial loss: 0.553328\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446787; batch adversarial loss: 0.525621\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522496; batch adversarial loss: 0.552294\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432528; batch adversarial loss: 0.511519\n",
      "epoch 36; iter: 0; batch classifier loss: 0.517175; batch adversarial loss: 0.508967\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487570; batch adversarial loss: 0.489643\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463601; batch adversarial loss: 0.547561\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414971; batch adversarial loss: 0.507503\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417072; batch adversarial loss: 0.578767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.383905; batch adversarial loss: 0.489725\n",
      "epoch 42; iter: 0; batch classifier loss: 0.379590; batch adversarial loss: 0.521090\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470621; batch adversarial loss: 0.637353\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408920; batch adversarial loss: 0.597996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.455821; batch adversarial loss: 0.570705\n",
      "epoch 46; iter: 0; batch classifier loss: 0.379857; batch adversarial loss: 0.559394\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453135; batch adversarial loss: 0.499354\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443329; batch adversarial loss: 0.528169\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455472; batch adversarial loss: 0.509618\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403545; batch adversarial loss: 0.553466\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442937; batch adversarial loss: 0.525033\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417757; batch adversarial loss: 0.544474\n",
      "epoch 53; iter: 0; batch classifier loss: 0.440536; batch adversarial loss: 0.554037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.470823; batch adversarial loss: 0.499209\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406353; batch adversarial loss: 0.507801\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442520; batch adversarial loss: 0.582192\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448819; batch adversarial loss: 0.493138\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420118; batch adversarial loss: 0.605434\n",
      "epoch 59; iter: 0; batch classifier loss: 0.390188; batch adversarial loss: 0.545796\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373102; batch adversarial loss: 0.554861\n",
      "epoch 61; iter: 0; batch classifier loss: 0.524395; batch adversarial loss: 0.509440\n",
      "epoch 62; iter: 0; batch classifier loss: 0.460611; batch adversarial loss: 0.516597\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423286; batch adversarial loss: 0.591215\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403032; batch adversarial loss: 0.590702\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438609; batch adversarial loss: 0.490124\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406346; batch adversarial loss: 0.582136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351214; batch adversarial loss: 0.544761\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417804; batch adversarial loss: 0.491256\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355465; batch adversarial loss: 0.609941\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387789; batch adversarial loss: 0.547589\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446923; batch adversarial loss: 0.608759\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387116; batch adversarial loss: 0.455176\n",
      "epoch 73; iter: 0; batch classifier loss: 0.449313; batch adversarial loss: 0.526287\n",
      "epoch 74; iter: 0; batch classifier loss: 0.352489; batch adversarial loss: 0.608587\n",
      "epoch 75; iter: 0; batch classifier loss: 0.473068; batch adversarial loss: 0.552365\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366606; batch adversarial loss: 0.588123\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371772; batch adversarial loss: 0.527422\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416876; batch adversarial loss: 0.615309\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357309; batch adversarial loss: 0.571305\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427993; batch adversarial loss: 0.516932\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415184; batch adversarial loss: 0.534357\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400366; batch adversarial loss: 0.599408\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430402; batch adversarial loss: 0.562627\n",
      "epoch 84; iter: 0; batch classifier loss: 0.466154; batch adversarial loss: 0.517391\n",
      "epoch 85; iter: 0; batch classifier loss: 0.337365; batch adversarial loss: 0.473033\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402838; batch adversarial loss: 0.518534\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392584; batch adversarial loss: 0.469937\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369953; batch adversarial loss: 0.572553\n",
      "epoch 89; iter: 0; batch classifier loss: 0.300838; batch adversarial loss: 0.545194\n",
      "epoch 90; iter: 0; batch classifier loss: 0.477269; batch adversarial loss: 0.481274\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363299; batch adversarial loss: 0.564114\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428643; batch adversarial loss: 0.542358\n",
      "epoch 93; iter: 0; batch classifier loss: 0.334497; batch adversarial loss: 0.527014\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430020; batch adversarial loss: 0.568955\n",
      "epoch 95; iter: 0; batch classifier loss: 0.439766; batch adversarial loss: 0.554970\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354330; batch adversarial loss: 0.538764\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385720; batch adversarial loss: 0.625869\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361374; batch adversarial loss: 0.545489\n",
      "epoch 99; iter: 0; batch classifier loss: 0.478444; batch adversarial loss: 0.544989\n",
      "epoch 100; iter: 0; batch classifier loss: 0.461168; batch adversarial loss: 0.498707\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366852; batch adversarial loss: 0.561684\n",
      "epoch 102; iter: 0; batch classifier loss: 0.434922; batch adversarial loss: 0.578726\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409985; batch adversarial loss: 0.554725\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362905; batch adversarial loss: 0.502390\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397562; batch adversarial loss: 0.659797\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407206; batch adversarial loss: 0.446404\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384294; batch adversarial loss: 0.606302\n",
      "epoch 108; iter: 0; batch classifier loss: 0.426184; batch adversarial loss: 0.526890\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375428; batch adversarial loss: 0.498539\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429731; batch adversarial loss: 0.591863\n",
      "epoch 111; iter: 0; batch classifier loss: 0.307259; batch adversarial loss: 0.517901\n",
      "epoch 112; iter: 0; batch classifier loss: 0.304006; batch adversarial loss: 0.538420\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391238; batch adversarial loss: 0.483017\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359310; batch adversarial loss: 0.562122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.356416; batch adversarial loss: 0.534578\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401397; batch adversarial loss: 0.608794\n",
      "epoch 117; iter: 0; batch classifier loss: 0.470236; batch adversarial loss: 0.617716\n",
      "epoch 118; iter: 0; batch classifier loss: 0.466514; batch adversarial loss: 0.589596\n",
      "epoch 119; iter: 0; batch classifier loss: 0.319858; batch adversarial loss: 0.492191\n",
      "epoch 120; iter: 0; batch classifier loss: 0.303609; batch adversarial loss: 0.605284\n",
      "epoch 121; iter: 0; batch classifier loss: 0.473508; batch adversarial loss: 0.560406\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383479; batch adversarial loss: 0.488535\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336388; batch adversarial loss: 0.529120\n",
      "epoch 124; iter: 0; batch classifier loss: 0.284825; batch adversarial loss: 0.589170\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369929; batch adversarial loss: 0.601366\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344814; batch adversarial loss: 0.562428\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366146; batch adversarial loss: 0.517357\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350369; batch adversarial loss: 0.519750\n",
      "epoch 129; iter: 0; batch classifier loss: 0.415177; batch adversarial loss: 0.636961\n",
      "epoch 130; iter: 0; batch classifier loss: 0.418361; batch adversarial loss: 0.544296\n",
      "epoch 131; iter: 0; batch classifier loss: 0.291498; batch adversarial loss: 0.598811\n",
      "epoch 132; iter: 0; batch classifier loss: 0.426943; batch adversarial loss: 0.538381\n",
      "epoch 133; iter: 0; batch classifier loss: 0.422547; batch adversarial loss: 0.587383\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354689; batch adversarial loss: 0.527600\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358864; batch adversarial loss: 0.524873\n",
      "epoch 136; iter: 0; batch classifier loss: 0.367822; batch adversarial loss: 0.490432\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372770; batch adversarial loss: 0.544011\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393480; batch adversarial loss: 0.481268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355719; batch adversarial loss: 0.544814\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393780; batch adversarial loss: 0.643959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.376464; batch adversarial loss: 0.589392\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333267; batch adversarial loss: 0.524712\n",
      "epoch 143; iter: 0; batch classifier loss: 0.307004; batch adversarial loss: 0.525666\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337312; batch adversarial loss: 0.528421\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407812; batch adversarial loss: 0.552599\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332573; batch adversarial loss: 0.535724\n",
      "epoch 147; iter: 0; batch classifier loss: 0.256459; batch adversarial loss: 0.508470\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345086; batch adversarial loss: 0.490595\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383935; batch adversarial loss: 0.596903\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396489; batch adversarial loss: 0.533006\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352270; batch adversarial loss: 0.560509\n",
      "epoch 152; iter: 0; batch classifier loss: 0.303707; batch adversarial loss: 0.534909\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358565; batch adversarial loss: 0.570893\n",
      "epoch 154; iter: 0; batch classifier loss: 0.297485; batch adversarial loss: 0.588218\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325376; batch adversarial loss: 0.562711\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381107; batch adversarial loss: 0.623594\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373254; batch adversarial loss: 0.589522\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341810; batch adversarial loss: 0.545195\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384495; batch adversarial loss: 0.551732\n",
      "epoch 160; iter: 0; batch classifier loss: 0.411492; batch adversarial loss: 0.590274\n",
      "epoch 161; iter: 0; batch classifier loss: 0.430932; batch adversarial loss: 0.517883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352470; batch adversarial loss: 0.597008\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420310; batch adversarial loss: 0.553441\n",
      "epoch 164; iter: 0; batch classifier loss: 0.249641; batch adversarial loss: 0.569521\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350742; batch adversarial loss: 0.563969\n",
      "epoch 166; iter: 0; batch classifier loss: 0.297150; batch adversarial loss: 0.579400\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366392; batch adversarial loss: 0.599409\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401035; batch adversarial loss: 0.571950\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354474; batch adversarial loss: 0.544908\n",
      "epoch 170; iter: 0; batch classifier loss: 0.413723; batch adversarial loss: 0.544247\n",
      "epoch 171; iter: 0; batch classifier loss: 0.402930; batch adversarial loss: 0.536823\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379572; batch adversarial loss: 0.645739\n",
      "epoch 173; iter: 0; batch classifier loss: 0.331321; batch adversarial loss: 0.537489\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357843; batch adversarial loss: 0.488215\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345339; batch adversarial loss: 0.570183\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349675; batch adversarial loss: 0.506516\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387371; batch adversarial loss: 0.536988\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363553; batch adversarial loss: 0.588904\n",
      "epoch 179; iter: 0; batch classifier loss: 0.277720; batch adversarial loss: 0.607000\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379869; batch adversarial loss: 0.517499\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320865; batch adversarial loss: 0.571693\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380593; batch adversarial loss: 0.535847\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371880; batch adversarial loss: 0.578572\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413701; batch adversarial loss: 0.473144\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333568; batch adversarial loss: 0.599179\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380634; batch adversarial loss: 0.472376\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315225; batch adversarial loss: 0.517110\n",
      "epoch 188; iter: 0; batch classifier loss: 0.283833; batch adversarial loss: 0.507760\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352906; batch adversarial loss: 0.580496\n",
      "epoch 190; iter: 0; batch classifier loss: 0.281769; batch adversarial loss: 0.614379\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338395; batch adversarial loss: 0.528417\n",
      "epoch 192; iter: 0; batch classifier loss: 0.417103; batch adversarial loss: 0.497993\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330453; batch adversarial loss: 0.563193\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385280; batch adversarial loss: 0.498043\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290816; batch adversarial loss: 0.630067\n",
      "epoch 196; iter: 0; batch classifier loss: 0.417037; batch adversarial loss: 0.554594\n",
      "epoch 197; iter: 0; batch classifier loss: 0.410533; batch adversarial loss: 0.614187\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339248; batch adversarial loss: 0.572067\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318682; batch adversarial loss: 0.579441\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689902; batch adversarial loss: 0.725619\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575969; batch adversarial loss: 0.668574\n",
      "epoch 2; iter: 0; batch classifier loss: 0.524989; batch adversarial loss: 0.654080\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573307; batch adversarial loss: 0.692757\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520810; batch adversarial loss: 0.573867\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551440; batch adversarial loss: 0.615945\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524495; batch adversarial loss: 0.611217\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536063; batch adversarial loss: 0.569179\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530951; batch adversarial loss: 0.663689\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522909; batch adversarial loss: 0.643060\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532302; batch adversarial loss: 0.606472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525761; batch adversarial loss: 0.648282\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496070; batch adversarial loss: 0.644612\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575464; batch adversarial loss: 0.626243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471539; batch adversarial loss: 0.606519\n",
      "epoch 15; iter: 0; batch classifier loss: 0.633433; batch adversarial loss: 0.603750\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561223; batch adversarial loss: 0.619279\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543908; batch adversarial loss: 0.598500\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499742; batch adversarial loss: 0.558754\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515671; batch adversarial loss: 0.625485\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491457; batch adversarial loss: 0.638042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491450; batch adversarial loss: 0.546706\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491564; batch adversarial loss: 0.637665\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514853; batch adversarial loss: 0.549107\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506019; batch adversarial loss: 0.578363\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498601; batch adversarial loss: 0.553856\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474310; batch adversarial loss: 0.617639\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478407; batch adversarial loss: 0.606541\n",
      "epoch 28; iter: 0; batch classifier loss: 0.563307; batch adversarial loss: 0.512804\n",
      "epoch 29; iter: 0; batch classifier loss: 0.515538; batch adversarial loss: 0.553472\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428656; batch adversarial loss: 0.555795\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484077; batch adversarial loss: 0.575480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498734; batch adversarial loss: 0.550101\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414469; batch adversarial loss: 0.571618\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451102; batch adversarial loss: 0.568204\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456641; batch adversarial loss: 0.594298\n",
      "epoch 36; iter: 0; batch classifier loss: 0.409743; batch adversarial loss: 0.477550\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416324; batch adversarial loss: 0.545931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.442278; batch adversarial loss: 0.493539\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468767; batch adversarial loss: 0.659192\n",
      "epoch 40; iter: 0; batch classifier loss: 0.527610; batch adversarial loss: 0.499158\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441824; batch adversarial loss: 0.561909\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396244; batch adversarial loss: 0.579286\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433710; batch adversarial loss: 0.519644\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423363; batch adversarial loss: 0.588898\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445474; batch adversarial loss: 0.537866\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431095; batch adversarial loss: 0.485933\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418313; batch adversarial loss: 0.535418\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452077; batch adversarial loss: 0.527467\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458581; batch adversarial loss: 0.587911\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450071; batch adversarial loss: 0.623952\n",
      "epoch 51; iter: 0; batch classifier loss: 0.499281; batch adversarial loss: 0.570837\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382812; batch adversarial loss: 0.562589\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451116; batch adversarial loss: 0.596852\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451758; batch adversarial loss: 0.492483\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454811; batch adversarial loss: 0.456891\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430724; batch adversarial loss: 0.580015\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461932; batch adversarial loss: 0.518812\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446007; batch adversarial loss: 0.518545\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424574; batch adversarial loss: 0.544355\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427350; batch adversarial loss: 0.492169\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403606; batch adversarial loss: 0.518777\n",
      "epoch 62; iter: 0; batch classifier loss: 0.561120; batch adversarial loss: 0.457113\n",
      "epoch 63; iter: 0; batch classifier loss: 0.483093; batch adversarial loss: 0.545007\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432471; batch adversarial loss: 0.544761\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379001; batch adversarial loss: 0.553600\n",
      "epoch 66; iter: 0; batch classifier loss: 0.520042; batch adversarial loss: 0.606347\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428291; batch adversarial loss: 0.544802\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390121; batch adversarial loss: 0.482871\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432870; batch adversarial loss: 0.597592\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424220; batch adversarial loss: 0.615286\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444096; batch adversarial loss: 0.527905\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399419; batch adversarial loss: 0.552837\n",
      "epoch 73; iter: 0; batch classifier loss: 0.432592; batch adversarial loss: 0.494476\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447370; batch adversarial loss: 0.508666\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434811; batch adversarial loss: 0.501464\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392511; batch adversarial loss: 0.598837\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388438; batch adversarial loss: 0.628979\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370682; batch adversarial loss: 0.535450\n",
      "epoch 79; iter: 0; batch classifier loss: 0.481329; batch adversarial loss: 0.560305\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366105; batch adversarial loss: 0.590311\n",
      "epoch 81; iter: 0; batch classifier loss: 0.516628; batch adversarial loss: 0.508990\n",
      "epoch 82; iter: 0; batch classifier loss: 0.425224; batch adversarial loss: 0.595346\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402067; batch adversarial loss: 0.569762\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398687; batch adversarial loss: 0.624152\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367857; batch adversarial loss: 0.553494\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373214; batch adversarial loss: 0.543746\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413563; batch adversarial loss: 0.561467\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374520; batch adversarial loss: 0.588800\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398165; batch adversarial loss: 0.579255\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419979; batch adversarial loss: 0.553575\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399673; batch adversarial loss: 0.420285\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382099; batch adversarial loss: 0.562585\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391235; batch adversarial loss: 0.482984\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421690; batch adversarial loss: 0.536658\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375882; batch adversarial loss: 0.570240\n",
      "epoch 96; iter: 0; batch classifier loss: 0.444168; batch adversarial loss: 0.544283\n",
      "epoch 97; iter: 0; batch classifier loss: 0.449996; batch adversarial loss: 0.544043\n",
      "epoch 98; iter: 0; batch classifier loss: 0.345794; batch adversarial loss: 0.606598\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400159; batch adversarial loss: 0.597463\n",
      "epoch 100; iter: 0; batch classifier loss: 0.395075; batch adversarial loss: 0.545568\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365923; batch adversarial loss: 0.510106\n",
      "epoch 102; iter: 0; batch classifier loss: 0.461089; batch adversarial loss: 0.553925\n",
      "epoch 103; iter: 0; batch classifier loss: 0.442346; batch adversarial loss: 0.561581\n",
      "epoch 104; iter: 0; batch classifier loss: 0.484444; batch adversarial loss: 0.536190\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379362; batch adversarial loss: 0.553830\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366095; batch adversarial loss: 0.562501\n",
      "epoch 107; iter: 0; batch classifier loss: 0.427655; batch adversarial loss: 0.633261\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373753; batch adversarial loss: 0.562577\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391618; batch adversarial loss: 0.562097\n",
      "epoch 110; iter: 0; batch classifier loss: 0.470564; batch adversarial loss: 0.623841\n",
      "epoch 111; iter: 0; batch classifier loss: 0.349572; batch adversarial loss: 0.535944\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382745; batch adversarial loss: 0.571256\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421388; batch adversarial loss: 0.509196\n",
      "epoch 114; iter: 0; batch classifier loss: 0.438272; batch adversarial loss: 0.535905\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378840; batch adversarial loss: 0.518183\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353904; batch adversarial loss: 0.606415\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375870; batch adversarial loss: 0.625389\n",
      "epoch 118; iter: 0; batch classifier loss: 0.442807; batch adversarial loss: 0.518488\n",
      "epoch 119; iter: 0; batch classifier loss: 0.413684; batch adversarial loss: 0.544887\n",
      "epoch 120; iter: 0; batch classifier loss: 0.459020; batch adversarial loss: 0.606218\n",
      "epoch 121; iter: 0; batch classifier loss: 0.330055; batch adversarial loss: 0.509929\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381519; batch adversarial loss: 0.596979\n",
      "epoch 123; iter: 0; batch classifier loss: 0.417625; batch adversarial loss: 0.554524\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337722; batch adversarial loss: 0.501329\n",
      "epoch 125; iter: 0; batch classifier loss: 0.441581; batch adversarial loss: 0.673437\n",
      "epoch 126; iter: 0; batch classifier loss: 0.318252; batch adversarial loss: 0.554098\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405719; batch adversarial loss: 0.606570\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401483; batch adversarial loss: 0.554124\n",
      "epoch 129; iter: 0; batch classifier loss: 0.458789; batch adversarial loss: 0.562375\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346439; batch adversarial loss: 0.579940\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355788; batch adversarial loss: 0.562367\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415024; batch adversarial loss: 0.544948\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383031; batch adversarial loss: 0.589185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.406231; batch adversarial loss: 0.518168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.464388; batch adversarial loss: 0.535730\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398086; batch adversarial loss: 0.491685\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382525; batch adversarial loss: 0.463735\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405781; batch adversarial loss: 0.542725\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388677; batch adversarial loss: 0.534268\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383586; batch adversarial loss: 0.536345\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356089; batch adversarial loss: 0.607670\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330129; batch adversarial loss: 0.517998\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412980; batch adversarial loss: 0.545166\n",
      "epoch 144; iter: 0; batch classifier loss: 0.419125; batch adversarial loss: 0.519759\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387524; batch adversarial loss: 0.605867\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401220; batch adversarial loss: 0.579656\n",
      "epoch 147; iter: 0; batch classifier loss: 0.420943; batch adversarial loss: 0.545416\n",
      "epoch 148; iter: 0; batch classifier loss: 0.304112; batch adversarial loss: 0.466555\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343496; batch adversarial loss: 0.544697\n",
      "epoch 150; iter: 0; batch classifier loss: 0.403944; batch adversarial loss: 0.484071\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354204; batch adversarial loss: 0.553764\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352411; batch adversarial loss: 0.483591\n",
      "epoch 153; iter: 0; batch classifier loss: 0.472292; batch adversarial loss: 0.562104\n",
      "epoch 154; iter: 0; batch classifier loss: 0.457075; batch adversarial loss: 0.597655\n",
      "epoch 155; iter: 0; batch classifier loss: 0.335679; batch adversarial loss: 0.509693\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380359; batch adversarial loss: 0.571375\n",
      "epoch 157; iter: 0; batch classifier loss: 0.431416; batch adversarial loss: 0.527486\n",
      "epoch 158; iter: 0; batch classifier loss: 0.385411; batch adversarial loss: 0.527628\n",
      "epoch 159; iter: 0; batch classifier loss: 0.477228; batch adversarial loss: 0.571101\n",
      "epoch 160; iter: 0; batch classifier loss: 0.426413; batch adversarial loss: 0.492413\n",
      "epoch 161; iter: 0; batch classifier loss: 0.422448; batch adversarial loss: 0.606020\n",
      "epoch 162; iter: 0; batch classifier loss: 0.297054; batch adversarial loss: 0.518359\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367822; batch adversarial loss: 0.570665\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398440; batch adversarial loss: 0.623991\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410263; batch adversarial loss: 0.606446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.420222; batch adversarial loss: 0.614644\n",
      "epoch 167; iter: 0; batch classifier loss: 0.417837; batch adversarial loss: 0.518359\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396545; batch adversarial loss: 0.596810\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356586; batch adversarial loss: 0.595259\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337916; batch adversarial loss: 0.605431\n",
      "epoch 171; iter: 0; batch classifier loss: 0.399823; batch adversarial loss: 0.561407\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397523; batch adversarial loss: 0.552801\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302707; batch adversarial loss: 0.571770\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381501; batch adversarial loss: 0.546054\n",
      "epoch 175; iter: 0; batch classifier loss: 0.370367; batch adversarial loss: 0.518944\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355880; batch adversarial loss: 0.597785\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345066; batch adversarial loss: 0.562323\n",
      "epoch 178; iter: 0; batch classifier loss: 0.430161; batch adversarial loss: 0.509426\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389546; batch adversarial loss: 0.519442\n",
      "epoch 180; iter: 0; batch classifier loss: 0.357527; batch adversarial loss: 0.526774\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337950; batch adversarial loss: 0.553659\n",
      "epoch 182; iter: 0; batch classifier loss: 0.297566; batch adversarial loss: 0.571351\n",
      "epoch 183; iter: 0; batch classifier loss: 0.390908; batch adversarial loss: 0.517923\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383356; batch adversarial loss: 0.597956\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333743; batch adversarial loss: 0.669167\n",
      "epoch 186; iter: 0; batch classifier loss: 0.484121; batch adversarial loss: 0.526986\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336420; batch adversarial loss: 0.553613\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375271; batch adversarial loss: 0.597674\n",
      "epoch 189; iter: 0; batch classifier loss: 0.325091; batch adversarial loss: 0.535828\n",
      "epoch 190; iter: 0; batch classifier loss: 0.406704; batch adversarial loss: 0.588772\n",
      "epoch 191; iter: 0; batch classifier loss: 0.416746; batch adversarial loss: 0.483211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397704; batch adversarial loss: 0.491910\n",
      "epoch 193; iter: 0; batch classifier loss: 0.488635; batch adversarial loss: 0.597423\n",
      "epoch 194; iter: 0; batch classifier loss: 0.450966; batch adversarial loss: 0.562637\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362348; batch adversarial loss: 0.535933\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373302; batch adversarial loss: 0.492381\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370408; batch adversarial loss: 0.606858\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358667; batch adversarial loss: 0.491688\n",
      "epoch 199; iter: 0; batch classifier loss: 0.402933; batch adversarial loss: 0.599096\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683967; batch adversarial loss: 0.625619\n",
      "epoch 1; iter: 0; batch classifier loss: 0.685062; batch adversarial loss: 0.672277\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553601; batch adversarial loss: 0.658905\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612128; batch adversarial loss: 0.654779\n",
      "epoch 4; iter: 0; batch classifier loss: 0.509448; batch adversarial loss: 0.654433\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577829; batch adversarial loss: 0.674445\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559724; batch adversarial loss: 0.690722\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595945; batch adversarial loss: 0.621492\n",
      "epoch 8; iter: 0; batch classifier loss: 0.591856; batch adversarial loss: 0.573605\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500792; batch adversarial loss: 0.569360\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536670; batch adversarial loss: 0.627059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537322; batch adversarial loss: 0.667611\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520874; batch adversarial loss: 0.561923\n",
      "epoch 13; iter: 0; batch classifier loss: 0.582573; batch adversarial loss: 0.595964\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501525; batch adversarial loss: 0.564561\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518890; batch adversarial loss: 0.538535\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499556; batch adversarial loss: 0.588017\n",
      "epoch 17; iter: 0; batch classifier loss: 0.566625; batch adversarial loss: 0.553912\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534482; batch adversarial loss: 0.552548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498269; batch adversarial loss: 0.543420\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511790; batch adversarial loss: 0.573833\n",
      "epoch 21; iter: 0; batch classifier loss: 0.585339; batch adversarial loss: 0.610407\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475980; batch adversarial loss: 0.574214\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512334; batch adversarial loss: 0.547068\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489308; batch adversarial loss: 0.613297\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424602; batch adversarial loss: 0.513306\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470694; batch adversarial loss: 0.519863\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485797; batch adversarial loss: 0.562560\n",
      "epoch 28; iter: 0; batch classifier loss: 0.520346; batch adversarial loss: 0.596673\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471890; batch adversarial loss: 0.545014\n",
      "epoch 30; iter: 0; batch classifier loss: 0.420576; batch adversarial loss: 0.640629\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465493; batch adversarial loss: 0.571011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.426383; batch adversarial loss: 0.605827\n",
      "epoch 33; iter: 0; batch classifier loss: 0.562684; batch adversarial loss: 0.544533\n",
      "epoch 34; iter: 0; batch classifier loss: 0.424123; batch adversarial loss: 0.552646\n",
      "epoch 35; iter: 0; batch classifier loss: 0.501505; batch adversarial loss: 0.562079\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436516; batch adversarial loss: 0.518060\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422444; batch adversarial loss: 0.633275\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472838; batch adversarial loss: 0.632918\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322852; batch adversarial loss: 0.597145\n",
      "epoch 40; iter: 0; batch classifier loss: 0.513545; batch adversarial loss: 0.562121\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473756; batch adversarial loss: 0.501634\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440933; batch adversarial loss: 0.572562\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480675; batch adversarial loss: 0.489706\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417780; batch adversarial loss: 0.564721\n",
      "epoch 45; iter: 0; batch classifier loss: 0.494321; batch adversarial loss: 0.533664\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470288; batch adversarial loss: 0.554767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.536384; batch adversarial loss: 0.527062\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421718; batch adversarial loss: 0.547281\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470835; batch adversarial loss: 0.614811\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434162; batch adversarial loss: 0.492235\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416740; batch adversarial loss: 0.559753\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427340; batch adversarial loss: 0.472038\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458592; batch adversarial loss: 0.557020\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455351; batch adversarial loss: 0.556072\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388457; batch adversarial loss: 0.517807\n",
      "epoch 56; iter: 0; batch classifier loss: 0.497669; batch adversarial loss: 0.528771\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449986; batch adversarial loss: 0.560239\n",
      "epoch 58; iter: 0; batch classifier loss: 0.476523; batch adversarial loss: 0.583399\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446414; batch adversarial loss: 0.462616\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406089; batch adversarial loss: 0.670571\n",
      "epoch 61; iter: 0; batch classifier loss: 0.431190; batch adversarial loss: 0.565240\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430811; batch adversarial loss: 0.534636\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385039; batch adversarial loss: 0.580428\n",
      "epoch 64; iter: 0; batch classifier loss: 0.468026; batch adversarial loss: 0.471695\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383062; batch adversarial loss: 0.506815\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415045; batch adversarial loss: 0.574628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403998; batch adversarial loss: 0.465789\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441517; batch adversarial loss: 0.613957\n",
      "epoch 69; iter: 0; batch classifier loss: 0.463528; batch adversarial loss: 0.597650\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409075; batch adversarial loss: 0.555657\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390302; batch adversarial loss: 0.553591\n",
      "epoch 72; iter: 0; batch classifier loss: 0.431300; batch adversarial loss: 0.591567\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402530; batch adversarial loss: 0.531610\n",
      "epoch 74; iter: 0; batch classifier loss: 0.462765; batch adversarial loss: 0.468400\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375291; batch adversarial loss: 0.537941\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383519; batch adversarial loss: 0.522769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363227; batch adversarial loss: 0.638911\n",
      "epoch 78; iter: 0; batch classifier loss: 0.436593; batch adversarial loss: 0.555049\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393647; batch adversarial loss: 0.608230\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401557; batch adversarial loss: 0.575405\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397857; batch adversarial loss: 0.533270\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342358; batch adversarial loss: 0.498770\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349750; batch adversarial loss: 0.614541\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446601; batch adversarial loss: 0.591462\n",
      "epoch 85; iter: 0; batch classifier loss: 0.457757; batch adversarial loss: 0.537132\n",
      "epoch 86; iter: 0; batch classifier loss: 0.342756; batch adversarial loss: 0.627145\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404023; batch adversarial loss: 0.461782\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429193; batch adversarial loss: 0.563961\n",
      "epoch 89; iter: 0; batch classifier loss: 0.325760; batch adversarial loss: 0.588075\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407872; batch adversarial loss: 0.543149\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421231; batch adversarial loss: 0.544854\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350668; batch adversarial loss: 0.515657\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391330; batch adversarial loss: 0.492644\n",
      "epoch 94; iter: 0; batch classifier loss: 0.417366; batch adversarial loss: 0.555532\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359055; batch adversarial loss: 0.592728\n",
      "epoch 96; iter: 0; batch classifier loss: 0.496773; batch adversarial loss: 0.571122\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387617; batch adversarial loss: 0.664712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.312552; batch adversarial loss: 0.575125\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386029; batch adversarial loss: 0.551461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394605; batch adversarial loss: 0.535012\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381115; batch adversarial loss: 0.509229\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399115; batch adversarial loss: 0.598338\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354406; batch adversarial loss: 0.547039\n",
      "epoch 104; iter: 0; batch classifier loss: 0.555388; batch adversarial loss: 0.547573\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392618; batch adversarial loss: 0.571952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.338593; batch adversarial loss: 0.571759\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343798; batch adversarial loss: 0.564257\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377858; batch adversarial loss: 0.572563\n",
      "epoch 109; iter: 0; batch classifier loss: 0.451674; batch adversarial loss: 0.570447\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408251; batch adversarial loss: 0.587903\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391431; batch adversarial loss: 0.593067\n",
      "epoch 112; iter: 0; batch classifier loss: 0.373463; batch adversarial loss: 0.584940\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346222; batch adversarial loss: 0.556625\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383968; batch adversarial loss: 0.617441\n",
      "epoch 115; iter: 0; batch classifier loss: 0.449770; batch adversarial loss: 0.584364\n",
      "epoch 116; iter: 0; batch classifier loss: 0.425431; batch adversarial loss: 0.574760\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373762; batch adversarial loss: 0.581136\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383425; batch adversarial loss: 0.561016\n",
      "epoch 119; iter: 0; batch classifier loss: 0.497383; batch adversarial loss: 0.535623\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357166; batch adversarial loss: 0.515479\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419088; batch adversarial loss: 0.543928\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353750; batch adversarial loss: 0.574925\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341191; batch adversarial loss: 0.581017\n",
      "epoch 124; iter: 0; batch classifier loss: 0.461591; batch adversarial loss: 0.573662\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332897; batch adversarial loss: 0.569631\n",
      "epoch 126; iter: 0; batch classifier loss: 0.320849; batch adversarial loss: 0.590397\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384357; batch adversarial loss: 0.544957\n",
      "epoch 128; iter: 0; batch classifier loss: 0.416487; batch adversarial loss: 0.544371\n",
      "epoch 129; iter: 0; batch classifier loss: 0.387930; batch adversarial loss: 0.560549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.357243; batch adversarial loss: 0.517615\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381681; batch adversarial loss: 0.536066\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395500; batch adversarial loss: 0.520311\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347413; batch adversarial loss: 0.595938\n",
      "epoch 134; iter: 0; batch classifier loss: 0.491956; batch adversarial loss: 0.490577\n",
      "epoch 135; iter: 0; batch classifier loss: 0.452874; batch adversarial loss: 0.555640\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345944; batch adversarial loss: 0.534580\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407510; batch adversarial loss: 0.488524\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373053; batch adversarial loss: 0.505121\n",
      "epoch 139; iter: 0; batch classifier loss: 0.429795; batch adversarial loss: 0.463634\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347085; batch adversarial loss: 0.526791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335545; batch adversarial loss: 0.545386\n",
      "epoch 142; iter: 0; batch classifier loss: 0.441265; batch adversarial loss: 0.567792\n",
      "epoch 143; iter: 0; batch classifier loss: 0.500106; batch adversarial loss: 0.480817\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392236; batch adversarial loss: 0.532530\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381191; batch adversarial loss: 0.499045\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346581; batch adversarial loss: 0.547636\n",
      "epoch 147; iter: 0; batch classifier loss: 0.311688; batch adversarial loss: 0.535840\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373048; batch adversarial loss: 0.576438\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323875; batch adversarial loss: 0.586395\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400981; batch adversarial loss: 0.563305\n",
      "epoch 151; iter: 0; batch classifier loss: 0.420700; batch adversarial loss: 0.557275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.418367; batch adversarial loss: 0.525407\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338349; batch adversarial loss: 0.545711\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351456; batch adversarial loss: 0.512809\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357919; batch adversarial loss: 0.535496\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387223; batch adversarial loss: 0.617727\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404128; batch adversarial loss: 0.536958\n",
      "epoch 158; iter: 0; batch classifier loss: 0.451524; batch adversarial loss: 0.480250\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354048; batch adversarial loss: 0.572082\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413401; batch adversarial loss: 0.516768\n",
      "epoch 161; iter: 0; batch classifier loss: 0.398114; batch adversarial loss: 0.441831\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381238; batch adversarial loss: 0.616790\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399994; batch adversarial loss: 0.565315\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351595; batch adversarial loss: 0.546682\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424793; batch adversarial loss: 0.587810\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301728; batch adversarial loss: 0.581185\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376115; batch adversarial loss: 0.587673\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315300; batch adversarial loss: 0.580571\n",
      "epoch 169; iter: 0; batch classifier loss: 0.397959; batch adversarial loss: 0.499343\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351798; batch adversarial loss: 0.663020\n",
      "epoch 171; iter: 0; batch classifier loss: 0.481335; batch adversarial loss: 0.580581\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349563; batch adversarial loss: 0.573741\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385573; batch adversarial loss: 0.554000\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347532; batch adversarial loss: 0.457277\n",
      "epoch 175; iter: 0; batch classifier loss: 0.422452; batch adversarial loss: 0.517158\n",
      "epoch 176; iter: 0; batch classifier loss: 0.390161; batch adversarial loss: 0.518229\n",
      "epoch 177; iter: 0; batch classifier loss: 0.402059; batch adversarial loss: 0.519486\n",
      "epoch 178; iter: 0; batch classifier loss: 0.426009; batch adversarial loss: 0.481347\n",
      "epoch 179; iter: 0; batch classifier loss: 0.408101; batch adversarial loss: 0.542925\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379176; batch adversarial loss: 0.553612\n",
      "epoch 181; iter: 0; batch classifier loss: 0.316478; batch adversarial loss: 0.546570\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340061; batch adversarial loss: 0.540978\n",
      "epoch 183; iter: 0; batch classifier loss: 0.440856; batch adversarial loss: 0.563976\n",
      "epoch 184; iter: 0; batch classifier loss: 0.308577; batch adversarial loss: 0.582011\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352777; batch adversarial loss: 0.572573\n",
      "epoch 186; iter: 0; batch classifier loss: 0.364015; batch adversarial loss: 0.549701\n",
      "epoch 187; iter: 0; batch classifier loss: 0.396668; batch adversarial loss: 0.586216\n",
      "epoch 188; iter: 0; batch classifier loss: 0.403262; batch adversarial loss: 0.514069\n",
      "epoch 189; iter: 0; batch classifier loss: 0.250878; batch adversarial loss: 0.559073\n",
      "epoch 190; iter: 0; batch classifier loss: 0.335654; batch adversarial loss: 0.570076\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379503; batch adversarial loss: 0.553907\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346466; batch adversarial loss: 0.473344\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373041; batch adversarial loss: 0.470645\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336655; batch adversarial loss: 0.600943\n",
      "epoch 195; iter: 0; batch classifier loss: 0.400718; batch adversarial loss: 0.545948\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376202; batch adversarial loss: 0.576486\n",
      "epoch 197; iter: 0; batch classifier loss: 0.280502; batch adversarial loss: 0.615480\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322432; batch adversarial loss: 0.588943\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366376; batch adversarial loss: 0.538210\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715452; batch adversarial loss: 0.654495\n",
      "epoch 1; iter: 0; batch classifier loss: 0.576376; batch adversarial loss: 0.646562\n",
      "epoch 2; iter: 0; batch classifier loss: 0.545766; batch adversarial loss: 0.634079\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616136; batch adversarial loss: 0.610166\n",
      "epoch 4; iter: 0; batch classifier loss: 0.650997; batch adversarial loss: 0.584982\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558658; batch adversarial loss: 0.628874\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520788; batch adversarial loss: 0.614160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542094; batch adversarial loss: 0.577073\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569414; batch adversarial loss: 0.589365\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528925; batch adversarial loss: 0.574443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562289; batch adversarial loss: 0.614374\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562262; batch adversarial loss: 0.561138\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501615; batch adversarial loss: 0.600585\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516912; batch adversarial loss: 0.544351\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557793; batch adversarial loss: 0.533391\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478588; batch adversarial loss: 0.624290\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480086; batch adversarial loss: 0.517588\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469272; batch adversarial loss: 0.501375\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462455; batch adversarial loss: 0.573605\n",
      "epoch 19; iter: 0; batch classifier loss: 0.420390; batch adversarial loss: 0.575730\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493779; batch adversarial loss: 0.613341\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462980; batch adversarial loss: 0.602676\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519208; batch adversarial loss: 0.591676\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497971; batch adversarial loss: 0.508494\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454578; batch adversarial loss: 0.563089\n",
      "epoch 25; iter: 0; batch classifier loss: 0.460589; batch adversarial loss: 0.522638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.478390; batch adversarial loss: 0.589991\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481081; batch adversarial loss: 0.521536\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407038; batch adversarial loss: 0.555708\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413513; batch adversarial loss: 0.611703\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495326; batch adversarial loss: 0.601900\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397116; batch adversarial loss: 0.501420\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516471; batch adversarial loss: 0.535095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481352; batch adversarial loss: 0.571828\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367322; batch adversarial loss: 0.474164\n",
      "epoch 35; iter: 0; batch classifier loss: 0.508734; batch adversarial loss: 0.434248\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441711; batch adversarial loss: 0.562309\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363590; batch adversarial loss: 0.570966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424881; batch adversarial loss: 0.564571\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429543; batch adversarial loss: 0.483070\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381495; batch adversarial loss: 0.500323\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465509; batch adversarial loss: 0.537276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.348513; batch adversarial loss: 0.518054\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423115; batch adversarial loss: 0.571254\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437453; batch adversarial loss: 0.453080\n",
      "epoch 45; iter: 0; batch classifier loss: 0.316072; batch adversarial loss: 0.535707\n",
      "epoch 46; iter: 0; batch classifier loss: 0.527879; batch adversarial loss: 0.570260\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442961; batch adversarial loss: 0.479464\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450217; batch adversarial loss: 0.601820\n",
      "epoch 49; iter: 0; batch classifier loss: 0.360596; batch adversarial loss: 0.496391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435010; batch adversarial loss: 0.537545\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428248; batch adversarial loss: 0.479289\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383843; batch adversarial loss: 0.515979\n",
      "epoch 53; iter: 0; batch classifier loss: 0.469178; batch adversarial loss: 0.570583\n",
      "epoch 54; iter: 0; batch classifier loss: 0.358174; batch adversarial loss: 0.554200\n",
      "epoch 55; iter: 0; batch classifier loss: 0.435842; batch adversarial loss: 0.507872\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463244; batch adversarial loss: 0.536513\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468095; batch adversarial loss: 0.481850\n",
      "epoch 58; iter: 0; batch classifier loss: 0.383764; batch adversarial loss: 0.472831\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464816; batch adversarial loss: 0.571483\n",
      "epoch 60; iter: 0; batch classifier loss: 0.277273; batch adversarial loss: 0.508626\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391444; batch adversarial loss: 0.517619\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416978; batch adversarial loss: 0.526047\n",
      "epoch 63; iter: 0; batch classifier loss: 0.485135; batch adversarial loss: 0.580870\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429657; batch adversarial loss: 0.672173\n",
      "epoch 65; iter: 0; batch classifier loss: 0.472321; batch adversarial loss: 0.481173\n",
      "epoch 66; iter: 0; batch classifier loss: 0.480413; batch adversarial loss: 0.489746\n",
      "epoch 67; iter: 0; batch classifier loss: 0.469947; batch adversarial loss: 0.535154\n",
      "epoch 68; iter: 0; batch classifier loss: 0.345620; batch adversarial loss: 0.517150\n",
      "epoch 69; iter: 0; batch classifier loss: 0.452098; batch adversarial loss: 0.571914\n",
      "epoch 70; iter: 0; batch classifier loss: 0.450317; batch adversarial loss: 0.507798\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394081; batch adversarial loss: 0.580750\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444482; batch adversarial loss: 0.589742\n",
      "epoch 73; iter: 0; batch classifier loss: 0.465875; batch adversarial loss: 0.508224\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426947; batch adversarial loss: 0.553273\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373129; batch adversarial loss: 0.508975\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375577; batch adversarial loss: 0.552355\n",
      "epoch 77; iter: 0; batch classifier loss: 0.462552; batch adversarial loss: 0.537088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.383263; batch adversarial loss: 0.507094\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392691; batch adversarial loss: 0.562512\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426133; batch adversarial loss: 0.580765\n",
      "epoch 81; iter: 0; batch classifier loss: 0.359180; batch adversarial loss: 0.580670\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366294; batch adversarial loss: 0.471778\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368197; batch adversarial loss: 0.536992\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430519; batch adversarial loss: 0.526374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385857; batch adversarial loss: 0.545419\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430599; batch adversarial loss: 0.544798\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385013; batch adversarial loss: 0.534480\n",
      "epoch 88; iter: 0; batch classifier loss: 0.410861; batch adversarial loss: 0.600722\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394911; batch adversarial loss: 0.462085\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350641; batch adversarial loss: 0.554608\n",
      "epoch 91; iter: 0; batch classifier loss: 0.425346; batch adversarial loss: 0.581183\n",
      "epoch 92; iter: 0; batch classifier loss: 0.467605; batch adversarial loss: 0.562664\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421989; batch adversarial loss: 0.636923\n",
      "epoch 94; iter: 0; batch classifier loss: 0.499604; batch adversarial loss: 0.488959\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322157; batch adversarial loss: 0.590049\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368234; batch adversarial loss: 0.580913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.343204; batch adversarial loss: 0.480072\n",
      "epoch 98; iter: 0; batch classifier loss: 0.455847; batch adversarial loss: 0.562577\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339896; batch adversarial loss: 0.508003\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383078; batch adversarial loss: 0.480688\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382695; batch adversarial loss: 0.562776\n",
      "epoch 102; iter: 0; batch classifier loss: 0.358393; batch adversarial loss: 0.680657\n",
      "epoch 103; iter: 0; batch classifier loss: 0.299224; batch adversarial loss: 0.535573\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374988; batch adversarial loss: 0.571899\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339167; batch adversarial loss: 0.535328\n",
      "epoch 106; iter: 0; batch classifier loss: 0.327746; batch adversarial loss: 0.591363\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361884; batch adversarial loss: 0.552864\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398422; batch adversarial loss: 0.599877\n",
      "epoch 109; iter: 0; batch classifier loss: 0.335914; batch adversarial loss: 0.553656\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356969; batch adversarial loss: 0.508279\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393046; batch adversarial loss: 0.499421\n",
      "epoch 112; iter: 0; batch classifier loss: 0.437636; batch adversarial loss: 0.517284\n",
      "epoch 113; iter: 0; batch classifier loss: 0.436190; batch adversarial loss: 0.580947\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381851; batch adversarial loss: 0.590181\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418572; batch adversarial loss: 0.507942\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355794; batch adversarial loss: 0.617555\n",
      "epoch 117; iter: 0; batch classifier loss: 0.334058; batch adversarial loss: 0.517007\n",
      "epoch 118; iter: 0; batch classifier loss: 0.459736; batch adversarial loss: 0.544493\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392847; batch adversarial loss: 0.571892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.412553; batch adversarial loss: 0.534935\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351349; batch adversarial loss: 0.526189\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417068; batch adversarial loss: 0.490000\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379751; batch adversarial loss: 0.471795\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326343; batch adversarial loss: 0.562708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.387703; batch adversarial loss: 0.508140\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381778; batch adversarial loss: 0.517242\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339181; batch adversarial loss: 0.498928\n",
      "epoch 128; iter: 0; batch classifier loss: 0.304587; batch adversarial loss: 0.526329\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347115; batch adversarial loss: 0.571700\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414075; batch adversarial loss: 0.553609\n",
      "epoch 131; iter: 0; batch classifier loss: 0.298585; batch adversarial loss: 0.499180\n",
      "epoch 132; iter: 0; batch classifier loss: 0.366776; batch adversarial loss: 0.590096\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370165; batch adversarial loss: 0.481338\n",
      "epoch 134; iter: 0; batch classifier loss: 0.291369; batch adversarial loss: 0.508105\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370321; batch adversarial loss: 0.535277\n",
      "epoch 136; iter: 0; batch classifier loss: 0.419080; batch adversarial loss: 0.517411\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362441; batch adversarial loss: 0.553934\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346992; batch adversarial loss: 0.599968\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374093; batch adversarial loss: 0.562756\n",
      "epoch 140; iter: 0; batch classifier loss: 0.448966; batch adversarial loss: 0.599131\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334579; batch adversarial loss: 0.525979\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383817; batch adversarial loss: 0.534773\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408683; batch adversarial loss: 0.535772\n",
      "epoch 144; iter: 0; batch classifier loss: 0.407366; batch adversarial loss: 0.544573\n",
      "epoch 145; iter: 0; batch classifier loss: 0.442161; batch adversarial loss: 0.526504\n",
      "epoch 146; iter: 0; batch classifier loss: 0.433919; batch adversarial loss: 0.517191\n",
      "epoch 147; iter: 0; batch classifier loss: 0.395949; batch adversarial loss: 0.480301\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389001; batch adversarial loss: 0.553921\n",
      "epoch 149; iter: 0; batch classifier loss: 0.296336; batch adversarial loss: 0.571885\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385529; batch adversarial loss: 0.525868\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409646; batch adversarial loss: 0.609117\n",
      "epoch 152; iter: 0; batch classifier loss: 0.420094; batch adversarial loss: 0.517121\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348767; batch adversarial loss: 0.508124\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402112; batch adversarial loss: 0.471614\n",
      "epoch 155; iter: 0; batch classifier loss: 0.405992; batch adversarial loss: 0.535316\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358180; batch adversarial loss: 0.553601\n",
      "epoch 157; iter: 0; batch classifier loss: 0.347808; batch adversarial loss: 0.599463\n",
      "epoch 158; iter: 0; batch classifier loss: 0.409468; batch adversarial loss: 0.489644\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368020; batch adversarial loss: 0.526327\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405851; batch adversarial loss: 0.535066\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354757; batch adversarial loss: 0.544787\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329936; batch adversarial loss: 0.571615\n",
      "epoch 163; iter: 0; batch classifier loss: 0.414283; batch adversarial loss: 0.535458\n",
      "epoch 164; iter: 0; batch classifier loss: 0.318969; batch adversarial loss: 0.553660\n",
      "epoch 165; iter: 0; batch classifier loss: 0.412830; batch adversarial loss: 0.480925\n",
      "epoch 166; iter: 0; batch classifier loss: 0.428911; batch adversarial loss: 0.626219\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329700; batch adversarial loss: 0.508101\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372576; batch adversarial loss: 0.571793\n",
      "epoch 169; iter: 0; batch classifier loss: 0.323381; batch adversarial loss: 0.626732\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299176; batch adversarial loss: 0.535249\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334479; batch adversarial loss: 0.508519\n",
      "epoch 172; iter: 0; batch classifier loss: 0.417233; batch adversarial loss: 0.544385\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380203; batch adversarial loss: 0.599217\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374390; batch adversarial loss: 0.655053\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346163; batch adversarial loss: 0.608429\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413780; batch adversarial loss: 0.544346\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358926; batch adversarial loss: 0.617700\n",
      "epoch 178; iter: 0; batch classifier loss: 0.290615; batch adversarial loss: 0.644693\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347288; batch adversarial loss: 0.526146\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351598; batch adversarial loss: 0.498867\n",
      "epoch 181; iter: 0; batch classifier loss: 0.303551; batch adversarial loss: 0.562478\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.535491\n",
      "epoch 183; iter: 0; batch classifier loss: 0.390101; batch adversarial loss: 0.535484\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372151; batch adversarial loss: 0.616838\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364140; batch adversarial loss: 0.535561\n",
      "epoch 186; iter: 0; batch classifier loss: 0.352026; batch adversarial loss: 0.589613\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375384; batch adversarial loss: 0.490604\n",
      "epoch 188; iter: 0; batch classifier loss: 0.414866; batch adversarial loss: 0.524666\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341523; batch adversarial loss: 0.508534\n",
      "epoch 190; iter: 0; batch classifier loss: 0.267823; batch adversarial loss: 0.588338\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335940; batch adversarial loss: 0.533209\n",
      "epoch 192; iter: 0; batch classifier loss: 0.310877; batch adversarial loss: 0.579872\n",
      "epoch 193; iter: 0; batch classifier loss: 0.289242; batch adversarial loss: 0.601257\n",
      "epoch 194; iter: 0; batch classifier loss: 0.309997; batch adversarial loss: 0.592407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.400443; batch adversarial loss: 0.468633\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356946; batch adversarial loss: 0.546244\n",
      "epoch 197; iter: 0; batch classifier loss: 0.395143; batch adversarial loss: 0.563109\n",
      "epoch 198; iter: 0; batch classifier loss: 0.398763; batch adversarial loss: 0.553273\n",
      "epoch 199; iter: 0; batch classifier loss: 0.424569; batch adversarial loss: 0.580942\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752250; batch adversarial loss: 1.021122\n",
      "epoch 1; iter: 0; batch classifier loss: 0.825782; batch adversarial loss: 1.131145\n",
      "epoch 2; iter: 0; batch classifier loss: 1.015077; batch adversarial loss: 1.109184\n",
      "epoch 3; iter: 0; batch classifier loss: 1.245892; batch adversarial loss: 1.027134\n",
      "epoch 4; iter: 0; batch classifier loss: 1.293268; batch adversarial loss: 0.968223\n",
      "epoch 5; iter: 0; batch classifier loss: 1.147839; batch adversarial loss: 0.859236\n",
      "epoch 6; iter: 0; batch classifier loss: 1.148742; batch adversarial loss: 0.803921\n",
      "epoch 7; iter: 0; batch classifier loss: 0.954066; batch adversarial loss: 0.737385\n",
      "epoch 8; iter: 0; batch classifier loss: 0.902997; batch adversarial loss: 0.682568\n",
      "epoch 9; iter: 0; batch classifier loss: 0.765361; batch adversarial loss: 0.645243\n",
      "epoch 10; iter: 0; batch classifier loss: 0.669224; batch adversarial loss: 0.611523\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506515; batch adversarial loss: 0.565422\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504564; batch adversarial loss: 0.608573\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545919; batch adversarial loss: 0.659909\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547421; batch adversarial loss: 0.583809\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432953; batch adversarial loss: 0.596172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.559215; batch adversarial loss: 0.575059\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528701; batch adversarial loss: 0.564792\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475105; batch adversarial loss: 0.595304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528482; batch adversarial loss: 0.588465\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491904; batch adversarial loss: 0.504201\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495344; batch adversarial loss: 0.617930\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493759; batch adversarial loss: 0.511864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.460369; batch adversarial loss: 0.588370\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494969; batch adversarial loss: 0.549612\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455642; batch adversarial loss: 0.516436\n",
      "epoch 26; iter: 0; batch classifier loss: 0.546185; batch adversarial loss: 0.463337\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447377; batch adversarial loss: 0.542687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491554; batch adversarial loss: 0.493549\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445898; batch adversarial loss: 0.533626\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467880; batch adversarial loss: 0.548501\n",
      "epoch 31; iter: 0; batch classifier loss: 0.547836; batch adversarial loss: 0.486343\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465201; batch adversarial loss: 0.481395\n",
      "epoch 33; iter: 0; batch classifier loss: 0.511485; batch adversarial loss: 0.566820\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477583; batch adversarial loss: 0.509178\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466358; batch adversarial loss: 0.586408\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402193; batch adversarial loss: 0.543620\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495958; batch adversarial loss: 0.567037\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455809; batch adversarial loss: 0.512818\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454899; batch adversarial loss: 0.547459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467887; batch adversarial loss: 0.492194\n",
      "epoch 41; iter: 0; batch classifier loss: 0.383322; batch adversarial loss: 0.613869\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482837; batch adversarial loss: 0.572322\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435517; batch adversarial loss: 0.522950\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460327; batch adversarial loss: 0.577704\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480637; batch adversarial loss: 0.491875\n",
      "epoch 46; iter: 0; batch classifier loss: 0.390511; batch adversarial loss: 0.506401\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440271; batch adversarial loss: 0.619424\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473009; batch adversarial loss: 0.540875\n",
      "epoch 49; iter: 0; batch classifier loss: 0.533212; batch adversarial loss: 0.578203\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423289; batch adversarial loss: 0.510308\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408881; batch adversarial loss: 0.484075\n",
      "epoch 52; iter: 0; batch classifier loss: 0.482268; batch adversarial loss: 0.505899\n",
      "epoch 53; iter: 0; batch classifier loss: 0.357981; batch adversarial loss: 0.483579\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411407; batch adversarial loss: 0.486778\n",
      "epoch 55; iter: 0; batch classifier loss: 0.424671; batch adversarial loss: 0.601480\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396489; batch adversarial loss: 0.554228\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411369; batch adversarial loss: 0.583995\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391194; batch adversarial loss: 0.528500\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388637; batch adversarial loss: 0.544437\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428512; batch adversarial loss: 0.616030\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409086; batch adversarial loss: 0.583434\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484294; batch adversarial loss: 0.508974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383487; batch adversarial loss: 0.471644\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439505; batch adversarial loss: 0.570006\n",
      "epoch 65; iter: 0; batch classifier loss: 0.446476; batch adversarial loss: 0.563498\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396164; batch adversarial loss: 0.507361\n",
      "epoch 67; iter: 0; batch classifier loss: 0.337691; batch adversarial loss: 0.554438\n",
      "epoch 68; iter: 0; batch classifier loss: 0.476913; batch adversarial loss: 0.507274\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378783; batch adversarial loss: 0.553188\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407754; batch adversarial loss: 0.479480\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414549; batch adversarial loss: 0.620339\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387703; batch adversarial loss: 0.470470\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386478; batch adversarial loss: 0.579784\n",
      "epoch 74; iter: 0; batch classifier loss: 0.362231; batch adversarial loss: 0.551616\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436754; batch adversarial loss: 0.571913\n",
      "epoch 76; iter: 0; batch classifier loss: 0.448146; batch adversarial loss: 0.543153\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434088; batch adversarial loss: 0.509709\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413490; batch adversarial loss: 0.601166\n",
      "epoch 79; iter: 0; batch classifier loss: 0.334690; batch adversarial loss: 0.572235\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400371; batch adversarial loss: 0.516426\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461714; batch adversarial loss: 0.516882\n",
      "epoch 82; iter: 0; batch classifier loss: 0.336687; batch adversarial loss: 0.636320\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387489; batch adversarial loss: 0.535197\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407534; batch adversarial loss: 0.490054\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396145; batch adversarial loss: 0.597643\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360025; batch adversarial loss: 0.587947\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365978; batch adversarial loss: 0.616622\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371855; batch adversarial loss: 0.507587\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401858; batch adversarial loss: 0.553512\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370471; batch adversarial loss: 0.535067\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387526; batch adversarial loss: 0.498075\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417021; batch adversarial loss: 0.480132\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407610; batch adversarial loss: 0.501299\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436731; batch adversarial loss: 0.579812\n",
      "epoch 95; iter: 0; batch classifier loss: 0.304819; batch adversarial loss: 0.509950\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390837; batch adversarial loss: 0.560630\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404186; batch adversarial loss: 0.480547\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351334; batch adversarial loss: 0.525376\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414309; batch adversarial loss: 0.555609\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365159; batch adversarial loss: 0.554480\n",
      "epoch 101; iter: 0; batch classifier loss: 0.350984; batch adversarial loss: 0.593121\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345714; batch adversarial loss: 0.599870\n",
      "epoch 103; iter: 0; batch classifier loss: 0.267245; batch adversarial loss: 0.564018\n",
      "epoch 104; iter: 0; batch classifier loss: 0.334328; batch adversarial loss: 0.526920\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383688; batch adversarial loss: 0.536626\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383325; batch adversarial loss: 0.567573\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361619; batch adversarial loss: 0.579340\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357062; batch adversarial loss: 0.571836\n",
      "epoch 109; iter: 0; batch classifier loss: 0.431989; batch adversarial loss: 0.506682\n",
      "epoch 110; iter: 0; batch classifier loss: 0.323923; batch adversarial loss: 0.543226\n",
      "epoch 111; iter: 0; batch classifier loss: 0.327331; batch adversarial loss: 0.562113\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365741; batch adversarial loss: 0.535015\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381291; batch adversarial loss: 0.515278\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387237; batch adversarial loss: 0.616508\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360376; batch adversarial loss: 0.580445\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389259; batch adversarial loss: 0.497844\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414285; batch adversarial loss: 0.479850\n",
      "epoch 118; iter: 0; batch classifier loss: 0.314775; batch adversarial loss: 0.559863\n",
      "epoch 119; iter: 0; batch classifier loss: 0.298554; batch adversarial loss: 0.461131\n",
      "epoch 120; iter: 0; batch classifier loss: 0.479661; batch adversarial loss: 0.539111\n",
      "epoch 121; iter: 0; batch classifier loss: 0.289141; batch adversarial loss: 0.536528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.325892; batch adversarial loss: 0.572321\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377357; batch adversarial loss: 0.581573\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337921; batch adversarial loss: 0.478699\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395972; batch adversarial loss: 0.508195\n",
      "epoch 126; iter: 0; batch classifier loss: 0.306710; batch adversarial loss: 0.552605\n",
      "epoch 127; iter: 0; batch classifier loss: 0.279198; batch adversarial loss: 0.636169\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375410; batch adversarial loss: 0.624955\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365797; batch adversarial loss: 0.436142\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397112; batch adversarial loss: 0.537247\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374702; batch adversarial loss: 0.545932\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339831; batch adversarial loss: 0.543491\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314108; batch adversarial loss: 0.480480\n",
      "epoch 134; iter: 0; batch classifier loss: 0.316303; batch adversarial loss: 0.567780\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320115; batch adversarial loss: 0.524604\n",
      "epoch 136; iter: 0; batch classifier loss: 0.299424; batch adversarial loss: 0.572324\n",
      "epoch 137; iter: 0; batch classifier loss: 0.387994; batch adversarial loss: 0.602613\n",
      "epoch 138; iter: 0; batch classifier loss: 0.332730; batch adversarial loss: 0.552189\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393168; batch adversarial loss: 0.574501\n",
      "epoch 140; iter: 0; batch classifier loss: 0.351721; batch adversarial loss: 0.534415\n",
      "epoch 141; iter: 0; batch classifier loss: 0.303895; batch adversarial loss: 0.505617\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412256; batch adversarial loss: 0.577435\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337135; batch adversarial loss: 0.547324\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380027; batch adversarial loss: 0.534418\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391023; batch adversarial loss: 0.575165\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410163; batch adversarial loss: 0.592143\n",
      "epoch 147; iter: 0; batch classifier loss: 0.300770; batch adversarial loss: 0.600695\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331207; batch adversarial loss: 0.590678\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368428; batch adversarial loss: 0.506225\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389821; batch adversarial loss: 0.562306\n",
      "epoch 151; iter: 0; batch classifier loss: 0.342217; batch adversarial loss: 0.527200\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353591; batch adversarial loss: 0.506977\n",
      "epoch 153; iter: 0; batch classifier loss: 0.303148; batch adversarial loss: 0.553622\n",
      "epoch 154; iter: 0; batch classifier loss: 0.413676; batch adversarial loss: 0.544632\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374414; batch adversarial loss: 0.558459\n",
      "epoch 156; iter: 0; batch classifier loss: 0.442700; batch adversarial loss: 0.518359\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329709; batch adversarial loss: 0.552830\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338313; batch adversarial loss: 0.510445\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342737; batch adversarial loss: 0.545043\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344877; batch adversarial loss: 0.606910\n",
      "epoch 161; iter: 0; batch classifier loss: 0.294349; batch adversarial loss: 0.541799\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368960; batch adversarial loss: 0.515273\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.590530\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353528; batch adversarial loss: 0.570883\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353529; batch adversarial loss: 0.560913\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378135; batch adversarial loss: 0.563443\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288725; batch adversarial loss: 0.527432\n",
      "epoch 168; iter: 0; batch classifier loss: 0.304819; batch adversarial loss: 0.527489\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386825; batch adversarial loss: 0.535643\n",
      "epoch 170; iter: 0; batch classifier loss: 0.419263; batch adversarial loss: 0.504178\n",
      "epoch 171; iter: 0; batch classifier loss: 0.397315; batch adversarial loss: 0.570483\n",
      "epoch 172; iter: 0; batch classifier loss: 0.301414; batch adversarial loss: 0.581373\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322410; batch adversarial loss: 0.561522\n",
      "epoch 174; iter: 0; batch classifier loss: 0.319803; batch adversarial loss: 0.532521\n",
      "epoch 175; iter: 0; batch classifier loss: 0.370407; batch adversarial loss: 0.582340\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339939; batch adversarial loss: 0.544583\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316478; batch adversarial loss: 0.599021\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387721; batch adversarial loss: 0.519291\n",
      "epoch 179; iter: 0; batch classifier loss: 0.288038; batch adversarial loss: 0.509696\n",
      "epoch 180; iter: 0; batch classifier loss: 0.446540; batch adversarial loss: 0.543903\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360900; batch adversarial loss: 0.442356\n",
      "epoch 182; iter: 0; batch classifier loss: 0.428330; batch adversarial loss: 0.557230\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429717; batch adversarial loss: 0.513568\n",
      "epoch 184; iter: 0; batch classifier loss: 0.292770; batch adversarial loss: 0.452483\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360387; batch adversarial loss: 0.543139\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327396; batch adversarial loss: 0.563209\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424430; batch adversarial loss: 0.486790\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302492; batch adversarial loss: 0.638359\n",
      "epoch 189; iter: 0; batch classifier loss: 0.308466; batch adversarial loss: 0.533959\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333589; batch adversarial loss: 0.534074\n",
      "epoch 191; iter: 0; batch classifier loss: 0.296317; batch adversarial loss: 0.587912\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335750; batch adversarial loss: 0.589404\n",
      "epoch 193; iter: 0; batch classifier loss: 0.257738; batch adversarial loss: 0.470132\n",
      "epoch 194; iter: 0; batch classifier loss: 0.402165; batch adversarial loss: 0.554262\n",
      "epoch 195; iter: 0; batch classifier loss: 0.305450; batch adversarial loss: 0.551394\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377671; batch adversarial loss: 0.517313\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340164; batch adversarial loss: 0.606987\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384925; batch adversarial loss: 0.580223\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331310; batch adversarial loss: 0.597860\n",
      "epoch 0; iter: 0; batch classifier loss: 0.786811; batch adversarial loss: 0.710959\n",
      "epoch 1; iter: 0; batch classifier loss: 0.620236; batch adversarial loss: 0.679234\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585676; batch adversarial loss: 0.654521\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623681; batch adversarial loss: 0.611345\n",
      "epoch 4; iter: 0; batch classifier loss: 0.458590; batch adversarial loss: 0.597136\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521721; batch adversarial loss: 0.584612\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578579; batch adversarial loss: 0.555905\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488908; batch adversarial loss: 0.592475\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549316; batch adversarial loss: 0.560892\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521835; batch adversarial loss: 0.535170\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485838; batch adversarial loss: 0.525357\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528835; batch adversarial loss: 0.529446\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470309; batch adversarial loss: 0.519535\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566428; batch adversarial loss: 0.650421\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478040; batch adversarial loss: 0.560003\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540700; batch adversarial loss: 0.614550\n",
      "epoch 16; iter: 0; batch classifier loss: 0.582258; batch adversarial loss: 0.520378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.555637; batch adversarial loss: 0.593505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471739; batch adversarial loss: 0.570275\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531503; batch adversarial loss: 0.550007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.429366; batch adversarial loss: 0.581897\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429019; batch adversarial loss: 0.517065\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494208; batch adversarial loss: 0.564434\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432547; batch adversarial loss: 0.532213\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468911; batch adversarial loss: 0.607269\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462454; batch adversarial loss: 0.550451\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470810; batch adversarial loss: 0.541125\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500016; batch adversarial loss: 0.547189\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414598; batch adversarial loss: 0.522967\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507622; batch adversarial loss: 0.496762\n",
      "epoch 30; iter: 0; batch classifier loss: 0.501865; batch adversarial loss: 0.621317\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479577; batch adversarial loss: 0.535982\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495433; batch adversarial loss: 0.552504\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412768; batch adversarial loss: 0.553324\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459597; batch adversarial loss: 0.597553\n",
      "epoch 35; iter: 0; batch classifier loss: 0.401396; batch adversarial loss: 0.625397\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397351; batch adversarial loss: 0.490464\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431804; batch adversarial loss: 0.536055\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424936; batch adversarial loss: 0.524112\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399192; batch adversarial loss: 0.471628\n",
      "epoch 40; iter: 0; batch classifier loss: 0.538127; batch adversarial loss: 0.563007\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418176; batch adversarial loss: 0.627429\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489390; batch adversarial loss: 0.489600\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395853; batch adversarial loss: 0.498372\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446967; batch adversarial loss: 0.553802\n",
      "epoch 45; iter: 0; batch classifier loss: 0.508588; batch adversarial loss: 0.517128\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356612; batch adversarial loss: 0.507205\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483338; batch adversarial loss: 0.489196\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406811; batch adversarial loss: 0.553859\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461654; batch adversarial loss: 0.599861\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465371; batch adversarial loss: 0.461434\n",
      "epoch 51; iter: 0; batch classifier loss: 0.367201; batch adversarial loss: 0.479482\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426101; batch adversarial loss: 0.563051\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417982; batch adversarial loss: 0.596849\n",
      "epoch 54; iter: 0; batch classifier loss: 0.480838; batch adversarial loss: 0.544996\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378748; batch adversarial loss: 0.563777\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412042; batch adversarial loss: 0.524998\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421093; batch adversarial loss: 0.470749\n",
      "epoch 58; iter: 0; batch classifier loss: 0.363143; batch adversarial loss: 0.514178\n",
      "epoch 59; iter: 0; batch classifier loss: 0.488282; batch adversarial loss: 0.535372\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477803; batch adversarial loss: 0.482471\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430831; batch adversarial loss: 0.513733\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425446; batch adversarial loss: 0.589473\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395880; batch adversarial loss: 0.500625\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395576; batch adversarial loss: 0.518297\n",
      "epoch 65; iter: 0; batch classifier loss: 0.351125; batch adversarial loss: 0.496387\n",
      "epoch 66; iter: 0; batch classifier loss: 0.444929; batch adversarial loss: 0.589965\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391764; batch adversarial loss: 0.561130\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406402; batch adversarial loss: 0.444352\n",
      "epoch 69; iter: 0; batch classifier loss: 0.466065; batch adversarial loss: 0.514784\n",
      "epoch 70; iter: 0; batch classifier loss: 0.490972; batch adversarial loss: 0.525842\n",
      "epoch 71; iter: 0; batch classifier loss: 0.430227; batch adversarial loss: 0.544147\n",
      "epoch 72; iter: 0; batch classifier loss: 0.351104; batch adversarial loss: 0.603289\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419397; batch adversarial loss: 0.572743\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464746; batch adversarial loss: 0.477477\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448971; batch adversarial loss: 0.536741\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379076; batch adversarial loss: 0.529022\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395891; batch adversarial loss: 0.618899\n",
      "epoch 78; iter: 0; batch classifier loss: 0.465107; batch adversarial loss: 0.589815\n",
      "epoch 79; iter: 0; batch classifier loss: 0.445680; batch adversarial loss: 0.552585\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403317; batch adversarial loss: 0.534342\n",
      "epoch 81; iter: 0; batch classifier loss: 0.342732; batch adversarial loss: 0.550920\n",
      "epoch 82; iter: 0; batch classifier loss: 0.316439; batch adversarial loss: 0.590792\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443524; batch adversarial loss: 0.610868\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391728; batch adversarial loss: 0.499627\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403004; batch adversarial loss: 0.623031\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378954; batch adversarial loss: 0.533597\n",
      "epoch 87; iter: 0; batch classifier loss: 0.296407; batch adversarial loss: 0.554720\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357361; batch adversarial loss: 0.659868\n",
      "epoch 89; iter: 0; batch classifier loss: 0.446646; batch adversarial loss: 0.535708\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388745; batch adversarial loss: 0.544685\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432052; batch adversarial loss: 0.627694\n",
      "epoch 92; iter: 0; batch classifier loss: 0.443735; batch adversarial loss: 0.575645\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451840; batch adversarial loss: 0.534925\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371425; batch adversarial loss: 0.555304\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430001; batch adversarial loss: 0.592030\n",
      "epoch 96; iter: 0; batch classifier loss: 0.447063; batch adversarial loss: 0.536385\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408250; batch adversarial loss: 0.601181\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373106; batch adversarial loss: 0.527918\n",
      "epoch 99; iter: 0; batch classifier loss: 0.383885; batch adversarial loss: 0.516663\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396366; batch adversarial loss: 0.543809\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376564; batch adversarial loss: 0.467943\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347143; batch adversarial loss: 0.581961\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408309; batch adversarial loss: 0.514874\n",
      "epoch 104; iter: 0; batch classifier loss: 0.402226; batch adversarial loss: 0.572757\n",
      "epoch 105; iter: 0; batch classifier loss: 0.356668; batch adversarial loss: 0.553484\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328983; batch adversarial loss: 0.526030\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421999; batch adversarial loss: 0.507154\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380602; batch adversarial loss: 0.609077\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363418; batch adversarial loss: 0.572879\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387571; batch adversarial loss: 0.498957\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395899; batch adversarial loss: 0.496942\n",
      "epoch 112; iter: 0; batch classifier loss: 0.311516; batch adversarial loss: 0.506931\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383376; batch adversarial loss: 0.572347\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327948; batch adversarial loss: 0.525694\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345226; batch adversarial loss: 0.488208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356655; batch adversarial loss: 0.545223\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393818; batch adversarial loss: 0.450238\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335246; batch adversarial loss: 0.479568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.464126; batch adversarial loss: 0.593750\n",
      "epoch 120; iter: 0; batch classifier loss: 0.335628; batch adversarial loss: 0.507599\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370785; batch adversarial loss: 0.534492\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371515; batch adversarial loss: 0.488098\n",
      "epoch 123; iter: 0; batch classifier loss: 0.383837; batch adversarial loss: 0.564520\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399638; batch adversarial loss: 0.543786\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350738; batch adversarial loss: 0.479867\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366184; batch adversarial loss: 0.552643\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340148; batch adversarial loss: 0.468842\n",
      "epoch 128; iter: 0; batch classifier loss: 0.307353; batch adversarial loss: 0.507478\n",
      "epoch 129; iter: 0; batch classifier loss: 0.421487; batch adversarial loss: 0.573790\n",
      "epoch 130; iter: 0; batch classifier loss: 0.468953; batch adversarial loss: 0.518405\n",
      "epoch 131; iter: 0; batch classifier loss: 0.357530; batch adversarial loss: 0.470670\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389676; batch adversarial loss: 0.516941\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396549; batch adversarial loss: 0.564201\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358570; batch adversarial loss: 0.582965\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360092; batch adversarial loss: 0.480149\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357515; batch adversarial loss: 0.611524\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370035; batch adversarial loss: 0.470565\n",
      "epoch 138; iter: 0; batch classifier loss: 0.420003; batch adversarial loss: 0.573029\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383858; batch adversarial loss: 0.525666\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377695; batch adversarial loss: 0.506740\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403770; batch adversarial loss: 0.506473\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415403; batch adversarial loss: 0.581756\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352467; batch adversarial loss: 0.619946\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376181; batch adversarial loss: 0.479627\n",
      "epoch 145; iter: 0; batch classifier loss: 0.388840; batch adversarial loss: 0.610135\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330485; batch adversarial loss: 0.478459\n",
      "epoch 147; iter: 0; batch classifier loss: 0.412140; batch adversarial loss: 0.583574\n",
      "epoch 148; iter: 0; batch classifier loss: 0.282478; batch adversarial loss: 0.517567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346241; batch adversarial loss: 0.532717\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367175; batch adversarial loss: 0.524761\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338091; batch adversarial loss: 0.572281\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322703; batch adversarial loss: 0.546141\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407798; batch adversarial loss: 0.478015\n",
      "epoch 154; iter: 0; batch classifier loss: 0.398280; batch adversarial loss: 0.529426\n",
      "epoch 155; iter: 0; batch classifier loss: 0.425865; batch adversarial loss: 0.541650\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319554; batch adversarial loss: 0.534669\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376882; batch adversarial loss: 0.545289\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373197; batch adversarial loss: 0.554679\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380780; batch adversarial loss: 0.449326\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372770; batch adversarial loss: 0.499686\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392973; batch adversarial loss: 0.537307\n",
      "epoch 162; iter: 0; batch classifier loss: 0.300966; batch adversarial loss: 0.515672\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369941; batch adversarial loss: 0.512634\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373774; batch adversarial loss: 0.570205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359001; batch adversarial loss: 0.561768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387363; batch adversarial loss: 0.548864\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409217; batch adversarial loss: 0.592785\n",
      "epoch 168; iter: 0; batch classifier loss: 0.427847; batch adversarial loss: 0.575683\n",
      "epoch 169; iter: 0; batch classifier loss: 0.396885; batch adversarial loss: 0.531646\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374320; batch adversarial loss: 0.566552\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295562; batch adversarial loss: 0.534784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385783; batch adversarial loss: 0.509681\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392562; batch adversarial loss: 0.517338\n",
      "epoch 174; iter: 0; batch classifier loss: 0.306536; batch adversarial loss: 0.573154\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325164; batch adversarial loss: 0.535782\n",
      "epoch 176; iter: 0; batch classifier loss: 0.317228; batch adversarial loss: 0.517813\n",
      "epoch 177; iter: 0; batch classifier loss: 0.408630; batch adversarial loss: 0.487544\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287446; batch adversarial loss: 0.554960\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343358; batch adversarial loss: 0.591931\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333306; batch adversarial loss: 0.507411\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395925; batch adversarial loss: 0.516184\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399351; batch adversarial loss: 0.488183\n",
      "epoch 183; iter: 0; batch classifier loss: 0.368931; batch adversarial loss: 0.536002\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387427; batch adversarial loss: 0.534429\n",
      "epoch 185; iter: 0; batch classifier loss: 0.405591; batch adversarial loss: 0.478344\n",
      "epoch 186; iter: 0; batch classifier loss: 0.305107; batch adversarial loss: 0.506786\n",
      "epoch 187; iter: 0; batch classifier loss: 0.297405; batch adversarial loss: 0.590011\n",
      "epoch 188; iter: 0; batch classifier loss: 0.380507; batch adversarial loss: 0.563943\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328734; batch adversarial loss: 0.553380\n",
      "epoch 190; iter: 0; batch classifier loss: 0.305509; batch adversarial loss: 0.620081\n",
      "epoch 191; iter: 0; batch classifier loss: 0.376195; batch adversarial loss: 0.544121\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340393; batch adversarial loss: 0.582245\n",
      "epoch 193; iter: 0; batch classifier loss: 0.393300; batch adversarial loss: 0.562024\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314008; batch adversarial loss: 0.515721\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328087; batch adversarial loss: 0.592120\n",
      "epoch 196; iter: 0; batch classifier loss: 0.319970; batch adversarial loss: 0.488639\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357819; batch adversarial loss: 0.507363\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372418; batch adversarial loss: 0.553881\n",
      "epoch 199; iter: 0; batch classifier loss: 0.443846; batch adversarial loss: 0.507417\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712307; batch adversarial loss: 0.981244\n",
      "epoch 1; iter: 0; batch classifier loss: 0.938602; batch adversarial loss: 1.264074\n",
      "epoch 2; iter: 0; batch classifier loss: 1.015222; batch adversarial loss: 1.123289\n",
      "epoch 3; iter: 0; batch classifier loss: 1.026803; batch adversarial loss: 1.016755\n",
      "epoch 4; iter: 0; batch classifier loss: 1.210379; batch adversarial loss: 1.064542\n",
      "epoch 5; iter: 0; batch classifier loss: 0.932432; batch adversarial loss: 0.879110\n",
      "epoch 6; iter: 0; batch classifier loss: 0.962316; batch adversarial loss: 0.880629\n",
      "epoch 7; iter: 0; batch classifier loss: 0.961598; batch adversarial loss: 0.806143\n",
      "epoch 8; iter: 0; batch classifier loss: 0.848139; batch adversarial loss: 0.716286\n",
      "epoch 9; iter: 0; batch classifier loss: 0.716995; batch adversarial loss: 0.651822\n",
      "epoch 10; iter: 0; batch classifier loss: 0.626424; batch adversarial loss: 0.650905\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540784; batch adversarial loss: 0.622703\n",
      "epoch 12; iter: 0; batch classifier loss: 0.541474; batch adversarial loss: 0.625420\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586213; batch adversarial loss: 0.575441\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456644; batch adversarial loss: 0.614132\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486409; batch adversarial loss: 0.587066\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532940; batch adversarial loss: 0.570419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.483551; batch adversarial loss: 0.629021\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560681; batch adversarial loss: 0.515384\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490499; batch adversarial loss: 0.546732\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468681; batch adversarial loss: 0.576455\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476558; batch adversarial loss: 0.580007\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533000; batch adversarial loss: 0.524426\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487703; batch adversarial loss: 0.610796\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511759; batch adversarial loss: 0.579733\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511473; batch adversarial loss: 0.584151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.535752; batch adversarial loss: 0.527186\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455174; batch adversarial loss: 0.628881\n",
      "epoch 28; iter: 0; batch classifier loss: 0.534602; batch adversarial loss: 0.565011\n",
      "epoch 29; iter: 0; batch classifier loss: 0.470152; batch adversarial loss: 0.590764\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450142; batch adversarial loss: 0.577540\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456431; batch adversarial loss: 0.587685\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529756; batch adversarial loss: 0.591917\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447440; batch adversarial loss: 0.566213\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447960; batch adversarial loss: 0.532850\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473817; batch adversarial loss: 0.530218\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421172; batch adversarial loss: 0.553460\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497075; batch adversarial loss: 0.590771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438186; batch adversarial loss: 0.506510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.444065; batch adversarial loss: 0.526437\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459021; batch adversarial loss: 0.588764\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499979; batch adversarial loss: 0.595949\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484205; batch adversarial loss: 0.508088\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380114; batch adversarial loss: 0.610245\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464260; batch adversarial loss: 0.592609\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394204; batch adversarial loss: 0.513166\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485422; batch adversarial loss: 0.531452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433897; batch adversarial loss: 0.480228\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453467; batch adversarial loss: 0.571774\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424873; batch adversarial loss: 0.587675\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403917; batch adversarial loss: 0.521019\n",
      "epoch 51; iter: 0; batch classifier loss: 0.472209; batch adversarial loss: 0.628112\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417774; batch adversarial loss: 0.475343\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429481; batch adversarial loss: 0.538561\n",
      "epoch 54; iter: 0; batch classifier loss: 0.444354; batch adversarial loss: 0.519253\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412906; batch adversarial loss: 0.583418\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439368; batch adversarial loss: 0.600446\n",
      "epoch 57; iter: 0; batch classifier loss: 0.372913; batch adversarial loss: 0.483322\n",
      "epoch 58; iter: 0; batch classifier loss: 0.474354; batch adversarial loss: 0.500289\n",
      "epoch 59; iter: 0; batch classifier loss: 0.473337; batch adversarial loss: 0.626784\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427353; batch adversarial loss: 0.555585\n",
      "epoch 61; iter: 0; batch classifier loss: 0.349437; batch adversarial loss: 0.592410\n",
      "epoch 62; iter: 0; batch classifier loss: 0.447619; batch adversarial loss: 0.626599\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391342; batch adversarial loss: 0.435717\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376147; batch adversarial loss: 0.527365\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407553; batch adversarial loss: 0.544494\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375970; batch adversarial loss: 0.553858\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429584; batch adversarial loss: 0.499075\n",
      "epoch 68; iter: 0; batch classifier loss: 0.492305; batch adversarial loss: 0.589918\n",
      "epoch 69; iter: 0; batch classifier loss: 0.391916; batch adversarial loss: 0.535565\n",
      "epoch 70; iter: 0; batch classifier loss: 0.345836; batch adversarial loss: 0.517681\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423456; batch adversarial loss: 0.435234\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372869; batch adversarial loss: 0.525481\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349195; batch adversarial loss: 0.589629\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354601; batch adversarial loss: 0.489712\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369893; batch adversarial loss: 0.526705\n",
      "epoch 76; iter: 0; batch classifier loss: 0.447965; batch adversarial loss: 0.507873\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364699; batch adversarial loss: 0.553756\n",
      "epoch 78; iter: 0; batch classifier loss: 0.364329; batch adversarial loss: 0.500784\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415443; batch adversarial loss: 0.535124\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330884; batch adversarial loss: 0.543822\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396823; batch adversarial loss: 0.580486\n",
      "epoch 82; iter: 0; batch classifier loss: 0.333092; batch adversarial loss: 0.525022\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401127; batch adversarial loss: 0.570528\n",
      "epoch 84; iter: 0; batch classifier loss: 0.442723; batch adversarial loss: 0.533652\n",
      "epoch 85; iter: 0; batch classifier loss: 0.331636; batch adversarial loss: 0.478385\n",
      "epoch 86; iter: 0; batch classifier loss: 0.434439; batch adversarial loss: 0.553529\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404969; batch adversarial loss: 0.555101\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412166; batch adversarial loss: 0.584787\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342064; batch adversarial loss: 0.605431\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365422; batch adversarial loss: 0.534796\n",
      "epoch 91; iter: 0; batch classifier loss: 0.311672; batch adversarial loss: 0.569334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353432; batch adversarial loss: 0.614288\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363795; batch adversarial loss: 0.552731\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384264; batch adversarial loss: 0.609890\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392012; batch adversarial loss: 0.562534\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425659; batch adversarial loss: 0.476998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.312664; batch adversarial loss: 0.597275\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415252; batch adversarial loss: 0.539041\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348554; batch adversarial loss: 0.465108\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346060; batch adversarial loss: 0.540377\n",
      "epoch 101; iter: 0; batch classifier loss: 0.343682; batch adversarial loss: 0.478794\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427195; batch adversarial loss: 0.507097\n",
      "epoch 103; iter: 0; batch classifier loss: 0.467336; batch adversarial loss: 0.609548\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365441; batch adversarial loss: 0.490627\n",
      "epoch 105; iter: 0; batch classifier loss: 0.312573; batch adversarial loss: 0.479289\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331044; batch adversarial loss: 0.532769\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319759; batch adversarial loss: 0.604180\n",
      "epoch 108; iter: 0; batch classifier loss: 0.349094; batch adversarial loss: 0.522473\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406116; batch adversarial loss: 0.526995\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383735; batch adversarial loss: 0.571646\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428123; batch adversarial loss: 0.496021\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403036; batch adversarial loss: 0.635507\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387602; batch adversarial loss: 0.579356\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361617; batch adversarial loss: 0.596874\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416665; batch adversarial loss: 0.551565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.308088; batch adversarial loss: 0.523915\n",
      "epoch 117; iter: 0; batch classifier loss: 0.344225; batch adversarial loss: 0.486737\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386883; batch adversarial loss: 0.540400\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384850; batch adversarial loss: 0.469558\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383529; batch adversarial loss: 0.509262\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334341; batch adversarial loss: 0.597159\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384246; batch adversarial loss: 0.525643\n",
      "epoch 123; iter: 0; batch classifier loss: 0.313768; batch adversarial loss: 0.545819\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392762; batch adversarial loss: 0.556293\n",
      "epoch 125; iter: 0; batch classifier loss: 0.285701; batch adversarial loss: 0.497073\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375627; batch adversarial loss: 0.495195\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348144; batch adversarial loss: 0.505041\n",
      "epoch 128; iter: 0; batch classifier loss: 0.288374; batch adversarial loss: 0.619631\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378700; batch adversarial loss: 0.555514\n",
      "epoch 130; iter: 0; batch classifier loss: 0.305772; batch adversarial loss: 0.531925\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364331; batch adversarial loss: 0.550490\n",
      "epoch 132; iter: 0; batch classifier loss: 0.324906; batch adversarial loss: 0.470460\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377119; batch adversarial loss: 0.491438\n",
      "epoch 134; iter: 0; batch classifier loss: 0.448216; batch adversarial loss: 0.556279\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351025; batch adversarial loss: 0.625303\n",
      "epoch 136; iter: 0; batch classifier loss: 0.352804; batch adversarial loss: 0.570365\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349568; batch adversarial loss: 0.561918\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387990; batch adversarial loss: 0.504851\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313614; batch adversarial loss: 0.625322\n",
      "epoch 140; iter: 0; batch classifier loss: 0.287972; batch adversarial loss: 0.520809\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325761; batch adversarial loss: 0.517197\n",
      "epoch 142; iter: 0; batch classifier loss: 0.284656; batch adversarial loss: 0.570109\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359278; batch adversarial loss: 0.454744\n",
      "epoch 144; iter: 0; batch classifier loss: 0.403737; batch adversarial loss: 0.567320\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350484; batch adversarial loss: 0.607507\n",
      "epoch 146; iter: 0; batch classifier loss: 0.372148; batch adversarial loss: 0.531716\n",
      "epoch 147; iter: 0; batch classifier loss: 0.398377; batch adversarial loss: 0.589793\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330543; batch adversarial loss: 0.557225\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333371; batch adversarial loss: 0.586041\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362165; batch adversarial loss: 0.540288\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323418; batch adversarial loss: 0.563256\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386911; batch adversarial loss: 0.485262\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376077; batch adversarial loss: 0.521880\n",
      "epoch 154; iter: 0; batch classifier loss: 0.277300; batch adversarial loss: 0.629335\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343106; batch adversarial loss: 0.509899\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312369; batch adversarial loss: 0.580403\n",
      "epoch 157; iter: 0; batch classifier loss: 0.280786; batch adversarial loss: 0.577282\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333221; batch adversarial loss: 0.542799\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362783; batch adversarial loss: 0.567313\n",
      "epoch 160; iter: 0; batch classifier loss: 0.290908; batch adversarial loss: 0.426530\n",
      "epoch 161; iter: 0; batch classifier loss: 0.320256; batch adversarial loss: 0.542765\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356172; batch adversarial loss: 0.553239\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360830; batch adversarial loss: 0.477878\n",
      "epoch 164; iter: 0; batch classifier loss: 0.399671; batch adversarial loss: 0.593142\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350675; batch adversarial loss: 0.540034\n",
      "epoch 166; iter: 0; batch classifier loss: 0.442429; batch adversarial loss: 0.493476\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345641; batch adversarial loss: 0.511790\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352301; batch adversarial loss: 0.592693\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349070; batch adversarial loss: 0.559177\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342832; batch adversarial loss: 0.542866\n",
      "epoch 171; iter: 0; batch classifier loss: 0.425246; batch adversarial loss: 0.593218\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332991; batch adversarial loss: 0.583381\n",
      "epoch 173; iter: 0; batch classifier loss: 0.319042; batch adversarial loss: 0.544166\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355540; batch adversarial loss: 0.483097\n",
      "epoch 175; iter: 0; batch classifier loss: 0.245922; batch adversarial loss: 0.537141\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395814; batch adversarial loss: 0.508712\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383858; batch adversarial loss: 0.593453\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344298; batch adversarial loss: 0.579820\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308110; batch adversarial loss: 0.601844\n",
      "epoch 180; iter: 0; batch classifier loss: 0.333839; batch adversarial loss: 0.515781\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348933; batch adversarial loss: 0.558188\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320854; batch adversarial loss: 0.488881\n",
      "epoch 183; iter: 0; batch classifier loss: 0.320375; batch adversarial loss: 0.525461\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328743; batch adversarial loss: 0.553799\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398039; batch adversarial loss: 0.504208\n",
      "epoch 186; iter: 0; batch classifier loss: 0.317244; batch adversarial loss: 0.490110\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353950; batch adversarial loss: 0.517642\n",
      "epoch 188; iter: 0; batch classifier loss: 0.305217; batch adversarial loss: 0.564412\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361360; batch adversarial loss: 0.612865\n",
      "epoch 190; iter: 0; batch classifier loss: 0.269606; batch adversarial loss: 0.581266\n",
      "epoch 191; iter: 0; batch classifier loss: 0.284025; batch adversarial loss: 0.404499\n",
      "epoch 192; iter: 0; batch classifier loss: 0.309411; batch adversarial loss: 0.610920\n",
      "epoch 193; iter: 0; batch classifier loss: 0.299304; batch adversarial loss: 0.590561\n",
      "epoch 194; iter: 0; batch classifier loss: 0.418128; batch adversarial loss: 0.566775\n",
      "epoch 195; iter: 0; batch classifier loss: 0.420800; batch adversarial loss: 0.575101\n",
      "epoch 196; iter: 0; batch classifier loss: 0.344651; batch adversarial loss: 0.515524\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385444; batch adversarial loss: 0.458639\n",
      "epoch 198; iter: 0; batch classifier loss: 0.407494; batch adversarial loss: 0.510339\n",
      "epoch 199; iter: 0; batch classifier loss: 0.322459; batch adversarial loss: 0.531898\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701577; batch adversarial loss: 0.603039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573986; batch adversarial loss: 0.640840\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593489; batch adversarial loss: 0.652623\n",
      "epoch 3; iter: 0; batch classifier loss: 0.475665; batch adversarial loss: 0.636161\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549444; batch adversarial loss: 0.627783\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582399; batch adversarial loss: 0.632949\n",
      "epoch 6; iter: 0; batch classifier loss: 0.621556; batch adversarial loss: 0.641731\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571147; batch adversarial loss: 0.629495\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517756; batch adversarial loss: 0.586950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.593256; batch adversarial loss: 0.645872\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502990; batch adversarial loss: 0.554304\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495595; batch adversarial loss: 0.552825\n",
      "epoch 12; iter: 0; batch classifier loss: 0.583233; batch adversarial loss: 0.559455\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551631; batch adversarial loss: 0.556170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.573050; batch adversarial loss: 0.551353\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488126; batch adversarial loss: 0.582863\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553650; batch adversarial loss: 0.597418\n",
      "epoch 17; iter: 0; batch classifier loss: 0.562644; batch adversarial loss: 0.552832\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488702; batch adversarial loss: 0.546828\n",
      "epoch 19; iter: 0; batch classifier loss: 0.409926; batch adversarial loss: 0.561700\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450772; batch adversarial loss: 0.569513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485618; batch adversarial loss: 0.520705\n",
      "epoch 22; iter: 0; batch classifier loss: 0.616687; batch adversarial loss: 0.615323\n",
      "epoch 23; iter: 0; batch classifier loss: 0.571076; batch adversarial loss: 0.493324\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478963; batch adversarial loss: 0.498884\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429597; batch adversarial loss: 0.554654\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490290; batch adversarial loss: 0.504330\n",
      "epoch 27; iter: 0; batch classifier loss: 0.542834; batch adversarial loss: 0.570613\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504271; batch adversarial loss: 0.588166\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482469; batch adversarial loss: 0.588145\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486765; batch adversarial loss: 0.554318\n",
      "epoch 31; iter: 0; batch classifier loss: 0.502724; batch adversarial loss: 0.598132\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506541; batch adversarial loss: 0.562553\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433360; batch adversarial loss: 0.580496\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450541; batch adversarial loss: 0.562758\n",
      "epoch 35; iter: 0; batch classifier loss: 0.401711; batch adversarial loss: 0.544617\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478952; batch adversarial loss: 0.562332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485644; batch adversarial loss: 0.526777\n",
      "epoch 38; iter: 0; batch classifier loss: 0.546532; batch adversarial loss: 0.590971\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420123; batch adversarial loss: 0.563146\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432020; batch adversarial loss: 0.563177\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488758; batch adversarial loss: 0.599891\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383214; batch adversarial loss: 0.545173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.376275; batch adversarial loss: 0.581832\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390940; batch adversarial loss: 0.572389\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470528; batch adversarial loss: 0.600360\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467441; batch adversarial loss: 0.580999\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384537; batch adversarial loss: 0.526238\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392984; batch adversarial loss: 0.535578\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436270; batch adversarial loss: 0.544487\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476197; batch adversarial loss: 0.599335\n",
      "epoch 51; iter: 0; batch classifier loss: 0.364286; batch adversarial loss: 0.507659\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435015; batch adversarial loss: 0.553536\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443688; batch adversarial loss: 0.545615\n",
      "epoch 54; iter: 0; batch classifier loss: 0.390076; batch adversarial loss: 0.562802\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395857; batch adversarial loss: 0.534697\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435528; batch adversarial loss: 0.517342\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396540; batch adversarial loss: 0.507058\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428826; batch adversarial loss: 0.507619\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398726; batch adversarial loss: 0.563256\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422452; batch adversarial loss: 0.619667\n",
      "epoch 61; iter: 0; batch classifier loss: 0.448616; batch adversarial loss: 0.535101\n",
      "epoch 62; iter: 0; batch classifier loss: 0.402114; batch adversarial loss: 0.582080\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412347; batch adversarial loss: 0.608917\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424628; batch adversarial loss: 0.535240\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420899; batch adversarial loss: 0.535890\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386594; batch adversarial loss: 0.554229\n",
      "epoch 67; iter: 0; batch classifier loss: 0.467445; batch adversarial loss: 0.535046\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384314; batch adversarial loss: 0.582087\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449652; batch adversarial loss: 0.535742\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424270; batch adversarial loss: 0.553699\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413933; batch adversarial loss: 0.517815\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438887; batch adversarial loss: 0.488790\n",
      "epoch 73; iter: 0; batch classifier loss: 0.469147; batch adversarial loss: 0.581196\n",
      "epoch 74; iter: 0; batch classifier loss: 0.340611; batch adversarial loss: 0.535746\n",
      "epoch 75; iter: 0; batch classifier loss: 0.368692; batch adversarial loss: 0.581762\n",
      "epoch 76; iter: 0; batch classifier loss: 0.457204; batch adversarial loss: 0.489725\n",
      "epoch 77; iter: 0; batch classifier loss: 0.465758; batch adversarial loss: 0.534896\n",
      "epoch 78; iter: 0; batch classifier loss: 0.383977; batch adversarial loss: 0.517540\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353444; batch adversarial loss: 0.525685\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374746; batch adversarial loss: 0.526580\n",
      "epoch 81; iter: 0; batch classifier loss: 0.482432; batch adversarial loss: 0.590044\n",
      "epoch 82; iter: 0; batch classifier loss: 0.292548; batch adversarial loss: 0.516692\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400448; batch adversarial loss: 0.526314\n",
      "epoch 84; iter: 0; batch classifier loss: 0.338639; batch adversarial loss: 0.526101\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406578; batch adversarial loss: 0.460940\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368267; batch adversarial loss: 0.479503\n",
      "epoch 87; iter: 0; batch classifier loss: 0.451787; batch adversarial loss: 0.627985\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437553; batch adversarial loss: 0.497837\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395272; batch adversarial loss: 0.508674\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376566; batch adversarial loss: 0.516956\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395201; batch adversarial loss: 0.581417\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353422; batch adversarial loss: 0.554045\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344334; batch adversarial loss: 0.648164\n",
      "epoch 94; iter: 0; batch classifier loss: 0.427611; batch adversarial loss: 0.601210\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423728; batch adversarial loss: 0.599912\n",
      "epoch 96; iter: 0; batch classifier loss: 0.457006; batch adversarial loss: 0.600290\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374754; batch adversarial loss: 0.582788\n",
      "epoch 98; iter: 0; batch classifier loss: 0.507933; batch adversarial loss: 0.552954\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433070; batch adversarial loss: 0.600258\n",
      "epoch 100; iter: 0; batch classifier loss: 0.414494; batch adversarial loss: 0.554006\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434875; batch adversarial loss: 0.581504\n",
      "epoch 102; iter: 0; batch classifier loss: 0.395708; batch adversarial loss: 0.553610\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406906; batch adversarial loss: 0.525167\n",
      "epoch 104; iter: 0; batch classifier loss: 0.406127; batch adversarial loss: 0.552450\n",
      "epoch 105; iter: 0; batch classifier loss: 0.438671; batch adversarial loss: 0.591644\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419533; batch adversarial loss: 0.536012\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401544; batch adversarial loss: 0.479566\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369757; batch adversarial loss: 0.497883\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369026; batch adversarial loss: 0.544362\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353369; batch adversarial loss: 0.507249\n",
      "epoch 111; iter: 0; batch classifier loss: 0.319162; batch adversarial loss: 0.572264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.392663; batch adversarial loss: 0.610173\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405962; batch adversarial loss: 0.536627\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381231; batch adversarial loss: 0.526233\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357505; batch adversarial loss: 0.518145\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353121; batch adversarial loss: 0.535440\n",
      "epoch 117; iter: 0; batch classifier loss: 0.430192; batch adversarial loss: 0.534801\n",
      "epoch 118; iter: 0; batch classifier loss: 0.348437; batch adversarial loss: 0.534016\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428516; batch adversarial loss: 0.562047\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416352; batch adversarial loss: 0.534043\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351672; batch adversarial loss: 0.545983\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392522; batch adversarial loss: 0.545770\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349456; batch adversarial loss: 0.553885\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367558; batch adversarial loss: 0.534820\n",
      "epoch 125; iter: 0; batch classifier loss: 0.352219; batch adversarial loss: 0.498468\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403820; batch adversarial loss: 0.535011\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352049; batch adversarial loss: 0.469526\n",
      "epoch 128; iter: 0; batch classifier loss: 0.441970; batch adversarial loss: 0.543653\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363478; batch adversarial loss: 0.543117\n",
      "epoch 130; iter: 0; batch classifier loss: 0.464583; batch adversarial loss: 0.646569\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362172; batch adversarial loss: 0.580555\n",
      "epoch 132; iter: 0; batch classifier loss: 0.356180; batch adversarial loss: 0.526386\n",
      "epoch 133; iter: 0; batch classifier loss: 0.462309; batch adversarial loss: 0.563038\n",
      "epoch 134; iter: 0; batch classifier loss: 0.318259; batch adversarial loss: 0.562234\n",
      "epoch 135; iter: 0; batch classifier loss: 0.415664; batch adversarial loss: 0.618733\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406380; batch adversarial loss: 0.525778\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380232; batch adversarial loss: 0.562206\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340526; batch adversarial loss: 0.544603\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377797; batch adversarial loss: 0.536236\n",
      "epoch 140; iter: 0; batch classifier loss: 0.282922; batch adversarial loss: 0.461050\n",
      "epoch 141; iter: 0; batch classifier loss: 0.418664; batch adversarial loss: 0.629220\n",
      "epoch 142; iter: 0; batch classifier loss: 0.485982; batch adversarial loss: 0.563106\n",
      "epoch 143; iter: 0; batch classifier loss: 0.418375; batch adversarial loss: 0.572534\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371011; batch adversarial loss: 0.489604\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348505; batch adversarial loss: 0.526441\n",
      "epoch 146; iter: 0; batch classifier loss: 0.438863; batch adversarial loss: 0.415529\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354105; batch adversarial loss: 0.580734\n",
      "epoch 148; iter: 0; batch classifier loss: 0.411015; batch adversarial loss: 0.524640\n",
      "epoch 149; iter: 0; batch classifier loss: 0.424571; batch adversarial loss: 0.479395\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.508182\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382098; batch adversarial loss: 0.581849\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376779; batch adversarial loss: 0.570333\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335788; batch adversarial loss: 0.516733\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401493; batch adversarial loss: 0.563239\n",
      "epoch 155; iter: 0; batch classifier loss: 0.393188; batch adversarial loss: 0.432860\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384456; batch adversarial loss: 0.611198\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351073; batch adversarial loss: 0.591790\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331517; batch adversarial loss: 0.561659\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372149; batch adversarial loss: 0.579710\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341697; batch adversarial loss: 0.571238\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336640; batch adversarial loss: 0.591488\n",
      "epoch 162; iter: 0; batch classifier loss: 0.303933; batch adversarial loss: 0.572119\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397395; batch adversarial loss: 0.480568\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340946; batch adversarial loss: 0.554365\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336380; batch adversarial loss: 0.579824\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366891; batch adversarial loss: 0.591293\n",
      "epoch 167; iter: 0; batch classifier loss: 0.305749; batch adversarial loss: 0.537160\n",
      "epoch 168; iter: 0; batch classifier loss: 0.319552; batch adversarial loss: 0.499952\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350780; batch adversarial loss: 0.461386\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371788; batch adversarial loss: 0.564332\n",
      "epoch 171; iter: 0; batch classifier loss: 0.435806; batch adversarial loss: 0.598981\n",
      "epoch 172; iter: 0; batch classifier loss: 0.371700; batch adversarial loss: 0.589463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365528; batch adversarial loss: 0.533098\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387538; batch adversarial loss: 0.490960\n",
      "epoch 175; iter: 0; batch classifier loss: 0.315809; batch adversarial loss: 0.593092\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367898; batch adversarial loss: 0.571706\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345410; batch adversarial loss: 0.519320\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389938; batch adversarial loss: 0.478747\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352490; batch adversarial loss: 0.562821\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392620; batch adversarial loss: 0.506250\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342429; batch adversarial loss: 0.581048\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370936; batch adversarial loss: 0.471057\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338921; batch adversarial loss: 0.509195\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379375; batch adversarial loss: 0.507426\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367027; batch adversarial loss: 0.555842\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363391; batch adversarial loss: 0.517844\n",
      "epoch 187; iter: 0; batch classifier loss: 0.402155; batch adversarial loss: 0.553204\n",
      "epoch 188; iter: 0; batch classifier loss: 0.389160; batch adversarial loss: 0.433438\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350415; batch adversarial loss: 0.443247\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326266; batch adversarial loss: 0.561980\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373945; batch adversarial loss: 0.544892\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356720; batch adversarial loss: 0.542819\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359993; batch adversarial loss: 0.488182\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335510; batch adversarial loss: 0.593274\n",
      "epoch 195; iter: 0; batch classifier loss: 0.413362; batch adversarial loss: 0.506881\n",
      "epoch 196; iter: 0; batch classifier loss: 0.325784; batch adversarial loss: 0.626910\n",
      "epoch 197; iter: 0; batch classifier loss: 0.426419; batch adversarial loss: 0.563214\n",
      "epoch 198; iter: 0; batch classifier loss: 0.402276; batch adversarial loss: 0.552865\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340100; batch adversarial loss: 0.545592\n",
      "epoch 0; iter: 0; batch classifier loss: 0.638708; batch adversarial loss: 0.679281\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629287; batch adversarial loss: 0.657083\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573274; batch adversarial loss: 0.671620\n",
      "epoch 3; iter: 0; batch classifier loss: 0.611052; batch adversarial loss: 0.640359\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617317; batch adversarial loss: 0.647365\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559484; batch adversarial loss: 0.668639\n",
      "epoch 6; iter: 0; batch classifier loss: 0.632097; batch adversarial loss: 0.622634\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578964; batch adversarial loss: 0.570833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.645204; batch adversarial loss: 0.613646\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493221; batch adversarial loss: 0.575027\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539967; batch adversarial loss: 0.587781\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496703; batch adversarial loss: 0.570621\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544702; batch adversarial loss: 0.587127\n",
      "epoch 13; iter: 0; batch classifier loss: 0.589677; batch adversarial loss: 0.584835\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480687; batch adversarial loss: 0.590667\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495215; batch adversarial loss: 0.618325\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492035; batch adversarial loss: 0.585628\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468927; batch adversarial loss: 0.607723\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483398; batch adversarial loss: 0.648192\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481179; batch adversarial loss: 0.525741\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470130; batch adversarial loss: 0.624412\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468672; batch adversarial loss: 0.543427\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465695; batch adversarial loss: 0.579939\n",
      "epoch 23; iter: 0; batch classifier loss: 0.448611; batch adversarial loss: 0.501758\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496479; batch adversarial loss: 0.566645\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508345; batch adversarial loss: 0.541355\n",
      "epoch 26; iter: 0; batch classifier loss: 0.537862; batch adversarial loss: 0.590845\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442043; batch adversarial loss: 0.537152\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434587; batch adversarial loss: 0.571465\n",
      "epoch 29; iter: 0; batch classifier loss: 0.550023; batch adversarial loss: 0.579231\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450316; batch adversarial loss: 0.595454\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470169; batch adversarial loss: 0.563659\n",
      "epoch 32; iter: 0; batch classifier loss: 0.476204; batch adversarial loss: 0.526349\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447940; batch adversarial loss: 0.553840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477382; batch adversarial loss: 0.579235\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424627; batch adversarial loss: 0.624188\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432284; batch adversarial loss: 0.571813\n",
      "epoch 37; iter: 0; batch classifier loss: 0.382510; batch adversarial loss: 0.553324\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470234; batch adversarial loss: 0.562289\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466961; batch adversarial loss: 0.526877\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391585; batch adversarial loss: 0.580578\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402725; batch adversarial loss: 0.535543\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481646; batch adversarial loss: 0.490674\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442571; batch adversarial loss: 0.535148\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456438; batch adversarial loss: 0.526950\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377723; batch adversarial loss: 0.590310\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409654; batch adversarial loss: 0.553858\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427720; batch adversarial loss: 0.489684\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399633; batch adversarial loss: 0.517559\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460492; batch adversarial loss: 0.617609\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463937; batch adversarial loss: 0.518152\n",
      "epoch 51; iter: 0; batch classifier loss: 0.495984; batch adversarial loss: 0.537809\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447189; batch adversarial loss: 0.616927\n",
      "epoch 53; iter: 0; batch classifier loss: 0.487871; batch adversarial loss: 0.511555\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453908; batch adversarial loss: 0.579792\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442788; batch adversarial loss: 0.581440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408879; batch adversarial loss: 0.590374\n",
      "epoch 57; iter: 0; batch classifier loss: 0.394621; batch adversarial loss: 0.571347\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416451; batch adversarial loss: 0.535520\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404997; batch adversarial loss: 0.487845\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439644; batch adversarial loss: 0.634334\n",
      "epoch 61; iter: 0; batch classifier loss: 0.405602; batch adversarial loss: 0.596267\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451059; batch adversarial loss: 0.539331\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370750; batch adversarial loss: 0.570445\n",
      "epoch 64; iter: 0; batch classifier loss: 0.487072; batch adversarial loss: 0.584310\n",
      "epoch 65; iter: 0; batch classifier loss: 0.422170; batch adversarial loss: 0.454904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380426; batch adversarial loss: 0.519603\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394068; batch adversarial loss: 0.533698\n",
      "epoch 68; iter: 0; batch classifier loss: 0.351049; batch adversarial loss: 0.554979\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411560; batch adversarial loss: 0.563437\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400917; batch adversarial loss: 0.575538\n",
      "epoch 71; iter: 0; batch classifier loss: 0.367075; batch adversarial loss: 0.524780\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386559; batch adversarial loss: 0.487509\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386195; batch adversarial loss: 0.544729\n",
      "epoch 74; iter: 0; batch classifier loss: 0.325544; batch adversarial loss: 0.507627\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429112; batch adversarial loss: 0.517749\n",
      "epoch 76; iter: 0; batch classifier loss: 0.401720; batch adversarial loss: 0.655244\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376758; batch adversarial loss: 0.516997\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381484; batch adversarial loss: 0.498006\n",
      "epoch 79; iter: 0; batch classifier loss: 0.414107; batch adversarial loss: 0.515178\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350108; batch adversarial loss: 0.519042\n",
      "epoch 81; iter: 0; batch classifier loss: 0.438142; batch adversarial loss: 0.517683\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367253; batch adversarial loss: 0.491121\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364064; batch adversarial loss: 0.580145\n",
      "epoch 84; iter: 0; batch classifier loss: 0.454537; batch adversarial loss: 0.534878\n",
      "epoch 85; iter: 0; batch classifier loss: 0.388686; batch adversarial loss: 0.551586\n",
      "epoch 86; iter: 0; batch classifier loss: 0.328908; batch adversarial loss: 0.554149\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398786; batch adversarial loss: 0.540879\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353615; batch adversarial loss: 0.493147\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394074; batch adversarial loss: 0.463025\n",
      "epoch 90; iter: 0; batch classifier loss: 0.429639; batch adversarial loss: 0.555196\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325544; batch adversarial loss: 0.547777\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450580; batch adversarial loss: 0.554846\n",
      "epoch 93; iter: 0; batch classifier loss: 0.310033; batch adversarial loss: 0.516496\n",
      "epoch 94; iter: 0; batch classifier loss: 0.304326; batch adversarial loss: 0.506737\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378350; batch adversarial loss: 0.610936\n",
      "epoch 96; iter: 0; batch classifier loss: 0.473191; batch adversarial loss: 0.374392\n",
      "epoch 97; iter: 0; batch classifier loss: 0.323488; batch adversarial loss: 0.572538\n",
      "epoch 98; iter: 0; batch classifier loss: 0.313377; batch adversarial loss: 0.600689\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417939; batch adversarial loss: 0.544273\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349674; batch adversarial loss: 0.646146\n",
      "epoch 101; iter: 0; batch classifier loss: 0.337366; batch adversarial loss: 0.572633\n",
      "epoch 102; iter: 0; batch classifier loss: 0.450345; batch adversarial loss: 0.646395\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382782; batch adversarial loss: 0.498733\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395424; batch adversarial loss: 0.498479\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363264; batch adversarial loss: 0.507229\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413996; batch adversarial loss: 0.507559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.379808; batch adversarial loss: 0.635101\n",
      "epoch 108; iter: 0; batch classifier loss: 0.376263; batch adversarial loss: 0.672643\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376349; batch adversarial loss: 0.553107\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367794; batch adversarial loss: 0.506041\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362562; batch adversarial loss: 0.443329\n",
      "epoch 112; iter: 0; batch classifier loss: 0.459634; batch adversarial loss: 0.525432\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328962; batch adversarial loss: 0.563861\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394494; batch adversarial loss: 0.562694\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418909; batch adversarial loss: 0.564134\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324015; batch adversarial loss: 0.545380\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416783; batch adversarial loss: 0.552893\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340754; batch adversarial loss: 0.469987\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383673; batch adversarial loss: 0.544957\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398341; batch adversarial loss: 0.609636\n",
      "epoch 121; iter: 0; batch classifier loss: 0.302375; batch adversarial loss: 0.609185\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378248; batch adversarial loss: 0.489067\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381815; batch adversarial loss: 0.536099\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339288; batch adversarial loss: 0.517040\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383940; batch adversarial loss: 0.552200\n",
      "epoch 126; iter: 0; batch classifier loss: 0.476195; batch adversarial loss: 0.507189\n",
      "epoch 127; iter: 0; batch classifier loss: 0.286823; batch adversarial loss: 0.525300\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354524; batch adversarial loss: 0.654203\n",
      "epoch 129; iter: 0; batch classifier loss: 0.404198; batch adversarial loss: 0.591025\n",
      "epoch 130; iter: 0; batch classifier loss: 0.403123; batch adversarial loss: 0.500810\n",
      "epoch 131; iter: 0; batch classifier loss: 0.459285; batch adversarial loss: 0.488344\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333518; batch adversarial loss: 0.534486\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374128; batch adversarial loss: 0.526636\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416702; batch adversarial loss: 0.536520\n",
      "epoch 135; iter: 0; batch classifier loss: 0.427243; batch adversarial loss: 0.416001\n",
      "epoch 136; iter: 0; batch classifier loss: 0.300283; batch adversarial loss: 0.708238\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352233; batch adversarial loss: 0.580023\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344522; batch adversarial loss: 0.554400\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326709; batch adversarial loss: 0.499802\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358011; batch adversarial loss: 0.562062\n",
      "epoch 141; iter: 0; batch classifier loss: 0.331919; batch adversarial loss: 0.563340\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362753; batch adversarial loss: 0.534666\n",
      "epoch 143; iter: 0; batch classifier loss: 0.292345; batch adversarial loss: 0.543656\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424280; batch adversarial loss: 0.572538\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334272; batch adversarial loss: 0.525506\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360550; batch adversarial loss: 0.601562\n",
      "epoch 147; iter: 0; batch classifier loss: 0.366187; batch adversarial loss: 0.542353\n",
      "epoch 148; iter: 0; batch classifier loss: 0.514956; batch adversarial loss: 0.480342\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343618; batch adversarial loss: 0.662594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.374312; batch adversarial loss: 0.618977\n",
      "epoch 151; iter: 0; batch classifier loss: 0.394277; batch adversarial loss: 0.570973\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369396; batch adversarial loss: 0.554045\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358546; batch adversarial loss: 0.609968\n",
      "epoch 154; iter: 0; batch classifier loss: 0.416443; batch adversarial loss: 0.580594\n",
      "epoch 155; iter: 0; batch classifier loss: 0.372185; batch adversarial loss: 0.527547\n",
      "epoch 156; iter: 0; batch classifier loss: 0.455322; batch adversarial loss: 0.629065\n",
      "epoch 157; iter: 0; batch classifier loss: 0.439005; batch adversarial loss: 0.554448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390176; batch adversarial loss: 0.508813\n",
      "epoch 159; iter: 0; batch classifier loss: 0.427833; batch adversarial loss: 0.479081\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353763; batch adversarial loss: 0.516046\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340116; batch adversarial loss: 0.553729\n",
      "epoch 162; iter: 0; batch classifier loss: 0.346739; batch adversarial loss: 0.572539\n",
      "epoch 163; iter: 0; batch classifier loss: 0.405968; batch adversarial loss: 0.480638\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368850; batch adversarial loss: 0.553559\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380628; batch adversarial loss: 0.561114\n",
      "epoch 166; iter: 0; batch classifier loss: 0.280511; batch adversarial loss: 0.509708\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367505; batch adversarial loss: 0.542668\n",
      "epoch 168; iter: 0; batch classifier loss: 0.374107; batch adversarial loss: 0.508691\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357715; batch adversarial loss: 0.496764\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342992; batch adversarial loss: 0.516130\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369402; batch adversarial loss: 0.600013\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342130; batch adversarial loss: 0.545406\n",
      "epoch 173; iter: 0; batch classifier loss: 0.283579; batch adversarial loss: 0.607445\n",
      "epoch 174; iter: 0; batch classifier loss: 0.464376; batch adversarial loss: 0.570563\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365468; batch adversarial loss: 0.469962\n",
      "epoch 176; iter: 0; batch classifier loss: 0.472650; batch adversarial loss: 0.498696\n",
      "epoch 177; iter: 0; batch classifier loss: 0.419500; batch adversarial loss: 0.572893\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367983; batch adversarial loss: 0.508551\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390260; batch adversarial loss: 0.553463\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316808; batch adversarial loss: 0.619127\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347891; batch adversarial loss: 0.536471\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408203; batch adversarial loss: 0.496617\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350982; batch adversarial loss: 0.564022\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344616; batch adversarial loss: 0.508021\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321788; batch adversarial loss: 0.545897\n",
      "epoch 186; iter: 0; batch classifier loss: 0.306007; batch adversarial loss: 0.627932\n",
      "epoch 187; iter: 0; batch classifier loss: 0.497798; batch adversarial loss: 0.573524\n",
      "epoch 188; iter: 0; batch classifier loss: 0.412142; batch adversarial loss: 0.534493\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297116; batch adversarial loss: 0.526684\n",
      "epoch 190; iter: 0; batch classifier loss: 0.381835; batch adversarial loss: 0.626946\n",
      "epoch 191; iter: 0; batch classifier loss: 0.437262; batch adversarial loss: 0.534217\n",
      "epoch 192; iter: 0; batch classifier loss: 0.408098; batch adversarial loss: 0.579148\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388680; batch adversarial loss: 0.564443\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344459; batch adversarial loss: 0.607559\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340802; batch adversarial loss: 0.610682\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308632; batch adversarial loss: 0.634775\n",
      "epoch 197; iter: 0; batch classifier loss: 0.287246; batch adversarial loss: 0.617041\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377562; batch adversarial loss: 0.601531\n",
      "epoch 199; iter: 0; batch classifier loss: 0.413414; batch adversarial loss: 0.561569\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690549; batch adversarial loss: 0.727331\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573070; batch adversarial loss: 0.657300\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602005; batch adversarial loss: 0.648357\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581901; batch adversarial loss: 0.620911\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569146; batch adversarial loss: 0.605172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.504304; batch adversarial loss: 0.614480\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519338; batch adversarial loss: 0.593439\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550878; batch adversarial loss: 0.558027\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552524; batch adversarial loss: 0.570415\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502317; batch adversarial loss: 0.558694\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494541; batch adversarial loss: 0.596503\n",
      "epoch 11; iter: 0; batch classifier loss: 0.558321; batch adversarial loss: 0.573090\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507786; batch adversarial loss: 0.524796\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497074; batch adversarial loss: 0.583737\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507972; batch adversarial loss: 0.571862\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549273; batch adversarial loss: 0.524770\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502666; batch adversarial loss: 0.579373\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511861; batch adversarial loss: 0.577381\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483187; batch adversarial loss: 0.557729\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481172; batch adversarial loss: 0.594001\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522984; batch adversarial loss: 0.511771\n",
      "epoch 21; iter: 0; batch classifier loss: 0.505449; batch adversarial loss: 0.490448\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463545; batch adversarial loss: 0.557118\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528665; batch adversarial loss: 0.550861\n",
      "epoch 24; iter: 0; batch classifier loss: 0.425578; batch adversarial loss: 0.512056\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499022; batch adversarial loss: 0.554199\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442838; batch adversarial loss: 0.558113\n",
      "epoch 27; iter: 0; batch classifier loss: 0.614652; batch adversarial loss: 0.511710\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464238; batch adversarial loss: 0.543509\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412338; batch adversarial loss: 0.571854\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463071; batch adversarial loss: 0.553648\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475608; batch adversarial loss: 0.583974\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407547; batch adversarial loss: 0.527965\n",
      "epoch 33; iter: 0; batch classifier loss: 0.410701; batch adversarial loss: 0.553791\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425894; batch adversarial loss: 0.510632\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454988; batch adversarial loss: 0.500583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450864; batch adversarial loss: 0.482455\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477273; batch adversarial loss: 0.596925\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435340; batch adversarial loss: 0.607082\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438512; batch adversarial loss: 0.517339\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461107; batch adversarial loss: 0.608750\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452647; batch adversarial loss: 0.444224\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480273; batch adversarial loss: 0.553961\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470441; batch adversarial loss: 0.454227\n",
      "epoch 44; iter: 0; batch classifier loss: 0.480549; batch adversarial loss: 0.589938\n",
      "epoch 45; iter: 0; batch classifier loss: 0.487842; batch adversarial loss: 0.526589\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410561; batch adversarial loss: 0.516302\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466014; batch adversarial loss: 0.608088\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460494; batch adversarial loss: 0.534265\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391628; batch adversarial loss: 0.479989\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449294; batch adversarial loss: 0.545040\n",
      "epoch 51; iter: 0; batch classifier loss: 0.523396; batch adversarial loss: 0.526287\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470205; batch adversarial loss: 0.535229\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442719; batch adversarial loss: 0.572437\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450505; batch adversarial loss: 0.553449\n",
      "epoch 55; iter: 0; batch classifier loss: 0.473620; batch adversarial loss: 0.581938\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453584; batch adversarial loss: 0.525324\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414691; batch adversarial loss: 0.561746\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448816; batch adversarial loss: 0.618434\n",
      "epoch 59; iter: 0; batch classifier loss: 0.507279; batch adversarial loss: 0.534091\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435156; batch adversarial loss: 0.534517\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435158; batch adversarial loss: 0.448671\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407128; batch adversarial loss: 0.487841\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399434; batch adversarial loss: 0.498814\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386453; batch adversarial loss: 0.562789\n",
      "epoch 65; iter: 0; batch classifier loss: 0.452123; batch adversarial loss: 0.526492\n",
      "epoch 66; iter: 0; batch classifier loss: 0.329841; batch adversarial loss: 0.525975\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392316; batch adversarial loss: 0.556005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428121; batch adversarial loss: 0.527954\n",
      "epoch 69; iter: 0; batch classifier loss: 0.454296; batch adversarial loss: 0.510385\n",
      "epoch 70; iter: 0; batch classifier loss: 0.347458; batch adversarial loss: 0.508278\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351292; batch adversarial loss: 0.572887\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437171; batch adversarial loss: 0.600075\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386726; batch adversarial loss: 0.535186\n",
      "epoch 74; iter: 0; batch classifier loss: 0.371470; batch adversarial loss: 0.561399\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378987; batch adversarial loss: 0.629258\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373599; batch adversarial loss: 0.581125\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345032; batch adversarial loss: 0.533608\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347750; batch adversarial loss: 0.497431\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387962; batch adversarial loss: 0.534461\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412832; batch adversarial loss: 0.535321\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413046; batch adversarial loss: 0.497449\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400343; batch adversarial loss: 0.592124\n",
      "epoch 83; iter: 0; batch classifier loss: 0.294049; batch adversarial loss: 0.535835\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373170; batch adversarial loss: 0.573034\n",
      "epoch 85; iter: 0; batch classifier loss: 0.469150; batch adversarial loss: 0.573089\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356678; batch adversarial loss: 0.601040\n",
      "epoch 87; iter: 0; batch classifier loss: 0.480727; batch adversarial loss: 0.580279\n",
      "epoch 88; iter: 0; batch classifier loss: 0.355608; batch adversarial loss: 0.523629\n",
      "epoch 89; iter: 0; batch classifier loss: 0.336858; batch adversarial loss: 0.479578\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363264; batch adversarial loss: 0.480410\n",
      "epoch 91; iter: 0; batch classifier loss: 0.355452; batch adversarial loss: 0.496564\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374292; batch adversarial loss: 0.527123\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390018; batch adversarial loss: 0.534104\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367820; batch adversarial loss: 0.572981\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396827; batch adversarial loss: 0.570721\n",
      "epoch 96; iter: 0; batch classifier loss: 0.457794; batch adversarial loss: 0.489356\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362125; batch adversarial loss: 0.543627\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372242; batch adversarial loss: 0.561257\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409815; batch adversarial loss: 0.582214\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394428; batch adversarial loss: 0.656860\n",
      "epoch 101; iter: 0; batch classifier loss: 0.437359; batch adversarial loss: 0.449155\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374461; batch adversarial loss: 0.496718\n",
      "epoch 103; iter: 0; batch classifier loss: 0.299704; batch adversarial loss: 0.572433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.429276; batch adversarial loss: 0.638790\n",
      "epoch 105; iter: 0; batch classifier loss: 0.338956; batch adversarial loss: 0.598661\n",
      "epoch 106; iter: 0; batch classifier loss: 0.435098; batch adversarial loss: 0.479455\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412499; batch adversarial loss: 0.581481\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400943; batch adversarial loss: 0.536807\n",
      "epoch 109; iter: 0; batch classifier loss: 0.334155; batch adversarial loss: 0.552755\n",
      "epoch 110; iter: 0; batch classifier loss: 0.310098; batch adversarial loss: 0.526822\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379122; batch adversarial loss: 0.487756\n",
      "epoch 112; iter: 0; batch classifier loss: 0.305260; batch adversarial loss: 0.423682\n",
      "epoch 113; iter: 0; batch classifier loss: 0.441020; batch adversarial loss: 0.628418\n",
      "epoch 114; iter: 0; batch classifier loss: 0.355456; batch adversarial loss: 0.515114\n",
      "epoch 115; iter: 0; batch classifier loss: 0.447966; batch adversarial loss: 0.526621\n",
      "epoch 116; iter: 0; batch classifier loss: 0.367993; batch adversarial loss: 0.489171\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340219; batch adversarial loss: 0.542012\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355208; batch adversarial loss: 0.553567\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323363; batch adversarial loss: 0.498387\n",
      "epoch 120; iter: 0; batch classifier loss: 0.345419; batch adversarial loss: 0.617294\n",
      "epoch 121; iter: 0; batch classifier loss: 0.413108; batch adversarial loss: 0.608765\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385689; batch adversarial loss: 0.618914\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352341; batch adversarial loss: 0.581622\n",
      "epoch 124; iter: 0; batch classifier loss: 0.462285; batch adversarial loss: 0.525587\n",
      "epoch 125; iter: 0; batch classifier loss: 0.396925; batch adversarial loss: 0.533713\n",
      "epoch 126; iter: 0; batch classifier loss: 0.322688; batch adversarial loss: 0.565788\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394848; batch adversarial loss: 0.523167\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390022; batch adversarial loss: 0.545361\n",
      "epoch 129; iter: 0; batch classifier loss: 0.390500; batch adversarial loss: 0.609430\n",
      "epoch 130; iter: 0; batch classifier loss: 0.331277; batch adversarial loss: 0.488793\n",
      "epoch 131; iter: 0; batch classifier loss: 0.411311; batch adversarial loss: 0.619989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382780; batch adversarial loss: 0.514829\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364086; batch adversarial loss: 0.638700\n",
      "epoch 134; iter: 0; batch classifier loss: 0.454777; batch adversarial loss: 0.593101\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385502; batch adversarial loss: 0.495388\n",
      "epoch 136; iter: 0; batch classifier loss: 0.350403; batch adversarial loss: 0.534045\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383253; batch adversarial loss: 0.544281\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358413; batch adversarial loss: 0.451093\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359334; batch adversarial loss: 0.480168\n",
      "epoch 140; iter: 0; batch classifier loss: 0.418101; batch adversarial loss: 0.590989\n",
      "epoch 141; iter: 0; batch classifier loss: 0.355825; batch adversarial loss: 0.583238\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334020; batch adversarial loss: 0.508094\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385702; batch adversarial loss: 0.470931\n",
      "epoch 144; iter: 0; batch classifier loss: 0.373447; batch adversarial loss: 0.581520\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373342; batch adversarial loss: 0.496806\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404380; batch adversarial loss: 0.515683\n",
      "epoch 147; iter: 0; batch classifier loss: 0.335466; batch adversarial loss: 0.516752\n",
      "epoch 148; iter: 0; batch classifier loss: 0.399148; batch adversarial loss: 0.589419\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350378; batch adversarial loss: 0.535470\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342841; batch adversarial loss: 0.449529\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368342; batch adversarial loss: 0.555370\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385861; batch adversarial loss: 0.498352\n",
      "epoch 153; iter: 0; batch classifier loss: 0.332280; batch adversarial loss: 0.507072\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395227; batch adversarial loss: 0.592383\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419221; batch adversarial loss: 0.544071\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355216; batch adversarial loss: 0.572638\n",
      "epoch 157; iter: 0; batch classifier loss: 0.439654; batch adversarial loss: 0.552745\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361187; batch adversarial loss: 0.469928\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370508; batch adversarial loss: 0.515807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332165; batch adversarial loss: 0.561201\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314969; batch adversarial loss: 0.555292\n",
      "epoch 162; iter: 0; batch classifier loss: 0.316769; batch adversarial loss: 0.524173\n",
      "epoch 163; iter: 0; batch classifier loss: 0.470361; batch adversarial loss: 0.505624\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369067; batch adversarial loss: 0.497089\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372847; batch adversarial loss: 0.579973\n",
      "epoch 166; iter: 0; batch classifier loss: 0.386463; batch adversarial loss: 0.524520\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323743; batch adversarial loss: 0.487762\n",
      "epoch 168; iter: 0; batch classifier loss: 0.311688; batch adversarial loss: 0.525371\n",
      "epoch 169; iter: 0; batch classifier loss: 0.288482; batch adversarial loss: 0.545720\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382179; batch adversarial loss: 0.450560\n",
      "epoch 171; iter: 0; batch classifier loss: 0.428568; batch adversarial loss: 0.506734\n",
      "epoch 172; iter: 0; batch classifier loss: 0.298877; batch adversarial loss: 0.489655\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301233; batch adversarial loss: 0.488348\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399473; batch adversarial loss: 0.593098\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342322; batch adversarial loss: 0.490124\n",
      "epoch 176; iter: 0; batch classifier loss: 0.342760; batch adversarial loss: 0.441317\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321628; batch adversarial loss: 0.497695\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312918; batch adversarial loss: 0.497067\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395597; batch adversarial loss: 0.525191\n",
      "epoch 180; iter: 0; batch classifier loss: 0.406909; batch adversarial loss: 0.536139\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320340; batch adversarial loss: 0.600871\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402362; batch adversarial loss: 0.588113\n",
      "epoch 183; iter: 0; batch classifier loss: 0.402883; batch adversarial loss: 0.573248\n",
      "epoch 184; iter: 0; batch classifier loss: 0.280949; batch adversarial loss: 0.553908\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354827; batch adversarial loss: 0.470168\n",
      "epoch 186; iter: 0; batch classifier loss: 0.411104; batch adversarial loss: 0.534190\n",
      "epoch 187; iter: 0; batch classifier loss: 0.415412; batch adversarial loss: 0.682835\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352322; batch adversarial loss: 0.496002\n",
      "epoch 189; iter: 0; batch classifier loss: 0.411674; batch adversarial loss: 0.571767\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368894; batch adversarial loss: 0.504626\n",
      "epoch 191; iter: 0; batch classifier loss: 0.303682; batch adversarial loss: 0.498029\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313526; batch adversarial loss: 0.545554\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361941; batch adversarial loss: 0.543658\n",
      "epoch 194; iter: 0; batch classifier loss: 0.293541; batch adversarial loss: 0.553136\n",
      "epoch 195; iter: 0; batch classifier loss: 0.269242; batch adversarial loss: 0.571101\n",
      "epoch 196; iter: 0; batch classifier loss: 0.352584; batch adversarial loss: 0.477718\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329957; batch adversarial loss: 0.507584\n",
      "epoch 198; iter: 0; batch classifier loss: 0.291614; batch adversarial loss: 0.526796\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340498; batch adversarial loss: 0.526914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.703299; batch adversarial loss: 0.676849\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585253; batch adversarial loss: 0.639457\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579767; batch adversarial loss: 0.620408\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553817; batch adversarial loss: 0.607075\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571940; batch adversarial loss: 0.596448\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554901; batch adversarial loss: 0.553258\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563442; batch adversarial loss: 0.622753\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545510; batch adversarial loss: 0.633840\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542826; batch adversarial loss: 0.599053\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465123; batch adversarial loss: 0.546118\n",
      "epoch 10; iter: 0; batch classifier loss: 0.476822; batch adversarial loss: 0.579899\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551176; batch adversarial loss: 0.670648\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440221; batch adversarial loss: 0.562540\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502225; batch adversarial loss: 0.612421\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501214; batch adversarial loss: 0.572160\n",
      "epoch 15; iter: 0; batch classifier loss: 0.568151; batch adversarial loss: 0.532127\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529268; batch adversarial loss: 0.582377\n",
      "epoch 17; iter: 0; batch classifier loss: 0.545037; batch adversarial loss: 0.543517\n",
      "epoch 18; iter: 0; batch classifier loss: 0.564010; batch adversarial loss: 0.606259\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488202; batch adversarial loss: 0.595989\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484871; batch adversarial loss: 0.567026\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517680; batch adversarial loss: 0.552251\n",
      "epoch 22; iter: 0; batch classifier loss: 0.527504; batch adversarial loss: 0.579624\n",
      "epoch 23; iter: 0; batch classifier loss: 0.584670; batch adversarial loss: 0.488861\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506338; batch adversarial loss: 0.599838\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467937; batch adversarial loss: 0.578135\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462586; batch adversarial loss: 0.605643\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439874; batch adversarial loss: 0.568395\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495842; batch adversarial loss: 0.477046\n",
      "epoch 29; iter: 0; batch classifier loss: 0.528333; batch adversarial loss: 0.577063\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515073; batch adversarial loss: 0.605709\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479553; batch adversarial loss: 0.543476\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484415; batch adversarial loss: 0.604829\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492979; batch adversarial loss: 0.518079\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420896; batch adversarial loss: 0.543628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454486; batch adversarial loss: 0.563212\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508019; batch adversarial loss: 0.573234\n",
      "epoch 37; iter: 0; batch classifier loss: 0.365359; batch adversarial loss: 0.571782\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464302; batch adversarial loss: 0.447103\n",
      "epoch 39; iter: 0; batch classifier loss: 0.416839; batch adversarial loss: 0.464960\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452412; batch adversarial loss: 0.579671\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434841; batch adversarial loss: 0.471633\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432745; batch adversarial loss: 0.635262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465093; batch adversarial loss: 0.569590\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476028; batch adversarial loss: 0.478362\n",
      "epoch 45; iter: 0; batch classifier loss: 0.500245; batch adversarial loss: 0.571732\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400208; batch adversarial loss: 0.533153\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385755; batch adversarial loss: 0.506284\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431363; batch adversarial loss: 0.545212\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476152; batch adversarial loss: 0.516036\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427504; batch adversarial loss: 0.551144\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392767; batch adversarial loss: 0.569588\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383624; batch adversarial loss: 0.527093\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381238; batch adversarial loss: 0.495126\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423712; batch adversarial loss: 0.561722\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413786; batch adversarial loss: 0.479129\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453747; batch adversarial loss: 0.479504\n",
      "epoch 57; iter: 0; batch classifier loss: 0.530510; batch adversarial loss: 0.488439\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447305; batch adversarial loss: 0.508809\n",
      "epoch 59; iter: 0; batch classifier loss: 0.533273; batch adversarial loss: 0.508263\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397691; batch adversarial loss: 0.516228\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432413; batch adversarial loss: 0.554266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.466288; batch adversarial loss: 0.590322\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425392; batch adversarial loss: 0.531264\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438782; batch adversarial loss: 0.542930\n",
      "epoch 65; iter: 0; batch classifier loss: 0.331018; batch adversarial loss: 0.563343\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418704; batch adversarial loss: 0.526370\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410225; batch adversarial loss: 0.505571\n",
      "epoch 68; iter: 0; batch classifier loss: 0.452996; batch adversarial loss: 0.591276\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389069; batch adversarial loss: 0.525900\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446019; batch adversarial loss: 0.534566\n",
      "epoch 71; iter: 0; batch classifier loss: 0.506749; batch adversarial loss: 0.567680\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416920; batch adversarial loss: 0.505582\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400566; batch adversarial loss: 0.561195\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389064; batch adversarial loss: 0.583814\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415369; batch adversarial loss: 0.573169\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373715; batch adversarial loss: 0.542247\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373822; batch adversarial loss: 0.586096\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417358; batch adversarial loss: 0.581720\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367742; batch adversarial loss: 0.561508\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388008; batch adversarial loss: 0.462915\n",
      "epoch 81; iter: 0; batch classifier loss: 0.446001; batch adversarial loss: 0.500719\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380032; batch adversarial loss: 0.552597\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424350; batch adversarial loss: 0.627428\n",
      "epoch 84; iter: 0; batch classifier loss: 0.379997; batch adversarial loss: 0.545708\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377282; batch adversarial loss: 0.557245\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431798; batch adversarial loss: 0.581897\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366168; batch adversarial loss: 0.550313\n",
      "epoch 88; iter: 0; batch classifier loss: 0.436134; batch adversarial loss: 0.509983\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411094; batch adversarial loss: 0.541650\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427488; batch adversarial loss: 0.604552\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405254; batch adversarial loss: 0.611501\n",
      "epoch 92; iter: 0; batch classifier loss: 0.336879; batch adversarial loss: 0.557300\n",
      "epoch 93; iter: 0; batch classifier loss: 0.448677; batch adversarial loss: 0.511235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377162; batch adversarial loss: 0.487004\n",
      "epoch 95; iter: 0; batch classifier loss: 0.367918; batch adversarial loss: 0.554269\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395061; batch adversarial loss: 0.587206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.461415; batch adversarial loss: 0.547624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.404979; batch adversarial loss: 0.571461\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425365; batch adversarial loss: 0.472960\n",
      "epoch 100; iter: 0; batch classifier loss: 0.391080; batch adversarial loss: 0.612177\n",
      "epoch 101; iter: 0; batch classifier loss: 0.429771; batch adversarial loss: 0.548339\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345180; batch adversarial loss: 0.555066\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337148; batch adversarial loss: 0.659649\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370093; batch adversarial loss: 0.650013\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415981; batch adversarial loss: 0.591601\n",
      "epoch 106; iter: 0; batch classifier loss: 0.361307; batch adversarial loss: 0.473444\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374237; batch adversarial loss: 0.603159\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377167; batch adversarial loss: 0.526061\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338101; batch adversarial loss: 0.584080\n",
      "epoch 110; iter: 0; batch classifier loss: 0.436063; batch adversarial loss: 0.580773\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365374; batch adversarial loss: 0.566490\n",
      "epoch 112; iter: 0; batch classifier loss: 0.400276; batch adversarial loss: 0.609256\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377962; batch adversarial loss: 0.506596\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362391; batch adversarial loss: 0.521188\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398516; batch adversarial loss: 0.523846\n",
      "epoch 116; iter: 0; batch classifier loss: 0.444882; batch adversarial loss: 0.611122\n",
      "epoch 117; iter: 0; batch classifier loss: 0.545652; batch adversarial loss: 0.591601\n",
      "epoch 118; iter: 0; batch classifier loss: 0.350580; batch adversarial loss: 0.573491\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390270; batch adversarial loss: 0.497127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362536; batch adversarial loss: 0.616259\n",
      "epoch 121; iter: 0; batch classifier loss: 0.377465; batch adversarial loss: 0.622102\n",
      "epoch 122; iter: 0; batch classifier loss: 0.526479; batch adversarial loss: 0.449046\n",
      "epoch 123; iter: 0; batch classifier loss: 0.410490; batch adversarial loss: 0.507811\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386511; batch adversarial loss: 0.603795\n",
      "epoch 125; iter: 0; batch classifier loss: 0.495422; batch adversarial loss: 0.552853\n",
      "epoch 126; iter: 0; batch classifier loss: 0.499815; batch adversarial loss: 0.558246\n",
      "epoch 127; iter: 0; batch classifier loss: 0.295073; batch adversarial loss: 0.583179\n",
      "epoch 128; iter: 0; batch classifier loss: 0.436628; batch adversarial loss: 0.486472\n",
      "epoch 129; iter: 0; batch classifier loss: 0.424789; batch adversarial loss: 0.618374\n",
      "epoch 130; iter: 0; batch classifier loss: 0.400812; batch adversarial loss: 0.646085\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408630; batch adversarial loss: 0.516256\n",
      "epoch 132; iter: 0; batch classifier loss: 0.488473; batch adversarial loss: 0.522180\n",
      "epoch 133; iter: 0; batch classifier loss: 0.435520; batch adversarial loss: 0.545586\n",
      "epoch 134; iter: 0; batch classifier loss: 0.425810; batch adversarial loss: 0.582433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.326884; batch adversarial loss: 0.504137\n",
      "epoch 136; iter: 0; batch classifier loss: 0.342300; batch adversarial loss: 0.533071\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368807; batch adversarial loss: 0.583053\n",
      "epoch 138; iter: 0; batch classifier loss: 0.412105; batch adversarial loss: 0.561807\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321961; batch adversarial loss: 0.508440\n",
      "epoch 140; iter: 0; batch classifier loss: 0.408065; batch adversarial loss: 0.495695\n",
      "epoch 141; iter: 0; batch classifier loss: 0.426412; batch adversarial loss: 0.532958\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376336; batch adversarial loss: 0.601408\n",
      "epoch 143; iter: 0; batch classifier loss: 0.417429; batch adversarial loss: 0.602585\n",
      "epoch 144; iter: 0; batch classifier loss: 0.335116; batch adversarial loss: 0.480134\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397093; batch adversarial loss: 0.524706\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416539; batch adversarial loss: 0.528489\n",
      "epoch 147; iter: 0; batch classifier loss: 0.296357; batch adversarial loss: 0.547120\n",
      "epoch 148; iter: 0; batch classifier loss: 0.401803; batch adversarial loss: 0.581212\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384619; batch adversarial loss: 0.532656\n",
      "epoch 150; iter: 0; batch classifier loss: 0.324396; batch adversarial loss: 0.514956\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372361; batch adversarial loss: 0.534552\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347232; batch adversarial loss: 0.530270\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339776; batch adversarial loss: 0.591075\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325308; batch adversarial loss: 0.560413\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373088; batch adversarial loss: 0.622499\n",
      "epoch 156; iter: 0; batch classifier loss: 0.269053; batch adversarial loss: 0.495435\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360654; batch adversarial loss: 0.583876\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372206; batch adversarial loss: 0.608400\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356726; batch adversarial loss: 0.505018\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384772; batch adversarial loss: 0.588915\n",
      "epoch 161; iter: 0; batch classifier loss: 0.490832; batch adversarial loss: 0.525757\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372438; batch adversarial loss: 0.492747\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416046; batch adversarial loss: 0.540448\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363278; batch adversarial loss: 0.612988\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389421; batch adversarial loss: 0.544549\n",
      "epoch 166; iter: 0; batch classifier loss: 0.320219; batch adversarial loss: 0.552009\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334611; batch adversarial loss: 0.627205\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375251; batch adversarial loss: 0.592389\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365440; batch adversarial loss: 0.520082\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354467; batch adversarial loss: 0.547296\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373322; batch adversarial loss: 0.524644\n",
      "epoch 172; iter: 0; batch classifier loss: 0.338967; batch adversarial loss: 0.554567\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380074; batch adversarial loss: 0.572835\n",
      "epoch 174; iter: 0; batch classifier loss: 0.319947; batch adversarial loss: 0.534579\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345253; batch adversarial loss: 0.599310\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308879; batch adversarial loss: 0.601589\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340153; batch adversarial loss: 0.522676\n",
      "epoch 178; iter: 0; batch classifier loss: 0.373656; batch adversarial loss: 0.570404\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327389; batch adversarial loss: 0.507639\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369725; batch adversarial loss: 0.536332\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374030; batch adversarial loss: 0.580095\n",
      "epoch 182; iter: 0; batch classifier loss: 0.430297; batch adversarial loss: 0.451360\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382995; batch adversarial loss: 0.571160\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334742; batch adversarial loss: 0.544043\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345578; batch adversarial loss: 0.521143\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335589; batch adversarial loss: 0.528325\n",
      "epoch 187; iter: 0; batch classifier loss: 0.285064; batch adversarial loss: 0.566924\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336589; batch adversarial loss: 0.520483\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356290; batch adversarial loss: 0.474139\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341362; batch adversarial loss: 0.506583\n",
      "epoch 191; iter: 0; batch classifier loss: 0.273766; batch adversarial loss: 0.582624\n",
      "epoch 192; iter: 0; batch classifier loss: 0.402450; batch adversarial loss: 0.496207\n",
      "epoch 193; iter: 0; batch classifier loss: 0.295988; batch adversarial loss: 0.527086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.371829; batch adversarial loss: 0.616094\n",
      "epoch 195; iter: 0; batch classifier loss: 0.300852; batch adversarial loss: 0.530482\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334535; batch adversarial loss: 0.563433\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355409; batch adversarial loss: 0.534154\n",
      "epoch 198; iter: 0; batch classifier loss: 0.293550; batch adversarial loss: 0.543872\n",
      "epoch 199; iter: 0; batch classifier loss: 0.424960; batch adversarial loss: 0.536138\n",
      "epoch 0; iter: 0; batch classifier loss: 0.737548; batch adversarial loss: 0.710634\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581293; batch adversarial loss: 0.672351\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617934; batch adversarial loss: 0.642483\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609259; batch adversarial loss: 0.647905\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615147; batch adversarial loss: 0.637060\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608317; batch adversarial loss: 0.606463\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562784; batch adversarial loss: 0.619429\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524188; batch adversarial loss: 0.613433\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543254; batch adversarial loss: 0.655110\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542285; batch adversarial loss: 0.644388\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588513; batch adversarial loss: 0.563210\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573287; batch adversarial loss: 0.554234\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518225; batch adversarial loss: 0.553349\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491217; batch adversarial loss: 0.544955\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548637; batch adversarial loss: 0.553651\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510766; batch adversarial loss: 0.568536\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550171; batch adversarial loss: 0.593112\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508707; batch adversarial loss: 0.626792\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519720; batch adversarial loss: 0.586524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536405; batch adversarial loss: 0.650301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489194; batch adversarial loss: 0.591555\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475168; batch adversarial loss: 0.593194\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499225; batch adversarial loss: 0.592782\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487675; batch adversarial loss: 0.560805\n",
      "epoch 24; iter: 0; batch classifier loss: 0.430461; batch adversarial loss: 0.574811\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483658; batch adversarial loss: 0.527307\n",
      "epoch 26; iter: 0; batch classifier loss: 0.402476; batch adversarial loss: 0.577414\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471325; batch adversarial loss: 0.522270\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442269; batch adversarial loss: 0.580411\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500035; batch adversarial loss: 0.553751\n",
      "epoch 30; iter: 0; batch classifier loss: 0.507806; batch adversarial loss: 0.564521\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421732; batch adversarial loss: 0.532877\n",
      "epoch 32; iter: 0; batch classifier loss: 0.613620; batch adversarial loss: 0.564315\n",
      "epoch 33; iter: 0; batch classifier loss: 0.387970; batch adversarial loss: 0.649234\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447813; batch adversarial loss: 0.630348\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455615; batch adversarial loss: 0.586924\n",
      "epoch 36; iter: 0; batch classifier loss: 0.548956; batch adversarial loss: 0.561331\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499935; batch adversarial loss: 0.569676\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427730; batch adversarial loss: 0.482913\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429991; batch adversarial loss: 0.527331\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464228; batch adversarial loss: 0.527580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461064; batch adversarial loss: 0.563129\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408781; batch adversarial loss: 0.542958\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419091; batch adversarial loss: 0.569810\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440420; batch adversarial loss: 0.543817\n",
      "epoch 45; iter: 0; batch classifier loss: 0.388826; batch adversarial loss: 0.544665\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466928; batch adversarial loss: 0.543853\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436472; batch adversarial loss: 0.552654\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383806; batch adversarial loss: 0.491073\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463413; batch adversarial loss: 0.544860\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471563; batch adversarial loss: 0.588985\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426621; batch adversarial loss: 0.453830\n",
      "epoch 52; iter: 0; batch classifier loss: 0.367924; batch adversarial loss: 0.570965\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386491; batch adversarial loss: 0.527387\n",
      "epoch 54; iter: 0; batch classifier loss: 0.401160; batch adversarial loss: 0.562361\n",
      "epoch 55; iter: 0; batch classifier loss: 0.349792; batch adversarial loss: 0.580157\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473035; batch adversarial loss: 0.607606\n",
      "epoch 57; iter: 0; batch classifier loss: 0.352121; batch adversarial loss: 0.580811\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407807; batch adversarial loss: 0.625370\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447818; batch adversarial loss: 0.616421\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437088; batch adversarial loss: 0.499779\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401613; batch adversarial loss: 0.625716\n",
      "epoch 62; iter: 0; batch classifier loss: 0.356463; batch adversarial loss: 0.544626\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449983; batch adversarial loss: 0.517501\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473355; batch adversarial loss: 0.562697\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408742; batch adversarial loss: 0.589494\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434137; batch adversarial loss: 0.553379\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420134; batch adversarial loss: 0.570374\n",
      "epoch 68; iter: 0; batch classifier loss: 0.509589; batch adversarial loss: 0.434452\n",
      "epoch 69; iter: 0; batch classifier loss: 0.372030; batch adversarial loss: 0.589263\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378627; batch adversarial loss: 0.618555\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448647; batch adversarial loss: 0.554665\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390298; batch adversarial loss: 0.626799\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390399; batch adversarial loss: 0.598439\n",
      "epoch 74; iter: 0; batch classifier loss: 0.345231; batch adversarial loss: 0.571516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421086; batch adversarial loss: 0.525698\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381979; batch adversarial loss: 0.545120\n",
      "epoch 77; iter: 0; batch classifier loss: 0.451668; batch adversarial loss: 0.571854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362666; batch adversarial loss: 0.508824\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399971; batch adversarial loss: 0.581736\n",
      "epoch 80; iter: 0; batch classifier loss: 0.318290; batch adversarial loss: 0.508913\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400144; batch adversarial loss: 0.517839\n",
      "epoch 82; iter: 0; batch classifier loss: 0.430973; batch adversarial loss: 0.482034\n",
      "epoch 83; iter: 0; batch classifier loss: 0.437012; batch adversarial loss: 0.562676\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384191; batch adversarial loss: 0.553588\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360632; batch adversarial loss: 0.581122\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380546; batch adversarial loss: 0.581233\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413957; batch adversarial loss: 0.626632\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395789; batch adversarial loss: 0.643647\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381302; batch adversarial loss: 0.562505\n",
      "epoch 90; iter: 0; batch classifier loss: 0.497569; batch adversarial loss: 0.544443\n",
      "epoch 91; iter: 0; batch classifier loss: 0.329148; batch adversarial loss: 0.526778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.389228; batch adversarial loss: 0.462899\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386851; batch adversarial loss: 0.571732\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368526; batch adversarial loss: 0.590915\n",
      "epoch 95; iter: 0; batch classifier loss: 0.448785; batch adversarial loss: 0.533922\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395286; batch adversarial loss: 0.571318\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371904; batch adversarial loss: 0.625668\n",
      "epoch 98; iter: 0; batch classifier loss: 0.408930; batch adversarial loss: 0.643710\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351299; batch adversarial loss: 0.489301\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375655; batch adversarial loss: 0.498688\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417276; batch adversarial loss: 0.554420\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373171; batch adversarial loss: 0.535072\n",
      "epoch 103; iter: 0; batch classifier loss: 0.320743; batch adversarial loss: 0.598723\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354687; batch adversarial loss: 0.572036\n",
      "epoch 105; iter: 0; batch classifier loss: 0.387002; batch adversarial loss: 0.537036\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379879; batch adversarial loss: 0.454365\n",
      "epoch 107; iter: 0; batch classifier loss: 0.440878; batch adversarial loss: 0.545263\n",
      "epoch 108; iter: 0; batch classifier loss: 0.368594; batch adversarial loss: 0.598569\n",
      "epoch 109; iter: 0; batch classifier loss: 0.411395; batch adversarial loss: 0.599248\n",
      "epoch 110; iter: 0; batch classifier loss: 0.355957; batch adversarial loss: 0.616719\n",
      "epoch 111; iter: 0; batch classifier loss: 0.472282; batch adversarial loss: 0.490395\n",
      "epoch 112; iter: 0; batch classifier loss: 0.434315; batch adversarial loss: 0.535357\n",
      "epoch 113; iter: 0; batch classifier loss: 0.458569; batch adversarial loss: 0.589712\n",
      "epoch 114; iter: 0; batch classifier loss: 0.465080; batch adversarial loss: 0.553495\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358848; batch adversarial loss: 0.490164\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365165; batch adversarial loss: 0.617060\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379080; batch adversarial loss: 0.499136\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374444; batch adversarial loss: 0.571045\n",
      "epoch 119; iter: 0; batch classifier loss: 0.405623; batch adversarial loss: 0.571597\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401241; batch adversarial loss: 0.580801\n",
      "epoch 121; iter: 0; batch classifier loss: 0.428478; batch adversarial loss: 0.598174\n",
      "epoch 122; iter: 0; batch classifier loss: 0.485152; batch adversarial loss: 0.563678\n",
      "epoch 123; iter: 0; batch classifier loss: 0.304863; batch adversarial loss: 0.553155\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399947; batch adversarial loss: 0.580832\n",
      "epoch 125; iter: 0; batch classifier loss: 0.388502; batch adversarial loss: 0.481568\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384901; batch adversarial loss: 0.535352\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415597; batch adversarial loss: 0.571525\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348480; batch adversarial loss: 0.517217\n",
      "epoch 129; iter: 0; batch classifier loss: 0.387928; batch adversarial loss: 0.526734\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363083; batch adversarial loss: 0.517735\n",
      "epoch 131; iter: 0; batch classifier loss: 0.487484; batch adversarial loss: 0.544533\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355589; batch adversarial loss: 0.552918\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372813; batch adversarial loss: 0.544718\n",
      "epoch 134; iter: 0; batch classifier loss: 0.426266; batch adversarial loss: 0.671344\n",
      "epoch 135; iter: 0; batch classifier loss: 0.367224; batch adversarial loss: 0.544801\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312037; batch adversarial loss: 0.563334\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403709; batch adversarial loss: 0.517497\n",
      "epoch 138; iter: 0; batch classifier loss: 0.315547; batch adversarial loss: 0.499359\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392803; batch adversarial loss: 0.544667\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375015; batch adversarial loss: 0.500050\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403291; batch adversarial loss: 0.571500\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331087; batch adversarial loss: 0.553487\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382254; batch adversarial loss: 0.636203\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336230; batch adversarial loss: 0.590298\n",
      "epoch 145; iter: 0; batch classifier loss: 0.310635; batch adversarial loss: 0.561819\n",
      "epoch 146; iter: 0; batch classifier loss: 0.390991; batch adversarial loss: 0.561920\n",
      "epoch 147; iter: 0; batch classifier loss: 0.401042; batch adversarial loss: 0.597697\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381823; batch adversarial loss: 0.533372\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410283; batch adversarial loss: 0.475685\n",
      "epoch 150; iter: 0; batch classifier loss: 0.366544; batch adversarial loss: 0.507922\n",
      "epoch 151; iter: 0; batch classifier loss: 0.394359; batch adversarial loss: 0.607277\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351798; batch adversarial loss: 0.497946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371263; batch adversarial loss: 0.607894\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350217; batch adversarial loss: 0.446847\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371611; batch adversarial loss: 0.570097\n",
      "epoch 156; iter: 0; batch classifier loss: 0.415175; batch adversarial loss: 0.634493\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384153; batch adversarial loss: 0.527419\n",
      "epoch 158; iter: 0; batch classifier loss: 0.303133; batch adversarial loss: 0.552762\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383586; batch adversarial loss: 0.589175\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355530; batch adversarial loss: 0.510157\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334527; batch adversarial loss: 0.624789\n",
      "epoch 162; iter: 0; batch classifier loss: 0.459335; batch adversarial loss: 0.580744\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365198; batch adversarial loss: 0.562129\n",
      "epoch 164; iter: 0; batch classifier loss: 0.437043; batch adversarial loss: 0.544267\n",
      "epoch 165; iter: 0; batch classifier loss: 0.409303; batch adversarial loss: 0.553795\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323619; batch adversarial loss: 0.544257\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409563; batch adversarial loss: 0.453553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.442674; batch adversarial loss: 0.553919\n",
      "epoch 169; iter: 0; batch classifier loss: 0.421966; batch adversarial loss: 0.572868\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318877; batch adversarial loss: 0.552569\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341667; batch adversarial loss: 0.527525\n",
      "epoch 172; iter: 0; batch classifier loss: 0.417795; batch adversarial loss: 0.508244\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372934; batch adversarial loss: 0.544115\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399043; batch adversarial loss: 0.537810\n",
      "epoch 175; iter: 0; batch classifier loss: 0.327862; batch adversarial loss: 0.562967\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381874; batch adversarial loss: 0.589460\n",
      "epoch 177; iter: 0; batch classifier loss: 0.313203; batch adversarial loss: 0.607715\n",
      "epoch 178; iter: 0; batch classifier loss: 0.329608; batch adversarial loss: 0.625808\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395818; batch adversarial loss: 0.571613\n",
      "epoch 180; iter: 0; batch classifier loss: 0.309381; batch adversarial loss: 0.536746\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370469; batch adversarial loss: 0.527241\n",
      "epoch 182; iter: 0; batch classifier loss: 0.326225; batch adversarial loss: 0.527036\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342968; batch adversarial loss: 0.571763\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424966; batch adversarial loss: 0.580021\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305515; batch adversarial loss: 0.579925\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326861; batch adversarial loss: 0.534968\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359131; batch adversarial loss: 0.608373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.372773; batch adversarial loss: 0.500276\n",
      "epoch 189; iter: 0; batch classifier loss: 0.319004; batch adversarial loss: 0.652691\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334346; batch adversarial loss: 0.500255\n",
      "epoch 191; iter: 0; batch classifier loss: 0.418407; batch adversarial loss: 0.535955\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327513; batch adversarial loss: 0.552597\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325231; batch adversarial loss: 0.589935\n",
      "epoch 194; iter: 0; batch classifier loss: 0.467292; batch adversarial loss: 0.535494\n",
      "epoch 195; iter: 0; batch classifier loss: 0.291997; batch adversarial loss: 0.500401\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350024; batch adversarial loss: 0.616608\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372019; batch adversarial loss: 0.490839\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358340; batch adversarial loss: 0.536621\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349000; batch adversarial loss: 0.499589\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720002; batch adversarial loss: 0.939052\n",
      "epoch 1; iter: 0; batch classifier loss: 0.829248; batch adversarial loss: 1.073784\n",
      "epoch 2; iter: 0; batch classifier loss: 1.071831; batch adversarial loss: 1.090163\n",
      "epoch 3; iter: 0; batch classifier loss: 1.021855; batch adversarial loss: 0.968738\n",
      "epoch 4; iter: 0; batch classifier loss: 1.086060; batch adversarial loss: 0.904935\n",
      "epoch 5; iter: 0; batch classifier loss: 1.206702; batch adversarial loss: 0.855066\n",
      "epoch 6; iter: 0; batch classifier loss: 0.966666; batch adversarial loss: 0.738342\n",
      "epoch 7; iter: 0; batch classifier loss: 0.880884; batch adversarial loss: 0.733183\n",
      "epoch 8; iter: 0; batch classifier loss: 0.752347; batch adversarial loss: 0.645428\n",
      "epoch 9; iter: 0; batch classifier loss: 0.639824; batch adversarial loss: 0.640297\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561188; batch adversarial loss: 0.614447\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557214; batch adversarial loss: 0.593867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552561; batch adversarial loss: 0.628565\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528720; batch adversarial loss: 0.557866\n",
      "epoch 14; iter: 0; batch classifier loss: 0.555924; batch adversarial loss: 0.558580\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507952; batch adversarial loss: 0.601477\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476092; batch adversarial loss: 0.518979\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477015; batch adversarial loss: 0.582834\n",
      "epoch 18; iter: 0; batch classifier loss: 0.426566; batch adversarial loss: 0.610733\n",
      "epoch 19; iter: 0; batch classifier loss: 0.423149; batch adversarial loss: 0.547222\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456605; batch adversarial loss: 0.505685\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486242; batch adversarial loss: 0.581670\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515865; batch adversarial loss: 0.544334\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498539; batch adversarial loss: 0.535415\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516238; batch adversarial loss: 0.580386\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520327; batch adversarial loss: 0.575131\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433201; batch adversarial loss: 0.578583\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457426; batch adversarial loss: 0.534359\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463029; batch adversarial loss: 0.572474\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462265; batch adversarial loss: 0.528413\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550061; batch adversarial loss: 0.530079\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476563; batch adversarial loss: 0.555675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477499; batch adversarial loss: 0.634742\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475415; batch adversarial loss: 0.544812\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477946; batch adversarial loss: 0.574650\n",
      "epoch 35; iter: 0; batch classifier loss: 0.501260; batch adversarial loss: 0.582508\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418667; batch adversarial loss: 0.534621\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476260; batch adversarial loss: 0.565644\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472828; batch adversarial loss: 0.577776\n",
      "epoch 39; iter: 0; batch classifier loss: 0.520861; batch adversarial loss: 0.535944\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390063; batch adversarial loss: 0.586829\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449839; batch adversarial loss: 0.518681\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478980; batch adversarial loss: 0.571820\n",
      "epoch 43; iter: 0; batch classifier loss: 0.559233; batch adversarial loss: 0.506669\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464762; batch adversarial loss: 0.547058\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424188; batch adversarial loss: 0.589170\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455850; batch adversarial loss: 0.565752\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444074; batch adversarial loss: 0.553275\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468912; batch adversarial loss: 0.509602\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460612; batch adversarial loss: 0.534691\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391650; batch adversarial loss: 0.511132\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400078; batch adversarial loss: 0.506269\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391358; batch adversarial loss: 0.590669\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383374; batch adversarial loss: 0.581271\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426442; batch adversarial loss: 0.589963\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406971; batch adversarial loss: 0.580972\n",
      "epoch 56; iter: 0; batch classifier loss: 0.294968; batch adversarial loss: 0.517253\n",
      "epoch 57; iter: 0; batch classifier loss: 0.474175; batch adversarial loss: 0.582387\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400993; batch adversarial loss: 0.589491\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383447; batch adversarial loss: 0.489246\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441325; batch adversarial loss: 0.498391\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412530; batch adversarial loss: 0.471172\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427101; batch adversarial loss: 0.471281\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370102; batch adversarial loss: 0.599979\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372971; batch adversarial loss: 0.563004\n",
      "epoch 65; iter: 0; batch classifier loss: 0.359761; batch adversarial loss: 0.488976\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363799; batch adversarial loss: 0.600079\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351516; batch adversarial loss: 0.451960\n",
      "epoch 68; iter: 0; batch classifier loss: 0.349186; batch adversarial loss: 0.507045\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358990; batch adversarial loss: 0.507336\n",
      "epoch 70; iter: 0; batch classifier loss: 0.347724; batch adversarial loss: 0.507095\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437571; batch adversarial loss: 0.525064\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433589; batch adversarial loss: 0.608058\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360177; batch adversarial loss: 0.517223\n",
      "epoch 74; iter: 0; batch classifier loss: 0.458161; batch adversarial loss: 0.561829\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416838; batch adversarial loss: 0.535938\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393019; batch adversarial loss: 0.601098\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409632; batch adversarial loss: 0.542898\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394510; batch adversarial loss: 0.527401\n",
      "epoch 79; iter: 0; batch classifier loss: 0.511172; batch adversarial loss: 0.515756\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374136; batch adversarial loss: 0.525331\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356914; batch adversarial loss: 0.516197\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397930; batch adversarial loss: 0.592873\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412867; batch adversarial loss: 0.560930\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372386; batch adversarial loss: 0.542275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.340342; batch adversarial loss: 0.515036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.351183; batch adversarial loss: 0.553559\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420668; batch adversarial loss: 0.555975\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422000; batch adversarial loss: 0.459655\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415045; batch adversarial loss: 0.600189\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450500; batch adversarial loss: 0.581449\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372985; batch adversarial loss: 0.532568\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406570; batch adversarial loss: 0.607605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357976; batch adversarial loss: 0.507997\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444921; batch adversarial loss: 0.496014\n",
      "epoch 95; iter: 0; batch classifier loss: 0.337457; batch adversarial loss: 0.598452\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389817; batch adversarial loss: 0.551190\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350479; batch adversarial loss: 0.498318\n",
      "epoch 98; iter: 0; batch classifier loss: 0.338128; batch adversarial loss: 0.591763\n",
      "epoch 99; iter: 0; batch classifier loss: 0.467597; batch adversarial loss: 0.452568\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372506; batch adversarial loss: 0.603417\n",
      "epoch 101; iter: 0; batch classifier loss: 0.346517; batch adversarial loss: 0.480220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.322635; batch adversarial loss: 0.525021\n",
      "epoch 103; iter: 0; batch classifier loss: 0.437339; batch adversarial loss: 0.509555\n",
      "epoch 104; iter: 0; batch classifier loss: 0.306768; batch adversarial loss: 0.572005\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358593; batch adversarial loss: 0.520022\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395758; batch adversarial loss: 0.533853\n",
      "epoch 107; iter: 0; batch classifier loss: 0.369934; batch adversarial loss: 0.571015\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352175; batch adversarial loss: 0.573674\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371476; batch adversarial loss: 0.555575\n",
      "epoch 110; iter: 0; batch classifier loss: 0.454654; batch adversarial loss: 0.516034\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359243; batch adversarial loss: 0.581660\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366207; batch adversarial loss: 0.634293\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335792; batch adversarial loss: 0.562352\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371145; batch adversarial loss: 0.583954\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354192; batch adversarial loss: 0.554021\n",
      "epoch 116; iter: 0; batch classifier loss: 0.329368; batch adversarial loss: 0.586697\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391960; batch adversarial loss: 0.538770\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362992; batch adversarial loss: 0.528469\n",
      "epoch 119; iter: 0; batch classifier loss: 0.272855; batch adversarial loss: 0.518381\n",
      "epoch 120; iter: 0; batch classifier loss: 0.306860; batch adversarial loss: 0.524772\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319307; batch adversarial loss: 0.594964\n",
      "epoch 122; iter: 0; batch classifier loss: 0.309960; batch adversarial loss: 0.452108\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342090; batch adversarial loss: 0.508215\n",
      "epoch 124; iter: 0; batch classifier loss: 0.295975; batch adversarial loss: 0.504632\n",
      "epoch 125; iter: 0; batch classifier loss: 0.302700; batch adversarial loss: 0.516832\n",
      "epoch 126; iter: 0; batch classifier loss: 0.278865; batch adversarial loss: 0.546980\n",
      "epoch 127; iter: 0; batch classifier loss: 0.334815; batch adversarial loss: 0.553081\n",
      "epoch 128; iter: 0; batch classifier loss: 0.391883; batch adversarial loss: 0.535097\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391812; batch adversarial loss: 0.572728\n",
      "epoch 130; iter: 0; batch classifier loss: 0.336375; batch adversarial loss: 0.505051\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331641; batch adversarial loss: 0.483783\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347046; batch adversarial loss: 0.481507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369212; batch adversarial loss: 0.634092\n",
      "epoch 134; iter: 0; batch classifier loss: 0.318481; batch adversarial loss: 0.523845\n",
      "epoch 135; iter: 0; batch classifier loss: 0.319026; batch adversarial loss: 0.495947\n",
      "epoch 136; iter: 0; batch classifier loss: 0.289440; batch adversarial loss: 0.487178\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334648; batch adversarial loss: 0.600656\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360512; batch adversarial loss: 0.543346\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345205; batch adversarial loss: 0.589640\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347385; batch adversarial loss: 0.535978\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342251; batch adversarial loss: 0.525045\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370306; batch adversarial loss: 0.538116\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322097; batch adversarial loss: 0.528263\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401401; batch adversarial loss: 0.591098\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372846; batch adversarial loss: 0.478020\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367053; batch adversarial loss: 0.448286\n",
      "epoch 147; iter: 0; batch classifier loss: 0.399531; batch adversarial loss: 0.471193\n",
      "epoch 148; iter: 0; batch classifier loss: 0.318600; batch adversarial loss: 0.535170\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329922; batch adversarial loss: 0.565446\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344723; batch adversarial loss: 0.542626\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357746; batch adversarial loss: 0.590079\n",
      "epoch 152; iter: 0; batch classifier loss: 0.303879; batch adversarial loss: 0.533623\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354596; batch adversarial loss: 0.432243\n",
      "epoch 154; iter: 0; batch classifier loss: 0.301020; batch adversarial loss: 0.517435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325746; batch adversarial loss: 0.545437\n",
      "epoch 156; iter: 0; batch classifier loss: 0.276865; batch adversarial loss: 0.555822\n",
      "epoch 157; iter: 0; batch classifier loss: 0.299478; batch adversarial loss: 0.589353\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300462; batch adversarial loss: 0.555008\n",
      "epoch 159; iter: 0; batch classifier loss: 0.295417; batch adversarial loss: 0.515868\n",
      "epoch 160; iter: 0; batch classifier loss: 0.388989; batch adversarial loss: 0.504553\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366927; batch adversarial loss: 0.541837\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350896; batch adversarial loss: 0.477835\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359365; batch adversarial loss: 0.545282\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372716; batch adversarial loss: 0.463891\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353945; batch adversarial loss: 0.564565\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308191; batch adversarial loss: 0.508260\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343418; batch adversarial loss: 0.519775\n",
      "epoch 168; iter: 0; batch classifier loss: 0.277639; batch adversarial loss: 0.522135\n",
      "epoch 169; iter: 0; batch classifier loss: 0.422646; batch adversarial loss: 0.533680\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297948; batch adversarial loss: 0.548826\n",
      "epoch 171; iter: 0; batch classifier loss: 0.286650; batch adversarial loss: 0.562228\n",
      "epoch 172; iter: 0; batch classifier loss: 0.419228; batch adversarial loss: 0.517145\n",
      "epoch 173; iter: 0; batch classifier loss: 0.278780; batch adversarial loss: 0.572742\n",
      "epoch 174; iter: 0; batch classifier loss: 0.331636; batch adversarial loss: 0.626323\n",
      "epoch 175; iter: 0; batch classifier loss: 0.300479; batch adversarial loss: 0.524378\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308545; batch adversarial loss: 0.536331\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351516; batch adversarial loss: 0.486237\n",
      "epoch 178; iter: 0; batch classifier loss: 0.310556; batch adversarial loss: 0.525337\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330618; batch adversarial loss: 0.535758\n",
      "epoch 180; iter: 0; batch classifier loss: 0.435335; batch adversarial loss: 0.547372\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337664; batch adversarial loss: 0.542683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.272504; batch adversarial loss: 0.508111\n",
      "epoch 183; iter: 0; batch classifier loss: 0.325984; batch adversarial loss: 0.546229\n",
      "epoch 184; iter: 0; batch classifier loss: 0.414883; batch adversarial loss: 0.568864\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328689; batch adversarial loss: 0.599876\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346518; batch adversarial loss: 0.533078\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365155; batch adversarial loss: 0.518088\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386312; batch adversarial loss: 0.485970\n",
      "epoch 189; iter: 0; batch classifier loss: 0.296775; batch adversarial loss: 0.543780\n",
      "epoch 190; iter: 0; batch classifier loss: 0.301873; batch adversarial loss: 0.560888\n",
      "epoch 191; iter: 0; batch classifier loss: 0.266780; batch adversarial loss: 0.534177\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328838; batch adversarial loss: 0.513103\n",
      "epoch 193; iter: 0; batch classifier loss: 0.267242; batch adversarial loss: 0.525724\n",
      "epoch 194; iter: 0; batch classifier loss: 0.310330; batch adversarial loss: 0.580315\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311652; batch adversarial loss: 0.580709\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299758; batch adversarial loss: 0.581647\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351992; batch adversarial loss: 0.526601\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356081; batch adversarial loss: 0.572038\n",
      "epoch 199; iter: 0; batch classifier loss: 0.276962; batch adversarial loss: 0.565650\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663745; batch adversarial loss: 0.697966\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616817; batch adversarial loss: 0.664717\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595203; batch adversarial loss: 0.645683\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576332; batch adversarial loss: 0.619030\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567488; batch adversarial loss: 0.617933\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543356; batch adversarial loss: 0.597774\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497306; batch adversarial loss: 0.617139\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549683; batch adversarial loss: 0.574447\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495807; batch adversarial loss: 0.618139\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557714; batch adversarial loss: 0.577478\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522904; batch adversarial loss: 0.585589\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532085; batch adversarial loss: 0.585007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507441; batch adversarial loss: 0.553359\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519519; batch adversarial loss: 0.551808\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527332; batch adversarial loss: 0.510659\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490162; batch adversarial loss: 0.652508\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504097; batch adversarial loss: 0.594987\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504767; batch adversarial loss: 0.592096\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460940; batch adversarial loss: 0.566946\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517473; batch adversarial loss: 0.564131\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451376; batch adversarial loss: 0.488293\n",
      "epoch 21; iter: 0; batch classifier loss: 0.438788; batch adversarial loss: 0.510293\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465701; batch adversarial loss: 0.549193\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472366; batch adversarial loss: 0.556380\n",
      "epoch 24; iter: 0; batch classifier loss: 0.450851; batch adversarial loss: 0.524834\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472326; batch adversarial loss: 0.508251\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476127; batch adversarial loss: 0.615269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460732; batch adversarial loss: 0.518966\n",
      "epoch 28; iter: 0; batch classifier loss: 0.537236; batch adversarial loss: 0.606107\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486947; batch adversarial loss: 0.515578\n",
      "epoch 30; iter: 0; batch classifier loss: 0.529347; batch adversarial loss: 0.562459\n",
      "epoch 31; iter: 0; batch classifier loss: 0.399229; batch adversarial loss: 0.539677\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432599; batch adversarial loss: 0.510497\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503721; batch adversarial loss: 0.577234\n",
      "epoch 34; iter: 0; batch classifier loss: 0.607837; batch adversarial loss: 0.563340\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461946; batch adversarial loss: 0.594044\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430224; batch adversarial loss: 0.531113\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447900; batch adversarial loss: 0.529339\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427520; batch adversarial loss: 0.520629\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458257; batch adversarial loss: 0.477072\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398180; batch adversarial loss: 0.562921\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476227; batch adversarial loss: 0.578907\n",
      "epoch 42; iter: 0; batch classifier loss: 0.521197; batch adversarial loss: 0.597460\n",
      "epoch 43; iter: 0; batch classifier loss: 0.369939; batch adversarial loss: 0.483451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388136; batch adversarial loss: 0.571872\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459453; batch adversarial loss: 0.446280\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464324; batch adversarial loss: 0.644187\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479767; batch adversarial loss: 0.526752\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483926; batch adversarial loss: 0.524800\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465409; batch adversarial loss: 0.562572\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374286; batch adversarial loss: 0.601566\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462379; batch adversarial loss: 0.542693\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408991; batch adversarial loss: 0.561279\n",
      "epoch 53; iter: 0; batch classifier loss: 0.460072; batch adversarial loss: 0.618243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413292; batch adversarial loss: 0.472230\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447388; batch adversarial loss: 0.581863\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410940; batch adversarial loss: 0.535509\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446693; batch adversarial loss: 0.526881\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444660; batch adversarial loss: 0.562985\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397624; batch adversarial loss: 0.508520\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440793; batch adversarial loss: 0.580578\n",
      "epoch 61; iter: 0; batch classifier loss: 0.472093; batch adversarial loss: 0.571557\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421603; batch adversarial loss: 0.490972\n",
      "epoch 63; iter: 0; batch classifier loss: 0.464571; batch adversarial loss: 0.544912\n",
      "epoch 64; iter: 0; batch classifier loss: 0.367743; batch adversarial loss: 0.490662\n",
      "epoch 65; iter: 0; batch classifier loss: 0.313289; batch adversarial loss: 0.489943\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437997; batch adversarial loss: 0.535342\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381867; batch adversarial loss: 0.471742\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400188; batch adversarial loss: 0.535632\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383985; batch adversarial loss: 0.554169\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409679; batch adversarial loss: 0.491052\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388004; batch adversarial loss: 0.553666\n",
      "epoch 72; iter: 0; batch classifier loss: 0.456467; batch adversarial loss: 0.508133\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441708; batch adversarial loss: 0.599110\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428206; batch adversarial loss: 0.581226\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380035; batch adversarial loss: 0.589257\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369710; batch adversarial loss: 0.508099\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.499364\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390900; batch adversarial loss: 0.517286\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417167; batch adversarial loss: 0.490612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.419906; batch adversarial loss: 0.580903\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415720; batch adversarial loss: 0.616835\n",
      "epoch 82; iter: 0; batch classifier loss: 0.458336; batch adversarial loss: 0.599041\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425958; batch adversarial loss: 0.507995\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392272; batch adversarial loss: 0.562771\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456639; batch adversarial loss: 0.599122\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390727; batch adversarial loss: 0.490132\n",
      "epoch 87; iter: 0; batch classifier loss: 0.507183; batch adversarial loss: 0.589989\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445055; batch adversarial loss: 0.526486\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376191; batch adversarial loss: 0.490395\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417529; batch adversarial loss: 0.581099\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365484; batch adversarial loss: 0.535616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434538; batch adversarial loss: 0.590115\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399416; batch adversarial loss: 0.571881\n",
      "epoch 94; iter: 0; batch classifier loss: 0.400074; batch adversarial loss: 0.635095\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362115; batch adversarial loss: 0.589875\n",
      "epoch 96; iter: 0; batch classifier loss: 0.323990; batch adversarial loss: 0.535285\n",
      "epoch 97; iter: 0; batch classifier loss: 0.286995; batch adversarial loss: 0.634748\n",
      "epoch 98; iter: 0; batch classifier loss: 0.465134; batch adversarial loss: 0.526147\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400122; batch adversarial loss: 0.544713\n",
      "epoch 100; iter: 0; batch classifier loss: 0.325502; batch adversarial loss: 0.662361\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367561; batch adversarial loss: 0.553759\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367819; batch adversarial loss: 0.562865\n",
      "epoch 103; iter: 0; batch classifier loss: 0.324154; batch adversarial loss: 0.498989\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366822; batch adversarial loss: 0.516512\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395273; batch adversarial loss: 0.590045\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362003; batch adversarial loss: 0.535597\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410377; batch adversarial loss: 0.544977\n",
      "epoch 108; iter: 0; batch classifier loss: 0.447517; batch adversarial loss: 0.526609\n",
      "epoch 109; iter: 0; batch classifier loss: 0.435077; batch adversarial loss: 0.598817\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367798; batch adversarial loss: 0.517406\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427235; batch adversarial loss: 0.480879\n",
      "epoch 112; iter: 0; batch classifier loss: 0.478108; batch adversarial loss: 0.472200\n",
      "epoch 113; iter: 0; batch classifier loss: 0.395835; batch adversarial loss: 0.526526\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357637; batch adversarial loss: 0.517414\n",
      "epoch 115; iter: 0; batch classifier loss: 0.310627; batch adversarial loss: 0.508118\n",
      "epoch 116; iter: 0; batch classifier loss: 0.416025; batch adversarial loss: 0.508388\n",
      "epoch 117; iter: 0; batch classifier loss: 0.395042; batch adversarial loss: 0.626473\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343862; batch adversarial loss: 0.580827\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353252; batch adversarial loss: 0.589781\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401365; batch adversarial loss: 0.517432\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390888; batch adversarial loss: 0.553699\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387656; batch adversarial loss: 0.499315\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370339; batch adversarial loss: 0.571791\n",
      "epoch 124; iter: 0; batch classifier loss: 0.321066; batch adversarial loss: 0.598969\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380762; batch adversarial loss: 0.553786\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381056; batch adversarial loss: 0.526491\n",
      "epoch 127; iter: 0; batch classifier loss: 0.435295; batch adversarial loss: 0.516941\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343444; batch adversarial loss: 0.507992\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342292; batch adversarial loss: 0.589898\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385056; batch adversarial loss: 0.517630\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438889; batch adversarial loss: 0.571555\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402792; batch adversarial loss: 0.589595\n",
      "epoch 133; iter: 0; batch classifier loss: 0.442600; batch adversarial loss: 0.472072\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416098; batch adversarial loss: 0.635479\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364516; batch adversarial loss: 0.535853\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421804; batch adversarial loss: 0.527009\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358474; batch adversarial loss: 0.580925\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383318; batch adversarial loss: 0.607893\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350746; batch adversarial loss: 0.526308\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374958; batch adversarial loss: 0.571809\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371017; batch adversarial loss: 0.535689\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356400; batch adversarial loss: 0.480894\n",
      "epoch 143; iter: 0; batch classifier loss: 0.344522; batch adversarial loss: 0.544610\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398223; batch adversarial loss: 0.598506\n",
      "epoch 145; iter: 0; batch classifier loss: 0.417134; batch adversarial loss: 0.562925\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388313; batch adversarial loss: 0.517205\n",
      "epoch 147; iter: 0; batch classifier loss: 0.335329; batch adversarial loss: 0.598889\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356129; batch adversarial loss: 0.472232\n",
      "epoch 149; iter: 0; batch classifier loss: 0.419076; batch adversarial loss: 0.535717\n",
      "epoch 150; iter: 0; batch classifier loss: 0.437271; batch adversarial loss: 0.589610\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398212; batch adversarial loss: 0.490587\n",
      "epoch 152; iter: 0; batch classifier loss: 0.406968; batch adversarial loss: 0.580521\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385634; batch adversarial loss: 0.525272\n",
      "epoch 154; iter: 0; batch classifier loss: 0.446572; batch adversarial loss: 0.517218\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334899; batch adversarial loss: 0.588648\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338497; batch adversarial loss: 0.535551\n",
      "epoch 157; iter: 0; batch classifier loss: 0.435877; batch adversarial loss: 0.518742\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321387; batch adversarial loss: 0.556300\n",
      "epoch 159; iter: 0; batch classifier loss: 0.289625; batch adversarial loss: 0.672539\n",
      "epoch 160; iter: 0; batch classifier loss: 0.403239; batch adversarial loss: 0.572829\n",
      "epoch 161; iter: 0; batch classifier loss: 0.403276; batch adversarial loss: 0.599719\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351047; batch adversarial loss: 0.481436\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356486; batch adversarial loss: 0.635697\n",
      "epoch 164; iter: 0; batch classifier loss: 0.486579; batch adversarial loss: 0.618210\n",
      "epoch 165; iter: 0; batch classifier loss: 0.472599; batch adversarial loss: 0.544456\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406987; batch adversarial loss: 0.581565\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407146; batch adversarial loss: 0.498545\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320885; batch adversarial loss: 0.544686\n",
      "epoch 169; iter: 0; batch classifier loss: 0.413538; batch adversarial loss: 0.554357\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403185; batch adversarial loss: 0.544056\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411319; batch adversarial loss: 0.525859\n",
      "epoch 172; iter: 0; batch classifier loss: 0.324571; batch adversarial loss: 0.607594\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359663; batch adversarial loss: 0.553115\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395972; batch adversarial loss: 0.544105\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336001; batch adversarial loss: 0.597015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.322428; batch adversarial loss: 0.553163\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360787; batch adversarial loss: 0.518006\n",
      "epoch 178; iter: 0; batch classifier loss: 0.459950; batch adversarial loss: 0.526721\n",
      "epoch 179; iter: 0; batch classifier loss: 0.449413; batch adversarial loss: 0.561190\n",
      "epoch 180; iter: 0; batch classifier loss: 0.449956; batch adversarial loss: 0.498647\n",
      "epoch 181; iter: 0; batch classifier loss: 0.414773; batch adversarial loss: 0.580782\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338765; batch adversarial loss: 0.544445\n",
      "epoch 183; iter: 0; batch classifier loss: 0.497035; batch adversarial loss: 0.536613\n",
      "epoch 184; iter: 0; batch classifier loss: 0.522528; batch adversarial loss: 0.552737\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390772; batch adversarial loss: 0.617649\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341810; batch adversarial loss: 0.526216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.306044; batch adversarial loss: 0.508192\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350200; batch adversarial loss: 0.571193\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328429; batch adversarial loss: 0.535185\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341235; batch adversarial loss: 0.499190\n",
      "epoch 191; iter: 0; batch classifier loss: 0.326311; batch adversarial loss: 0.581098\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367392; batch adversarial loss: 0.580639\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398762; batch adversarial loss: 0.518042\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333629; batch adversarial loss: 0.597221\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335499; batch adversarial loss: 0.571666\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354951; batch adversarial loss: 0.516368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422948; batch adversarial loss: 0.581037\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347431; batch adversarial loss: 0.517297\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339728; batch adversarial loss: 0.544186\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661500; batch adversarial loss: 0.587778\n",
      "epoch 1; iter: 0; batch classifier loss: 0.549899; batch adversarial loss: 0.735995\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556805; batch adversarial loss: 0.643620\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572569; batch adversarial loss: 0.724218\n",
      "epoch 4; iter: 0; batch classifier loss: 0.592351; batch adversarial loss: 0.663006\n",
      "epoch 5; iter: 0; batch classifier loss: 0.529860; batch adversarial loss: 0.689772\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596271; batch adversarial loss: 0.734437\n",
      "epoch 7; iter: 0; batch classifier loss: 0.641440; batch adversarial loss: 0.636439\n",
      "epoch 8; iter: 0; batch classifier loss: 0.621998; batch adversarial loss: 0.692968\n",
      "epoch 9; iter: 0; batch classifier loss: 0.593867; batch adversarial loss: 0.575607\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594739; batch adversarial loss: 0.655769\n",
      "epoch 11; iter: 0; batch classifier loss: 0.623379; batch adversarial loss: 0.612055\n",
      "epoch 12; iter: 0; batch classifier loss: 0.643898; batch adversarial loss: 0.592790\n",
      "epoch 13; iter: 0; batch classifier loss: 0.625579; batch adversarial loss: 0.647533\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579570; batch adversarial loss: 0.564135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.628348; batch adversarial loss: 0.554621\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513502; batch adversarial loss: 0.571865\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544318; batch adversarial loss: 0.587860\n",
      "epoch 18; iter: 0; batch classifier loss: 0.582282; batch adversarial loss: 0.537282\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482497; batch adversarial loss: 0.455804\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485625; batch adversarial loss: 0.533609\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473470; batch adversarial loss: 0.554950\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519341; batch adversarial loss: 0.628972\n",
      "epoch 23; iter: 0; batch classifier loss: 0.399078; batch adversarial loss: 0.580408\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494638; batch adversarial loss: 0.492685\n",
      "epoch 25; iter: 0; batch classifier loss: 0.592482; batch adversarial loss: 0.443934\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462107; batch adversarial loss: 0.519687\n",
      "epoch 27; iter: 0; batch classifier loss: 0.516841; batch adversarial loss: 0.581735\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453030; batch adversarial loss: 0.614982\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489170; batch adversarial loss: 0.535475\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465820; batch adversarial loss: 0.454729\n",
      "epoch 31; iter: 0; batch classifier loss: 0.418117; batch adversarial loss: 0.599064\n",
      "epoch 32; iter: 0; batch classifier loss: 0.489826; batch adversarial loss: 0.587100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497224; batch adversarial loss: 0.624566\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474037; batch adversarial loss: 0.579625\n",
      "epoch 35; iter: 0; batch classifier loss: 0.536291; batch adversarial loss: 0.562130\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499422; batch adversarial loss: 0.606301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449449; batch adversarial loss: 0.561738\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392360; batch adversarial loss: 0.562005\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473374; batch adversarial loss: 0.607429\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436490; batch adversarial loss: 0.489178\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445717; batch adversarial loss: 0.464706\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434690; batch adversarial loss: 0.563228\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450708; batch adversarial loss: 0.445190\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489623; batch adversarial loss: 0.489667\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373347; batch adversarial loss: 0.607405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449259; batch adversarial loss: 0.554931\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493643; batch adversarial loss: 0.589978\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434194; batch adversarial loss: 0.633424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382822; batch adversarial loss: 0.654547\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441007; batch adversarial loss: 0.589235\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427038; batch adversarial loss: 0.545209\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417727; batch adversarial loss: 0.455727\n",
      "epoch 53; iter: 0; batch classifier loss: 0.487896; batch adversarial loss: 0.491770\n",
      "epoch 54; iter: 0; batch classifier loss: 0.403757; batch adversarial loss: 0.446270\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448777; batch adversarial loss: 0.562092\n",
      "epoch 56; iter: 0; batch classifier loss: 0.347985; batch adversarial loss: 0.571448\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392645; batch adversarial loss: 0.589844\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451854; batch adversarial loss: 0.580341\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429818; batch adversarial loss: 0.598836\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440911; batch adversarial loss: 0.554732\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475791; batch adversarial loss: 0.544235\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433687; batch adversarial loss: 0.571366\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416570; batch adversarial loss: 0.553522\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387035; batch adversarial loss: 0.554183\n",
      "epoch 65; iter: 0; batch classifier loss: 0.446164; batch adversarial loss: 0.463410\n",
      "epoch 66; iter: 0; batch classifier loss: 0.477139; batch adversarial loss: 0.463353\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363150; batch adversarial loss: 0.481395\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403727; batch adversarial loss: 0.499613\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378503; batch adversarial loss: 0.589846\n",
      "epoch 70; iter: 0; batch classifier loss: 0.435944; batch adversarial loss: 0.598322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377298; batch adversarial loss: 0.508698\n",
      "epoch 72; iter: 0; batch classifier loss: 0.458382; batch adversarial loss: 0.553446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415673; batch adversarial loss: 0.569647\n",
      "epoch 74; iter: 0; batch classifier loss: 0.359746; batch adversarial loss: 0.534949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.392534; batch adversarial loss: 0.609107\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409996; batch adversarial loss: 0.582159\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378126; batch adversarial loss: 0.554680\n",
      "epoch 78; iter: 0; batch classifier loss: 0.418935; batch adversarial loss: 0.652323\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398507; batch adversarial loss: 0.616066\n",
      "epoch 80; iter: 0; batch classifier loss: 0.396929; batch adversarial loss: 0.545305\n",
      "epoch 81; iter: 0; batch classifier loss: 0.364253; batch adversarial loss: 0.571656\n",
      "epoch 82; iter: 0; batch classifier loss: 0.469111; batch adversarial loss: 0.509682\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429173; batch adversarial loss: 0.605941\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395496; batch adversarial loss: 0.650306\n",
      "epoch 85; iter: 0; batch classifier loss: 0.492380; batch adversarial loss: 0.603587\n",
      "epoch 86; iter: 0; batch classifier loss: 0.448375; batch adversarial loss: 0.517345\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381165; batch adversarial loss: 0.624643\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352137; batch adversarial loss: 0.509540\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419004; batch adversarial loss: 0.563223\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374067; batch adversarial loss: 0.562742\n",
      "epoch 91; iter: 0; batch classifier loss: 0.339743; batch adversarial loss: 0.562864\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402040; batch adversarial loss: 0.572579\n",
      "epoch 93; iter: 0; batch classifier loss: 0.442828; batch adversarial loss: 0.553228\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405254; batch adversarial loss: 0.588713\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375239; batch adversarial loss: 0.508116\n",
      "epoch 96; iter: 0; batch classifier loss: 0.519514; batch adversarial loss: 0.690583\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387210; batch adversarial loss: 0.526635\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366741; batch adversarial loss: 0.643920\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384180; batch adversarial loss: 0.563012\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377983; batch adversarial loss: 0.544020\n",
      "epoch 101; iter: 0; batch classifier loss: 0.424656; batch adversarial loss: 0.562763\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379230; batch adversarial loss: 0.526949\n",
      "epoch 103; iter: 0; batch classifier loss: 0.428093; batch adversarial loss: 0.580391\n",
      "epoch 104; iter: 0; batch classifier loss: 0.388677; batch adversarial loss: 0.562491\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337973; batch adversarial loss: 0.543643\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402590; batch adversarial loss: 0.526006\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366145; batch adversarial loss: 0.545626\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417201; batch adversarial loss: 0.625031\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363639; batch adversarial loss: 0.545374\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385816; batch adversarial loss: 0.588262\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416732; batch adversarial loss: 0.536646\n",
      "epoch 112; iter: 0; batch classifier loss: 0.455274; batch adversarial loss: 0.526506\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419521; batch adversarial loss: 0.580528\n",
      "epoch 114; iter: 0; batch classifier loss: 0.416781; batch adversarial loss: 0.527752\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341383; batch adversarial loss: 0.544636\n",
      "epoch 116; iter: 0; batch classifier loss: 0.283538; batch adversarial loss: 0.627422\n",
      "epoch 117; iter: 0; batch classifier loss: 0.482190; batch adversarial loss: 0.554062\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408420; batch adversarial loss: 0.653205\n",
      "epoch 119; iter: 0; batch classifier loss: 0.307470; batch adversarial loss: 0.526486\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371340; batch adversarial loss: 0.490822\n",
      "epoch 121; iter: 0; batch classifier loss: 0.460803; batch adversarial loss: 0.599102\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386577; batch adversarial loss: 0.490543\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360915; batch adversarial loss: 0.517475\n",
      "epoch 124; iter: 0; batch classifier loss: 0.445822; batch adversarial loss: 0.526547\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399483; batch adversarial loss: 0.607655\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405414; batch adversarial loss: 0.597671\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387477; batch adversarial loss: 0.507836\n",
      "epoch 128; iter: 0; batch classifier loss: 0.421535; batch adversarial loss: 0.554625\n",
      "epoch 129; iter: 0; batch classifier loss: 0.387296; batch adversarial loss: 0.527222\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362000; batch adversarial loss: 0.526391\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351310; batch adversarial loss: 0.536231\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431504; batch adversarial loss: 0.535645\n",
      "epoch 133; iter: 0; batch classifier loss: 0.387274; batch adversarial loss: 0.544995\n",
      "epoch 134; iter: 0; batch classifier loss: 0.408775; batch adversarial loss: 0.571532\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361430; batch adversarial loss: 0.571383\n",
      "epoch 136; iter: 0; batch classifier loss: 0.347271; batch adversarial loss: 0.607171\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372268; batch adversarial loss: 0.490520\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366298; batch adversarial loss: 0.534931\n",
      "epoch 139; iter: 0; batch classifier loss: 0.427930; batch adversarial loss: 0.579452\n",
      "epoch 140; iter: 0; batch classifier loss: 0.408607; batch adversarial loss: 0.527088\n",
      "epoch 141; iter: 0; batch classifier loss: 0.401851; batch adversarial loss: 0.580166\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380009; batch adversarial loss: 0.616611\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391948; batch adversarial loss: 0.608151\n",
      "epoch 144; iter: 0; batch classifier loss: 0.326663; batch adversarial loss: 0.562382\n",
      "epoch 145; iter: 0; batch classifier loss: 0.402943; batch adversarial loss: 0.544895\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331855; batch adversarial loss: 0.517543\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383835; batch adversarial loss: 0.580901\n",
      "epoch 148; iter: 0; batch classifier loss: 0.306655; batch adversarial loss: 0.499259\n",
      "epoch 149; iter: 0; batch classifier loss: 0.452239; batch adversarial loss: 0.553583\n",
      "epoch 150; iter: 0; batch classifier loss: 0.313747; batch adversarial loss: 0.626015\n",
      "epoch 151; iter: 0; batch classifier loss: 0.401450; batch adversarial loss: 0.517497\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376494; batch adversarial loss: 0.625765\n",
      "epoch 153; iter: 0; batch classifier loss: 0.428746; batch adversarial loss: 0.517411\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381545; batch adversarial loss: 0.616723\n",
      "epoch 155; iter: 0; batch classifier loss: 0.404173; batch adversarial loss: 0.616314\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351881; batch adversarial loss: 0.508730\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309253; batch adversarial loss: 0.616853\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343020; batch adversarial loss: 0.634953\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371265; batch adversarial loss: 0.463846\n",
      "epoch 160; iter: 0; batch classifier loss: 0.441376; batch adversarial loss: 0.580493\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370064; batch adversarial loss: 0.508877\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349767; batch adversarial loss: 0.661528\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356469; batch adversarial loss: 0.544448\n",
      "epoch 164; iter: 0; batch classifier loss: 0.357102; batch adversarial loss: 0.481325\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397809; batch adversarial loss: 0.580761\n",
      "epoch 166; iter: 0; batch classifier loss: 0.398480; batch adversarial loss: 0.544937\n",
      "epoch 167; iter: 0; batch classifier loss: 0.314827; batch adversarial loss: 0.544427\n",
      "epoch 168; iter: 0; batch classifier loss: 0.458257; batch adversarial loss: 0.480691\n",
      "epoch 169; iter: 0; batch classifier loss: 0.331652; batch adversarial loss: 0.563064\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393943; batch adversarial loss: 0.462914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.325760; batch adversarial loss: 0.535405\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378372; batch adversarial loss: 0.472393\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357461; batch adversarial loss: 0.544849\n",
      "epoch 174; iter: 0; batch classifier loss: 0.323244; batch adversarial loss: 0.472386\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347486; batch adversarial loss: 0.588938\n",
      "epoch 176; iter: 0; batch classifier loss: 0.419469; batch adversarial loss: 0.562774\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399621; batch adversarial loss: 0.580825\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416895; batch adversarial loss: 0.598274\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354597; batch adversarial loss: 0.508939\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344859; batch adversarial loss: 0.553833\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377539; batch adversarial loss: 0.562142\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348890; batch adversarial loss: 0.606913\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391477; batch adversarial loss: 0.644335\n",
      "epoch 184; iter: 0; batch classifier loss: 0.418276; batch adversarial loss: 0.526608\n",
      "epoch 185; iter: 0; batch classifier loss: 0.403433; batch adversarial loss: 0.553977\n",
      "epoch 186; iter: 0; batch classifier loss: 0.419787; batch adversarial loss: 0.580467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.487128; batch adversarial loss: 0.517128\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341036; batch adversarial loss: 0.545478\n",
      "epoch 189; iter: 0; batch classifier loss: 0.400478; batch adversarial loss: 0.562407\n",
      "epoch 190; iter: 0; batch classifier loss: 0.418243; batch adversarial loss: 0.556145\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366086; batch adversarial loss: 0.562987\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378631; batch adversarial loss: 0.535982\n",
      "epoch 193; iter: 0; batch classifier loss: 0.435492; batch adversarial loss: 0.536476\n",
      "epoch 194; iter: 0; batch classifier loss: 0.323430; batch adversarial loss: 0.535045\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349409; batch adversarial loss: 0.617481\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314548; batch adversarial loss: 0.526481\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357825; batch adversarial loss: 0.563144\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319063; batch adversarial loss: 0.517982\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359619; batch adversarial loss: 0.589878\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732986; batch adversarial loss: 1.003374\n",
      "epoch 1; iter: 0; batch classifier loss: 0.644131; batch adversarial loss: 0.907493\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581028; batch adversarial loss: 0.793759\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570448; batch adversarial loss: 0.780988\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505476; batch adversarial loss: 0.767227\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578448; batch adversarial loss: 0.712067\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544222; batch adversarial loss: 0.686822\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532036; batch adversarial loss: 0.666492\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571061; batch adversarial loss: 0.667173\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546764; batch adversarial loss: 0.661173\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562784; batch adversarial loss: 0.632334\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554992; batch adversarial loss: 0.569600\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582106; batch adversarial loss: 0.617374\n",
      "epoch 13; iter: 0; batch classifier loss: 0.581977; batch adversarial loss: 0.530164\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481402; batch adversarial loss: 0.543277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482244; batch adversarial loss: 0.577803\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552150; batch adversarial loss: 0.585562\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507883; batch adversarial loss: 0.565456\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492361; batch adversarial loss: 0.604843\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448087; batch adversarial loss: 0.566247\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465670; batch adversarial loss: 0.548010\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502921; batch adversarial loss: 0.566990\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443704; batch adversarial loss: 0.545991\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519208; batch adversarial loss: 0.597922\n",
      "epoch 24; iter: 0; batch classifier loss: 0.513614; batch adversarial loss: 0.504335\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504497; batch adversarial loss: 0.550544\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460677; batch adversarial loss: 0.620750\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489410; batch adversarial loss: 0.564622\n",
      "epoch 28; iter: 0; batch classifier loss: 0.559397; batch adversarial loss: 0.511594\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452925; batch adversarial loss: 0.521042\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550974; batch adversarial loss: 0.607986\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523667; batch adversarial loss: 0.570745\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504068; batch adversarial loss: 0.539552\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486558; batch adversarial loss: 0.555367\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501184; batch adversarial loss: 0.536211\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434239; batch adversarial loss: 0.559342\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357468; batch adversarial loss: 0.520629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484360; batch adversarial loss: 0.535724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434385; batch adversarial loss: 0.562895\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445669; batch adversarial loss: 0.512318\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395520; batch adversarial loss: 0.512423\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437407; batch adversarial loss: 0.508205\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475516; batch adversarial loss: 0.564390\n",
      "epoch 43; iter: 0; batch classifier loss: 0.545848; batch adversarial loss: 0.533549\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481702; batch adversarial loss: 0.506817\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431497; batch adversarial loss: 0.560373\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367862; batch adversarial loss: 0.512482\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401528; batch adversarial loss: 0.607017\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491835; batch adversarial loss: 0.599169\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443316; batch adversarial loss: 0.533927\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443885; batch adversarial loss: 0.580902\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399444; batch adversarial loss: 0.596857\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447494; batch adversarial loss: 0.525968\n",
      "epoch 53; iter: 0; batch classifier loss: 0.498493; batch adversarial loss: 0.532991\n",
      "epoch 54; iter: 0; batch classifier loss: 0.524969; batch adversarial loss: 0.607007\n",
      "epoch 55; iter: 0; batch classifier loss: 0.359652; batch adversarial loss: 0.586107\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430324; batch adversarial loss: 0.491633\n",
      "epoch 57; iter: 0; batch classifier loss: 0.320385; batch adversarial loss: 0.517834\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414105; batch adversarial loss: 0.491604\n",
      "epoch 59; iter: 0; batch classifier loss: 0.395965; batch adversarial loss: 0.579817\n",
      "epoch 60; iter: 0; batch classifier loss: 0.351730; batch adversarial loss: 0.553759\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411090; batch adversarial loss: 0.590241\n",
      "epoch 62; iter: 0; batch classifier loss: 0.404877; batch adversarial loss: 0.632355\n",
      "epoch 63; iter: 0; batch classifier loss: 0.445568; batch adversarial loss: 0.518767\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376804; batch adversarial loss: 0.599260\n",
      "epoch 65; iter: 0; batch classifier loss: 0.418772; batch adversarial loss: 0.526067\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416340; batch adversarial loss: 0.554064\n",
      "epoch 67; iter: 0; batch classifier loss: 0.357938; batch adversarial loss: 0.625105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.398052; batch adversarial loss: 0.600136\n",
      "epoch 69; iter: 0; batch classifier loss: 0.464269; batch adversarial loss: 0.525805\n",
      "epoch 70; iter: 0; batch classifier loss: 0.362203; batch adversarial loss: 0.555016\n",
      "epoch 71; iter: 0; batch classifier loss: 0.487126; batch adversarial loss: 0.562704\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404880; batch adversarial loss: 0.543706\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405278; batch adversarial loss: 0.568953\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417013; batch adversarial loss: 0.533500\n",
      "epoch 75; iter: 0; batch classifier loss: 0.392154; batch adversarial loss: 0.579823\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394972; batch adversarial loss: 0.547402\n",
      "epoch 77; iter: 0; batch classifier loss: 0.461421; batch adversarial loss: 0.579587\n",
      "epoch 78; iter: 0; batch classifier loss: 0.325094; batch adversarial loss: 0.572797\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452304; batch adversarial loss: 0.598565\n",
      "epoch 80; iter: 0; batch classifier loss: 0.468178; batch adversarial loss: 0.536344\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402659; batch adversarial loss: 0.471318\n",
      "epoch 82; iter: 0; batch classifier loss: 0.514456; batch adversarial loss: 0.544660\n",
      "epoch 83; iter: 0; batch classifier loss: 0.478472; batch adversarial loss: 0.570364\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426938; batch adversarial loss: 0.590639\n",
      "epoch 85; iter: 0; batch classifier loss: 0.375709; batch adversarial loss: 0.489344\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419194; batch adversarial loss: 0.554084\n",
      "epoch 87; iter: 0; batch classifier loss: 0.407839; batch adversarial loss: 0.598295\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367888; batch adversarial loss: 0.588517\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408555; batch adversarial loss: 0.563016\n",
      "epoch 90; iter: 0; batch classifier loss: 0.510256; batch adversarial loss: 0.572562\n",
      "epoch 91; iter: 0; batch classifier loss: 0.574772; batch adversarial loss: 0.481689\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393986; batch adversarial loss: 0.562810\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392421; batch adversarial loss: 0.599215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.462234; batch adversarial loss: 0.562061\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415785; batch adversarial loss: 0.517512\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383432; batch adversarial loss: 0.479940\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369730; batch adversarial loss: 0.519044\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378430; batch adversarial loss: 0.527131\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402422; batch adversarial loss: 0.511305\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431890; batch adversarial loss: 0.528653\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409966; batch adversarial loss: 0.586978\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437613; batch adversarial loss: 0.543878\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376114; batch adversarial loss: 0.526374\n",
      "epoch 104; iter: 0; batch classifier loss: 0.455105; batch adversarial loss: 0.527926\n",
      "epoch 105; iter: 0; batch classifier loss: 0.381151; batch adversarial loss: 0.554204\n",
      "epoch 106; iter: 0; batch classifier loss: 0.429213; batch adversarial loss: 0.607001\n",
      "epoch 107; iter: 0; batch classifier loss: 0.424862; batch adversarial loss: 0.572214\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400676; batch adversarial loss: 0.562704\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407498; batch adversarial loss: 0.552650\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405541; batch adversarial loss: 0.542091\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387969; batch adversarial loss: 0.579855\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360218; batch adversarial loss: 0.520130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369969; batch adversarial loss: 0.596385\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394378; batch adversarial loss: 0.635229\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366419; batch adversarial loss: 0.471603\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366033; batch adversarial loss: 0.615444\n",
      "epoch 117; iter: 0; batch classifier loss: 0.470633; batch adversarial loss: 0.569335\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340038; batch adversarial loss: 0.560176\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425221; batch adversarial loss: 0.598192\n",
      "epoch 120; iter: 0; batch classifier loss: 0.498289; batch adversarial loss: 0.527299\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365125; batch adversarial loss: 0.616221\n",
      "epoch 122; iter: 0; batch classifier loss: 0.374622; batch adversarial loss: 0.524436\n",
      "epoch 123; iter: 0; batch classifier loss: 0.402031; batch adversarial loss: 0.544753\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418348; batch adversarial loss: 0.543725\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400275; batch adversarial loss: 0.614643\n",
      "epoch 126; iter: 0; batch classifier loss: 0.427972; batch adversarial loss: 0.590550\n",
      "epoch 127; iter: 0; batch classifier loss: 0.461499; batch adversarial loss: 0.573062\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411530; batch adversarial loss: 0.597634\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388226; batch adversarial loss: 0.492522\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396853; batch adversarial loss: 0.598477\n",
      "epoch 131; iter: 0; batch classifier loss: 0.412487; batch adversarial loss: 0.525526\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350535; batch adversarial loss: 0.544517\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340010; batch adversarial loss: 0.517266\n",
      "epoch 134; iter: 0; batch classifier loss: 0.543538; batch adversarial loss: 0.581710\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378119; batch adversarial loss: 0.605796\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366188; batch adversarial loss: 0.528733\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399469; batch adversarial loss: 0.580267\n",
      "epoch 138; iter: 0; batch classifier loss: 0.300604; batch adversarial loss: 0.545017\n",
      "epoch 139; iter: 0; batch classifier loss: 0.281093; batch adversarial loss: 0.606053\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350142; batch adversarial loss: 0.572797\n",
      "epoch 141; iter: 0; batch classifier loss: 0.427107; batch adversarial loss: 0.526471\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397505; batch adversarial loss: 0.554805\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413513; batch adversarial loss: 0.572579\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359199; batch adversarial loss: 0.561751\n",
      "epoch 145; iter: 0; batch classifier loss: 0.408246; batch adversarial loss: 0.517351\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345928; batch adversarial loss: 0.538273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.406629; batch adversarial loss: 0.561969\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386837; batch adversarial loss: 0.591568\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374985; batch adversarial loss: 0.597676\n",
      "epoch 150; iter: 0; batch classifier loss: 0.466110; batch adversarial loss: 0.473972\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432073; batch adversarial loss: 0.569334\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364161; batch adversarial loss: 0.571503\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364991; batch adversarial loss: 0.617180\n",
      "epoch 154; iter: 0; batch classifier loss: 0.435690; batch adversarial loss: 0.498784\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374648; batch adversarial loss: 0.543660\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386982; batch adversarial loss: 0.642156\n",
      "epoch 157; iter: 0; batch classifier loss: 0.430262; batch adversarial loss: 0.500281\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343537; batch adversarial loss: 0.555246\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360969; batch adversarial loss: 0.578742\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382508; batch adversarial loss: 0.561879\n",
      "epoch 161; iter: 0; batch classifier loss: 0.504456; batch adversarial loss: 0.591417\n",
      "epoch 162; iter: 0; batch classifier loss: 0.339788; batch adversarial loss: 0.554346\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375692; batch adversarial loss: 0.551274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.376838; batch adversarial loss: 0.580359\n",
      "epoch 165; iter: 0; batch classifier loss: 0.337946; batch adversarial loss: 0.545953\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362049; batch adversarial loss: 0.573783\n",
      "epoch 167; iter: 0; batch classifier loss: 0.396107; batch adversarial loss: 0.590927\n",
      "epoch 168; iter: 0; batch classifier loss: 0.454448; batch adversarial loss: 0.563973\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339420; batch adversarial loss: 0.535397\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369628; batch adversarial loss: 0.516411\n",
      "epoch 171; iter: 0; batch classifier loss: 0.429714; batch adversarial loss: 0.534419\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344002; batch adversarial loss: 0.551676\n",
      "epoch 173; iter: 0; batch classifier loss: 0.409780; batch adversarial loss: 0.517338\n",
      "epoch 174; iter: 0; batch classifier loss: 0.278660; batch adversarial loss: 0.536371\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365130; batch adversarial loss: 0.479562\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370984; batch adversarial loss: 0.528540\n",
      "epoch 177; iter: 0; batch classifier loss: 0.397429; batch adversarial loss: 0.590741\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345074; batch adversarial loss: 0.607189\n",
      "epoch 179; iter: 0; batch classifier loss: 0.312441; batch adversarial loss: 0.544657\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327268; batch adversarial loss: 0.525673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.427800; batch adversarial loss: 0.579297\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404572; batch adversarial loss: 0.471195\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333084; batch adversarial loss: 0.517869\n",
      "epoch 184; iter: 0; batch classifier loss: 0.453959; batch adversarial loss: 0.543220\n",
      "epoch 185; iter: 0; batch classifier loss: 0.413740; batch adversarial loss: 0.498852\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367118; batch adversarial loss: 0.599339\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382744; batch adversarial loss: 0.515781\n",
      "epoch 188; iter: 0; batch classifier loss: 0.426423; batch adversarial loss: 0.587075\n",
      "epoch 189; iter: 0; batch classifier loss: 0.449002; batch adversarial loss: 0.544552\n",
      "epoch 190; iter: 0; batch classifier loss: 0.296494; batch adversarial loss: 0.571199\n",
      "epoch 191; iter: 0; batch classifier loss: 0.304710; batch adversarial loss: 0.517868\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306483; batch adversarial loss: 0.534982\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398745; batch adversarial loss: 0.512122\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404639; batch adversarial loss: 0.516500\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366114; batch adversarial loss: 0.516198\n",
      "epoch 196; iter: 0; batch classifier loss: 0.376067; batch adversarial loss: 0.605124\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422911; batch adversarial loss: 0.525168\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358129; batch adversarial loss: 0.536312\n",
      "epoch 199; iter: 0; batch classifier loss: 0.414544; batch adversarial loss: 0.652165\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708319; batch adversarial loss: 0.633029\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544576; batch adversarial loss: 0.648562\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619153; batch adversarial loss: 0.614460\n",
      "epoch 3; iter: 0; batch classifier loss: 0.483425; batch adversarial loss: 0.593050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580188; batch adversarial loss: 0.613627\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552407; batch adversarial loss: 0.608047\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548371; batch adversarial loss: 0.614439\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536640; batch adversarial loss: 0.615272\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587796; batch adversarial loss: 0.600053\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504940; batch adversarial loss: 0.547310\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568249; batch adversarial loss: 0.588475\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525529; batch adversarial loss: 0.561220\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511688; batch adversarial loss: 0.586939\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491216; batch adversarial loss: 0.633048\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496274; batch adversarial loss: 0.581702\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507987; batch adversarial loss: 0.607803\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571022; batch adversarial loss: 0.499201\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528628; batch adversarial loss: 0.530505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532913; batch adversarial loss: 0.559283\n",
      "epoch 19; iter: 0; batch classifier loss: 0.546694; batch adversarial loss: 0.602380\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515921; batch adversarial loss: 0.627276\n",
      "epoch 21; iter: 0; batch classifier loss: 0.563632; batch adversarial loss: 0.538758\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428271; batch adversarial loss: 0.585445\n",
      "epoch 23; iter: 0; batch classifier loss: 0.389167; batch adversarial loss: 0.543725\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541849; batch adversarial loss: 0.601183\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519329; batch adversarial loss: 0.534076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494511; batch adversarial loss: 0.567689\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432050; batch adversarial loss: 0.564070\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541412; batch adversarial loss: 0.546771\n",
      "epoch 29; iter: 0; batch classifier loss: 0.607352; batch adversarial loss: 0.523205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.375003; batch adversarial loss: 0.587397\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494896; batch adversarial loss: 0.495380\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464206; batch adversarial loss: 0.520536\n",
      "epoch 33; iter: 0; batch classifier loss: 0.348421; batch adversarial loss: 0.555514\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479353; batch adversarial loss: 0.510161\n",
      "epoch 35; iter: 0; batch classifier loss: 0.531787; batch adversarial loss: 0.536756\n",
      "epoch 36; iter: 0; batch classifier loss: 0.349551; batch adversarial loss: 0.544978\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429110; batch adversarial loss: 0.491726\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444692; batch adversarial loss: 0.535767\n",
      "epoch 39; iter: 0; batch classifier loss: 0.515384; batch adversarial loss: 0.544619\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464864; batch adversarial loss: 0.517522\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445497; batch adversarial loss: 0.598649\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416564; batch adversarial loss: 0.535698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454420; batch adversarial loss: 0.562661\n",
      "epoch 44; iter: 0; batch classifier loss: 0.413915; batch adversarial loss: 0.490520\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392971; batch adversarial loss: 0.517238\n",
      "epoch 46; iter: 0; batch classifier loss: 0.435854; batch adversarial loss: 0.598629\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484011; batch adversarial loss: 0.571242\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370719; batch adversarial loss: 0.596172\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435482; batch adversarial loss: 0.500876\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491164; batch adversarial loss: 0.551264\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379811; batch adversarial loss: 0.491419\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431328; batch adversarial loss: 0.552602\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413961; batch adversarial loss: 0.544214\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422140; batch adversarial loss: 0.598051\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403010; batch adversarial loss: 0.514803\n",
      "epoch 56; iter: 0; batch classifier loss: 0.462724; batch adversarial loss: 0.588332\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413905; batch adversarial loss: 0.480025\n",
      "epoch 58; iter: 0; batch classifier loss: 0.479651; batch adversarial loss: 0.508773\n",
      "epoch 59; iter: 0; batch classifier loss: 0.362335; batch adversarial loss: 0.571543\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411458; batch adversarial loss: 0.535255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61; iter: 0; batch classifier loss: 0.446971; batch adversarial loss: 0.620050\n",
      "epoch 62; iter: 0; batch classifier loss: 0.572551; batch adversarial loss: 0.573074\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412861; batch adversarial loss: 0.554166\n",
      "epoch 64; iter: 0; batch classifier loss: 0.433166; batch adversarial loss: 0.570478\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402257; batch adversarial loss: 0.553797\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414986; batch adversarial loss: 0.518374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394920; batch adversarial loss: 0.519502\n",
      "epoch 68; iter: 0; batch classifier loss: 0.444315; batch adversarial loss: 0.490559\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402412; batch adversarial loss: 0.544598\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377153; batch adversarial loss: 0.525823\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373403; batch adversarial loss: 0.618013\n",
      "epoch 72; iter: 0; batch classifier loss: 0.325009; batch adversarial loss: 0.553851\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433863; batch adversarial loss: 0.535521\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372844; batch adversarial loss: 0.526189\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402148; batch adversarial loss: 0.544247\n",
      "epoch 76; iter: 0; batch classifier loss: 0.348892; batch adversarial loss: 0.507752\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427865; batch adversarial loss: 0.553735\n",
      "epoch 78; iter: 0; batch classifier loss: 0.459714; batch adversarial loss: 0.508407\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404141; batch adversarial loss: 0.535487\n",
      "epoch 80; iter: 0; batch classifier loss: 0.359479; batch adversarial loss: 0.599171\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463771; batch adversarial loss: 0.527201\n",
      "epoch 82; iter: 0; batch classifier loss: 0.338892; batch adversarial loss: 0.618265\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364800; batch adversarial loss: 0.507767\n",
      "epoch 84; iter: 0; batch classifier loss: 0.361169; batch adversarial loss: 0.561888\n",
      "epoch 85; iter: 0; batch classifier loss: 0.422764; batch adversarial loss: 0.562420\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386208; batch adversarial loss: 0.599485\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385995; batch adversarial loss: 0.663370\n",
      "epoch 88; iter: 0; batch classifier loss: 0.456596; batch adversarial loss: 0.525967\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374390; batch adversarial loss: 0.516437\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410911; batch adversarial loss: 0.608805\n",
      "epoch 91; iter: 0; batch classifier loss: 0.474759; batch adversarial loss: 0.635256\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394542; batch adversarial loss: 0.553353\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439421; batch adversarial loss: 0.571814\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362922; batch adversarial loss: 0.526700\n",
      "epoch 95; iter: 0; batch classifier loss: 0.320617; batch adversarial loss: 0.590204\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324696; batch adversarial loss: 0.572338\n",
      "epoch 97; iter: 0; batch classifier loss: 0.421670; batch adversarial loss: 0.517167\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389311; batch adversarial loss: 0.508568\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433109; batch adversarial loss: 0.543841\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404896; batch adversarial loss: 0.597204\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421852; batch adversarial loss: 0.508118\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365569; batch adversarial loss: 0.554420\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397917; batch adversarial loss: 0.499725\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395937; batch adversarial loss: 0.623968\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424515; batch adversarial loss: 0.553620\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395436; batch adversarial loss: 0.526593\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393004; batch adversarial loss: 0.516676\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355659; batch adversarial loss: 0.593490\n",
      "epoch 109; iter: 0; batch classifier loss: 0.444884; batch adversarial loss: 0.561292\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399966; batch adversarial loss: 0.543828\n",
      "epoch 111; iter: 0; batch classifier loss: 0.413946; batch adversarial loss: 0.524991\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355503; batch adversarial loss: 0.557420\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380865; batch adversarial loss: 0.585917\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386761; batch adversarial loss: 0.589880\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407522; batch adversarial loss: 0.567027\n",
      "epoch 116; iter: 0; batch classifier loss: 0.352412; batch adversarial loss: 0.508041\n",
      "epoch 117; iter: 0; batch classifier loss: 0.364944; batch adversarial loss: 0.629026\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387103; batch adversarial loss: 0.508715\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352742; batch adversarial loss: 0.553887\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370646; batch adversarial loss: 0.608956\n",
      "epoch 121; iter: 0; batch classifier loss: 0.438939; batch adversarial loss: 0.636470\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335451; batch adversarial loss: 0.534874\n",
      "epoch 123; iter: 0; batch classifier loss: 0.364371; batch adversarial loss: 0.491659\n",
      "epoch 124; iter: 0; batch classifier loss: 0.388903; batch adversarial loss: 0.553108\n",
      "epoch 125; iter: 0; batch classifier loss: 0.462653; batch adversarial loss: 0.443935\n",
      "epoch 126; iter: 0; batch classifier loss: 0.311304; batch adversarial loss: 0.497720\n",
      "epoch 127; iter: 0; batch classifier loss: 0.486580; batch adversarial loss: 0.516558\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395743; batch adversarial loss: 0.553842\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362978; batch adversarial loss: 0.544928\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389235; batch adversarial loss: 0.581940\n",
      "epoch 131; iter: 0; batch classifier loss: 0.378952; batch adversarial loss: 0.553958\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313182; batch adversarial loss: 0.489189\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344585; batch adversarial loss: 0.516748\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349824; batch adversarial loss: 0.525307\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357915; batch adversarial loss: 0.480605\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369572; batch adversarial loss: 0.571711\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416144; batch adversarial loss: 0.499106\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366352; batch adversarial loss: 0.589886\n",
      "epoch 139; iter: 0; batch classifier loss: 0.382158; batch adversarial loss: 0.571995\n",
      "epoch 140; iter: 0; batch classifier loss: 0.436757; batch adversarial loss: 0.571107\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329715; batch adversarial loss: 0.499322\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361430; batch adversarial loss: 0.453371\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331892; batch adversarial loss: 0.607745\n",
      "epoch 144; iter: 0; batch classifier loss: 0.555196; batch adversarial loss: 0.536457\n",
      "epoch 145; iter: 0; batch classifier loss: 0.445810; batch adversarial loss: 0.598910\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380624; batch adversarial loss: 0.571823\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349661; batch adversarial loss: 0.535131\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346418; batch adversarial loss: 0.573130\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346697; batch adversarial loss: 0.534764\n",
      "epoch 150; iter: 0; batch classifier loss: 0.454251; batch adversarial loss: 0.526364\n",
      "epoch 151; iter: 0; batch classifier loss: 0.425032; batch adversarial loss: 0.563434\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378036; batch adversarial loss: 0.508540\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407514; batch adversarial loss: 0.535542\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375056; batch adversarial loss: 0.608931\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352472; batch adversarial loss: 0.507714\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348813; batch adversarial loss: 0.508778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 157; iter: 0; batch classifier loss: 0.312106; batch adversarial loss: 0.545054\n",
      "epoch 158; iter: 0; batch classifier loss: 0.399426; batch adversarial loss: 0.526139\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322055; batch adversarial loss: 0.617165\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364585; batch adversarial loss: 0.517919\n",
      "epoch 161; iter: 0; batch classifier loss: 0.295828; batch adversarial loss: 0.507653\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400181; batch adversarial loss: 0.508201\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357938; batch adversarial loss: 0.517739\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398096; batch adversarial loss: 0.608895\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394378; batch adversarial loss: 0.589763\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377490; batch adversarial loss: 0.499192\n",
      "epoch 167; iter: 0; batch classifier loss: 0.419284; batch adversarial loss: 0.615910\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402756; batch adversarial loss: 0.608777\n",
      "epoch 169; iter: 0; batch classifier loss: 0.420252; batch adversarial loss: 0.606123\n",
      "epoch 170; iter: 0; batch classifier loss: 0.377803; batch adversarial loss: 0.562460\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323678; batch adversarial loss: 0.499756\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345857; batch adversarial loss: 0.544364\n",
      "epoch 173; iter: 0; batch classifier loss: 0.452944; batch adversarial loss: 0.518927\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325617; batch adversarial loss: 0.580221\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325129; batch adversarial loss: 0.534696\n",
      "epoch 176; iter: 0; batch classifier loss: 0.285995; batch adversarial loss: 0.563365\n",
      "epoch 177; iter: 0; batch classifier loss: 0.393832; batch adversarial loss: 0.516009\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332196; batch adversarial loss: 0.480736\n",
      "epoch 179; iter: 0; batch classifier loss: 0.291177; batch adversarial loss: 0.554043\n",
      "epoch 180; iter: 0; batch classifier loss: 0.319393; batch adversarial loss: 0.507795\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331825; batch adversarial loss: 0.508041\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370043; batch adversarial loss: 0.542285\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391020; batch adversarial loss: 0.470157\n",
      "epoch 184; iter: 0; batch classifier loss: 0.403261; batch adversarial loss: 0.536673\n",
      "epoch 185; iter: 0; batch classifier loss: 0.424361; batch adversarial loss: 0.544242\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346011; batch adversarial loss: 0.543768\n",
      "epoch 187; iter: 0; batch classifier loss: 0.449579; batch adversarial loss: 0.535130\n",
      "epoch 188; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.590188\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350762; batch adversarial loss: 0.571039\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400941; batch adversarial loss: 0.586497\n",
      "epoch 191; iter: 0; batch classifier loss: 0.342893; batch adversarial loss: 0.572828\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347295; batch adversarial loss: 0.573138\n",
      "epoch 193; iter: 0; batch classifier loss: 0.394584; batch adversarial loss: 0.507895\n",
      "epoch 194; iter: 0; batch classifier loss: 0.423998; batch adversarial loss: 0.507292\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312571; batch adversarial loss: 0.552790\n",
      "epoch 196; iter: 0; batch classifier loss: 0.393880; batch adversarial loss: 0.535312\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373943; batch adversarial loss: 0.497007\n",
      "epoch 198; iter: 0; batch classifier loss: 0.410575; batch adversarial loss: 0.535795\n",
      "epoch 199; iter: 0; batch classifier loss: 0.265771; batch adversarial loss: 0.570057\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667973; batch adversarial loss: 0.625091\n",
      "epoch 1; iter: 0; batch classifier loss: 0.527636; batch adversarial loss: 0.632515\n",
      "epoch 2; iter: 0; batch classifier loss: 0.554702; batch adversarial loss: 0.640278\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605655; batch adversarial loss: 0.635204\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544653; batch adversarial loss: 0.571489\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553623; batch adversarial loss: 0.620643\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599082; batch adversarial loss: 0.549378\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612147; batch adversarial loss: 0.561681\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516964; batch adversarial loss: 0.659339\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536364; batch adversarial loss: 0.557361\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509442; batch adversarial loss: 0.519648\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548931; batch adversarial loss: 0.559628\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502899; batch adversarial loss: 0.560084\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503998; batch adversarial loss: 0.591358\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437252; batch adversarial loss: 0.524961\n",
      "epoch 15; iter: 0; batch classifier loss: 0.445926; batch adversarial loss: 0.531263\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408092; batch adversarial loss: 0.672690\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435539; batch adversarial loss: 0.572027\n",
      "epoch 18; iter: 0; batch classifier loss: 0.450051; batch adversarial loss: 0.555597\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478786; batch adversarial loss: 0.555791\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503720; batch adversarial loss: 0.526424\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497991; batch adversarial loss: 0.557032\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473644; batch adversarial loss: 0.581990\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466436; batch adversarial loss: 0.550400\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459439; batch adversarial loss: 0.636172\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471774; batch adversarial loss: 0.529586\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428860; batch adversarial loss: 0.509138\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451112; batch adversarial loss: 0.552878\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495571; batch adversarial loss: 0.526232\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490674; batch adversarial loss: 0.634266\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515747; batch adversarial loss: 0.551344\n",
      "epoch 31; iter: 0; batch classifier loss: 0.527372; batch adversarial loss: 0.609763\n",
      "epoch 32; iter: 0; batch classifier loss: 0.501177; batch adversarial loss: 0.535765\n",
      "epoch 33; iter: 0; batch classifier loss: 0.436672; batch adversarial loss: 0.529515\n",
      "epoch 34; iter: 0; batch classifier loss: 0.355410; batch adversarial loss: 0.529334\n",
      "epoch 35; iter: 0; batch classifier loss: 0.564596; batch adversarial loss: 0.555428\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401408; batch adversarial loss: 0.554542\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417408; batch adversarial loss: 0.570778\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480382; batch adversarial loss: 0.527299\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463207; batch adversarial loss: 0.518617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457915; batch adversarial loss: 0.527112\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438954; batch adversarial loss: 0.544843\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470626; batch adversarial loss: 0.517505\n",
      "epoch 43; iter: 0; batch classifier loss: 0.517242; batch adversarial loss: 0.580669\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404479; batch adversarial loss: 0.562946\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423397; batch adversarial loss: 0.553053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423863; batch adversarial loss: 0.552936\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405286; batch adversarial loss: 0.535802\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487082; batch adversarial loss: 0.598222\n",
      "epoch 49; iter: 0; batch classifier loss: 0.378849; batch adversarial loss: 0.544861\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411604; batch adversarial loss: 0.562401\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466633; batch adversarial loss: 0.579834\n",
      "epoch 52; iter: 0; batch classifier loss: 0.364243; batch adversarial loss: 0.560698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.468607; batch adversarial loss: 0.535266\n",
      "epoch 54; iter: 0; batch classifier loss: 0.477240; batch adversarial loss: 0.544537\n",
      "epoch 55; iter: 0; batch classifier loss: 0.497638; batch adversarial loss: 0.628400\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436972; batch adversarial loss: 0.479962\n",
      "epoch 57; iter: 0; batch classifier loss: 0.378149; batch adversarial loss: 0.653826\n",
      "epoch 58; iter: 0; batch classifier loss: 0.366289; batch adversarial loss: 0.627625\n",
      "epoch 59; iter: 0; batch classifier loss: 0.533266; batch adversarial loss: 0.470535\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407166; batch adversarial loss: 0.528706\n",
      "epoch 61; iter: 0; batch classifier loss: 0.367038; batch adversarial loss: 0.535890\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482916; batch adversarial loss: 0.573449\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436339; batch adversarial loss: 0.581218\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410597; batch adversarial loss: 0.506611\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406372; batch adversarial loss: 0.489289\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366011; batch adversarial loss: 0.647327\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386339; batch adversarial loss: 0.580640\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425094; batch adversarial loss: 0.516912\n",
      "epoch 69; iter: 0; batch classifier loss: 0.443781; batch adversarial loss: 0.518347\n",
      "epoch 70; iter: 0; batch classifier loss: 0.489046; batch adversarial loss: 0.571637\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415761; batch adversarial loss: 0.617335\n",
      "epoch 72; iter: 0; batch classifier loss: 0.482568; batch adversarial loss: 0.553446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376763; batch adversarial loss: 0.588492\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399696; batch adversarial loss: 0.572311\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412177; batch adversarial loss: 0.572894\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420930; batch adversarial loss: 0.506254\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412767; batch adversarial loss: 0.497671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429600; batch adversarial loss: 0.516626\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411917; batch adversarial loss: 0.543049\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422655; batch adversarial loss: 0.498353\n",
      "epoch 81; iter: 0; batch classifier loss: 0.448510; batch adversarial loss: 0.644825\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350923; batch adversarial loss: 0.545720\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370393; batch adversarial loss: 0.599517\n",
      "epoch 84; iter: 0; batch classifier loss: 0.471206; batch adversarial loss: 0.515292\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399057; batch adversarial loss: 0.529405\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431533; batch adversarial loss: 0.505584\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411913; batch adversarial loss: 0.546669\n",
      "epoch 88; iter: 0; batch classifier loss: 0.459561; batch adversarial loss: 0.579395\n",
      "epoch 89; iter: 0; batch classifier loss: 0.341630; batch adversarial loss: 0.518078\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370046; batch adversarial loss: 0.584097\n",
      "epoch 91; iter: 0; batch classifier loss: 0.453111; batch adversarial loss: 0.563128\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389182; batch adversarial loss: 0.498089\n",
      "epoch 93; iter: 0; batch classifier loss: 0.401127; batch adversarial loss: 0.504178\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433871; batch adversarial loss: 0.527360\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414991; batch adversarial loss: 0.527261\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407193; batch adversarial loss: 0.638614\n",
      "epoch 97; iter: 0; batch classifier loss: 0.337432; batch adversarial loss: 0.572633\n",
      "epoch 98; iter: 0; batch classifier loss: 0.422655; batch adversarial loss: 0.571448\n",
      "epoch 99; iter: 0; batch classifier loss: 0.496893; batch adversarial loss: 0.487684\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433626; batch adversarial loss: 0.635176\n",
      "epoch 101; iter: 0; batch classifier loss: 0.488125; batch adversarial loss: 0.501687\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400427; batch adversarial loss: 0.636437\n",
      "epoch 103; iter: 0; batch classifier loss: 0.425191; batch adversarial loss: 0.509240\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434138; batch adversarial loss: 0.634293\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359551; batch adversarial loss: 0.600849\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330723; batch adversarial loss: 0.616204\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405947; batch adversarial loss: 0.515689\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401388; batch adversarial loss: 0.553798\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379744; batch adversarial loss: 0.535608\n",
      "epoch 110; iter: 0; batch classifier loss: 0.416585; batch adversarial loss: 0.543206\n",
      "epoch 111; iter: 0; batch classifier loss: 0.319491; batch adversarial loss: 0.555720\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392757; batch adversarial loss: 0.543866\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350081; batch adversarial loss: 0.507912\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364537; batch adversarial loss: 0.627652\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357313; batch adversarial loss: 0.526605\n",
      "epoch 116; iter: 0; batch classifier loss: 0.333787; batch adversarial loss: 0.543860\n",
      "epoch 117; iter: 0; batch classifier loss: 0.343668; batch adversarial loss: 0.586720\n",
      "epoch 118; iter: 0; batch classifier loss: 0.430668; batch adversarial loss: 0.560283\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350669; batch adversarial loss: 0.553234\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372497; batch adversarial loss: 0.607989\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419249; batch adversarial loss: 0.543251\n",
      "epoch 122; iter: 0; batch classifier loss: 0.405004; batch adversarial loss: 0.538771\n",
      "epoch 123; iter: 0; batch classifier loss: 0.491855; batch adversarial loss: 0.525708\n",
      "epoch 124; iter: 0; batch classifier loss: 0.445848; batch adversarial loss: 0.498891\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356301; batch adversarial loss: 0.588243\n",
      "epoch 126; iter: 0; batch classifier loss: 0.318912; batch adversarial loss: 0.573600\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400642; batch adversarial loss: 0.523776\n",
      "epoch 128; iter: 0; batch classifier loss: 0.428384; batch adversarial loss: 0.546021\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358452; batch adversarial loss: 0.489021\n",
      "epoch 130; iter: 0; batch classifier loss: 0.415511; batch adversarial loss: 0.563489\n",
      "epoch 131; iter: 0; batch classifier loss: 0.446262; batch adversarial loss: 0.535273\n",
      "epoch 132; iter: 0; batch classifier loss: 0.383395; batch adversarial loss: 0.571162\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357610; batch adversarial loss: 0.553051\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333188; batch adversarial loss: 0.510542\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385027; batch adversarial loss: 0.506181\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410573; batch adversarial loss: 0.508424\n",
      "epoch 137; iter: 0; batch classifier loss: 0.410523; batch adversarial loss: 0.541575\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383161; batch adversarial loss: 0.581051\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333361; batch adversarial loss: 0.619225\n",
      "epoch 140; iter: 0; batch classifier loss: 0.362165; batch adversarial loss: 0.651242\n",
      "epoch 141; iter: 0; batch classifier loss: 0.378122; batch adversarial loss: 0.459996\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369025; batch adversarial loss: 0.579530\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369943; batch adversarial loss: 0.589977\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366392; batch adversarial loss: 0.579279\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398975; batch adversarial loss: 0.530786\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382201; batch adversarial loss: 0.580117\n",
      "epoch 147; iter: 0; batch classifier loss: 0.454136; batch adversarial loss: 0.552560\n",
      "epoch 148; iter: 0; batch classifier loss: 0.434777; batch adversarial loss: 0.562664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.390070; batch adversarial loss: 0.536965\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350223; batch adversarial loss: 0.508749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384236; batch adversarial loss: 0.525477\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390115; batch adversarial loss: 0.553026\n",
      "epoch 153; iter: 0; batch classifier loss: 0.315857; batch adversarial loss: 0.579787\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346591; batch adversarial loss: 0.580790\n",
      "epoch 155; iter: 0; batch classifier loss: 0.382484; batch adversarial loss: 0.536427\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339642; batch adversarial loss: 0.495556\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368555; batch adversarial loss: 0.503911\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403256; batch adversarial loss: 0.496686\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366470; batch adversarial loss: 0.626984\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340063; batch adversarial loss: 0.533158\n",
      "epoch 161; iter: 0; batch classifier loss: 0.420096; batch adversarial loss: 0.571616\n",
      "epoch 162; iter: 0; batch classifier loss: 0.441017; batch adversarial loss: 0.573871\n",
      "epoch 163; iter: 0; batch classifier loss: 0.415994; batch adversarial loss: 0.535823\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371147; batch adversarial loss: 0.554598\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394531; batch adversarial loss: 0.498370\n",
      "epoch 166; iter: 0; batch classifier loss: 0.455724; batch adversarial loss: 0.482745\n",
      "epoch 167; iter: 0; batch classifier loss: 0.350094; batch adversarial loss: 0.507769\n",
      "epoch 168; iter: 0; batch classifier loss: 0.330537; batch adversarial loss: 0.523258\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345925; batch adversarial loss: 0.499199\n",
      "epoch 170; iter: 0; batch classifier loss: 0.463909; batch adversarial loss: 0.535510\n",
      "epoch 171; iter: 0; batch classifier loss: 0.444285; batch adversarial loss: 0.534263\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344477; batch adversarial loss: 0.461902\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361068; batch adversarial loss: 0.485654\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335561; batch adversarial loss: 0.544568\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368629; batch adversarial loss: 0.500043\n",
      "epoch 176; iter: 0; batch classifier loss: 0.386257; batch adversarial loss: 0.545169\n",
      "epoch 177; iter: 0; batch classifier loss: 0.283167; batch adversarial loss: 0.509035\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337759; batch adversarial loss: 0.534519\n",
      "epoch 179; iter: 0; batch classifier loss: 0.387329; batch adversarial loss: 0.524483\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350378; batch adversarial loss: 0.591543\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337607; batch adversarial loss: 0.516358\n",
      "epoch 182; iter: 0; batch classifier loss: 0.316482; batch adversarial loss: 0.561864\n",
      "epoch 183; iter: 0; batch classifier loss: 0.283032; batch adversarial loss: 0.435588\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367704; batch adversarial loss: 0.651199\n",
      "epoch 185; iter: 0; batch classifier loss: 0.419638; batch adversarial loss: 0.534574\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313512; batch adversarial loss: 0.551032\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370620; batch adversarial loss: 0.544068\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341682; batch adversarial loss: 0.534515\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365070; batch adversarial loss: 0.573334\n",
      "epoch 190; iter: 0; batch classifier loss: 0.388770; batch adversarial loss: 0.535115\n",
      "epoch 191; iter: 0; batch classifier loss: 0.300657; batch adversarial loss: 0.626123\n",
      "epoch 192; iter: 0; batch classifier loss: 0.435722; batch adversarial loss: 0.563263\n",
      "epoch 193; iter: 0; batch classifier loss: 0.374550; batch adversarial loss: 0.588064\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379741; batch adversarial loss: 0.494553\n",
      "epoch 195; iter: 0; batch classifier loss: 0.292175; batch adversarial loss: 0.494050\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394853; batch adversarial loss: 0.526080\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337040; batch adversarial loss: 0.553755\n",
      "epoch 198; iter: 0; batch classifier loss: 0.443371; batch adversarial loss: 0.506537\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323614; batch adversarial loss: 0.527861\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730903; batch adversarial loss: 0.639613\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591450; batch adversarial loss: 0.662348\n",
      "epoch 2; iter: 0; batch classifier loss: 0.564237; batch adversarial loss: 0.703048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605892; batch adversarial loss: 0.687744\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539297; batch adversarial loss: 0.712354\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617969; batch adversarial loss: 0.658979\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598678; batch adversarial loss: 0.600677\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536610; batch adversarial loss: 0.601650\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486749; batch adversarial loss: 0.576254\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553752; batch adversarial loss: 0.585696\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494818; batch adversarial loss: 0.641250\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498244; batch adversarial loss: 0.596531\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556009; batch adversarial loss: 0.544934\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430314; batch adversarial loss: 0.609400\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526504; batch adversarial loss: 0.573144\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493458; batch adversarial loss: 0.551933\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490842; batch adversarial loss: 0.579805\n",
      "epoch 17; iter: 0; batch classifier loss: 0.413758; batch adversarial loss: 0.549113\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504083; batch adversarial loss: 0.587311\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505831; batch adversarial loss: 0.565337\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491406; batch adversarial loss: 0.550343\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544931; batch adversarial loss: 0.555311\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468118; batch adversarial loss: 0.523492\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459181; batch adversarial loss: 0.498377\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547575; batch adversarial loss: 0.602648\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505076; batch adversarial loss: 0.536829\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413267; batch adversarial loss: 0.518825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484664; batch adversarial loss: 0.553363\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422716; batch adversarial loss: 0.474209\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461500; batch adversarial loss: 0.517634\n",
      "epoch 30; iter: 0; batch classifier loss: 0.382366; batch adversarial loss: 0.599985\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506699; batch adversarial loss: 0.447037\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473417; batch adversarial loss: 0.515235\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453580; batch adversarial loss: 0.516391\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485212; batch adversarial loss: 0.614469\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485162; batch adversarial loss: 0.615883\n",
      "epoch 36; iter: 0; batch classifier loss: 0.394360; batch adversarial loss: 0.572153\n",
      "epoch 37; iter: 0; batch classifier loss: 0.580320; batch adversarial loss: 0.615618\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438895; batch adversarial loss: 0.526542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.512179; batch adversarial loss: 0.606639\n",
      "epoch 40; iter: 0; batch classifier loss: 0.476924; batch adversarial loss: 0.563313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421329; batch adversarial loss: 0.570814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449896; batch adversarial loss: 0.552966\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463182; batch adversarial loss: 0.464061\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443017; batch adversarial loss: 0.481808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.456346; batch adversarial loss: 0.543957\n",
      "epoch 46; iter: 0; batch classifier loss: 0.450386; batch adversarial loss: 0.554006\n",
      "epoch 47; iter: 0; batch classifier loss: 0.388269; batch adversarial loss: 0.598204\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424707; batch adversarial loss: 0.643624\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422555; batch adversarial loss: 0.472844\n",
      "epoch 50; iter: 0; batch classifier loss: 0.483250; batch adversarial loss: 0.553627\n",
      "epoch 51; iter: 0; batch classifier loss: 0.491051; batch adversarial loss: 0.544805\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387677; batch adversarial loss: 0.536076\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446138; batch adversarial loss: 0.598110\n",
      "epoch 54; iter: 0; batch classifier loss: 0.436675; batch adversarial loss: 0.598035\n",
      "epoch 55; iter: 0; batch classifier loss: 0.495225; batch adversarial loss: 0.572356\n",
      "epoch 56; iter: 0; batch classifier loss: 0.379562; batch adversarial loss: 0.660640\n",
      "epoch 57; iter: 0; batch classifier loss: 0.481863; batch adversarial loss: 0.598169\n",
      "epoch 58; iter: 0; batch classifier loss: 0.364889; batch adversarial loss: 0.588682\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407371; batch adversarial loss: 0.564128\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391660; batch adversarial loss: 0.527580\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422317; batch adversarial loss: 0.562768\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448447; batch adversarial loss: 0.505384\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403384; batch adversarial loss: 0.519898\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375876; batch adversarial loss: 0.608168\n",
      "epoch 65; iter: 0; batch classifier loss: 0.620046; batch adversarial loss: 0.553060\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423676; batch adversarial loss: 0.535144\n",
      "epoch 67; iter: 0; batch classifier loss: 0.471334; batch adversarial loss: 0.561024\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403227; batch adversarial loss: 0.525547\n",
      "epoch 69; iter: 0; batch classifier loss: 0.471125; batch adversarial loss: 0.560646\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451295; batch adversarial loss: 0.536947\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429282; batch adversarial loss: 0.535169\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374994; batch adversarial loss: 0.526022\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427022; batch adversarial loss: 0.552822\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448583; batch adversarial loss: 0.563078\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379520; batch adversarial loss: 0.525972\n",
      "epoch 76; iter: 0; batch classifier loss: 0.481917; batch adversarial loss: 0.544719\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411535; batch adversarial loss: 0.544069\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447903; batch adversarial loss: 0.589473\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420044; batch adversarial loss: 0.571750\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411531; batch adversarial loss: 0.499632\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421699; batch adversarial loss: 0.526787\n",
      "epoch 82; iter: 0; batch classifier loss: 0.468879; batch adversarial loss: 0.544432\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349745; batch adversarial loss: 0.426551\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356684; batch adversarial loss: 0.526364\n",
      "epoch 85; iter: 0; batch classifier loss: 0.446137; batch adversarial loss: 0.517579\n",
      "epoch 86; iter: 0; batch classifier loss: 0.479750; batch adversarial loss: 0.543911\n",
      "epoch 87; iter: 0; batch classifier loss: 0.449251; batch adversarial loss: 0.571384\n",
      "epoch 88; iter: 0; batch classifier loss: 0.329966; batch adversarial loss: 0.599004\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339249; batch adversarial loss: 0.608563\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427653; batch adversarial loss: 0.535012\n",
      "epoch 91; iter: 0; batch classifier loss: 0.470444; batch adversarial loss: 0.490325\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382972; batch adversarial loss: 0.553661\n",
      "epoch 93; iter: 0; batch classifier loss: 0.406137; batch adversarial loss: 0.589323\n",
      "epoch 94; iter: 0; batch classifier loss: 0.428773; batch adversarial loss: 0.617099\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415662; batch adversarial loss: 0.589570\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346257; batch adversarial loss: 0.544853\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387534; batch adversarial loss: 0.580413\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354976; batch adversarial loss: 0.562262\n",
      "epoch 99; iter: 0; batch classifier loss: 0.421053; batch adversarial loss: 0.553871\n",
      "epoch 100; iter: 0; batch classifier loss: 0.342876; batch adversarial loss: 0.535477\n",
      "epoch 101; iter: 0; batch classifier loss: 0.452740; batch adversarial loss: 0.625723\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355832; batch adversarial loss: 0.625856\n",
      "epoch 103; iter: 0; batch classifier loss: 0.393524; batch adversarial loss: 0.525960\n",
      "epoch 104; iter: 0; batch classifier loss: 0.327524; batch adversarial loss: 0.598501\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374947; batch adversarial loss: 0.589593\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408238; batch adversarial loss: 0.571255\n",
      "epoch 107; iter: 0; batch classifier loss: 0.409567; batch adversarial loss: 0.643193\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378400; batch adversarial loss: 0.490346\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415116; batch adversarial loss: 0.554416\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379076; batch adversarial loss: 0.554641\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388899; batch adversarial loss: 0.580394\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397879; batch adversarial loss: 0.580601\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391775; batch adversarial loss: 0.536547\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368166; batch adversarial loss: 0.526691\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367134; batch adversarial loss: 0.589610\n",
      "epoch 116; iter: 0; batch classifier loss: 0.408485; batch adversarial loss: 0.499706\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379451; batch adversarial loss: 0.482023\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342066; batch adversarial loss: 0.553821\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340095; batch adversarial loss: 0.526445\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349882; batch adversarial loss: 0.562608\n",
      "epoch 121; iter: 0; batch classifier loss: 0.461746; batch adversarial loss: 0.553886\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402758; batch adversarial loss: 0.535310\n",
      "epoch 123; iter: 0; batch classifier loss: 0.383027; batch adversarial loss: 0.616690\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403615; batch adversarial loss: 0.616776\n",
      "epoch 125; iter: 0; batch classifier loss: 0.320903; batch adversarial loss: 0.563091\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373638; batch adversarial loss: 0.526575\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377112; batch adversarial loss: 0.571255\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334758; batch adversarial loss: 0.570770\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325806; batch adversarial loss: 0.535451\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380875; batch adversarial loss: 0.580937\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347546; batch adversarial loss: 0.553311\n",
      "epoch 132; iter: 0; batch classifier loss: 0.441826; batch adversarial loss: 0.580740\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375880; batch adversarial loss: 0.553800\n",
      "epoch 134; iter: 0; batch classifier loss: 0.409811; batch adversarial loss: 0.490134\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413807; batch adversarial loss: 0.525657\n",
      "epoch 136; iter: 0; batch classifier loss: 0.433414; batch adversarial loss: 0.535532\n",
      "epoch 137; iter: 0; batch classifier loss: 0.324761; batch adversarial loss: 0.580985\n",
      "epoch 138; iter: 0; batch classifier loss: 0.396131; batch adversarial loss: 0.616610\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374857; batch adversarial loss: 0.481249\n",
      "epoch 140; iter: 0; batch classifier loss: 0.370157; batch adversarial loss: 0.516671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.427316; batch adversarial loss: 0.536027\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321924; batch adversarial loss: 0.571731\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364386; batch adversarial loss: 0.554303\n",
      "epoch 144; iter: 0; batch classifier loss: 0.410315; batch adversarial loss: 0.562210\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424001; batch adversarial loss: 0.562329\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368288; batch adversarial loss: 0.562661\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404631; batch adversarial loss: 0.571770\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312619; batch adversarial loss: 0.526751\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417608; batch adversarial loss: 0.535233\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355814; batch adversarial loss: 0.508442\n",
      "epoch 151; iter: 0; batch classifier loss: 0.438041; batch adversarial loss: 0.571280\n",
      "epoch 152; iter: 0; batch classifier loss: 0.367719; batch adversarial loss: 0.554177\n",
      "epoch 153; iter: 0; batch classifier loss: 0.417955; batch adversarial loss: 0.562700\n",
      "epoch 154; iter: 0; batch classifier loss: 0.409785; batch adversarial loss: 0.570948\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413079; batch adversarial loss: 0.518238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336470; batch adversarial loss: 0.588936\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382382; batch adversarial loss: 0.545473\n",
      "epoch 158; iter: 0; batch classifier loss: 0.442050; batch adversarial loss: 0.508436\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407053; batch adversarial loss: 0.625967\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333037; batch adversarial loss: 0.562736\n",
      "epoch 161; iter: 0; batch classifier loss: 0.306154; batch adversarial loss: 0.499385\n",
      "epoch 162; iter: 0; batch classifier loss: 0.317809; batch adversarial loss: 0.562574\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374774; batch adversarial loss: 0.582013\n",
      "epoch 164; iter: 0; batch classifier loss: 0.319057; batch adversarial loss: 0.636565\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372130; batch adversarial loss: 0.517043\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374392; batch adversarial loss: 0.589913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342029; batch adversarial loss: 0.598706\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367973; batch adversarial loss: 0.572060\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350539; batch adversarial loss: 0.597934\n",
      "epoch 170; iter: 0; batch classifier loss: 0.399635; batch adversarial loss: 0.581893\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401002; batch adversarial loss: 0.526442\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348390; batch adversarial loss: 0.616343\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344257; batch adversarial loss: 0.517837\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360536; batch adversarial loss: 0.526471\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337559; batch adversarial loss: 0.571576\n",
      "epoch 176; iter: 0; batch classifier loss: 0.399440; batch adversarial loss: 0.552856\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314559; batch adversarial loss: 0.580695\n",
      "epoch 178; iter: 0; batch classifier loss: 0.308055; batch adversarial loss: 0.508451\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306399; batch adversarial loss: 0.536526\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366370; batch adversarial loss: 0.589912\n",
      "epoch 181; iter: 0; batch classifier loss: 0.426157; batch adversarial loss: 0.581353\n",
      "epoch 182; iter: 0; batch classifier loss: 0.436881; batch adversarial loss: 0.490146\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362942; batch adversarial loss: 0.589157\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359903; batch adversarial loss: 0.454722\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391766; batch adversarial loss: 0.571124\n",
      "epoch 186; iter: 0; batch classifier loss: 0.329005; batch adversarial loss: 0.581929\n",
      "epoch 187; iter: 0; batch classifier loss: 0.337108; batch adversarial loss: 0.572816\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423328; batch adversarial loss: 0.589517\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295748; batch adversarial loss: 0.598012\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360540; batch adversarial loss: 0.445925\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299339; batch adversarial loss: 0.544126\n",
      "epoch 192; iter: 0; batch classifier loss: 0.410386; batch adversarial loss: 0.544274\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326173; batch adversarial loss: 0.580247\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321416; batch adversarial loss: 0.544639\n",
      "epoch 195; iter: 0; batch classifier loss: 0.385663; batch adversarial loss: 0.571411\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369726; batch adversarial loss: 0.526332\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275216; batch adversarial loss: 0.552970\n",
      "epoch 198; iter: 0; batch classifier loss: 0.412940; batch adversarial loss: 0.590059\n",
      "epoch 199; iter: 0; batch classifier loss: 0.263888; batch adversarial loss: 0.518091\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692854; batch adversarial loss: 0.735277\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590655; batch adversarial loss: 0.696047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565993; batch adversarial loss: 0.676822\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556620; batch adversarial loss: 0.647876\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580285; batch adversarial loss: 0.616684\n",
      "epoch 5; iter: 0; batch classifier loss: 0.491369; batch adversarial loss: 0.615742\n",
      "epoch 6; iter: 0; batch classifier loss: 0.650801; batch adversarial loss: 0.562476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549548; batch adversarial loss: 0.599424\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486122; batch adversarial loss: 0.613023\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507658; batch adversarial loss: 0.611294\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580159; batch adversarial loss: 0.592841\n",
      "epoch 11; iter: 0; batch classifier loss: 0.474481; batch adversarial loss: 0.556614\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562645; batch adversarial loss: 0.579855\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488689; batch adversarial loss: 0.504908\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505725; batch adversarial loss: 0.615042\n",
      "epoch 15; iter: 0; batch classifier loss: 0.559770; batch adversarial loss: 0.581207\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517526; batch adversarial loss: 0.552430\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474917; batch adversarial loss: 0.634787\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525750; batch adversarial loss: 0.637439\n",
      "epoch 19; iter: 0; batch classifier loss: 0.547493; batch adversarial loss: 0.582285\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503912; batch adversarial loss: 0.557266\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476956; batch adversarial loss: 0.567458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535889; batch adversarial loss: 0.592693\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525381; batch adversarial loss: 0.537969\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455966; batch adversarial loss: 0.587029\n",
      "epoch 25; iter: 0; batch classifier loss: 0.408367; batch adversarial loss: 0.516281\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520788; batch adversarial loss: 0.605028\n",
      "epoch 27; iter: 0; batch classifier loss: 0.519870; batch adversarial loss: 0.552674\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454214; batch adversarial loss: 0.579536\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489019; batch adversarial loss: 0.527984\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445219; batch adversarial loss: 0.537338\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523972; batch adversarial loss: 0.532311\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504944; batch adversarial loss: 0.603483\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457066; batch adversarial loss: 0.519841\n",
      "epoch 34; iter: 0; batch classifier loss: 0.531300; batch adversarial loss: 0.544809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455967; batch adversarial loss: 0.498752\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467614; batch adversarial loss: 0.540806\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472985; batch adversarial loss: 0.634812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.414374; batch adversarial loss: 0.526772\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431327; batch adversarial loss: 0.553992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464133; batch adversarial loss: 0.555938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443694; batch adversarial loss: 0.551010\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483643; batch adversarial loss: 0.528419\n",
      "epoch 43; iter: 0; batch classifier loss: 0.387622; batch adversarial loss: 0.590559\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366952; batch adversarial loss: 0.571514\n",
      "epoch 45; iter: 0; batch classifier loss: 0.346988; batch adversarial loss: 0.516231\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462870; batch adversarial loss: 0.603660\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398130; batch adversarial loss: 0.507862\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418782; batch adversarial loss: 0.502615\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397054; batch adversarial loss: 0.540780\n",
      "epoch 50; iter: 0; batch classifier loss: 0.364630; batch adversarial loss: 0.544629\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428451; batch adversarial loss: 0.590753\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456914; batch adversarial loss: 0.544445\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430315; batch adversarial loss: 0.561271\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418923; batch adversarial loss: 0.565251\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416577; batch adversarial loss: 0.540478\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383350; batch adversarial loss: 0.532652\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450333; batch adversarial loss: 0.537553\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416607; batch adversarial loss: 0.531958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409781; batch adversarial loss: 0.581930\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417443; batch adversarial loss: 0.563372\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397476; batch adversarial loss: 0.533618\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386888; batch adversarial loss: 0.571310\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433481; batch adversarial loss: 0.527357\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408702; batch adversarial loss: 0.510909\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387481; batch adversarial loss: 0.540855\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378764; batch adversarial loss: 0.566979\n",
      "epoch 67; iter: 0; batch classifier loss: 0.450878; batch adversarial loss: 0.572246\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413745; batch adversarial loss: 0.581410\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457049; batch adversarial loss: 0.537176\n",
      "epoch 70; iter: 0; batch classifier loss: 0.448677; batch adversarial loss: 0.632773\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403176; batch adversarial loss: 0.600482\n",
      "epoch 72; iter: 0; batch classifier loss: 0.348102; batch adversarial loss: 0.508587\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389754; batch adversarial loss: 0.547243\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391239; batch adversarial loss: 0.562312\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405335; batch adversarial loss: 0.568890\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421023; batch adversarial loss: 0.553032\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393562; batch adversarial loss: 0.563757\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440497; batch adversarial loss: 0.551624\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368768; batch adversarial loss: 0.544905\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410874; batch adversarial loss: 0.499122\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394285; batch adversarial loss: 0.584705\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410452; batch adversarial loss: 0.641513\n",
      "epoch 83; iter: 0; batch classifier loss: 0.436027; batch adversarial loss: 0.516416\n",
      "epoch 84; iter: 0; batch classifier loss: 0.450640; batch adversarial loss: 0.617477\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412008; batch adversarial loss: 0.525429\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435976; batch adversarial loss: 0.524482\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410582; batch adversarial loss: 0.598459\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.591189\n",
      "epoch 89; iter: 0; batch classifier loss: 0.347044; batch adversarial loss: 0.481340\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393007; batch adversarial loss: 0.545310\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432306; batch adversarial loss: 0.525973\n",
      "epoch 92; iter: 0; batch classifier loss: 0.296976; batch adversarial loss: 0.542396\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385448; batch adversarial loss: 0.510414\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410122; batch adversarial loss: 0.588147\n",
      "epoch 95; iter: 0; batch classifier loss: 0.421982; batch adversarial loss: 0.552162\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371774; batch adversarial loss: 0.491321\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402906; batch adversarial loss: 0.452539\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385999; batch adversarial loss: 0.481078\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401802; batch adversarial loss: 0.525307\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352802; batch adversarial loss: 0.597452\n",
      "epoch 101; iter: 0; batch classifier loss: 0.332474; batch adversarial loss: 0.526259\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426239; batch adversarial loss: 0.498975\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404142; batch adversarial loss: 0.500264\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350239; batch adversarial loss: 0.547568\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339451; batch adversarial loss: 0.588851\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443395; batch adversarial loss: 0.497165\n",
      "epoch 107; iter: 0; batch classifier loss: 0.376363; batch adversarial loss: 0.553694\n",
      "epoch 108; iter: 0; batch classifier loss: 0.446517; batch adversarial loss: 0.517008\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372884; batch adversarial loss: 0.518543\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362736; batch adversarial loss: 0.597896\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409997; batch adversarial loss: 0.500258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.345894; batch adversarial loss: 0.573475\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396868; batch adversarial loss: 0.589116\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372293; batch adversarial loss: 0.565975\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386733; batch adversarial loss: 0.472800\n",
      "epoch 116; iter: 0; batch classifier loss: 0.342214; batch adversarial loss: 0.618330\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350178; batch adversarial loss: 0.553288\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377586; batch adversarial loss: 0.579326\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396076; batch adversarial loss: 0.519343\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399263; batch adversarial loss: 0.555490\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388595; batch adversarial loss: 0.553322\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378222; batch adversarial loss: 0.526677\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353291; batch adversarial loss: 0.509047\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374633; batch adversarial loss: 0.617802\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382418; batch adversarial loss: 0.490452\n",
      "epoch 126; iter: 0; batch classifier loss: 0.415499; batch adversarial loss: 0.559715\n",
      "epoch 127; iter: 0; batch classifier loss: 0.332379; batch adversarial loss: 0.517585\n",
      "epoch 128; iter: 0; batch classifier loss: 0.359382; batch adversarial loss: 0.561952\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395670; batch adversarial loss: 0.552811\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358913; batch adversarial loss: 0.507794\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391142; batch adversarial loss: 0.525095\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400464; batch adversarial loss: 0.517478\n",
      "epoch 133; iter: 0; batch classifier loss: 0.409494; batch adversarial loss: 0.444788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.402117; batch adversarial loss: 0.480208\n",
      "epoch 135; iter: 0; batch classifier loss: 0.425198; batch adversarial loss: 0.627221\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356694; batch adversarial loss: 0.561077\n",
      "epoch 137; iter: 0; batch classifier loss: 0.406121; batch adversarial loss: 0.478691\n",
      "epoch 138; iter: 0; batch classifier loss: 0.337018; batch adversarial loss: 0.623786\n",
      "epoch 139; iter: 0; batch classifier loss: 0.370328; batch adversarial loss: 0.554803\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333230; batch adversarial loss: 0.549838\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404317; batch adversarial loss: 0.507168\n",
      "epoch 142; iter: 0; batch classifier loss: 0.296092; batch adversarial loss: 0.470552\n",
      "epoch 143; iter: 0; batch classifier loss: 0.448658; batch adversarial loss: 0.498853\n",
      "epoch 144; iter: 0; batch classifier loss: 0.355374; batch adversarial loss: 0.478273\n",
      "epoch 145; iter: 0; batch classifier loss: 0.425450; batch adversarial loss: 0.491268\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329864; batch adversarial loss: 0.587842\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317781; batch adversarial loss: 0.519273\n",
      "epoch 148; iter: 0; batch classifier loss: 0.441532; batch adversarial loss: 0.572508\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376112; batch adversarial loss: 0.625401\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376973; batch adversarial loss: 0.533743\n",
      "epoch 151; iter: 0; batch classifier loss: 0.430708; batch adversarial loss: 0.516011\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389722; batch adversarial loss: 0.552667\n",
      "epoch 153; iter: 0; batch classifier loss: 0.426245; batch adversarial loss: 0.571012\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335212; batch adversarial loss: 0.452414\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341608; batch adversarial loss: 0.609001\n",
      "epoch 156; iter: 0; batch classifier loss: 0.315032; batch adversarial loss: 0.482305\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379235; batch adversarial loss: 0.561486\n",
      "epoch 158; iter: 0; batch classifier loss: 0.294513; batch adversarial loss: 0.572215\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362227; batch adversarial loss: 0.589860\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384303; batch adversarial loss: 0.582223\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388901; batch adversarial loss: 0.554989\n",
      "epoch 162; iter: 0; batch classifier loss: 0.396855; batch adversarial loss: 0.553581\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348591; batch adversarial loss: 0.610229\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366307; batch adversarial loss: 0.561162\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334593; batch adversarial loss: 0.596779\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329095; batch adversarial loss: 0.572502\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348608; batch adversarial loss: 0.507542\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392771; batch adversarial loss: 0.498113\n",
      "epoch 169; iter: 0; batch classifier loss: 0.399433; batch adversarial loss: 0.571820\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355202; batch adversarial loss: 0.671839\n",
      "epoch 171; iter: 0; batch classifier loss: 0.412883; batch adversarial loss: 0.525988\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350325; batch adversarial loss: 0.516972\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362660; batch adversarial loss: 0.571299\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347896; batch adversarial loss: 0.553012\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382346; batch adversarial loss: 0.571864\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379306; batch adversarial loss: 0.560353\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356689; batch adversarial loss: 0.525936\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370869; batch adversarial loss: 0.564018\n",
      "epoch 179; iter: 0; batch classifier loss: 0.441539; batch adversarial loss: 0.555077\n",
      "epoch 180; iter: 0; batch classifier loss: 0.310413; batch adversarial loss: 0.550377\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423345; batch adversarial loss: 0.589145\n",
      "epoch 182; iter: 0; batch classifier loss: 0.395791; batch adversarial loss: 0.533702\n",
      "epoch 183; iter: 0; batch classifier loss: 0.436621; batch adversarial loss: 0.554683\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335247; batch adversarial loss: 0.583392\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356776; batch adversarial loss: 0.509352\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399457; batch adversarial loss: 0.552543\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315260; batch adversarial loss: 0.580917\n",
      "epoch 188; iter: 0; batch classifier loss: 0.289574; batch adversarial loss: 0.579150\n",
      "epoch 189; iter: 0; batch classifier loss: 0.374760; batch adversarial loss: 0.463879\n",
      "epoch 190; iter: 0; batch classifier loss: 0.459185; batch adversarial loss: 0.561240\n",
      "epoch 191; iter: 0; batch classifier loss: 0.423978; batch adversarial loss: 0.507537\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327998; batch adversarial loss: 0.461020\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349634; batch adversarial loss: 0.590344\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313469; batch adversarial loss: 0.572375\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384449; batch adversarial loss: 0.583400\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343919; batch adversarial loss: 0.508662\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348375; batch adversarial loss: 0.591780\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328629; batch adversarial loss: 0.572316\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385454; batch adversarial loss: 0.524485\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704230; batch adversarial loss: 0.631579\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595389; batch adversarial loss: 0.650493\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605885; batch adversarial loss: 0.620264\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572734; batch adversarial loss: 0.614357\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523264; batch adversarial loss: 0.617336\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518982; batch adversarial loss: 0.621753\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561271; batch adversarial loss: 0.640870\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582097; batch adversarial loss: 0.615595\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611985; batch adversarial loss: 0.576370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573411; batch adversarial loss: 0.604460\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559241; batch adversarial loss: 0.550995\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540851; batch adversarial loss: 0.592010\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509323; batch adversarial loss: 0.600244\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533257; batch adversarial loss: 0.602072\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569142; batch adversarial loss: 0.593653\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454514; batch adversarial loss: 0.617580\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522841; batch adversarial loss: 0.522157\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508426; batch adversarial loss: 0.600850\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508124; batch adversarial loss: 0.500207\n",
      "epoch 19; iter: 0; batch classifier loss: 0.553058; batch adversarial loss: 0.573587\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500458; batch adversarial loss: 0.576309\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468146; batch adversarial loss: 0.556464\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474232; batch adversarial loss: 0.549001\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480503; batch adversarial loss: 0.614781\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440270; batch adversarial loss: 0.496274\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451164; batch adversarial loss: 0.597299\n",
      "epoch 26; iter: 0; batch classifier loss: 0.544156; batch adversarial loss: 0.581282\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464634; batch adversarial loss: 0.545119\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485872; batch adversarial loss: 0.529140\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520475; batch adversarial loss: 0.520227\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448873; batch adversarial loss: 0.579556\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453347; batch adversarial loss: 0.579994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.381406; batch adversarial loss: 0.439139\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504979; batch adversarial loss: 0.570258\n",
      "epoch 34; iter: 0; batch classifier loss: 0.396277; batch adversarial loss: 0.580575\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436881; batch adversarial loss: 0.472614\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440701; batch adversarial loss: 0.581187\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395845; batch adversarial loss: 0.516434\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406372; batch adversarial loss: 0.518171\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438378; batch adversarial loss: 0.570598\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428591; batch adversarial loss: 0.570945\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378351; batch adversarial loss: 0.572431\n",
      "epoch 42; iter: 0; batch classifier loss: 0.514655; batch adversarial loss: 0.551695\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407934; batch adversarial loss: 0.588687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412437; batch adversarial loss: 0.524939\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481070; batch adversarial loss: 0.542946\n",
      "epoch 46; iter: 0; batch classifier loss: 0.472563; batch adversarial loss: 0.554517\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422870; batch adversarial loss: 0.525549\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402060; batch adversarial loss: 0.617561\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473788; batch adversarial loss: 0.589032\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460763; batch adversarial loss: 0.553768\n",
      "epoch 51; iter: 0; batch classifier loss: 0.474496; batch adversarial loss: 0.580397\n",
      "epoch 52; iter: 0; batch classifier loss: 0.484035; batch adversarial loss: 0.451664\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395445; batch adversarial loss: 0.478474\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419793; batch adversarial loss: 0.507372\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480890; batch adversarial loss: 0.544588\n",
      "epoch 56; iter: 0; batch classifier loss: 0.469419; batch adversarial loss: 0.552932\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430468; batch adversarial loss: 0.571139\n",
      "epoch 58; iter: 0; batch classifier loss: 0.496471; batch adversarial loss: 0.518426\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447786; batch adversarial loss: 0.562129\n",
      "epoch 60; iter: 0; batch classifier loss: 0.378492; batch adversarial loss: 0.581925\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418680; batch adversarial loss: 0.542249\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465782; batch adversarial loss: 0.626861\n",
      "epoch 63; iter: 0; batch classifier loss: 0.476714; batch adversarial loss: 0.544791\n",
      "epoch 64; iter: 0; batch classifier loss: 0.399543; batch adversarial loss: 0.525916\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412841; batch adversarial loss: 0.573054\n",
      "epoch 66; iter: 0; batch classifier loss: 0.349411; batch adversarial loss: 0.545549\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394681; batch adversarial loss: 0.488059\n",
      "epoch 68; iter: 0; batch classifier loss: 0.343780; batch adversarial loss: 0.578864\n",
      "epoch 69; iter: 0; batch classifier loss: 0.367984; batch adversarial loss: 0.504408\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400818; batch adversarial loss: 0.549870\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378100; batch adversarial loss: 0.553101\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398331; batch adversarial loss: 0.581054\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440632; batch adversarial loss: 0.532339\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380250; batch adversarial loss: 0.505596\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378183; batch adversarial loss: 0.506831\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378301; batch adversarial loss: 0.523186\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410305; batch adversarial loss: 0.516093\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386006; batch adversarial loss: 0.609538\n",
      "epoch 79; iter: 0; batch classifier loss: 0.447853; batch adversarial loss: 0.590107\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392426; batch adversarial loss: 0.553120\n",
      "epoch 81; iter: 0; batch classifier loss: 0.330610; batch adversarial loss: 0.580624\n",
      "epoch 82; iter: 0; batch classifier loss: 0.458560; batch adversarial loss: 0.534165\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409953; batch adversarial loss: 0.571081\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382355; batch adversarial loss: 0.550101\n",
      "epoch 85; iter: 0; batch classifier loss: 0.303810; batch adversarial loss: 0.524234\n",
      "epoch 86; iter: 0; batch classifier loss: 0.361445; batch adversarial loss: 0.562335\n",
      "epoch 87; iter: 0; batch classifier loss: 0.424169; batch adversarial loss: 0.545529\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417132; batch adversarial loss: 0.597807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365698; batch adversarial loss: 0.542444\n",
      "epoch 90; iter: 0; batch classifier loss: 0.357127; batch adversarial loss: 0.544064\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434886; batch adversarial loss: 0.552369\n",
      "epoch 92; iter: 0; batch classifier loss: 0.430154; batch adversarial loss: 0.588028\n",
      "epoch 93; iter: 0; batch classifier loss: 0.460403; batch adversarial loss: 0.498685\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423092; batch adversarial loss: 0.499700\n",
      "epoch 95; iter: 0; batch classifier loss: 0.523310; batch adversarial loss: 0.598479\n",
      "epoch 96; iter: 0; batch classifier loss: 0.379513; batch adversarial loss: 0.526380\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350615; batch adversarial loss: 0.480099\n",
      "epoch 98; iter: 0; batch classifier loss: 0.471528; batch adversarial loss: 0.462147\n",
      "epoch 99; iter: 0; batch classifier loss: 0.411439; batch adversarial loss: 0.489669\n",
      "epoch 100; iter: 0; batch classifier loss: 0.440404; batch adversarial loss: 0.618109\n",
      "epoch 101; iter: 0; batch classifier loss: 0.297043; batch adversarial loss: 0.509009\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369801; batch adversarial loss: 0.589652\n",
      "epoch 103; iter: 0; batch classifier loss: 0.424525; batch adversarial loss: 0.560898\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348161; batch adversarial loss: 0.543120\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390147; batch adversarial loss: 0.558787\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419772; batch adversarial loss: 0.505247\n",
      "epoch 107; iter: 0; batch classifier loss: 0.425192; batch adversarial loss: 0.551346\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399110; batch adversarial loss: 0.571112\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368581; batch adversarial loss: 0.550771\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334723; batch adversarial loss: 0.520258\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409616; batch adversarial loss: 0.608589\n",
      "epoch 112; iter: 0; batch classifier loss: 0.436114; batch adversarial loss: 0.480613\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377843; batch adversarial loss: 0.636563\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394911; batch adversarial loss: 0.560870\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355481; batch adversarial loss: 0.570615\n",
      "epoch 116; iter: 0; batch classifier loss: 0.322057; batch adversarial loss: 0.498047\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354760; batch adversarial loss: 0.500178\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398750; batch adversarial loss: 0.546639\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376835; batch adversarial loss: 0.472783\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420486; batch adversarial loss: 0.525164\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396054; batch adversarial loss: 0.563294\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352173; batch adversarial loss: 0.562433\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381405; batch adversarial loss: 0.551299\n",
      "epoch 124; iter: 0; batch classifier loss: 0.470157; batch adversarial loss: 0.506371\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343952; batch adversarial loss: 0.526241\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395356; batch adversarial loss: 0.567891\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415164; batch adversarial loss: 0.543887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361043; batch adversarial loss: 0.597936\n",
      "epoch 129; iter: 0; batch classifier loss: 0.429194; batch adversarial loss: 0.482489\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355325; batch adversarial loss: 0.544518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.371836; batch adversarial loss: 0.586725\n",
      "epoch 132; iter: 0; batch classifier loss: 0.362020; batch adversarial loss: 0.533576\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379765; batch adversarial loss: 0.515986\n",
      "epoch 134; iter: 0; batch classifier loss: 0.398407; batch adversarial loss: 0.570960\n",
      "epoch 135; iter: 0; batch classifier loss: 0.455960; batch adversarial loss: 0.552803\n",
      "epoch 136; iter: 0; batch classifier loss: 0.407472; batch adversarial loss: 0.469425\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359290; batch adversarial loss: 0.586099\n",
      "epoch 138; iter: 0; batch classifier loss: 0.288399; batch adversarial loss: 0.578707\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390637; batch adversarial loss: 0.581299\n",
      "epoch 140; iter: 0; batch classifier loss: 0.426318; batch adversarial loss: 0.507422\n",
      "epoch 141; iter: 0; batch classifier loss: 0.449929; batch adversarial loss: 0.480161\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396152; batch adversarial loss: 0.553207\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390870; batch adversarial loss: 0.532942\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381365; batch adversarial loss: 0.553729\n",
      "epoch 145; iter: 0; batch classifier loss: 0.354909; batch adversarial loss: 0.508913\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374974; batch adversarial loss: 0.609233\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334813; batch adversarial loss: 0.514535\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360976; batch adversarial loss: 0.527915\n",
      "epoch 149; iter: 0; batch classifier loss: 0.372029; batch adversarial loss: 0.568828\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396167; batch adversarial loss: 0.565072\n",
      "epoch 151; iter: 0; batch classifier loss: 0.431228; batch adversarial loss: 0.526842\n",
      "epoch 152; iter: 0; batch classifier loss: 0.361928; batch adversarial loss: 0.507327\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388478; batch adversarial loss: 0.588432\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340905; batch adversarial loss: 0.662457\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365539; batch adversarial loss: 0.562145\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381865; batch adversarial loss: 0.524849\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349791; batch adversarial loss: 0.545506\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380715; batch adversarial loss: 0.506422\n",
      "epoch 159; iter: 0; batch classifier loss: 0.458492; batch adversarial loss: 0.543290\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390179; batch adversarial loss: 0.583216\n",
      "epoch 161; iter: 0; batch classifier loss: 0.394107; batch adversarial loss: 0.509290\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376899; batch adversarial loss: 0.600361\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330184; batch adversarial loss: 0.578909\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322910; batch adversarial loss: 0.599486\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382723; batch adversarial loss: 0.471732\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310682; batch adversarial loss: 0.506771\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406970; batch adversarial loss: 0.479604\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358426; batch adversarial loss: 0.498651\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326197; batch adversarial loss: 0.536332\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352632; batch adversarial loss: 0.517443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.438863; batch adversarial loss: 0.533076\n",
      "epoch 172; iter: 0; batch classifier loss: 0.423277; batch adversarial loss: 0.541880\n",
      "epoch 173; iter: 0; batch classifier loss: 0.462938; batch adversarial loss: 0.552913\n",
      "epoch 174; iter: 0; batch classifier loss: 0.401397; batch adversarial loss: 0.498952\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340092; batch adversarial loss: 0.561006\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347935; batch adversarial loss: 0.561845\n",
      "epoch 177; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.607682\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395939; batch adversarial loss: 0.579080\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337034; batch adversarial loss: 0.580490\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328680; batch adversarial loss: 0.558769\n",
      "epoch 181; iter: 0; batch classifier loss: 0.416334; batch adversarial loss: 0.515934\n",
      "epoch 182; iter: 0; batch classifier loss: 0.420840; batch adversarial loss: 0.534068\n",
      "epoch 183; iter: 0; batch classifier loss: 0.408163; batch adversarial loss: 0.589313\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332472; batch adversarial loss: 0.518465\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375673; batch adversarial loss: 0.534405\n",
      "epoch 186; iter: 0; batch classifier loss: 0.402154; batch adversarial loss: 0.490113\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388754; batch adversarial loss: 0.528700\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375387; batch adversarial loss: 0.526251\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345219; batch adversarial loss: 0.519459\n",
      "epoch 190; iter: 0; batch classifier loss: 0.405659; batch adversarial loss: 0.580795\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363275; batch adversarial loss: 0.548927\n",
      "epoch 192; iter: 0; batch classifier loss: 0.427144; batch adversarial loss: 0.535956\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359026; batch adversarial loss: 0.571016\n",
      "epoch 194; iter: 0; batch classifier loss: 0.283447; batch adversarial loss: 0.570431\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374153; batch adversarial loss: 0.618871\n",
      "epoch 196; iter: 0; batch classifier loss: 0.418426; batch adversarial loss: 0.515046\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356153; batch adversarial loss: 0.469751\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350087; batch adversarial loss: 0.599299\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351304; batch adversarial loss: 0.550801\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712197; batch adversarial loss: 0.659201\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574484; batch adversarial loss: 0.651418\n",
      "epoch 2; iter: 0; batch classifier loss: 0.548144; batch adversarial loss: 0.631501\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559705; batch adversarial loss: 0.590870\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606096; batch adversarial loss: 0.586511\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527102; batch adversarial loss: 0.602794\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546467; batch adversarial loss: 0.584139\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494876; batch adversarial loss: 0.572125\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570874; batch adversarial loss: 0.580075\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616221; batch adversarial loss: 0.625166\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558436; batch adversarial loss: 0.633852\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543849; batch adversarial loss: 0.614005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523340; batch adversarial loss: 0.521789\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532142; batch adversarial loss: 0.588674\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489797; batch adversarial loss: 0.631273\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561057; batch adversarial loss: 0.608201\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470162; batch adversarial loss: 0.533626\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507255; batch adversarial loss: 0.584433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503091; batch adversarial loss: 0.598567\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525808; batch adversarial loss: 0.593951\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503361; batch adversarial loss: 0.609052\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500783; batch adversarial loss: 0.551039\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486463; batch adversarial loss: 0.465660\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493999; batch adversarial loss: 0.594912\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531585; batch adversarial loss: 0.606929\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441859; batch adversarial loss: 0.575029\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441825; batch adversarial loss: 0.531711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.502510; batch adversarial loss: 0.633386\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463516; batch adversarial loss: 0.631662\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437259; batch adversarial loss: 0.529609\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402833; batch adversarial loss: 0.571319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468166; batch adversarial loss: 0.501848\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485816; batch adversarial loss: 0.535489\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448318; batch adversarial loss: 0.536270\n",
      "epoch 34; iter: 0; batch classifier loss: 0.588199; batch adversarial loss: 0.508835\n",
      "epoch 35; iter: 0; batch classifier loss: 0.383649; batch adversarial loss: 0.517731\n",
      "epoch 36; iter: 0; batch classifier loss: 0.491900; batch adversarial loss: 0.499006\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408953; batch adversarial loss: 0.506797\n",
      "epoch 38; iter: 0; batch classifier loss: 0.363164; batch adversarial loss: 0.506341\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505584; batch adversarial loss: 0.572775\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432293; batch adversarial loss: 0.551186\n",
      "epoch 41; iter: 0; batch classifier loss: 0.439743; batch adversarial loss: 0.554665\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405513; batch adversarial loss: 0.611454\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467622; batch adversarial loss: 0.477847\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485602; batch adversarial loss: 0.543166\n",
      "epoch 45; iter: 0; batch classifier loss: 0.447806; batch adversarial loss: 0.603055\n",
      "epoch 46; iter: 0; batch classifier loss: 0.347343; batch adversarial loss: 0.467970\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367501; batch adversarial loss: 0.526826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450899; batch adversarial loss: 0.543230\n",
      "epoch 49; iter: 0; batch classifier loss: 0.483879; batch adversarial loss: 0.507703\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449695; batch adversarial loss: 0.517331\n",
      "epoch 51; iter: 0; batch classifier loss: 0.381477; batch adversarial loss: 0.593436\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404118; batch adversarial loss: 0.471729\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403261; batch adversarial loss: 0.581164\n",
      "epoch 54; iter: 0; batch classifier loss: 0.468988; batch adversarial loss: 0.441601\n",
      "epoch 55; iter: 0; batch classifier loss: 0.438971; batch adversarial loss: 0.606577\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437484; batch adversarial loss: 0.505523\n",
      "epoch 57; iter: 0; batch classifier loss: 0.354979; batch adversarial loss: 0.563044\n",
      "epoch 58; iter: 0; batch classifier loss: 0.375333; batch adversarial loss: 0.505356\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478119; batch adversarial loss: 0.545051\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432546; batch adversarial loss: 0.552025\n",
      "epoch 61; iter: 0; batch classifier loss: 0.323731; batch adversarial loss: 0.470562\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380738; batch adversarial loss: 0.524714\n",
      "epoch 63; iter: 0; batch classifier loss: 0.338900; batch adversarial loss: 0.527443\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393822; batch adversarial loss: 0.573422\n",
      "epoch 65; iter: 0; batch classifier loss: 0.465699; batch adversarial loss: 0.590626\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415409; batch adversarial loss: 0.488999\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360813; batch adversarial loss: 0.439369\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411571; batch adversarial loss: 0.535168\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400599; batch adversarial loss: 0.525867\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366540; batch adversarial loss: 0.638479\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431007; batch adversarial loss: 0.506151\n",
      "epoch 72; iter: 0; batch classifier loss: 0.329684; batch adversarial loss: 0.544261\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429348; batch adversarial loss: 0.506875\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390666; batch adversarial loss: 0.599659\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411766; batch adversarial loss: 0.562933\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421682; batch adversarial loss: 0.619958\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395271; batch adversarial loss: 0.572084\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404107; batch adversarial loss: 0.535630\n",
      "epoch 79; iter: 0; batch classifier loss: 0.450834; batch adversarial loss: 0.479261\n",
      "epoch 80; iter: 0; batch classifier loss: 0.501639; batch adversarial loss: 0.619389\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392506; batch adversarial loss: 0.543695\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366553; batch adversarial loss: 0.591331\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419061; batch adversarial loss: 0.533908\n",
      "epoch 84; iter: 0; batch classifier loss: 0.335803; batch adversarial loss: 0.592006\n",
      "epoch 85; iter: 0; batch classifier loss: 0.483169; batch adversarial loss: 0.460006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.322612; batch adversarial loss: 0.554998\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409340; batch adversarial loss: 0.526675\n",
      "epoch 88; iter: 0; batch classifier loss: 0.323002; batch adversarial loss: 0.563007\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425313; batch adversarial loss: 0.554259\n",
      "epoch 90; iter: 0; batch classifier loss: 0.433216; batch adversarial loss: 0.505463\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433439; batch adversarial loss: 0.553893\n",
      "epoch 92; iter: 0; batch classifier loss: 0.349124; batch adversarial loss: 0.582209\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367600; batch adversarial loss: 0.535955\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351760; batch adversarial loss: 0.572151\n",
      "epoch 95; iter: 0; batch classifier loss: 0.436957; batch adversarial loss: 0.562316\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358305; batch adversarial loss: 0.545834\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392985; batch adversarial loss: 0.554060\n",
      "epoch 98; iter: 0; batch classifier loss: 0.419565; batch adversarial loss: 0.496851\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425104; batch adversarial loss: 0.638471\n",
      "epoch 100; iter: 0; batch classifier loss: 0.475462; batch adversarial loss: 0.571079\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335045; batch adversarial loss: 0.543761\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410897; batch adversarial loss: 0.552930\n",
      "epoch 103; iter: 0; batch classifier loss: 0.451704; batch adversarial loss: 0.505552\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383144; batch adversarial loss: 0.450256\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427006; batch adversarial loss: 0.525705\n",
      "epoch 106; iter: 0; batch classifier loss: 0.411452; batch adversarial loss: 0.554797\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392803; batch adversarial loss: 0.488915\n",
      "epoch 108; iter: 0; batch classifier loss: 0.337071; batch adversarial loss: 0.590664\n",
      "epoch 109; iter: 0; batch classifier loss: 0.300052; batch adversarial loss: 0.505819\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387947; batch adversarial loss: 0.534581\n",
      "epoch 111; iter: 0; batch classifier loss: 0.414409; batch adversarial loss: 0.591487\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356499; batch adversarial loss: 0.508146\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399890; batch adversarial loss: 0.572200\n",
      "epoch 114; iter: 0; batch classifier loss: 0.337922; batch adversarial loss: 0.563303\n",
      "epoch 115; iter: 0; batch classifier loss: 0.482458; batch adversarial loss: 0.440401\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387828; batch adversarial loss: 0.487985\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377164; batch adversarial loss: 0.533625\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366620; batch adversarial loss: 0.611523\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377379; batch adversarial loss: 0.554659\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363201; batch adversarial loss: 0.498769\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342516; batch adversarial loss: 0.469987\n",
      "epoch 122; iter: 0; batch classifier loss: 0.428613; batch adversarial loss: 0.516786\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346889; batch adversarial loss: 0.422279\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408104; batch adversarial loss: 0.460601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.336950; batch adversarial loss: 0.554765\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362500; batch adversarial loss: 0.498570\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349603; batch adversarial loss: 0.506377\n",
      "epoch 128; iter: 0; batch classifier loss: 0.452646; batch adversarial loss: 0.562859\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381527; batch adversarial loss: 0.582699\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342884; batch adversarial loss: 0.544508\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375531; batch adversarial loss: 0.592407\n",
      "epoch 132; iter: 0; batch classifier loss: 0.447916; batch adversarial loss: 0.554146\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371640; batch adversarial loss: 0.592776\n",
      "epoch 134; iter: 0; batch classifier loss: 0.388926; batch adversarial loss: 0.525915\n",
      "epoch 135; iter: 0; batch classifier loss: 0.316120; batch adversarial loss: 0.610555\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397129; batch adversarial loss: 0.562695\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413518; batch adversarial loss: 0.582762\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369629; batch adversarial loss: 0.562415\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381181; batch adversarial loss: 0.649305\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402116; batch adversarial loss: 0.591792\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353865; batch adversarial loss: 0.591030\n",
      "epoch 142; iter: 0; batch classifier loss: 0.488233; batch adversarial loss: 0.525248\n",
      "epoch 143; iter: 0; batch classifier loss: 0.402614; batch adversarial loss: 0.488052\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365700; batch adversarial loss: 0.478547\n",
      "epoch 145; iter: 0; batch classifier loss: 0.406298; batch adversarial loss: 0.497346\n",
      "epoch 146; iter: 0; batch classifier loss: 0.443301; batch adversarial loss: 0.496872\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379519; batch adversarial loss: 0.487812\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389944; batch adversarial loss: 0.486787\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376462; batch adversarial loss: 0.507136\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326053; batch adversarial loss: 0.572902\n",
      "epoch 151; iter: 0; batch classifier loss: 0.420361; batch adversarial loss: 0.507001\n",
      "epoch 152; iter: 0; batch classifier loss: 0.298617; batch adversarial loss: 0.525488\n",
      "epoch 153; iter: 0; batch classifier loss: 0.433909; batch adversarial loss: 0.516546\n",
      "epoch 154; iter: 0; batch classifier loss: 0.445636; batch adversarial loss: 0.516385\n",
      "epoch 155; iter: 0; batch classifier loss: 0.295845; batch adversarial loss: 0.591415\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354775; batch adversarial loss: 0.525395\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404161; batch adversarial loss: 0.592291\n",
      "epoch 158; iter: 0; batch classifier loss: 0.429831; batch adversarial loss: 0.554019\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366379; batch adversarial loss: 0.450371\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361911; batch adversarial loss: 0.544223\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358187; batch adversarial loss: 0.535164\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363455; batch adversarial loss: 0.478456\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354719; batch adversarial loss: 0.553268\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368373; batch adversarial loss: 0.572372\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361811; batch adversarial loss: 0.563739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375459; batch adversarial loss: 0.621432\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353617; batch adversarial loss: 0.563311\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366184; batch adversarial loss: 0.544464\n",
      "epoch 169; iter: 0; batch classifier loss: 0.247107; batch adversarial loss: 0.544554\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403585; batch adversarial loss: 0.497273\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420936; batch adversarial loss: 0.534819\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402356; batch adversarial loss: 0.506653\n",
      "epoch 173; iter: 0; batch classifier loss: 0.419359; batch adversarial loss: 0.535296\n",
      "epoch 174; iter: 0; batch classifier loss: 0.291690; batch adversarial loss: 0.563527\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325420; batch adversarial loss: 0.629444\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360428; batch adversarial loss: 0.582227\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384853; batch adversarial loss: 0.497423\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368835; batch adversarial loss: 0.544159\n",
      "epoch 179; iter: 0; batch classifier loss: 0.453821; batch adversarial loss: 0.553660\n",
      "epoch 180; iter: 0; batch classifier loss: 0.361726; batch adversarial loss: 0.572338\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373779; batch adversarial loss: 0.591601\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380995; batch adversarial loss: 0.506956\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347868; batch adversarial loss: 0.601034\n",
      "epoch 184; iter: 0; batch classifier loss: 0.426820; batch adversarial loss: 0.544807\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368362; batch adversarial loss: 0.572812\n",
      "epoch 186; iter: 0; batch classifier loss: 0.344597; batch adversarial loss: 0.506757\n",
      "epoch 187; iter: 0; batch classifier loss: 0.272683; batch adversarial loss: 0.544253\n",
      "epoch 188; iter: 0; batch classifier loss: 0.321555; batch adversarial loss: 0.592402\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369442; batch adversarial loss: 0.534250\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372685; batch adversarial loss: 0.523990\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314659; batch adversarial loss: 0.466093\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399897; batch adversarial loss: 0.503989\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378121; batch adversarial loss: 0.545406\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390678; batch adversarial loss: 0.556370\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397416; batch adversarial loss: 0.478942\n",
      "epoch 196; iter: 0; batch classifier loss: 0.371423; batch adversarial loss: 0.514757\n",
      "epoch 197; iter: 0; batch classifier loss: 0.429734; batch adversarial loss: 0.534621\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335270; batch adversarial loss: 0.610182\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340646; batch adversarial loss: 0.475545\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725113; batch adversarial loss: 0.712712\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544248; batch adversarial loss: 0.671289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573639; batch adversarial loss: 0.657302\n",
      "epoch 3; iter: 0; batch classifier loss: 0.526088; batch adversarial loss: 0.660319\n",
      "epoch 4; iter: 0; batch classifier loss: 0.470453; batch adversarial loss: 0.652252\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541980; batch adversarial loss: 0.613302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558524; batch adversarial loss: 0.616581\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509778; batch adversarial loss: 0.599727\n",
      "epoch 8; iter: 0; batch classifier loss: 0.592645; batch adversarial loss: 0.632137\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586597; batch adversarial loss: 0.568089\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488929; batch adversarial loss: 0.593177\n",
      "epoch 11; iter: 0; batch classifier loss: 0.497027; batch adversarial loss: 0.543183\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498772; batch adversarial loss: 0.608310\n",
      "epoch 13; iter: 0; batch classifier loss: 0.582518; batch adversarial loss: 0.541154\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466878; batch adversarial loss: 0.477898\n",
      "epoch 15; iter: 0; batch classifier loss: 0.586994; batch adversarial loss: 0.628632\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528706; batch adversarial loss: 0.537797\n",
      "epoch 17; iter: 0; batch classifier loss: 0.448583; batch adversarial loss: 0.500358\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492777; batch adversarial loss: 0.571909\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499372; batch adversarial loss: 0.588448\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482023; batch adversarial loss: 0.507377\n",
      "epoch 21; iter: 0; batch classifier loss: 0.411518; batch adversarial loss: 0.553656\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507299; batch adversarial loss: 0.601705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.450807; batch adversarial loss: 0.532763\n",
      "epoch 24; iter: 0; batch classifier loss: 0.443889; batch adversarial loss: 0.530806\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480889; batch adversarial loss: 0.574504\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472688; batch adversarial loss: 0.510759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469771; batch adversarial loss: 0.563147\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456319; batch adversarial loss: 0.487314\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503152; batch adversarial loss: 0.516852\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472480; batch adversarial loss: 0.503451\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455486; batch adversarial loss: 0.599095\n",
      "epoch 32; iter: 0; batch classifier loss: 0.386226; batch adversarial loss: 0.507512\n",
      "epoch 33; iter: 0; batch classifier loss: 0.525950; batch adversarial loss: 0.592908\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483319; batch adversarial loss: 0.562211\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482404; batch adversarial loss: 0.582947\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467120; batch adversarial loss: 0.550438\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458271; batch adversarial loss: 0.500144\n",
      "epoch 38; iter: 0; batch classifier loss: 0.355642; batch adversarial loss: 0.466081\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449051; batch adversarial loss: 0.568754\n",
      "epoch 40; iter: 0; batch classifier loss: 0.364882; batch adversarial loss: 0.503459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459952; batch adversarial loss: 0.532424\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428113; batch adversarial loss: 0.497939\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470956; batch adversarial loss: 0.544278\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395736; batch adversarial loss: 0.552516\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426985; batch adversarial loss: 0.586298\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417847; batch adversarial loss: 0.509187\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435374; batch adversarial loss: 0.463841\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372973; batch adversarial loss: 0.526952\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410881; batch adversarial loss: 0.534680\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411764; batch adversarial loss: 0.610234\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434364; batch adversarial loss: 0.509571\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429019; batch adversarial loss: 0.491597\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470008; batch adversarial loss: 0.572657\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418226; batch adversarial loss: 0.553079\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478320; batch adversarial loss: 0.516455\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455502; batch adversarial loss: 0.509705\n",
      "epoch 57; iter: 0; batch classifier loss: 0.350779; batch adversarial loss: 0.558187\n",
      "epoch 58; iter: 0; batch classifier loss: 0.376175; batch adversarial loss: 0.518311\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452991; batch adversarial loss: 0.619699\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418538; batch adversarial loss: 0.545111\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433428; batch adversarial loss: 0.576356\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479954; batch adversarial loss: 0.487907\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421691; batch adversarial loss: 0.550756\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432343; batch adversarial loss: 0.538989\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369100; batch adversarial loss: 0.518177\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386549; batch adversarial loss: 0.580180\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421761; batch adversarial loss: 0.542915\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422421; batch adversarial loss: 0.462748\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385364; batch adversarial loss: 0.571957\n",
      "epoch 70; iter: 0; batch classifier loss: 0.389575; batch adversarial loss: 0.582061\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427598; batch adversarial loss: 0.574986\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400221; batch adversarial loss: 0.553320\n",
      "epoch 73; iter: 0; batch classifier loss: 0.456531; batch adversarial loss: 0.590734\n",
      "epoch 74; iter: 0; batch classifier loss: 0.501391; batch adversarial loss: 0.561672\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395190; batch adversarial loss: 0.636558\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436884; batch adversarial loss: 0.598159\n",
      "epoch 77; iter: 0; batch classifier loss: 0.356658; batch adversarial loss: 0.479239\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402487; batch adversarial loss: 0.490418\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436809; batch adversarial loss: 0.455318\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430022; batch adversarial loss: 0.491126\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421762; batch adversarial loss: 0.564733\n",
      "epoch 82; iter: 0; batch classifier loss: 0.402198; batch adversarial loss: 0.606110\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380754; batch adversarial loss: 0.534339\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362790; batch adversarial loss: 0.581963\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378767; batch adversarial loss: 0.568946\n",
      "epoch 86; iter: 0; batch classifier loss: 0.438594; batch adversarial loss: 0.544547\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455472; batch adversarial loss: 0.572058\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401149; batch adversarial loss: 0.574817\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366358; batch adversarial loss: 0.566903\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391832; batch adversarial loss: 0.588699\n",
      "epoch 91; iter: 0; batch classifier loss: 0.318796; batch adversarial loss: 0.579743\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387235; batch adversarial loss: 0.553378\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371077; batch adversarial loss: 0.614461\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421161; batch adversarial loss: 0.578678\n",
      "epoch 95; iter: 0; batch classifier loss: 0.367206; batch adversarial loss: 0.610670\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375869; batch adversarial loss: 0.553193\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367275; batch adversarial loss: 0.526049\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382925; batch adversarial loss: 0.552973\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374651; batch adversarial loss: 0.507350\n",
      "epoch 100; iter: 0; batch classifier loss: 0.414512; batch adversarial loss: 0.528563\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390102; batch adversarial loss: 0.546269\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413303; batch adversarial loss: 0.527246\n",
      "epoch 103; iter: 0; batch classifier loss: 0.324595; batch adversarial loss: 0.552071\n",
      "epoch 104; iter: 0; batch classifier loss: 0.334289; batch adversarial loss: 0.455568\n",
      "epoch 105; iter: 0; batch classifier loss: 0.377150; batch adversarial loss: 0.490164\n",
      "epoch 106; iter: 0; batch classifier loss: 0.457872; batch adversarial loss: 0.545796\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417335; batch adversarial loss: 0.510920\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405350; batch adversarial loss: 0.536917\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386751; batch adversarial loss: 0.509747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382518; batch adversarial loss: 0.622461\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398534; batch adversarial loss: 0.573858\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368782; batch adversarial loss: 0.569130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382294; batch adversarial loss: 0.555657\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347624; batch adversarial loss: 0.581033\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383320; batch adversarial loss: 0.535270\n",
      "epoch 116; iter: 0; batch classifier loss: 0.418368; batch adversarial loss: 0.568873\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375467; batch adversarial loss: 0.580277\n",
      "epoch 118; iter: 0; batch classifier loss: 0.314838; batch adversarial loss: 0.607886\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347565; batch adversarial loss: 0.589489\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400344; batch adversarial loss: 0.621028\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350160; batch adversarial loss: 0.595867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.426860; batch adversarial loss: 0.489968\n",
      "epoch 123; iter: 0; batch classifier loss: 0.425100; batch adversarial loss: 0.572666\n",
      "epoch 124; iter: 0; batch classifier loss: 0.313395; batch adversarial loss: 0.553063\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397432; batch adversarial loss: 0.561149\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368565; batch adversarial loss: 0.535879\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392297; batch adversarial loss: 0.545170\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381356; batch adversarial loss: 0.490251\n",
      "epoch 129; iter: 0; batch classifier loss: 0.440483; batch adversarial loss: 0.535306\n",
      "epoch 130; iter: 0; batch classifier loss: 0.484203; batch adversarial loss: 0.597131\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414046; batch adversarial loss: 0.580934\n",
      "epoch 132; iter: 0; batch classifier loss: 0.337144; batch adversarial loss: 0.571307\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356113; batch adversarial loss: 0.553924\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387739; batch adversarial loss: 0.559933\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378741; batch adversarial loss: 0.571243\n",
      "epoch 136; iter: 0; batch classifier loss: 0.440272; batch adversarial loss: 0.594761\n",
      "epoch 137; iter: 0; batch classifier loss: 0.410446; batch adversarial loss: 0.470019\n",
      "epoch 138; iter: 0; batch classifier loss: 0.400225; batch adversarial loss: 0.624651\n",
      "epoch 139; iter: 0; batch classifier loss: 0.413100; batch adversarial loss: 0.581038\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367862; batch adversarial loss: 0.555637\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368462; batch adversarial loss: 0.597362\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381810; batch adversarial loss: 0.605868\n",
      "epoch 143; iter: 0; batch classifier loss: 0.302951; batch adversarial loss: 0.535817\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384565; batch adversarial loss: 0.554269\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349606; batch adversarial loss: 0.529579\n",
      "epoch 146; iter: 0; batch classifier loss: 0.278786; batch adversarial loss: 0.563517\n",
      "epoch 147; iter: 0; batch classifier loss: 0.430120; batch adversarial loss: 0.572928\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353905; batch adversarial loss: 0.515805\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316535; batch adversarial loss: 0.518152\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399218; batch adversarial loss: 0.535895\n",
      "epoch 151; iter: 0; batch classifier loss: 0.414434; batch adversarial loss: 0.525685\n",
      "epoch 152; iter: 0; batch classifier loss: 0.427639; batch adversarial loss: 0.571804\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383554; batch adversarial loss: 0.545147\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346600; batch adversarial loss: 0.615792\n",
      "epoch 155; iter: 0; batch classifier loss: 0.321298; batch adversarial loss: 0.554632\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372085; batch adversarial loss: 0.632710\n",
      "epoch 157; iter: 0; batch classifier loss: 0.387653; batch adversarial loss: 0.446805\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315403; batch adversarial loss: 0.546041\n",
      "epoch 159; iter: 0; batch classifier loss: 0.463952; batch adversarial loss: 0.588758\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384710; batch adversarial loss: 0.534449\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385128; batch adversarial loss: 0.608595\n",
      "epoch 162; iter: 0; batch classifier loss: 0.377622; batch adversarial loss: 0.553406\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321430; batch adversarial loss: 0.616752\n",
      "epoch 164; iter: 0; batch classifier loss: 0.320332; batch adversarial loss: 0.545439\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375611; batch adversarial loss: 0.481589\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372963; batch adversarial loss: 0.644426\n",
      "epoch 167; iter: 0; batch classifier loss: 0.411511; batch adversarial loss: 0.481364\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406591; batch adversarial loss: 0.492160\n",
      "epoch 169; iter: 0; batch classifier loss: 0.431642; batch adversarial loss: 0.480716\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374859; batch adversarial loss: 0.518410\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334311; batch adversarial loss: 0.501650\n",
      "epoch 172; iter: 0; batch classifier loss: 0.393425; batch adversarial loss: 0.517374\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335338; batch adversarial loss: 0.580320\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399180; batch adversarial loss: 0.481798\n",
      "epoch 175; iter: 0; batch classifier loss: 0.242599; batch adversarial loss: 0.603716\n",
      "epoch 176; iter: 0; batch classifier loss: 0.371867; batch adversarial loss: 0.526535\n",
      "epoch 177; iter: 0; batch classifier loss: 0.382147; batch adversarial loss: 0.576106\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350372; batch adversarial loss: 0.581688\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347245; batch adversarial loss: 0.510105\n",
      "epoch 180; iter: 0; batch classifier loss: 0.404607; batch adversarial loss: 0.544886\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399340; batch adversarial loss: 0.536009\n",
      "epoch 182; iter: 0; batch classifier loss: 0.332862; batch adversarial loss: 0.564817\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344905; batch adversarial loss: 0.538702\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372849; batch adversarial loss: 0.562399\n",
      "epoch 185; iter: 0; batch classifier loss: 0.350975; batch adversarial loss: 0.545513\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398922; batch adversarial loss: 0.562586\n",
      "epoch 187; iter: 0; batch classifier loss: 0.416630; batch adversarial loss: 0.499386\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318855; batch adversarial loss: 0.652491\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354824; batch adversarial loss: 0.615144\n",
      "epoch 190; iter: 0; batch classifier loss: 0.355939; batch adversarial loss: 0.517249\n",
      "epoch 191; iter: 0; batch classifier loss: 0.404352; batch adversarial loss: 0.535092\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353820; batch adversarial loss: 0.455891\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376433; batch adversarial loss: 0.508522\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407643; batch adversarial loss: 0.581763\n",
      "epoch 195; iter: 0; batch classifier loss: 0.301310; batch adversarial loss: 0.590649\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320531; batch adversarial loss: 0.526766\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368203; batch adversarial loss: 0.536020\n",
      "epoch 198; iter: 0; batch classifier loss: 0.346390; batch adversarial loss: 0.555943\n",
      "epoch 199; iter: 0; batch classifier loss: 0.392082; batch adversarial loss: 0.526781\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681416; batch adversarial loss: 0.675029\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593886; batch adversarial loss: 0.661169\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551630; batch adversarial loss: 0.644647\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577886; batch adversarial loss: 0.642675\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585305; batch adversarial loss: 0.632559\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533889; batch adversarial loss: 0.630088\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568665; batch adversarial loss: 0.572384\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530955; batch adversarial loss: 0.591302\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530356; batch adversarial loss: 0.611701\n",
      "epoch 9; iter: 0; batch classifier loss: 0.464855; batch adversarial loss: 0.542547\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507918; batch adversarial loss: 0.596842\n",
      "epoch 11; iter: 0; batch classifier loss: 0.455374; batch adversarial loss: 0.609673\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598062; batch adversarial loss: 0.524372\n",
      "epoch 13; iter: 0; batch classifier loss: 0.464675; batch adversarial loss: 0.572348\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480321; batch adversarial loss: 0.522292\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458345; batch adversarial loss: 0.553080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492013; batch adversarial loss: 0.600968\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474612; batch adversarial loss: 0.557263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.497572; batch adversarial loss: 0.557814\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483288; batch adversarial loss: 0.533628\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406367; batch adversarial loss: 0.606835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456872; batch adversarial loss: 0.503808\n",
      "epoch 22; iter: 0; batch classifier loss: 0.508955; batch adversarial loss: 0.565457\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525167; batch adversarial loss: 0.526313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460928; batch adversarial loss: 0.500795\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495704; batch adversarial loss: 0.556315\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532599; batch adversarial loss: 0.571660\n",
      "epoch 27; iter: 0; batch classifier loss: 0.452706; batch adversarial loss: 0.522597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477642; batch adversarial loss: 0.596212\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533135; batch adversarial loss: 0.554273\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478808; batch adversarial loss: 0.579212\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505172; batch adversarial loss: 0.511070\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474889; batch adversarial loss: 0.579661\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460455; batch adversarial loss: 0.597580\n",
      "epoch 34; iter: 0; batch classifier loss: 0.386731; batch adversarial loss: 0.509909\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435992; batch adversarial loss: 0.544847\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461825; batch adversarial loss: 0.632251\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493529; batch adversarial loss: 0.516350\n",
      "epoch 38; iter: 0; batch classifier loss: 0.515723; batch adversarial loss: 0.525749\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431466; batch adversarial loss: 0.542819\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440506; batch adversarial loss: 0.480472\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432198; batch adversarial loss: 0.562150\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484791; batch adversarial loss: 0.572518\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455310; batch adversarial loss: 0.499539\n",
      "epoch 44; iter: 0; batch classifier loss: 0.376199; batch adversarial loss: 0.572152\n",
      "epoch 45; iter: 0; batch classifier loss: 0.352396; batch adversarial loss: 0.571618\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385694; batch adversarial loss: 0.516477\n",
      "epoch 47; iter: 0; batch classifier loss: 0.342767; batch adversarial loss: 0.535882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477929; batch adversarial loss: 0.529227\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429301; batch adversarial loss: 0.544911\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410104; batch adversarial loss: 0.551226\n",
      "epoch 51; iter: 0; batch classifier loss: 0.381105; batch adversarial loss: 0.562834\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434997; batch adversarial loss: 0.544105\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417769; batch adversarial loss: 0.579830\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381957; batch adversarial loss: 0.577271\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410305; batch adversarial loss: 0.600338\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392567; batch adversarial loss: 0.544205\n",
      "epoch 57; iter: 0; batch classifier loss: 0.419832; batch adversarial loss: 0.491825\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358982; batch adversarial loss: 0.583054\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392369; batch adversarial loss: 0.499287\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395644; batch adversarial loss: 0.529898\n",
      "epoch 61; iter: 0; batch classifier loss: 0.348495; batch adversarial loss: 0.560320\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379371; batch adversarial loss: 0.581817\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356240; batch adversarial loss: 0.518372\n",
      "epoch 64; iter: 0; batch classifier loss: 0.482105; batch adversarial loss: 0.559783\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375239; batch adversarial loss: 0.486951\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419417; batch adversarial loss: 0.543278\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437668; batch adversarial loss: 0.542876\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414211; batch adversarial loss: 0.515642\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448550; batch adversarial loss: 0.667670\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401573; batch adversarial loss: 0.571768\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412041; batch adversarial loss: 0.566058\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449861; batch adversarial loss: 0.518230\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382780; batch adversarial loss: 0.535067\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422077; batch adversarial loss: 0.472518\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405702; batch adversarial loss: 0.536449\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368839; batch adversarial loss: 0.498729\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415142; batch adversarial loss: 0.565202\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402066; batch adversarial loss: 0.540087\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373494; batch adversarial loss: 0.552149\n",
      "epoch 80; iter: 0; batch classifier loss: 0.454261; batch adversarial loss: 0.542899\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396388; batch adversarial loss: 0.561559\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396216; batch adversarial loss: 0.518864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.347950; batch adversarial loss: 0.488268\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399360; batch adversarial loss: 0.494416\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424446; batch adversarial loss: 0.525593\n",
      "epoch 86; iter: 0; batch classifier loss: 0.450861; batch adversarial loss: 0.547280\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375289; batch adversarial loss: 0.488595\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394420; batch adversarial loss: 0.495669\n",
      "epoch 89; iter: 0; batch classifier loss: 0.354743; batch adversarial loss: 0.480446\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351249; batch adversarial loss: 0.538893\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399981; batch adversarial loss: 0.474459\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421893; batch adversarial loss: 0.540232\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384251; batch adversarial loss: 0.553892\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396834; batch adversarial loss: 0.510116\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394817; batch adversarial loss: 0.495822\n",
      "epoch 96; iter: 0; batch classifier loss: 0.432888; batch adversarial loss: 0.515461\n",
      "epoch 97; iter: 0; batch classifier loss: 0.327215; batch adversarial loss: 0.642520\n",
      "epoch 98; iter: 0; batch classifier loss: 0.332610; batch adversarial loss: 0.531880\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388890; batch adversarial loss: 0.546716\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355181; batch adversarial loss: 0.581222\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378152; batch adversarial loss: 0.591733\n",
      "epoch 102; iter: 0; batch classifier loss: 0.420490; batch adversarial loss: 0.609558\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401687; batch adversarial loss: 0.472272\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387709; batch adversarial loss: 0.656779\n",
      "epoch 105; iter: 0; batch classifier loss: 0.438537; batch adversarial loss: 0.523919\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379744; batch adversarial loss: 0.545025\n",
      "epoch 107; iter: 0; batch classifier loss: 0.334311; batch adversarial loss: 0.576918\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422067; batch adversarial loss: 0.543113\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375927; batch adversarial loss: 0.540915\n",
      "epoch 110; iter: 0; batch classifier loss: 0.423783; batch adversarial loss: 0.535054\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357555; batch adversarial loss: 0.579773\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366528; batch adversarial loss: 0.552181\n",
      "epoch 113; iter: 0; batch classifier loss: 0.313627; batch adversarial loss: 0.573956\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393985; batch adversarial loss: 0.500541\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378167; batch adversarial loss: 0.525593\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368598; batch adversarial loss: 0.529226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.332307; batch adversarial loss: 0.475610\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453373; batch adversarial loss: 0.538433\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408458; batch adversarial loss: 0.526502\n",
      "epoch 120; iter: 0; batch classifier loss: 0.313517; batch adversarial loss: 0.591626\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375769; batch adversarial loss: 0.641284\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359101; batch adversarial loss: 0.628962\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381945; batch adversarial loss: 0.560908\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426771; batch adversarial loss: 0.590422\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387421; batch adversarial loss: 0.619548\n",
      "epoch 126; iter: 0; batch classifier loss: 0.440400; batch adversarial loss: 0.631569\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379517; batch adversarial loss: 0.521737\n",
      "epoch 128; iter: 0; batch classifier loss: 0.504877; batch adversarial loss: 0.517951\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354171; batch adversarial loss: 0.589069\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348313; batch adversarial loss: 0.508985\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347329; batch adversarial loss: 0.550758\n",
      "epoch 132; iter: 0; batch classifier loss: 0.391622; batch adversarial loss: 0.480331\n",
      "epoch 133; iter: 0; batch classifier loss: 0.424105; batch adversarial loss: 0.597915\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326791; batch adversarial loss: 0.525515\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386741; batch adversarial loss: 0.552704\n",
      "epoch 136; iter: 0; batch classifier loss: 0.450684; batch adversarial loss: 0.568863\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371842; batch adversarial loss: 0.520013\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388029; batch adversarial loss: 0.562107\n",
      "epoch 139; iter: 0; batch classifier loss: 0.314536; batch adversarial loss: 0.533972\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364240; batch adversarial loss: 0.498577\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388570; batch adversarial loss: 0.485660\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356557; batch adversarial loss: 0.480614\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367233; batch adversarial loss: 0.517638\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341715; batch adversarial loss: 0.491227\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367343; batch adversarial loss: 0.526991\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383619; batch adversarial loss: 0.478251\n",
      "epoch 147; iter: 0; batch classifier loss: 0.279989; batch adversarial loss: 0.526175\n",
      "epoch 148; iter: 0; batch classifier loss: 0.309438; batch adversarial loss: 0.609174\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317067; batch adversarial loss: 0.545223\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385111; batch adversarial loss: 0.555283\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385010; batch adversarial loss: 0.490925\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370605; batch adversarial loss: 0.624680\n",
      "epoch 153; iter: 0; batch classifier loss: 0.410301; batch adversarial loss: 0.500346\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389184; batch adversarial loss: 0.602998\n",
      "epoch 155; iter: 0; batch classifier loss: 0.386930; batch adversarial loss: 0.561300\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337948; batch adversarial loss: 0.539368\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405956; batch adversarial loss: 0.518865\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367269; batch adversarial loss: 0.544739\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391810; batch adversarial loss: 0.479437\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319979; batch adversarial loss: 0.506990\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347165; batch adversarial loss: 0.583469\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353062; batch adversarial loss: 0.624651\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340119; batch adversarial loss: 0.544440\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328058; batch adversarial loss: 0.608067\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348857; batch adversarial loss: 0.485680\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312967; batch adversarial loss: 0.499454\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374509; batch adversarial loss: 0.516162\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367456; batch adversarial loss: 0.559312\n",
      "epoch 169; iter: 0; batch classifier loss: 0.315219; batch adversarial loss: 0.591482\n",
      "epoch 170; iter: 0; batch classifier loss: 0.328565; batch adversarial loss: 0.565714\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369980; batch adversarial loss: 0.525416\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366227; batch adversarial loss: 0.588839\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330442; batch adversarial loss: 0.598921\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378374; batch adversarial loss: 0.526933\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356121; batch adversarial loss: 0.571216\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335960; batch adversarial loss: 0.536620\n",
      "epoch 177; iter: 0; batch classifier loss: 0.289323; batch adversarial loss: 0.636120\n",
      "epoch 178; iter: 0; batch classifier loss: 0.415034; batch adversarial loss: 0.571343\n",
      "epoch 179; iter: 0; batch classifier loss: 0.289007; batch adversarial loss: 0.581790\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331207; batch adversarial loss: 0.606956\n",
      "epoch 181; iter: 0; batch classifier loss: 0.302135; batch adversarial loss: 0.481594\n",
      "epoch 182; iter: 0; batch classifier loss: 0.398758; batch adversarial loss: 0.578197\n",
      "epoch 183; iter: 0; batch classifier loss: 0.299106; batch adversarial loss: 0.589411\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337035; batch adversarial loss: 0.525426\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354127; batch adversarial loss: 0.573068\n",
      "epoch 186; iter: 0; batch classifier loss: 0.293412; batch adversarial loss: 0.512984\n",
      "epoch 187; iter: 0; batch classifier loss: 0.384534; batch adversarial loss: 0.588202\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352106; batch adversarial loss: 0.569935\n",
      "epoch 189; iter: 0; batch classifier loss: 0.300813; batch adversarial loss: 0.628748\n",
      "epoch 190; iter: 0; batch classifier loss: 0.297029; batch adversarial loss: 0.587431\n",
      "epoch 191; iter: 0; batch classifier loss: 0.315584; batch adversarial loss: 0.537530\n",
      "epoch 192; iter: 0; batch classifier loss: 0.294402; batch adversarial loss: 0.588622\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395124; batch adversarial loss: 0.491673\n",
      "epoch 194; iter: 0; batch classifier loss: 0.459244; batch adversarial loss: 0.620776\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327469; batch adversarial loss: 0.560356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392733; batch adversarial loss: 0.578948\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345767; batch adversarial loss: 0.601349\n",
      "epoch 198; iter: 0; batch classifier loss: 0.364226; batch adversarial loss: 0.527105\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363278; batch adversarial loss: 0.578844\n",
      "epoch 0; iter: 0; batch classifier loss: 0.789329; batch adversarial loss: 0.857808\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607410; batch adversarial loss: 0.783278\n",
      "epoch 2; iter: 0; batch classifier loss: 0.481341; batch adversarial loss: 0.774276\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567665; batch adversarial loss: 0.721739\n",
      "epoch 4; iter: 0; batch classifier loss: 0.484503; batch adversarial loss: 0.678886\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562383; batch adversarial loss: 0.682964\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561621; batch adversarial loss: 0.662200\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503545; batch adversarial loss: 0.620097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.584970; batch adversarial loss: 0.637267\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488008; batch adversarial loss: 0.594481\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543202; batch adversarial loss: 0.597934\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527487; batch adversarial loss: 0.582325\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544370; batch adversarial loss: 0.530029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13; iter: 0; batch classifier loss: 0.375086; batch adversarial loss: 0.509033\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514217; batch adversarial loss: 0.581659\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511168; batch adversarial loss: 0.510605\n",
      "epoch 16; iter: 0; batch classifier loss: 0.456724; batch adversarial loss: 0.551630\n",
      "epoch 17; iter: 0; batch classifier loss: 0.551456; batch adversarial loss: 0.568214\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485994; batch adversarial loss: 0.506736\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522056; batch adversarial loss: 0.529713\n",
      "epoch 20; iter: 0; batch classifier loss: 0.425617; batch adversarial loss: 0.588041\n",
      "epoch 21; iter: 0; batch classifier loss: 0.577419; batch adversarial loss: 0.500260\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495812; batch adversarial loss: 0.538184\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485783; batch adversarial loss: 0.577696\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525445; batch adversarial loss: 0.516346\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440418; batch adversarial loss: 0.533494\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425209; batch adversarial loss: 0.589296\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461502; batch adversarial loss: 0.539710\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431802; batch adversarial loss: 0.550920\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467120; batch adversarial loss: 0.539462\n",
      "epoch 30; iter: 0; batch classifier loss: 0.518027; batch adversarial loss: 0.534319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460264; batch adversarial loss: 0.529681\n",
      "epoch 32; iter: 0; batch classifier loss: 0.437295; batch adversarial loss: 0.515504\n",
      "epoch 33; iter: 0; batch classifier loss: 0.479578; batch adversarial loss: 0.492392\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452372; batch adversarial loss: 0.564933\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502509; batch adversarial loss: 0.549264\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439955; batch adversarial loss: 0.504833\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483618; batch adversarial loss: 0.576751\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448098; batch adversarial loss: 0.553188\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480146; batch adversarial loss: 0.489730\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461353; batch adversarial loss: 0.459716\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454189; batch adversarial loss: 0.531194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.520060; batch adversarial loss: 0.573361\n",
      "epoch 43; iter: 0; batch classifier loss: 0.448376; batch adversarial loss: 0.484080\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504948; batch adversarial loss: 0.520121\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418832; batch adversarial loss: 0.552597\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469902; batch adversarial loss: 0.550195\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404383; batch adversarial loss: 0.497228\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450342; batch adversarial loss: 0.576577\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417130; batch adversarial loss: 0.538808\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433354; batch adversarial loss: 0.477841\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476561; batch adversarial loss: 0.508008\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427657; batch adversarial loss: 0.519438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465023; batch adversarial loss: 0.534353\n",
      "epoch 54; iter: 0; batch classifier loss: 0.357057; batch adversarial loss: 0.551600\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377684; batch adversarial loss: 0.598474\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418237; batch adversarial loss: 0.499750\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498292; batch adversarial loss: 0.589586\n",
      "epoch 58; iter: 0; batch classifier loss: 0.515995; batch adversarial loss: 0.554821\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441979; batch adversarial loss: 0.527738\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374852; batch adversarial loss: 0.535444\n",
      "epoch 61; iter: 0; batch classifier loss: 0.503108; batch adversarial loss: 0.553775\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377608; batch adversarial loss: 0.490200\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400912; batch adversarial loss: 0.452592\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489633; batch adversarial loss: 0.505713\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367176; batch adversarial loss: 0.561717\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366106; batch adversarial loss: 0.552469\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398578; batch adversarial loss: 0.584141\n",
      "epoch 68; iter: 0; batch classifier loss: 0.469696; batch adversarial loss: 0.536677\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361733; batch adversarial loss: 0.561724\n",
      "epoch 70; iter: 0; batch classifier loss: 0.363342; batch adversarial loss: 0.469569\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378135; batch adversarial loss: 0.508820\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418120; batch adversarial loss: 0.525492\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383748; batch adversarial loss: 0.543231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.512809; batch adversarial loss: 0.552339\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452082; batch adversarial loss: 0.557301\n",
      "epoch 76; iter: 0; batch classifier loss: 0.444717; batch adversarial loss: 0.536304\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423846; batch adversarial loss: 0.481419\n",
      "epoch 78; iter: 0; batch classifier loss: 0.434612; batch adversarial loss: 0.558840\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429969; batch adversarial loss: 0.543493\n",
      "epoch 80; iter: 0; batch classifier loss: 0.457884; batch adversarial loss: 0.502766\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378890; batch adversarial loss: 0.461930\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371387; batch adversarial loss: 0.542952\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348802; batch adversarial loss: 0.460911\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440525; batch adversarial loss: 0.597055\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381826; batch adversarial loss: 0.545604\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407309; batch adversarial loss: 0.471304\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375067; batch adversarial loss: 0.543787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.500380; batch adversarial loss: 0.546737\n",
      "epoch 89; iter: 0; batch classifier loss: 0.318046; batch adversarial loss: 0.580260\n",
      "epoch 90; iter: 0; batch classifier loss: 0.440046; batch adversarial loss: 0.491615\n",
      "epoch 91; iter: 0; batch classifier loss: 0.436695; batch adversarial loss: 0.518573\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351351; batch adversarial loss: 0.488364\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380865; batch adversarial loss: 0.583511\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425260; batch adversarial loss: 0.572556\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420821; batch adversarial loss: 0.542475\n",
      "epoch 96; iter: 0; batch classifier loss: 0.351635; batch adversarial loss: 0.502491\n",
      "epoch 97; iter: 0; batch classifier loss: 0.406502; batch adversarial loss: 0.555653\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383944; batch adversarial loss: 0.580121\n",
      "epoch 99; iter: 0; batch classifier loss: 0.430582; batch adversarial loss: 0.555078\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429410; batch adversarial loss: 0.499137\n",
      "epoch 101; iter: 0; batch classifier loss: 0.502946; batch adversarial loss: 0.562106\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355288; batch adversarial loss: 0.583388\n",
      "epoch 103; iter: 0; batch classifier loss: 0.342474; batch adversarial loss: 0.544798\n",
      "epoch 104; iter: 0; batch classifier loss: 0.439796; batch adversarial loss: 0.460276\n",
      "epoch 105; iter: 0; batch classifier loss: 0.433734; batch adversarial loss: 0.536865\n",
      "epoch 106; iter: 0; batch classifier loss: 0.425521; batch adversarial loss: 0.545972\n",
      "epoch 107; iter: 0; batch classifier loss: 0.497638; batch adversarial loss: 0.572692\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370897; batch adversarial loss: 0.571329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416713; batch adversarial loss: 0.580996\n",
      "epoch 110; iter: 0; batch classifier loss: 0.443495; batch adversarial loss: 0.521210\n",
      "epoch 111; iter: 0; batch classifier loss: 0.448128; batch adversarial loss: 0.672602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.375757; batch adversarial loss: 0.544848\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407100; batch adversarial loss: 0.562998\n",
      "epoch 114; iter: 0; batch classifier loss: 0.467342; batch adversarial loss: 0.518749\n",
      "epoch 115; iter: 0; batch classifier loss: 0.449801; batch adversarial loss: 0.527995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.434240; batch adversarial loss: 0.518103\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326026; batch adversarial loss: 0.599692\n",
      "epoch 118; iter: 0; batch classifier loss: 0.489004; batch adversarial loss: 0.549223\n",
      "epoch 119; iter: 0; batch classifier loss: 0.321970; batch adversarial loss: 0.487949\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418660; batch adversarial loss: 0.536889\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400954; batch adversarial loss: 0.497552\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351142; batch adversarial loss: 0.470285\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380274; batch adversarial loss: 0.544030\n",
      "epoch 124; iter: 0; batch classifier loss: 0.283986; batch adversarial loss: 0.515850\n",
      "epoch 125; iter: 0; batch classifier loss: 0.352702; batch adversarial loss: 0.571072\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354852; batch adversarial loss: 0.543786\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372523; batch adversarial loss: 0.571415\n",
      "epoch 128; iter: 0; batch classifier loss: 0.405616; batch adversarial loss: 0.520875\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343266; batch adversarial loss: 0.482196\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321194; batch adversarial loss: 0.487166\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407424; batch adversarial loss: 0.640347\n",
      "epoch 132; iter: 0; batch classifier loss: 0.328563; batch adversarial loss: 0.621132\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331218; batch adversarial loss: 0.534733\n",
      "epoch 134; iter: 0; batch classifier loss: 0.322327; batch adversarial loss: 0.489183\n",
      "epoch 135; iter: 0; batch classifier loss: 0.429909; batch adversarial loss: 0.589538\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374157; batch adversarial loss: 0.507538\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400070; batch adversarial loss: 0.570053\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357820; batch adversarial loss: 0.509611\n",
      "epoch 139; iter: 0; batch classifier loss: 0.404576; batch adversarial loss: 0.629057\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353920; batch adversarial loss: 0.534861\n",
      "epoch 141; iter: 0; batch classifier loss: 0.421519; batch adversarial loss: 0.594311\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371014; batch adversarial loss: 0.521170\n",
      "epoch 143; iter: 0; batch classifier loss: 0.335375; batch adversarial loss: 0.597653\n",
      "epoch 144; iter: 0; batch classifier loss: 0.375443; batch adversarial loss: 0.561927\n",
      "epoch 145; iter: 0; batch classifier loss: 0.410414; batch adversarial loss: 0.627917\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355443; batch adversarial loss: 0.603176\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394336; batch adversarial loss: 0.573063\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379184; batch adversarial loss: 0.607109\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315212; batch adversarial loss: 0.607627\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367459; batch adversarial loss: 0.541360\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334971; batch adversarial loss: 0.506086\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335683; batch adversarial loss: 0.498745\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335965; batch adversarial loss: 0.591025\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382092; batch adversarial loss: 0.608282\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366369; batch adversarial loss: 0.489920\n",
      "epoch 156; iter: 0; batch classifier loss: 0.343529; batch adversarial loss: 0.597269\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381481; batch adversarial loss: 0.529347\n",
      "epoch 158; iter: 0; batch classifier loss: 0.276586; batch adversarial loss: 0.509323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.283040; batch adversarial loss: 0.516053\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358649; batch adversarial loss: 0.562662\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343259; batch adversarial loss: 0.526959\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356595; batch adversarial loss: 0.554288\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327456; batch adversarial loss: 0.582713\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336534; batch adversarial loss: 0.603065\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365110; batch adversarial loss: 0.563423\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373215; batch adversarial loss: 0.527390\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366460; batch adversarial loss: 0.516760\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323855; batch adversarial loss: 0.552557\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390264; batch adversarial loss: 0.523417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.401631; batch adversarial loss: 0.450840\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330929; batch adversarial loss: 0.543341\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387784; batch adversarial loss: 0.472158\n",
      "epoch 173; iter: 0; batch classifier loss: 0.251982; batch adversarial loss: 0.444840\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310454; batch adversarial loss: 0.544218\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362752; batch adversarial loss: 0.544251\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347314; batch adversarial loss: 0.528066\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363673; batch adversarial loss: 0.500500\n",
      "epoch 178; iter: 0; batch classifier loss: 0.304834; batch adversarial loss: 0.517467\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340350; batch adversarial loss: 0.577332\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378389; batch adversarial loss: 0.572014\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374113; batch adversarial loss: 0.552893\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415299; batch adversarial loss: 0.609332\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370790; batch adversarial loss: 0.589613\n",
      "epoch 184; iter: 0; batch classifier loss: 0.291183; batch adversarial loss: 0.470209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356565; batch adversarial loss: 0.545248\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348052; batch adversarial loss: 0.618954\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385185; batch adversarial loss: 0.588037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337022; batch adversarial loss: 0.534297\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356303; batch adversarial loss: 0.535314\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385826; batch adversarial loss: 0.552983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363545; batch adversarial loss: 0.607399\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375720; batch adversarial loss: 0.560136\n",
      "epoch 193; iter: 0; batch classifier loss: 0.379124; batch adversarial loss: 0.556449\n",
      "epoch 194; iter: 0; batch classifier loss: 0.295483; batch adversarial loss: 0.479122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.313928; batch adversarial loss: 0.460520\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394536; batch adversarial loss: 0.497469\n",
      "epoch 197; iter: 0; batch classifier loss: 0.338997; batch adversarial loss: 0.517759\n",
      "epoch 198; iter: 0; batch classifier loss: 0.312978; batch adversarial loss: 0.539276\n",
      "epoch 199; iter: 0; batch classifier loss: 0.354464; batch adversarial loss: 0.535463\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736411; batch adversarial loss: 0.766446\n",
      "epoch 1; iter: 0; batch classifier loss: 0.620867; batch adversarial loss: 0.725656\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596256; batch adversarial loss: 0.701644\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577153; batch adversarial loss: 0.663256\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555676; batch adversarial loss: 0.636936\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586370; batch adversarial loss: 0.642488\n",
      "epoch 6; iter: 0; batch classifier loss: 0.611079; batch adversarial loss: 0.637342\n",
      "epoch 7; iter: 0; batch classifier loss: 0.502465; batch adversarial loss: 0.633136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.517291; batch adversarial loss: 0.602397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533386; batch adversarial loss: 0.548535\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511060; batch adversarial loss: 0.609528\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546885; batch adversarial loss: 0.550074\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513991; batch adversarial loss: 0.526277\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507952; batch adversarial loss: 0.596560\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483974; batch adversarial loss: 0.521174\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563896; batch adversarial loss: 0.546042\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553535; batch adversarial loss: 0.533571\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531866; batch adversarial loss: 0.565901\n",
      "epoch 18; iter: 0; batch classifier loss: 0.569708; batch adversarial loss: 0.664480\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487041; batch adversarial loss: 0.482499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471559; batch adversarial loss: 0.519257\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525939; batch adversarial loss: 0.501740\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492939; batch adversarial loss: 0.561339\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519551; batch adversarial loss: 0.600974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518598; batch adversarial loss: 0.593099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.507107; batch adversarial loss: 0.516011\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467862; batch adversarial loss: 0.522729\n",
      "epoch 27; iter: 0; batch classifier loss: 0.404797; batch adversarial loss: 0.553235\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523863; batch adversarial loss: 0.512086\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466636; batch adversarial loss: 0.565426\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478319; batch adversarial loss: 0.483939\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463357; batch adversarial loss: 0.592003\n",
      "epoch 32; iter: 0; batch classifier loss: 0.408457; batch adversarial loss: 0.602970\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466488; batch adversarial loss: 0.521109\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473268; batch adversarial loss: 0.534601\n",
      "epoch 35; iter: 0; batch classifier loss: 0.513358; batch adversarial loss: 0.562620\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471244; batch adversarial loss: 0.511462\n",
      "epoch 37; iter: 0; batch classifier loss: 0.396157; batch adversarial loss: 0.572284\n",
      "epoch 38; iter: 0; batch classifier loss: 0.376120; batch adversarial loss: 0.520329\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431560; batch adversarial loss: 0.521575\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462104; batch adversarial loss: 0.615975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.391905; batch adversarial loss: 0.562108\n",
      "epoch 42; iter: 0; batch classifier loss: 0.384840; batch adversarial loss: 0.494481\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362467; batch adversarial loss: 0.570830\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407044; batch adversarial loss: 0.600030\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437616; batch adversarial loss: 0.580395\n",
      "epoch 46; iter: 0; batch classifier loss: 0.472836; batch adversarial loss: 0.590004\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451378; batch adversarial loss: 0.545290\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397894; batch adversarial loss: 0.605209\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452969; batch adversarial loss: 0.556716\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392924; batch adversarial loss: 0.466273\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415319; batch adversarial loss: 0.504732\n",
      "epoch 52; iter: 0; batch classifier loss: 0.480894; batch adversarial loss: 0.579913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.493461; batch adversarial loss: 0.526445\n",
      "epoch 54; iter: 0; batch classifier loss: 0.471815; batch adversarial loss: 0.550101\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442367; batch adversarial loss: 0.625473\n",
      "epoch 56; iter: 0; batch classifier loss: 0.363560; batch adversarial loss: 0.574367\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422156; batch adversarial loss: 0.572670\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426091; batch adversarial loss: 0.489489\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427754; batch adversarial loss: 0.531486\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445406; batch adversarial loss: 0.491926\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409642; batch adversarial loss: 0.494971\n",
      "epoch 62; iter: 0; batch classifier loss: 0.460324; batch adversarial loss: 0.525723\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375771; batch adversarial loss: 0.497586\n",
      "epoch 64; iter: 0; batch classifier loss: 0.338866; batch adversarial loss: 0.506888\n",
      "epoch 65; iter: 0; batch classifier loss: 0.326258; batch adversarial loss: 0.514536\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381208; batch adversarial loss: 0.580760\n",
      "epoch 67; iter: 0; batch classifier loss: 0.343720; batch adversarial loss: 0.549167\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382494; batch adversarial loss: 0.548990\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357208; batch adversarial loss: 0.528687\n",
      "epoch 70; iter: 0; batch classifier loss: 0.372300; batch adversarial loss: 0.589357\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406336; batch adversarial loss: 0.517615\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400435; batch adversarial loss: 0.458004\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409488; batch adversarial loss: 0.472542\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387933; batch adversarial loss: 0.626404\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407334; batch adversarial loss: 0.644808\n",
      "epoch 76; iter: 0; batch classifier loss: 0.502793; batch adversarial loss: 0.563500\n",
      "epoch 77; iter: 0; batch classifier loss: 0.339992; batch adversarial loss: 0.562950\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394390; batch adversarial loss: 0.506113\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404672; batch adversarial loss: 0.477850\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374096; batch adversarial loss: 0.464427\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386781; batch adversarial loss: 0.553322\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378295; batch adversarial loss: 0.621242\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404312; batch adversarial loss: 0.594387\n",
      "epoch 84; iter: 0; batch classifier loss: 0.420214; batch adversarial loss: 0.526704\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434069; batch adversarial loss: 0.521457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.363794; batch adversarial loss: 0.534392\n",
      "epoch 87; iter: 0; batch classifier loss: 0.343681; batch adversarial loss: 0.552514\n",
      "epoch 88; iter: 0; batch classifier loss: 0.455890; batch adversarial loss: 0.563365\n",
      "epoch 89; iter: 0; batch classifier loss: 0.360486; batch adversarial loss: 0.554402\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396373; batch adversarial loss: 0.482887\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388567; batch adversarial loss: 0.489798\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402449; batch adversarial loss: 0.596487\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399082; batch adversarial loss: 0.652823\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342026; batch adversarial loss: 0.593283\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420743; batch adversarial loss: 0.558693\n",
      "epoch 96; iter: 0; batch classifier loss: 0.357959; batch adversarial loss: 0.546872\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416802; batch adversarial loss: 0.526428\n",
      "epoch 98; iter: 0; batch classifier loss: 0.316770; batch adversarial loss: 0.546161\n",
      "epoch 99; iter: 0; batch classifier loss: 0.391722; batch adversarial loss: 0.518033\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350928; batch adversarial loss: 0.480083\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352891; batch adversarial loss: 0.607812\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381049; batch adversarial loss: 0.529850\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412421; batch adversarial loss: 0.536808\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421032; batch adversarial loss: 0.572633\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389196; batch adversarial loss: 0.617854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.475898; batch adversarial loss: 0.499904\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322365; batch adversarial loss: 0.607245\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334004; batch adversarial loss: 0.574989\n",
      "epoch 109; iter: 0; batch classifier loss: 0.459637; batch adversarial loss: 0.524900\n",
      "epoch 110; iter: 0; batch classifier loss: 0.323629; batch adversarial loss: 0.575357\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369837; batch adversarial loss: 0.574003\n",
      "epoch 112; iter: 0; batch classifier loss: 0.264501; batch adversarial loss: 0.555178\n",
      "epoch 113; iter: 0; batch classifier loss: 0.430313; batch adversarial loss: 0.530080\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398605; batch adversarial loss: 0.535309\n",
      "epoch 115; iter: 0; batch classifier loss: 0.431416; batch adversarial loss: 0.565722\n",
      "epoch 116; iter: 0; batch classifier loss: 0.430076; batch adversarial loss: 0.580658\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357962; batch adversarial loss: 0.591974\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397284; batch adversarial loss: 0.496910\n",
      "epoch 119; iter: 0; batch classifier loss: 0.299525; batch adversarial loss: 0.549730\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380272; batch adversarial loss: 0.598714\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347215; batch adversarial loss: 0.491336\n",
      "epoch 122; iter: 0; batch classifier loss: 0.303167; batch adversarial loss: 0.586576\n",
      "epoch 123; iter: 0; batch classifier loss: 0.430602; batch adversarial loss: 0.466463\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354536; batch adversarial loss: 0.576781\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387714; batch adversarial loss: 0.589096\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381537; batch adversarial loss: 0.560264\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350799; batch adversarial loss: 0.574203\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365121; batch adversarial loss: 0.447683\n",
      "epoch 129; iter: 0; batch classifier loss: 0.302848; batch adversarial loss: 0.551035\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372934; batch adversarial loss: 0.517814\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340565; batch adversarial loss: 0.514423\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364411; batch adversarial loss: 0.576309\n",
      "epoch 133; iter: 0; batch classifier loss: 0.274786; batch adversarial loss: 0.585228\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344959; batch adversarial loss: 0.523257\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337303; batch adversarial loss: 0.511426\n",
      "epoch 136; iter: 0; batch classifier loss: 0.472139; batch adversarial loss: 0.579546\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327612; batch adversarial loss: 0.573478\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392064; batch adversarial loss: 0.543594\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340868; batch adversarial loss: 0.516313\n",
      "epoch 140; iter: 0; batch classifier loss: 0.293362; batch adversarial loss: 0.542095\n",
      "epoch 141; iter: 0; batch classifier loss: 0.385602; batch adversarial loss: 0.517333\n",
      "epoch 142; iter: 0; batch classifier loss: 0.407682; batch adversarial loss: 0.542218\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396069; batch adversarial loss: 0.622417\n",
      "epoch 144; iter: 0; batch classifier loss: 0.319400; batch adversarial loss: 0.586546\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369969; batch adversarial loss: 0.529449\n",
      "epoch 146; iter: 0; batch classifier loss: 0.440734; batch adversarial loss: 0.566249\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350909; batch adversarial loss: 0.583185\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310778; batch adversarial loss: 0.552843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361812; batch adversarial loss: 0.552238\n",
      "epoch 150; iter: 0; batch classifier loss: 0.249298; batch adversarial loss: 0.581970\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347697; batch adversarial loss: 0.532437\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373320; batch adversarial loss: 0.591952\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354184; batch adversarial loss: 0.578841\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379400; batch adversarial loss: 0.626944\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338555; batch adversarial loss: 0.554891\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382752; batch adversarial loss: 0.525315\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313875; batch adversarial loss: 0.535864\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363652; batch adversarial loss: 0.595886\n",
      "epoch 159; iter: 0; batch classifier loss: 0.304834; batch adversarial loss: 0.536906\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346084; batch adversarial loss: 0.569182\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397107; batch adversarial loss: 0.606326\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374889; batch adversarial loss: 0.532149\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348791; batch adversarial loss: 0.507609\n",
      "epoch 164; iter: 0; batch classifier loss: 0.347595; batch adversarial loss: 0.486499\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349483; batch adversarial loss: 0.601724\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340234; batch adversarial loss: 0.601785\n",
      "epoch 167; iter: 0; batch classifier loss: 0.313866; batch adversarial loss: 0.600620\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370566; batch adversarial loss: 0.592716\n",
      "epoch 169; iter: 0; batch classifier loss: 0.250170; batch adversarial loss: 0.534582\n",
      "epoch 170; iter: 0; batch classifier loss: 0.277094; batch adversarial loss: 0.501840\n",
      "epoch 171; iter: 0; batch classifier loss: 0.302260; batch adversarial loss: 0.575706\n",
      "epoch 172; iter: 0; batch classifier loss: 0.290668; batch adversarial loss: 0.491139\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333155; batch adversarial loss: 0.447779\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381618; batch adversarial loss: 0.546389\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384449; batch adversarial loss: 0.620034\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323416; batch adversarial loss: 0.547620\n",
      "epoch 177; iter: 0; batch classifier loss: 0.437691; batch adversarial loss: 0.522450\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295920; batch adversarial loss: 0.616249\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374878; batch adversarial loss: 0.534907\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408372; batch adversarial loss: 0.425026\n",
      "epoch 181; iter: 0; batch classifier loss: 0.407462; batch adversarial loss: 0.572927\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382702; batch adversarial loss: 0.637874\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363542; batch adversarial loss: 0.450599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.290146; batch adversarial loss: 0.552060\n",
      "epoch 185; iter: 0; batch classifier loss: 0.296606; batch adversarial loss: 0.566752\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368456; batch adversarial loss: 0.573796\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310019; batch adversarial loss: 0.556905\n",
      "epoch 188; iter: 0; batch classifier loss: 0.451447; batch adversarial loss: 0.524631\n",
      "epoch 189; iter: 0; batch classifier loss: 0.400261; batch adversarial loss: 0.558432\n",
      "epoch 190; iter: 0; batch classifier loss: 0.381857; batch adversarial loss: 0.511299\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356755; batch adversarial loss: 0.541684\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342666; batch adversarial loss: 0.505188\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403457; batch adversarial loss: 0.553025\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364090; batch adversarial loss: 0.580429\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319400; batch adversarial loss: 0.594865\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358836; batch adversarial loss: 0.553141\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326717; batch adversarial loss: 0.527903\n",
      "epoch 198; iter: 0; batch classifier loss: 0.316619; batch adversarial loss: 0.654140\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338185; batch adversarial loss: 0.534604\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694191; batch adversarial loss: 0.669736\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609814; batch adversarial loss: 0.639625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.558035; batch adversarial loss: 0.633562\n",
      "epoch 3; iter: 0; batch classifier loss: 0.545900; batch adversarial loss: 0.600736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546485; batch adversarial loss: 0.621861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548677; batch adversarial loss: 0.604426\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555612; batch adversarial loss: 0.617371\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541176; batch adversarial loss: 0.592814\n",
      "epoch 8; iter: 0; batch classifier loss: 0.636971; batch adversarial loss: 0.624879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582632; batch adversarial loss: 0.619427\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579053; batch adversarial loss: 0.557320\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538516; batch adversarial loss: 0.644427\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490458; batch adversarial loss: 0.543879\n",
      "epoch 13; iter: 0; batch classifier loss: 0.450065; batch adversarial loss: 0.576896\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506052; batch adversarial loss: 0.585286\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506314; batch adversarial loss: 0.553678\n",
      "epoch 16; iter: 0; batch classifier loss: 0.562873; batch adversarial loss: 0.548183\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535345; batch adversarial loss: 0.569201\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507402; batch adversarial loss: 0.595128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488743; batch adversarial loss: 0.559488\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572050; batch adversarial loss: 0.524939\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486062; batch adversarial loss: 0.533648\n",
      "epoch 22; iter: 0; batch classifier loss: 0.536065; batch adversarial loss: 0.600517\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521520; batch adversarial loss: 0.536985\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438406; batch adversarial loss: 0.510739\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434028; batch adversarial loss: 0.571804\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387527; batch adversarial loss: 0.578135\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450027; batch adversarial loss: 0.594109\n",
      "epoch 28; iter: 0; batch classifier loss: 0.521630; batch adversarial loss: 0.586527\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475785; batch adversarial loss: 0.554055\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427954; batch adversarial loss: 0.554044\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400434; batch adversarial loss: 0.518319\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403598; batch adversarial loss: 0.527525\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434261; batch adversarial loss: 0.589375\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416315; batch adversarial loss: 0.509694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498080; batch adversarial loss: 0.535684\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419019; batch adversarial loss: 0.481960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485481; batch adversarial loss: 0.517189\n",
      "epoch 38; iter: 0; batch classifier loss: 0.364473; batch adversarial loss: 0.554178\n",
      "epoch 39; iter: 0; batch classifier loss: 0.372161; batch adversarial loss: 0.633314\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471876; batch adversarial loss: 0.500456\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474843; batch adversarial loss: 0.580506\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418328; batch adversarial loss: 0.580853\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479754; batch adversarial loss: 0.526813\n",
      "epoch 44; iter: 0; batch classifier loss: 0.482956; batch adversarial loss: 0.490140\n",
      "epoch 45; iter: 0; batch classifier loss: 0.358461; batch adversarial loss: 0.490454\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400275; batch adversarial loss: 0.590723\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461727; batch adversarial loss: 0.535612\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423797; batch adversarial loss: 0.589256\n",
      "epoch 49; iter: 0; batch classifier loss: 0.370760; batch adversarial loss: 0.544997\n",
      "epoch 50; iter: 0; batch classifier loss: 0.405002; batch adversarial loss: 0.571658\n",
      "epoch 51; iter: 0; batch classifier loss: 0.402443; batch adversarial loss: 0.599178\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471270; batch adversarial loss: 0.526299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.491469; batch adversarial loss: 0.535197\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412069; batch adversarial loss: 0.508139\n",
      "epoch 55; iter: 0; batch classifier loss: 0.380064; batch adversarial loss: 0.535460\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450971; batch adversarial loss: 0.644873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405421; batch adversarial loss: 0.562601\n",
      "epoch 58; iter: 0; batch classifier loss: 0.416753; batch adversarial loss: 0.517219\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407104; batch adversarial loss: 0.581036\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374563; batch adversarial loss: 0.590419\n",
      "epoch 61; iter: 0; batch classifier loss: 0.393264; batch adversarial loss: 0.617178\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438357; batch adversarial loss: 0.636480\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396560; batch adversarial loss: 0.572007\n",
      "epoch 64; iter: 0; batch classifier loss: 0.458033; batch adversarial loss: 0.508197\n",
      "epoch 65; iter: 0; batch classifier loss: 0.363513; batch adversarial loss: 0.526043\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421349; batch adversarial loss: 0.461387\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417333; batch adversarial loss: 0.516099\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431544; batch adversarial loss: 0.628193\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371593; batch adversarial loss: 0.553332\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424388; batch adversarial loss: 0.581936\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402609; batch adversarial loss: 0.563430\n",
      "epoch 72; iter: 0; batch classifier loss: 0.489965; batch adversarial loss: 0.515173\n",
      "epoch 73; iter: 0; batch classifier loss: 0.416608; batch adversarial loss: 0.607245\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364628; batch adversarial loss: 0.545123\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408324; batch adversarial loss: 0.606592\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418490; batch adversarial loss: 0.449228\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423757; batch adversarial loss: 0.491148\n",
      "epoch 78; iter: 0; batch classifier loss: 0.481847; batch adversarial loss: 0.526133\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413063; batch adversarial loss: 0.541862\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431735; batch adversarial loss: 0.496973\n",
      "epoch 81; iter: 0; batch classifier loss: 0.327520; batch adversarial loss: 0.563699\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414579; batch adversarial loss: 0.635833\n",
      "epoch 83; iter: 0; batch classifier loss: 0.457052; batch adversarial loss: 0.553791\n",
      "epoch 84; iter: 0; batch classifier loss: 0.331239; batch adversarial loss: 0.528991\n",
      "epoch 85; iter: 0; batch classifier loss: 0.324340; batch adversarial loss: 0.597618\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435800; batch adversarial loss: 0.484002\n",
      "epoch 87; iter: 0; batch classifier loss: 0.407877; batch adversarial loss: 0.506470\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440378; batch adversarial loss: 0.554622\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365923; batch adversarial loss: 0.554492\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387001; batch adversarial loss: 0.510026\n",
      "epoch 91; iter: 0; batch classifier loss: 0.339533; batch adversarial loss: 0.517499\n",
      "epoch 92; iter: 0; batch classifier loss: 0.338798; batch adversarial loss: 0.509257\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378435; batch adversarial loss: 0.625358\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436877; batch adversarial loss: 0.553136\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387278; batch adversarial loss: 0.581622\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396599; batch adversarial loss: 0.625707\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434486; batch adversarial loss: 0.627065\n",
      "epoch 98; iter: 0; batch classifier loss: 0.353735; batch adversarial loss: 0.498958\n",
      "epoch 99; iter: 0; batch classifier loss: 0.306296; batch adversarial loss: 0.519307\n",
      "epoch 100; iter: 0; batch classifier loss: 0.343230; batch adversarial loss: 0.543573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.414303; batch adversarial loss: 0.554100\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362045; batch adversarial loss: 0.597716\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434444; batch adversarial loss: 0.537017\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389872; batch adversarial loss: 0.516694\n",
      "epoch 105; iter: 0; batch classifier loss: 0.403821; batch adversarial loss: 0.589525\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367298; batch adversarial loss: 0.626514\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405620; batch adversarial loss: 0.517107\n",
      "epoch 108; iter: 0; batch classifier loss: 0.425789; batch adversarial loss: 0.481435\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391218; batch adversarial loss: 0.570808\n",
      "epoch 110; iter: 0; batch classifier loss: 0.297724; batch adversarial loss: 0.625528\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367033; batch adversarial loss: 0.555112\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339816; batch adversarial loss: 0.500206\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381598; batch adversarial loss: 0.590807\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410575; batch adversarial loss: 0.573748\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372350; batch adversarial loss: 0.507412\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319500; batch adversarial loss: 0.535543\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384193; batch adversarial loss: 0.552679\n",
      "epoch 118; iter: 0; batch classifier loss: 0.415650; batch adversarial loss: 0.489586\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354965; batch adversarial loss: 0.570295\n",
      "epoch 120; iter: 0; batch classifier loss: 0.396123; batch adversarial loss: 0.570857\n",
      "epoch 121; iter: 0; batch classifier loss: 0.337240; batch adversarial loss: 0.507665\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355177; batch adversarial loss: 0.497552\n",
      "epoch 123; iter: 0; batch classifier loss: 0.432733; batch adversarial loss: 0.528479\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382852; batch adversarial loss: 0.483184\n",
      "epoch 125; iter: 0; batch classifier loss: 0.308741; batch adversarial loss: 0.636615\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400473; batch adversarial loss: 0.590123\n",
      "epoch 127; iter: 0; batch classifier loss: 0.506940; batch adversarial loss: 0.541139\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389458; batch adversarial loss: 0.534815\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355014; batch adversarial loss: 0.527958\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405281; batch adversarial loss: 0.590622\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336805; batch adversarial loss: 0.544185\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415956; batch adversarial loss: 0.497744\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396230; batch adversarial loss: 0.596742\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352819; batch adversarial loss: 0.517379\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360571; batch adversarial loss: 0.545042\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348214; batch adversarial loss: 0.449934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368787; batch adversarial loss: 0.506258\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335770; batch adversarial loss: 0.552388\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395268; batch adversarial loss: 0.517585\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309966; batch adversarial loss: 0.627120\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368200; batch adversarial loss: 0.553428\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371512; batch adversarial loss: 0.496112\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379013; batch adversarial loss: 0.581277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341799; batch adversarial loss: 0.574914\n",
      "epoch 145; iter: 0; batch classifier loss: 0.300201; batch adversarial loss: 0.519044\n",
      "epoch 146; iter: 0; batch classifier loss: 0.323384; batch adversarial loss: 0.453063\n",
      "epoch 147; iter: 0; batch classifier loss: 0.428094; batch adversarial loss: 0.541789\n",
      "epoch 148; iter: 0; batch classifier loss: 0.414640; batch adversarial loss: 0.554800\n",
      "epoch 149; iter: 0; batch classifier loss: 0.454561; batch adversarial loss: 0.667857\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337861; batch adversarial loss: 0.570828\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375141; batch adversarial loss: 0.571367\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354341; batch adversarial loss: 0.555236\n",
      "epoch 153; iter: 0; batch classifier loss: 0.277101; batch adversarial loss: 0.580286\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424188; batch adversarial loss: 0.554165\n",
      "epoch 155; iter: 0; batch classifier loss: 0.404377; batch adversarial loss: 0.598193\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358801; batch adversarial loss: 0.506418\n",
      "epoch 157; iter: 0; batch classifier loss: 0.387932; batch adversarial loss: 0.608454\n",
      "epoch 158; iter: 0; batch classifier loss: 0.282882; batch adversarial loss: 0.490414\n",
      "epoch 159; iter: 0; batch classifier loss: 0.310292; batch adversarial loss: 0.525664\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376187; batch adversarial loss: 0.537707\n",
      "epoch 161; iter: 0; batch classifier loss: 0.288074; batch adversarial loss: 0.515782\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347870; batch adversarial loss: 0.498273\n",
      "epoch 163; iter: 0; batch classifier loss: 0.288899; batch adversarial loss: 0.480344\n",
      "epoch 164; iter: 0; batch classifier loss: 0.309102; batch adversarial loss: 0.533596\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360667; batch adversarial loss: 0.589373\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310623; batch adversarial loss: 0.517607\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374740; batch adversarial loss: 0.510255\n",
      "epoch 168; iter: 0; batch classifier loss: 0.261738; batch adversarial loss: 0.517008\n",
      "epoch 169; iter: 0; batch classifier loss: 0.329816; batch adversarial loss: 0.554905\n",
      "epoch 170; iter: 0; batch classifier loss: 0.401742; batch adversarial loss: 0.555445\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334162; batch adversarial loss: 0.553051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.310930; batch adversarial loss: 0.489031\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357481; batch adversarial loss: 0.572985\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357480; batch adversarial loss: 0.564751\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368795; batch adversarial loss: 0.562285\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323022; batch adversarial loss: 0.499293\n",
      "epoch 177; iter: 0; batch classifier loss: 0.444181; batch adversarial loss: 0.480519\n",
      "epoch 178; iter: 0; batch classifier loss: 0.392405; batch adversarial loss: 0.479869\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380111; batch adversarial loss: 0.580128\n",
      "epoch 180; iter: 0; batch classifier loss: 0.403752; batch adversarial loss: 0.517646\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332874; batch adversarial loss: 0.517066\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314158; batch adversarial loss: 0.517664\n",
      "epoch 183; iter: 0; batch classifier loss: 0.420341; batch adversarial loss: 0.570864\n",
      "epoch 184; iter: 0; batch classifier loss: 0.295921; batch adversarial loss: 0.580175\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423426; batch adversarial loss: 0.533453\n",
      "epoch 186; iter: 0; batch classifier loss: 0.280216; batch adversarial loss: 0.534707\n",
      "epoch 187; iter: 0; batch classifier loss: 0.328124; batch adversarial loss: 0.551464\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356658; batch adversarial loss: 0.515605\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344645; batch adversarial loss: 0.590179\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346921; batch adversarial loss: 0.544370\n",
      "epoch 191; iter: 0; batch classifier loss: 0.415907; batch adversarial loss: 0.544702\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332404; batch adversarial loss: 0.519822\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376511; batch adversarial loss: 0.545713\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366897; batch adversarial loss: 0.582157\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357697; batch adversarial loss: 0.498627\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345956; batch adversarial loss: 0.498557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.403765; batch adversarial loss: 0.507592\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355288; batch adversarial loss: 0.515919\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360942; batch adversarial loss: 0.588302\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695659; batch adversarial loss: 0.718913\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591423; batch adversarial loss: 0.677961\n",
      "epoch 2; iter: 0; batch classifier loss: 0.516318; batch adversarial loss: 0.661068\n",
      "epoch 3; iter: 0; batch classifier loss: 0.521356; batch adversarial loss: 0.638228\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617224; batch adversarial loss: 0.620786\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617446; batch adversarial loss: 0.640229\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496302; batch adversarial loss: 0.578652\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582081; batch adversarial loss: 0.587479\n",
      "epoch 8; iter: 0; batch classifier loss: 0.594267; batch adversarial loss: 0.597182\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510957; batch adversarial loss: 0.591239\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479424; batch adversarial loss: 0.548670\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528563; batch adversarial loss: 0.598375\n",
      "epoch 12; iter: 0; batch classifier loss: 0.561706; batch adversarial loss: 0.613305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522937; batch adversarial loss: 0.587147\n",
      "epoch 14; iter: 0; batch classifier loss: 0.587018; batch adversarial loss: 0.560451\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494079; batch adversarial loss: 0.580099\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592680; batch adversarial loss: 0.518358\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560612; batch adversarial loss: 0.551813\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471232; batch adversarial loss: 0.555069\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536373; batch adversarial loss: 0.551939\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518339; batch adversarial loss: 0.536023\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519080; batch adversarial loss: 0.552948\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496463; batch adversarial loss: 0.535026\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467219; batch adversarial loss: 0.542323\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468186; batch adversarial loss: 0.540805\n",
      "epoch 25; iter: 0; batch classifier loss: 0.554702; batch adversarial loss: 0.516288\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433140; batch adversarial loss: 0.579069\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478873; batch adversarial loss: 0.520896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.558634; batch adversarial loss: 0.503546\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504130; batch adversarial loss: 0.619949\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522578; batch adversarial loss: 0.588226\n",
      "epoch 31; iter: 0; batch classifier loss: 0.549166; batch adversarial loss: 0.544008\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435174; batch adversarial loss: 0.546285\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480107; batch adversarial loss: 0.537380\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497447; batch adversarial loss: 0.597347\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442253; batch adversarial loss: 0.563470\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486395; batch adversarial loss: 0.502903\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452951; batch adversarial loss: 0.579198\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464523; batch adversarial loss: 0.625121\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474601; batch adversarial loss: 0.535459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367799; batch adversarial loss: 0.501031\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450323; batch adversarial loss: 0.544974\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458570; batch adversarial loss: 0.490953\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482089; batch adversarial loss: 0.581342\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490435; batch adversarial loss: 0.552765\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417007; batch adversarial loss: 0.507475\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405916; batch adversarial loss: 0.517233\n",
      "epoch 47; iter: 0; batch classifier loss: 0.481379; batch adversarial loss: 0.517736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393068; batch adversarial loss: 0.517917\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442772; batch adversarial loss: 0.508257\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461748; batch adversarial loss: 0.571181\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427857; batch adversarial loss: 0.518313\n",
      "epoch 52; iter: 0; batch classifier loss: 0.499915; batch adversarial loss: 0.607418\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471658; batch adversarial loss: 0.517256\n",
      "epoch 54; iter: 0; batch classifier loss: 0.459749; batch adversarial loss: 0.607836\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412618; batch adversarial loss: 0.580491\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416774; batch adversarial loss: 0.489242\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439779; batch adversarial loss: 0.571388\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403038; batch adversarial loss: 0.588748\n",
      "epoch 59; iter: 0; batch classifier loss: 0.436989; batch adversarial loss: 0.527102\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442186; batch adversarial loss: 0.571667\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464912; batch adversarial loss: 0.571154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433084; batch adversarial loss: 0.544555\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375470; batch adversarial loss: 0.643202\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398121; batch adversarial loss: 0.509353\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432072; batch adversarial loss: 0.473114\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438760; batch adversarial loss: 0.607512\n",
      "epoch 67; iter: 0; batch classifier loss: 0.568557; batch adversarial loss: 0.616596\n",
      "epoch 68; iter: 0; batch classifier loss: 0.372033; batch adversarial loss: 0.508432\n",
      "epoch 69; iter: 0; batch classifier loss: 0.362376; batch adversarial loss: 0.562021\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393491; batch adversarial loss: 0.590023\n",
      "epoch 71; iter: 0; batch classifier loss: 0.455700; batch adversarial loss: 0.610276\n",
      "epoch 72; iter: 0; batch classifier loss: 0.342223; batch adversarial loss: 0.507601\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417973; batch adversarial loss: 0.500554\n",
      "epoch 74; iter: 0; batch classifier loss: 0.400628; batch adversarial loss: 0.516971\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384958; batch adversarial loss: 0.545189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375452; batch adversarial loss: 0.527025\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379888; batch adversarial loss: 0.563287\n",
      "epoch 78; iter: 0; batch classifier loss: 0.490773; batch adversarial loss: 0.510074\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374702; batch adversarial loss: 0.508561\n",
      "epoch 80; iter: 0; batch classifier loss: 0.504040; batch adversarial loss: 0.598452\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388301; batch adversarial loss: 0.517690\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359416; batch adversarial loss: 0.508860\n",
      "epoch 83; iter: 0; batch classifier loss: 0.362799; batch adversarial loss: 0.535010\n",
      "epoch 84; iter: 0; batch classifier loss: 0.491243; batch adversarial loss: 0.508295\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427827; batch adversarial loss: 0.525907\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391879; batch adversarial loss: 0.525592\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410010; batch adversarial loss: 0.536190\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357711; batch adversarial loss: 0.572516\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382798; batch adversarial loss: 0.525577\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418560; batch adversarial loss: 0.554338\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390621; batch adversarial loss: 0.472591\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384775; batch adversarial loss: 0.545458\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341856; batch adversarial loss: 0.465334\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408989; batch adversarial loss: 0.589862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.431023; batch adversarial loss: 0.524913\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417663; batch adversarial loss: 0.562062\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399129; batch adversarial loss: 0.579063\n",
      "epoch 98; iter: 0; batch classifier loss: 0.481139; batch adversarial loss: 0.535573\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436639; batch adversarial loss: 0.582839\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350677; batch adversarial loss: 0.512225\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349086; batch adversarial loss: 0.617528\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437913; batch adversarial loss: 0.616206\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355095; batch adversarial loss: 0.534764\n",
      "epoch 104; iter: 0; batch classifier loss: 0.427711; batch adversarial loss: 0.626065\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405114; batch adversarial loss: 0.489163\n",
      "epoch 106; iter: 0; batch classifier loss: 0.321763; batch adversarial loss: 0.544186\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365457; batch adversarial loss: 0.672318\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391063; batch adversarial loss: 0.544763\n",
      "epoch 109; iter: 0; batch classifier loss: 0.452211; batch adversarial loss: 0.581949\n",
      "epoch 110; iter: 0; batch classifier loss: 0.491928; batch adversarial loss: 0.571432\n",
      "epoch 111; iter: 0; batch classifier loss: 0.501813; batch adversarial loss: 0.487631\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403805; batch adversarial loss: 0.608076\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387352; batch adversarial loss: 0.607849\n",
      "epoch 114; iter: 0; batch classifier loss: 0.473540; batch adversarial loss: 0.580029\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379509; batch adversarial loss: 0.596956\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427275; batch adversarial loss: 0.617680\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394218; batch adversarial loss: 0.545647\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394632; batch adversarial loss: 0.580877\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349734; batch adversarial loss: 0.545299\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357470; batch adversarial loss: 0.607053\n",
      "epoch 121; iter: 0; batch classifier loss: 0.447108; batch adversarial loss: 0.543968\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327352; batch adversarial loss: 0.542861\n",
      "epoch 123; iter: 0; batch classifier loss: 0.428134; batch adversarial loss: 0.474627\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326289; batch adversarial loss: 0.544713\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380681; batch adversarial loss: 0.517557\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424821; batch adversarial loss: 0.606203\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388208; batch adversarial loss: 0.598431\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344288; batch adversarial loss: 0.517168\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355064; batch adversarial loss: 0.582102\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342262; batch adversarial loss: 0.589040\n",
      "epoch 131; iter: 0; batch classifier loss: 0.426493; batch adversarial loss: 0.526519\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414912; batch adversarial loss: 0.574279\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390707; batch adversarial loss: 0.534127\n",
      "epoch 134; iter: 0; batch classifier loss: 0.497957; batch adversarial loss: 0.559521\n",
      "epoch 135; iter: 0; batch classifier loss: 0.412383; batch adversarial loss: 0.535785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338424; batch adversarial loss: 0.598171\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353516; batch adversarial loss: 0.543185\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370872; batch adversarial loss: 0.517855\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390352; batch adversarial loss: 0.561514\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401462; batch adversarial loss: 0.499076\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346812; batch adversarial loss: 0.500317\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362285; batch adversarial loss: 0.517987\n",
      "epoch 143; iter: 0; batch classifier loss: 0.302290; batch adversarial loss: 0.527965\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349079; batch adversarial loss: 0.490577\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359791; batch adversarial loss: 0.516859\n",
      "epoch 146; iter: 0; batch classifier loss: 0.408463; batch adversarial loss: 0.572153\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340442; batch adversarial loss: 0.580719\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375021; batch adversarial loss: 0.561653\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315173; batch adversarial loss: 0.517447\n",
      "epoch 150; iter: 0; batch classifier loss: 0.374670; batch adversarial loss: 0.534959\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409866; batch adversarial loss: 0.481690\n",
      "epoch 152; iter: 0; batch classifier loss: 0.337502; batch adversarial loss: 0.580743\n",
      "epoch 153; iter: 0; batch classifier loss: 0.323564; batch adversarial loss: 0.525945\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373745; batch adversarial loss: 0.544016\n",
      "epoch 155; iter: 0; batch classifier loss: 0.385686; batch adversarial loss: 0.554726\n",
      "epoch 156; iter: 0; batch classifier loss: 0.459681; batch adversarial loss: 0.517372\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360252; batch adversarial loss: 0.472046\n",
      "epoch 158; iter: 0; batch classifier loss: 0.411816; batch adversarial loss: 0.535873\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343933; batch adversarial loss: 0.525879\n",
      "epoch 160; iter: 0; batch classifier loss: 0.402964; batch adversarial loss: 0.536646\n",
      "epoch 161; iter: 0; batch classifier loss: 0.438759; batch adversarial loss: 0.589670\n",
      "epoch 162; iter: 0; batch classifier loss: 0.403962; batch adversarial loss: 0.573629\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344073; batch adversarial loss: 0.552618\n",
      "epoch 164; iter: 0; batch classifier loss: 0.432067; batch adversarial loss: 0.555337\n",
      "epoch 165; iter: 0; batch classifier loss: 0.428983; batch adversarial loss: 0.500058\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368556; batch adversarial loss: 0.561999\n",
      "epoch 167; iter: 0; batch classifier loss: 0.424275; batch adversarial loss: 0.616070\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342559; batch adversarial loss: 0.473061\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364440; batch adversarial loss: 0.634751\n",
      "epoch 170; iter: 0; batch classifier loss: 0.413150; batch adversarial loss: 0.555195\n",
      "epoch 171; iter: 0; batch classifier loss: 0.304355; batch adversarial loss: 0.490177\n",
      "epoch 172; iter: 0; batch classifier loss: 0.267808; batch adversarial loss: 0.481851\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382717; batch adversarial loss: 0.563315\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321410; batch adversarial loss: 0.517409\n",
      "epoch 175; iter: 0; batch classifier loss: 0.290450; batch adversarial loss: 0.527048\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360173; batch adversarial loss: 0.562347\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318061; batch adversarial loss: 0.491614\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331777; batch adversarial loss: 0.570058\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358488; batch adversarial loss: 0.526893\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372465; batch adversarial loss: 0.562038\n",
      "epoch 181; iter: 0; batch classifier loss: 0.443196; batch adversarial loss: 0.627620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359581; batch adversarial loss: 0.552718\n",
      "epoch 183; iter: 0; batch classifier loss: 0.308353; batch adversarial loss: 0.571153\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353092; batch adversarial loss: 0.510517\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342532; batch adversarial loss: 0.562831\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366491; batch adversarial loss: 0.553327\n",
      "epoch 187; iter: 0; batch classifier loss: 0.304566; batch adversarial loss: 0.516592\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406077; batch adversarial loss: 0.552865\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355533; batch adversarial loss: 0.526894\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359866; batch adversarial loss: 0.525954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.396913; batch adversarial loss: 0.563458\n",
      "epoch 192; iter: 0; batch classifier loss: 0.413314; batch adversarial loss: 0.553474\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369706; batch adversarial loss: 0.454433\n",
      "epoch 194; iter: 0; batch classifier loss: 0.433097; batch adversarial loss: 0.534076\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360991; batch adversarial loss: 0.453523\n",
      "epoch 196; iter: 0; batch classifier loss: 0.293816; batch adversarial loss: 0.527633\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318025; batch adversarial loss: 0.551790\n",
      "epoch 198; iter: 0; batch classifier loss: 0.400383; batch adversarial loss: 0.499631\n",
      "epoch 199; iter: 0; batch classifier loss: 0.414485; batch adversarial loss: 0.517228\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661495; batch adversarial loss: 0.608362\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607553; batch adversarial loss: 0.646089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575279; batch adversarial loss: 0.622467\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575935; batch adversarial loss: 0.602652\n",
      "epoch 4; iter: 0; batch classifier loss: 0.511355; batch adversarial loss: 0.659586\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595700; batch adversarial loss: 0.623166\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520253; batch adversarial loss: 0.679298\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615706; batch adversarial loss: 0.626198\n",
      "epoch 8; iter: 0; batch classifier loss: 0.641736; batch adversarial loss: 0.634049\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499865; batch adversarial loss: 0.649065\n",
      "epoch 10; iter: 0; batch classifier loss: 0.593668; batch adversarial loss: 0.673463\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539658; batch adversarial loss: 0.615649\n",
      "epoch 12; iter: 0; batch classifier loss: 0.596651; batch adversarial loss: 0.545532\n",
      "epoch 13; iter: 0; batch classifier loss: 0.576561; batch adversarial loss: 0.582350\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543899; batch adversarial loss: 0.550635\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477147; batch adversarial loss: 0.568491\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533623; batch adversarial loss: 0.549899\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554744; batch adversarial loss: 0.635663\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526839; batch adversarial loss: 0.616329\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440442; batch adversarial loss: 0.589666\n",
      "epoch 20; iter: 0; batch classifier loss: 0.596253; batch adversarial loss: 0.541125\n",
      "epoch 21; iter: 0; batch classifier loss: 0.534448; batch adversarial loss: 0.491236\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447667; batch adversarial loss: 0.547991\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464070; batch adversarial loss: 0.554079\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488439; batch adversarial loss: 0.549205\n",
      "epoch 25; iter: 0; batch classifier loss: 0.542589; batch adversarial loss: 0.539795\n",
      "epoch 26; iter: 0; batch classifier loss: 0.481741; batch adversarial loss: 0.506807\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443973; batch adversarial loss: 0.520046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513316; batch adversarial loss: 0.528761\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475581; batch adversarial loss: 0.622501\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550146; batch adversarial loss: 0.546483\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470977; batch adversarial loss: 0.502904\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470363; batch adversarial loss: 0.571645\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463997; batch adversarial loss: 0.571949\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491718; batch adversarial loss: 0.519789\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475289; batch adversarial loss: 0.562451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.511392; batch adversarial loss: 0.580698\n",
      "epoch 37; iter: 0; batch classifier loss: 0.563901; batch adversarial loss: 0.562929\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498774; batch adversarial loss: 0.562196\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454300; batch adversarial loss: 0.580220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450956; batch adversarial loss: 0.562271\n",
      "epoch 41; iter: 0; batch classifier loss: 0.492895; batch adversarial loss: 0.535810\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436389; batch adversarial loss: 0.526875\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489190; batch adversarial loss: 0.544494\n",
      "epoch 44; iter: 0; batch classifier loss: 0.354585; batch adversarial loss: 0.571809\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469290; batch adversarial loss: 0.480952\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381935; batch adversarial loss: 0.608413\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410079; batch adversarial loss: 0.535302\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398415; batch adversarial loss: 0.535629\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463467; batch adversarial loss: 0.571536\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411686; batch adversarial loss: 0.526558\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405306; batch adversarial loss: 0.489528\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441992; batch adversarial loss: 0.661820\n",
      "epoch 53; iter: 0; batch classifier loss: 0.558530; batch adversarial loss: 0.581263\n",
      "epoch 54; iter: 0; batch classifier loss: 0.493517; batch adversarial loss: 0.499399\n",
      "epoch 55; iter: 0; batch classifier loss: 0.356138; batch adversarial loss: 0.434661\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456109; batch adversarial loss: 0.572551\n",
      "epoch 57; iter: 0; batch classifier loss: 0.511527; batch adversarial loss: 0.618142\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415297; batch adversarial loss: 0.625933\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427436; batch adversarial loss: 0.417845\n",
      "epoch 60; iter: 0; batch classifier loss: 0.361033; batch adversarial loss: 0.590600\n",
      "epoch 61; iter: 0; batch classifier loss: 0.490324; batch adversarial loss: 0.562879\n",
      "epoch 62; iter: 0; batch classifier loss: 0.501717; batch adversarial loss: 0.569017\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429730; batch adversarial loss: 0.516136\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427640; batch adversarial loss: 0.561403\n",
      "epoch 65; iter: 0; batch classifier loss: 0.460180; batch adversarial loss: 0.589085\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385832; batch adversarial loss: 0.533778\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408418; batch adversarial loss: 0.491073\n",
      "epoch 68; iter: 0; batch classifier loss: 0.385899; batch adversarial loss: 0.463296\n",
      "epoch 69; iter: 0; batch classifier loss: 0.469007; batch adversarial loss: 0.554881\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378268; batch adversarial loss: 0.599002\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411706; batch adversarial loss: 0.571904\n",
      "epoch 72; iter: 0; batch classifier loss: 0.436584; batch adversarial loss: 0.651921\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438980; batch adversarial loss: 0.616829\n",
      "epoch 74; iter: 0; batch classifier loss: 0.451342; batch adversarial loss: 0.509100\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427058; batch adversarial loss: 0.489744\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400687; batch adversarial loss: 0.563820\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442816; batch adversarial loss: 0.609563\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441729; batch adversarial loss: 0.516935\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379257; batch adversarial loss: 0.518319\n",
      "epoch 80; iter: 0; batch classifier loss: 0.462335; batch adversarial loss: 0.461144\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422102; batch adversarial loss: 0.573115\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399353; batch adversarial loss: 0.543368\n",
      "epoch 83; iter: 0; batch classifier loss: 0.500832; batch adversarial loss: 0.562278\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401258; batch adversarial loss: 0.509669\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352170; batch adversarial loss: 0.516485\n",
      "epoch 86; iter: 0; batch classifier loss: 0.441726; batch adversarial loss: 0.501135\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365012; batch adversarial loss: 0.668800\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405396; batch adversarial loss: 0.543758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.342773; batch adversarial loss: 0.586876\n",
      "epoch 90; iter: 0; batch classifier loss: 0.462955; batch adversarial loss: 0.581995\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358631; batch adversarial loss: 0.554461\n",
      "epoch 92; iter: 0; batch classifier loss: 0.438501; batch adversarial loss: 0.456794\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368921; batch adversarial loss: 0.481908\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410256; batch adversarial loss: 0.551861\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361279; batch adversarial loss: 0.461847\n",
      "epoch 96; iter: 0; batch classifier loss: 0.321769; batch adversarial loss: 0.563152\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423460; batch adversarial loss: 0.566184\n",
      "epoch 98; iter: 0; batch classifier loss: 0.447458; batch adversarial loss: 0.525403\n",
      "epoch 99; iter: 0; batch classifier loss: 0.352287; batch adversarial loss: 0.501072\n",
      "epoch 100; iter: 0; batch classifier loss: 0.442133; batch adversarial loss: 0.638085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371789; batch adversarial loss: 0.571903\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380444; batch adversarial loss: 0.470524\n",
      "epoch 103; iter: 0; batch classifier loss: 0.431844; batch adversarial loss: 0.578987\n",
      "epoch 104; iter: 0; batch classifier loss: 0.379360; batch adversarial loss: 0.534498\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362979; batch adversarial loss: 0.471879\n",
      "epoch 106; iter: 0; batch classifier loss: 0.292423; batch adversarial loss: 0.580148\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399527; batch adversarial loss: 0.564494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398399; batch adversarial loss: 0.550544\n",
      "epoch 109; iter: 0; batch classifier loss: 0.395312; batch adversarial loss: 0.562624\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368708; batch adversarial loss: 0.481261\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350061; batch adversarial loss: 0.525660\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405697; batch adversarial loss: 0.462437\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389545; batch adversarial loss: 0.524342\n",
      "epoch 114; iter: 0; batch classifier loss: 0.434694; batch adversarial loss: 0.546507\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333077; batch adversarial loss: 0.570176\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364563; batch adversarial loss: 0.534646\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338468; batch adversarial loss: 0.571032\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395712; batch adversarial loss: 0.617547\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370672; batch adversarial loss: 0.554916\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349642; batch adversarial loss: 0.560861\n",
      "epoch 121; iter: 0; batch classifier loss: 0.434686; batch adversarial loss: 0.616530\n",
      "epoch 122; iter: 0; batch classifier loss: 0.467542; batch adversarial loss: 0.516347\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396624; batch adversarial loss: 0.489543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.413864; batch adversarial loss: 0.524666\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383958; batch adversarial loss: 0.444190\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336882; batch adversarial loss: 0.570911\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353345; batch adversarial loss: 0.601525\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364790; batch adversarial loss: 0.581256\n",
      "epoch 129; iter: 0; batch classifier loss: 0.303391; batch adversarial loss: 0.479043\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393311; batch adversarial loss: 0.519964\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427144; batch adversarial loss: 0.524893\n",
      "epoch 132; iter: 0; batch classifier loss: 0.496884; batch adversarial loss: 0.553356\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372808; batch adversarial loss: 0.577365\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356827; batch adversarial loss: 0.527797\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350445; batch adversarial loss: 0.580373\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357988; batch adversarial loss: 0.563141\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377816; batch adversarial loss: 0.508008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375377; batch adversarial loss: 0.546360\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386771; batch adversarial loss: 0.525517\n",
      "epoch 140; iter: 0; batch classifier loss: 0.304566; batch adversarial loss: 0.583534\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367836; batch adversarial loss: 0.527972\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420861; batch adversarial loss: 0.534075\n",
      "epoch 143; iter: 0; batch classifier loss: 0.344245; batch adversarial loss: 0.588971\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337935; batch adversarial loss: 0.545046\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365362; batch adversarial loss: 0.599679\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365027; batch adversarial loss: 0.600136\n",
      "epoch 147; iter: 0; batch classifier loss: 0.456031; batch adversarial loss: 0.561775\n",
      "epoch 148; iter: 0; batch classifier loss: 0.467003; batch adversarial loss: 0.592303\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382927; batch adversarial loss: 0.506954\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343947; batch adversarial loss: 0.443728\n",
      "epoch 151; iter: 0; batch classifier loss: 0.393206; batch adversarial loss: 0.582289\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385020; batch adversarial loss: 0.590704\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380717; batch adversarial loss: 0.523288\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378053; batch adversarial loss: 0.580758\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388835; batch adversarial loss: 0.532832\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352018; batch adversarial loss: 0.588056\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356136; batch adversarial loss: 0.580073\n",
      "epoch 158; iter: 0; batch classifier loss: 0.500761; batch adversarial loss: 0.603852\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325669; batch adversarial loss: 0.571240\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323015; batch adversarial loss: 0.526787\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408088; batch adversarial loss: 0.569634\n",
      "epoch 162; iter: 0; batch classifier loss: 0.416792; batch adversarial loss: 0.527727\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335489; batch adversarial loss: 0.543904\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353622; batch adversarial loss: 0.453495\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353248; batch adversarial loss: 0.561511\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350392; batch adversarial loss: 0.602453\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343514; batch adversarial loss: 0.537546\n",
      "epoch 168; iter: 0; batch classifier loss: 0.432317; batch adversarial loss: 0.437187\n",
      "epoch 169; iter: 0; batch classifier loss: 0.274715; batch adversarial loss: 0.489119\n",
      "epoch 170; iter: 0; batch classifier loss: 0.416381; batch adversarial loss: 0.535127\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321323; batch adversarial loss: 0.562160\n",
      "epoch 172; iter: 0; batch classifier loss: 0.403160; batch adversarial loss: 0.614671\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365614; batch adversarial loss: 0.563012\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357424; batch adversarial loss: 0.491092\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342323; batch adversarial loss: 0.561683\n",
      "epoch 176; iter: 0; batch classifier loss: 0.261980; batch adversarial loss: 0.470435\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360693; batch adversarial loss: 0.555142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.410906; batch adversarial loss: 0.534859\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369958; batch adversarial loss: 0.659141\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392903; batch adversarial loss: 0.517507\n",
      "epoch 181; iter: 0; batch classifier loss: 0.467278; batch adversarial loss: 0.536950\n",
      "epoch 182; iter: 0; batch classifier loss: 0.271596; batch adversarial loss: 0.589011\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364756; batch adversarial loss: 0.552235\n",
      "epoch 184; iter: 0; batch classifier loss: 0.411380; batch adversarial loss: 0.560205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.510747; batch adversarial loss: 0.536031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368472; batch adversarial loss: 0.479753\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339450; batch adversarial loss: 0.544161\n",
      "epoch 188; iter: 0; batch classifier loss: 0.400429; batch adversarial loss: 0.627533\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336245; batch adversarial loss: 0.563748\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333159; batch adversarial loss: 0.534560\n",
      "epoch 191; iter: 0; batch classifier loss: 0.371362; batch adversarial loss: 0.497516\n",
      "epoch 192; iter: 0; batch classifier loss: 0.280434; batch adversarial loss: 0.508358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414879; batch adversarial loss: 0.600361\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315700; batch adversarial loss: 0.524583\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327229; batch adversarial loss: 0.554016\n",
      "epoch 196; iter: 0; batch classifier loss: 0.427808; batch adversarial loss: 0.591360\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339926; batch adversarial loss: 0.620912\n",
      "epoch 198; iter: 0; batch classifier loss: 0.416526; batch adversarial loss: 0.534390\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367430; batch adversarial loss: 0.587663\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700953; batch adversarial loss: 0.543181\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582125; batch adversarial loss: 0.605211\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591441; batch adversarial loss: 0.685049\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594370; batch adversarial loss: 0.663706\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517662; batch adversarial loss: 0.670239\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601665; batch adversarial loss: 0.659651\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578996; batch adversarial loss: 0.687223\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586176; batch adversarial loss: 0.587529\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476422; batch adversarial loss: 0.586537\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545139; batch adversarial loss: 0.565777\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512461; batch adversarial loss: 0.613400\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545710; batch adversarial loss: 0.576566\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545934; batch adversarial loss: 0.601368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.454015; batch adversarial loss: 0.502000\n",
      "epoch 14; iter: 0; batch classifier loss: 0.623944; batch adversarial loss: 0.594782\n",
      "epoch 15; iter: 0; batch classifier loss: 0.636889; batch adversarial loss: 0.539818\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533370; batch adversarial loss: 0.557631\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469501; batch adversarial loss: 0.547617\n",
      "epoch 18; iter: 0; batch classifier loss: 0.448768; batch adversarial loss: 0.493521\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506698; batch adversarial loss: 0.504518\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495226; batch adversarial loss: 0.610582\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519577; batch adversarial loss: 0.547881\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533056; batch adversarial loss: 0.515684\n",
      "epoch 23; iter: 0; batch classifier loss: 0.552633; batch adversarial loss: 0.582331\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455553; batch adversarial loss: 0.486027\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498863; batch adversarial loss: 0.503081\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474548; batch adversarial loss: 0.587992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473227; batch adversarial loss: 0.545057\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480485; batch adversarial loss: 0.518920\n",
      "epoch 29; iter: 0; batch classifier loss: 0.543169; batch adversarial loss: 0.564746\n",
      "epoch 30; iter: 0; batch classifier loss: 0.556858; batch adversarial loss: 0.587926\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455771; batch adversarial loss: 0.544799\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469064; batch adversarial loss: 0.553508\n",
      "epoch 33; iter: 0; batch classifier loss: 0.558108; batch adversarial loss: 0.552822\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429514; batch adversarial loss: 0.562168\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484883; batch adversarial loss: 0.508452\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471134; batch adversarial loss: 0.571170\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469868; batch adversarial loss: 0.509291\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431835; batch adversarial loss: 0.482578\n",
      "epoch 39; iter: 0; batch classifier loss: 0.492628; batch adversarial loss: 0.606637\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462029; batch adversarial loss: 0.500539\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466089; batch adversarial loss: 0.492770\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466695; batch adversarial loss: 0.502169\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431695; batch adversarial loss: 0.499639\n",
      "epoch 44; iter: 0; batch classifier loss: 0.391258; batch adversarial loss: 0.481219\n",
      "epoch 45; iter: 0; batch classifier loss: 0.505881; batch adversarial loss: 0.536211\n",
      "epoch 46; iter: 0; batch classifier loss: 0.375428; batch adversarial loss: 0.507816\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457887; batch adversarial loss: 0.628034\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389049; batch adversarial loss: 0.544707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422389; batch adversarial loss: 0.507699\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394836; batch adversarial loss: 0.544834\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448222; batch adversarial loss: 0.571934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.514656; batch adversarial loss: 0.608131\n",
      "epoch 53; iter: 0; batch classifier loss: 0.502429; batch adversarial loss: 0.508283\n",
      "epoch 54; iter: 0; batch classifier loss: 0.363687; batch adversarial loss: 0.572247\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465312; batch adversarial loss: 0.526019\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457792; batch adversarial loss: 0.634756\n",
      "epoch 57; iter: 0; batch classifier loss: 0.470343; batch adversarial loss: 0.499599\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429889; batch adversarial loss: 0.518143\n",
      "epoch 59; iter: 0; batch classifier loss: 0.405476; batch adversarial loss: 0.517909\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365733; batch adversarial loss: 0.579938\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388306; batch adversarial loss: 0.454182\n",
      "epoch 62; iter: 0; batch classifier loss: 0.371242; batch adversarial loss: 0.544173\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370742; batch adversarial loss: 0.553287\n",
      "epoch 64; iter: 0; batch classifier loss: 0.448347; batch adversarial loss: 0.444446\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369751; batch adversarial loss: 0.596376\n",
      "epoch 66; iter: 0; batch classifier loss: 0.341566; batch adversarial loss: 0.544742\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408550; batch adversarial loss: 0.553879\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402177; batch adversarial loss: 0.562904\n",
      "epoch 69; iter: 0; batch classifier loss: 0.345938; batch adversarial loss: 0.535585\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459398; batch adversarial loss: 0.526550\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411423; batch adversarial loss: 0.508471\n",
      "epoch 72; iter: 0; batch classifier loss: 0.471950; batch adversarial loss: 0.563363\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426753; batch adversarial loss: 0.609470\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396855; batch adversarial loss: 0.618035\n",
      "epoch 75; iter: 0; batch classifier loss: 0.348511; batch adversarial loss: 0.526715\n",
      "epoch 76; iter: 0; batch classifier loss: 0.360490; batch adversarial loss: 0.554097\n",
      "epoch 77; iter: 0; batch classifier loss: 0.568884; batch adversarial loss: 0.525725\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396628; batch adversarial loss: 0.615544\n",
      "epoch 79; iter: 0; batch classifier loss: 0.473449; batch adversarial loss: 0.545197\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392870; batch adversarial loss: 0.653986\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382470; batch adversarial loss: 0.453633\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387983; batch adversarial loss: 0.524908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.380210; batch adversarial loss: 0.535594\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371840; batch adversarial loss: 0.535473\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438398; batch adversarial loss: 0.553342\n",
      "epoch 86; iter: 0; batch classifier loss: 0.423854; batch adversarial loss: 0.552050\n",
      "epoch 87; iter: 0; batch classifier loss: 0.454673; batch adversarial loss: 0.562989\n",
      "epoch 88; iter: 0; batch classifier loss: 0.323050; batch adversarial loss: 0.545488\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400226; batch adversarial loss: 0.589265\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349685; batch adversarial loss: 0.661941\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409884; batch adversarial loss: 0.553131\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387235; batch adversarial loss: 0.507582\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380851; batch adversarial loss: 0.464299\n",
      "epoch 94; iter: 0; batch classifier loss: 0.334015; batch adversarial loss: 0.654593\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364092; batch adversarial loss: 0.517674\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417224; batch adversarial loss: 0.536330\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358100; batch adversarial loss: 0.489129\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368818; batch adversarial loss: 0.553345\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422637; batch adversarial loss: 0.534291\n",
      "epoch 100; iter: 0; batch classifier loss: 0.343761; batch adversarial loss: 0.588201\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355925; batch adversarial loss: 0.507818\n",
      "epoch 102; iter: 0; batch classifier loss: 0.322968; batch adversarial loss: 0.508147\n",
      "epoch 103; iter: 0; batch classifier loss: 0.446304; batch adversarial loss: 0.516772\n",
      "epoch 104; iter: 0; batch classifier loss: 0.318156; batch adversarial loss: 0.554384\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404519; batch adversarial loss: 0.482046\n",
      "epoch 106; iter: 0; batch classifier loss: 0.403564; batch adversarial loss: 0.608170\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365026; batch adversarial loss: 0.626002\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389317; batch adversarial loss: 0.588832\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380596; batch adversarial loss: 0.541783\n",
      "epoch 110; iter: 0; batch classifier loss: 0.406116; batch adversarial loss: 0.553039\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382841; batch adversarial loss: 0.590568\n",
      "epoch 112; iter: 0; batch classifier loss: 0.302422; batch adversarial loss: 0.500577\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383507; batch adversarial loss: 0.580381\n",
      "epoch 114; iter: 0; batch classifier loss: 0.404404; batch adversarial loss: 0.589727\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410199; batch adversarial loss: 0.635394\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358487; batch adversarial loss: 0.543369\n",
      "epoch 117; iter: 0; batch classifier loss: 0.470349; batch adversarial loss: 0.554106\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358547; batch adversarial loss: 0.580771\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354849; batch adversarial loss: 0.543474\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361976; batch adversarial loss: 0.571526\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345335; batch adversarial loss: 0.536811\n",
      "epoch 122; iter: 0; batch classifier loss: 0.309124; batch adversarial loss: 0.663106\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384260; batch adversarial loss: 0.544355\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426099; batch adversarial loss: 0.535887\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330389; batch adversarial loss: 0.535062\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388335; batch adversarial loss: 0.507098\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396007; batch adversarial loss: 0.599828\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344286; batch adversarial loss: 0.625875\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355359; batch adversarial loss: 0.571496\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364671; batch adversarial loss: 0.461967\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427799; batch adversarial loss: 0.581338\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404448; batch adversarial loss: 0.497611\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347405; batch adversarial loss: 0.553436\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383656; batch adversarial loss: 0.579652\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364940; batch adversarial loss: 0.563041\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.627618\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359830; batch adversarial loss: 0.580484\n",
      "epoch 138; iter: 0; batch classifier loss: 0.339580; batch adversarial loss: 0.562989\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373275; batch adversarial loss: 0.536307\n",
      "epoch 140; iter: 0; batch classifier loss: 0.279930; batch adversarial loss: 0.543883\n",
      "epoch 141; iter: 0; batch classifier loss: 0.298787; batch adversarial loss: 0.560939\n",
      "epoch 142; iter: 0; batch classifier loss: 0.269791; batch adversarial loss: 0.562380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390516; batch adversarial loss: 0.482599\n",
      "epoch 144; iter: 0; batch classifier loss: 0.264683; batch adversarial loss: 0.472871\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349013; batch adversarial loss: 0.534108\n",
      "epoch 146; iter: 0; batch classifier loss: 0.297247; batch adversarial loss: 0.499399\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362788; batch adversarial loss: 0.598292\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419939; batch adversarial loss: 0.573493\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361611; batch adversarial loss: 0.534652\n",
      "epoch 150; iter: 0; batch classifier loss: 0.398697; batch adversarial loss: 0.517243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324632; batch adversarial loss: 0.581548\n",
      "epoch 152; iter: 0; batch classifier loss: 0.450831; batch adversarial loss: 0.553567\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430151; batch adversarial loss: 0.514943\n",
      "epoch 154; iter: 0; batch classifier loss: 0.355785; batch adversarial loss: 0.536082\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352897; batch adversarial loss: 0.534688\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418348; batch adversarial loss: 0.598368\n",
      "epoch 157; iter: 0; batch classifier loss: 0.282571; batch adversarial loss: 0.543631\n",
      "epoch 158; iter: 0; batch classifier loss: 0.302514; batch adversarial loss: 0.643084\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390370; batch adversarial loss: 0.517170\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316055; batch adversarial loss: 0.535419\n",
      "epoch 161; iter: 0; batch classifier loss: 0.291631; batch adversarial loss: 0.608096\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365558; batch adversarial loss: 0.507923\n",
      "epoch 163; iter: 0; batch classifier loss: 0.254932; batch adversarial loss: 0.480788\n",
      "epoch 164; iter: 0; batch classifier loss: 0.437324; batch adversarial loss: 0.481765\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389261; batch adversarial loss: 0.479937\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330001; batch adversarial loss: 0.546502\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416676; batch adversarial loss: 0.538601\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307811; batch adversarial loss: 0.526030\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384821; batch adversarial loss: 0.590469\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361300; batch adversarial loss: 0.572095\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384653; batch adversarial loss: 0.591005\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364687; batch adversarial loss: 0.641969\n",
      "epoch 173; iter: 0; batch classifier loss: 0.421442; batch adversarial loss: 0.560885\n",
      "epoch 174; iter: 0; batch classifier loss: 0.346161; batch adversarial loss: 0.553049\n",
      "epoch 175; iter: 0; batch classifier loss: 0.435637; batch adversarial loss: 0.544445\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388264; batch adversarial loss: 0.597708\n",
      "epoch 177; iter: 0; batch classifier loss: 0.427230; batch adversarial loss: 0.597191\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389766; batch adversarial loss: 0.509693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.366534; batch adversarial loss: 0.562804\n",
      "epoch 180; iter: 0; batch classifier loss: 0.493225; batch adversarial loss: 0.688326\n",
      "epoch 181; iter: 0; batch classifier loss: 0.405850; batch adversarial loss: 0.581114\n",
      "epoch 182; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.571433\n",
      "epoch 183; iter: 0; batch classifier loss: 0.404511; batch adversarial loss: 0.536790\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294940; batch adversarial loss: 0.552851\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376129; batch adversarial loss: 0.633464\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414450; batch adversarial loss: 0.506190\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382725; batch adversarial loss: 0.535056\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332140; batch adversarial loss: 0.701091\n",
      "epoch 189; iter: 0; batch classifier loss: 0.417714; batch adversarial loss: 0.605867\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282407; batch adversarial loss: 0.624098\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320618; batch adversarial loss: 0.518245\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388724; batch adversarial loss: 0.511456\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351689; batch adversarial loss: 0.529452\n",
      "epoch 194; iter: 0; batch classifier loss: 0.282930; batch adversarial loss: 0.509047\n",
      "epoch 195; iter: 0; batch classifier loss: 0.435870; batch adversarial loss: 0.523384\n",
      "epoch 196; iter: 0; batch classifier loss: 0.379185; batch adversarial loss: 0.515161\n",
      "epoch 197; iter: 0; batch classifier loss: 0.311218; batch adversarial loss: 0.503423\n",
      "epoch 198; iter: 0; batch classifier loss: 0.391671; batch adversarial loss: 0.518246\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335672; batch adversarial loss: 0.519230\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677392; batch adversarial loss: 0.663640\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565369; batch adversarial loss: 0.652398\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611641; batch adversarial loss: 0.639021\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588281; batch adversarial loss: 0.628686\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598193; batch adversarial loss: 0.594007\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614678; batch adversarial loss: 0.628533\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504410; batch adversarial loss: 0.631615\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624096; batch adversarial loss: 0.552960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535926; batch adversarial loss: 0.556656\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634720; batch adversarial loss: 0.573939\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520851; batch adversarial loss: 0.619017\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528447; batch adversarial loss: 0.598683\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537327; batch adversarial loss: 0.607966\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514584; batch adversarial loss: 0.593623\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524830; batch adversarial loss: 0.589098\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530699; batch adversarial loss: 0.541947\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541416; batch adversarial loss: 0.565476\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518555; batch adversarial loss: 0.559557\n",
      "epoch 18; iter: 0; batch classifier loss: 0.421541; batch adversarial loss: 0.635391\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496480; batch adversarial loss: 0.511414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520627; batch adversarial loss: 0.591491\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545696; batch adversarial loss: 0.585342\n",
      "epoch 22; iter: 0; batch classifier loss: 0.571152; batch adversarial loss: 0.577711\n",
      "epoch 23; iter: 0; batch classifier loss: 0.557523; batch adversarial loss: 0.495554\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473504; batch adversarial loss: 0.488929\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485261; batch adversarial loss: 0.537445\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508457; batch adversarial loss: 0.516657\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467019; batch adversarial loss: 0.478624\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484828; batch adversarial loss: 0.546476\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458985; batch adversarial loss: 0.553141\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454007; batch adversarial loss: 0.525466\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469995; batch adversarial loss: 0.548717\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494035; batch adversarial loss: 0.630883\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441228; batch adversarial loss: 0.569760\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482039; batch adversarial loss: 0.571994\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487851; batch adversarial loss: 0.563440\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487805; batch adversarial loss: 0.616923\n",
      "epoch 37; iter: 0; batch classifier loss: 0.478937; batch adversarial loss: 0.563441\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459765; batch adversarial loss: 0.589326\n",
      "epoch 39; iter: 0; batch classifier loss: 0.416250; batch adversarial loss: 0.517202\n",
      "epoch 40; iter: 0; batch classifier loss: 0.478283; batch adversarial loss: 0.526177\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427452; batch adversarial loss: 0.517211\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391027; batch adversarial loss: 0.563295\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400456; batch adversarial loss: 0.535293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457827; batch adversarial loss: 0.544385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.406044; batch adversarial loss: 0.562336\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503633; batch adversarial loss: 0.607490\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450462; batch adversarial loss: 0.480736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.518990; batch adversarial loss: 0.572280\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400379; batch adversarial loss: 0.516776\n",
      "epoch 50; iter: 0; batch classifier loss: 0.354794; batch adversarial loss: 0.553855\n",
      "epoch 51; iter: 0; batch classifier loss: 0.478102; batch adversarial loss: 0.507161\n",
      "epoch 52; iter: 0; batch classifier loss: 0.381201; batch adversarial loss: 0.525735\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443470; batch adversarial loss: 0.646867\n",
      "epoch 54; iter: 0; batch classifier loss: 0.360141; batch adversarial loss: 0.592834\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447435; batch adversarial loss: 0.564225\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468698; batch adversarial loss: 0.544033\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408804; batch adversarial loss: 0.570778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.475539; batch adversarial loss: 0.527011\n",
      "epoch 59; iter: 0; batch classifier loss: 0.469224; batch adversarial loss: 0.478954\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395374; batch adversarial loss: 0.517011\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433277; batch adversarial loss: 0.573012\n",
      "epoch 62; iter: 0; batch classifier loss: 0.402077; batch adversarial loss: 0.572501\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376257; batch adversarial loss: 0.517694\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410613; batch adversarial loss: 0.500340\n",
      "epoch 65; iter: 0; batch classifier loss: 0.434116; batch adversarial loss: 0.536374\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391206; batch adversarial loss: 0.535080\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380116; batch adversarial loss: 0.526121\n",
      "epoch 68; iter: 0; batch classifier loss: 0.385252; batch adversarial loss: 0.553293\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424868; batch adversarial loss: 0.526193\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404892; batch adversarial loss: 0.526105\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480355; batch adversarial loss: 0.572633\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416293; batch adversarial loss: 0.572198\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427732; batch adversarial loss: 0.563052\n",
      "epoch 74; iter: 0; batch classifier loss: 0.373951; batch adversarial loss: 0.544724\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443506; batch adversarial loss: 0.553814\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376378; batch adversarial loss: 0.572065\n",
      "epoch 77; iter: 0; batch classifier loss: 0.449443; batch adversarial loss: 0.525926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.393844; batch adversarial loss: 0.647265\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417419; batch adversarial loss: 0.525688\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447842; batch adversarial loss: 0.498114\n",
      "epoch 81; iter: 0; batch classifier loss: 0.455207; batch adversarial loss: 0.554001\n",
      "epoch 82; iter: 0; batch classifier loss: 0.508903; batch adversarial loss: 0.535762\n",
      "epoch 83; iter: 0; batch classifier loss: 0.494129; batch adversarial loss: 0.489192\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368518; batch adversarial loss: 0.489362\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442896; batch adversarial loss: 0.460880\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415419; batch adversarial loss: 0.507412\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412410; batch adversarial loss: 0.581669\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433115; batch adversarial loss: 0.525299\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400991; batch adversarial loss: 0.544952\n",
      "epoch 90; iter: 0; batch classifier loss: 0.321542; batch adversarial loss: 0.609028\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359820; batch adversarial loss: 0.535828\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370831; batch adversarial loss: 0.600250\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397975; batch adversarial loss: 0.535871\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397625; batch adversarial loss: 0.516599\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395206; batch adversarial loss: 0.563222\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417069; batch adversarial loss: 0.562994\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404673; batch adversarial loss: 0.600571\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409277; batch adversarial loss: 0.461022\n",
      "epoch 99; iter: 0; batch classifier loss: 0.449118; batch adversarial loss: 0.554148\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427311; batch adversarial loss: 0.470649\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360126; batch adversarial loss: 0.516906\n",
      "epoch 102; iter: 0; batch classifier loss: 0.356593; batch adversarial loss: 0.525951\n",
      "epoch 103; iter: 0; batch classifier loss: 0.347000; batch adversarial loss: 0.591010\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350352; batch adversarial loss: 0.433474\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368971; batch adversarial loss: 0.526135\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369212; batch adversarial loss: 0.544561\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391056; batch adversarial loss: 0.554021\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381273; batch adversarial loss: 0.516694\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383275; batch adversarial loss: 0.610079\n",
      "epoch 110; iter: 0; batch classifier loss: 0.375121; batch adversarial loss: 0.480033\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406131; batch adversarial loss: 0.498303\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398131; batch adversarial loss: 0.573120\n",
      "epoch 113; iter: 0; batch classifier loss: 0.467882; batch adversarial loss: 0.535347\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418885; batch adversarial loss: 0.563475\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409813; batch adversarial loss: 0.600019\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399677; batch adversarial loss: 0.498135\n",
      "epoch 117; iter: 0; batch classifier loss: 0.412039; batch adversarial loss: 0.525695\n",
      "epoch 118; iter: 0; batch classifier loss: 0.468083; batch adversarial loss: 0.424540\n",
      "epoch 119; iter: 0; batch classifier loss: 0.488816; batch adversarial loss: 0.562828\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341163; batch adversarial loss: 0.507532\n",
      "epoch 121; iter: 0; batch classifier loss: 0.325656; batch adversarial loss: 0.544418\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352619; batch adversarial loss: 0.535258\n",
      "epoch 123; iter: 0; batch classifier loss: 0.438678; batch adversarial loss: 0.581364\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407590; batch adversarial loss: 0.571990\n",
      "epoch 125; iter: 0; batch classifier loss: 0.388973; batch adversarial loss: 0.544287\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412387; batch adversarial loss: 0.544798\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384613; batch adversarial loss: 0.600396\n",
      "epoch 128; iter: 0; batch classifier loss: 0.462956; batch adversarial loss: 0.581620\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362530; batch adversarial loss: 0.507089\n",
      "epoch 130; iter: 0; batch classifier loss: 0.419568; batch adversarial loss: 0.535538\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379780; batch adversarial loss: 0.600322\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320610; batch adversarial loss: 0.618706\n",
      "epoch 133; iter: 0; batch classifier loss: 0.463014; batch adversarial loss: 0.461670\n",
      "epoch 134; iter: 0; batch classifier loss: 0.298180; batch adversarial loss: 0.517047\n",
      "epoch 135; iter: 0; batch classifier loss: 0.401361; batch adversarial loss: 0.563074\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360993; batch adversarial loss: 0.553530\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423241; batch adversarial loss: 0.517179\n",
      "epoch 138; iter: 0; batch classifier loss: 0.397180; batch adversarial loss: 0.498037\n",
      "epoch 139; iter: 0; batch classifier loss: 0.422696; batch adversarial loss: 0.516279\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384096; batch adversarial loss: 0.461652\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388400; batch adversarial loss: 0.554099\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378906; batch adversarial loss: 0.590373\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352877; batch adversarial loss: 0.525596\n",
      "epoch 144; iter: 0; batch classifier loss: 0.515072; batch adversarial loss: 0.507539\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340383; batch adversarial loss: 0.470511\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400791; batch adversarial loss: 0.479296\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387843; batch adversarial loss: 0.534795\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329793; batch adversarial loss: 0.526305\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384222; batch adversarial loss: 0.470251\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337249; batch adversarial loss: 0.581544\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399383; batch adversarial loss: 0.562676\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398865; batch adversarial loss: 0.609139\n",
      "epoch 153; iter: 0; batch classifier loss: 0.507353; batch adversarial loss: 0.544686\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397907; batch adversarial loss: 0.646613\n",
      "epoch 155; iter: 0; batch classifier loss: 0.311686; batch adversarial loss: 0.507963\n",
      "epoch 156; iter: 0; batch classifier loss: 0.428794; batch adversarial loss: 0.498420\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341186; batch adversarial loss: 0.572240\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330754; batch adversarial loss: 0.572231\n",
      "epoch 159; iter: 0; batch classifier loss: 0.452592; batch adversarial loss: 0.572400\n",
      "epoch 160; iter: 0; batch classifier loss: 0.304469; batch adversarial loss: 0.572148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.302279; batch adversarial loss: 0.544331\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313972; batch adversarial loss: 0.553719\n",
      "epoch 163; iter: 0; batch classifier loss: 0.432184; batch adversarial loss: 0.572041\n",
      "epoch 164; iter: 0; batch classifier loss: 0.455010; batch adversarial loss: 0.581755\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379296; batch adversarial loss: 0.553814\n",
      "epoch 166; iter: 0; batch classifier loss: 0.262117; batch adversarial loss: 0.562730\n",
      "epoch 167; iter: 0; batch classifier loss: 0.317524; batch adversarial loss: 0.627957\n",
      "epoch 168; iter: 0; batch classifier loss: 0.411641; batch adversarial loss: 0.534811\n",
      "epoch 169; iter: 0; batch classifier loss: 0.378807; batch adversarial loss: 0.571555\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359975; batch adversarial loss: 0.461113\n",
      "epoch 171; iter: 0; batch classifier loss: 0.461297; batch adversarial loss: 0.479682\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318339; batch adversarial loss: 0.489251\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367883; batch adversarial loss: 0.544410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.400557; batch adversarial loss: 0.626883\n",
      "epoch 175; iter: 0; batch classifier loss: 0.284709; batch adversarial loss: 0.479759\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364318; batch adversarial loss: 0.562808\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407618; batch adversarial loss: 0.526734\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362917; batch adversarial loss: 0.600623\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348023; batch adversarial loss: 0.461030\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374420; batch adversarial loss: 0.515949\n",
      "epoch 181; iter: 0; batch classifier loss: 0.356136; batch adversarial loss: 0.506895\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341776; batch adversarial loss: 0.508200\n",
      "epoch 183; iter: 0; batch classifier loss: 0.380035; batch adversarial loss: 0.543774\n",
      "epoch 184; iter: 0; batch classifier loss: 0.364901; batch adversarial loss: 0.554111\n",
      "epoch 185; iter: 0; batch classifier loss: 0.482333; batch adversarial loss: 0.526421\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311255; batch adversarial loss: 0.572449\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389890; batch adversarial loss: 0.600718\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404230; batch adversarial loss: 0.489318\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333864; batch adversarial loss: 0.461583\n",
      "epoch 190; iter: 0; batch classifier loss: 0.412141; batch adversarial loss: 0.497959\n",
      "epoch 191; iter: 0; batch classifier loss: 0.388224; batch adversarial loss: 0.553997\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367375; batch adversarial loss: 0.581496\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376132; batch adversarial loss: 0.517146\n",
      "epoch 194; iter: 0; batch classifier loss: 0.454899; batch adversarial loss: 0.497806\n",
      "epoch 195; iter: 0; batch classifier loss: 0.380550; batch adversarial loss: 0.600286\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335856; batch adversarial loss: 0.506888\n",
      "epoch 197; iter: 0; batch classifier loss: 0.333155; batch adversarial loss: 0.563357\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338006; batch adversarial loss: 0.507742\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404415; batch adversarial loss: 0.506293\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673908; batch adversarial loss: 0.823430\n",
      "epoch 1; iter: 0; batch classifier loss: 0.845521; batch adversarial loss: 1.138288\n",
      "epoch 2; iter: 0; batch classifier loss: 1.008450; batch adversarial loss: 1.151489\n",
      "epoch 3; iter: 0; batch classifier loss: 1.112578; batch adversarial loss: 1.031455\n",
      "epoch 4; iter: 0; batch classifier loss: 1.006828; batch adversarial loss: 0.933702\n",
      "epoch 5; iter: 0; batch classifier loss: 0.952241; batch adversarial loss: 0.853289\n",
      "epoch 6; iter: 0; batch classifier loss: 0.936357; batch adversarial loss: 0.812447\n",
      "epoch 7; iter: 0; batch classifier loss: 0.840549; batch adversarial loss: 0.744795\n",
      "epoch 8; iter: 0; batch classifier loss: 0.725210; batch adversarial loss: 0.688562\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572775; batch adversarial loss: 0.643921\n",
      "epoch 10; iter: 0; batch classifier loss: 0.625027; batch adversarial loss: 0.605696\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563890; batch adversarial loss: 0.599749\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570919; batch adversarial loss: 0.629826\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514863; batch adversarial loss: 0.603328\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504735; batch adversarial loss: 0.556886\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540431; batch adversarial loss: 0.592044\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499081; batch adversarial loss: 0.618464\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478733; batch adversarial loss: 0.552747\n",
      "epoch 18; iter: 0; batch classifier loss: 0.546142; batch adversarial loss: 0.559336\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480487; batch adversarial loss: 0.609098\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514680; batch adversarial loss: 0.563372\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523965; batch adversarial loss: 0.553634\n",
      "epoch 22; iter: 0; batch classifier loss: 0.508876; batch adversarial loss: 0.548910\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484960; batch adversarial loss: 0.556696\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518434; batch adversarial loss: 0.568258\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524605; batch adversarial loss: 0.584319\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445867; batch adversarial loss: 0.595008\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455099; batch adversarial loss: 0.538379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.517879; batch adversarial loss: 0.525664\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455950; batch adversarial loss: 0.568482\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417869; batch adversarial loss: 0.539633\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436793; batch adversarial loss: 0.611662\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444703; batch adversarial loss: 0.530842\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446881; batch adversarial loss: 0.584341\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471636; batch adversarial loss: 0.548983\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507345; batch adversarial loss: 0.607509\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499434; batch adversarial loss: 0.551205\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409604; batch adversarial loss: 0.531942\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466284; batch adversarial loss: 0.591889\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422517; batch adversarial loss: 0.551893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451294; batch adversarial loss: 0.586849\n",
      "epoch 41; iter: 0; batch classifier loss: 0.494423; batch adversarial loss: 0.590752\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432928; batch adversarial loss: 0.563326\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482919; batch adversarial loss: 0.552080\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415571; batch adversarial loss: 0.542831\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444303; batch adversarial loss: 0.604167\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416678; batch adversarial loss: 0.646449\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420074; batch adversarial loss: 0.515642\n",
      "epoch 48; iter: 0; batch classifier loss: 0.618869; batch adversarial loss: 0.534897\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478170; batch adversarial loss: 0.522047\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445432; batch adversarial loss: 0.565615\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422425; batch adversarial loss: 0.583038\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415741; batch adversarial loss: 0.573557\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415206; batch adversarial loss: 0.569238\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385707; batch adversarial loss: 0.550750\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441216; batch adversarial loss: 0.534679\n",
      "epoch 56; iter: 0; batch classifier loss: 0.511450; batch adversarial loss: 0.536994\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404735; batch adversarial loss: 0.524480\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439610; batch adversarial loss: 0.608428\n",
      "epoch 59; iter: 0; batch classifier loss: 0.390973; batch adversarial loss: 0.526666\n",
      "epoch 60; iter: 0; batch classifier loss: 0.351645; batch adversarial loss: 0.591517\n",
      "epoch 61; iter: 0; batch classifier loss: 0.415268; batch adversarial loss: 0.588551\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414221; batch adversarial loss: 0.599672\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414723; batch adversarial loss: 0.636237\n",
      "epoch 64; iter: 0; batch classifier loss: 0.443005; batch adversarial loss: 0.544559\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433644; batch adversarial loss: 0.607637\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413904; batch adversarial loss: 0.580441\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388629; batch adversarial loss: 0.580817\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460178; batch adversarial loss: 0.516452\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397264; batch adversarial loss: 0.499208\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424458; batch adversarial loss: 0.508025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.444409; batch adversarial loss: 0.535597\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391954; batch adversarial loss: 0.499108\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349885; batch adversarial loss: 0.553985\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372541; batch adversarial loss: 0.599101\n",
      "epoch 75; iter: 0; batch classifier loss: 0.383811; batch adversarial loss: 0.553451\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398696; batch adversarial loss: 0.562942\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437529; batch adversarial loss: 0.544046\n",
      "epoch 78; iter: 0; batch classifier loss: 0.418568; batch adversarial loss: 0.562590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.468582; batch adversarial loss: 0.571293\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389265; batch adversarial loss: 0.590179\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416322; batch adversarial loss: 0.588998\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405200; batch adversarial loss: 0.553806\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428769; batch adversarial loss: 0.525878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418673; batch adversarial loss: 0.634244\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433749; batch adversarial loss: 0.471924\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399746; batch adversarial loss: 0.580886\n",
      "epoch 87; iter: 0; batch classifier loss: 0.336857; batch adversarial loss: 0.563149\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345878; batch adversarial loss: 0.644070\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409182; batch adversarial loss: 0.563923\n",
      "epoch 90; iter: 0; batch classifier loss: 0.296509; batch adversarial loss: 0.617245\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365265; batch adversarial loss: 0.586799\n",
      "epoch 92; iter: 0; batch classifier loss: 0.437503; batch adversarial loss: 0.569188\n",
      "epoch 93; iter: 0; batch classifier loss: 0.360323; batch adversarial loss: 0.609112\n",
      "epoch 94; iter: 0; batch classifier loss: 0.340828; batch adversarial loss: 0.552552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.450418; batch adversarial loss: 0.598661\n",
      "epoch 96; iter: 0; batch classifier loss: 0.297614; batch adversarial loss: 0.597041\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319656; batch adversarial loss: 0.479830\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383151; batch adversarial loss: 0.533861\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429027; batch adversarial loss: 0.590532\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382917; batch adversarial loss: 0.524913\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386003; batch adversarial loss: 0.581222\n",
      "epoch 102; iter: 0; batch classifier loss: 0.396826; batch adversarial loss: 0.533051\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372221; batch adversarial loss: 0.587836\n",
      "epoch 104; iter: 0; batch classifier loss: 0.308793; batch adversarial loss: 0.545148\n",
      "epoch 105; iter: 0; batch classifier loss: 0.313903; batch adversarial loss: 0.545626\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376436; batch adversarial loss: 0.535269\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379229; batch adversarial loss: 0.545493\n",
      "epoch 108; iter: 0; batch classifier loss: 0.296124; batch adversarial loss: 0.589326\n",
      "epoch 109; iter: 0; batch classifier loss: 0.309225; batch adversarial loss: 0.499242\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358179; batch adversarial loss: 0.553033\n",
      "epoch 111; iter: 0; batch classifier loss: 0.414730; batch adversarial loss: 0.582980\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339803; batch adversarial loss: 0.551919\n",
      "epoch 113; iter: 0; batch classifier loss: 0.327225; batch adversarial loss: 0.537384\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400086; batch adversarial loss: 0.563221\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350466; batch adversarial loss: 0.561576\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389831; batch adversarial loss: 0.552544\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393643; batch adversarial loss: 0.564206\n",
      "epoch 118; iter: 0; batch classifier loss: 0.438741; batch adversarial loss: 0.518603\n",
      "epoch 119; iter: 0; batch classifier loss: 0.309427; batch adversarial loss: 0.618331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357078; batch adversarial loss: 0.609651\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380700; batch adversarial loss: 0.607432\n",
      "epoch 122; iter: 0; batch classifier loss: 0.490030; batch adversarial loss: 0.559697\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369888; batch adversarial loss: 0.499265\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365957; batch adversarial loss: 0.526756\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415311; batch adversarial loss: 0.516861\n",
      "epoch 126; iter: 0; batch classifier loss: 0.451664; batch adversarial loss: 0.609642\n",
      "epoch 127; iter: 0; batch classifier loss: 0.336530; batch adversarial loss: 0.493037\n",
      "epoch 128; iter: 0; batch classifier loss: 0.437735; batch adversarial loss: 0.507494\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359257; batch adversarial loss: 0.598013\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358799; batch adversarial loss: 0.543779\n",
      "epoch 131; iter: 0; batch classifier loss: 0.413684; batch adversarial loss: 0.598466\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351635; batch adversarial loss: 0.490379\n",
      "epoch 133; iter: 0; batch classifier loss: 0.289768; batch adversarial loss: 0.597372\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396125; batch adversarial loss: 0.580858\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356629; batch adversarial loss: 0.590484\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322976; batch adversarial loss: 0.554317\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332954; batch adversarial loss: 0.604716\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364659; batch adversarial loss: 0.524254\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316971; batch adversarial loss: 0.536647\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389823; batch adversarial loss: 0.572567\n",
      "epoch 141; iter: 0; batch classifier loss: 0.373243; batch adversarial loss: 0.581300\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330224; batch adversarial loss: 0.542563\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.525619\n",
      "epoch 144; iter: 0; batch classifier loss: 0.410699; batch adversarial loss: 0.509758\n",
      "epoch 145; iter: 0; batch classifier loss: 0.439095; batch adversarial loss: 0.636028\n",
      "epoch 146; iter: 0; batch classifier loss: 0.328557; batch adversarial loss: 0.571683\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390965; batch adversarial loss: 0.470794\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395886; batch adversarial loss: 0.545106\n",
      "epoch 149; iter: 0; batch classifier loss: 0.395379; batch adversarial loss: 0.561682\n",
      "epoch 150; iter: 0; batch classifier loss: 0.449255; batch adversarial loss: 0.544882\n",
      "epoch 151; iter: 0; batch classifier loss: 0.307933; batch adversarial loss: 0.488794\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332893; batch adversarial loss: 0.616138\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346789; batch adversarial loss: 0.562498\n",
      "epoch 154; iter: 0; batch classifier loss: 0.296418; batch adversarial loss: 0.480989\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351782; batch adversarial loss: 0.541579\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358952; batch adversarial loss: 0.535336\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326088; batch adversarial loss: 0.552921\n",
      "epoch 158; iter: 0; batch classifier loss: 0.405576; batch adversarial loss: 0.536381\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373656; batch adversarial loss: 0.518209\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345960; batch adversarial loss: 0.569881\n",
      "epoch 161; iter: 0; batch classifier loss: 0.330334; batch adversarial loss: 0.542721\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379210; batch adversarial loss: 0.509981\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338684; batch adversarial loss: 0.572938\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351149; batch adversarial loss: 0.561399\n",
      "epoch 165; iter: 0; batch classifier loss: 0.448825; batch adversarial loss: 0.609597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.296362; batch adversarial loss: 0.653131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.360624; batch adversarial loss: 0.490371\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373775; batch adversarial loss: 0.546190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365433; batch adversarial loss: 0.490241\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346212; batch adversarial loss: 0.589253\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385417; batch adversarial loss: 0.499553\n",
      "epoch 172; iter: 0; batch classifier loss: 0.380390; batch adversarial loss: 0.506186\n",
      "epoch 173; iter: 0; batch classifier loss: 0.312263; batch adversarial loss: 0.581005\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339034; batch adversarial loss: 0.605880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348767; batch adversarial loss: 0.525700\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332816; batch adversarial loss: 0.526848\n",
      "epoch 177; iter: 0; batch classifier loss: 0.350417; batch adversarial loss: 0.497868\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381495; batch adversarial loss: 0.617613\n",
      "epoch 179; iter: 0; batch classifier loss: 0.436949; batch adversarial loss: 0.517255\n",
      "epoch 180; iter: 0; batch classifier loss: 0.432752; batch adversarial loss: 0.488920\n",
      "epoch 181; iter: 0; batch classifier loss: 0.390666; batch adversarial loss: 0.516917\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379567; batch adversarial loss: 0.471115\n",
      "epoch 183; iter: 0; batch classifier loss: 0.276780; batch adversarial loss: 0.497811\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347393; batch adversarial loss: 0.500667\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346089; batch adversarial loss: 0.553975\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323464; batch adversarial loss: 0.542328\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370491; batch adversarial loss: 0.461904\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343705; batch adversarial loss: 0.510372\n",
      "epoch 189; iter: 0; batch classifier loss: 0.410979; batch adversarial loss: 0.525099\n",
      "epoch 190; iter: 0; batch classifier loss: 0.413144; batch adversarial loss: 0.552804\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368036; batch adversarial loss: 0.517059\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308535; batch adversarial loss: 0.570552\n",
      "epoch 193; iter: 0; batch classifier loss: 0.305237; batch adversarial loss: 0.587321\n",
      "epoch 194; iter: 0; batch classifier loss: 0.345230; batch adversarial loss: 0.481010\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310355; batch adversarial loss: 0.527250\n",
      "epoch 196; iter: 0; batch classifier loss: 0.288425; batch adversarial loss: 0.644333\n",
      "epoch 197; iter: 0; batch classifier loss: 0.325190; batch adversarial loss: 0.589474\n",
      "epoch 198; iter: 0; batch classifier loss: 0.364990; batch adversarial loss: 0.572188\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333567; batch adversarial loss: 0.606937\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741626; batch adversarial loss: 0.990959\n",
      "epoch 1; iter: 0; batch classifier loss: 0.726441; batch adversarial loss: 0.944839\n",
      "epoch 2; iter: 0; batch classifier loss: 0.714943; batch adversarial loss: 0.922671\n",
      "epoch 3; iter: 0; batch classifier loss: 0.635175; batch adversarial loss: 0.858696\n",
      "epoch 4; iter: 0; batch classifier loss: 0.688268; batch adversarial loss: 0.758778\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559378; batch adversarial loss: 0.695935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514468; batch adversarial loss: 0.651087\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591632; batch adversarial loss: 0.636154\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576631; batch adversarial loss: 0.636826\n",
      "epoch 9; iter: 0; batch classifier loss: 0.629151; batch adversarial loss: 0.614129\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538379; batch adversarial loss: 0.628902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527619; batch adversarial loss: 0.588123\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489341; batch adversarial loss: 0.588689\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558333; batch adversarial loss: 0.550664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467479; batch adversarial loss: 0.570349\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482802; batch adversarial loss: 0.572133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526752; batch adversarial loss: 0.576208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451313; batch adversarial loss: 0.573472\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452943; batch adversarial loss: 0.569456\n",
      "epoch 19; iter: 0; batch classifier loss: 0.446545; batch adversarial loss: 0.539267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479835; batch adversarial loss: 0.533659\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489346; batch adversarial loss: 0.574453\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471011; batch adversarial loss: 0.616085\n",
      "epoch 23; iter: 0; batch classifier loss: 0.428590; batch adversarial loss: 0.555332\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531352; batch adversarial loss: 0.588607\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558293; batch adversarial loss: 0.506618\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487183; batch adversarial loss: 0.594538\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472779; batch adversarial loss: 0.613684\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486301; batch adversarial loss: 0.563086\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480956; batch adversarial loss: 0.618056\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495023; batch adversarial loss: 0.625110\n",
      "epoch 31; iter: 0; batch classifier loss: 0.434444; batch adversarial loss: 0.532631\n",
      "epoch 32; iter: 0; batch classifier loss: 0.489854; batch adversarial loss: 0.475068\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491798; batch adversarial loss: 0.535091\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427721; batch adversarial loss: 0.551085\n",
      "epoch 35; iter: 0; batch classifier loss: 0.500975; batch adversarial loss: 0.526182\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453418; batch adversarial loss: 0.562144\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420045; batch adversarial loss: 0.506054\n",
      "epoch 38; iter: 0; batch classifier loss: 0.360783; batch adversarial loss: 0.518815\n",
      "epoch 39; iter: 0; batch classifier loss: 0.511174; batch adversarial loss: 0.514003\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492059; batch adversarial loss: 0.581347\n",
      "epoch 41; iter: 0; batch classifier loss: 0.510439; batch adversarial loss: 0.507134\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445575; batch adversarial loss: 0.568302\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381205; batch adversarial loss: 0.546372\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423631; batch adversarial loss: 0.488439\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518544; batch adversarial loss: 0.570543\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419227; batch adversarial loss: 0.502198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484026; batch adversarial loss: 0.477420\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446069; batch adversarial loss: 0.545978\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477550; batch adversarial loss: 0.535492\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390746; batch adversarial loss: 0.572980\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482048; batch adversarial loss: 0.499030\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442636; batch adversarial loss: 0.506390\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450483; batch adversarial loss: 0.584371\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392153; batch adversarial loss: 0.571157\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466864; batch adversarial loss: 0.608260\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443649; batch adversarial loss: 0.562302\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424156; batch adversarial loss: 0.546343\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442614; batch adversarial loss: 0.561633\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440383; batch adversarial loss: 0.496193\n",
      "epoch 60; iter: 0; batch classifier loss: 0.465349; batch adversarial loss: 0.533932\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446653; batch adversarial loss: 0.552011\n",
      "epoch 62; iter: 0; batch classifier loss: 0.357761; batch adversarial loss: 0.424447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414105; batch adversarial loss: 0.527383\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390420; batch adversarial loss: 0.499271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.426639; batch adversarial loss: 0.536217\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433713; batch adversarial loss: 0.571584\n",
      "epoch 67; iter: 0; batch classifier loss: 0.357619; batch adversarial loss: 0.526404\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392967; batch adversarial loss: 0.562772\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385374; batch adversarial loss: 0.487475\n",
      "epoch 70; iter: 0; batch classifier loss: 0.513452; batch adversarial loss: 0.563581\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448411; batch adversarial loss: 0.564282\n",
      "epoch 72; iter: 0; batch classifier loss: 0.392643; batch adversarial loss: 0.531519\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405854; batch adversarial loss: 0.454498\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430368; batch adversarial loss: 0.600104\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395414; batch adversarial loss: 0.609291\n",
      "epoch 76; iter: 0; batch classifier loss: 0.469838; batch adversarial loss: 0.525413\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423196; batch adversarial loss: 0.504638\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406794; batch adversarial loss: 0.608796\n",
      "epoch 79; iter: 0; batch classifier loss: 0.488487; batch adversarial loss: 0.572600\n",
      "epoch 80; iter: 0; batch classifier loss: 0.509749; batch adversarial loss: 0.563062\n",
      "epoch 81; iter: 0; batch classifier loss: 0.379980; batch adversarial loss: 0.544609\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365955; batch adversarial loss: 0.524942\n",
      "epoch 83; iter: 0; batch classifier loss: 0.435017; batch adversarial loss: 0.627791\n",
      "epoch 84; iter: 0; batch classifier loss: 0.345870; batch adversarial loss: 0.534390\n",
      "epoch 85; iter: 0; batch classifier loss: 0.470061; batch adversarial loss: 0.587700\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403143; batch adversarial loss: 0.489561\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398059; batch adversarial loss: 0.563068\n",
      "epoch 88; iter: 0; batch classifier loss: 0.301538; batch adversarial loss: 0.497808\n",
      "epoch 89; iter: 0; batch classifier loss: 0.333849; batch adversarial loss: 0.589656\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364524; batch adversarial loss: 0.535820\n",
      "epoch 91; iter: 0; batch classifier loss: 0.329163; batch adversarial loss: 0.582622\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418775; batch adversarial loss: 0.533577\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390427; batch adversarial loss: 0.546916\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383372; batch adversarial loss: 0.572024\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419020; batch adversarial loss: 0.592948\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341855; batch adversarial loss: 0.582238\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373393; batch adversarial loss: 0.537929\n",
      "epoch 98; iter: 0; batch classifier loss: 0.350777; batch adversarial loss: 0.545870\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359511; batch adversarial loss: 0.554566\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368237; batch adversarial loss: 0.553018\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360382; batch adversarial loss: 0.564013\n",
      "epoch 102; iter: 0; batch classifier loss: 0.318198; batch adversarial loss: 0.571594\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374425; batch adversarial loss: 0.527384\n",
      "epoch 104; iter: 0; batch classifier loss: 0.404794; batch adversarial loss: 0.546801\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351392; batch adversarial loss: 0.552361\n",
      "epoch 106; iter: 0; batch classifier loss: 0.431763; batch adversarial loss: 0.573790\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402793; batch adversarial loss: 0.527527\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407028; batch adversarial loss: 0.508867\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410901; batch adversarial loss: 0.581130\n",
      "epoch 110; iter: 0; batch classifier loss: 0.441437; batch adversarial loss: 0.591050\n",
      "epoch 111; iter: 0; batch classifier loss: 0.328268; batch adversarial loss: 0.579009\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402255; batch adversarial loss: 0.509688\n",
      "epoch 113; iter: 0; batch classifier loss: 0.438497; batch adversarial loss: 0.534224\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347338; batch adversarial loss: 0.572390\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416849; batch adversarial loss: 0.573537\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395554; batch adversarial loss: 0.560652\n",
      "epoch 117; iter: 0; batch classifier loss: 0.355619; batch adversarial loss: 0.504948\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330438; batch adversarial loss: 0.551326\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344119; batch adversarial loss: 0.546751\n",
      "epoch 120; iter: 0; batch classifier loss: 0.429196; batch adversarial loss: 0.590490\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390172; batch adversarial loss: 0.579422\n",
      "epoch 122; iter: 0; batch classifier loss: 0.458544; batch adversarial loss: 0.537892\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381166; batch adversarial loss: 0.601106\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336035; batch adversarial loss: 0.579737\n",
      "epoch 125; iter: 0; batch classifier loss: 0.338566; batch adversarial loss: 0.540865\n",
      "epoch 126; iter: 0; batch classifier loss: 0.349675; batch adversarial loss: 0.480002\n",
      "epoch 127; iter: 0; batch classifier loss: 0.425174; batch adversarial loss: 0.488278\n",
      "epoch 128; iter: 0; batch classifier loss: 0.384804; batch adversarial loss: 0.499791\n",
      "epoch 129; iter: 0; batch classifier loss: 0.427805; batch adversarial loss: 0.522714\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377413; batch adversarial loss: 0.569481\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381062; batch adversarial loss: 0.609182\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404964; batch adversarial loss: 0.536540\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391411; batch adversarial loss: 0.560687\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337990; batch adversarial loss: 0.602084\n",
      "epoch 135; iter: 0; batch classifier loss: 0.426861; batch adversarial loss: 0.403406\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375047; batch adversarial loss: 0.562002\n",
      "epoch 137; iter: 0; batch classifier loss: 0.397154; batch adversarial loss: 0.563972\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370292; batch adversarial loss: 0.600518\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345750; batch adversarial loss: 0.555373\n",
      "epoch 140; iter: 0; batch classifier loss: 0.437138; batch adversarial loss: 0.636641\n",
      "epoch 141; iter: 0; batch classifier loss: 0.401794; batch adversarial loss: 0.543093\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334273; batch adversarial loss: 0.481190\n",
      "epoch 143; iter: 0; batch classifier loss: 0.291440; batch adversarial loss: 0.628580\n",
      "epoch 144; iter: 0; batch classifier loss: 0.465290; batch adversarial loss: 0.551474\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404073; batch adversarial loss: 0.549111\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368507; batch adversarial loss: 0.549722\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326882; batch adversarial loss: 0.563898\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403541; batch adversarial loss: 0.476041\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384024; batch adversarial loss: 0.502045\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311707; batch adversarial loss: 0.545379\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309971; batch adversarial loss: 0.622651\n",
      "epoch 152; iter: 0; batch classifier loss: 0.437662; batch adversarial loss: 0.582077\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329913; batch adversarial loss: 0.581376\n",
      "epoch 154; iter: 0; batch classifier loss: 0.293459; batch adversarial loss: 0.507519\n",
      "epoch 155; iter: 0; batch classifier loss: 0.313821; batch adversarial loss: 0.552204\n",
      "epoch 156; iter: 0; batch classifier loss: 0.322407; batch adversarial loss: 0.609517\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352406; batch adversarial loss: 0.550368\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345091; batch adversarial loss: 0.560363\n",
      "epoch 159; iter: 0; batch classifier loss: 0.357340; batch adversarial loss: 0.487993\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347163; batch adversarial loss: 0.565815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.358755; batch adversarial loss: 0.544365\n",
      "epoch 162; iter: 0; batch classifier loss: 0.406590; batch adversarial loss: 0.507637\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356524; batch adversarial loss: 0.569427\n",
      "epoch 164; iter: 0; batch classifier loss: 0.384047; batch adversarial loss: 0.532138\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372390; batch adversarial loss: 0.599296\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336893; batch adversarial loss: 0.597820\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348226; batch adversarial loss: 0.551164\n",
      "epoch 168; iter: 0; batch classifier loss: 0.310820; batch adversarial loss: 0.542301\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366823; batch adversarial loss: 0.582042\n",
      "epoch 170; iter: 0; batch classifier loss: 0.370896; batch adversarial loss: 0.596288\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313807; batch adversarial loss: 0.525527\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342770; batch adversarial loss: 0.492505\n",
      "epoch 173; iter: 0; batch classifier loss: 0.320840; batch adversarial loss: 0.501786\n",
      "epoch 174; iter: 0; batch classifier loss: 0.382059; batch adversarial loss: 0.622002\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311366; batch adversarial loss: 0.622054\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351469; batch adversarial loss: 0.580411\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337839; batch adversarial loss: 0.527356\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371489; batch adversarial loss: 0.553145\n",
      "epoch 179; iter: 0; batch classifier loss: 0.363716; batch adversarial loss: 0.544107\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376071; batch adversarial loss: 0.571713\n",
      "epoch 181; iter: 0; batch classifier loss: 0.372998; batch adversarial loss: 0.547026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375520; batch adversarial loss: 0.572267\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347820; batch adversarial loss: 0.520661\n",
      "epoch 184; iter: 0; batch classifier loss: 0.311011; batch adversarial loss: 0.607884\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376755; batch adversarial loss: 0.544901\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404273; batch adversarial loss: 0.592913\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345700; batch adversarial loss: 0.573663\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362593; batch adversarial loss: 0.600672\n",
      "epoch 189; iter: 0; batch classifier loss: 0.359827; batch adversarial loss: 0.553707\n",
      "epoch 190; iter: 0; batch classifier loss: 0.429962; batch adversarial loss: 0.607368\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324314; batch adversarial loss: 0.543936\n",
      "epoch 192; iter: 0; batch classifier loss: 0.280595; batch adversarial loss: 0.489357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378226; batch adversarial loss: 0.564949\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365264; batch adversarial loss: 0.524625\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335399; batch adversarial loss: 0.509112\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374624; batch adversarial loss: 0.559181\n",
      "epoch 197; iter: 0; batch classifier loss: 0.311206; batch adversarial loss: 0.590297\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390990; batch adversarial loss: 0.659348\n",
      "epoch 199; iter: 0; batch classifier loss: 0.403920; batch adversarial loss: 0.532904\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694435; batch adversarial loss: 0.903252\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627245; batch adversarial loss: 0.902315\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578874; batch adversarial loss: 0.787506\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637280; batch adversarial loss: 0.781098\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551209; batch adversarial loss: 0.717183\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512447; batch adversarial loss: 0.700350\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486837; batch adversarial loss: 0.686393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592160; batch adversarial loss: 0.642709\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490241; batch adversarial loss: 0.645061\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530733; batch adversarial loss: 0.624700\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507362; batch adversarial loss: 0.623924\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522984; batch adversarial loss: 0.644594\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564764; batch adversarial loss: 0.560175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472624; batch adversarial loss: 0.598577\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489727; batch adversarial loss: 0.577562\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531431; batch adversarial loss: 0.546361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504620; batch adversarial loss: 0.556123\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435809; batch adversarial loss: 0.616847\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488747; batch adversarial loss: 0.591540\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476911; batch adversarial loss: 0.532354\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473738; batch adversarial loss: 0.527134\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478362; batch adversarial loss: 0.511864\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489426; batch adversarial loss: 0.565444\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460571; batch adversarial loss: 0.578459\n",
      "epoch 24; iter: 0; batch classifier loss: 0.430955; batch adversarial loss: 0.642839\n",
      "epoch 25; iter: 0; batch classifier loss: 0.444729; batch adversarial loss: 0.573547\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512975; batch adversarial loss: 0.603059\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489321; batch adversarial loss: 0.541231\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499721; batch adversarial loss: 0.516436\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462922; batch adversarial loss: 0.622776\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456057; batch adversarial loss: 0.638803\n",
      "epoch 31; iter: 0; batch classifier loss: 0.386268; batch adversarial loss: 0.554473\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420918; batch adversarial loss: 0.562617\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441627; batch adversarial loss: 0.580966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390649; batch adversarial loss: 0.530423\n",
      "epoch 35; iter: 0; batch classifier loss: 0.541458; batch adversarial loss: 0.470425\n",
      "epoch 36; iter: 0; batch classifier loss: 0.393028; batch adversarial loss: 0.466804\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432220; batch adversarial loss: 0.528739\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426455; batch adversarial loss: 0.625916\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470597; batch adversarial loss: 0.530855\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475567; batch adversarial loss: 0.571242\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456862; batch adversarial loss: 0.592150\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447714; batch adversarial loss: 0.525354\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425183; batch adversarial loss: 0.559175\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509299; batch adversarial loss: 0.578948\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428368; batch adversarial loss: 0.579665\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422520; batch adversarial loss: 0.537784\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450439; batch adversarial loss: 0.561396\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430263; batch adversarial loss: 0.560679\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390685; batch adversarial loss: 0.607234\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386265; batch adversarial loss: 0.597587\n",
      "epoch 51; iter: 0; batch classifier loss: 0.491689; batch adversarial loss: 0.525403\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456199; batch adversarial loss: 0.553827\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439387; batch adversarial loss: 0.499567\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418346; batch adversarial loss: 0.580328\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426308; batch adversarial loss: 0.562601\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418620; batch adversarial loss: 0.518180\n",
      "epoch 57; iter: 0; batch classifier loss: 0.373871; batch adversarial loss: 0.570432\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378672; batch adversarial loss: 0.510633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.389529; batch adversarial loss: 0.527678\n",
      "epoch 60; iter: 0; batch classifier loss: 0.378527; batch adversarial loss: 0.526822\n",
      "epoch 61; iter: 0; batch classifier loss: 0.487580; batch adversarial loss: 0.595960\n",
      "epoch 62; iter: 0; batch classifier loss: 0.447013; batch adversarial loss: 0.474321\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423758; batch adversarial loss: 0.617060\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465125; batch adversarial loss: 0.615988\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413860; batch adversarial loss: 0.570771\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433316; batch adversarial loss: 0.482849\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387957; batch adversarial loss: 0.517122\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410326; batch adversarial loss: 0.561278\n",
      "epoch 69; iter: 0; batch classifier loss: 0.379468; batch adversarial loss: 0.588707\n",
      "epoch 70; iter: 0; batch classifier loss: 0.479945; batch adversarial loss: 0.570475\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432391; batch adversarial loss: 0.571468\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412885; batch adversarial loss: 0.518600\n",
      "epoch 73; iter: 0; batch classifier loss: 0.475850; batch adversarial loss: 0.482052\n",
      "epoch 74; iter: 0; batch classifier loss: 0.494194; batch adversarial loss: 0.526223\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420052; batch adversarial loss: 0.562686\n",
      "epoch 76; iter: 0; batch classifier loss: 0.346424; batch adversarial loss: 0.554305\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434024; batch adversarial loss: 0.544794\n",
      "epoch 78; iter: 0; batch classifier loss: 0.513963; batch adversarial loss: 0.553372\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418264; batch adversarial loss: 0.553078\n",
      "epoch 80; iter: 0; batch classifier loss: 0.329686; batch adversarial loss: 0.597377\n",
      "epoch 81; iter: 0; batch classifier loss: 0.453060; batch adversarial loss: 0.500344\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366472; batch adversarial loss: 0.561625\n",
      "epoch 83; iter: 0; batch classifier loss: 0.454410; batch adversarial loss: 0.499647\n",
      "epoch 84; iter: 0; batch classifier loss: 0.328896; batch adversarial loss: 0.607018\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392833; batch adversarial loss: 0.634508\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418263; batch adversarial loss: 0.562129\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386925; batch adversarial loss: 0.490378\n",
      "epoch 88; iter: 0; batch classifier loss: 0.463862; batch adversarial loss: 0.535516\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398876; batch adversarial loss: 0.552842\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413715; batch adversarial loss: 0.607517\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391101; batch adversarial loss: 0.581221\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408950; batch adversarial loss: 0.597448\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378529; batch adversarial loss: 0.560895\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356922; batch adversarial loss: 0.518787\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407072; batch adversarial loss: 0.605967\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404614; batch adversarial loss: 0.553746\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430267; batch adversarial loss: 0.588185\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368171; batch adversarial loss: 0.596087\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389515; batch adversarial loss: 0.501247\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349402; batch adversarial loss: 0.535172\n",
      "epoch 101; iter: 0; batch classifier loss: 0.416203; batch adversarial loss: 0.483835\n",
      "epoch 102; iter: 0; batch classifier loss: 0.425238; batch adversarial loss: 0.535536\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388989; batch adversarial loss: 0.562034\n",
      "epoch 104; iter: 0; batch classifier loss: 0.330951; batch adversarial loss: 0.615218\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404903; batch adversarial loss: 0.562046\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376664; batch adversarial loss: 0.536749\n",
      "epoch 107; iter: 0; batch classifier loss: 0.442920; batch adversarial loss: 0.605766\n",
      "epoch 108; iter: 0; batch classifier loss: 0.284643; batch adversarial loss: 0.597483\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365512; batch adversarial loss: 0.587940\n",
      "epoch 110; iter: 0; batch classifier loss: 0.323003; batch adversarial loss: 0.588678\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386135; batch adversarial loss: 0.552198\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398462; batch adversarial loss: 0.551931\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343698; batch adversarial loss: 0.481399\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391428; batch adversarial loss: 0.518069\n",
      "epoch 115; iter: 0; batch classifier loss: 0.422053; batch adversarial loss: 0.535828\n",
      "epoch 116; iter: 0; batch classifier loss: 0.330706; batch adversarial loss: 0.552914\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388604; batch adversarial loss: 0.535061\n",
      "epoch 118; iter: 0; batch classifier loss: 0.303605; batch adversarial loss: 0.572009\n",
      "epoch 119; iter: 0; batch classifier loss: 0.322158; batch adversarial loss: 0.544242\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398831; batch adversarial loss: 0.545373\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346468; batch adversarial loss: 0.525778\n",
      "epoch 122; iter: 0; batch classifier loss: 0.287539; batch adversarial loss: 0.615200\n",
      "epoch 123; iter: 0; batch classifier loss: 0.379565; batch adversarial loss: 0.589101\n",
      "epoch 124; iter: 0; batch classifier loss: 0.540592; batch adversarial loss: 0.519357\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397699; batch adversarial loss: 0.553414\n",
      "epoch 126; iter: 0; batch classifier loss: 0.431343; batch adversarial loss: 0.473396\n",
      "epoch 127; iter: 0; batch classifier loss: 0.459139; batch adversarial loss: 0.571939\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383714; batch adversarial loss: 0.545190\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376071; batch adversarial loss: 0.562342\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340799; batch adversarial loss: 0.491490\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380412; batch adversarial loss: 0.553544\n",
      "epoch 132; iter: 0; batch classifier loss: 0.383104; batch adversarial loss: 0.544528\n",
      "epoch 133; iter: 0; batch classifier loss: 0.297532; batch adversarial loss: 0.589141\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344226; batch adversarial loss: 0.553632\n",
      "epoch 135; iter: 0; batch classifier loss: 0.447324; batch adversarial loss: 0.553365\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372612; batch adversarial loss: 0.571235\n",
      "epoch 137; iter: 0; batch classifier loss: 0.438587; batch adversarial loss: 0.509475\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368878; batch adversarial loss: 0.544893\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342220; batch adversarial loss: 0.633610\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400564; batch adversarial loss: 0.616183\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367535; batch adversarial loss: 0.472692\n",
      "epoch 142; iter: 0; batch classifier loss: 0.414769; batch adversarial loss: 0.581119\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394060; batch adversarial loss: 0.606712\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388913; batch adversarial loss: 0.571669\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334647; batch adversarial loss: 0.589432\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371599; batch adversarial loss: 0.482499\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351622; batch adversarial loss: 0.544261\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356424; batch adversarial loss: 0.562385\n",
      "epoch 149; iter: 0; batch classifier loss: 0.260286; batch adversarial loss: 0.518002\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388385; batch adversarial loss: 0.606733\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327888; batch adversarial loss: 0.633118\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323349; batch adversarial loss: 0.616195\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352342; batch adversarial loss: 0.588020\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344698; batch adversarial loss: 0.553995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.446950; batch adversarial loss: 0.581353\n",
      "epoch 156; iter: 0; batch classifier loss: 0.276792; batch adversarial loss: 0.553417\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381378; batch adversarial loss: 0.500859\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342180; batch adversarial loss: 0.624995\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383647; batch adversarial loss: 0.473549\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346517; batch adversarial loss: 0.554112\n",
      "epoch 161; iter: 0; batch classifier loss: 0.285759; batch adversarial loss: 0.544861\n",
      "epoch 162; iter: 0; batch classifier loss: 0.425909; batch adversarial loss: 0.570959\n",
      "epoch 163; iter: 0; batch classifier loss: 0.332196; batch adversarial loss: 0.571480\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400703; batch adversarial loss: 0.580203\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330235; batch adversarial loss: 0.517209\n",
      "epoch 166; iter: 0; batch classifier loss: 0.281188; batch adversarial loss: 0.579825\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346904; batch adversarial loss: 0.553104\n",
      "epoch 168; iter: 0; batch classifier loss: 0.394339; batch adversarial loss: 0.624932\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330231; batch adversarial loss: 0.561683\n",
      "epoch 170; iter: 0; batch classifier loss: 0.418266; batch adversarial loss: 0.490591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367206; batch adversarial loss: 0.535351\n",
      "epoch 172; iter: 0; batch classifier loss: 0.309591; batch adversarial loss: 0.606851\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301062; batch adversarial loss: 0.447090\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350646; batch adversarial loss: 0.668704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339704; batch adversarial loss: 0.579654\n",
      "epoch 176; iter: 0; batch classifier loss: 0.298616; batch adversarial loss: 0.571289\n",
      "epoch 177; iter: 0; batch classifier loss: 0.302153; batch adversarial loss: 0.553343\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391368; batch adversarial loss: 0.544822\n",
      "epoch 179; iter: 0; batch classifier loss: 0.415122; batch adversarial loss: 0.553386\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390841; batch adversarial loss: 0.625058\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388327; batch adversarial loss: 0.473898\n",
      "epoch 182; iter: 0; batch classifier loss: 0.311018; batch adversarial loss: 0.597783\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338028; batch adversarial loss: 0.553608\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343706; batch adversarial loss: 0.588939\n",
      "epoch 185; iter: 0; batch classifier loss: 0.287501; batch adversarial loss: 0.571226\n",
      "epoch 186; iter: 0; batch classifier loss: 0.345170; batch adversarial loss: 0.544729\n",
      "epoch 187; iter: 0; batch classifier loss: 0.321719; batch adversarial loss: 0.544732\n",
      "epoch 188; iter: 0; batch classifier loss: 0.414467; batch adversarial loss: 0.517911\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377335; batch adversarial loss: 0.518321\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368003; batch adversarial loss: 0.517571\n",
      "epoch 191; iter: 0; batch classifier loss: 0.394146; batch adversarial loss: 0.490425\n",
      "epoch 192; iter: 0; batch classifier loss: 0.307735; batch adversarial loss: 0.579609\n",
      "epoch 193; iter: 0; batch classifier loss: 0.385916; batch adversarial loss: 0.572188\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359215; batch adversarial loss: 0.580897\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332711; batch adversarial loss: 0.482372\n",
      "epoch 196; iter: 0; batch classifier loss: 0.404641; batch adversarial loss: 0.588872\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365690; batch adversarial loss: 0.562337\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350157; batch adversarial loss: 0.438757\n",
      "epoch 199; iter: 0; batch classifier loss: 0.402206; batch adversarial loss: 0.598595\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668485; batch adversarial loss: 0.599069\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606843; batch adversarial loss: 0.657965\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570073; batch adversarial loss: 0.662815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572029; batch adversarial loss: 0.639779\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601917; batch adversarial loss: 0.655905\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537807; batch adversarial loss: 0.604671\n",
      "epoch 6; iter: 0; batch classifier loss: 0.495734; batch adversarial loss: 0.649816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626508; batch adversarial loss: 0.610223\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541050; batch adversarial loss: 0.604443\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480728; batch adversarial loss: 0.608999\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546002; batch adversarial loss: 0.649336\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505316; batch adversarial loss: 0.612397\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566773; batch adversarial loss: 0.592085\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580624; batch adversarial loss: 0.600353\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507786; batch adversarial loss: 0.589289\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569638; batch adversarial loss: 0.497133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408462; batch adversarial loss: 0.594599\n",
      "epoch 17; iter: 0; batch classifier loss: 0.438365; batch adversarial loss: 0.591040\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467103; batch adversarial loss: 0.508238\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531523; batch adversarial loss: 0.578229\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502521; batch adversarial loss: 0.535676\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512562; batch adversarial loss: 0.580599\n",
      "epoch 22; iter: 0; batch classifier loss: 0.588620; batch adversarial loss: 0.572481\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451679; batch adversarial loss: 0.597137\n",
      "epoch 24; iter: 0; batch classifier loss: 0.415319; batch adversarial loss: 0.488916\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437916; batch adversarial loss: 0.494816\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472888; batch adversarial loss: 0.566525\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448482; batch adversarial loss: 0.459438\n",
      "epoch 28; iter: 0; batch classifier loss: 0.391097; batch adversarial loss: 0.473583\n",
      "epoch 29; iter: 0; batch classifier loss: 0.381063; batch adversarial loss: 0.596548\n",
      "epoch 30; iter: 0; batch classifier loss: 0.379627; batch adversarial loss: 0.551983\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432953; batch adversarial loss: 0.541587\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499767; batch adversarial loss: 0.611891\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412707; batch adversarial loss: 0.557403\n",
      "epoch 34; iter: 0; batch classifier loss: 0.369267; batch adversarial loss: 0.516375\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473121; batch adversarial loss: 0.508405\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477630; batch adversarial loss: 0.522220\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421510; batch adversarial loss: 0.548871\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398662; batch adversarial loss: 0.536526\n",
      "epoch 39; iter: 0; batch classifier loss: 0.565587; batch adversarial loss: 0.572873\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416872; batch adversarial loss: 0.467853\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440600; batch adversarial loss: 0.559988\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454253; batch adversarial loss: 0.599076\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481140; batch adversarial loss: 0.646121\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400381; batch adversarial loss: 0.490041\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481279; batch adversarial loss: 0.507664\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417737; batch adversarial loss: 0.563793\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447665; batch adversarial loss: 0.483221\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448719; batch adversarial loss: 0.570600\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404729; batch adversarial loss: 0.566630\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378878; batch adversarial loss: 0.512092\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382884; batch adversarial loss: 0.539998\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415183; batch adversarial loss: 0.526531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.391234; batch adversarial loss: 0.561534\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404032; batch adversarial loss: 0.534876\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413451; batch adversarial loss: 0.503508\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396231; batch adversarial loss: 0.494733\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374431; batch adversarial loss: 0.524726\n",
      "epoch 58; iter: 0; batch classifier loss: 0.449106; batch adversarial loss: 0.523521\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445280; batch adversarial loss: 0.517822\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411757; batch adversarial loss: 0.479483\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427958; batch adversarial loss: 0.562074\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370307; batch adversarial loss: 0.580928\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436743; batch adversarial loss: 0.525435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360031; batch adversarial loss: 0.562699\n",
      "epoch 65; iter: 0; batch classifier loss: 0.337161; batch adversarial loss: 0.507567\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434071; batch adversarial loss: 0.620224\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402882; batch adversarial loss: 0.469776\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415483; batch adversarial loss: 0.535528\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409391; batch adversarial loss: 0.544636\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434747; batch adversarial loss: 0.505545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381153; batch adversarial loss: 0.537008\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371586; batch adversarial loss: 0.571894\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421250; batch adversarial loss: 0.527138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428535; batch adversarial loss: 0.489706\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366543; batch adversarial loss: 0.481301\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385178; batch adversarial loss: 0.644834\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403566; batch adversarial loss: 0.506743\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386794; batch adversarial loss: 0.572758\n",
      "epoch 79; iter: 0; batch classifier loss: 0.438154; batch adversarial loss: 0.505824\n",
      "epoch 80; iter: 0; batch classifier loss: 0.310779; batch adversarial loss: 0.578379\n",
      "epoch 81; iter: 0; batch classifier loss: 0.339857; batch adversarial loss: 0.463215\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363917; batch adversarial loss: 0.481016\n",
      "epoch 83; iter: 0; batch classifier loss: 0.480342; batch adversarial loss: 0.508469\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390673; batch adversarial loss: 0.459203\n",
      "epoch 85; iter: 0; batch classifier loss: 0.439242; batch adversarial loss: 0.542801\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419536; batch adversarial loss: 0.570997\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383031; batch adversarial loss: 0.480100\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357529; batch adversarial loss: 0.514420\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412095; batch adversarial loss: 0.562168\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435502; batch adversarial loss: 0.574069\n",
      "epoch 91; iter: 0; batch classifier loss: 0.436883; batch adversarial loss: 0.518621\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368380; batch adversarial loss: 0.572536\n",
      "epoch 93; iter: 0; batch classifier loss: 0.430605; batch adversarial loss: 0.554430\n",
      "epoch 94; iter: 0; batch classifier loss: 0.445291; batch adversarial loss: 0.509282\n",
      "epoch 95; iter: 0; batch classifier loss: 0.354659; batch adversarial loss: 0.609127\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429468; batch adversarial loss: 0.563862\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355291; batch adversarial loss: 0.552673\n",
      "epoch 98; iter: 0; batch classifier loss: 0.431645; batch adversarial loss: 0.562997\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384274; batch adversarial loss: 0.608869\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416517; batch adversarial loss: 0.554383\n",
      "epoch 101; iter: 0; batch classifier loss: 0.271820; batch adversarial loss: 0.471817\n",
      "epoch 102; iter: 0; batch classifier loss: 0.408005; batch adversarial loss: 0.564544\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377340; batch adversarial loss: 0.572504\n",
      "epoch 104; iter: 0; batch classifier loss: 0.308648; batch adversarial loss: 0.507473\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363898; batch adversarial loss: 0.580484\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369494; batch adversarial loss: 0.580372\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399205; batch adversarial loss: 0.536042\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396540; batch adversarial loss: 0.580207\n",
      "epoch 109; iter: 0; batch classifier loss: 0.332700; batch adversarial loss: 0.534278\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349221; batch adversarial loss: 0.628549\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387736; batch adversarial loss: 0.569982\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379286; batch adversarial loss: 0.506985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343697; batch adversarial loss: 0.536853\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374254; batch adversarial loss: 0.515725\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367935; batch adversarial loss: 0.547450\n",
      "epoch 116; iter: 0; batch classifier loss: 0.362288; batch adversarial loss: 0.550668\n",
      "epoch 117; iter: 0; batch classifier loss: 0.320387; batch adversarial loss: 0.507480\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343489; batch adversarial loss: 0.507763\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375915; batch adversarial loss: 0.560556\n",
      "epoch 120; iter: 0; batch classifier loss: 0.304377; batch adversarial loss: 0.573854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365158; batch adversarial loss: 0.422646\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356537; batch adversarial loss: 0.532997\n",
      "epoch 123; iter: 0; batch classifier loss: 0.331392; batch adversarial loss: 0.552145\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373019; batch adversarial loss: 0.554063\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329856; batch adversarial loss: 0.573303\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390520; batch adversarial loss: 0.506374\n",
      "epoch 127; iter: 0; batch classifier loss: 0.428238; batch adversarial loss: 0.600331\n",
      "epoch 128; iter: 0; batch classifier loss: 0.284247; batch adversarial loss: 0.534395\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399627; batch adversarial loss: 0.554910\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359882; batch adversarial loss: 0.571092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.444216; batch adversarial loss: 0.562992\n",
      "epoch 132; iter: 0; batch classifier loss: 0.432821; batch adversarial loss: 0.516455\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375772; batch adversarial loss: 0.554963\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366848; batch adversarial loss: 0.533897\n",
      "epoch 135; iter: 0; batch classifier loss: 0.391406; batch adversarial loss: 0.588354\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399552; batch adversarial loss: 0.451808\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378179; batch adversarial loss: 0.591264\n",
      "epoch 138; iter: 0; batch classifier loss: 0.521003; batch adversarial loss: 0.527612\n",
      "epoch 139; iter: 0; batch classifier loss: 0.454288; batch adversarial loss: 0.517495\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381141; batch adversarial loss: 0.486646\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422987; batch adversarial loss: 0.545646\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395898; batch adversarial loss: 0.479883\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328322; batch adversarial loss: 0.497175\n",
      "epoch 144; iter: 0; batch classifier loss: 0.450183; batch adversarial loss: 0.563600\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404162; batch adversarial loss: 0.487695\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330437; batch adversarial loss: 0.617216\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361650; batch adversarial loss: 0.517603\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396009; batch adversarial loss: 0.536260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.354355; batch adversarial loss: 0.564224\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379151; batch adversarial loss: 0.544702\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322083; batch adversarial loss: 0.518921\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397590; batch adversarial loss: 0.562865\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364073; batch adversarial loss: 0.553547\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402103; batch adversarial loss: 0.563818\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373463; batch adversarial loss: 0.518711\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354980; batch adversarial loss: 0.516661\n",
      "epoch 157; iter: 0; batch classifier loss: 0.390169; batch adversarial loss: 0.525313\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352233; batch adversarial loss: 0.526148\n",
      "epoch 159; iter: 0; batch classifier loss: 0.307960; batch adversarial loss: 0.645922\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342328; batch adversarial loss: 0.525419\n",
      "epoch 161; iter: 0; batch classifier loss: 0.413216; batch adversarial loss: 0.626535\n",
      "epoch 162; iter: 0; batch classifier loss: 0.316689; batch adversarial loss: 0.617123\n",
      "epoch 163; iter: 0; batch classifier loss: 0.286612; batch adversarial loss: 0.525618\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363738; batch adversarial loss: 0.490416\n",
      "epoch 165; iter: 0; batch classifier loss: 0.347742; batch adversarial loss: 0.545700\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349244; batch adversarial loss: 0.590021\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356041; batch adversarial loss: 0.590869\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370459; batch adversarial loss: 0.535544\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358087; batch adversarial loss: 0.524409\n",
      "epoch 170; iter: 0; batch classifier loss: 0.334210; batch adversarial loss: 0.525084\n",
      "epoch 171; iter: 0; batch classifier loss: 0.337332; batch adversarial loss: 0.525697\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409355; batch adversarial loss: 0.534803\n",
      "epoch 173; iter: 0; batch classifier loss: 0.294421; batch adversarial loss: 0.618545\n",
      "epoch 174; iter: 0; batch classifier loss: 0.286246; batch adversarial loss: 0.562328\n",
      "epoch 175; iter: 0; batch classifier loss: 0.301705; batch adversarial loss: 0.489234\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369877; batch adversarial loss: 0.544063\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305336; batch adversarial loss: 0.563001\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390352; batch adversarial loss: 0.489702\n",
      "epoch 179; iter: 0; batch classifier loss: 0.436183; batch adversarial loss: 0.506740\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372670; batch adversarial loss: 0.562975\n",
      "epoch 181; iter: 0; batch classifier loss: 0.359128; batch adversarial loss: 0.488770\n",
      "epoch 182; iter: 0; batch classifier loss: 0.403529; batch adversarial loss: 0.478996\n",
      "epoch 183; iter: 0; batch classifier loss: 0.389528; batch adversarial loss: 0.544957\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374669; batch adversarial loss: 0.562609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.285576; batch adversarial loss: 0.518193\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377782; batch adversarial loss: 0.608790\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338873; batch adversarial loss: 0.640245\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348071; batch adversarial loss: 0.499383\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370380; batch adversarial loss: 0.674126\n",
      "epoch 190; iter: 0; batch classifier loss: 0.331003; batch adversarial loss: 0.600536\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372724; batch adversarial loss: 0.545678\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367351; batch adversarial loss: 0.488018\n",
      "epoch 193; iter: 0; batch classifier loss: 0.283908; batch adversarial loss: 0.527028\n",
      "epoch 194; iter: 0; batch classifier loss: 0.402944; batch adversarial loss: 0.551787\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338898; batch adversarial loss: 0.562908\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314482; batch adversarial loss: 0.536172\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364408; batch adversarial loss: 0.507188\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356943; batch adversarial loss: 0.525188\n",
      "epoch 199; iter: 0; batch classifier loss: 0.322505; batch adversarial loss: 0.609318\n",
      "epoch 0; iter: 0; batch classifier loss: 0.778774; batch adversarial loss: 0.624626\n",
      "epoch 1; iter: 0; batch classifier loss: 0.641993; batch adversarial loss: 0.630361\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575422; batch adversarial loss: 0.652799\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530169; batch adversarial loss: 0.622611\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553067; batch adversarial loss: 0.626669\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521966; batch adversarial loss: 0.609607\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582942; batch adversarial loss: 0.597019\n",
      "epoch 7; iter: 0; batch classifier loss: 0.590833; batch adversarial loss: 0.661746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501068; batch adversarial loss: 0.585167\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610489; batch adversarial loss: 0.579820\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547737; batch adversarial loss: 0.657857\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539252; batch adversarial loss: 0.622256\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578479; batch adversarial loss: 0.604356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537796; batch adversarial loss: 0.533805\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486056; batch adversarial loss: 0.531613\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487115; batch adversarial loss: 0.563730\n",
      "epoch 16; iter: 0; batch classifier loss: 0.544897; batch adversarial loss: 0.588535\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463948; batch adversarial loss: 0.560563\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526897; batch adversarial loss: 0.520619\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522408; batch adversarial loss: 0.545340\n",
      "epoch 20; iter: 0; batch classifier loss: 0.570911; batch adversarial loss: 0.547503\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488989; batch adversarial loss: 0.449070\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512903; batch adversarial loss: 0.528865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490140; batch adversarial loss: 0.518073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.418293; batch adversarial loss: 0.617772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480127; batch adversarial loss: 0.451576\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436261; batch adversarial loss: 0.554993\n",
      "epoch 27; iter: 0; batch classifier loss: 0.545217; batch adversarial loss: 0.496817\n",
      "epoch 28; iter: 0; batch classifier loss: 0.371430; batch adversarial loss: 0.553740\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458856; batch adversarial loss: 0.580797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430563; batch adversarial loss: 0.545246\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466487; batch adversarial loss: 0.544643\n",
      "epoch 32; iter: 0; batch classifier loss: 0.401919; batch adversarial loss: 0.571321\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483925; batch adversarial loss: 0.526590\n",
      "epoch 34; iter: 0; batch classifier loss: 0.375483; batch adversarial loss: 0.570027\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457664; batch adversarial loss: 0.579822\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463001; batch adversarial loss: 0.535415\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503278; batch adversarial loss: 0.553403\n",
      "epoch 38; iter: 0; batch classifier loss: 0.509205; batch adversarial loss: 0.597814\n",
      "epoch 39; iter: 0; batch classifier loss: 0.496495; batch adversarial loss: 0.625879\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445502; batch adversarial loss: 0.526273\n",
      "epoch 41; iter: 0; batch classifier loss: 0.479508; batch adversarial loss: 0.562634\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438957; batch adversarial loss: 0.553431\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458439; batch adversarial loss: 0.580971\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366642; batch adversarial loss: 0.562673\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441265; batch adversarial loss: 0.580839\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411962; batch adversarial loss: 0.499210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.500336; batch adversarial loss: 0.463240\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444217; batch adversarial loss: 0.616150\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371065; batch adversarial loss: 0.571532\n",
      "epoch 50; iter: 0; batch classifier loss: 0.364678; batch adversarial loss: 0.570344\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445668; batch adversarial loss: 0.518352\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399983; batch adversarial loss: 0.580388\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462492; batch adversarial loss: 0.526100\n",
      "epoch 54; iter: 0; batch classifier loss: 0.403149; batch adversarial loss: 0.604485\n",
      "epoch 55; iter: 0; batch classifier loss: 0.365723; batch adversarial loss: 0.544716\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391696; batch adversarial loss: 0.597917\n",
      "epoch 57; iter: 0; batch classifier loss: 0.452081; batch adversarial loss: 0.574974\n",
      "epoch 58; iter: 0; batch classifier loss: 0.486994; batch adversarial loss: 0.569437\n",
      "epoch 59; iter: 0; batch classifier loss: 0.379156; batch adversarial loss: 0.550945\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397096; batch adversarial loss: 0.509607\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475594; batch adversarial loss: 0.593158\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392232; batch adversarial loss: 0.491621\n",
      "epoch 63; iter: 0; batch classifier loss: 0.445509; batch adversarial loss: 0.517285\n",
      "epoch 64; iter: 0; batch classifier loss: 0.468610; batch adversarial loss: 0.676432\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407771; batch adversarial loss: 0.581867\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389404; batch adversarial loss: 0.488466\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403423; batch adversarial loss: 0.544437\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386354; batch adversarial loss: 0.516635\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395922; batch adversarial loss: 0.535270\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358606; batch adversarial loss: 0.489202\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349880; batch adversarial loss: 0.544379\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405728; batch adversarial loss: 0.562828\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358335; batch adversarial loss: 0.516895\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446797; batch adversarial loss: 0.562935\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425143; batch adversarial loss: 0.544511\n",
      "epoch 76; iter: 0; batch classifier loss: 0.401792; batch adversarial loss: 0.516999\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398004; batch adversarial loss: 0.480438\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379024; batch adversarial loss: 0.553746\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376649; batch adversarial loss: 0.553730\n",
      "epoch 80; iter: 0; batch classifier loss: 0.352447; batch adversarial loss: 0.562548\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368376; batch adversarial loss: 0.599254\n",
      "epoch 82; iter: 0; batch classifier loss: 0.373252; batch adversarial loss: 0.434987\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391505; batch adversarial loss: 0.489228\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409449; batch adversarial loss: 0.543821\n",
      "epoch 85; iter: 0; batch classifier loss: 0.488037; batch adversarial loss: 0.571879\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406032; batch adversarial loss: 0.553232\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381149; batch adversarial loss: 0.570881\n",
      "epoch 88; iter: 0; batch classifier loss: 0.404836; batch adversarial loss: 0.608251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382827; batch adversarial loss: 0.554321\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393424; batch adversarial loss: 0.546376\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421876; batch adversarial loss: 0.572160\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.508498\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402356; batch adversarial loss: 0.562633\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357899; batch adversarial loss: 0.635166\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401817; batch adversarial loss: 0.499125\n",
      "epoch 96; iter: 0; batch classifier loss: 0.462236; batch adversarial loss: 0.543922\n",
      "epoch 97; iter: 0; batch classifier loss: 0.327171; batch adversarial loss: 0.580437\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382784; batch adversarial loss: 0.489476\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332262; batch adversarial loss: 0.599747\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370925; batch adversarial loss: 0.452683\n",
      "epoch 101; iter: 0; batch classifier loss: 0.451768; batch adversarial loss: 0.571989\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342429; batch adversarial loss: 0.626661\n",
      "epoch 103; iter: 0; batch classifier loss: 0.319395; batch adversarial loss: 0.516824\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415853; batch adversarial loss: 0.525638\n",
      "epoch 105; iter: 0; batch classifier loss: 0.354070; batch adversarial loss: 0.498904\n",
      "epoch 106; iter: 0; batch classifier loss: 0.426085; batch adversarial loss: 0.552989\n",
      "epoch 107; iter: 0; batch classifier loss: 0.359466; batch adversarial loss: 0.552742\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387466; batch adversarial loss: 0.554155\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385235; batch adversarial loss: 0.562899\n",
      "epoch 110; iter: 0; batch classifier loss: 0.416855; batch adversarial loss: 0.552906\n",
      "epoch 111; iter: 0; batch classifier loss: 0.296797; batch adversarial loss: 0.625266\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358452; batch adversarial loss: 0.525896\n",
      "epoch 113; iter: 0; batch classifier loss: 0.393774; batch adversarial loss: 0.617483\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344774; batch adversarial loss: 0.480720\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340758; batch adversarial loss: 0.591240\n",
      "epoch 116; iter: 0; batch classifier loss: 0.442320; batch adversarial loss: 0.545464\n",
      "epoch 117; iter: 0; batch classifier loss: 0.323585; batch adversarial loss: 0.579981\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342949; batch adversarial loss: 0.489310\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344324; batch adversarial loss: 0.544901\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379486; batch adversarial loss: 0.508477\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358325; batch adversarial loss: 0.572032\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356114; batch adversarial loss: 0.581603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357797; batch adversarial loss: 0.452779\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339723; batch adversarial loss: 0.580802\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371802; batch adversarial loss: 0.599489\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324322; batch adversarial loss: 0.590093\n",
      "epoch 127; iter: 0; batch classifier loss: 0.279515; batch adversarial loss: 0.534771\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332552; batch adversarial loss: 0.565005\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395623; batch adversarial loss: 0.563837\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383522; batch adversarial loss: 0.553039\n",
      "epoch 131; iter: 0; batch classifier loss: 0.325105; batch adversarial loss: 0.562742\n",
      "epoch 132; iter: 0; batch classifier loss: 0.338973; batch adversarial loss: 0.554598\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326457; batch adversarial loss: 0.480803\n",
      "epoch 134; iter: 0; batch classifier loss: 0.296051; batch adversarial loss: 0.508035\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325396; batch adversarial loss: 0.570958\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328113; batch adversarial loss: 0.535064\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354759; batch adversarial loss: 0.617374\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378649; batch adversarial loss: 0.507233\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363562; batch adversarial loss: 0.516385\n",
      "epoch 140; iter: 0; batch classifier loss: 0.321950; batch adversarial loss: 0.543844\n",
      "epoch 141; iter: 0; batch classifier loss: 0.331676; batch adversarial loss: 0.545273\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354052; batch adversarial loss: 0.524637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.434874; batch adversarial loss: 0.488920\n",
      "epoch 144; iter: 0; batch classifier loss: 0.514216; batch adversarial loss: 0.573823\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418998; batch adversarial loss: 0.497840\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358137; batch adversarial loss: 0.542470\n",
      "epoch 147; iter: 0; batch classifier loss: 0.324464; batch adversarial loss: 0.546253\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360501; batch adversarial loss: 0.551831\n",
      "epoch 149; iter: 0; batch classifier loss: 0.340631; batch adversarial loss: 0.527464\n",
      "epoch 150; iter: 0; batch classifier loss: 0.408035; batch adversarial loss: 0.534772\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353713; batch adversarial loss: 0.544407\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363883; batch adversarial loss: 0.480831\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381598; batch adversarial loss: 0.562228\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375187; batch adversarial loss: 0.600224\n",
      "epoch 155; iter: 0; batch classifier loss: 0.402282; batch adversarial loss: 0.625302\n",
      "epoch 156; iter: 0; batch classifier loss: 0.407518; batch adversarial loss: 0.580176\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333053; batch adversarial loss: 0.590361\n",
      "epoch 158; iter: 0; batch classifier loss: 0.293755; batch adversarial loss: 0.554405\n",
      "epoch 159; iter: 0; batch classifier loss: 0.283947; batch adversarial loss: 0.544504\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328799; batch adversarial loss: 0.536082\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369831; batch adversarial loss: 0.535186\n",
      "epoch 162; iter: 0; batch classifier loss: 0.319650; batch adversarial loss: 0.480665\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321223; batch adversarial loss: 0.544132\n",
      "epoch 164; iter: 0; batch classifier loss: 0.449263; batch adversarial loss: 0.481738\n",
      "epoch 165; iter: 0; batch classifier loss: 0.293039; batch adversarial loss: 0.590474\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366588; batch adversarial loss: 0.580513\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353399; batch adversarial loss: 0.553613\n",
      "epoch 168; iter: 0; batch classifier loss: 0.379292; batch adversarial loss: 0.590403\n",
      "epoch 169; iter: 0; batch classifier loss: 0.402995; batch adversarial loss: 0.588824\n",
      "epoch 170; iter: 0; batch classifier loss: 0.317675; batch adversarial loss: 0.518382\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346700; batch adversarial loss: 0.526054\n",
      "epoch 172; iter: 0; batch classifier loss: 0.338009; batch adversarial loss: 0.589359\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342184; batch adversarial loss: 0.536246\n",
      "epoch 174; iter: 0; batch classifier loss: 0.398458; batch adversarial loss: 0.526099\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395337; batch adversarial loss: 0.544058\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352684; batch adversarial loss: 0.534067\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336861; batch adversarial loss: 0.498801\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336952; batch adversarial loss: 0.525573\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356369; batch adversarial loss: 0.570978\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376392; batch adversarial loss: 0.499333\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339240; batch adversarial loss: 0.535524\n",
      "epoch 182; iter: 0; batch classifier loss: 0.481064; batch adversarial loss: 0.534381\n",
      "epoch 183; iter: 0; batch classifier loss: 0.399795; batch adversarial loss: 0.489412\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385978; batch adversarial loss: 0.563397\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379337; batch adversarial loss: 0.597748\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349312; batch adversarial loss: 0.626252\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357878; batch adversarial loss: 0.499174\n",
      "epoch 188; iter: 0; batch classifier loss: 0.319428; batch adversarial loss: 0.572398\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336717; batch adversarial loss: 0.526500\n",
      "epoch 190; iter: 0; batch classifier loss: 0.279015; batch adversarial loss: 0.516379\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350619; batch adversarial loss: 0.536357\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319539; batch adversarial loss: 0.488287\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350542; batch adversarial loss: 0.562673\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356658; batch adversarial loss: 0.553689\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349289; batch adversarial loss: 0.534616\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374178; batch adversarial loss: 0.490438\n",
      "epoch 197; iter: 0; batch classifier loss: 0.310983; batch adversarial loss: 0.498945\n",
      "epoch 198; iter: 0; batch classifier loss: 0.412541; batch adversarial loss: 0.524835\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348672; batch adversarial loss: 0.590383\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728406; batch adversarial loss: 0.620294\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539781; batch adversarial loss: 0.622976\n",
      "epoch 2; iter: 0; batch classifier loss: 0.543512; batch adversarial loss: 0.626067\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584104; batch adversarial loss: 0.652356\n",
      "epoch 4; iter: 0; batch classifier loss: 0.503996; batch adversarial loss: 0.644332\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621614; batch adversarial loss: 0.654336\n",
      "epoch 6; iter: 0; batch classifier loss: 0.672912; batch adversarial loss: 0.633554\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604466; batch adversarial loss: 0.571500\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574923; batch adversarial loss: 0.599804\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544654; batch adversarial loss: 0.535171\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508145; batch adversarial loss: 0.604252\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549622; batch adversarial loss: 0.595384\n",
      "epoch 12; iter: 0; batch classifier loss: 0.574760; batch adversarial loss: 0.527280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580890; batch adversarial loss: 0.567049\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553449; batch adversarial loss: 0.546533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520524; batch adversarial loss: 0.593995\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459379; batch adversarial loss: 0.568777\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502286; batch adversarial loss: 0.570055\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474959; batch adversarial loss: 0.527507\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445177; batch adversarial loss: 0.544285\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499217; batch adversarial loss: 0.585713\n",
      "epoch 21; iter: 0; batch classifier loss: 0.579505; batch adversarial loss: 0.552603\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495657; batch adversarial loss: 0.549374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379254; batch adversarial loss: 0.551927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519310; batch adversarial loss: 0.602154\n",
      "epoch 25; iter: 0; batch classifier loss: 0.554547; batch adversarial loss: 0.604845\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493008; batch adversarial loss: 0.545628\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461830; batch adversarial loss: 0.552307\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462321; batch adversarial loss: 0.558057\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492936; batch adversarial loss: 0.571232\n",
      "epoch 30; iter: 0; batch classifier loss: 0.420118; batch adversarial loss: 0.570984\n",
      "epoch 31; iter: 0; batch classifier loss: 0.401233; batch adversarial loss: 0.602383\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407308; batch adversarial loss: 0.597230\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422073; batch adversarial loss: 0.609126\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390378; batch adversarial loss: 0.564925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429176; batch adversarial loss: 0.637991\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425001; batch adversarial loss: 0.599206\n",
      "epoch 37; iter: 0; batch classifier loss: 0.377174; batch adversarial loss: 0.510328\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424354; batch adversarial loss: 0.615535\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441799; batch adversarial loss: 0.581324\n",
      "epoch 40; iter: 0; batch classifier loss: 0.512427; batch adversarial loss: 0.554278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.450693; batch adversarial loss: 0.518673\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451123; batch adversarial loss: 0.491366\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419002; batch adversarial loss: 0.599825\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469176; batch adversarial loss: 0.515950\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451588; batch adversarial loss: 0.489283\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428462; batch adversarial loss: 0.580261\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423557; batch adversarial loss: 0.471136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.472666; batch adversarial loss: 0.621243\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426938; batch adversarial loss: 0.542467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460545; batch adversarial loss: 0.554726\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409158; batch adversarial loss: 0.432894\n",
      "epoch 52; iter: 0; batch classifier loss: 0.481281; batch adversarial loss: 0.479536\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439084; batch adversarial loss: 0.551391\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486841; batch adversarial loss: 0.628780\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442471; batch adversarial loss: 0.514776\n",
      "epoch 56; iter: 0; batch classifier loss: 0.367156; batch adversarial loss: 0.516479\n",
      "epoch 57; iter: 0; batch classifier loss: 0.485976; batch adversarial loss: 0.601234\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432171; batch adversarial loss: 0.536380\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467525; batch adversarial loss: 0.526773\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402267; batch adversarial loss: 0.626805\n",
      "epoch 61; iter: 0; batch classifier loss: 0.377667; batch adversarial loss: 0.626006\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.562777\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460342; batch adversarial loss: 0.626378\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381006; batch adversarial loss: 0.517149\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380711; batch adversarial loss: 0.480671\n",
      "epoch 66; iter: 0; batch classifier loss: 0.478459; batch adversarial loss: 0.526633\n",
      "epoch 67; iter: 0; batch classifier loss: 0.371360; batch adversarial loss: 0.516596\n",
      "epoch 68; iter: 0; batch classifier loss: 0.470615; batch adversarial loss: 0.526240\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396403; batch adversarial loss: 0.562777\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437803; batch adversarial loss: 0.527000\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393680; batch adversarial loss: 0.517191\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432801; batch adversarial loss: 0.581348\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438030; batch adversarial loss: 0.517967\n",
      "epoch 74; iter: 0; batch classifier loss: 0.316340; batch adversarial loss: 0.601055\n",
      "epoch 75; iter: 0; batch classifier loss: 0.348443; batch adversarial loss: 0.525541\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388615; batch adversarial loss: 0.637862\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419467; batch adversarial loss: 0.535508\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400505; batch adversarial loss: 0.562781\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395016; batch adversarial loss: 0.526381\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441901; batch adversarial loss: 0.544884\n",
      "epoch 81; iter: 0; batch classifier loss: 0.485268; batch adversarial loss: 0.572475\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417000; batch adversarial loss: 0.498439\n",
      "epoch 83; iter: 0; batch classifier loss: 0.344204; batch adversarial loss: 0.544041\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410671; batch adversarial loss: 0.563043\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412731; batch adversarial loss: 0.590926\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425046; batch adversarial loss: 0.497989\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422743; batch adversarial loss: 0.600061\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393506; batch adversarial loss: 0.544395\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428999; batch adversarial loss: 0.609147\n",
      "epoch 90; iter: 0; batch classifier loss: 0.468317; batch adversarial loss: 0.535122\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441090; batch adversarial loss: 0.590372\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382578; batch adversarial loss: 0.600171\n",
      "epoch 93; iter: 0; batch classifier loss: 0.523155; batch adversarial loss: 0.572695\n",
      "epoch 94; iter: 0; batch classifier loss: 0.474716; batch adversarial loss: 0.516701\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392543; batch adversarial loss: 0.480259\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394305; batch adversarial loss: 0.562830\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411596; batch adversarial loss: 0.627444\n",
      "epoch 98; iter: 0; batch classifier loss: 0.314591; batch adversarial loss: 0.498708\n",
      "epoch 99; iter: 0; batch classifier loss: 0.449120; batch adversarial loss: 0.563005\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358277; batch adversarial loss: 0.572080\n",
      "epoch 101; iter: 0; batch classifier loss: 0.380696; batch adversarial loss: 0.581151\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371842; batch adversarial loss: 0.489744\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373329; batch adversarial loss: 0.562814\n",
      "epoch 104; iter: 0; batch classifier loss: 0.459664; batch adversarial loss: 0.544039\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404370; batch adversarial loss: 0.525350\n",
      "epoch 106; iter: 0; batch classifier loss: 0.323935; batch adversarial loss: 0.579997\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357277; batch adversarial loss: 0.569880\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386963; batch adversarial loss: 0.608491\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423860; batch adversarial loss: 0.572964\n",
      "epoch 110; iter: 0; batch classifier loss: 0.332535; batch adversarial loss: 0.582132\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366354; batch adversarial loss: 0.553803\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372077; batch adversarial loss: 0.525895\n",
      "epoch 113; iter: 0; batch classifier loss: 0.320942; batch adversarial loss: 0.563089\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418634; batch adversarial loss: 0.544307\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396216; batch adversarial loss: 0.553206\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339732; batch adversarial loss: 0.526643\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354269; batch adversarial loss: 0.656060\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330801; batch adversarial loss: 0.553776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433411; batch adversarial loss: 0.535203\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338600; batch adversarial loss: 0.553841\n",
      "epoch 121; iter: 0; batch classifier loss: 0.410440; batch adversarial loss: 0.579929\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418578; batch adversarial loss: 0.608350\n",
      "epoch 123; iter: 0; batch classifier loss: 0.397665; batch adversarial loss: 0.480108\n",
      "epoch 124; iter: 0; batch classifier loss: 0.306809; batch adversarial loss: 0.572657\n",
      "epoch 125; iter: 0; batch classifier loss: 0.453016; batch adversarial loss: 0.536276\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387181; batch adversarial loss: 0.637099\n",
      "epoch 127; iter: 0; batch classifier loss: 0.457381; batch adversarial loss: 0.535443\n",
      "epoch 128; iter: 0; batch classifier loss: 0.414259; batch adversarial loss: 0.646697\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346812; batch adversarial loss: 0.591236\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406803; batch adversarial loss: 0.600381\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398744; batch adversarial loss: 0.609441\n",
      "epoch 132; iter: 0; batch classifier loss: 0.385759; batch adversarial loss: 0.553764\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356803; batch adversarial loss: 0.572337\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352845; batch adversarial loss: 0.535713\n",
      "epoch 135; iter: 0; batch classifier loss: 0.497096; batch adversarial loss: 0.516693\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385946; batch adversarial loss: 0.609647\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354053; batch adversarial loss: 0.544676\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368519; batch adversarial loss: 0.525882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.434233; batch adversarial loss: 0.488886\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395500; batch adversarial loss: 0.544540\n",
      "epoch 141; iter: 0; batch classifier loss: 0.431781; batch adversarial loss: 0.507464\n",
      "epoch 142; iter: 0; batch classifier loss: 0.445281; batch adversarial loss: 0.553607\n",
      "epoch 143; iter: 0; batch classifier loss: 0.427404; batch adversarial loss: 0.535214\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379659; batch adversarial loss: 0.581141\n",
      "epoch 145; iter: 0; batch classifier loss: 0.395014; batch adversarial loss: 0.525880\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329057; batch adversarial loss: 0.563037\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388646; batch adversarial loss: 0.544361\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352091; batch adversarial loss: 0.553750\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375518; batch adversarial loss: 0.554211\n",
      "epoch 150; iter: 0; batch classifier loss: 0.407033; batch adversarial loss: 0.590727\n",
      "epoch 151; iter: 0; batch classifier loss: 0.297100; batch adversarial loss: 0.553791\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356459; batch adversarial loss: 0.544743\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322176; batch adversarial loss: 0.516917\n",
      "epoch 154; iter: 0; batch classifier loss: 0.416776; batch adversarial loss: 0.498359\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360519; batch adversarial loss: 0.544769\n",
      "epoch 156; iter: 0; batch classifier loss: 0.423130; batch adversarial loss: 0.553732\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360343; batch adversarial loss: 0.599632\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349273; batch adversarial loss: 0.535347\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331528; batch adversarial loss: 0.563084\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378916; batch adversarial loss: 0.599689\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345614; batch adversarial loss: 0.544458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.432430; batch adversarial loss: 0.479853\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364698; batch adversarial loss: 0.553142\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414627; batch adversarial loss: 0.581652\n",
      "epoch 165; iter: 0; batch classifier loss: 0.332044; batch adversarial loss: 0.590560\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344617; batch adversarial loss: 0.590334\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334706; batch adversarial loss: 0.572036\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369070; batch adversarial loss: 0.590409\n",
      "epoch 169; iter: 0; batch classifier loss: 0.347540; batch adversarial loss: 0.526494\n",
      "epoch 170; iter: 0; batch classifier loss: 0.452103; batch adversarial loss: 0.553669\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317736; batch adversarial loss: 0.600015\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345632; batch adversarial loss: 0.590767\n",
      "epoch 173; iter: 0; batch classifier loss: 0.331342; batch adversarial loss: 0.590799\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345658; batch adversarial loss: 0.516780\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373264; batch adversarial loss: 0.553496\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355027; batch adversarial loss: 0.544435\n",
      "epoch 177; iter: 0; batch classifier loss: 0.310158; batch adversarial loss: 0.498212\n",
      "epoch 178; iter: 0; batch classifier loss: 0.435974; batch adversarial loss: 0.553657\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406641; batch adversarial loss: 0.507910\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374622; batch adversarial loss: 0.508453\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322951; batch adversarial loss: 0.600120\n",
      "epoch 182; iter: 0; batch classifier loss: 0.427370; batch adversarial loss: 0.553845\n",
      "epoch 183; iter: 0; batch classifier loss: 0.405524; batch adversarial loss: 0.553558\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353257; batch adversarial loss: 0.525605\n",
      "epoch 185; iter: 0; batch classifier loss: 0.438084; batch adversarial loss: 0.544365\n",
      "epoch 186; iter: 0; batch classifier loss: 0.288082; batch adversarial loss: 0.489076\n",
      "epoch 187; iter: 0; batch classifier loss: 0.344875; batch adversarial loss: 0.554936\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396186; batch adversarial loss: 0.516512\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361766; batch adversarial loss: 0.553630\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321320; batch adversarial loss: 0.516884\n",
      "epoch 191; iter: 0; batch classifier loss: 0.303697; batch adversarial loss: 0.525172\n",
      "epoch 192; iter: 0; batch classifier loss: 0.486181; batch adversarial loss: 0.572352\n",
      "epoch 193; iter: 0; batch classifier loss: 0.321926; batch adversarial loss: 0.470694\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356005; batch adversarial loss: 0.553918\n",
      "epoch 195; iter: 0; batch classifier loss: 0.435472; batch adversarial loss: 0.617698\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372075; batch adversarial loss: 0.517360\n",
      "epoch 197; iter: 0; batch classifier loss: 0.333877; batch adversarial loss: 0.535435\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383975; batch adversarial loss: 0.498367\n",
      "epoch 199; iter: 0; batch classifier loss: 0.436626; batch adversarial loss: 0.600002\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675434; batch adversarial loss: 0.638856\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589404; batch adversarial loss: 0.653268\n",
      "epoch 2; iter: 0; batch classifier loss: 0.540500; batch adversarial loss: 0.627115\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564713; batch adversarial loss: 0.599983\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577589; batch adversarial loss: 0.629970\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505099; batch adversarial loss: 0.611301\n",
      "epoch 6; iter: 0; batch classifier loss: 0.620099; batch adversarial loss: 0.603381\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548835; batch adversarial loss: 0.560663\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578004; batch adversarial loss: 0.622436\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586868; batch adversarial loss: 0.597736\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549481; batch adversarial loss: 0.537295\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550264; batch adversarial loss: 0.576216\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553287; batch adversarial loss: 0.617597\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481879; batch adversarial loss: 0.637529\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571236; batch adversarial loss: 0.534966\n",
      "epoch 15; iter: 0; batch classifier loss: 0.588347; batch adversarial loss: 0.526542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445241; batch adversarial loss: 0.619474\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537190; batch adversarial loss: 0.528766\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495838; batch adversarial loss: 0.593220\n",
      "epoch 19; iter: 0; batch classifier loss: 0.568208; batch adversarial loss: 0.517767\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486747; batch adversarial loss: 0.573229\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526958; batch adversarial loss: 0.502570\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454906; batch adversarial loss: 0.529298\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443698; batch adversarial loss: 0.500661\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483923; batch adversarial loss: 0.532200\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470461; batch adversarial loss: 0.530491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.529322; batch adversarial loss: 0.538633\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472616; batch adversarial loss: 0.522431\n",
      "epoch 28; iter: 0; batch classifier loss: 0.533639; batch adversarial loss: 0.545879\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488551; batch adversarial loss: 0.544497\n",
      "epoch 30; iter: 0; batch classifier loss: 0.505981; batch adversarial loss: 0.490559\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457724; batch adversarial loss: 0.510237\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499626; batch adversarial loss: 0.499989\n",
      "epoch 33; iter: 0; batch classifier loss: 0.502241; batch adversarial loss: 0.608178\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456881; batch adversarial loss: 0.509288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.424558; batch adversarial loss: 0.492121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497293; batch adversarial loss: 0.544601\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455359; batch adversarial loss: 0.571401\n",
      "epoch 38; iter: 0; batch classifier loss: 0.535291; batch adversarial loss: 0.600464\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473910; batch adversarial loss: 0.498372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.350749; batch adversarial loss: 0.582164\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421802; batch adversarial loss: 0.599995\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411695; batch adversarial loss: 0.497772\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444903; batch adversarial loss: 0.544314\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431240; batch adversarial loss: 0.478556\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393199; batch adversarial loss: 0.543533\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451300; batch adversarial loss: 0.553807\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461159; batch adversarial loss: 0.507624\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467955; batch adversarial loss: 0.544665\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419493; batch adversarial loss: 0.526791\n",
      "epoch 50; iter: 0; batch classifier loss: 0.436001; batch adversarial loss: 0.534654\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445245; batch adversarial loss: 0.554660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451697; batch adversarial loss: 0.486330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.378606; batch adversarial loss: 0.573204\n",
      "epoch 54; iter: 0; batch classifier loss: 0.489011; batch adversarial loss: 0.573088\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450841; batch adversarial loss: 0.544939\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419283; batch adversarial loss: 0.534161\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382941; batch adversarial loss: 0.515567\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393050; batch adversarial loss: 0.487918\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452356; batch adversarial loss: 0.544385\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431168; batch adversarial loss: 0.515679\n",
      "epoch 61; iter: 0; batch classifier loss: 0.478062; batch adversarial loss: 0.485841\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391295; batch adversarial loss: 0.486255\n",
      "epoch 63; iter: 0; batch classifier loss: 0.481576; batch adversarial loss: 0.525120\n",
      "epoch 64; iter: 0; batch classifier loss: 0.446557; batch adversarial loss: 0.526168\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438842; batch adversarial loss: 0.610629\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425011; batch adversarial loss: 0.563272\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444790; batch adversarial loss: 0.508047\n",
      "epoch 68; iter: 0; batch classifier loss: 0.496866; batch adversarial loss: 0.527139\n",
      "epoch 69; iter: 0; batch classifier loss: 0.324567; batch adversarial loss: 0.496524\n",
      "epoch 70; iter: 0; batch classifier loss: 0.333513; batch adversarial loss: 0.590623\n",
      "epoch 71; iter: 0; batch classifier loss: 0.457118; batch adversarial loss: 0.552413\n",
      "epoch 72; iter: 0; batch classifier loss: 0.351766; batch adversarial loss: 0.496767\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391794; batch adversarial loss: 0.545550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425641; batch adversarial loss: 0.639863\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434643; batch adversarial loss: 0.544884\n",
      "epoch 76; iter: 0; batch classifier loss: 0.506421; batch adversarial loss: 0.507613\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440715; batch adversarial loss: 0.629425\n",
      "epoch 78; iter: 0; batch classifier loss: 0.501895; batch adversarial loss: 0.595338\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398203; batch adversarial loss: 0.505376\n",
      "epoch 80; iter: 0; batch classifier loss: 0.382000; batch adversarial loss: 0.525004\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417533; batch adversarial loss: 0.515730\n",
      "epoch 82; iter: 0; batch classifier loss: 0.322802; batch adversarial loss: 0.533903\n",
      "epoch 83; iter: 0; batch classifier loss: 0.351338; batch adversarial loss: 0.603451\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405454; batch adversarial loss: 0.469154\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424050; batch adversarial loss: 0.602812\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421423; batch adversarial loss: 0.478573\n",
      "epoch 87; iter: 0; batch classifier loss: 0.476592; batch adversarial loss: 0.515576\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352513; batch adversarial loss: 0.582008\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436177; batch adversarial loss: 0.440151\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432553; batch adversarial loss: 0.573501\n",
      "epoch 91; iter: 0; batch classifier loss: 0.322724; batch adversarial loss: 0.523328\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400168; batch adversarial loss: 0.524874\n",
      "epoch 93; iter: 0; batch classifier loss: 0.411705; batch adversarial loss: 0.505891\n",
      "epoch 94; iter: 0; batch classifier loss: 0.403487; batch adversarial loss: 0.534131\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377846; batch adversarial loss: 0.546027\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420383; batch adversarial loss: 0.524150\n",
      "epoch 97; iter: 0; batch classifier loss: 0.546762; batch adversarial loss: 0.458471\n",
      "epoch 98; iter: 0; batch classifier loss: 0.419403; batch adversarial loss: 0.517033\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410913; batch adversarial loss: 0.534665\n",
      "epoch 100; iter: 0; batch classifier loss: 0.316475; batch adversarial loss: 0.517002\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391183; batch adversarial loss: 0.516347\n",
      "epoch 102; iter: 0; batch classifier loss: 0.443078; batch adversarial loss: 0.544121\n",
      "epoch 103; iter: 0; batch classifier loss: 0.344745; batch adversarial loss: 0.602191\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375311; batch adversarial loss: 0.505807\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337992; batch adversarial loss: 0.601944\n",
      "epoch 106; iter: 0; batch classifier loss: 0.411159; batch adversarial loss: 0.536693\n",
      "epoch 107; iter: 0; batch classifier loss: 0.325128; batch adversarial loss: 0.514155\n",
      "epoch 108; iter: 0; batch classifier loss: 0.431869; batch adversarial loss: 0.486620\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381252; batch adversarial loss: 0.535947\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370917; batch adversarial loss: 0.534745\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441931; batch adversarial loss: 0.620179\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378463; batch adversarial loss: 0.506859\n",
      "epoch 113; iter: 0; batch classifier loss: 0.426005; batch adversarial loss: 0.516618\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352571; batch adversarial loss: 0.486310\n",
      "epoch 115; iter: 0; batch classifier loss: 0.455422; batch adversarial loss: 0.489625\n",
      "epoch 116; iter: 0; batch classifier loss: 0.430094; batch adversarial loss: 0.570286\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429577; batch adversarial loss: 0.514630\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397096; batch adversarial loss: 0.488005\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369037; batch adversarial loss: 0.535146\n",
      "epoch 120; iter: 0; batch classifier loss: 0.393318; batch adversarial loss: 0.455865\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320408; batch adversarial loss: 0.429596\n",
      "epoch 122; iter: 0; batch classifier loss: 0.306814; batch adversarial loss: 0.517684\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370508; batch adversarial loss: 0.496837\n",
      "epoch 124; iter: 0; batch classifier loss: 0.497965; batch adversarial loss: 0.523746\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383444; batch adversarial loss: 0.543051\n",
      "epoch 126; iter: 0; batch classifier loss: 0.431009; batch adversarial loss: 0.547116\n",
      "epoch 127; iter: 0; batch classifier loss: 0.342544; batch adversarial loss: 0.486210\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419191; batch adversarial loss: 0.572544\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370953; batch adversarial loss: 0.518090\n",
      "epoch 130; iter: 0; batch classifier loss: 0.379970; batch adversarial loss: 0.469185\n",
      "epoch 131; iter: 0; batch classifier loss: 0.411443; batch adversarial loss: 0.460195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.402495; batch adversarial loss: 0.593412\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367575; batch adversarial loss: 0.545490\n",
      "epoch 134; iter: 0; batch classifier loss: 0.320589; batch adversarial loss: 0.591426\n",
      "epoch 135; iter: 0; batch classifier loss: 0.447828; batch adversarial loss: 0.553325\n",
      "epoch 136; iter: 0; batch classifier loss: 0.311293; batch adversarial loss: 0.495229\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332576; batch adversarial loss: 0.574976\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376899; batch adversarial loss: 0.592066\n",
      "epoch 139; iter: 0; batch classifier loss: 0.400000; batch adversarial loss: 0.477019\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400051; batch adversarial loss: 0.523910\n",
      "epoch 141; iter: 0; batch classifier loss: 0.466263; batch adversarial loss: 0.458091\n",
      "epoch 142; iter: 0; batch classifier loss: 0.413600; batch adversarial loss: 0.572791\n",
      "epoch 143; iter: 0; batch classifier loss: 0.432755; batch adversarial loss: 0.551746\n",
      "epoch 144; iter: 0; batch classifier loss: 0.427694; batch adversarial loss: 0.546772\n",
      "epoch 145; iter: 0; batch classifier loss: 0.257074; batch adversarial loss: 0.524897\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369820; batch adversarial loss: 0.526933\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327299; batch adversarial loss: 0.554198\n",
      "epoch 148; iter: 0; batch classifier loss: 0.469402; batch adversarial loss: 0.506300\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339100; batch adversarial loss: 0.601744\n",
      "epoch 150; iter: 0; batch classifier loss: 0.427892; batch adversarial loss: 0.544999\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371765; batch adversarial loss: 0.525914\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333328; batch adversarial loss: 0.638885\n",
      "epoch 153; iter: 0; batch classifier loss: 0.375207; batch adversarial loss: 0.591961\n",
      "epoch 154; iter: 0; batch classifier loss: 0.387404; batch adversarial loss: 0.581321\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398393; batch adversarial loss: 0.430183\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334962; batch adversarial loss: 0.504249\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346666; batch adversarial loss: 0.518258\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387362; batch adversarial loss: 0.565469\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338850; batch adversarial loss: 0.497134\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368699; batch adversarial loss: 0.545647\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367047; batch adversarial loss: 0.537024\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407922; batch adversarial loss: 0.563211\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375584; batch adversarial loss: 0.487335\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369885; batch adversarial loss: 0.507861\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367491; batch adversarial loss: 0.486981\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308285; batch adversarial loss: 0.439674\n",
      "epoch 167; iter: 0; batch classifier loss: 0.316987; batch adversarial loss: 0.535768\n",
      "epoch 168; iter: 0; batch classifier loss: 0.468385; batch adversarial loss: 0.534611\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333956; batch adversarial loss: 0.608937\n",
      "epoch 170; iter: 0; batch classifier loss: 0.269663; batch adversarial loss: 0.544509\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355299; batch adversarial loss: 0.534479\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394110; batch adversarial loss: 0.498084\n",
      "epoch 173; iter: 0; batch classifier loss: 0.368746; batch adversarial loss: 0.533993\n",
      "epoch 174; iter: 0; batch classifier loss: 0.442458; batch adversarial loss: 0.536285\n",
      "epoch 175; iter: 0; batch classifier loss: 0.358297; batch adversarial loss: 0.517949\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378316; batch adversarial loss: 0.504554\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384820; batch adversarial loss: 0.525547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355716; batch adversarial loss: 0.544690\n",
      "epoch 179; iter: 0; batch classifier loss: 0.342582; batch adversarial loss: 0.517266\n",
      "epoch 180; iter: 0; batch classifier loss: 0.437618; batch adversarial loss: 0.537213\n",
      "epoch 181; iter: 0; batch classifier loss: 0.407360; batch adversarial loss: 0.486676\n",
      "epoch 182; iter: 0; batch classifier loss: 0.433003; batch adversarial loss: 0.554895\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373386; batch adversarial loss: 0.478506\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362194; batch adversarial loss: 0.534808\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369131; batch adversarial loss: 0.567497\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386079; batch adversarial loss: 0.419681\n",
      "epoch 187; iter: 0; batch classifier loss: 0.381654; batch adversarial loss: 0.552919\n",
      "epoch 188; iter: 0; batch classifier loss: 0.372620; batch adversarial loss: 0.621258\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367131; batch adversarial loss: 0.536425\n",
      "epoch 190; iter: 0; batch classifier loss: 0.405082; batch adversarial loss: 0.584176\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366123; batch adversarial loss: 0.545202\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340599; batch adversarial loss: 0.488381\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403546; batch adversarial loss: 0.478031\n",
      "epoch 194; iter: 0; batch classifier loss: 0.327640; batch adversarial loss: 0.543923\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393785; batch adversarial loss: 0.526206\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360197; batch adversarial loss: 0.546390\n",
      "epoch 197; iter: 0; batch classifier loss: 0.382101; batch adversarial loss: 0.678154\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338742; batch adversarial loss: 0.552851\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339885; batch adversarial loss: 0.476366\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673828; batch adversarial loss: 0.822276\n",
      "epoch 1; iter: 0; batch classifier loss: 0.848776; batch adversarial loss: 1.023962\n",
      "epoch 2; iter: 0; batch classifier loss: 0.895602; batch adversarial loss: 0.956970\n",
      "epoch 3; iter: 0; batch classifier loss: 0.949734; batch adversarial loss: 0.883244\n",
      "epoch 4; iter: 0; batch classifier loss: 0.853780; batch adversarial loss: 0.796134\n",
      "epoch 5; iter: 0; batch classifier loss: 0.837295; batch adversarial loss: 0.766323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.738614; batch adversarial loss: 0.706948\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598671; batch adversarial loss: 0.622834\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633598; batch adversarial loss: 0.592223\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539183; batch adversarial loss: 0.631461\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519803; batch adversarial loss: 0.608832\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557793; batch adversarial loss: 0.603066\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540112; batch adversarial loss: 0.587708\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511909; batch adversarial loss: 0.647942\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501734; batch adversarial loss: 0.583943\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501801; batch adversarial loss: 0.559678\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498842; batch adversarial loss: 0.577780\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527793; batch adversarial loss: 0.532136\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543601; batch adversarial loss: 0.596444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507880; batch adversarial loss: 0.502954\n",
      "epoch 20; iter: 0; batch classifier loss: 0.497370; batch adversarial loss: 0.578465\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517681; batch adversarial loss: 0.602677\n",
      "epoch 22; iter: 0; batch classifier loss: 0.544091; batch adversarial loss: 0.533467\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497837; batch adversarial loss: 0.527013\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498876; batch adversarial loss: 0.556235\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521867; batch adversarial loss: 0.569244\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487935; batch adversarial loss: 0.466935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458112; batch adversarial loss: 0.582589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.393545; batch adversarial loss: 0.516400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482275; batch adversarial loss: 0.554023\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455979; batch adversarial loss: 0.498504\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465677; batch adversarial loss: 0.560069\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478068; batch adversarial loss: 0.522495\n",
      "epoch 33; iter: 0; batch classifier loss: 0.534988; batch adversarial loss: 0.482818\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458086; batch adversarial loss: 0.474440\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476586; batch adversarial loss: 0.571022\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464803; batch adversarial loss: 0.544641\n",
      "epoch 37; iter: 0; batch classifier loss: 0.403458; batch adversarial loss: 0.490484\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467324; batch adversarial loss: 0.580550\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429683; batch adversarial loss: 0.566672\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416776; batch adversarial loss: 0.590687\n",
      "epoch 41; iter: 0; batch classifier loss: 0.497117; batch adversarial loss: 0.624784\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481344; batch adversarial loss: 0.537786\n",
      "epoch 43; iter: 0; batch classifier loss: 0.507184; batch adversarial loss: 0.562365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430950; batch adversarial loss: 0.582556\n",
      "epoch 45; iter: 0; batch classifier loss: 0.396101; batch adversarial loss: 0.533408\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474386; batch adversarial loss: 0.511260\n",
      "epoch 47; iter: 0; batch classifier loss: 0.458616; batch adversarial loss: 0.470875\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491830; batch adversarial loss: 0.580749\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385804; batch adversarial loss: 0.544452\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433797; batch adversarial loss: 0.507352\n",
      "epoch 51; iter: 0; batch classifier loss: 0.389449; batch adversarial loss: 0.559612\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457630; batch adversarial loss: 0.629621\n",
      "epoch 53; iter: 0; batch classifier loss: 0.351960; batch adversarial loss: 0.564829\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447417; batch adversarial loss: 0.601172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.498757; batch adversarial loss: 0.483166\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371657; batch adversarial loss: 0.582474\n",
      "epoch 57; iter: 0; batch classifier loss: 0.344856; batch adversarial loss: 0.470455\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399231; batch adversarial loss: 0.563467\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371973; batch adversarial loss: 0.563576\n",
      "epoch 60; iter: 0; batch classifier loss: 0.454720; batch adversarial loss: 0.555056\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371198; batch adversarial loss: 0.562035\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452347; batch adversarial loss: 0.543834\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399009; batch adversarial loss: 0.572070\n",
      "epoch 64; iter: 0; batch classifier loss: 0.339288; batch adversarial loss: 0.562137\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433287; batch adversarial loss: 0.508920\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411888; batch adversarial loss: 0.562407\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363103; batch adversarial loss: 0.543767\n",
      "epoch 68; iter: 0; batch classifier loss: 0.438713; batch adversarial loss: 0.552604\n",
      "epoch 69; iter: 0; batch classifier loss: 0.381998; batch adversarial loss: 0.490736\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398493; batch adversarial loss: 0.506594\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418571; batch adversarial loss: 0.481132\n",
      "epoch 72; iter: 0; batch classifier loss: 0.323804; batch adversarial loss: 0.526164\n",
      "epoch 73; iter: 0; batch classifier loss: 0.351740; batch adversarial loss: 0.562951\n",
      "epoch 74; iter: 0; batch classifier loss: 0.429088; batch adversarial loss: 0.507764\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373076; batch adversarial loss: 0.528000\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394918; batch adversarial loss: 0.545201\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422924; batch adversarial loss: 0.581405\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375078; batch adversarial loss: 0.564248\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382422; batch adversarial loss: 0.444152\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408983; batch adversarial loss: 0.562245\n",
      "epoch 81; iter: 0; batch classifier loss: 0.377774; batch adversarial loss: 0.599256\n",
      "epoch 82; iter: 0; batch classifier loss: 0.482450; batch adversarial loss: 0.617526\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452203; batch adversarial loss: 0.535344\n",
      "epoch 84; iter: 0; batch classifier loss: 0.394619; batch adversarial loss: 0.589955\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424969; batch adversarial loss: 0.581727\n",
      "epoch 86; iter: 0; batch classifier loss: 0.422469; batch adversarial loss: 0.545351\n",
      "epoch 87; iter: 0; batch classifier loss: 0.457049; batch adversarial loss: 0.562727\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377719; batch adversarial loss: 0.572437\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380478; batch adversarial loss: 0.507582\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395816; batch adversarial loss: 0.542017\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349589; batch adversarial loss: 0.516129\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389375; batch adversarial loss: 0.525384\n",
      "epoch 93; iter: 0; batch classifier loss: 0.314886; batch adversarial loss: 0.508276\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423327; batch adversarial loss: 0.561711\n",
      "epoch 95; iter: 0; batch classifier loss: 0.441606; batch adversarial loss: 0.536251\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341669; batch adversarial loss: 0.552192\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371829; batch adversarial loss: 0.508332\n",
      "epoch 98; iter: 0; batch classifier loss: 0.324585; batch adversarial loss: 0.517354\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344220; batch adversarial loss: 0.601307\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401335; batch adversarial loss: 0.590974\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394638; batch adversarial loss: 0.554736\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354879; batch adversarial loss: 0.563580\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399922; batch adversarial loss: 0.498627\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428134; batch adversarial loss: 0.516550\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339509; batch adversarial loss: 0.552825\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402546; batch adversarial loss: 0.554486\n",
      "epoch 107; iter: 0; batch classifier loss: 0.455594; batch adversarial loss: 0.562127\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392626; batch adversarial loss: 0.590369\n",
      "epoch 109; iter: 0; batch classifier loss: 0.417751; batch adversarial loss: 0.517681\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396721; batch adversarial loss: 0.526696\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403589; batch adversarial loss: 0.544326\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349110; batch adversarial loss: 0.599804\n",
      "epoch 113; iter: 0; batch classifier loss: 0.428301; batch adversarial loss: 0.543979\n",
      "epoch 114; iter: 0; batch classifier loss: 0.404859; batch adversarial loss: 0.571006\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358406; batch adversarial loss: 0.590038\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405163; batch adversarial loss: 0.498978\n",
      "epoch 117; iter: 0; batch classifier loss: 0.448473; batch adversarial loss: 0.625415\n",
      "epoch 118; iter: 0; batch classifier loss: 0.442306; batch adversarial loss: 0.572147\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423434; batch adversarial loss: 0.536053\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341205; batch adversarial loss: 0.498902\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392577; batch adversarial loss: 0.498932\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409924; batch adversarial loss: 0.471860\n",
      "epoch 123; iter: 0; batch classifier loss: 0.321638; batch adversarial loss: 0.571878\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374105; batch adversarial loss: 0.581426\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397304; batch adversarial loss: 0.599654\n",
      "epoch 126; iter: 0; batch classifier loss: 0.410783; batch adversarial loss: 0.554581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 127; iter: 0; batch classifier loss: 0.321813; batch adversarial loss: 0.535053\n",
      "epoch 128; iter: 0; batch classifier loss: 0.438063; batch adversarial loss: 0.508988\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403430; batch adversarial loss: 0.580435\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339632; batch adversarial loss: 0.490206\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406437; batch adversarial loss: 0.515933\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354101; batch adversarial loss: 0.563482\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343502; batch adversarial loss: 0.608010\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370114; batch adversarial loss: 0.544063\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369414; batch adversarial loss: 0.562432\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346177; batch adversarial loss: 0.618652\n",
      "epoch 137; iter: 0; batch classifier loss: 0.309882; batch adversarial loss: 0.600104\n",
      "epoch 138; iter: 0; batch classifier loss: 0.427968; batch adversarial loss: 0.562895\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341159; batch adversarial loss: 0.581648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354229; batch adversarial loss: 0.646008\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371278; batch adversarial loss: 0.563009\n",
      "epoch 142; iter: 0; batch classifier loss: 0.402103; batch adversarial loss: 0.561907\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376033; batch adversarial loss: 0.572307\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352872; batch adversarial loss: 0.588709\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382941; batch adversarial loss: 0.599378\n",
      "epoch 146; iter: 0; batch classifier loss: 0.463046; batch adversarial loss: 0.591623\n",
      "epoch 147; iter: 0; batch classifier loss: 0.301123; batch adversarial loss: 0.535204\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350118; batch adversarial loss: 0.517477\n",
      "epoch 149; iter: 0; batch classifier loss: 0.327772; batch adversarial loss: 0.489750\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364039; batch adversarial loss: 0.489136\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387915; batch adversarial loss: 0.490514\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342474; batch adversarial loss: 0.544616\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361119; batch adversarial loss: 0.535565\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373297; batch adversarial loss: 0.591358\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339782; batch adversarial loss: 0.551250\n",
      "epoch 156; iter: 0; batch classifier loss: 0.415214; batch adversarial loss: 0.625348\n",
      "epoch 157; iter: 0; batch classifier loss: 0.312376; batch adversarial loss: 0.535751\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362102; batch adversarial loss: 0.572489\n",
      "epoch 159; iter: 0; batch classifier loss: 0.414517; batch adversarial loss: 0.554049\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300782; batch adversarial loss: 0.553900\n",
      "epoch 161; iter: 0; batch classifier loss: 0.291576; batch adversarial loss: 0.581130\n",
      "epoch 162; iter: 0; batch classifier loss: 0.330907; batch adversarial loss: 0.461126\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343677; batch adversarial loss: 0.571612\n",
      "epoch 164; iter: 0; batch classifier loss: 0.403087; batch adversarial loss: 0.516880\n",
      "epoch 165; iter: 0; batch classifier loss: 0.298919; batch adversarial loss: 0.507451\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308343; batch adversarial loss: 0.535401\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302216; batch adversarial loss: 0.553465\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390718; batch adversarial loss: 0.517273\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363300; batch adversarial loss: 0.655085\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342143; batch adversarial loss: 0.498503\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358100; batch adversarial loss: 0.589799\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360607; batch adversarial loss: 0.515432\n",
      "epoch 173; iter: 0; batch classifier loss: 0.352598; batch adversarial loss: 0.553106\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357848; batch adversarial loss: 0.590262\n",
      "epoch 175; iter: 0; batch classifier loss: 0.419460; batch adversarial loss: 0.552769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.275226; batch adversarial loss: 0.526440\n",
      "epoch 177; iter: 0; batch classifier loss: 0.287150; batch adversarial loss: 0.534299\n",
      "epoch 178; iter: 0; batch classifier loss: 0.305540; batch adversarial loss: 0.590098\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354251; batch adversarial loss: 0.580041\n",
      "epoch 180; iter: 0; batch classifier loss: 0.276371; batch adversarial loss: 0.627378\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387219; batch adversarial loss: 0.505456\n",
      "epoch 182; iter: 0; batch classifier loss: 0.310775; batch adversarial loss: 0.556104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393700; batch adversarial loss: 0.535264\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330548; batch adversarial loss: 0.510707\n",
      "epoch 185; iter: 0; batch classifier loss: 0.309412; batch adversarial loss: 0.525343\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404378; batch adversarial loss: 0.568607\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352385; batch adversarial loss: 0.684851\n",
      "epoch 188; iter: 0; batch classifier loss: 0.351947; batch adversarial loss: 0.535346\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352000; batch adversarial loss: 0.525876\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369843; batch adversarial loss: 0.571042\n",
      "epoch 191; iter: 0; batch classifier loss: 0.333251; batch adversarial loss: 0.580935\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389925; batch adversarial loss: 0.535184\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318487; batch adversarial loss: 0.489987\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330044; batch adversarial loss: 0.552725\n",
      "epoch 195; iter: 0; batch classifier loss: 0.396518; batch adversarial loss: 0.489016\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400715; batch adversarial loss: 0.590604\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387559; batch adversarial loss: 0.517303\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351126; batch adversarial loss: 0.580321\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339445; batch adversarial loss: 0.551466\n",
      "epoch 0; iter: 0; batch classifier loss: 0.801027; batch adversarial loss: 0.909975\n",
      "epoch 1; iter: 0; batch classifier loss: 0.711480; batch adversarial loss: 0.794635\n",
      "epoch 2; iter: 0; batch classifier loss: 0.854064; batch adversarial loss: 0.817855\n",
      "epoch 3; iter: 0; batch classifier loss: 0.682792; batch adversarial loss: 0.690945\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590698; batch adversarial loss: 0.616343\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538448; batch adversarial loss: 0.685664\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550583; batch adversarial loss: 0.624741\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524058; batch adversarial loss: 0.572346\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512529; batch adversarial loss: 0.622759\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535602; batch adversarial loss: 0.557150\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539189; batch adversarial loss: 0.601269\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566715; batch adversarial loss: 0.573116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578268; batch adversarial loss: 0.521235\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584101; batch adversarial loss: 0.568459\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535266; batch adversarial loss: 0.584292\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505379; batch adversarial loss: 0.583707\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511570; batch adversarial loss: 0.601661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527860; batch adversarial loss: 0.619007\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500930; batch adversarial loss: 0.576490\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527342; batch adversarial loss: 0.576039\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518816; batch adversarial loss: 0.582311\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493144; batch adversarial loss: 0.607754\n",
      "epoch 22; iter: 0; batch classifier loss: 0.430204; batch adversarial loss: 0.600998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.470203; batch adversarial loss: 0.580508\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507369; batch adversarial loss: 0.612643\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485713; batch adversarial loss: 0.566712\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511119; batch adversarial loss: 0.485535\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450468; batch adversarial loss: 0.546261\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504596; batch adversarial loss: 0.605158\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501704; batch adversarial loss: 0.573024\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486819; batch adversarial loss: 0.528148\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462900; batch adversarial loss: 0.542320\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452766; batch adversarial loss: 0.524386\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471430; batch adversarial loss: 0.568005\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511222; batch adversarial loss: 0.524172\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458090; batch adversarial loss: 0.549353\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462872; batch adversarial loss: 0.538890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441924; batch adversarial loss: 0.543946\n",
      "epoch 38; iter: 0; batch classifier loss: 0.495995; batch adversarial loss: 0.538210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408958; batch adversarial loss: 0.521419\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456854; batch adversarial loss: 0.520237\n",
      "epoch 41; iter: 0; batch classifier loss: 0.514396; batch adversarial loss: 0.581165\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467404; batch adversarial loss: 0.589538\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480345; batch adversarial loss: 0.491014\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458679; batch adversarial loss: 0.586720\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437308; batch adversarial loss: 0.483608\n",
      "epoch 46; iter: 0; batch classifier loss: 0.472477; batch adversarial loss: 0.546114\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409682; batch adversarial loss: 0.528193\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464132; batch adversarial loss: 0.563329\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423894; batch adversarial loss: 0.518971\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403387; batch adversarial loss: 0.553514\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424857; batch adversarial loss: 0.597595\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445813; batch adversarial loss: 0.624476\n",
      "epoch 53; iter: 0; batch classifier loss: 0.509785; batch adversarial loss: 0.491623\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431392; batch adversarial loss: 0.535117\n",
      "epoch 55; iter: 0; batch classifier loss: 0.399585; batch adversarial loss: 0.632673\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417886; batch adversarial loss: 0.561893\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432031; batch adversarial loss: 0.511099\n",
      "epoch 58; iter: 0; batch classifier loss: 0.552495; batch adversarial loss: 0.464450\n",
      "epoch 59; iter: 0; batch classifier loss: 0.471734; batch adversarial loss: 0.537411\n",
      "epoch 60; iter: 0; batch classifier loss: 0.517955; batch adversarial loss: 0.533873\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382114; batch adversarial loss: 0.500808\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429174; batch adversarial loss: 0.544865\n",
      "epoch 63; iter: 0; batch classifier loss: 0.495244; batch adversarial loss: 0.603815\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408404; batch adversarial loss: 0.599024\n",
      "epoch 65; iter: 0; batch classifier loss: 0.361981; batch adversarial loss: 0.564590\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411771; batch adversarial loss: 0.648528\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428168; batch adversarial loss: 0.545570\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401625; batch adversarial loss: 0.479880\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378284; batch adversarial loss: 0.559076\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443643; batch adversarial loss: 0.631113\n",
      "epoch 71; iter: 0; batch classifier loss: 0.343414; batch adversarial loss: 0.550958\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365472; batch adversarial loss: 0.595547\n",
      "epoch 73; iter: 0; batch classifier loss: 0.359867; batch adversarial loss: 0.516236\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388441; batch adversarial loss: 0.613408\n",
      "epoch 75; iter: 0; batch classifier loss: 0.392791; batch adversarial loss: 0.597154\n",
      "epoch 76; iter: 0; batch classifier loss: 0.361579; batch adversarial loss: 0.623620\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400006; batch adversarial loss: 0.597809\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413221; batch adversarial loss: 0.568089\n",
      "epoch 79; iter: 0; batch classifier loss: 0.365723; batch adversarial loss: 0.624100\n",
      "epoch 80; iter: 0; batch classifier loss: 0.461797; batch adversarial loss: 0.614506\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391210; batch adversarial loss: 0.562202\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447228; batch adversarial loss: 0.490519\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370008; batch adversarial loss: 0.465192\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410043; batch adversarial loss: 0.543761\n",
      "epoch 85; iter: 0; batch classifier loss: 0.330614; batch adversarial loss: 0.566597\n",
      "epoch 86; iter: 0; batch classifier loss: 0.305598; batch adversarial loss: 0.500830\n",
      "epoch 87; iter: 0; batch classifier loss: 0.425492; batch adversarial loss: 0.519207\n",
      "epoch 88; iter: 0; batch classifier loss: 0.480617; batch adversarial loss: 0.523260\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417950; batch adversarial loss: 0.615766\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394617; batch adversarial loss: 0.518281\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361955; batch adversarial loss: 0.525477\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421594; batch adversarial loss: 0.565471\n",
      "epoch 93; iter: 0; batch classifier loss: 0.468458; batch adversarial loss: 0.551481\n",
      "epoch 94; iter: 0; batch classifier loss: 0.476577; batch adversarial loss: 0.595813\n",
      "epoch 95; iter: 0; batch classifier loss: 0.444130; batch adversarial loss: 0.453363\n",
      "epoch 96; iter: 0; batch classifier loss: 0.458076; batch adversarial loss: 0.585998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434994; batch adversarial loss: 0.556824\n",
      "epoch 98; iter: 0; batch classifier loss: 0.464230; batch adversarial loss: 0.552045\n",
      "epoch 99; iter: 0; batch classifier loss: 0.391282; batch adversarial loss: 0.595730\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389793; batch adversarial loss: 0.614745\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365482; batch adversarial loss: 0.463595\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418818; batch adversarial loss: 0.560255\n",
      "epoch 103; iter: 0; batch classifier loss: 0.305309; batch adversarial loss: 0.607618\n",
      "epoch 104; iter: 0; batch classifier loss: 0.313812; batch adversarial loss: 0.543196\n",
      "epoch 105; iter: 0; batch classifier loss: 0.431924; batch adversarial loss: 0.497844\n",
      "epoch 106; iter: 0; batch classifier loss: 0.447592; batch adversarial loss: 0.651104\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354200; batch adversarial loss: 0.525364\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422400; batch adversarial loss: 0.587833\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364232; batch adversarial loss: 0.577765\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353764; batch adversarial loss: 0.515905\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406610; batch adversarial loss: 0.557370\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324109; batch adversarial loss: 0.619764\n",
      "epoch 113; iter: 0; batch classifier loss: 0.452767; batch adversarial loss: 0.554119\n",
      "epoch 114; iter: 0; batch classifier loss: 0.435741; batch adversarial loss: 0.587727\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397159; batch adversarial loss: 0.501536\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328291; batch adversarial loss: 0.616154\n",
      "epoch 117; iter: 0; batch classifier loss: 0.289081; batch adversarial loss: 0.577773\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395933; batch adversarial loss: 0.465419\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388752; batch adversarial loss: 0.489994\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394466; batch adversarial loss: 0.604460\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349026; batch adversarial loss: 0.570203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.375462; batch adversarial loss: 0.549426\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416892; batch adversarial loss: 0.565779\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365118; batch adversarial loss: 0.638047\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359775; batch adversarial loss: 0.533388\n",
      "epoch 126; iter: 0; batch classifier loss: 0.421250; batch adversarial loss: 0.580975\n",
      "epoch 127; iter: 0; batch classifier loss: 0.477812; batch adversarial loss: 0.606961\n",
      "epoch 128; iter: 0; batch classifier loss: 0.485788; batch adversarial loss: 0.546154\n",
      "epoch 129; iter: 0; batch classifier loss: 0.328117; batch adversarial loss: 0.578283\n",
      "epoch 130; iter: 0; batch classifier loss: 0.410478; batch adversarial loss: 0.498764\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338816; batch adversarial loss: 0.596231\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394520; batch adversarial loss: 0.553578\n",
      "epoch 133; iter: 0; batch classifier loss: 0.373527; batch adversarial loss: 0.557994\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375586; batch adversarial loss: 0.640366\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413603; batch adversarial loss: 0.605919\n",
      "epoch 136; iter: 0; batch classifier loss: 0.450433; batch adversarial loss: 0.615318\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347411; batch adversarial loss: 0.481248\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414654; batch adversarial loss: 0.591250\n",
      "epoch 139; iter: 0; batch classifier loss: 0.463219; batch adversarial loss: 0.562455\n",
      "epoch 140; iter: 0; batch classifier loss: 0.416322; batch adversarial loss: 0.537494\n",
      "epoch 141; iter: 0; batch classifier loss: 0.401184; batch adversarial loss: 0.491850\n",
      "epoch 142; iter: 0; batch classifier loss: 0.327830; batch adversarial loss: 0.586295\n",
      "epoch 143; iter: 0; batch classifier loss: 0.384778; batch adversarial loss: 0.551486\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310098; batch adversarial loss: 0.543896\n",
      "epoch 145; iter: 0; batch classifier loss: 0.419893; batch adversarial loss: 0.498826\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405048; batch adversarial loss: 0.646858\n",
      "epoch 147; iter: 0; batch classifier loss: 0.406051; batch adversarial loss: 0.570763\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375720; batch adversarial loss: 0.577824\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402663; batch adversarial loss: 0.599394\n",
      "epoch 150; iter: 0; batch classifier loss: 0.333469; batch adversarial loss: 0.603061\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415288; batch adversarial loss: 0.538160\n",
      "epoch 152; iter: 0; batch classifier loss: 0.371791; batch adversarial loss: 0.588133\n",
      "epoch 153; iter: 0; batch classifier loss: 0.485902; batch adversarial loss: 0.510317\n",
      "epoch 154; iter: 0; batch classifier loss: 0.318776; batch adversarial loss: 0.510032\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365041; batch adversarial loss: 0.510135\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356528; batch adversarial loss: 0.604953\n",
      "epoch 157; iter: 0; batch classifier loss: 0.425140; batch adversarial loss: 0.562759\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340280; batch adversarial loss: 0.575363\n",
      "epoch 159; iter: 0; batch classifier loss: 0.317218; batch adversarial loss: 0.598798\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350149; batch adversarial loss: 0.569445\n",
      "epoch 161; iter: 0; batch classifier loss: 0.458048; batch adversarial loss: 0.493332\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369612; batch adversarial loss: 0.595979\n",
      "epoch 163; iter: 0; batch classifier loss: 0.376705; batch adversarial loss: 0.660878\n",
      "epoch 164; iter: 0; batch classifier loss: 0.303418; batch adversarial loss: 0.520222\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394528; batch adversarial loss: 0.569909\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330444; batch adversarial loss: 0.605185\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364603; batch adversarial loss: 0.622839\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349305; batch adversarial loss: 0.572370\n",
      "epoch 169; iter: 0; batch classifier loss: 0.412813; batch adversarial loss: 0.591519\n",
      "epoch 170; iter: 0; batch classifier loss: 0.423992; batch adversarial loss: 0.485359\n",
      "epoch 171; iter: 0; batch classifier loss: 0.405692; batch adversarial loss: 0.553618\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317542; batch adversarial loss: 0.527507\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414610; batch adversarial loss: 0.526635\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353625; batch adversarial loss: 0.571523\n",
      "epoch 175; iter: 0; batch classifier loss: 0.319033; batch adversarial loss: 0.515879\n",
      "epoch 176; iter: 0; batch classifier loss: 0.309297; batch adversarial loss: 0.576653\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336120; batch adversarial loss: 0.644179\n",
      "epoch 178; iter: 0; batch classifier loss: 0.404797; batch adversarial loss: 0.588680\n",
      "epoch 179; iter: 0; batch classifier loss: 0.361315; batch adversarial loss: 0.534648\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358804; batch adversarial loss: 0.566934\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364680; batch adversarial loss: 0.616556\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336726; batch adversarial loss: 0.567958\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355377; batch adversarial loss: 0.609460\n",
      "epoch 184; iter: 0; batch classifier loss: 0.340545; batch adversarial loss: 0.543411\n",
      "epoch 185; iter: 0; batch classifier loss: 0.500943; batch adversarial loss: 0.581577\n",
      "epoch 186; iter: 0; batch classifier loss: 0.310709; batch adversarial loss: 0.483565\n",
      "epoch 187; iter: 0; batch classifier loss: 0.435537; batch adversarial loss: 0.606134\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373936; batch adversarial loss: 0.516479\n",
      "epoch 189; iter: 0; batch classifier loss: 0.436097; batch adversarial loss: 0.516410\n",
      "epoch 190; iter: 0; batch classifier loss: 0.490740; batch adversarial loss: 0.594166\n",
      "epoch 191; iter: 0; batch classifier loss: 0.395763; batch adversarial loss: 0.553638\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344523; batch adversarial loss: 0.606768\n",
      "epoch 193; iter: 0; batch classifier loss: 0.401589; batch adversarial loss: 0.576551\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414140; batch adversarial loss: 0.565754\n",
      "epoch 195; iter: 0; batch classifier loss: 0.423042; batch adversarial loss: 0.598399\n",
      "epoch 196; iter: 0; batch classifier loss: 0.388108; batch adversarial loss: 0.569476\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347163; batch adversarial loss: 0.536091\n",
      "epoch 198; iter: 0; batch classifier loss: 0.450170; batch adversarial loss: 0.601250\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337056; batch adversarial loss: 0.536742\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717543; batch adversarial loss: 1.080724\n",
      "epoch 1; iter: 0; batch classifier loss: 0.885622; batch adversarial loss: 1.260197\n",
      "epoch 2; iter: 0; batch classifier loss: 1.034822; batch adversarial loss: 1.231984\n",
      "epoch 3; iter: 0; batch classifier loss: 1.156915; batch adversarial loss: 1.144929\n",
      "epoch 4; iter: 0; batch classifier loss: 1.221462; batch adversarial loss: 1.081640\n",
      "epoch 5; iter: 0; batch classifier loss: 1.335613; batch adversarial loss: 0.999941\n",
      "epoch 6; iter: 0; batch classifier loss: 1.224369; batch adversarial loss: 0.906824\n",
      "epoch 7; iter: 0; batch classifier loss: 1.287642; batch adversarial loss: 0.846708\n",
      "epoch 8; iter: 0; batch classifier loss: 1.249118; batch adversarial loss: 0.779372\n",
      "epoch 9; iter: 0; batch classifier loss: 0.994928; batch adversarial loss: 0.756454\n",
      "epoch 10; iter: 0; batch classifier loss: 1.088580; batch adversarial loss: 0.684618\n",
      "epoch 11; iter: 0; batch classifier loss: 0.974180; batch adversarial loss: 0.631710\n",
      "epoch 12; iter: 0; batch classifier loss: 0.813568; batch adversarial loss: 0.589996\n",
      "epoch 13; iter: 0; batch classifier loss: 0.621722; batch adversarial loss: 0.606464\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554158; batch adversarial loss: 0.546445\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526247; batch adversarial loss: 0.581755\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518235; batch adversarial loss: 0.580328\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530197; batch adversarial loss: 0.579718\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483458; batch adversarial loss: 0.512424\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498790; batch adversarial loss: 0.526719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.434298; batch adversarial loss: 0.578657\n",
      "epoch 21; iter: 0; batch classifier loss: 0.575127; batch adversarial loss: 0.575389\n",
      "epoch 22; iter: 0; batch classifier loss: 0.548299; batch adversarial loss: 0.599839\n",
      "epoch 23; iter: 0; batch classifier loss: 0.593447; batch adversarial loss: 0.585844\n",
      "epoch 24; iter: 0; batch classifier loss: 0.573213; batch adversarial loss: 0.574772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.560857; batch adversarial loss: 0.599102\n",
      "epoch 26; iter: 0; batch classifier loss: 0.515959; batch adversarial loss: 0.542827\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520410; batch adversarial loss: 0.540008\n",
      "epoch 28; iter: 0; batch classifier loss: 0.531610; batch adversarial loss: 0.584915\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465093; batch adversarial loss: 0.586920\n",
      "epoch 30; iter: 0; batch classifier loss: 0.516041; batch adversarial loss: 0.543887\n",
      "epoch 31; iter: 0; batch classifier loss: 0.502293; batch adversarial loss: 0.539824\n",
      "epoch 32; iter: 0; batch classifier loss: 0.574060; batch adversarial loss: 0.584903\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457629; batch adversarial loss: 0.558941\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470866; batch adversarial loss: 0.504820\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474657; batch adversarial loss: 0.500028\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499574; batch adversarial loss: 0.581270\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455303; batch adversarial loss: 0.511681\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444745; batch adversarial loss: 0.499129\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421728; batch adversarial loss: 0.570693\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481298; batch adversarial loss: 0.570073\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475123; batch adversarial loss: 0.521193\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438989; batch adversarial loss: 0.588145\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496366; batch adversarial loss: 0.586654\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457002; batch adversarial loss: 0.468045\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444247; batch adversarial loss: 0.621812\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487570; batch adversarial loss: 0.504286\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367783; batch adversarial loss: 0.517625\n",
      "epoch 48; iter: 0; batch classifier loss: 0.365886; batch adversarial loss: 0.662315\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434938; batch adversarial loss: 0.580205\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461180; batch adversarial loss: 0.519777\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425478; batch adversarial loss: 0.542997\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450583; batch adversarial loss: 0.542589\n",
      "epoch 53; iter: 0; batch classifier loss: 0.447646; batch adversarial loss: 0.501183\n",
      "epoch 54; iter: 0; batch classifier loss: 0.496726; batch adversarial loss: 0.571208\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384320; batch adversarial loss: 0.603914\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430386; batch adversarial loss: 0.535036\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472087; batch adversarial loss: 0.606820\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430871; batch adversarial loss: 0.509840\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449657; batch adversarial loss: 0.527760\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418880; batch adversarial loss: 0.589102\n",
      "epoch 61; iter: 0; batch classifier loss: 0.490159; batch adversarial loss: 0.501678\n",
      "epoch 62; iter: 0; batch classifier loss: 0.499866; batch adversarial loss: 0.527624\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369217; batch adversarial loss: 0.544689\n",
      "epoch 64; iter: 0; batch classifier loss: 0.391808; batch adversarial loss: 0.483348\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379224; batch adversarial loss: 0.544930\n",
      "epoch 66; iter: 0; batch classifier loss: 0.475801; batch adversarial loss: 0.624431\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394535; batch adversarial loss: 0.528916\n",
      "epoch 68; iter: 0; batch classifier loss: 0.355552; batch adversarial loss: 0.588255\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442473; batch adversarial loss: 0.525871\n",
      "epoch 70; iter: 0; batch classifier loss: 0.311229; batch adversarial loss: 0.464925\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389304; batch adversarial loss: 0.581033\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365290; batch adversarial loss: 0.590096\n",
      "epoch 73; iter: 0; batch classifier loss: 0.334359; batch adversarial loss: 0.578903\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426465; batch adversarial loss: 0.570703\n",
      "epoch 75; iter: 0; batch classifier loss: 0.463076; batch adversarial loss: 0.571989\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430960; batch adversarial loss: 0.570201\n",
      "epoch 77; iter: 0; batch classifier loss: 0.317158; batch adversarial loss: 0.563465\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405925; batch adversarial loss: 0.474336\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394119; batch adversarial loss: 0.528998\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422033; batch adversarial loss: 0.581795\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408490; batch adversarial loss: 0.561135\n",
      "epoch 82; iter: 0; batch classifier loss: 0.340043; batch adversarial loss: 0.526596\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415564; batch adversarial loss: 0.581046\n",
      "epoch 84; iter: 0; batch classifier loss: 0.361636; batch adversarial loss: 0.525136\n",
      "epoch 85; iter: 0; batch classifier loss: 0.327423; batch adversarial loss: 0.564539\n",
      "epoch 86; iter: 0; batch classifier loss: 0.502089; batch adversarial loss: 0.484860\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402998; batch adversarial loss: 0.564215\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371236; batch adversarial loss: 0.528117\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377320; batch adversarial loss: 0.528825\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435656; batch adversarial loss: 0.467083\n",
      "epoch 91; iter: 0; batch classifier loss: 0.342502; batch adversarial loss: 0.529725\n",
      "epoch 92; iter: 0; batch classifier loss: 0.337675; batch adversarial loss: 0.544338\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361336; batch adversarial loss: 0.562508\n",
      "epoch 94; iter: 0; batch classifier loss: 0.443168; batch adversarial loss: 0.535126\n",
      "epoch 95; iter: 0; batch classifier loss: 0.390756; batch adversarial loss: 0.598243\n",
      "epoch 96; iter: 0; batch classifier loss: 0.293506; batch adversarial loss: 0.609422\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396298; batch adversarial loss: 0.578341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.337743; batch adversarial loss: 0.474973\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381142; batch adversarial loss: 0.686886\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413209; batch adversarial loss: 0.563834\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392152; batch adversarial loss: 0.554722\n",
      "epoch 102; iter: 0; batch classifier loss: 0.268301; batch adversarial loss: 0.596074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.343339; batch adversarial loss: 0.571337\n",
      "epoch 104; iter: 0; batch classifier loss: 0.345181; batch adversarial loss: 0.612211\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366967; batch adversarial loss: 0.563143\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421883; batch adversarial loss: 0.535063\n",
      "epoch 107; iter: 0; batch classifier loss: 0.407471; batch adversarial loss: 0.520447\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417687; batch adversarial loss: 0.583827\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404360; batch adversarial loss: 0.562661\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366633; batch adversarial loss: 0.473244\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381887; batch adversarial loss: 0.566083\n",
      "epoch 112; iter: 0; batch classifier loss: 0.426793; batch adversarial loss: 0.588641\n",
      "epoch 113; iter: 0; batch classifier loss: 0.450392; batch adversarial loss: 0.606005\n",
      "epoch 114; iter: 0; batch classifier loss: 0.278674; batch adversarial loss: 0.581703\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359862; batch adversarial loss: 0.564521\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406906; batch adversarial loss: 0.552903\n",
      "epoch 117; iter: 0; batch classifier loss: 0.310071; batch adversarial loss: 0.518925\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341893; batch adversarial loss: 0.602926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.319789; batch adversarial loss: 0.546429\n",
      "epoch 120; iter: 0; batch classifier loss: 0.347095; batch adversarial loss: 0.535809\n",
      "epoch 121; iter: 0; batch classifier loss: 0.325646; batch adversarial loss: 0.582161\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346551; batch adversarial loss: 0.569269\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360684; batch adversarial loss: 0.510205\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343921; batch adversarial loss: 0.570688\n",
      "epoch 125; iter: 0; batch classifier loss: 0.448560; batch adversarial loss: 0.561315\n",
      "epoch 126; iter: 0; batch classifier loss: 0.292979; batch adversarial loss: 0.598354\n",
      "epoch 127; iter: 0; batch classifier loss: 0.450844; batch adversarial loss: 0.605577\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352476; batch adversarial loss: 0.447083\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356480; batch adversarial loss: 0.552383\n",
      "epoch 130; iter: 0; batch classifier loss: 0.337604; batch adversarial loss: 0.562044\n",
      "epoch 131; iter: 0; batch classifier loss: 0.346278; batch adversarial loss: 0.554926\n",
      "epoch 132; iter: 0; batch classifier loss: 0.433316; batch adversarial loss: 0.615120\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349154; batch adversarial loss: 0.509117\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397617; batch adversarial loss: 0.508189\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343998; batch adversarial loss: 0.534036\n",
      "epoch 136; iter: 0; batch classifier loss: 0.244963; batch adversarial loss: 0.593162\n",
      "epoch 137; iter: 0; batch classifier loss: 0.393651; batch adversarial loss: 0.470854\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360246; batch adversarial loss: 0.587539\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397646; batch adversarial loss: 0.492261\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356302; batch adversarial loss: 0.555633\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353146; batch adversarial loss: 0.528362\n",
      "epoch 142; iter: 0; batch classifier loss: 0.401824; batch adversarial loss: 0.557408\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306159; batch adversarial loss: 0.536550\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354187; batch adversarial loss: 0.574728\n",
      "epoch 145; iter: 0; batch classifier loss: 0.307441; batch adversarial loss: 0.568487\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355165; batch adversarial loss: 0.697666\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322010; batch adversarial loss: 0.560492\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311114; batch adversarial loss: 0.607133\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323689; batch adversarial loss: 0.545806\n",
      "epoch 150; iter: 0; batch classifier loss: 0.284450; batch adversarial loss: 0.521775\n",
      "epoch 151; iter: 0; batch classifier loss: 0.302539; batch adversarial loss: 0.573231\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395953; batch adversarial loss: 0.581866\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376235; batch adversarial loss: 0.581516\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351264; batch adversarial loss: 0.596935\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366883; batch adversarial loss: 0.517531\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354933; batch adversarial loss: 0.589200\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376272; batch adversarial loss: 0.555338\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337203; batch adversarial loss: 0.570305\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350837; batch adversarial loss: 0.601540\n",
      "epoch 160; iter: 0; batch classifier loss: 0.315357; batch adversarial loss: 0.523811\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333823; batch adversarial loss: 0.573120\n",
      "epoch 162; iter: 0; batch classifier loss: 0.315920; batch adversarial loss: 0.614807\n",
      "epoch 163; iter: 0; batch classifier loss: 0.387208; batch adversarial loss: 0.579861\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362907; batch adversarial loss: 0.542458\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402995; batch adversarial loss: 0.481211\n",
      "epoch 166; iter: 0; batch classifier loss: 0.280943; batch adversarial loss: 0.480715\n",
      "epoch 167; iter: 0; batch classifier loss: 0.298248; batch adversarial loss: 0.563774\n",
      "epoch 168; iter: 0; batch classifier loss: 0.407905; batch adversarial loss: 0.474591\n",
      "epoch 169; iter: 0; batch classifier loss: 0.335509; batch adversarial loss: 0.462559\n",
      "epoch 170; iter: 0; batch classifier loss: 0.231251; batch adversarial loss: 0.489065\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335606; batch adversarial loss: 0.636058\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333439; batch adversarial loss: 0.571740\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338314; batch adversarial loss: 0.554916\n",
      "epoch 174; iter: 0; batch classifier loss: 0.298164; batch adversarial loss: 0.518458\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345618; batch adversarial loss: 0.543930\n",
      "epoch 176; iter: 0; batch classifier loss: 0.302918; batch adversarial loss: 0.516133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.320378; batch adversarial loss: 0.526425\n",
      "epoch 178; iter: 0; batch classifier loss: 0.426020; batch adversarial loss: 0.552689\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372748; batch adversarial loss: 0.581623\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315560; batch adversarial loss: 0.576589\n",
      "epoch 181; iter: 0; batch classifier loss: 0.340222; batch adversarial loss: 0.596467\n",
      "epoch 182; iter: 0; batch classifier loss: 0.285332; batch adversarial loss: 0.610636\n",
      "epoch 183; iter: 0; batch classifier loss: 0.340169; batch adversarial loss: 0.543074\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374004; batch adversarial loss: 0.679791\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342049; batch adversarial loss: 0.543219\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331543; batch adversarial loss: 0.499833\n",
      "epoch 187; iter: 0; batch classifier loss: 0.267494; batch adversarial loss: 0.493937\n",
      "epoch 188; iter: 0; batch classifier loss: 0.267671; batch adversarial loss: 0.524681\n",
      "epoch 189; iter: 0; batch classifier loss: 0.278868; batch adversarial loss: 0.509715\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346527; batch adversarial loss: 0.553085\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370600; batch adversarial loss: 0.581141\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373822; batch adversarial loss: 0.546753\n",
      "epoch 193; iter: 0; batch classifier loss: 0.282870; batch adversarial loss: 0.565858\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325781; batch adversarial loss: 0.570732\n",
      "epoch 195; iter: 0; batch classifier loss: 0.281751; batch adversarial loss: 0.467066\n",
      "epoch 196; iter: 0; batch classifier loss: 0.281769; batch adversarial loss: 0.574364\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324978; batch adversarial loss: 0.585976\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370962; batch adversarial loss: 0.508291\n",
      "epoch 199; iter: 0; batch classifier loss: 0.283443; batch adversarial loss: 0.499223\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676185; batch adversarial loss: 0.780734\n",
      "epoch 1; iter: 0; batch classifier loss: 0.850545; batch adversarial loss: 0.815717\n",
      "epoch 2; iter: 0; batch classifier loss: 0.773663; batch adversarial loss: 0.737189\n",
      "epoch 3; iter: 0; batch classifier loss: 0.720138; batch adversarial loss: 0.670740\n",
      "epoch 4; iter: 0; batch classifier loss: 0.637825; batch adversarial loss: 0.658248\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586171; batch adversarial loss: 0.644727\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551062; batch adversarial loss: 0.626284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558757; batch adversarial loss: 0.615075\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534320; batch adversarial loss: 0.605541\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513557; batch adversarial loss: 0.614708\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548499; batch adversarial loss: 0.583878\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575898; batch adversarial loss: 0.558649\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455180; batch adversarial loss: 0.565256\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544884; batch adversarial loss: 0.558076\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505675; batch adversarial loss: 0.569870\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534042; batch adversarial loss: 0.513047\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470119; batch adversarial loss: 0.542101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.461547; batch adversarial loss: 0.553781\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520583; batch adversarial loss: 0.602082\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513515; batch adversarial loss: 0.534964\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488027; batch adversarial loss: 0.526700\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501784; batch adversarial loss: 0.514532\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463237; batch adversarial loss: 0.583513\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489971; batch adversarial loss: 0.480366\n",
      "epoch 24; iter: 0; batch classifier loss: 0.582926; batch adversarial loss: 0.590817\n",
      "epoch 25; iter: 0; batch classifier loss: 0.427261; batch adversarial loss: 0.535791\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424348; batch adversarial loss: 0.575143\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505708; batch adversarial loss: 0.542081\n",
      "epoch 28; iter: 0; batch classifier loss: 0.530291; batch adversarial loss: 0.550130\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422263; batch adversarial loss: 0.583825\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513462; batch adversarial loss: 0.567517\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449222; batch adversarial loss: 0.484690\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464975; batch adversarial loss: 0.528014\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443345; batch adversarial loss: 0.557809\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458766; batch adversarial loss: 0.483616\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450774; batch adversarial loss: 0.632442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.526514; batch adversarial loss: 0.561289\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444427; batch adversarial loss: 0.555811\n",
      "epoch 38; iter: 0; batch classifier loss: 0.489312; batch adversarial loss: 0.593678\n",
      "epoch 39; iter: 0; batch classifier loss: 0.400409; batch adversarial loss: 0.500632\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422160; batch adversarial loss: 0.528263\n",
      "epoch 41; iter: 0; batch classifier loss: 0.442365; batch adversarial loss: 0.572268\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476159; batch adversarial loss: 0.552819\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430763; batch adversarial loss: 0.554005\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406578; batch adversarial loss: 0.553321\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451287; batch adversarial loss: 0.562320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.310441; batch adversarial loss: 0.571406\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420562; batch adversarial loss: 0.616258\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440290; batch adversarial loss: 0.544929\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416768; batch adversarial loss: 0.526821\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406793; batch adversarial loss: 0.570971\n",
      "epoch 51; iter: 0; batch classifier loss: 0.510475; batch adversarial loss: 0.578408\n",
      "epoch 52; iter: 0; batch classifier loss: 0.370440; batch adversarial loss: 0.517060\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399980; batch adversarial loss: 0.613942\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393965; batch adversarial loss: 0.491746\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416107; batch adversarial loss: 0.490150\n",
      "epoch 56; iter: 0; batch classifier loss: 0.476599; batch adversarial loss: 0.587262\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390228; batch adversarial loss: 0.565082\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399451; batch adversarial loss: 0.481883\n",
      "epoch 59; iter: 0; batch classifier loss: 0.450557; batch adversarial loss: 0.525765\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370356; batch adversarial loss: 0.627553\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438816; batch adversarial loss: 0.527755\n",
      "epoch 62; iter: 0; batch classifier loss: 0.491882; batch adversarial loss: 0.537048\n",
      "epoch 63; iter: 0; batch classifier loss: 0.359737; batch adversarial loss: 0.489066\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410043; batch adversarial loss: 0.489602\n",
      "epoch 65; iter: 0; batch classifier loss: 0.469076; batch adversarial loss: 0.515952\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387804; batch adversarial loss: 0.517246\n",
      "epoch 67; iter: 0; batch classifier loss: 0.451087; batch adversarial loss: 0.562774\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432668; batch adversarial loss: 0.534454\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389411; batch adversarial loss: 0.480214\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413026; batch adversarial loss: 0.608006\n",
      "epoch 71; iter: 0; batch classifier loss: 0.368824; batch adversarial loss: 0.561799\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417131; batch adversarial loss: 0.554112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418614; batch adversarial loss: 0.617593\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422260; batch adversarial loss: 0.516635\n",
      "epoch 75; iter: 0; batch classifier loss: 0.428824; batch adversarial loss: 0.589625\n",
      "epoch 76; iter: 0; batch classifier loss: 0.343137; batch adversarial loss: 0.489891\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436606; batch adversarial loss: 0.571347\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431508; batch adversarial loss: 0.517080\n",
      "epoch 79; iter: 0; batch classifier loss: 0.348059; batch adversarial loss: 0.535290\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420594; batch adversarial loss: 0.490016\n",
      "epoch 81; iter: 0; batch classifier loss: 0.342594; batch adversarial loss: 0.444206\n",
      "epoch 82; iter: 0; batch classifier loss: 0.439810; batch adversarial loss: 0.544973\n",
      "epoch 83; iter: 0; batch classifier loss: 0.355116; batch adversarial loss: 0.519313\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397587; batch adversarial loss: 0.570916\n",
      "epoch 85; iter: 0; batch classifier loss: 0.459876; batch adversarial loss: 0.508461\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398713; batch adversarial loss: 0.587749\n",
      "epoch 87; iter: 0; batch classifier loss: 0.321621; batch adversarial loss: 0.474489\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400429; batch adversarial loss: 0.489347\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431436; batch adversarial loss: 0.497658\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424674; batch adversarial loss: 0.560860\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433831; batch adversarial loss: 0.556168\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382545; batch adversarial loss: 0.560182\n",
      "epoch 93; iter: 0; batch classifier loss: 0.373243; batch adversarial loss: 0.527371\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365753; batch adversarial loss: 0.506768\n",
      "epoch 95; iter: 0; batch classifier loss: 0.354005; batch adversarial loss: 0.561329\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412759; batch adversarial loss: 0.589869\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396384; batch adversarial loss: 0.587645\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383692; batch adversarial loss: 0.561524\n",
      "epoch 99; iter: 0; batch classifier loss: 0.305784; batch adversarial loss: 0.482015\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345964; batch adversarial loss: 0.536623\n",
      "epoch 101; iter: 0; batch classifier loss: 0.351620; batch adversarial loss: 0.543312\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328483; batch adversarial loss: 0.582413\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390728; batch adversarial loss: 0.541771\n",
      "epoch 104; iter: 0; batch classifier loss: 0.353891; batch adversarial loss: 0.532389\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427684; batch adversarial loss: 0.496789\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393530; batch adversarial loss: 0.520767\n",
      "epoch 107; iter: 0; batch classifier loss: 0.434008; batch adversarial loss: 0.609565\n",
      "epoch 108; iter: 0; batch classifier loss: 0.505371; batch adversarial loss: 0.498825\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375871; batch adversarial loss: 0.619146\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366303; batch adversarial loss: 0.618877\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335540; batch adversarial loss: 0.488603\n",
      "epoch 112; iter: 0; batch classifier loss: 0.454175; batch adversarial loss: 0.544822\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399113; batch adversarial loss: 0.544371\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365644; batch adversarial loss: 0.544768\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366276; batch adversarial loss: 0.535465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.334728; batch adversarial loss: 0.589571\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356938; batch adversarial loss: 0.535723\n",
      "epoch 118; iter: 0; batch classifier loss: 0.290709; batch adversarial loss: 0.570108\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415325; batch adversarial loss: 0.552514\n",
      "epoch 120; iter: 0; batch classifier loss: 0.347793; batch adversarial loss: 0.498251\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366277; batch adversarial loss: 0.526527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.337820; batch adversarial loss: 0.526395\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354663; batch adversarial loss: 0.509361\n",
      "epoch 124; iter: 0; batch classifier loss: 0.312755; batch adversarial loss: 0.462097\n",
      "epoch 125; iter: 0; batch classifier loss: 0.423430; batch adversarial loss: 0.599146\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334379; batch adversarial loss: 0.579208\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395248; batch adversarial loss: 0.608091\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397268; batch adversarial loss: 0.547873\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434100; batch adversarial loss: 0.454796\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390438; batch adversarial loss: 0.572643\n",
      "epoch 131; iter: 0; batch classifier loss: 0.397409; batch adversarial loss: 0.552054\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390007; batch adversarial loss: 0.561788\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376168; batch adversarial loss: 0.534564\n",
      "epoch 134; iter: 0; batch classifier loss: 0.388101; batch adversarial loss: 0.553626\n",
      "epoch 135; iter: 0; batch classifier loss: 0.393037; batch adversarial loss: 0.533196\n",
      "epoch 136; iter: 0; batch classifier loss: 0.321919; batch adversarial loss: 0.500173\n",
      "epoch 137; iter: 0; batch classifier loss: 0.298143; batch adversarial loss: 0.571511\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381999; batch adversarial loss: 0.553954\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392975; batch adversarial loss: 0.534291\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367985; batch adversarial loss: 0.515143\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422865; batch adversarial loss: 0.586113\n",
      "epoch 142; iter: 0; batch classifier loss: 0.399149; batch adversarial loss: 0.571299\n",
      "epoch 143; iter: 0; batch classifier loss: 0.466118; batch adversarial loss: 0.563980\n",
      "epoch 144; iter: 0; batch classifier loss: 0.308489; batch adversarial loss: 0.564174\n",
      "epoch 145; iter: 0; batch classifier loss: 0.361812; batch adversarial loss: 0.481824\n",
      "epoch 146; iter: 0; batch classifier loss: 0.424635; batch adversarial loss: 0.580555\n",
      "epoch 147; iter: 0; batch classifier loss: 0.396791; batch adversarial loss: 0.560132\n",
      "epoch 148; iter: 0; batch classifier loss: 0.428908; batch adversarial loss: 0.542848\n",
      "epoch 149; iter: 0; batch classifier loss: 0.364058; batch adversarial loss: 0.601307\n",
      "epoch 150; iter: 0; batch classifier loss: 0.331142; batch adversarial loss: 0.524734\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371999; batch adversarial loss: 0.572099\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363361; batch adversarial loss: 0.555933\n",
      "epoch 153; iter: 0; batch classifier loss: 0.269676; batch adversarial loss: 0.600080\n",
      "epoch 154; iter: 0; batch classifier loss: 0.296900; batch adversarial loss: 0.569672\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388214; batch adversarial loss: 0.552002\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338761; batch adversarial loss: 0.626913\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327043; batch adversarial loss: 0.497718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.322011; batch adversarial loss: 0.544707\n",
      "epoch 159; iter: 0; batch classifier loss: 0.413926; batch adversarial loss: 0.598294\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386737; batch adversarial loss: 0.516318\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341057; batch adversarial loss: 0.508132\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366529; batch adversarial loss: 0.562734\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321398; batch adversarial loss: 0.535866\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336850; batch adversarial loss: 0.589069\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344941; batch adversarial loss: 0.516899\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367429; batch adversarial loss: 0.498559\n",
      "epoch 167; iter: 0; batch classifier loss: 0.388354; batch adversarial loss: 0.554061\n",
      "epoch 168; iter: 0; batch classifier loss: 0.290276; batch adversarial loss: 0.497676\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324165; batch adversarial loss: 0.598531\n",
      "epoch 170; iter: 0; batch classifier loss: 0.289374; batch adversarial loss: 0.582129\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378234; batch adversarial loss: 0.516056\n",
      "epoch 172; iter: 0; batch classifier loss: 0.300345; batch adversarial loss: 0.496621\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324328; batch adversarial loss: 0.551699\n",
      "epoch 174; iter: 0; batch classifier loss: 0.421320; batch adversarial loss: 0.544418\n",
      "epoch 175; iter: 0; batch classifier loss: 0.377121; batch adversarial loss: 0.525787\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377838; batch adversarial loss: 0.601210\n",
      "epoch 177; iter: 0; batch classifier loss: 0.434710; batch adversarial loss: 0.535751\n",
      "epoch 178; iter: 0; batch classifier loss: 0.325831; batch adversarial loss: 0.590447\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352399; batch adversarial loss: 0.583013\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368934; batch adversarial loss: 0.498396\n",
      "epoch 181; iter: 0; batch classifier loss: 0.489860; batch adversarial loss: 0.490971\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376913; batch adversarial loss: 0.571505\n",
      "epoch 183; iter: 0; batch classifier loss: 0.335028; batch adversarial loss: 0.536394\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335982; batch adversarial loss: 0.546266\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376714; batch adversarial loss: 0.544352\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357075; batch adversarial loss: 0.453968\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326188; batch adversarial loss: 0.527811\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343908; batch adversarial loss: 0.601518\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382432; batch adversarial loss: 0.682526\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338111; batch adversarial loss: 0.552188\n",
      "epoch 191; iter: 0; batch classifier loss: 0.393606; batch adversarial loss: 0.525547\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353787; batch adversarial loss: 0.535353\n",
      "epoch 193; iter: 0; batch classifier loss: 0.400992; batch adversarial loss: 0.544533\n",
      "epoch 194; iter: 0; batch classifier loss: 0.302855; batch adversarial loss: 0.479848\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308966; batch adversarial loss: 0.626779\n",
      "epoch 196; iter: 0; batch classifier loss: 0.325824; batch adversarial loss: 0.571072\n",
      "epoch 197; iter: 0; batch classifier loss: 0.334903; batch adversarial loss: 0.563277\n",
      "epoch 198; iter: 0; batch classifier loss: 0.295496; batch adversarial loss: 0.571232\n",
      "epoch 199; iter: 0; batch classifier loss: 0.369490; batch adversarial loss: 0.544258\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690187; batch adversarial loss: 0.653070\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592153; batch adversarial loss: 0.644727\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586145; batch adversarial loss: 0.591650\n",
      "epoch 3; iter: 0; batch classifier loss: 0.601390; batch adversarial loss: 0.625188\n",
      "epoch 4; iter: 0; batch classifier loss: 0.511983; batch adversarial loss: 0.617268\n",
      "epoch 5; iter: 0; batch classifier loss: 0.542252; batch adversarial loss: 0.591698\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569279; batch adversarial loss: 0.623811\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529125; batch adversarial loss: 0.591012\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577225; batch adversarial loss: 0.607301\n",
      "epoch 9; iter: 0; batch classifier loss: 0.618588; batch adversarial loss: 0.602666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547141; batch adversarial loss: 0.583063\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495793; batch adversarial loss: 0.574986\n",
      "epoch 12; iter: 0; batch classifier loss: 0.524750; batch adversarial loss: 0.495810\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574535; batch adversarial loss: 0.596105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.574987; batch adversarial loss: 0.510206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436667; batch adversarial loss: 0.587153\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502856; batch adversarial loss: 0.595763\n",
      "epoch 17; iter: 0; batch classifier loss: 0.433442; batch adversarial loss: 0.573402\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465582; batch adversarial loss: 0.571458\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490847; batch adversarial loss: 0.602118\n",
      "epoch 20; iter: 0; batch classifier loss: 0.600661; batch adversarial loss: 0.634967\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541940; batch adversarial loss: 0.513608\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423527; batch adversarial loss: 0.550489\n",
      "epoch 23; iter: 0; batch classifier loss: 0.554276; batch adversarial loss: 0.535886\n",
      "epoch 24; iter: 0; batch classifier loss: 0.521914; batch adversarial loss: 0.601016\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509425; batch adversarial loss: 0.534055\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453907; batch adversarial loss: 0.476394\n",
      "epoch 27; iter: 0; batch classifier loss: 0.497101; batch adversarial loss: 0.615773\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432057; batch adversarial loss: 0.545391\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477438; batch adversarial loss: 0.555814\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437965; batch adversarial loss: 0.555344\n",
      "epoch 31; iter: 0; batch classifier loss: 0.418142; batch adversarial loss: 0.536900\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463521; batch adversarial loss: 0.580148\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522364; batch adversarial loss: 0.597010\n",
      "epoch 34; iter: 0; batch classifier loss: 0.530467; batch adversarial loss: 0.606127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440810; batch adversarial loss: 0.615313\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461772; batch adversarial loss: 0.526601\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450138; batch adversarial loss: 0.580591\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469185; batch adversarial loss: 0.580723\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462414; batch adversarial loss: 0.543956\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474643; batch adversarial loss: 0.535189\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486487; batch adversarial loss: 0.505312\n",
      "epoch 42; iter: 0; batch classifier loss: 0.341372; batch adversarial loss: 0.590475\n",
      "epoch 43; iter: 0; batch classifier loss: 0.510861; batch adversarial loss: 0.555179\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490155; batch adversarial loss: 0.517913\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395199; batch adversarial loss: 0.515248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.521015; batch adversarial loss: 0.542417\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468213; batch adversarial loss: 0.552522\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422399; batch adversarial loss: 0.580555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393828; batch adversarial loss: 0.497024\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442768; batch adversarial loss: 0.497750\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414472; batch adversarial loss: 0.497049\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435856; batch adversarial loss: 0.544871\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429221; batch adversarial loss: 0.508783\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411354; batch adversarial loss: 0.591151\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413175; batch adversarial loss: 0.581587\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435178; batch adversarial loss: 0.534704\n",
      "epoch 57; iter: 0; batch classifier loss: 0.371920; batch adversarial loss: 0.489569\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390768; batch adversarial loss: 0.555541\n",
      "epoch 59; iter: 0; batch classifier loss: 0.520838; batch adversarial loss: 0.563794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.448685; batch adversarial loss: 0.515739\n",
      "epoch 61; iter: 0; batch classifier loss: 0.456710; batch adversarial loss: 0.543625\n",
      "epoch 62; iter: 0; batch classifier loss: 0.419397; batch adversarial loss: 0.515365\n",
      "epoch 63; iter: 0; batch classifier loss: 0.494249; batch adversarial loss: 0.488857\n",
      "epoch 64; iter: 0; batch classifier loss: 0.476584; batch adversarial loss: 0.536327\n",
      "epoch 65; iter: 0; batch classifier loss: 0.485968; batch adversarial loss: 0.480290\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377637; batch adversarial loss: 0.515048\n",
      "epoch 67; iter: 0; batch classifier loss: 0.508141; batch adversarial loss: 0.552283\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447754; batch adversarial loss: 0.640488\n",
      "epoch 69; iter: 0; batch classifier loss: 0.453808; batch adversarial loss: 0.564750\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387638; batch adversarial loss: 0.589221\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410287; batch adversarial loss: 0.476315\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377719; batch adversarial loss: 0.450209\n",
      "epoch 73; iter: 0; batch classifier loss: 0.497033; batch adversarial loss: 0.590120\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406161; batch adversarial loss: 0.532895\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329783; batch adversarial loss: 0.504094\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396580; batch adversarial loss: 0.650556\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418265; batch adversarial loss: 0.502369\n",
      "epoch 78; iter: 0; batch classifier loss: 0.403202; batch adversarial loss: 0.497068\n",
      "epoch 79; iter: 0; batch classifier loss: 0.364364; batch adversarial loss: 0.561950\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421694; batch adversarial loss: 0.607157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406294; batch adversarial loss: 0.534767\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415420; batch adversarial loss: 0.529111\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415512; batch adversarial loss: 0.544121\n",
      "epoch 84; iter: 0; batch classifier loss: 0.467585; batch adversarial loss: 0.562507\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424445; batch adversarial loss: 0.517479\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432430; batch adversarial loss: 0.535730\n",
      "epoch 87; iter: 0; batch classifier loss: 0.305458; batch adversarial loss: 0.573248\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362531; batch adversarial loss: 0.545204\n",
      "epoch 89; iter: 0; batch classifier loss: 0.447678; batch adversarial loss: 0.563451\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391723; batch adversarial loss: 0.599181\n",
      "epoch 91; iter: 0; batch classifier loss: 0.306973; batch adversarial loss: 0.598012\n",
      "epoch 92; iter: 0; batch classifier loss: 0.345046; batch adversarial loss: 0.598994\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359486; batch adversarial loss: 0.470855\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426929; batch adversarial loss: 0.507457\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384934; batch adversarial loss: 0.571070\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392370; batch adversarial loss: 0.579265\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346448; batch adversarial loss: 0.582625\n",
      "epoch 98; iter: 0; batch classifier loss: 0.482996; batch adversarial loss: 0.533211\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344200; batch adversarial loss: 0.581758\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418181; batch adversarial loss: 0.517718\n",
      "epoch 101; iter: 0; batch classifier loss: 0.454197; batch adversarial loss: 0.516073\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367074; batch adversarial loss: 0.543939\n",
      "epoch 103; iter: 0; batch classifier loss: 0.450005; batch adversarial loss: 0.480644\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361756; batch adversarial loss: 0.499431\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365042; batch adversarial loss: 0.580129\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380379; batch adversarial loss: 0.545242\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353593; batch adversarial loss: 0.497940\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371213; batch adversarial loss: 0.553899\n",
      "epoch 109; iter: 0; batch classifier loss: 0.429192; batch adversarial loss: 0.535101\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403332; batch adversarial loss: 0.414976\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356135; batch adversarial loss: 0.562306\n",
      "epoch 112; iter: 0; batch classifier loss: 0.318455; batch adversarial loss: 0.562672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.385098; batch adversarial loss: 0.598009\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373801; batch adversarial loss: 0.589710\n",
      "epoch 115; iter: 0; batch classifier loss: 0.486344; batch adversarial loss: 0.480193\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364396; batch adversarial loss: 0.601017\n",
      "epoch 117; iter: 0; batch classifier loss: 0.427410; batch adversarial loss: 0.555468\n",
      "epoch 118; iter: 0; batch classifier loss: 0.509333; batch adversarial loss: 0.626468\n",
      "epoch 119; iter: 0; batch classifier loss: 0.361808; batch adversarial loss: 0.635498\n",
      "epoch 120; iter: 0; batch classifier loss: 0.341884; batch adversarial loss: 0.609327\n",
      "epoch 121; iter: 0; batch classifier loss: 0.455843; batch adversarial loss: 0.572576\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346708; batch adversarial loss: 0.530059\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394812; batch adversarial loss: 0.683708\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338685; batch adversarial loss: 0.574218\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368046; batch adversarial loss: 0.477770\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336729; batch adversarial loss: 0.555791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.403769; batch adversarial loss: 0.560601\n",
      "epoch 128; iter: 0; batch classifier loss: 0.439475; batch adversarial loss: 0.505809\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394542; batch adversarial loss: 0.606685\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388475; batch adversarial loss: 0.614279\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345050; batch adversarial loss: 0.720916\n",
      "epoch 132; iter: 0; batch classifier loss: 0.427315; batch adversarial loss: 0.515712\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425817; batch adversarial loss: 0.564947\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368782; batch adversarial loss: 0.619916\n",
      "epoch 135; iter: 0; batch classifier loss: 0.436313; batch adversarial loss: 0.499914\n",
      "epoch 136; iter: 0; batch classifier loss: 0.344057; batch adversarial loss: 0.514063\n",
      "epoch 137; iter: 0; batch classifier loss: 0.422350; batch adversarial loss: 0.512725\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392578; batch adversarial loss: 0.501080\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408008; batch adversarial loss: 0.557806\n",
      "epoch 140; iter: 0; batch classifier loss: 0.491442; batch adversarial loss: 0.566507\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424041; batch adversarial loss: 0.562900\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333850; batch adversarial loss: 0.519416\n",
      "epoch 143; iter: 0; batch classifier loss: 0.415168; batch adversarial loss: 0.555259\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356037; batch adversarial loss: 0.536620\n",
      "epoch 145; iter: 0; batch classifier loss: 0.343225; batch adversarial loss: 0.546126\n",
      "epoch 146; iter: 0; batch classifier loss: 0.417920; batch adversarial loss: 0.518545\n",
      "epoch 147; iter: 0; batch classifier loss: 0.418373; batch adversarial loss: 0.598943\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405312; batch adversarial loss: 0.527176\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391839; batch adversarial loss: 0.606894\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391507; batch adversarial loss: 0.507488\n",
      "epoch 151; iter: 0; batch classifier loss: 0.457617; batch adversarial loss: 0.564328\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336721; batch adversarial loss: 0.497190\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372071; batch adversarial loss: 0.490335\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360262; batch adversarial loss: 0.619201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.446550; batch adversarial loss: 0.536410\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379216; batch adversarial loss: 0.453795\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358160; batch adversarial loss: 0.528391\n",
      "epoch 158; iter: 0; batch classifier loss: 0.443894; batch adversarial loss: 0.544111\n",
      "epoch 159; iter: 0; batch classifier loss: 0.466200; batch adversarial loss: 0.544741\n",
      "epoch 160; iter: 0; batch classifier loss: 0.421607; batch adversarial loss: 0.509272\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366415; batch adversarial loss: 0.518138\n",
      "epoch 162; iter: 0; batch classifier loss: 0.405635; batch adversarial loss: 0.499675\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400978; batch adversarial loss: 0.526540\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366812; batch adversarial loss: 0.598954\n",
      "epoch 165; iter: 0; batch classifier loss: 0.431207; batch adversarial loss: 0.507542\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387299; batch adversarial loss: 0.526347\n",
      "epoch 167; iter: 0; batch classifier loss: 0.400334; batch adversarial loss: 0.434361\n",
      "epoch 168; iter: 0; batch classifier loss: 0.355751; batch adversarial loss: 0.489688\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324086; batch adversarial loss: 0.536324\n",
      "epoch 170; iter: 0; batch classifier loss: 0.524830; batch adversarial loss: 0.499158\n",
      "epoch 171; iter: 0; batch classifier loss: 0.428836; batch adversarial loss: 0.581505\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379771; batch adversarial loss: 0.527328\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322584; batch adversarial loss: 0.544379\n",
      "epoch 174; iter: 0; batch classifier loss: 0.342277; batch adversarial loss: 0.579619\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389282; batch adversarial loss: 0.489783\n",
      "epoch 176; iter: 0; batch classifier loss: 0.440349; batch adversarial loss: 0.517247\n",
      "epoch 177; iter: 0; batch classifier loss: 0.367089; batch adversarial loss: 0.489712\n",
      "epoch 178; iter: 0; batch classifier loss: 0.277559; batch adversarial loss: 0.544781\n",
      "epoch 179; iter: 0; batch classifier loss: 0.304077; batch adversarial loss: 0.544405\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366958; batch adversarial loss: 0.498568\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400958; batch adversarial loss: 0.580433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352074; batch adversarial loss: 0.590896\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379749; batch adversarial loss: 0.533882\n",
      "epoch 184; iter: 0; batch classifier loss: 0.400291; batch adversarial loss: 0.543799\n",
      "epoch 185; iter: 0; batch classifier loss: 0.452923; batch adversarial loss: 0.545465\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366020; batch adversarial loss: 0.498447\n",
      "epoch 187; iter: 0; batch classifier loss: 0.296989; batch adversarial loss: 0.570448\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345540; batch adversarial loss: 0.507685\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336197; batch adversarial loss: 0.571924\n",
      "epoch 190; iter: 0; batch classifier loss: 0.393700; batch adversarial loss: 0.499688\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403789; batch adversarial loss: 0.571548\n",
      "epoch 192; iter: 0; batch classifier loss: 0.426934; batch adversarial loss: 0.498303\n",
      "epoch 193; iter: 0; batch classifier loss: 0.306737; batch adversarial loss: 0.572642\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374123; batch adversarial loss: 0.533309\n",
      "epoch 195; iter: 0; batch classifier loss: 0.468515; batch adversarial loss: 0.517144\n",
      "epoch 196; iter: 0; batch classifier loss: 0.279127; batch adversarial loss: 0.599191\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342219; batch adversarial loss: 0.581360\n",
      "epoch 198; iter: 0; batch classifier loss: 0.410944; batch adversarial loss: 0.644011\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330559; batch adversarial loss: 0.526872\n",
      "epoch 0; iter: 0; batch classifier loss: 0.806268; batch adversarial loss: 0.584039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542397; batch adversarial loss: 0.651104\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602894; batch adversarial loss: 0.676421\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618426; batch adversarial loss: 0.654222\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513062; batch adversarial loss: 0.597974\n",
      "epoch 5; iter: 0; batch classifier loss: 0.667413; batch adversarial loss: 0.640962\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639242; batch adversarial loss: 0.582849\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549560; batch adversarial loss: 0.568936\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585591; batch adversarial loss: 0.627766\n",
      "epoch 9; iter: 0; batch classifier loss: 0.674023; batch adversarial loss: 0.600957\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500673; batch adversarial loss: 0.583271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.467341; batch adversarial loss: 0.627254\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527305; batch adversarial loss: 0.579537\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556337; batch adversarial loss: 0.598638\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474941; batch adversarial loss: 0.576400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508181; batch adversarial loss: 0.574881\n",
      "epoch 16; iter: 0; batch classifier loss: 0.588044; batch adversarial loss: 0.595579\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485402; batch adversarial loss: 0.543647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559814; batch adversarial loss: 0.549950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489106; batch adversarial loss: 0.524360\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548290; batch adversarial loss: 0.584182\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539786; batch adversarial loss: 0.545888\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438671; batch adversarial loss: 0.613287\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484823; batch adversarial loss: 0.532583\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428305; batch adversarial loss: 0.566747\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468270; batch adversarial loss: 0.595379\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519626; batch adversarial loss: 0.560987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509993; batch adversarial loss: 0.537970\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452683; batch adversarial loss: 0.508881\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449524; batch adversarial loss: 0.508135\n",
      "epoch 30; iter: 0; batch classifier loss: 0.399901; batch adversarial loss: 0.553432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455520; batch adversarial loss: 0.552436\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431139; batch adversarial loss: 0.620982\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458486; batch adversarial loss: 0.573534\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500912; batch adversarial loss: 0.535275\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491669; batch adversarial loss: 0.559896\n",
      "epoch 36; iter: 0; batch classifier loss: 0.489926; batch adversarial loss: 0.590724\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430280; batch adversarial loss: 0.536316\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466912; batch adversarial loss: 0.534529\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491778; batch adversarial loss: 0.525072\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449739; batch adversarial loss: 0.576658\n",
      "epoch 41; iter: 0; batch classifier loss: 0.442551; batch adversarial loss: 0.535703\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451062; batch adversarial loss: 0.526796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403878; batch adversarial loss: 0.464113\n",
      "epoch 44; iter: 0; batch classifier loss: 0.384256; batch adversarial loss: 0.599212\n",
      "epoch 45; iter: 0; batch classifier loss: 0.390085; batch adversarial loss: 0.562562\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461163; batch adversarial loss: 0.527119\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409387; batch adversarial loss: 0.517701\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422534; batch adversarial loss: 0.582100\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460544; batch adversarial loss: 0.518190\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471120; batch adversarial loss: 0.578462\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436157; batch adversarial loss: 0.559510\n",
      "epoch 52; iter: 0; batch classifier loss: 0.497436; batch adversarial loss: 0.572320\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458203; batch adversarial loss: 0.553775\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443401; batch adversarial loss: 0.525780\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391141; batch adversarial loss: 0.528591\n",
      "epoch 56; iter: 0; batch classifier loss: 0.471312; batch adversarial loss: 0.589611\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490774; batch adversarial loss: 0.554844\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378780; batch adversarial loss: 0.553895\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398474; batch adversarial loss: 0.608939\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391649; batch adversarial loss: 0.453550\n",
      "epoch 61; iter: 0; batch classifier loss: 0.481525; batch adversarial loss: 0.582026\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406382; batch adversarial loss: 0.553255\n",
      "epoch 63; iter: 0; batch classifier loss: 0.380151; batch adversarial loss: 0.579990\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460603; batch adversarial loss: 0.580294\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384095; batch adversarial loss: 0.562863\n",
      "epoch 66; iter: 0; batch classifier loss: 0.469899; batch adversarial loss: 0.469942\n",
      "epoch 67; iter: 0; batch classifier loss: 0.397298; batch adversarial loss: 0.546516\n",
      "epoch 68; iter: 0; batch classifier loss: 0.354290; batch adversarial loss: 0.532231\n",
      "epoch 69; iter: 0; batch classifier loss: 0.327024; batch adversarial loss: 0.551338\n",
      "epoch 70; iter: 0; batch classifier loss: 0.442499; batch adversarial loss: 0.546038\n",
      "epoch 71; iter: 0; batch classifier loss: 0.319835; batch adversarial loss: 0.526945\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416374; batch adversarial loss: 0.565570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.472673; batch adversarial loss: 0.528014\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423973; batch adversarial loss: 0.535303\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367456; batch adversarial loss: 0.518518\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422174; batch adversarial loss: 0.527118\n",
      "epoch 77; iter: 0; batch classifier loss: 0.334098; batch adversarial loss: 0.659973\n",
      "epoch 78; iter: 0; batch classifier loss: 0.337547; batch adversarial loss: 0.570893\n",
      "epoch 79; iter: 0; batch classifier loss: 0.317687; batch adversarial loss: 0.479801\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412173; batch adversarial loss: 0.536116\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432188; batch adversarial loss: 0.547012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419081; batch adversarial loss: 0.508189\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413315; batch adversarial loss: 0.534435\n",
      "epoch 84; iter: 0; batch classifier loss: 0.321663; batch adversarial loss: 0.519166\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391346; batch adversarial loss: 0.589534\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344577; batch adversarial loss: 0.579346\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372008; batch adversarial loss: 0.572174\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381821; batch adversarial loss: 0.490952\n",
      "epoch 89; iter: 0; batch classifier loss: 0.306633; batch adversarial loss: 0.562943\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358447; batch adversarial loss: 0.625485\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396454; batch adversarial loss: 0.543984\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354645; batch adversarial loss: 0.517464\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356515; batch adversarial loss: 0.560345\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380664; batch adversarial loss: 0.497969\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408391; batch adversarial loss: 0.588494\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359179; batch adversarial loss: 0.506205\n",
      "epoch 97; iter: 0; batch classifier loss: 0.435417; batch adversarial loss: 0.589499\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377150; batch adversarial loss: 0.553588\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363520; batch adversarial loss: 0.571668\n",
      "epoch 100; iter: 0; batch classifier loss: 0.323091; batch adversarial loss: 0.525831\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417497; batch adversarial loss: 0.563182\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415790; batch adversarial loss: 0.553626\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382059; batch adversarial loss: 0.567441\n",
      "epoch 104; iter: 0; batch classifier loss: 0.445020; batch adversarial loss: 0.626332\n",
      "epoch 105; iter: 0; batch classifier loss: 0.393088; batch adversarial loss: 0.565336\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388581; batch adversarial loss: 0.536926\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368891; batch adversarial loss: 0.519300\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435417; batch adversarial loss: 0.536379\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356289; batch adversarial loss: 0.544970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.402437; batch adversarial loss: 0.500706\n",
      "epoch 111; iter: 0; batch classifier loss: 0.338265; batch adversarial loss: 0.562530\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353119; batch adversarial loss: 0.580549\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384153; batch adversarial loss: 0.598390\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378439; batch adversarial loss: 0.518377\n",
      "epoch 115; iter: 0; batch classifier loss: 0.287798; batch adversarial loss: 0.525687\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371947; batch adversarial loss: 0.572219\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337507; batch adversarial loss: 0.543983\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342953; batch adversarial loss: 0.490601\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396616; batch adversarial loss: 0.562724\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387312; batch adversarial loss: 0.571537\n",
      "epoch 121; iter: 0; batch classifier loss: 0.432431; batch adversarial loss: 0.526508\n",
      "epoch 122; iter: 0; batch classifier loss: 0.472356; batch adversarial loss: 0.624211\n",
      "epoch 123; iter: 0; batch classifier loss: 0.392770; batch adversarial loss: 0.499053\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348442; batch adversarial loss: 0.490783\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418607; batch adversarial loss: 0.535866\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374805; batch adversarial loss: 0.509966\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417372; batch adversarial loss: 0.517639\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348961; batch adversarial loss: 0.553724\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359528; batch adversarial loss: 0.571179\n",
      "epoch 130; iter: 0; batch classifier loss: 0.290528; batch adversarial loss: 0.509280\n",
      "epoch 131; iter: 0; batch classifier loss: 0.305047; batch adversarial loss: 0.544811\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359559; batch adversarial loss: 0.571504\n",
      "epoch 133; iter: 0; batch classifier loss: 0.454572; batch adversarial loss: 0.588954\n",
      "epoch 134; iter: 0; batch classifier loss: 0.437809; batch adversarial loss: 0.589227\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387309; batch adversarial loss: 0.553803\n",
      "epoch 136; iter: 0; batch classifier loss: 0.312382; batch adversarial loss: 0.572016\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340949; batch adversarial loss: 0.526285\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359525; batch adversarial loss: 0.535064\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381024; batch adversarial loss: 0.562238\n",
      "epoch 140; iter: 0; batch classifier loss: 0.412815; batch adversarial loss: 0.573441\n",
      "epoch 141; iter: 0; batch classifier loss: 0.317884; batch adversarial loss: 0.579300\n",
      "epoch 142; iter: 0; batch classifier loss: 0.450422; batch adversarial loss: 0.491138\n",
      "epoch 143; iter: 0; batch classifier loss: 0.441789; batch adversarial loss: 0.518526\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363660; batch adversarial loss: 0.535443\n",
      "epoch 145; iter: 0; batch classifier loss: 0.422473; batch adversarial loss: 0.571583\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353844; batch adversarial loss: 0.599017\n",
      "epoch 147; iter: 0; batch classifier loss: 0.332969; batch adversarial loss: 0.571262\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358564; batch adversarial loss: 0.508721\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378982; batch adversarial loss: 0.598505\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365153; batch adversarial loss: 0.500221\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370359; batch adversarial loss: 0.535718\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352114; batch adversarial loss: 0.527028\n",
      "epoch 153; iter: 0; batch classifier loss: 0.270041; batch adversarial loss: 0.526601\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404894; batch adversarial loss: 0.607857\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350045; batch adversarial loss: 0.509278\n",
      "epoch 156; iter: 0; batch classifier loss: 0.427156; batch adversarial loss: 0.562672\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411814; batch adversarial loss: 0.617063\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334490; batch adversarial loss: 0.445075\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383184; batch adversarial loss: 0.572308\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346483; batch adversarial loss: 0.544830\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397820; batch adversarial loss: 0.544757\n",
      "epoch 162; iter: 0; batch classifier loss: 0.307590; batch adversarial loss: 0.580458\n",
      "epoch 163; iter: 0; batch classifier loss: 0.316119; batch adversarial loss: 0.616885\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386858; batch adversarial loss: 0.616311\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389243; batch adversarial loss: 0.507253\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388003; batch adversarial loss: 0.544058\n",
      "epoch 167; iter: 0; batch classifier loss: 0.438362; batch adversarial loss: 0.499748\n",
      "epoch 168; iter: 0; batch classifier loss: 0.355121; batch adversarial loss: 0.616399\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380004; batch adversarial loss: 0.508808\n",
      "epoch 170; iter: 0; batch classifier loss: 0.406777; batch adversarial loss: 0.634180\n",
      "epoch 171; iter: 0; batch classifier loss: 0.435009; batch adversarial loss: 0.553070\n",
      "epoch 172; iter: 0; batch classifier loss: 0.294828; batch adversarial loss: 0.571105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333420; batch adversarial loss: 0.544444\n",
      "epoch 174; iter: 0; batch classifier loss: 0.308286; batch adversarial loss: 0.553010\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356894; batch adversarial loss: 0.455275\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410637; batch adversarial loss: 0.553435\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372369; batch adversarial loss: 0.544695\n",
      "epoch 178; iter: 0; batch classifier loss: 0.406112; batch adversarial loss: 0.517917\n",
      "epoch 179; iter: 0; batch classifier loss: 0.385959; batch adversarial loss: 0.607749\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378546; batch adversarial loss: 0.553157\n",
      "epoch 181; iter: 0; batch classifier loss: 0.447246; batch adversarial loss: 0.517942\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374686; batch adversarial loss: 0.562146\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313534; batch adversarial loss: 0.652706\n",
      "epoch 184; iter: 0; batch classifier loss: 0.269999; batch adversarial loss: 0.517748\n",
      "epoch 185; iter: 0; batch classifier loss: 0.403294; batch adversarial loss: 0.607340\n",
      "epoch 186; iter: 0; batch classifier loss: 0.337709; batch adversarial loss: 0.634389\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363040; batch adversarial loss: 0.517603\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313406; batch adversarial loss: 0.580817\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332895; batch adversarial loss: 0.562911\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364502; batch adversarial loss: 0.499662\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347202; batch adversarial loss: 0.608855\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401012; batch adversarial loss: 0.480967\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344570; batch adversarial loss: 0.590825\n",
      "epoch 194; iter: 0; batch classifier loss: 0.339102; batch adversarial loss: 0.526975\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349822; batch adversarial loss: 0.518242\n",
      "epoch 196; iter: 0; batch classifier loss: 0.344954; batch adversarial loss: 0.571384\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347638; batch adversarial loss: 0.482528\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396557; batch adversarial loss: 0.535604\n",
      "epoch 199; iter: 0; batch classifier loss: 0.303884; batch adversarial loss: 0.500110\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689707; batch adversarial loss: 0.872533\n",
      "epoch 1; iter: 0; batch classifier loss: 0.847195; batch adversarial loss: 1.302407\n",
      "epoch 2; iter: 0; batch classifier loss: 0.978496; batch adversarial loss: 1.229201\n",
      "epoch 3; iter: 0; batch classifier loss: 0.879350; batch adversarial loss: 1.214329\n",
      "epoch 4; iter: 0; batch classifier loss: 1.145530; batch adversarial loss: 1.064183\n",
      "epoch 5; iter: 0; batch classifier loss: 1.074320; batch adversarial loss: 0.967630\n",
      "epoch 6; iter: 0; batch classifier loss: 1.192875; batch adversarial loss: 0.906705\n",
      "epoch 7; iter: 0; batch classifier loss: 1.089405; batch adversarial loss: 0.831376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 1.009765; batch adversarial loss: 0.776888\n",
      "epoch 9; iter: 0; batch classifier loss: 0.845247; batch adversarial loss: 0.711903\n",
      "epoch 10; iter: 0; batch classifier loss: 0.807465; batch adversarial loss: 0.691180\n",
      "epoch 11; iter: 0; batch classifier loss: 0.615724; batch adversarial loss: 0.621727\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586856; batch adversarial loss: 0.623174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553867; batch adversarial loss: 0.621538\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511543; batch adversarial loss: 0.527263\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505672; batch adversarial loss: 0.576041\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508779; batch adversarial loss: 0.579481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531622; batch adversarial loss: 0.556323\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471246; batch adversarial loss: 0.606341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475605; batch adversarial loss: 0.553439\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485953; batch adversarial loss: 0.621747\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531194; batch adversarial loss: 0.543865\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501152; batch adversarial loss: 0.535341\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472967; batch adversarial loss: 0.522822\n",
      "epoch 24; iter: 0; batch classifier loss: 0.543743; batch adversarial loss: 0.544127\n",
      "epoch 25; iter: 0; batch classifier loss: 0.548212; batch adversarial loss: 0.550476\n",
      "epoch 26; iter: 0; batch classifier loss: 0.530679; batch adversarial loss: 0.509802\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455829; batch adversarial loss: 0.518736\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480823; batch adversarial loss: 0.508467\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431366; batch adversarial loss: 0.559159\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495498; batch adversarial loss: 0.501409\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435167; batch adversarial loss: 0.538858\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419077; batch adversarial loss: 0.514655\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498196; batch adversarial loss: 0.523450\n",
      "epoch 34; iter: 0; batch classifier loss: 0.489579; batch adversarial loss: 0.511265\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414428; batch adversarial loss: 0.619098\n",
      "epoch 36; iter: 0; batch classifier loss: 0.568378; batch adversarial loss: 0.595711\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456103; batch adversarial loss: 0.641258\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414956; batch adversarial loss: 0.527878\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437298; batch adversarial loss: 0.503957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.536047; batch adversarial loss: 0.480595\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390566; batch adversarial loss: 0.509425\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425344; batch adversarial loss: 0.525108\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486042; batch adversarial loss: 0.605761\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386010; batch adversarial loss: 0.633740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.452420; batch adversarial loss: 0.526457\n",
      "epoch 46; iter: 0; batch classifier loss: 0.492715; batch adversarial loss: 0.571130\n",
      "epoch 47; iter: 0; batch classifier loss: 0.489439; batch adversarial loss: 0.536785\n",
      "epoch 48; iter: 0; batch classifier loss: 0.463345; batch adversarial loss: 0.433785\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439096; batch adversarial loss: 0.543850\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450603; batch adversarial loss: 0.544954\n",
      "epoch 51; iter: 0; batch classifier loss: 0.459639; batch adversarial loss: 0.626378\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382279; batch adversarial loss: 0.552840\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465260; batch adversarial loss: 0.479787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452778; batch adversarial loss: 0.543092\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436283; batch adversarial loss: 0.617255\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431954; batch adversarial loss: 0.533066\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437658; batch adversarial loss: 0.559544\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413809; batch adversarial loss: 0.571692\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394895; batch adversarial loss: 0.514953\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431803; batch adversarial loss: 0.500480\n",
      "epoch 61; iter: 0; batch classifier loss: 0.493359; batch adversarial loss: 0.524308\n",
      "epoch 62; iter: 0; batch classifier loss: 0.420441; batch adversarial loss: 0.591304\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432920; batch adversarial loss: 0.546131\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432518; batch adversarial loss: 0.598424\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365821; batch adversarial loss: 0.526499\n",
      "epoch 66; iter: 0; batch classifier loss: 0.464739; batch adversarial loss: 0.488591\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405033; batch adversarial loss: 0.559177\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375235; batch adversarial loss: 0.563717\n",
      "epoch 69; iter: 0; batch classifier loss: 0.322037; batch adversarial loss: 0.570686\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396461; batch adversarial loss: 0.606288\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449775; batch adversarial loss: 0.662308\n",
      "epoch 72; iter: 0; batch classifier loss: 0.384097; batch adversarial loss: 0.479225\n",
      "epoch 73; iter: 0; batch classifier loss: 0.343172; batch adversarial loss: 0.545564\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384638; batch adversarial loss: 0.486609\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346098; batch adversarial loss: 0.551913\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387481; batch adversarial loss: 0.564402\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424097; batch adversarial loss: 0.573271\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390928; batch adversarial loss: 0.467605\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440359; batch adversarial loss: 0.661988\n",
      "epoch 80; iter: 0; batch classifier loss: 0.323014; batch adversarial loss: 0.595534\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402596; batch adversarial loss: 0.646917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414093; batch adversarial loss: 0.562925\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385522; batch adversarial loss: 0.515992\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391333; batch adversarial loss: 0.544817\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400728; batch adversarial loss: 0.514895\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386428; batch adversarial loss: 0.634728\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410515; batch adversarial loss: 0.582172\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382214; batch adversarial loss: 0.507796\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427906; batch adversarial loss: 0.533585\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390870; batch adversarial loss: 0.569603\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400633; batch adversarial loss: 0.547369\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368914; batch adversarial loss: 0.637297\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358983; batch adversarial loss: 0.632665\n",
      "epoch 94; iter: 0; batch classifier loss: 0.441930; batch adversarial loss: 0.589640\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373630; batch adversarial loss: 0.470850\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419333; batch adversarial loss: 0.561022\n",
      "epoch 97; iter: 0; batch classifier loss: 0.332075; batch adversarial loss: 0.578085\n",
      "epoch 98; iter: 0; batch classifier loss: 0.320007; batch adversarial loss: 0.489406\n",
      "epoch 99; iter: 0; batch classifier loss: 0.465388; batch adversarial loss: 0.570624\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400071; batch adversarial loss: 0.531462\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388398; batch adversarial loss: 0.579258\n",
      "epoch 102; iter: 0; batch classifier loss: 0.317521; batch adversarial loss: 0.526824\n",
      "epoch 103; iter: 0; batch classifier loss: 0.321767; batch adversarial loss: 0.444408\n",
      "epoch 104; iter: 0; batch classifier loss: 0.388630; batch adversarial loss: 0.514343\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373405; batch adversarial loss: 0.553877\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381786; batch adversarial loss: 0.567402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.345577; batch adversarial loss: 0.543728\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382733; batch adversarial loss: 0.598580\n",
      "epoch 109; iter: 0; batch classifier loss: 0.332876; batch adversarial loss: 0.600444\n",
      "epoch 110; iter: 0; batch classifier loss: 0.304563; batch adversarial loss: 0.508743\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350299; batch adversarial loss: 0.516757\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415160; batch adversarial loss: 0.566725\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406232; batch adversarial loss: 0.527854\n",
      "epoch 114; iter: 0; batch classifier loss: 0.453638; batch adversarial loss: 0.569990\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352850; batch adversarial loss: 0.503984\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357426; batch adversarial loss: 0.547555\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363391; batch adversarial loss: 0.541242\n",
      "epoch 118; iter: 0; batch classifier loss: 0.319164; batch adversarial loss: 0.579793\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338180; batch adversarial loss: 0.587909\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330348; batch adversarial loss: 0.526326\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383407; batch adversarial loss: 0.545205\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371958; batch adversarial loss: 0.458544\n",
      "epoch 123; iter: 0; batch classifier loss: 0.386004; batch adversarial loss: 0.589375\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407106; batch adversarial loss: 0.502024\n",
      "epoch 125; iter: 0; batch classifier loss: 0.310774; batch adversarial loss: 0.551575\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399645; batch adversarial loss: 0.581308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353298; batch adversarial loss: 0.552721\n",
      "epoch 128; iter: 0; batch classifier loss: 0.331072; batch adversarial loss: 0.481105\n",
      "epoch 129; iter: 0; batch classifier loss: 0.328532; batch adversarial loss: 0.569188\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391004; batch adversarial loss: 0.469331\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324719; batch adversarial loss: 0.547691\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404952; batch adversarial loss: 0.503478\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367212; batch adversarial loss: 0.535424\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369759; batch adversarial loss: 0.541545\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389102; batch adversarial loss: 0.526237\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382041; batch adversarial loss: 0.524785\n",
      "epoch 137; iter: 0; batch classifier loss: 0.331900; batch adversarial loss: 0.489818\n",
      "epoch 138; iter: 0; batch classifier loss: 0.398359; batch adversarial loss: 0.554709\n",
      "epoch 139; iter: 0; batch classifier loss: 0.353703; batch adversarial loss: 0.491068\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375050; batch adversarial loss: 0.504309\n",
      "epoch 141; iter: 0; batch classifier loss: 0.355711; batch adversarial loss: 0.588913\n",
      "epoch 142; iter: 0; batch classifier loss: 0.409615; batch adversarial loss: 0.610116\n",
      "epoch 143; iter: 0; batch classifier loss: 0.261614; batch adversarial loss: 0.543762\n",
      "epoch 144; iter: 0; batch classifier loss: 0.343004; batch adversarial loss: 0.572323\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400489; batch adversarial loss: 0.610606\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366115; batch adversarial loss: 0.544366\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372973; batch adversarial loss: 0.527047\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364039; batch adversarial loss: 0.615203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391354; batch adversarial loss: 0.552327\n",
      "epoch 150; iter: 0; batch classifier loss: 0.494858; batch adversarial loss: 0.521592\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341066; batch adversarial loss: 0.582280\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362593; batch adversarial loss: 0.443408\n",
      "epoch 153; iter: 0; batch classifier loss: 0.319711; batch adversarial loss: 0.552621\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345486; batch adversarial loss: 0.519204\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347266; batch adversarial loss: 0.536273\n",
      "epoch 156; iter: 0; batch classifier loss: 0.389003; batch adversarial loss: 0.582558\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314627; batch adversarial loss: 0.543847\n",
      "epoch 158; iter: 0; batch classifier loss: 0.310533; batch adversarial loss: 0.541194\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338809; batch adversarial loss: 0.516643\n",
      "epoch 160; iter: 0; batch classifier loss: 0.367360; batch adversarial loss: 0.508558\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401857; batch adversarial loss: 0.578233\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385927; batch adversarial loss: 0.525262\n",
      "epoch 163; iter: 0; batch classifier loss: 0.393577; batch adversarial loss: 0.556335\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322086; batch adversarial loss: 0.484734\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360771; batch adversarial loss: 0.541855\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357789; batch adversarial loss: 0.516158\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346811; batch adversarial loss: 0.562867\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354485; batch adversarial loss: 0.562769\n",
      "epoch 169; iter: 0; batch classifier loss: 0.290830; batch adversarial loss: 0.476663\n",
      "epoch 170; iter: 0; batch classifier loss: 0.310940; batch adversarial loss: 0.461434\n",
      "epoch 171; iter: 0; batch classifier loss: 0.276755; batch adversarial loss: 0.542276\n",
      "epoch 172; iter: 0; batch classifier loss: 0.403394; batch adversarial loss: 0.472025\n",
      "epoch 173; iter: 0; batch classifier loss: 0.358973; batch adversarial loss: 0.516898\n",
      "epoch 174; iter: 0; batch classifier loss: 0.409517; batch adversarial loss: 0.458512\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416478; batch adversarial loss: 0.559574\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365341; batch adversarial loss: 0.497186\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366214; batch adversarial loss: 0.500865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336224; batch adversarial loss: 0.528011\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356143; batch adversarial loss: 0.599067\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364102; batch adversarial loss: 0.556391\n",
      "epoch 181; iter: 0; batch classifier loss: 0.282494; batch adversarial loss: 0.590555\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351661; batch adversarial loss: 0.474793\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311680; batch adversarial loss: 0.470036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309552; batch adversarial loss: 0.471711\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377115; batch adversarial loss: 0.550928\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338867; batch adversarial loss: 0.560774\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368654; batch adversarial loss: 0.562116\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404061; batch adversarial loss: 0.554250\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320913; batch adversarial loss: 0.536714\n",
      "epoch 190; iter: 0; batch classifier loss: 0.300317; batch adversarial loss: 0.555562\n",
      "epoch 191; iter: 0; batch classifier loss: 0.256953; batch adversarial loss: 0.509267\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358475; batch adversarial loss: 0.497505\n",
      "epoch 193; iter: 0; batch classifier loss: 0.312879; batch adversarial loss: 0.517721\n",
      "epoch 194; iter: 0; batch classifier loss: 0.284444; batch adversarial loss: 0.528251\n",
      "epoch 195; iter: 0; batch classifier loss: 0.303174; batch adversarial loss: 0.624363\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337463; batch adversarial loss: 0.637432\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367961; batch adversarial loss: 0.578522\n",
      "epoch 198; iter: 0; batch classifier loss: 0.315967; batch adversarial loss: 0.581173\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351143; batch adversarial loss: 0.551901\n",
      "epoch 0; iter: 0; batch classifier loss: 0.634872; batch adversarial loss: 0.620208\n",
      "epoch 1; iter: 0; batch classifier loss: 0.570456; batch adversarial loss: 0.635923\n",
      "epoch 2; iter: 0; batch classifier loss: 0.520011; batch adversarial loss: 0.644736\n",
      "epoch 3; iter: 0; batch classifier loss: 0.604345; batch adversarial loss: 0.687370\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523662; batch adversarial loss: 0.625774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.548829; batch adversarial loss: 0.636197\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605410; batch adversarial loss: 0.651947\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569413; batch adversarial loss: 0.674191\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503394; batch adversarial loss: 0.631970\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612113; batch adversarial loss: 0.582920\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522948; batch adversarial loss: 0.577134\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508401; batch adversarial loss: 0.577324\n",
      "epoch 12; iter: 0; batch classifier loss: 0.637431; batch adversarial loss: 0.584164\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526005; batch adversarial loss: 0.564108\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479706; batch adversarial loss: 0.609855\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505980; batch adversarial loss: 0.628086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550127; batch adversarial loss: 0.583405\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535378; batch adversarial loss: 0.611384\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473555; batch adversarial loss: 0.580285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508445; batch adversarial loss: 0.528837\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506923; batch adversarial loss: 0.570343\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439063; batch adversarial loss: 0.546810\n",
      "epoch 22; iter: 0; batch classifier loss: 0.553081; batch adversarial loss: 0.543821\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494505; batch adversarial loss: 0.530541\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503501; batch adversarial loss: 0.585489\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502767; batch adversarial loss: 0.603398\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484170; batch adversarial loss: 0.580614\n",
      "epoch 27; iter: 0; batch classifier loss: 0.525041; batch adversarial loss: 0.454236\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470067; batch adversarial loss: 0.514439\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476984; batch adversarial loss: 0.503766\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515591; batch adversarial loss: 0.534496\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485156; batch adversarial loss: 0.475924\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485179; batch adversarial loss: 0.537211\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518089; batch adversarial loss: 0.562948\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457596; batch adversarial loss: 0.527738\n",
      "epoch 35; iter: 0; batch classifier loss: 0.546559; batch adversarial loss: 0.562276\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461994; batch adversarial loss: 0.579373\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476791; batch adversarial loss: 0.510131\n",
      "epoch 38; iter: 0; batch classifier loss: 0.394336; batch adversarial loss: 0.632177\n",
      "epoch 39; iter: 0; batch classifier loss: 0.402204; batch adversarial loss: 0.528096\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475513; batch adversarial loss: 0.589030\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472143; batch adversarial loss: 0.596866\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478512; batch adversarial loss: 0.501636\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436458; batch adversarial loss: 0.580152\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473441; batch adversarial loss: 0.570376\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393007; batch adversarial loss: 0.509874\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430658; batch adversarial loss: 0.589793\n",
      "epoch 47; iter: 0; batch classifier loss: 0.518675; batch adversarial loss: 0.594717\n",
      "epoch 48; iter: 0; batch classifier loss: 0.488837; batch adversarial loss: 0.580311\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487379; batch adversarial loss: 0.543689\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413885; batch adversarial loss: 0.502042\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455906; batch adversarial loss: 0.588761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438139; batch adversarial loss: 0.511096\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404162; batch adversarial loss: 0.688213\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453301; batch adversarial loss: 0.509503\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401211; batch adversarial loss: 0.571875\n",
      "epoch 56; iter: 0; batch classifier loss: 0.485242; batch adversarial loss: 0.553482\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442131; batch adversarial loss: 0.589480\n",
      "epoch 58; iter: 0; batch classifier loss: 0.479114; batch adversarial loss: 0.535423\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427488; batch adversarial loss: 0.579046\n",
      "epoch 60; iter: 0; batch classifier loss: 0.495466; batch adversarial loss: 0.657201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422651; batch adversarial loss: 0.484920\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390182; batch adversarial loss: 0.570059\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449916; batch adversarial loss: 0.565146\n",
      "epoch 64; iter: 0; batch classifier loss: 0.470407; batch adversarial loss: 0.538276\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419653; batch adversarial loss: 0.588852\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441104; batch adversarial loss: 0.511988\n",
      "epoch 67; iter: 0; batch classifier loss: 0.470686; batch adversarial loss: 0.587823\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392356; batch adversarial loss: 0.555505\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422662; batch adversarial loss: 0.543822\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411399; batch adversarial loss: 0.504715\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436640; batch adversarial loss: 0.557200\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403556; batch adversarial loss: 0.528683\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447009; batch adversarial loss: 0.478462\n",
      "epoch 74; iter: 0; batch classifier loss: 0.347009; batch adversarial loss: 0.546274\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409010; batch adversarial loss: 0.561385\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420449; batch adversarial loss: 0.545071\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434460; batch adversarial loss: 0.511803\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447362; batch adversarial loss: 0.634412\n",
      "epoch 79; iter: 0; batch classifier loss: 0.427427; batch adversarial loss: 0.509216\n",
      "epoch 80; iter: 0; batch classifier loss: 0.485318; batch adversarial loss: 0.536145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421417; batch adversarial loss: 0.543585\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418680; batch adversarial loss: 0.562536\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384978; batch adversarial loss: 0.553948\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397305; batch adversarial loss: 0.570809\n",
      "epoch 85; iter: 0; batch classifier loss: 0.353959; batch adversarial loss: 0.633198\n",
      "epoch 86; iter: 0; batch classifier loss: 0.458977; batch adversarial loss: 0.535244\n",
      "epoch 87; iter: 0; batch classifier loss: 0.353578; batch adversarial loss: 0.492458\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433995; batch adversarial loss: 0.579820\n",
      "epoch 89; iter: 0; batch classifier loss: 0.488845; batch adversarial loss: 0.580929\n",
      "epoch 90; iter: 0; batch classifier loss: 0.465909; batch adversarial loss: 0.543739\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439243; batch adversarial loss: 0.613507\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410050; batch adversarial loss: 0.623190\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409593; batch adversarial loss: 0.578677\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424155; batch adversarial loss: 0.517189\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427292; batch adversarial loss: 0.536106\n",
      "epoch 96; iter: 0; batch classifier loss: 0.397475; batch adversarial loss: 0.544859\n",
      "epoch 97; iter: 0; batch classifier loss: 0.495717; batch adversarial loss: 0.562659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.433059; batch adversarial loss: 0.631461\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382037; batch adversarial loss: 0.515386\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439188; batch adversarial loss: 0.567692\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411437; batch adversarial loss: 0.540439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.452261; batch adversarial loss: 0.579063\n",
      "epoch 103; iter: 0; batch classifier loss: 0.456943; batch adversarial loss: 0.577259\n",
      "epoch 104; iter: 0; batch classifier loss: 0.312287; batch adversarial loss: 0.606812\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365481; batch adversarial loss: 0.606210\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374304; batch adversarial loss: 0.577383\n",
      "epoch 107; iter: 0; batch classifier loss: 0.512432; batch adversarial loss: 0.540867\n",
      "epoch 108; iter: 0; batch classifier loss: 0.376575; batch adversarial loss: 0.618966\n",
      "epoch 109; iter: 0; batch classifier loss: 0.339878; batch adversarial loss: 0.553901\n",
      "epoch 110; iter: 0; batch classifier loss: 0.417366; batch adversarial loss: 0.600521\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374817; batch adversarial loss: 0.631849\n",
      "epoch 112; iter: 0; batch classifier loss: 0.427337; batch adversarial loss: 0.577205\n",
      "epoch 113; iter: 0; batch classifier loss: 0.411184; batch adversarial loss: 0.536959\n",
      "epoch 114; iter: 0; batch classifier loss: 0.342197; batch adversarial loss: 0.543553\n",
      "epoch 115; iter: 0; batch classifier loss: 0.427243; batch adversarial loss: 0.496285\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361922; batch adversarial loss: 0.502456\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396694; batch adversarial loss: 0.507946\n",
      "epoch 118; iter: 0; batch classifier loss: 0.426182; batch adversarial loss: 0.545831\n",
      "epoch 119; iter: 0; batch classifier loss: 0.351217; batch adversarial loss: 0.571776\n",
      "epoch 120; iter: 0; batch classifier loss: 0.353984; batch adversarial loss: 0.500777\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392691; batch adversarial loss: 0.500527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335726; batch adversarial loss: 0.508904\n",
      "epoch 123; iter: 0; batch classifier loss: 0.454242; batch adversarial loss: 0.580939\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370953; batch adversarial loss: 0.466126\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373354; batch adversarial loss: 0.588890\n",
      "epoch 126; iter: 0; batch classifier loss: 0.511927; batch adversarial loss: 0.526629\n",
      "epoch 127; iter: 0; batch classifier loss: 0.439853; batch adversarial loss: 0.527297\n",
      "epoch 128; iter: 0; batch classifier loss: 0.425411; batch adversarial loss: 0.597292\n",
      "epoch 129; iter: 0; batch classifier loss: 0.400933; batch adversarial loss: 0.533359\n",
      "epoch 130; iter: 0; batch classifier loss: 0.473289; batch adversarial loss: 0.534526\n",
      "epoch 131; iter: 0; batch classifier loss: 0.435065; batch adversarial loss: 0.561178\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392960; batch adversarial loss: 0.561954\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412672; batch adversarial loss: 0.555069\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406999; batch adversarial loss: 0.501171\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325942; batch adversarial loss: 0.534724\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361488; batch adversarial loss: 0.577929\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359915; batch adversarial loss: 0.555790\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365802; batch adversarial loss: 0.527907\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398581; batch adversarial loss: 0.624128\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400285; batch adversarial loss: 0.518695\n",
      "epoch 141; iter: 0; batch classifier loss: 0.378348; batch adversarial loss: 0.580742\n",
      "epoch 142; iter: 0; batch classifier loss: 0.451066; batch adversarial loss: 0.511143\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342802; batch adversarial loss: 0.605348\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368279; batch adversarial loss: 0.500078\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403475; batch adversarial loss: 0.544272\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385770; batch adversarial loss: 0.594505\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340294; batch adversarial loss: 0.546927\n",
      "epoch 148; iter: 0; batch classifier loss: 0.359628; batch adversarial loss: 0.517685\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370863; batch adversarial loss: 0.569647\n",
      "epoch 150; iter: 0; batch classifier loss: 0.440372; batch adversarial loss: 0.560865\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387418; batch adversarial loss: 0.597065\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389727; batch adversarial loss: 0.498511\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363121; batch adversarial loss: 0.568349\n",
      "epoch 154; iter: 0; batch classifier loss: 0.428490; batch adversarial loss: 0.541849\n",
      "epoch 155; iter: 0; batch classifier loss: 0.441300; batch adversarial loss: 0.597321\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384530; batch adversarial loss: 0.489009\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359411; batch adversarial loss: 0.651130\n",
      "epoch 158; iter: 0; batch classifier loss: 0.443239; batch adversarial loss: 0.605998\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383269; batch adversarial loss: 0.570869\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369036; batch adversarial loss: 0.510849\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391498; batch adversarial loss: 0.538917\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368554; batch adversarial loss: 0.599688\n",
      "epoch 163; iter: 0; batch classifier loss: 0.371108; batch adversarial loss: 0.535312\n",
      "epoch 164; iter: 0; batch classifier loss: 0.309502; batch adversarial loss: 0.580665\n",
      "epoch 165; iter: 0; batch classifier loss: 0.409295; batch adversarial loss: 0.642113\n",
      "epoch 166; iter: 0; batch classifier loss: 0.427038; batch adversarial loss: 0.559424\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335029; batch adversarial loss: 0.563703\n",
      "epoch 168; iter: 0; batch classifier loss: 0.418678; batch adversarial loss: 0.510655\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330838; batch adversarial loss: 0.561278\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373998; batch adversarial loss: 0.571710\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375242; batch adversarial loss: 0.580943\n",
      "epoch 172; iter: 0; batch classifier loss: 0.386646; batch adversarial loss: 0.535541\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377015; batch adversarial loss: 0.571241\n",
      "epoch 174; iter: 0; batch classifier loss: 0.398475; batch adversarial loss: 0.546887\n",
      "epoch 175; iter: 0; batch classifier loss: 0.402648; batch adversarial loss: 0.566947\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335526; batch adversarial loss: 0.618189\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417797; batch adversarial loss: 0.580676\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331057; batch adversarial loss: 0.542994\n",
      "epoch 179; iter: 0; batch classifier loss: 0.307731; batch adversarial loss: 0.632638\n",
      "epoch 180; iter: 0; batch classifier loss: 0.380979; batch adversarial loss: 0.598119\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350096; batch adversarial loss: 0.554322\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352854; batch adversarial loss: 0.615120\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358816; batch adversarial loss: 0.534884\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381756; batch adversarial loss: 0.605445\n",
      "epoch 185; iter: 0; batch classifier loss: 0.374814; batch adversarial loss: 0.562604\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367951; batch adversarial loss: 0.552671\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385822; batch adversarial loss: 0.543940\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358316; batch adversarial loss: 0.563851\n",
      "epoch 189; iter: 0; batch classifier loss: 0.389226; batch adversarial loss: 0.616308\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386321; batch adversarial loss: 0.588297\n",
      "epoch 191; iter: 0; batch classifier loss: 0.421590; batch adversarial loss: 0.569991\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357549; batch adversarial loss: 0.525540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350738; batch adversarial loss: 0.590912\n",
      "epoch 194; iter: 0; batch classifier loss: 0.375981; batch adversarial loss: 0.616547\n",
      "epoch 195; iter: 0; batch classifier loss: 0.405375; batch adversarial loss: 0.558853\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353798; batch adversarial loss: 0.525867\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362162; batch adversarial loss: 0.553976\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328667; batch adversarial loss: 0.595136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.334248; batch adversarial loss: 0.555367\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686264; batch adversarial loss: 0.610397\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586080; batch adversarial loss: 0.648534\n",
      "epoch 2; iter: 0; batch classifier loss: 0.641551; batch adversarial loss: 0.637002\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534725; batch adversarial loss: 0.629298\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590574; batch adversarial loss: 0.583476\n",
      "epoch 5; iter: 0; batch classifier loss: 0.610669; batch adversarial loss: 0.655909\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579572; batch adversarial loss: 0.563272\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516197; batch adversarial loss: 0.616136\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536535; batch adversarial loss: 0.567801\n",
      "epoch 9; iter: 0; batch classifier loss: 0.611731; batch adversarial loss: 0.550797\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499918; batch adversarial loss: 0.593536\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527200; batch adversarial loss: 0.637251\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529054; batch adversarial loss: 0.596703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512470; batch adversarial loss: 0.568394\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560996; batch adversarial loss: 0.529593\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561075; batch adversarial loss: 0.565296\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510601; batch adversarial loss: 0.592077\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525532; batch adversarial loss: 0.509047\n",
      "epoch 18; iter: 0; batch classifier loss: 0.435099; batch adversarial loss: 0.530679\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500263; batch adversarial loss: 0.587175\n",
      "epoch 20; iter: 0; batch classifier loss: 0.445401; batch adversarial loss: 0.554383\n",
      "epoch 21; iter: 0; batch classifier loss: 0.435232; batch adversarial loss: 0.478419\n",
      "epoch 22; iter: 0; batch classifier loss: 0.424424; batch adversarial loss: 0.569879\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450471; batch adversarial loss: 0.585942\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490625; batch adversarial loss: 0.638523\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457191; batch adversarial loss: 0.541600\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475396; batch adversarial loss: 0.536521\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504188; batch adversarial loss: 0.589683\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471773; batch adversarial loss: 0.566839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438929; batch adversarial loss: 0.531827\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517483; batch adversarial loss: 0.537568\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456281; batch adversarial loss: 0.545107\n",
      "epoch 32; iter: 0; batch classifier loss: 0.515820; batch adversarial loss: 0.519809\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518418; batch adversarial loss: 0.538417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425586; batch adversarial loss: 0.564040\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422429; batch adversarial loss: 0.579362\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457397; batch adversarial loss: 0.546017\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475480; batch adversarial loss: 0.535606\n",
      "epoch 38; iter: 0; batch classifier loss: 0.495611; batch adversarial loss: 0.449327\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483346; batch adversarial loss: 0.545035\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437474; batch adversarial loss: 0.518958\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473686; batch adversarial loss: 0.544780\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475969; batch adversarial loss: 0.579972\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461146; batch adversarial loss: 0.561723\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463749; batch adversarial loss: 0.631056\n",
      "epoch 45; iter: 0; batch classifier loss: 0.386627; batch adversarial loss: 0.553101\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430869; batch adversarial loss: 0.554158\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466196; batch adversarial loss: 0.527215\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446749; batch adversarial loss: 0.580916\n",
      "epoch 49; iter: 0; batch classifier loss: 0.482827; batch adversarial loss: 0.509098\n",
      "epoch 50; iter: 0; batch classifier loss: 0.382401; batch adversarial loss: 0.526115\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413697; batch adversarial loss: 0.535065\n",
      "epoch 52; iter: 0; batch classifier loss: 0.515616; batch adversarial loss: 0.570734\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443354; batch adversarial loss: 0.535660\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435895; batch adversarial loss: 0.554142\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425837; batch adversarial loss: 0.516483\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387695; batch adversarial loss: 0.527044\n",
      "epoch 57; iter: 0; batch classifier loss: 0.433206; batch adversarial loss: 0.544717\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418558; batch adversarial loss: 0.538169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447850; batch adversarial loss: 0.590476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.419678; batch adversarial loss: 0.579543\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430687; batch adversarial loss: 0.581848\n",
      "epoch 62; iter: 0; batch classifier loss: 0.473306; batch adversarial loss: 0.544602\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429452; batch adversarial loss: 0.443139\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406174; batch adversarial loss: 0.562533\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415266; batch adversarial loss: 0.489907\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368505; batch adversarial loss: 0.598084\n",
      "epoch 67; iter: 0; batch classifier loss: 0.462683; batch adversarial loss: 0.553066\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395673; batch adversarial loss: 0.525810\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414543; batch adversarial loss: 0.569967\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391123; batch adversarial loss: 0.545843\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418662; batch adversarial loss: 0.535032\n",
      "epoch 72; iter: 0; batch classifier loss: 0.460300; batch adversarial loss: 0.544753\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445274; batch adversarial loss: 0.608138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.508908; batch adversarial loss: 0.543592\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399506; batch adversarial loss: 0.634886\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395661; batch adversarial loss: 0.571541\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391234; batch adversarial loss: 0.519560\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404404; batch adversarial loss: 0.535119\n",
      "epoch 79; iter: 0; batch classifier loss: 0.328553; batch adversarial loss: 0.606436\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370278; batch adversarial loss: 0.561787\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402444; batch adversarial loss: 0.597414\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404684; batch adversarial loss: 0.544861\n",
      "epoch 83; iter: 0; batch classifier loss: 0.465696; batch adversarial loss: 0.509123\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384947; batch adversarial loss: 0.517452\n",
      "epoch 85; iter: 0; batch classifier loss: 0.356624; batch adversarial loss: 0.571945\n",
      "epoch 86; iter: 0; batch classifier loss: 0.423561; batch adversarial loss: 0.554648\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362716; batch adversarial loss: 0.537225\n",
      "epoch 88; iter: 0; batch classifier loss: 0.337193; batch adversarial loss: 0.544789\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419086; batch adversarial loss: 0.599153\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391436; batch adversarial loss: 0.598149\n",
      "epoch 91; iter: 0; batch classifier loss: 0.355775; batch adversarial loss: 0.561097\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351938; batch adversarial loss: 0.517707\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384964; batch adversarial loss: 0.555167\n",
      "epoch 94; iter: 0; batch classifier loss: 0.494143; batch adversarial loss: 0.544924\n",
      "epoch 95; iter: 0; batch classifier loss: 0.330171; batch adversarial loss: 0.599098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.448835; batch adversarial loss: 0.500498\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362000; batch adversarial loss: 0.527265\n",
      "epoch 98; iter: 0; batch classifier loss: 0.355349; batch adversarial loss: 0.570880\n",
      "epoch 99; iter: 0; batch classifier loss: 0.465447; batch adversarial loss: 0.516606\n",
      "epoch 100; iter: 0; batch classifier loss: 0.353603; batch adversarial loss: 0.508912\n",
      "epoch 101; iter: 0; batch classifier loss: 0.404690; batch adversarial loss: 0.553560\n",
      "epoch 102; iter: 0; batch classifier loss: 0.429040; batch adversarial loss: 0.607966\n",
      "epoch 103; iter: 0; batch classifier loss: 0.425760; batch adversarial loss: 0.545114\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392594; batch adversarial loss: 0.517310\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352751; batch adversarial loss: 0.572286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405604; batch adversarial loss: 0.537382\n",
      "epoch 107; iter: 0; batch classifier loss: 0.325374; batch adversarial loss: 0.552617\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383006; batch adversarial loss: 0.553452\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408734; batch adversarial loss: 0.597579\n",
      "epoch 110; iter: 0; batch classifier loss: 0.440948; batch adversarial loss: 0.616114\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366412; batch adversarial loss: 0.562224\n",
      "epoch 112; iter: 0; batch classifier loss: 0.399783; batch adversarial loss: 0.536976\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369618; batch adversarial loss: 0.633028\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368905; batch adversarial loss: 0.545406\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336622; batch adversarial loss: 0.571676\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380229; batch adversarial loss: 0.625869\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426247; batch adversarial loss: 0.553766\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403120; batch adversarial loss: 0.490503\n",
      "epoch 119; iter: 0; batch classifier loss: 0.326348; batch adversarial loss: 0.535145\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395291; batch adversarial loss: 0.510203\n",
      "epoch 121; iter: 0; batch classifier loss: 0.441614; batch adversarial loss: 0.568406\n",
      "epoch 122; iter: 0; batch classifier loss: 0.374150; batch adversarial loss: 0.561738\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327332; batch adversarial loss: 0.543822\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404511; batch adversarial loss: 0.538689\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372369; batch adversarial loss: 0.535116\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360634; batch adversarial loss: 0.518356\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369498; batch adversarial loss: 0.536256\n",
      "epoch 128; iter: 0; batch classifier loss: 0.312471; batch adversarial loss: 0.488821\n",
      "epoch 129; iter: 0; batch classifier loss: 0.425889; batch adversarial loss: 0.536449\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413100; batch adversarial loss: 0.490227\n",
      "epoch 131; iter: 0; batch classifier loss: 0.346269; batch adversarial loss: 0.590176\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347461; batch adversarial loss: 0.644034\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388593; batch adversarial loss: 0.527083\n",
      "epoch 134; iter: 0; batch classifier loss: 0.332095; batch adversarial loss: 0.590295\n",
      "epoch 135; iter: 0; batch classifier loss: 0.410769; batch adversarial loss: 0.570362\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371897; batch adversarial loss: 0.461726\n",
      "epoch 137; iter: 0; batch classifier loss: 0.387275; batch adversarial loss: 0.581976\n",
      "epoch 138; iter: 0; batch classifier loss: 0.391019; batch adversarial loss: 0.554866\n",
      "epoch 139; iter: 0; batch classifier loss: 0.477207; batch adversarial loss: 0.546256\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340019; batch adversarial loss: 0.561961\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364067; batch adversarial loss: 0.501900\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375100; batch adversarial loss: 0.598534\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346545; batch adversarial loss: 0.516245\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437378; batch adversarial loss: 0.581522\n",
      "epoch 145; iter: 0; batch classifier loss: 0.386049; batch adversarial loss: 0.544064\n",
      "epoch 146; iter: 0; batch classifier loss: 0.429882; batch adversarial loss: 0.560658\n",
      "epoch 147; iter: 0; batch classifier loss: 0.289453; batch adversarial loss: 0.540532\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334186; batch adversarial loss: 0.545156\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319832; batch adversarial loss: 0.609441\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409514; batch adversarial loss: 0.545204\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327202; batch adversarial loss: 0.591375\n",
      "epoch 152; iter: 0; batch classifier loss: 0.443560; batch adversarial loss: 0.516406\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360879; batch adversarial loss: 0.545630\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401317; batch adversarial loss: 0.587969\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408722; batch adversarial loss: 0.554629\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399206; batch adversarial loss: 0.562460\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337239; batch adversarial loss: 0.553120\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383152; batch adversarial loss: 0.571944\n",
      "epoch 159; iter: 0; batch classifier loss: 0.299827; batch adversarial loss: 0.553129\n",
      "epoch 160; iter: 0; batch classifier loss: 0.407084; batch adversarial loss: 0.516154\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333480; batch adversarial loss: 0.490150\n",
      "epoch 162; iter: 0; batch classifier loss: 0.395133; batch adversarial loss: 0.550791\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355077; batch adversarial loss: 0.572019\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339640; batch adversarial loss: 0.564205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.456059; batch adversarial loss: 0.518595\n",
      "epoch 166; iter: 0; batch classifier loss: 0.438669; batch adversarial loss: 0.497866\n",
      "epoch 167; iter: 0; batch classifier loss: 0.316814; batch adversarial loss: 0.616011\n",
      "epoch 168; iter: 0; batch classifier loss: 0.286142; batch adversarial loss: 0.511729\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368083; batch adversarial loss: 0.571344\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404573; batch adversarial loss: 0.537579\n",
      "epoch 171; iter: 0; batch classifier loss: 0.339224; batch adversarial loss: 0.571213\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374452; batch adversarial loss: 0.544954\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315365; batch adversarial loss: 0.563394\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392332; batch adversarial loss: 0.563516\n",
      "epoch 175; iter: 0; batch classifier loss: 0.371636; batch adversarial loss: 0.561707\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362825; batch adversarial loss: 0.542439\n",
      "epoch 177; iter: 0; batch classifier loss: 0.437576; batch adversarial loss: 0.472547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.322847; batch adversarial loss: 0.587136\n",
      "epoch 179; iter: 0; batch classifier loss: 0.415823; batch adversarial loss: 0.536272\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390304; batch adversarial loss: 0.537107\n",
      "epoch 181; iter: 0; batch classifier loss: 0.404843; batch adversarial loss: 0.554511\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313158; batch adversarial loss: 0.606861\n",
      "epoch 183; iter: 0; batch classifier loss: 0.487075; batch adversarial loss: 0.517665\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370469; batch adversarial loss: 0.633343\n",
      "epoch 185; iter: 0; batch classifier loss: 0.374839; batch adversarial loss: 0.560489\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379278; batch adversarial loss: 0.499739\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424085; batch adversarial loss: 0.491087\n",
      "epoch 188; iter: 0; batch classifier loss: 0.518343; batch adversarial loss: 0.599319\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339079; batch adversarial loss: 0.534483\n",
      "epoch 190; iter: 0; batch classifier loss: 0.288525; batch adversarial loss: 0.544063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341135; batch adversarial loss: 0.554207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.334261; batch adversarial loss: 0.562508\n",
      "epoch 193; iter: 0; batch classifier loss: 0.291623; batch adversarial loss: 0.562993\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377724; batch adversarial loss: 0.481972\n",
      "epoch 195; iter: 0; batch classifier loss: 0.303920; batch adversarial loss: 0.605866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.361370; batch adversarial loss: 0.534156\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390815; batch adversarial loss: 0.591231\n",
      "epoch 198; iter: 0; batch classifier loss: 0.315117; batch adversarial loss: 0.561765\n",
      "epoch 199; iter: 0; batch classifier loss: 0.354842; batch adversarial loss: 0.499169\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729222; batch adversarial loss: 0.611318\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595620; batch adversarial loss: 0.642216\n",
      "epoch 2; iter: 0; batch classifier loss: 0.536013; batch adversarial loss: 0.671839\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630740; batch adversarial loss: 0.642221\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513602; batch adversarial loss: 0.650678\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519497; batch adversarial loss: 0.599441\n",
      "epoch 6; iter: 0; batch classifier loss: 0.505112; batch adversarial loss: 0.571478\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578163; batch adversarial loss: 0.601288\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499140; batch adversarial loss: 0.560031\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573361; batch adversarial loss: 0.664712\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514096; batch adversarial loss: 0.562661\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544880; batch adversarial loss: 0.594130\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549739; batch adversarial loss: 0.580854\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559646; batch adversarial loss: 0.575315\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522981; batch adversarial loss: 0.575258\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562377; batch adversarial loss: 0.582806\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489944; batch adversarial loss: 0.629072\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495393; batch adversarial loss: 0.555997\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487807; batch adversarial loss: 0.537035\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499393; batch adversarial loss: 0.511357\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440331; batch adversarial loss: 0.523560\n",
      "epoch 21; iter: 0; batch classifier loss: 0.548368; batch adversarial loss: 0.564693\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496134; batch adversarial loss: 0.549622\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487314; batch adversarial loss: 0.540499\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516949; batch adversarial loss: 0.580548\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458092; batch adversarial loss: 0.571184\n",
      "epoch 26; iter: 0; batch classifier loss: 0.437467; batch adversarial loss: 0.536966\n",
      "epoch 27; iter: 0; batch classifier loss: 0.514637; batch adversarial loss: 0.486431\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473744; batch adversarial loss: 0.528523\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441313; batch adversarial loss: 0.501760\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464982; batch adversarial loss: 0.588372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517729; batch adversarial loss: 0.535747\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448948; batch adversarial loss: 0.587163\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467627; batch adversarial loss: 0.483991\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417729; batch adversarial loss: 0.489088\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459968; batch adversarial loss: 0.612422\n",
      "epoch 36; iter: 0; batch classifier loss: 0.412899; batch adversarial loss: 0.492072\n",
      "epoch 37; iter: 0; batch classifier loss: 0.484580; batch adversarial loss: 0.588289\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425577; batch adversarial loss: 0.523237\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453488; batch adversarial loss: 0.463419\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396138; batch adversarial loss: 0.487767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.530692; batch adversarial loss: 0.486822\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398008; batch adversarial loss: 0.533111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456641; batch adversarial loss: 0.536251\n",
      "epoch 44; iter: 0; batch classifier loss: 0.486902; batch adversarial loss: 0.542493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397360; batch adversarial loss: 0.472368\n",
      "epoch 46; iter: 0; batch classifier loss: 0.526043; batch adversarial loss: 0.638077\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443170; batch adversarial loss: 0.600839\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442608; batch adversarial loss: 0.553441\n",
      "epoch 49; iter: 0; batch classifier loss: 0.509302; batch adversarial loss: 0.583081\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445686; batch adversarial loss: 0.514817\n",
      "epoch 51; iter: 0; batch classifier loss: 0.475146; batch adversarial loss: 0.498938\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430676; batch adversarial loss: 0.514048\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422613; batch adversarial loss: 0.560054\n",
      "epoch 54; iter: 0; batch classifier loss: 0.512020; batch adversarial loss: 0.592838\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419229; batch adversarial loss: 0.477416\n",
      "epoch 56; iter: 0; batch classifier loss: 0.566751; batch adversarial loss: 0.565334\n",
      "epoch 57; iter: 0; batch classifier loss: 0.482042; batch adversarial loss: 0.542853\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451270; batch adversarial loss: 0.506013\n",
      "epoch 59; iter: 0; batch classifier loss: 0.512267; batch adversarial loss: 0.486627\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390487; batch adversarial loss: 0.580457\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390602; batch adversarial loss: 0.529839\n",
      "epoch 62; iter: 0; batch classifier loss: 0.481014; batch adversarial loss: 0.512564\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473208; batch adversarial loss: 0.505776\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404646; batch adversarial loss: 0.537401\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450230; batch adversarial loss: 0.543032\n",
      "epoch 66; iter: 0; batch classifier loss: 0.496652; batch adversarial loss: 0.563167\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405355; batch adversarial loss: 0.440142\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407655; batch adversarial loss: 0.590093\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403740; batch adversarial loss: 0.581809\n",
      "epoch 70; iter: 0; batch classifier loss: 0.481548; batch adversarial loss: 0.495725\n",
      "epoch 71; iter: 0; batch classifier loss: 0.434486; batch adversarial loss: 0.507072\n",
      "epoch 72; iter: 0; batch classifier loss: 0.474203; batch adversarial loss: 0.489044\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418925; batch adversarial loss: 0.582322\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438815; batch adversarial loss: 0.529151\n",
      "epoch 75; iter: 0; batch classifier loss: 0.465608; batch adversarial loss: 0.496602\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377949; batch adversarial loss: 0.524051\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458748; batch adversarial loss: 0.515614\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421504; batch adversarial loss: 0.534509\n",
      "epoch 79; iter: 0; batch classifier loss: 0.479463; batch adversarial loss: 0.524802\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470687; batch adversarial loss: 0.554165\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403252; batch adversarial loss: 0.617934\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390634; batch adversarial loss: 0.545025\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396126; batch adversarial loss: 0.574714\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397665; batch adversarial loss: 0.534523\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363984; batch adversarial loss: 0.525116\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416443; batch adversarial loss: 0.527974\n",
      "epoch 87; iter: 0; batch classifier loss: 0.458071; batch adversarial loss: 0.583534\n",
      "epoch 88; iter: 0; batch classifier loss: 0.468188; batch adversarial loss: 0.523203\n",
      "epoch 89; iter: 0; batch classifier loss: 0.434679; batch adversarial loss: 0.526300\n",
      "epoch 90; iter: 0; batch classifier loss: 0.442668; batch adversarial loss: 0.517286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.427825; batch adversarial loss: 0.553835\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382906; batch adversarial loss: 0.571995\n",
      "epoch 93; iter: 0; batch classifier loss: 0.408426; batch adversarial loss: 0.545933\n",
      "epoch 94; iter: 0; batch classifier loss: 0.462754; batch adversarial loss: 0.544869\n",
      "epoch 95; iter: 0; batch classifier loss: 0.346942; batch adversarial loss: 0.486969\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381501; batch adversarial loss: 0.553651\n",
      "epoch 97; iter: 0; batch classifier loss: 0.445543; batch adversarial loss: 0.608034\n",
      "epoch 98; iter: 0; batch classifier loss: 0.460537; batch adversarial loss: 0.525163\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312972; batch adversarial loss: 0.564631\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376818; batch adversarial loss: 0.635483\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347097; batch adversarial loss: 0.597908\n",
      "epoch 102; iter: 0; batch classifier loss: 0.448089; batch adversarial loss: 0.562048\n",
      "epoch 103; iter: 0; batch classifier loss: 0.387819; batch adversarial loss: 0.500627\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358020; batch adversarial loss: 0.546157\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411998; batch adversarial loss: 0.564353\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412571; batch adversarial loss: 0.553092\n",
      "epoch 107; iter: 0; batch classifier loss: 0.349307; batch adversarial loss: 0.553741\n",
      "epoch 108; iter: 0; batch classifier loss: 0.441260; batch adversarial loss: 0.556715\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381176; batch adversarial loss: 0.587377\n",
      "epoch 110; iter: 0; batch classifier loss: 0.374165; batch adversarial loss: 0.555399\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344597; batch adversarial loss: 0.498721\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394787; batch adversarial loss: 0.583920\n",
      "epoch 113; iter: 0; batch classifier loss: 0.404978; batch adversarial loss: 0.509234\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345401; batch adversarial loss: 0.563559\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398100; batch adversarial loss: 0.545982\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376269; batch adversarial loss: 0.469707\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390842; batch adversarial loss: 0.479092\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453060; batch adversarial loss: 0.550217\n",
      "epoch 119; iter: 0; batch classifier loss: 0.442779; batch adversarial loss: 0.466995\n",
      "epoch 120; iter: 0; batch classifier loss: 0.324152; batch adversarial loss: 0.571772\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395750; batch adversarial loss: 0.562142\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384133; batch adversarial loss: 0.515451\n",
      "epoch 123; iter: 0; batch classifier loss: 0.473163; batch adversarial loss: 0.572235\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378785; batch adversarial loss: 0.610639\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350539; batch adversarial loss: 0.443291\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399629; batch adversarial loss: 0.516041\n",
      "epoch 127; iter: 0; batch classifier loss: 0.427868; batch adversarial loss: 0.591264\n",
      "epoch 128; iter: 0; batch classifier loss: 0.421164; batch adversarial loss: 0.562801\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386927; batch adversarial loss: 0.545877\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377276; batch adversarial loss: 0.533920\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400254; batch adversarial loss: 0.545866\n",
      "epoch 132; iter: 0; batch classifier loss: 0.443909; batch adversarial loss: 0.543566\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302698; batch adversarial loss: 0.534018\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391195; batch adversarial loss: 0.510033\n",
      "epoch 135; iter: 0; batch classifier loss: 0.304236; batch adversarial loss: 0.554479\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337473; batch adversarial loss: 0.532674\n",
      "epoch 137; iter: 0; batch classifier loss: 0.422191; batch adversarial loss: 0.525406\n",
      "epoch 138; iter: 0; batch classifier loss: 0.390317; batch adversarial loss: 0.567262\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403650; batch adversarial loss: 0.508675\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403435; batch adversarial loss: 0.537350\n",
      "epoch 141; iter: 0; batch classifier loss: 0.447380; batch adversarial loss: 0.536689\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398877; batch adversarial loss: 0.542750\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397188; batch adversarial loss: 0.557203\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405781; batch adversarial loss: 0.583421\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405399; batch adversarial loss: 0.551451\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348537; batch adversarial loss: 0.523640\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384921; batch adversarial loss: 0.487856\n",
      "epoch 148; iter: 0; batch classifier loss: 0.430809; batch adversarial loss: 0.583364\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368156; batch adversarial loss: 0.608416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.386509; batch adversarial loss: 0.505775\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325531; batch adversarial loss: 0.565180\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357974; batch adversarial loss: 0.562545\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393268; batch adversarial loss: 0.532823\n",
      "epoch 154; iter: 0; batch classifier loss: 0.392205; batch adversarial loss: 0.514728\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354083; batch adversarial loss: 0.572499\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413643; batch adversarial loss: 0.637220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318381; batch adversarial loss: 0.499914\n",
      "epoch 158; iter: 0; batch classifier loss: 0.271425; batch adversarial loss: 0.532030\n",
      "epoch 159; iter: 0; batch classifier loss: 0.410578; batch adversarial loss: 0.537984\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365240; batch adversarial loss: 0.525977\n",
      "epoch 161; iter: 0; batch classifier loss: 0.405532; batch adversarial loss: 0.586251\n",
      "epoch 162; iter: 0; batch classifier loss: 0.300551; batch adversarial loss: 0.477658\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397810; batch adversarial loss: 0.507771\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341182; batch adversarial loss: 0.544368\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334773; batch adversarial loss: 0.597826\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387833; batch adversarial loss: 0.556347\n",
      "epoch 167; iter: 0; batch classifier loss: 0.454736; batch adversarial loss: 0.485463\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356266; batch adversarial loss: 0.608024\n",
      "epoch 169; iter: 0; batch classifier loss: 0.323475; batch adversarial loss: 0.542904\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379822; batch adversarial loss: 0.552634\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386169; batch adversarial loss: 0.456777\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379107; batch adversarial loss: 0.635432\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387716; batch adversarial loss: 0.580570\n",
      "epoch 174; iter: 0; batch classifier loss: 0.436702; batch adversarial loss: 0.515130\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325106; batch adversarial loss: 0.527031\n",
      "epoch 176; iter: 0; batch classifier loss: 0.406942; batch adversarial loss: 0.546278\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399097; batch adversarial loss: 0.569796\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347750; batch adversarial loss: 0.573118\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351567; batch adversarial loss: 0.573270\n",
      "epoch 180; iter: 0; batch classifier loss: 0.492384; batch adversarial loss: 0.569630\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397327; batch adversarial loss: 0.524964\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367274; batch adversarial loss: 0.514811\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375977; batch adversarial loss: 0.554918\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346337; batch adversarial loss: 0.515965\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367672; batch adversarial loss: 0.599599\n",
      "epoch 186; iter: 0; batch classifier loss: 0.301326; batch adversarial loss: 0.479910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187; iter: 0; batch classifier loss: 0.294415; batch adversarial loss: 0.534881\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375923; batch adversarial loss: 0.518556\n",
      "epoch 189; iter: 0; batch classifier loss: 0.294446; batch adversarial loss: 0.487725\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323493; batch adversarial loss: 0.523856\n",
      "epoch 191; iter: 0; batch classifier loss: 0.409407; batch adversarial loss: 0.533592\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397505; batch adversarial loss: 0.507834\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332566; batch adversarial loss: 0.553617\n",
      "epoch 194; iter: 0; batch classifier loss: 0.367144; batch adversarial loss: 0.424380\n",
      "epoch 195; iter: 0; batch classifier loss: 0.316160; batch adversarial loss: 0.598723\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392590; batch adversarial loss: 0.518516\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345608; batch adversarial loss: 0.513834\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339882; batch adversarial loss: 0.627827\n",
      "epoch 199; iter: 0; batch classifier loss: 0.392466; batch adversarial loss: 0.597746\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677402; batch adversarial loss: 0.855328\n",
      "epoch 1; iter: 0; batch classifier loss: 0.892522; batch adversarial loss: 1.034154\n",
      "epoch 2; iter: 0; batch classifier loss: 0.826981; batch adversarial loss: 1.020323\n",
      "epoch 3; iter: 0; batch classifier loss: 1.048852; batch adversarial loss: 0.946078\n",
      "epoch 4; iter: 0; batch classifier loss: 1.121336; batch adversarial loss: 0.856229\n",
      "epoch 5; iter: 0; batch classifier loss: 1.120214; batch adversarial loss: 0.789213\n",
      "epoch 6; iter: 0; batch classifier loss: 1.109211; batch adversarial loss: 0.735095\n",
      "epoch 7; iter: 0; batch classifier loss: 1.006340; batch adversarial loss: 0.685049\n",
      "epoch 8; iter: 0; batch classifier loss: 0.950284; batch adversarial loss: 0.638574\n",
      "epoch 9; iter: 0; batch classifier loss: 0.810277; batch adversarial loss: 0.602640\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610823; batch adversarial loss: 0.628000\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525160; batch adversarial loss: 0.589888\n",
      "epoch 12; iter: 0; batch classifier loss: 0.568139; batch adversarial loss: 0.550890\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524409; batch adversarial loss: 0.576217\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558996; batch adversarial loss: 0.625224\n",
      "epoch 15; iter: 0; batch classifier loss: 0.641332; batch adversarial loss: 0.582869\n",
      "epoch 16; iter: 0; batch classifier loss: 0.588015; batch adversarial loss: 0.516513\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510651; batch adversarial loss: 0.547195\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461606; batch adversarial loss: 0.555325\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508556; batch adversarial loss: 0.567894\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476733; batch adversarial loss: 0.552221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492392; batch adversarial loss: 0.595061\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500358; batch adversarial loss: 0.550961\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499733; batch adversarial loss: 0.475480\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422077; batch adversarial loss: 0.564273\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488166; batch adversarial loss: 0.566276\n",
      "epoch 26; iter: 0; batch classifier loss: 0.575192; batch adversarial loss: 0.578551\n",
      "epoch 27; iter: 0; batch classifier loss: 0.534811; batch adversarial loss: 0.524106\n",
      "epoch 28; iter: 0; batch classifier loss: 0.579900; batch adversarial loss: 0.539902\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451129; batch adversarial loss: 0.572792\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449660; batch adversarial loss: 0.575046\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435304; batch adversarial loss: 0.500305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469694; batch adversarial loss: 0.540504\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437764; batch adversarial loss: 0.548494\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470962; batch adversarial loss: 0.617293\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470179; batch adversarial loss: 0.537934\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483162; batch adversarial loss: 0.511471\n",
      "epoch 37; iter: 0; batch classifier loss: 0.526426; batch adversarial loss: 0.556161\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472600; batch adversarial loss: 0.552335\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417796; batch adversarial loss: 0.615813\n",
      "epoch 40; iter: 0; batch classifier loss: 0.537548; batch adversarial loss: 0.563250\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396273; batch adversarial loss: 0.526749\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436145; batch adversarial loss: 0.528115\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428566; batch adversarial loss: 0.519363\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455185; batch adversarial loss: 0.545033\n",
      "epoch 45; iter: 0; batch classifier loss: 0.510711; batch adversarial loss: 0.491208\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431846; batch adversarial loss: 0.580183\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441767; batch adversarial loss: 0.508803\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449563; batch adversarial loss: 0.588255\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418846; batch adversarial loss: 0.562642\n",
      "epoch 50; iter: 0; batch classifier loss: 0.436209; batch adversarial loss: 0.517118\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463999; batch adversarial loss: 0.571379\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419103; batch adversarial loss: 0.525709\n",
      "epoch 53; iter: 0; batch classifier loss: 0.407303; batch adversarial loss: 0.460960\n",
      "epoch 54; iter: 0; batch classifier loss: 0.390298; batch adversarial loss: 0.479983\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389865; batch adversarial loss: 0.579759\n",
      "epoch 56; iter: 0; batch classifier loss: 0.477283; batch adversarial loss: 0.526618\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397526; batch adversarial loss: 0.489250\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380966; batch adversarial loss: 0.533718\n",
      "epoch 59; iter: 0; batch classifier loss: 0.397311; batch adversarial loss: 0.556003\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411157; batch adversarial loss: 0.598672\n",
      "epoch 61; iter: 0; batch classifier loss: 0.471107; batch adversarial loss: 0.573412\n",
      "epoch 62; iter: 0; batch classifier loss: 0.373628; batch adversarial loss: 0.537094\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413206; batch adversarial loss: 0.505628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.453086; batch adversarial loss: 0.533729\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423802; batch adversarial loss: 0.537182\n",
      "epoch 66; iter: 0; batch classifier loss: 0.393225; batch adversarial loss: 0.543465\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416165; batch adversarial loss: 0.505535\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415382; batch adversarial loss: 0.566400\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435089; batch adversarial loss: 0.547482\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359034; batch adversarial loss: 0.546651\n",
      "epoch 71; iter: 0; batch classifier loss: 0.445084; batch adversarial loss: 0.554422\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377298; batch adversarial loss: 0.657445\n",
      "epoch 73; iter: 0; batch classifier loss: 0.342307; batch adversarial loss: 0.519170\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383411; batch adversarial loss: 0.524823\n",
      "epoch 75; iter: 0; batch classifier loss: 0.451077; batch adversarial loss: 0.532316\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384807; batch adversarial loss: 0.513893\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407848; batch adversarial loss: 0.541827\n",
      "epoch 78; iter: 0; batch classifier loss: 0.433323; batch adversarial loss: 0.565760\n",
      "epoch 79; iter: 0; batch classifier loss: 0.533681; batch adversarial loss: 0.546409\n",
      "epoch 80; iter: 0; batch classifier loss: 0.354572; batch adversarial loss: 0.531756\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402792; batch adversarial loss: 0.497367\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366972; batch adversarial loss: 0.579781\n",
      "epoch 83; iter: 0; batch classifier loss: 0.480312; batch adversarial loss: 0.535716\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354269; batch adversarial loss: 0.599715\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410693; batch adversarial loss: 0.486433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.396211; batch adversarial loss: 0.552575\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382566; batch adversarial loss: 0.591515\n",
      "epoch 88; iter: 0; batch classifier loss: 0.346463; batch adversarial loss: 0.627494\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366703; batch adversarial loss: 0.497826\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366216; batch adversarial loss: 0.618000\n",
      "epoch 91; iter: 0; batch classifier loss: 0.313068; batch adversarial loss: 0.439992\n",
      "epoch 92; iter: 0; batch classifier loss: 0.451965; batch adversarial loss: 0.513054\n",
      "epoch 93; iter: 0; batch classifier loss: 0.444799; batch adversarial loss: 0.481839\n",
      "epoch 94; iter: 0; batch classifier loss: 0.314468; batch adversarial loss: 0.573933\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359125; batch adversarial loss: 0.565268\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391461; batch adversarial loss: 0.535421\n",
      "epoch 97; iter: 0; batch classifier loss: 0.342483; batch adversarial loss: 0.538986\n",
      "epoch 98; iter: 0; batch classifier loss: 0.338120; batch adversarial loss: 0.576530\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350014; batch adversarial loss: 0.535059\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351753; batch adversarial loss: 0.643227\n",
      "epoch 101; iter: 0; batch classifier loss: 0.311705; batch adversarial loss: 0.476219\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435721; batch adversarial loss: 0.546329\n",
      "epoch 103; iter: 0; batch classifier loss: 0.318034; batch adversarial loss: 0.704931\n",
      "epoch 104; iter: 0; batch classifier loss: 0.347079; batch adversarial loss: 0.638714\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348433; batch adversarial loss: 0.600045\n",
      "epoch 106; iter: 0; batch classifier loss: 0.449187; batch adversarial loss: 0.587507\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350247; batch adversarial loss: 0.525573\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409976; batch adversarial loss: 0.600314\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357361; batch adversarial loss: 0.517413\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400385; batch adversarial loss: 0.543293\n",
      "epoch 111; iter: 0; batch classifier loss: 0.289350; batch adversarial loss: 0.510266\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330788; batch adversarial loss: 0.593012\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328548; batch adversarial loss: 0.514689\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346008; batch adversarial loss: 0.589462\n",
      "epoch 115; iter: 0; batch classifier loss: 0.287940; batch adversarial loss: 0.594108\n",
      "epoch 116; iter: 0; batch classifier loss: 0.326144; batch adversarial loss: 0.601102\n",
      "epoch 117; iter: 0; batch classifier loss: 0.318615; batch adversarial loss: 0.555841\n",
      "epoch 118; iter: 0; batch classifier loss: 0.388391; batch adversarial loss: 0.563094\n",
      "epoch 119; iter: 0; batch classifier loss: 0.358294; batch adversarial loss: 0.594335\n",
      "epoch 120; iter: 0; batch classifier loss: 0.403036; batch adversarial loss: 0.443237\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314029; batch adversarial loss: 0.515587\n",
      "epoch 122; iter: 0; batch classifier loss: 0.309225; batch adversarial loss: 0.542173\n",
      "epoch 123; iter: 0; batch classifier loss: 0.338737; batch adversarial loss: 0.508162\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405392; batch adversarial loss: 0.574757\n",
      "epoch 125; iter: 0; batch classifier loss: 0.451416; batch adversarial loss: 0.552254\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402970; batch adversarial loss: 0.572617\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355443; batch adversarial loss: 0.553172\n",
      "epoch 128; iter: 0; batch classifier loss: 0.333431; batch adversarial loss: 0.562023\n",
      "epoch 129; iter: 0; batch classifier loss: 0.320147; batch adversarial loss: 0.620886\n",
      "epoch 130; iter: 0; batch classifier loss: 0.338183; batch adversarial loss: 0.521708\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344239; batch adversarial loss: 0.473797\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313989; batch adversarial loss: 0.582412\n",
      "epoch 133; iter: 0; batch classifier loss: 0.267590; batch adversarial loss: 0.547372\n",
      "epoch 134; iter: 0; batch classifier loss: 0.479512; batch adversarial loss: 0.512845\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340876; batch adversarial loss: 0.505483\n",
      "epoch 136; iter: 0; batch classifier loss: 0.286336; batch adversarial loss: 0.546608\n",
      "epoch 137; iter: 0; batch classifier loss: 0.314241; batch adversarial loss: 0.643377\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360428; batch adversarial loss: 0.475602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.309026; batch adversarial loss: 0.586232\n",
      "epoch 140; iter: 0; batch classifier loss: 0.277380; batch adversarial loss: 0.531743\n",
      "epoch 141; iter: 0; batch classifier loss: 0.354846; batch adversarial loss: 0.497497\n",
      "epoch 142; iter: 0; batch classifier loss: 0.450869; batch adversarial loss: 0.522588\n",
      "epoch 143; iter: 0; batch classifier loss: 0.333101; batch adversarial loss: 0.502969\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370009; batch adversarial loss: 0.592245\n",
      "epoch 145; iter: 0; batch classifier loss: 0.275192; batch adversarial loss: 0.511956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343963; batch adversarial loss: 0.500041\n",
      "epoch 147; iter: 0; batch classifier loss: 0.285047; batch adversarial loss: 0.561105\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358750; batch adversarial loss: 0.615141\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371762; batch adversarial loss: 0.552413\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339177; batch adversarial loss: 0.533202\n",
      "epoch 151; iter: 0; batch classifier loss: 0.461073; batch adversarial loss: 0.542304\n",
      "epoch 152; iter: 0; batch classifier loss: 0.321328; batch adversarial loss: 0.562131\n",
      "epoch 153; iter: 0; batch classifier loss: 0.323386; batch adversarial loss: 0.561500\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377637; batch adversarial loss: 0.506970\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351521; batch adversarial loss: 0.595972\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330335; batch adversarial loss: 0.478017\n",
      "epoch 157; iter: 0; batch classifier loss: 0.306499; batch adversarial loss: 0.538505\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315969; batch adversarial loss: 0.597936\n",
      "epoch 159; iter: 0; batch classifier loss: 0.253459; batch adversarial loss: 0.488269\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339758; batch adversarial loss: 0.567685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319670; batch adversarial loss: 0.461032\n",
      "epoch 162; iter: 0; batch classifier loss: 0.354798; batch adversarial loss: 0.572926\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333422; batch adversarial loss: 0.548326\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342022; batch adversarial loss: 0.550806\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359121; batch adversarial loss: 0.515650\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341984; batch adversarial loss: 0.589854\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321430; batch adversarial loss: 0.600226\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313171; batch adversarial loss: 0.499167\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314954; batch adversarial loss: 0.536081\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366396; batch adversarial loss: 0.570748\n",
      "epoch 171; iter: 0; batch classifier loss: 0.290617; batch adversarial loss: 0.521777\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343707; batch adversarial loss: 0.543228\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378655; batch adversarial loss: 0.516323\n",
      "epoch 174; iter: 0; batch classifier loss: 0.285930; batch adversarial loss: 0.617608\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345373; batch adversarial loss: 0.578315\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370599; batch adversarial loss: 0.512458\n",
      "epoch 177; iter: 0; batch classifier loss: 0.270993; batch adversarial loss: 0.563095\n",
      "epoch 178; iter: 0; batch classifier loss: 0.298347; batch adversarial loss: 0.564862\n",
      "epoch 179; iter: 0; batch classifier loss: 0.275627; batch adversarial loss: 0.551005\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312815; batch adversarial loss: 0.574452\n",
      "epoch 181; iter: 0; batch classifier loss: 0.286118; batch adversarial loss: 0.541267\n",
      "epoch 182; iter: 0; batch classifier loss: 0.319156; batch adversarial loss: 0.497912\n",
      "epoch 183; iter: 0; batch classifier loss: 0.297947; batch adversarial loss: 0.563416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.332131; batch adversarial loss: 0.545104\n",
      "epoch 185; iter: 0; batch classifier loss: 0.287991; batch adversarial loss: 0.557781\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351967; batch adversarial loss: 0.526144\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375217; batch adversarial loss: 0.477951\n",
      "epoch 188; iter: 0; batch classifier loss: 0.399648; batch adversarial loss: 0.590332\n",
      "epoch 189; iter: 0; batch classifier loss: 0.273530; batch adversarial loss: 0.536161\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354782; batch adversarial loss: 0.514223\n",
      "epoch 191; iter: 0; batch classifier loss: 0.273376; batch adversarial loss: 0.458019\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403398; batch adversarial loss: 0.510350\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361633; batch adversarial loss: 0.553336\n",
      "epoch 194; iter: 0; batch classifier loss: 0.202863; batch adversarial loss: 0.516844\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370152; batch adversarial loss: 0.585951\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306178; batch adversarial loss: 0.491846\n",
      "epoch 197; iter: 0; batch classifier loss: 0.295621; batch adversarial loss: 0.574999\n",
      "epoch 198; iter: 0; batch classifier loss: 0.280168; batch adversarial loss: 0.629814\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333225; batch adversarial loss: 0.541324\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680236; batch adversarial loss: 0.704441\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567961; batch adversarial loss: 0.671548\n",
      "epoch 2; iter: 0; batch classifier loss: 0.638200; batch adversarial loss: 0.652208\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614940; batch adversarial loss: 0.627861\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552185; batch adversarial loss: 0.625091\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531713; batch adversarial loss: 0.602462\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529998; batch adversarial loss: 0.620489\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561703; batch adversarial loss: 0.583180\n",
      "epoch 8; iter: 0; batch classifier loss: 0.502044; batch adversarial loss: 0.651211\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547947; batch adversarial loss: 0.596123\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557715; batch adversarial loss: 0.559295\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517452; batch adversarial loss: 0.603125\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527185; batch adversarial loss: 0.557738\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524167; batch adversarial loss: 0.571659\n",
      "epoch 14; iter: 0; batch classifier loss: 0.585181; batch adversarial loss: 0.626107\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525467; batch adversarial loss: 0.588979\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539271; batch adversarial loss: 0.559311\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529475; batch adversarial loss: 0.549586\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521683; batch adversarial loss: 0.570818\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543015; batch adversarial loss: 0.508683\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520989; batch adversarial loss: 0.538172\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517520; batch adversarial loss: 0.560233\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454067; batch adversarial loss: 0.530502\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436051; batch adversarial loss: 0.512424\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515737; batch adversarial loss: 0.581768\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451483; batch adversarial loss: 0.546671\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483499; batch adversarial loss: 0.618042\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458105; batch adversarial loss: 0.553227\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431657; batch adversarial loss: 0.503061\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465341; batch adversarial loss: 0.589022\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457500; batch adversarial loss: 0.496043\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443091; batch adversarial loss: 0.544486\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481788; batch adversarial loss: 0.641884\n",
      "epoch 33; iter: 0; batch classifier loss: 0.506229; batch adversarial loss: 0.650983\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422533; batch adversarial loss: 0.484237\n",
      "epoch 35; iter: 0; batch classifier loss: 0.517945; batch adversarial loss: 0.590780\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474572; batch adversarial loss: 0.517882\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503617; batch adversarial loss: 0.553318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473008; batch adversarial loss: 0.526845\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481694; batch adversarial loss: 0.553195\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447669; batch adversarial loss: 0.526173\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443428; batch adversarial loss: 0.481377\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463075; batch adversarial loss: 0.508078\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456546; batch adversarial loss: 0.526722\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476455; batch adversarial loss: 0.562173\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414271; batch adversarial loss: 0.471454\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485173; batch adversarial loss: 0.544951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442163; batch adversarial loss: 0.534548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439767; batch adversarial loss: 0.535852\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429370; batch adversarial loss: 0.535104\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453716; batch adversarial loss: 0.516769\n",
      "epoch 51; iter: 0; batch classifier loss: 0.377754; batch adversarial loss: 0.498966\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467157; batch adversarial loss: 0.581384\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431667; batch adversarial loss: 0.535713\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448118; batch adversarial loss: 0.460296\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407276; batch adversarial loss: 0.601105\n",
      "epoch 56; iter: 0; batch classifier loss: 0.381238; batch adversarial loss: 0.535155\n",
      "epoch 57; iter: 0; batch classifier loss: 0.503961; batch adversarial loss: 0.589586\n",
      "epoch 58; iter: 0; batch classifier loss: 0.492761; batch adversarial loss: 0.460663\n",
      "epoch 59; iter: 0; batch classifier loss: 0.502141; batch adversarial loss: 0.580816\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393664; batch adversarial loss: 0.561613\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449647; batch adversarial loss: 0.590983\n",
      "epoch 62; iter: 0; batch classifier loss: 0.493638; batch adversarial loss: 0.534153\n",
      "epoch 63; iter: 0; batch classifier loss: 0.490906; batch adversarial loss: 0.599075\n",
      "epoch 64; iter: 0; batch classifier loss: 0.504640; batch adversarial loss: 0.556138\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410435; batch adversarial loss: 0.516568\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412943; batch adversarial loss: 0.610144\n",
      "epoch 67; iter: 0; batch classifier loss: 0.467105; batch adversarial loss: 0.507094\n",
      "epoch 68; iter: 0; batch classifier loss: 0.463197; batch adversarial loss: 0.499513\n",
      "epoch 69; iter: 0; batch classifier loss: 0.421912; batch adversarial loss: 0.532283\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388007; batch adversarial loss: 0.591874\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407121; batch adversarial loss: 0.591069\n",
      "epoch 72; iter: 0; batch classifier loss: 0.431764; batch adversarial loss: 0.533183\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418945; batch adversarial loss: 0.606922\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423668; batch adversarial loss: 0.480826\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404112; batch adversarial loss: 0.563074\n",
      "epoch 76; iter: 0; batch classifier loss: 0.478920; batch adversarial loss: 0.518374\n",
      "epoch 77; iter: 0; batch classifier loss: 0.475867; batch adversarial loss: 0.479668\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392416; batch adversarial loss: 0.517338\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429446; batch adversarial loss: 0.608864\n",
      "epoch 80; iter: 0; batch classifier loss: 0.415631; batch adversarial loss: 0.472666\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403077; batch adversarial loss: 0.591164\n",
      "epoch 82; iter: 0; batch classifier loss: 0.340141; batch adversarial loss: 0.553027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.386871; batch adversarial loss: 0.553028\n",
      "epoch 84; iter: 0; batch classifier loss: 0.467351; batch adversarial loss: 0.554225\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424733; batch adversarial loss: 0.459228\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384213; batch adversarial loss: 0.591120\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385695; batch adversarial loss: 0.514188\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415415; batch adversarial loss: 0.506450\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367098; batch adversarial loss: 0.595357\n",
      "epoch 90; iter: 0; batch classifier loss: 0.423043; batch adversarial loss: 0.596537\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408573; batch adversarial loss: 0.619459\n",
      "epoch 92; iter: 0; batch classifier loss: 0.333176; batch adversarial loss: 0.620014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.513868; batch adversarial loss: 0.530918\n",
      "epoch 94; iter: 0; batch classifier loss: 0.590427; batch adversarial loss: 0.602054\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398961; batch adversarial loss: 0.512879\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423427; batch adversarial loss: 0.605279\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395284; batch adversarial loss: 0.518405\n",
      "epoch 98; iter: 0; batch classifier loss: 0.513121; batch adversarial loss: 0.636452\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416596; batch adversarial loss: 0.530399\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372631; batch adversarial loss: 0.572918\n",
      "epoch 101; iter: 0; batch classifier loss: 0.431305; batch adversarial loss: 0.658771\n",
      "epoch 102; iter: 0; batch classifier loss: 0.436420; batch adversarial loss: 0.534635\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364905; batch adversarial loss: 0.508978\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367859; batch adversarial loss: 0.498630\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404677; batch adversarial loss: 0.526951\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343573; batch adversarial loss: 0.618878\n",
      "epoch 107; iter: 0; batch classifier loss: 0.424744; batch adversarial loss: 0.571003\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420474; batch adversarial loss: 0.591847\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421733; batch adversarial loss: 0.551213\n",
      "epoch 110; iter: 0; batch classifier loss: 0.456947; batch adversarial loss: 0.588907\n",
      "epoch 111; iter: 0; batch classifier loss: 0.439707; batch adversarial loss: 0.527464\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351825; batch adversarial loss: 0.555816\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378218; batch adversarial loss: 0.569512\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422404; batch adversarial loss: 0.506441\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370362; batch adversarial loss: 0.583758\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422104; batch adversarial loss: 0.451655\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400906; batch adversarial loss: 0.599972\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402012; batch adversarial loss: 0.560704\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417902; batch adversarial loss: 0.514469\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351774; batch adversarial loss: 0.574131\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404975; batch adversarial loss: 0.548018\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371966; batch adversarial loss: 0.561899\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409244; batch adversarial loss: 0.641299\n",
      "epoch 124; iter: 0; batch classifier loss: 0.462088; batch adversarial loss: 0.475616\n",
      "epoch 125; iter: 0; batch classifier loss: 0.431621; batch adversarial loss: 0.523576\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387972; batch adversarial loss: 0.552711\n",
      "epoch 127; iter: 0; batch classifier loss: 0.458232; batch adversarial loss: 0.618686\n",
      "epoch 128; iter: 0; batch classifier loss: 0.430222; batch adversarial loss: 0.517257\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374922; batch adversarial loss: 0.505988\n",
      "epoch 130; iter: 0; batch classifier loss: 0.303084; batch adversarial loss: 0.513595\n",
      "epoch 131; iter: 0; batch classifier loss: 0.433979; batch adversarial loss: 0.527605\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368324; batch adversarial loss: 0.603506\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358247; batch adversarial loss: 0.585786\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364795; batch adversarial loss: 0.488090\n",
      "epoch 135; iter: 0; batch classifier loss: 0.385272; batch adversarial loss: 0.532785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368954; batch adversarial loss: 0.594606\n",
      "epoch 137; iter: 0; batch classifier loss: 0.451545; batch adversarial loss: 0.553168\n",
      "epoch 138; iter: 0; batch classifier loss: 0.331537; batch adversarial loss: 0.530051\n",
      "epoch 139; iter: 0; batch classifier loss: 0.442951; batch adversarial loss: 0.569337\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384929; batch adversarial loss: 0.529399\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422242; batch adversarial loss: 0.541337\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378094; batch adversarial loss: 0.570449\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359498; batch adversarial loss: 0.595292\n",
      "epoch 144; iter: 0; batch classifier loss: 0.333417; batch adversarial loss: 0.542928\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373578; batch adversarial loss: 0.498699\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385472; batch adversarial loss: 0.526940\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373271; batch adversarial loss: 0.496530\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339129; batch adversarial loss: 0.580661\n",
      "epoch 149; iter: 0; batch classifier loss: 0.310469; batch adversarial loss: 0.496993\n",
      "epoch 150; iter: 0; batch classifier loss: 0.457729; batch adversarial loss: 0.600545\n",
      "epoch 151; iter: 0; batch classifier loss: 0.420017; batch adversarial loss: 0.581126\n",
      "epoch 152; iter: 0; batch classifier loss: 0.317014; batch adversarial loss: 0.564503\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325905; batch adversarial loss: 0.543087\n",
      "epoch 154; iter: 0; batch classifier loss: 0.399631; batch adversarial loss: 0.500416\n",
      "epoch 155; iter: 0; batch classifier loss: 0.460307; batch adversarial loss: 0.535401\n",
      "epoch 156; iter: 0; batch classifier loss: 0.417532; batch adversarial loss: 0.536551\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340235; batch adversarial loss: 0.549265\n",
      "epoch 158; iter: 0; batch classifier loss: 0.410663; batch adversarial loss: 0.555638\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374921; batch adversarial loss: 0.571276\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398212; batch adversarial loss: 0.553559\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384331; batch adversarial loss: 0.553516\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.548772\n",
      "epoch 163; iter: 0; batch classifier loss: 0.433332; batch adversarial loss: 0.583970\n",
      "epoch 164; iter: 0; batch classifier loss: 0.468409; batch adversarial loss: 0.590094\n",
      "epoch 165; iter: 0; batch classifier loss: 0.322302; batch adversarial loss: 0.488752\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354327; batch adversarial loss: 0.498828\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363083; batch adversarial loss: 0.523306\n",
      "epoch 168; iter: 0; batch classifier loss: 0.328197; batch adversarial loss: 0.515607\n",
      "epoch 169; iter: 0; batch classifier loss: 0.348202; batch adversarial loss: 0.522859\n",
      "epoch 170; iter: 0; batch classifier loss: 0.356030; batch adversarial loss: 0.525029\n",
      "epoch 171; iter: 0; batch classifier loss: 0.446700; batch adversarial loss: 0.606760\n",
      "epoch 172; iter: 0; batch classifier loss: 0.449847; batch adversarial loss: 0.593473\n",
      "epoch 173; iter: 0; batch classifier loss: 0.304338; batch adversarial loss: 0.525267\n",
      "epoch 174; iter: 0; batch classifier loss: 0.327792; batch adversarial loss: 0.513406\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387177; batch adversarial loss: 0.510571\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349370; batch adversarial loss: 0.584493\n",
      "epoch 177; iter: 0; batch classifier loss: 0.445756; batch adversarial loss: 0.566225\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316099; batch adversarial loss: 0.583529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.348425; batch adversarial loss: 0.467657\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362393; batch adversarial loss: 0.557300\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382485; batch adversarial loss: 0.562373\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333804; batch adversarial loss: 0.489438\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347381; batch adversarial loss: 0.541812\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355124; batch adversarial loss: 0.508543\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375025; batch adversarial loss: 0.517594\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318465; batch adversarial loss: 0.570571\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376700; batch adversarial loss: 0.433892\n",
      "epoch 188; iter: 0; batch classifier loss: 0.316302; batch adversarial loss: 0.515937\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381144; batch adversarial loss: 0.527822\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372625; batch adversarial loss: 0.527065\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403215; batch adversarial loss: 0.480859\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335230; batch adversarial loss: 0.536927\n",
      "epoch 193; iter: 0; batch classifier loss: 0.435401; batch adversarial loss: 0.512883\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351770; batch adversarial loss: 0.549133\n",
      "epoch 195; iter: 0; batch classifier loss: 0.410213; batch adversarial loss: 0.557273\n",
      "epoch 196; iter: 0; batch classifier loss: 0.377340; batch adversarial loss: 0.653624\n",
      "epoch 197; iter: 0; batch classifier loss: 0.421652; batch adversarial loss: 0.503749\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390745; batch adversarial loss: 0.498322\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314737; batch adversarial loss: 0.593261\n",
      "epoch 0; iter: 0; batch classifier loss: 0.771012; batch adversarial loss: 0.585281\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580107; batch adversarial loss: 0.663523\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561251; batch adversarial loss: 0.645073\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563255; batch adversarial loss: 0.670207\n",
      "epoch 4; iter: 0; batch classifier loss: 0.633875; batch adversarial loss: 0.604199\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558200; batch adversarial loss: 0.666664\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550055; batch adversarial loss: 0.644081\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561283; batch adversarial loss: 0.603973\n",
      "epoch 8; iter: 0; batch classifier loss: 0.604376; batch adversarial loss: 0.624851\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481718; batch adversarial loss: 0.573814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502641; batch adversarial loss: 0.561544\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562856; batch adversarial loss: 0.543577\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501693; batch adversarial loss: 0.527178\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586232; batch adversarial loss: 0.533354\n",
      "epoch 14; iter: 0; batch classifier loss: 0.450120; batch adversarial loss: 0.519065\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480415; batch adversarial loss: 0.498458\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481297; batch adversarial loss: 0.589498\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505853; batch adversarial loss: 0.540291\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555714; batch adversarial loss: 0.542071\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518353; batch adversarial loss: 0.566376\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429553; batch adversarial loss: 0.588451\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468180; batch adversarial loss: 0.594261\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486048; batch adversarial loss: 0.597227\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467776; batch adversarial loss: 0.513469\n",
      "epoch 24; iter: 0; batch classifier loss: 0.529237; batch adversarial loss: 0.554423\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505245; batch adversarial loss: 0.495152\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463814; batch adversarial loss: 0.573531\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484402; batch adversarial loss: 0.571517\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471982; batch adversarial loss: 0.500936\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468186; batch adversarial loss: 0.527087\n",
      "epoch 30; iter: 0; batch classifier loss: 0.516617; batch adversarial loss: 0.518246\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438352; batch adversarial loss: 0.634717\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481680; batch adversarial loss: 0.454125\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487505; batch adversarial loss: 0.507863\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420798; batch adversarial loss: 0.561343\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461744; batch adversarial loss: 0.552451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477775; batch adversarial loss: 0.562644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471019; batch adversarial loss: 0.489134\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447380; batch adversarial loss: 0.610657\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435066; batch adversarial loss: 0.515594\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418070; batch adversarial loss: 0.420736\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390178; batch adversarial loss: 0.562379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463094; batch adversarial loss: 0.563434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491137; batch adversarial loss: 0.611547\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444063; batch adversarial loss: 0.581601\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443262; batch adversarial loss: 0.509053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423028; batch adversarial loss: 0.544371\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377569; batch adversarial loss: 0.508017\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425468; batch adversarial loss: 0.603484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.541011; batch adversarial loss: 0.476346\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498357; batch adversarial loss: 0.566693\n",
      "epoch 51; iter: 0; batch classifier loss: 0.540041; batch adversarial loss: 0.458088\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415079; batch adversarial loss: 0.551603\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420872; batch adversarial loss: 0.557538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408496; batch adversarial loss: 0.578047\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427567; batch adversarial loss: 0.504483\n",
      "epoch 56; iter: 0; batch classifier loss: 0.381605; batch adversarial loss: 0.554524\n",
      "epoch 57; iter: 0; batch classifier loss: 0.451848; batch adversarial loss: 0.642286\n",
      "epoch 58; iter: 0; batch classifier loss: 0.481355; batch adversarial loss: 0.557553\n",
      "epoch 59; iter: 0; batch classifier loss: 0.490270; batch adversarial loss: 0.534755\n",
      "epoch 60; iter: 0; batch classifier loss: 0.458584; batch adversarial loss: 0.525494\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409045; batch adversarial loss: 0.553921\n",
      "epoch 62; iter: 0; batch classifier loss: 0.455353; batch adversarial loss: 0.643613\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388686; batch adversarial loss: 0.584536\n",
      "epoch 64; iter: 0; batch classifier loss: 0.503480; batch adversarial loss: 0.488869\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412633; batch adversarial loss: 0.497381\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410991; batch adversarial loss: 0.600551\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413225; batch adversarial loss: 0.476883\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402113; batch adversarial loss: 0.493528\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440079; batch adversarial loss: 0.540709\n",
      "epoch 70; iter: 0; batch classifier loss: 0.585695; batch adversarial loss: 0.449643\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471079; batch adversarial loss: 0.544393\n",
      "epoch 72; iter: 0; batch classifier loss: 0.284716; batch adversarial loss: 0.511013\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446831; batch adversarial loss: 0.538988\n",
      "epoch 74; iter: 0; batch classifier loss: 0.407324; batch adversarial loss: 0.506190\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390046; batch adversarial loss: 0.470705\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.487541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.434555; batch adversarial loss: 0.458289\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427577; batch adversarial loss: 0.446814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440346; batch adversarial loss: 0.437445\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377664; batch adversarial loss: 0.599017\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419605; batch adversarial loss: 0.544838\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414895; batch adversarial loss: 0.543483\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443160; batch adversarial loss: 0.614396\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402408; batch adversarial loss: 0.589450\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425264; batch adversarial loss: 0.569887\n",
      "epoch 86; iter: 0; batch classifier loss: 0.352966; batch adversarial loss: 0.499634\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394465; batch adversarial loss: 0.517255\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376269; batch adversarial loss: 0.464213\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379835; batch adversarial loss: 0.595810\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391555; batch adversarial loss: 0.532779\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423617; batch adversarial loss: 0.524095\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371561; batch adversarial loss: 0.615399\n",
      "epoch 93; iter: 0; batch classifier loss: 0.416333; batch adversarial loss: 0.554770\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411034; batch adversarial loss: 0.574967\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381899; batch adversarial loss: 0.504238\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374792; batch adversarial loss: 0.534288\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362693; batch adversarial loss: 0.561454\n",
      "epoch 98; iter: 0; batch classifier loss: 0.465327; batch adversarial loss: 0.422424\n",
      "epoch 99; iter: 0; batch classifier loss: 0.445989; batch adversarial loss: 0.476067\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413032; batch adversarial loss: 0.573324\n",
      "epoch 101; iter: 0; batch classifier loss: 0.294651; batch adversarial loss: 0.504973\n",
      "epoch 102; iter: 0; batch classifier loss: 0.484401; batch adversarial loss: 0.515957\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371854; batch adversarial loss: 0.570386\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436749; batch adversarial loss: 0.492513\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445438; batch adversarial loss: 0.541788\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388683; batch adversarial loss: 0.496600\n",
      "epoch 107; iter: 0; batch classifier loss: 0.460558; batch adversarial loss: 0.581135\n",
      "epoch 108; iter: 0; batch classifier loss: 0.368925; batch adversarial loss: 0.553657\n",
      "epoch 109; iter: 0; batch classifier loss: 0.442362; batch adversarial loss: 0.493045\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359642; batch adversarial loss: 0.557179\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415594; batch adversarial loss: 0.491591\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435594; batch adversarial loss: 0.578050\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358030; batch adversarial loss: 0.456891\n",
      "epoch 114; iter: 0; batch classifier loss: 0.334949; batch adversarial loss: 0.506261\n",
      "epoch 115; iter: 0; batch classifier loss: 0.425993; batch adversarial loss: 0.494057\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357670; batch adversarial loss: 0.546452\n",
      "epoch 117; iter: 0; batch classifier loss: 0.433727; batch adversarial loss: 0.550714\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376916; batch adversarial loss: 0.550980\n",
      "epoch 119; iter: 0; batch classifier loss: 0.459217; batch adversarial loss: 0.530070\n",
      "epoch 120; iter: 0; batch classifier loss: 0.444489; batch adversarial loss: 0.493460\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320219; batch adversarial loss: 0.568694\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395923; batch adversarial loss: 0.555789\n",
      "epoch 123; iter: 0; batch classifier loss: 0.524838; batch adversarial loss: 0.589754\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374840; batch adversarial loss: 0.576256\n",
      "epoch 125; iter: 0; batch classifier loss: 0.461865; batch adversarial loss: 0.474933\n",
      "epoch 126; iter: 0; batch classifier loss: 0.335731; batch adversarial loss: 0.553850\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419137; batch adversarial loss: 0.525536\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338590; batch adversarial loss: 0.565065\n",
      "epoch 129; iter: 0; batch classifier loss: 0.441606; batch adversarial loss: 0.477344\n",
      "epoch 130; iter: 0; batch classifier loss: 0.331416; batch adversarial loss: 0.524988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343679; batch adversarial loss: 0.525698\n",
      "epoch 132; iter: 0; batch classifier loss: 0.448242; batch adversarial loss: 0.554575\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370957; batch adversarial loss: 0.527841\n",
      "epoch 134; iter: 0; batch classifier loss: 0.332926; batch adversarial loss: 0.495151\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366365; batch adversarial loss: 0.526719\n",
      "epoch 136; iter: 0; batch classifier loss: 0.363460; batch adversarial loss: 0.563580\n",
      "epoch 137; iter: 0; batch classifier loss: 0.381525; batch adversarial loss: 0.527663\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404269; batch adversarial loss: 0.539192\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365907; batch adversarial loss: 0.489247\n",
      "epoch 140; iter: 0; batch classifier loss: 0.432843; batch adversarial loss: 0.564763\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336530; batch adversarial loss: 0.484018\n",
      "epoch 142; iter: 0; batch classifier loss: 0.408405; batch adversarial loss: 0.583143\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370578; batch adversarial loss: 0.583873\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341747; batch adversarial loss: 0.528400\n",
      "epoch 145; iter: 0; batch classifier loss: 0.485982; batch adversarial loss: 0.548498\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339529; batch adversarial loss: 0.505409\n",
      "epoch 147; iter: 0; batch classifier loss: 0.427195; batch adversarial loss: 0.574591\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403618; batch adversarial loss: 0.630996\n",
      "epoch 149; iter: 0; batch classifier loss: 0.438051; batch adversarial loss: 0.571635\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373345; batch adversarial loss: 0.555873\n",
      "epoch 151; iter: 0; batch classifier loss: 0.425711; batch adversarial loss: 0.584032\n",
      "epoch 152; iter: 0; batch classifier loss: 0.433874; batch adversarial loss: 0.678241\n",
      "epoch 153; iter: 0; batch classifier loss: 0.418850; batch adversarial loss: 0.523199\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394166; batch adversarial loss: 0.583451\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374093; batch adversarial loss: 0.476424\n",
      "epoch 156; iter: 0; batch classifier loss: 0.446969; batch adversarial loss: 0.535890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359815; batch adversarial loss: 0.551279\n",
      "epoch 158; iter: 0; batch classifier loss: 0.418135; batch adversarial loss: 0.505425\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342751; batch adversarial loss: 0.507526\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378894; batch adversarial loss: 0.493709\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318992; batch adversarial loss: 0.527948\n",
      "epoch 162; iter: 0; batch classifier loss: 0.414419; batch adversarial loss: 0.465084\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359222; batch adversarial loss: 0.476491\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345625; batch adversarial loss: 0.566828\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398794; batch adversarial loss: 0.496707\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319554; batch adversarial loss: 0.545997\n",
      "epoch 167; iter: 0; batch classifier loss: 0.405857; batch adversarial loss: 0.593815\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383751; batch adversarial loss: 0.517683\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343284; batch adversarial loss: 0.509986\n",
      "epoch 170; iter: 0; batch classifier loss: 0.343491; batch adversarial loss: 0.507609\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384222; batch adversarial loss: 0.570259\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364247; batch adversarial loss: 0.551301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.435683; batch adversarial loss: 0.541115\n",
      "epoch 174; iter: 0; batch classifier loss: 0.397062; batch adversarial loss: 0.583068\n",
      "epoch 175; iter: 0; batch classifier loss: 0.309908; batch adversarial loss: 0.484549\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335122; batch adversarial loss: 0.492700\n",
      "epoch 177; iter: 0; batch classifier loss: 0.480742; batch adversarial loss: 0.519167\n",
      "epoch 178; iter: 0; batch classifier loss: 0.443685; batch adversarial loss: 0.502335\n",
      "epoch 179; iter: 0; batch classifier loss: 0.412845; batch adversarial loss: 0.544277\n",
      "epoch 180; iter: 0; batch classifier loss: 0.332102; batch adversarial loss: 0.607334\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375363; batch adversarial loss: 0.561526\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382977; batch adversarial loss: 0.477609\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409995; batch adversarial loss: 0.538917\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390121; batch adversarial loss: 0.553597\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371901; batch adversarial loss: 0.531022\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353599; batch adversarial loss: 0.524210\n",
      "epoch 187; iter: 0; batch classifier loss: 0.415607; batch adversarial loss: 0.504852\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384333; batch adversarial loss: 0.499336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.394352; batch adversarial loss: 0.543515\n",
      "epoch 190; iter: 0; batch classifier loss: 0.446038; batch adversarial loss: 0.559034\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366260; batch adversarial loss: 0.505316\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308246; batch adversarial loss: 0.469696\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307375; batch adversarial loss: 0.458619\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368313; batch adversarial loss: 0.489610\n",
      "epoch 195; iter: 0; batch classifier loss: 0.284892; batch adversarial loss: 0.650115\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364942; batch adversarial loss: 0.475172\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337443; batch adversarial loss: 0.504831\n",
      "epoch 198; iter: 0; batch classifier loss: 0.446340; batch adversarial loss: 0.535664\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312122; batch adversarial loss: 0.565856\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698996; batch adversarial loss: 0.681709\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615393; batch adversarial loss: 0.678422\n",
      "epoch 2; iter: 0; batch classifier loss: 0.632725; batch adversarial loss: 0.678394\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558597; batch adversarial loss: 0.679703\n",
      "epoch 4; iter: 0; batch classifier loss: 0.554478; batch adversarial loss: 0.624336\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559079; batch adversarial loss: 0.615408\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513101; batch adversarial loss: 0.615644\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525438; batch adversarial loss: 0.600962\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514118; batch adversarial loss: 0.628234\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551762; batch adversarial loss: 0.593158\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488204; batch adversarial loss: 0.602234\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590043; batch adversarial loss: 0.569469\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418799; batch adversarial loss: 0.585768\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551615; batch adversarial loss: 0.511629\n",
      "epoch 14; iter: 0; batch classifier loss: 0.646566; batch adversarial loss: 0.513449\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491775; batch adversarial loss: 0.525010\n",
      "epoch 16; iter: 0; batch classifier loss: 0.555400; batch adversarial loss: 0.541402\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515724; batch adversarial loss: 0.574367\n",
      "epoch 18; iter: 0; batch classifier loss: 0.516482; batch adversarial loss: 0.680073\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530450; batch adversarial loss: 0.554174\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484677; batch adversarial loss: 0.544711\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537677; batch adversarial loss: 0.609681\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458671; batch adversarial loss: 0.530207\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523397; batch adversarial loss: 0.487911\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528419; batch adversarial loss: 0.502977\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495890; batch adversarial loss: 0.541783\n",
      "epoch 26; iter: 0; batch classifier loss: 0.430558; batch adversarial loss: 0.505521\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414565; batch adversarial loss: 0.580450\n",
      "epoch 28; iter: 0; batch classifier loss: 0.543019; batch adversarial loss: 0.564454\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465523; batch adversarial loss: 0.523464\n",
      "epoch 30; iter: 0; batch classifier loss: 0.382321; batch adversarial loss: 0.474435\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494006; batch adversarial loss: 0.649322\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499154; batch adversarial loss: 0.554448\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447069; batch adversarial loss: 0.560247\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473571; batch adversarial loss: 0.569870\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476310; batch adversarial loss: 0.505079\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422238; batch adversarial loss: 0.562547\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491501; batch adversarial loss: 0.554174\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447567; batch adversarial loss: 0.562251\n",
      "epoch 39; iter: 0; batch classifier loss: 0.472248; batch adversarial loss: 0.527560\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495363; batch adversarial loss: 0.456928\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420675; batch adversarial loss: 0.580854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.358521; batch adversarial loss: 0.536007\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478490; batch adversarial loss: 0.526990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422633; batch adversarial loss: 0.617180\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463594; batch adversarial loss: 0.625605\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452675; batch adversarial loss: 0.508891\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469742; batch adversarial loss: 0.551113\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447226; batch adversarial loss: 0.517106\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430216; batch adversarial loss: 0.526827\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411067; batch adversarial loss: 0.535305\n",
      "epoch 51; iter: 0; batch classifier loss: 0.522232; batch adversarial loss: 0.498673\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436942; batch adversarial loss: 0.517179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381341; batch adversarial loss: 0.501282\n",
      "epoch 54; iter: 0; batch classifier loss: 0.521667; batch adversarial loss: 0.516535\n",
      "epoch 55; iter: 0; batch classifier loss: 0.363413; batch adversarial loss: 0.517858\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463784; batch adversarial loss: 0.562288\n",
      "epoch 57; iter: 0; batch classifier loss: 0.473817; batch adversarial loss: 0.562214\n",
      "epoch 58; iter: 0; batch classifier loss: 0.377950; batch adversarial loss: 0.569497\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426917; batch adversarial loss: 0.506845\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435743; batch adversarial loss: 0.519897\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383914; batch adversarial loss: 0.553268\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433257; batch adversarial loss: 0.581063\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419446; batch adversarial loss: 0.518803\n",
      "epoch 64; iter: 0; batch classifier loss: 0.480950; batch adversarial loss: 0.543128\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411117; batch adversarial loss: 0.501154\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425424; batch adversarial loss: 0.479973\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445148; batch adversarial loss: 0.597712\n",
      "epoch 68; iter: 0; batch classifier loss: 0.446156; batch adversarial loss: 0.605801\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420474; batch adversarial loss: 0.551696\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343166; batch adversarial loss: 0.599041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.471548; batch adversarial loss: 0.562342\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466890; batch adversarial loss: 0.562565\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396071; batch adversarial loss: 0.517542\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364302; batch adversarial loss: 0.551621\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381277; batch adversarial loss: 0.553578\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402152; batch adversarial loss: 0.553700\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395809; batch adversarial loss: 0.562396\n",
      "epoch 78; iter: 0; batch classifier loss: 0.326068; batch adversarial loss: 0.481215\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420746; batch adversarial loss: 0.624332\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400943; batch adversarial loss: 0.562765\n",
      "epoch 81; iter: 0; batch classifier loss: 0.455898; batch adversarial loss: 0.506834\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395855; batch adversarial loss: 0.515340\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421654; batch adversarial loss: 0.570363\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391217; batch adversarial loss: 0.545267\n",
      "epoch 85; iter: 0; batch classifier loss: 0.453131; batch adversarial loss: 0.543510\n",
      "epoch 86; iter: 0; batch classifier loss: 0.396786; batch adversarial loss: 0.580986\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376348; batch adversarial loss: 0.562971\n",
      "epoch 88; iter: 0; batch classifier loss: 0.472216; batch adversarial loss: 0.545193\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380118; batch adversarial loss: 0.509755\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409388; batch adversarial loss: 0.615107\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365698; batch adversarial loss: 0.541634\n",
      "epoch 92; iter: 0; batch classifier loss: 0.468144; batch adversarial loss: 0.591727\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420053; batch adversarial loss: 0.575075\n",
      "epoch 94; iter: 0; batch classifier loss: 0.509081; batch adversarial loss: 0.496485\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422098; batch adversarial loss: 0.515501\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374222; batch adversarial loss: 0.610956\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375204; batch adversarial loss: 0.553657\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385961; batch adversarial loss: 0.543672\n",
      "epoch 99; iter: 0; batch classifier loss: 0.476783; batch adversarial loss: 0.608388\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364512; batch adversarial loss: 0.554370\n",
      "epoch 101; iter: 0; batch classifier loss: 0.495773; batch adversarial loss: 0.499475\n",
      "epoch 102; iter: 0; batch classifier loss: 0.433517; batch adversarial loss: 0.604187\n",
      "epoch 103; iter: 0; batch classifier loss: 0.310930; batch adversarial loss: 0.634504\n",
      "epoch 104; iter: 0; batch classifier loss: 0.345631; batch adversarial loss: 0.720723\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379165; batch adversarial loss: 0.535351\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363261; batch adversarial loss: 0.639547\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362182; batch adversarial loss: 0.617985\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380059; batch adversarial loss: 0.598235\n",
      "epoch 109; iter: 0; batch classifier loss: 0.445712; batch adversarial loss: 0.514618\n",
      "epoch 110; iter: 0; batch classifier loss: 0.265554; batch adversarial loss: 0.626580\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356720; batch adversarial loss: 0.487633\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381852; batch adversarial loss: 0.554216\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345528; batch adversarial loss: 0.535268\n",
      "epoch 114; iter: 0; batch classifier loss: 0.424311; batch adversarial loss: 0.633279\n",
      "epoch 115; iter: 0; batch classifier loss: 0.368069; batch adversarial loss: 0.552091\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385700; batch adversarial loss: 0.587476\n",
      "epoch 117; iter: 0; batch classifier loss: 0.472142; batch adversarial loss: 0.521410\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453079; batch adversarial loss: 0.573578\n",
      "epoch 119; iter: 0; batch classifier loss: 0.400460; batch adversarial loss: 0.581496\n",
      "epoch 120; iter: 0; batch classifier loss: 0.417435; batch adversarial loss: 0.594875\n",
      "epoch 121; iter: 0; batch classifier loss: 0.386130; batch adversarial loss: 0.517527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376809; batch adversarial loss: 0.561851\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344753; batch adversarial loss: 0.522807\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393855; batch adversarial loss: 0.562965\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351746; batch adversarial loss: 0.533209\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344261; batch adversarial loss: 0.463300\n",
      "epoch 127; iter: 0; batch classifier loss: 0.466099; batch adversarial loss: 0.506267\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387689; batch adversarial loss: 0.527139\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380054; batch adversarial loss: 0.577040\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383432; batch adversarial loss: 0.593390\n",
      "epoch 131; iter: 0; batch classifier loss: 0.319053; batch adversarial loss: 0.511283\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382004; batch adversarial loss: 0.550311\n",
      "epoch 133; iter: 0; batch classifier loss: 0.424693; batch adversarial loss: 0.516558\n",
      "epoch 134; iter: 0; batch classifier loss: 0.327003; batch adversarial loss: 0.514732\n",
      "epoch 135; iter: 0; batch classifier loss: 0.401591; batch adversarial loss: 0.528192\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373177; batch adversarial loss: 0.483538\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401019; batch adversarial loss: 0.559754\n",
      "epoch 138; iter: 0; batch classifier loss: 0.432804; batch adversarial loss: 0.553063\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409720; batch adversarial loss: 0.598547\n",
      "epoch 140; iter: 0; batch classifier loss: 0.420228; batch adversarial loss: 0.554162\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420790; batch adversarial loss: 0.462997\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395973; batch adversarial loss: 0.546096\n",
      "epoch 143; iter: 0; batch classifier loss: 0.448936; batch adversarial loss: 0.606264\n",
      "epoch 144; iter: 0; batch classifier loss: 0.330988; batch adversarial loss: 0.544405\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389533; batch adversarial loss: 0.590867\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337552; batch adversarial loss: 0.576022\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404897; batch adversarial loss: 0.526168\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378717; batch adversarial loss: 0.491389\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348077; batch adversarial loss: 0.598988\n",
      "epoch 150; iter: 0; batch classifier loss: 0.401223; batch adversarial loss: 0.632207\n",
      "epoch 151; iter: 0; batch classifier loss: 0.451285; batch adversarial loss: 0.581227\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343779; batch adversarial loss: 0.489238\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361328; batch adversarial loss: 0.572107\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370081; batch adversarial loss: 0.583120\n",
      "epoch 155; iter: 0; batch classifier loss: 0.345859; batch adversarial loss: 0.534029\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401035; batch adversarial loss: 0.534587\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391619; batch adversarial loss: 0.464782\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344313; batch adversarial loss: 0.501906\n",
      "epoch 159; iter: 0; batch classifier loss: 0.403003; batch adversarial loss: 0.521131\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351853; batch adversarial loss: 0.480881\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391643; batch adversarial loss: 0.551012\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392136; batch adversarial loss: 0.581249\n",
      "epoch 163; iter: 0; batch classifier loss: 0.377295; batch adversarial loss: 0.543309\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381386; batch adversarial loss: 0.608626\n",
      "epoch 165; iter: 0; batch classifier loss: 0.404855; batch adversarial loss: 0.554534\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331210; batch adversarial loss: 0.559957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.387745; batch adversarial loss: 0.507737\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395738; batch adversarial loss: 0.527722\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382247; batch adversarial loss: 0.547029\n",
      "epoch 170; iter: 0; batch classifier loss: 0.332981; batch adversarial loss: 0.490410\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362817; batch adversarial loss: 0.546279\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349626; batch adversarial loss: 0.534009\n",
      "epoch 173; iter: 0; batch classifier loss: 0.424876; batch adversarial loss: 0.542563\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381061; batch adversarial loss: 0.471896\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388876; batch adversarial loss: 0.556477\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395237; batch adversarial loss: 0.563495\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383682; batch adversarial loss: 0.545673\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381622; batch adversarial loss: 0.548638\n",
      "epoch 179; iter: 0; batch classifier loss: 0.410185; batch adversarial loss: 0.510135\n",
      "epoch 180; iter: 0; batch classifier loss: 0.463352; batch adversarial loss: 0.516438\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322726; batch adversarial loss: 0.518048\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382360; batch adversarial loss: 0.552190\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323021; batch adversarial loss: 0.551777\n",
      "epoch 184; iter: 0; batch classifier loss: 0.409851; batch adversarial loss: 0.588893\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402041; batch adversarial loss: 0.524957\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309244; batch adversarial loss: 0.559716\n",
      "epoch 187; iter: 0; batch classifier loss: 0.420436; batch adversarial loss: 0.578996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.420188; batch adversarial loss: 0.562066\n",
      "epoch 189; iter: 0; batch classifier loss: 0.291209; batch adversarial loss: 0.576913\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367797; batch adversarial loss: 0.484160\n",
      "epoch 191; iter: 0; batch classifier loss: 0.394392; batch adversarial loss: 0.485994\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374671; batch adversarial loss: 0.525249\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360063; batch adversarial loss: 0.438671\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398955; batch adversarial loss: 0.517881\n",
      "epoch 195; iter: 0; batch classifier loss: 0.425688; batch adversarial loss: 0.532181\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363847; batch adversarial loss: 0.551363\n",
      "epoch 197; iter: 0; batch classifier loss: 0.461845; batch adversarial loss: 0.617140\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359211; batch adversarial loss: 0.485501\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348509; batch adversarial loss: 0.556192\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684919; batch adversarial loss: 0.623989\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582588; batch adversarial loss: 0.661901\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603070; batch adversarial loss: 0.662678\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570966; batch adversarial loss: 0.629081\n",
      "epoch 4; iter: 0; batch classifier loss: 0.618315; batch adversarial loss: 0.605555\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590874; batch adversarial loss: 0.654084\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509928; batch adversarial loss: 0.633424\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542116; batch adversarial loss: 0.529961\n",
      "epoch 8; iter: 0; batch classifier loss: 0.635983; batch adversarial loss: 0.652683\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576210; batch adversarial loss: 0.563267\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496259; batch adversarial loss: 0.597204\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534995; batch adversarial loss: 0.546693\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468820; batch adversarial loss: 0.570585\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490456; batch adversarial loss: 0.635627\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527769; batch adversarial loss: 0.614464\n",
      "epoch 15; iter: 0; batch classifier loss: 0.429527; batch adversarial loss: 0.554359\n",
      "epoch 16; iter: 0; batch classifier loss: 0.560800; batch adversarial loss: 0.535298\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435125; batch adversarial loss: 0.583218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484938; batch adversarial loss: 0.564209\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564291; batch adversarial loss: 0.566485\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505217; batch adversarial loss: 0.599418\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429111; batch adversarial loss: 0.459689\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542280; batch adversarial loss: 0.533526\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400441; batch adversarial loss: 0.570194\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498796; batch adversarial loss: 0.533544\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490721; batch adversarial loss: 0.553764\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496450; batch adversarial loss: 0.448899\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490397; batch adversarial loss: 0.523039\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453411; batch adversarial loss: 0.517732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.552205; batch adversarial loss: 0.553494\n",
      "epoch 30; iter: 0; batch classifier loss: 0.498716; batch adversarial loss: 0.542155\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468184; batch adversarial loss: 0.472201\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435780; batch adversarial loss: 0.525195\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438506; batch adversarial loss: 0.555749\n",
      "epoch 34; iter: 0; batch classifier loss: 0.486068; batch adversarial loss: 0.509566\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454239; batch adversarial loss: 0.581063\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455850; batch adversarial loss: 0.578104\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464867; batch adversarial loss: 0.568760\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398903; batch adversarial loss: 0.575543\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505193; batch adversarial loss: 0.549162\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495834; batch adversarial loss: 0.584225\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469247; batch adversarial loss: 0.536459\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408218; batch adversarial loss: 0.564642\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491658; batch adversarial loss: 0.476484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462592; batch adversarial loss: 0.511870\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449410; batch adversarial loss: 0.581771\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454506; batch adversarial loss: 0.515028\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436739; batch adversarial loss: 0.515155\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454542; batch adversarial loss: 0.505996\n",
      "epoch 49; iter: 0; batch classifier loss: 0.352954; batch adversarial loss: 0.563143\n",
      "epoch 50; iter: 0; batch classifier loss: 0.365413; batch adversarial loss: 0.539973\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425555; batch adversarial loss: 0.508241\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411282; batch adversarial loss: 0.518563\n",
      "epoch 53; iter: 0; batch classifier loss: 0.457796; batch adversarial loss: 0.498094\n",
      "epoch 54; iter: 0; batch classifier loss: 0.339978; batch adversarial loss: 0.553357\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404560; batch adversarial loss: 0.580932\n",
      "epoch 56; iter: 0; batch classifier loss: 0.334143; batch adversarial loss: 0.570464\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393018; batch adversarial loss: 0.561684\n",
      "epoch 58; iter: 0; batch classifier loss: 0.482676; batch adversarial loss: 0.597777\n",
      "epoch 59; iter: 0; batch classifier loss: 0.567727; batch adversarial loss: 0.478120\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424325; batch adversarial loss: 0.552753\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422737; batch adversarial loss: 0.552037\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456865; batch adversarial loss: 0.588058\n",
      "epoch 63; iter: 0; batch classifier loss: 0.365709; batch adversarial loss: 0.541332\n",
      "epoch 64; iter: 0; batch classifier loss: 0.459528; batch adversarial loss: 0.543812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.396654; batch adversarial loss: 0.572097\n",
      "epoch 66; iter: 0; batch classifier loss: 0.448413; batch adversarial loss: 0.552291\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399810; batch adversarial loss: 0.508130\n",
      "epoch 68; iter: 0; batch classifier loss: 0.435480; batch adversarial loss: 0.525076\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399053; batch adversarial loss: 0.470860\n",
      "epoch 70; iter: 0; batch classifier loss: 0.362841; batch adversarial loss: 0.608405\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403968; batch adversarial loss: 0.527810\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434910; batch adversarial loss: 0.507427\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441472; batch adversarial loss: 0.554837\n",
      "epoch 74; iter: 0; batch classifier loss: 0.487382; batch adversarial loss: 0.526492\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370208; batch adversarial loss: 0.693490\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415030; batch adversarial loss: 0.574679\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407807; batch adversarial loss: 0.536186\n",
      "epoch 78; iter: 0; batch classifier loss: 0.328641; batch adversarial loss: 0.515495\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343284; batch adversarial loss: 0.592676\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408451; batch adversarial loss: 0.580888\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410797; batch adversarial loss: 0.543023\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419769; batch adversarial loss: 0.645049\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403420; batch adversarial loss: 0.571585\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368157; batch adversarial loss: 0.666381\n",
      "epoch 85; iter: 0; batch classifier loss: 0.372889; batch adversarial loss: 0.600379\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409721; batch adversarial loss: 0.571115\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430055; batch adversarial loss: 0.589617\n",
      "epoch 88; iter: 0; batch classifier loss: 0.342379; batch adversarial loss: 0.532669\n",
      "epoch 89; iter: 0; batch classifier loss: 0.454388; batch adversarial loss: 0.459495\n",
      "epoch 90; iter: 0; batch classifier loss: 0.460105; batch adversarial loss: 0.635283\n",
      "epoch 91; iter: 0; batch classifier loss: 0.458266; batch adversarial loss: 0.469901\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397349; batch adversarial loss: 0.508412\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378417; batch adversarial loss: 0.593577\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405610; batch adversarial loss: 0.554752\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396052; batch adversarial loss: 0.535787\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429192; batch adversarial loss: 0.508968\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377907; batch adversarial loss: 0.534374\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444191; batch adversarial loss: 0.460640\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339469; batch adversarial loss: 0.581193\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439934; batch adversarial loss: 0.481505\n",
      "epoch 101; iter: 0; batch classifier loss: 0.531034; batch adversarial loss: 0.555521\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385673; batch adversarial loss: 0.551628\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383482; batch adversarial loss: 0.505679\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409672; batch adversarial loss: 0.580071\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442638; batch adversarial loss: 0.528431\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363619; batch adversarial loss: 0.572757\n",
      "epoch 107; iter: 0; batch classifier loss: 0.495981; batch adversarial loss: 0.508446\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415493; batch adversarial loss: 0.497351\n",
      "epoch 109; iter: 0; batch classifier loss: 0.425597; batch adversarial loss: 0.562720\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408406; batch adversarial loss: 0.554657\n",
      "epoch 111; iter: 0; batch classifier loss: 0.453692; batch adversarial loss: 0.471603\n",
      "epoch 112; iter: 0; batch classifier loss: 0.331045; batch adversarial loss: 0.634099\n",
      "epoch 113; iter: 0; batch classifier loss: 0.457725; batch adversarial loss: 0.590203\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401399; batch adversarial loss: 0.591398\n",
      "epoch 115; iter: 0; batch classifier loss: 0.400761; batch adversarial loss: 0.590494\n",
      "epoch 116; iter: 0; batch classifier loss: 0.481695; batch adversarial loss: 0.490815\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388919; batch adversarial loss: 0.525432\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394707; batch adversarial loss: 0.579742\n",
      "epoch 119; iter: 0; batch classifier loss: 0.419123; batch adversarial loss: 0.544953\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378302; batch adversarial loss: 0.460760\n",
      "epoch 121; iter: 0; batch classifier loss: 0.386816; batch adversarial loss: 0.535320\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387018; batch adversarial loss: 0.599271\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395052; batch adversarial loss: 0.626836\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372000; batch adversarial loss: 0.607772\n",
      "epoch 125; iter: 0; batch classifier loss: 0.310443; batch adversarial loss: 0.540867\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357756; batch adversarial loss: 0.562632\n",
      "epoch 127; iter: 0; batch classifier loss: 0.449041; batch adversarial loss: 0.664905\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396525; batch adversarial loss: 0.452925\n",
      "epoch 129; iter: 0; batch classifier loss: 0.414243; batch adversarial loss: 0.609779\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356284; batch adversarial loss: 0.591096\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338554; batch adversarial loss: 0.496808\n",
      "epoch 132; iter: 0; batch classifier loss: 0.353654; batch adversarial loss: 0.543030\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362855; batch adversarial loss: 0.615130\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381821; batch adversarial loss: 0.534639\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370322; batch adversarial loss: 0.499372\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348642; batch adversarial loss: 0.571793\n",
      "epoch 137; iter: 0; batch classifier loss: 0.455530; batch adversarial loss: 0.581303\n",
      "epoch 138; iter: 0; batch classifier loss: 0.445239; batch adversarial loss: 0.663168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328794; batch adversarial loss: 0.553334\n",
      "epoch 140; iter: 0; batch classifier loss: 0.420147; batch adversarial loss: 0.481803\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400735; batch adversarial loss: 0.516870\n",
      "epoch 142; iter: 0; batch classifier loss: 0.303030; batch adversarial loss: 0.480999\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348145; batch adversarial loss: 0.675468\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374246; batch adversarial loss: 0.488499\n",
      "epoch 145; iter: 0; batch classifier loss: 0.361221; batch adversarial loss: 0.526322\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363606; batch adversarial loss: 0.552318\n",
      "epoch 147; iter: 0; batch classifier loss: 0.308174; batch adversarial loss: 0.564556\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352917; batch adversarial loss: 0.489210\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358573; batch adversarial loss: 0.543803\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360746; batch adversarial loss: 0.564049\n",
      "epoch 151; iter: 0; batch classifier loss: 0.490220; batch adversarial loss: 0.526661\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351107; batch adversarial loss: 0.600082\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342221; batch adversarial loss: 0.527094\n",
      "epoch 154; iter: 0; batch classifier loss: 0.421525; batch adversarial loss: 0.481004\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380324; batch adversarial loss: 0.499413\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352826; batch adversarial loss: 0.516172\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416931; batch adversarial loss: 0.500336\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397313; batch adversarial loss: 0.535663\n",
      "epoch 159; iter: 0; batch classifier loss: 0.401435; batch adversarial loss: 0.588464\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374043; batch adversarial loss: 0.552783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.495257; batch adversarial loss: 0.564241\n",
      "epoch 162; iter: 0; batch classifier loss: 0.422268; batch adversarial loss: 0.506434\n",
      "epoch 163; iter: 0; batch classifier loss: 0.297052; batch adversarial loss: 0.712639\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366610; batch adversarial loss: 0.514560\n",
      "epoch 165; iter: 0; batch classifier loss: 0.322712; batch adversarial loss: 0.542814\n",
      "epoch 166; iter: 0; batch classifier loss: 0.402843; batch adversarial loss: 0.488480\n",
      "epoch 167; iter: 0; batch classifier loss: 0.419131; batch adversarial loss: 0.515551\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353830; batch adversarial loss: 0.589729\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368120; batch adversarial loss: 0.574298\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409304; batch adversarial loss: 0.515953\n",
      "epoch 171; iter: 0; batch classifier loss: 0.371163; batch adversarial loss: 0.600242\n",
      "epoch 172; iter: 0; batch classifier loss: 0.316307; batch adversarial loss: 0.505968\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350910; batch adversarial loss: 0.535422\n",
      "epoch 174; iter: 0; batch classifier loss: 0.402810; batch adversarial loss: 0.563495\n",
      "epoch 175; iter: 0; batch classifier loss: 0.431638; batch adversarial loss: 0.551352\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329625; batch adversarial loss: 0.441740\n",
      "epoch 177; iter: 0; batch classifier loss: 0.403884; batch adversarial loss: 0.571753\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323482; batch adversarial loss: 0.470836\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354511; batch adversarial loss: 0.544549\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337990; batch adversarial loss: 0.572259\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365035; batch adversarial loss: 0.543722\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364763; batch adversarial loss: 0.515179\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351989; batch adversarial loss: 0.552081\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360490; batch adversarial loss: 0.580616\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369928; batch adversarial loss: 0.572392\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430689; batch adversarial loss: 0.497867\n",
      "epoch 187; iter: 0; batch classifier loss: 0.390432; batch adversarial loss: 0.570526\n",
      "epoch 188; iter: 0; batch classifier loss: 0.364941; batch adversarial loss: 0.470284\n",
      "epoch 189; iter: 0; batch classifier loss: 0.407093; batch adversarial loss: 0.533684\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323734; batch adversarial loss: 0.563646\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366836; batch adversarial loss: 0.636430\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308701; batch adversarial loss: 0.552780\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345645; batch adversarial loss: 0.470149\n",
      "epoch 194; iter: 0; batch classifier loss: 0.430535; batch adversarial loss: 0.536282\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353610; batch adversarial loss: 0.470518\n",
      "epoch 196; iter: 0; batch classifier loss: 0.296078; batch adversarial loss: 0.592084\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332489; batch adversarial loss: 0.497292\n",
      "epoch 198; iter: 0; batch classifier loss: 0.431194; batch adversarial loss: 0.599014\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332183; batch adversarial loss: 0.554050\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712935; batch adversarial loss: 0.610774\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587232; batch adversarial loss: 0.622015\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583029; batch adversarial loss: 0.653782\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569565; batch adversarial loss: 0.621231\n",
      "epoch 4; iter: 0; batch classifier loss: 0.647170; batch adversarial loss: 0.616679\n",
      "epoch 5; iter: 0; batch classifier loss: 0.623996; batch adversarial loss: 0.614241\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577998; batch adversarial loss: 0.664182\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550636; batch adversarial loss: 0.597220\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560688; batch adversarial loss: 0.568512\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540695; batch adversarial loss: 0.615543\n",
      "epoch 10; iter: 0; batch classifier loss: 0.640006; batch adversarial loss: 0.577596\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565616; batch adversarial loss: 0.543046\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558923; batch adversarial loss: 0.559055\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536504; batch adversarial loss: 0.542960\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474815; batch adversarial loss: 0.545088\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534029; batch adversarial loss: 0.567904\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515342; batch adversarial loss: 0.536787\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554756; batch adversarial loss: 0.569138\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507865; batch adversarial loss: 0.531383\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430917; batch adversarial loss: 0.549479\n",
      "epoch 20; iter: 0; batch classifier loss: 0.382430; batch adversarial loss: 0.547118\n",
      "epoch 21; iter: 0; batch classifier loss: 0.547788; batch adversarial loss: 0.620324\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517766; batch adversarial loss: 0.643193\n",
      "epoch 23; iter: 0; batch classifier loss: 0.639213; batch adversarial loss: 0.522745\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512023; batch adversarial loss: 0.537255\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498969; batch adversarial loss: 0.538287\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462244; batch adversarial loss: 0.554184\n",
      "epoch 27; iter: 0; batch classifier loss: 0.420905; batch adversarial loss: 0.494760\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494387; batch adversarial loss: 0.511179\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465141; batch adversarial loss: 0.622096\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478729; batch adversarial loss: 0.527158\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433227; batch adversarial loss: 0.553813\n",
      "epoch 32; iter: 0; batch classifier loss: 0.528883; batch adversarial loss: 0.526793\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468977; batch adversarial loss: 0.553583\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431771; batch adversarial loss: 0.625131\n",
      "epoch 35; iter: 0; batch classifier loss: 0.439868; batch adversarial loss: 0.526813\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456763; batch adversarial loss: 0.616839\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472176; batch adversarial loss: 0.508533\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424564; batch adversarial loss: 0.508513\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441647; batch adversarial loss: 0.635218\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423815; batch adversarial loss: 0.517729\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408258; batch adversarial loss: 0.587796\n",
      "epoch 42; iter: 0; batch classifier loss: 0.508408; batch adversarial loss: 0.462122\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471758; batch adversarial loss: 0.533594\n",
      "epoch 44; iter: 0; batch classifier loss: 0.318063; batch adversarial loss: 0.534680\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489100; batch adversarial loss: 0.590418\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424296; batch adversarial loss: 0.609223\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424776; batch adversarial loss: 0.552681\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477915; batch adversarial loss: 0.543808\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458478; batch adversarial loss: 0.609744\n",
      "epoch 50; iter: 0; batch classifier loss: 0.541256; batch adversarial loss: 0.552228\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441295; batch adversarial loss: 0.499922\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417739; batch adversarial loss: 0.607544\n",
      "epoch 53; iter: 0; batch classifier loss: 0.398694; batch adversarial loss: 0.534016\n",
      "epoch 54; iter: 0; batch classifier loss: 0.348018; batch adversarial loss: 0.451928\n",
      "epoch 55; iter: 0; batch classifier loss: 0.537302; batch adversarial loss: 0.561779\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425317; batch adversarial loss: 0.452303\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443654; batch adversarial loss: 0.572819\n",
      "epoch 58; iter: 0; batch classifier loss: 0.461393; batch adversarial loss: 0.494568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.460497; batch adversarial loss: 0.581724\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425468; batch adversarial loss: 0.601171\n",
      "epoch 61; iter: 0; batch classifier loss: 0.431974; batch adversarial loss: 0.583655\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398246; batch adversarial loss: 0.538778\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400415; batch adversarial loss: 0.480976\n",
      "epoch 64; iter: 0; batch classifier loss: 0.364483; batch adversarial loss: 0.485101\n",
      "epoch 65; iter: 0; batch classifier loss: 0.469551; batch adversarial loss: 0.669165\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451176; batch adversarial loss: 0.533862\n",
      "epoch 67; iter: 0; batch classifier loss: 0.504134; batch adversarial loss: 0.546142\n",
      "epoch 68; iter: 0; batch classifier loss: 0.486225; batch adversarial loss: 0.527692\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457556; batch adversarial loss: 0.524879\n",
      "epoch 70; iter: 0; batch classifier loss: 0.452692; batch adversarial loss: 0.525658\n",
      "epoch 71; iter: 0; batch classifier loss: 0.447310; batch adversarial loss: 0.512478\n",
      "epoch 72; iter: 0; batch classifier loss: 0.496467; batch adversarial loss: 0.500047\n",
      "epoch 73; iter: 0; batch classifier loss: 0.331369; batch adversarial loss: 0.551300\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393057; batch adversarial loss: 0.517620\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422907; batch adversarial loss: 0.603107\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456801; batch adversarial loss: 0.612542\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393636; batch adversarial loss: 0.548907\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401977; batch adversarial loss: 0.571339\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453515; batch adversarial loss: 0.423051\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447688; batch adversarial loss: 0.512743\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403669; batch adversarial loss: 0.505607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393932; batch adversarial loss: 0.483277\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412442; batch adversarial loss: 0.535080\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353290; batch adversarial loss: 0.548983\n",
      "epoch 85; iter: 0; batch classifier loss: 0.430072; batch adversarial loss: 0.580568\n",
      "epoch 86; iter: 0; batch classifier loss: 0.294443; batch adversarial loss: 0.489101\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371445; batch adversarial loss: 0.585508\n",
      "epoch 88; iter: 0; batch classifier loss: 0.465943; batch adversarial loss: 0.466634\n",
      "epoch 89; iter: 0; batch classifier loss: 0.480718; batch adversarial loss: 0.471133\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409280; batch adversarial loss: 0.572520\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409026; batch adversarial loss: 0.591349\n",
      "epoch 92; iter: 0; batch classifier loss: 0.427310; batch adversarial loss: 0.562692\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413717; batch adversarial loss: 0.514932\n",
      "epoch 94; iter: 0; batch classifier loss: 0.439396; batch adversarial loss: 0.595692\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376961; batch adversarial loss: 0.526738\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391155; batch adversarial loss: 0.533554\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383111; batch adversarial loss: 0.459877\n",
      "epoch 98; iter: 0; batch classifier loss: 0.505689; batch adversarial loss: 0.544075\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346530; batch adversarial loss: 0.536445\n",
      "epoch 100; iter: 0; batch classifier loss: 0.322744; batch adversarial loss: 0.558813\n",
      "epoch 101; iter: 0; batch classifier loss: 0.412263; batch adversarial loss: 0.546549\n",
      "epoch 102; iter: 0; batch classifier loss: 0.442516; batch adversarial loss: 0.554813\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401243; batch adversarial loss: 0.540641\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420051; batch adversarial loss: 0.553451\n",
      "epoch 105; iter: 0; batch classifier loss: 0.367041; batch adversarial loss: 0.541464\n",
      "epoch 106; iter: 0; batch classifier loss: 0.518981; batch adversarial loss: 0.560344\n",
      "epoch 107; iter: 0; batch classifier loss: 0.518874; batch adversarial loss: 0.546590\n",
      "epoch 108; iter: 0; batch classifier loss: 0.424742; batch adversarial loss: 0.559831\n",
      "epoch 109; iter: 0; batch classifier loss: 0.504313; batch adversarial loss: 0.555292\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389346; batch adversarial loss: 0.529583\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436009; batch adversarial loss: 0.567661\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402000; batch adversarial loss: 0.573394\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387191; batch adversarial loss: 0.519002\n",
      "epoch 114; iter: 0; batch classifier loss: 0.440724; batch adversarial loss: 0.591711\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387543; batch adversarial loss: 0.520662\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412601; batch adversarial loss: 0.531202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.349253; batch adversarial loss: 0.497985\n",
      "epoch 118; iter: 0; batch classifier loss: 0.431976; batch adversarial loss: 0.517040\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384315; batch adversarial loss: 0.542042\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350182; batch adversarial loss: 0.562614\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365010; batch adversarial loss: 0.552802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379347; batch adversarial loss: 0.487090\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370757; batch adversarial loss: 0.541530\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352776; batch adversarial loss: 0.562461\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380196; batch adversarial loss: 0.554756\n",
      "epoch 126; iter: 0; batch classifier loss: 0.428593; batch adversarial loss: 0.570505\n",
      "epoch 127; iter: 0; batch classifier loss: 0.433559; batch adversarial loss: 0.506652\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330619; batch adversarial loss: 0.562540\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394068; batch adversarial loss: 0.498218\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363624; batch adversarial loss: 0.562533\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398669; batch adversarial loss: 0.613992\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388594; batch adversarial loss: 0.537190\n",
      "epoch 133; iter: 0; batch classifier loss: 0.487383; batch adversarial loss: 0.495219\n",
      "epoch 134; iter: 0; batch classifier loss: 0.335310; batch adversarial loss: 0.576652\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353209; batch adversarial loss: 0.467768\n",
      "epoch 136; iter: 0; batch classifier loss: 0.296924; batch adversarial loss: 0.546583\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371249; batch adversarial loss: 0.530895\n",
      "epoch 138; iter: 0; batch classifier loss: 0.391404; batch adversarial loss: 0.606219\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332186; batch adversarial loss: 0.531995\n",
      "epoch 140; iter: 0; batch classifier loss: 0.479951; batch adversarial loss: 0.589309\n",
      "epoch 141; iter: 0; batch classifier loss: 0.460853; batch adversarial loss: 0.566075\n",
      "epoch 142; iter: 0; batch classifier loss: 0.344964; batch adversarial loss: 0.533240\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413256; batch adversarial loss: 0.552271\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401347; batch adversarial loss: 0.536860\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366767; batch adversarial loss: 0.469658\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341453; batch adversarial loss: 0.515569\n",
      "epoch 147; iter: 0; batch classifier loss: 0.366921; batch adversarial loss: 0.525230\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343672; batch adversarial loss: 0.648828\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361863; batch adversarial loss: 0.512478\n",
      "epoch 150; iter: 0; batch classifier loss: 0.323115; batch adversarial loss: 0.583007\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391746; batch adversarial loss: 0.468856\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349020; batch adversarial loss: 0.488631\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365589; batch adversarial loss: 0.492799\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350966; batch adversarial loss: 0.565301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.363977; batch adversarial loss: 0.659730\n",
      "epoch 156; iter: 0; batch classifier loss: 0.448006; batch adversarial loss: 0.522170\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339719; batch adversarial loss: 0.501349\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342562; batch adversarial loss: 0.589272\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311047; batch adversarial loss: 0.557506\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336826; batch adversarial loss: 0.526541\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372764; batch adversarial loss: 0.621645\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379434; batch adversarial loss: 0.532057\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325241; batch adversarial loss: 0.591890\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376871; batch adversarial loss: 0.534627\n",
      "epoch 165; iter: 0; batch classifier loss: 0.521874; batch adversarial loss: 0.581496\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373818; batch adversarial loss: 0.564670\n",
      "epoch 167; iter: 0; batch classifier loss: 0.259700; batch adversarial loss: 0.612569\n",
      "epoch 168; iter: 0; batch classifier loss: 0.517260; batch adversarial loss: 0.562812\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327099; batch adversarial loss: 0.594848\n",
      "epoch 170; iter: 0; batch classifier loss: 0.419607; batch adversarial loss: 0.529011\n",
      "epoch 171; iter: 0; batch classifier loss: 0.350517; batch adversarial loss: 0.504727\n",
      "epoch 172; iter: 0; batch classifier loss: 0.310539; batch adversarial loss: 0.535927\n",
      "epoch 173; iter: 0; batch classifier loss: 0.275683; batch adversarial loss: 0.551727\n",
      "epoch 174; iter: 0; batch classifier loss: 0.331811; batch adversarial loss: 0.564211\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350126; batch adversarial loss: 0.601491\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338182; batch adversarial loss: 0.458456\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392107; batch adversarial loss: 0.497764\n",
      "epoch 178; iter: 0; batch classifier loss: 0.285410; batch adversarial loss: 0.591898\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392377; batch adversarial loss: 0.572720\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378387; batch adversarial loss: 0.602089\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342115; batch adversarial loss: 0.570482\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371693; batch adversarial loss: 0.580388\n",
      "epoch 183; iter: 0; batch classifier loss: 0.424788; batch adversarial loss: 0.602599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.345022; batch adversarial loss: 0.536503\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390350; batch adversarial loss: 0.535224\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389764; batch adversarial loss: 0.580555\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369514; batch adversarial loss: 0.535891\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361723; batch adversarial loss: 0.597130\n",
      "epoch 189; iter: 0; batch classifier loss: 0.396643; batch adversarial loss: 0.534785\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379486; batch adversarial loss: 0.524277\n",
      "epoch 191; iter: 0; batch classifier loss: 0.332411; batch adversarial loss: 0.583420\n",
      "epoch 192; iter: 0; batch classifier loss: 0.409467; batch adversarial loss: 0.532450\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329610; batch adversarial loss: 0.507409\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368575; batch adversarial loss: 0.582419\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383257; batch adversarial loss: 0.577688\n",
      "epoch 196; iter: 0; batch classifier loss: 0.389615; batch adversarial loss: 0.561089\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351657; batch adversarial loss: 0.581833\n",
      "epoch 198; iter: 0; batch classifier loss: 0.392483; batch adversarial loss: 0.512859\n",
      "epoch 199; iter: 0; batch classifier loss: 0.429062; batch adversarial loss: 0.548966\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753897; batch adversarial loss: 0.693634\n",
      "epoch 1; iter: 0; batch classifier loss: 0.612058; batch adversarial loss: 0.642358\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565646; batch adversarial loss: 0.650013\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568163; batch adversarial loss: 0.616691\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582741; batch adversarial loss: 0.569076\n",
      "epoch 5; iter: 0; batch classifier loss: 0.493361; batch adversarial loss: 0.628384\n",
      "epoch 6; iter: 0; batch classifier loss: 0.444556; batch adversarial loss: 0.613771\n",
      "epoch 7; iter: 0; batch classifier loss: 0.500844; batch adversarial loss: 0.589806\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549193; batch adversarial loss: 0.603633\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563164; batch adversarial loss: 0.631586\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480253; batch adversarial loss: 0.579930\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547000; batch adversarial loss: 0.622491\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525840; batch adversarial loss: 0.546545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489908; batch adversarial loss: 0.587269\n",
      "epoch 14; iter: 0; batch classifier loss: 0.630596; batch adversarial loss: 0.629138\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518644; batch adversarial loss: 0.589175\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518490; batch adversarial loss: 0.571023\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518482; batch adversarial loss: 0.569835\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540126; batch adversarial loss: 0.610531\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480472; batch adversarial loss: 0.556861\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538003; batch adversarial loss: 0.581666\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463934; batch adversarial loss: 0.571714\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465368; batch adversarial loss: 0.575953\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523694; batch adversarial loss: 0.579751\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528844; batch adversarial loss: 0.555014\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458005; batch adversarial loss: 0.596976\n",
      "epoch 26; iter: 0; batch classifier loss: 0.531500; batch adversarial loss: 0.516664\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480702; batch adversarial loss: 0.575752\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470828; batch adversarial loss: 0.539700\n",
      "epoch 29; iter: 0; batch classifier loss: 0.528427; batch adversarial loss: 0.525004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477081; batch adversarial loss: 0.498486\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449987; batch adversarial loss: 0.529082\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466796; batch adversarial loss: 0.563082\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424801; batch adversarial loss: 0.519592\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446942; batch adversarial loss: 0.477407\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398678; batch adversarial loss: 0.510968\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425377; batch adversarial loss: 0.518696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497413; batch adversarial loss: 0.579577\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445224; batch adversarial loss: 0.615218\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418243; batch adversarial loss: 0.553519\n",
      "epoch 40; iter: 0; batch classifier loss: 0.392342; batch adversarial loss: 0.580232\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486943; batch adversarial loss: 0.598177\n",
      "epoch 42; iter: 0; batch classifier loss: 0.493964; batch adversarial loss: 0.571181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431200; batch adversarial loss: 0.490266\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407000; batch adversarial loss: 0.553454\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453303; batch adversarial loss: 0.598802\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420065; batch adversarial loss: 0.518105\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422584; batch adversarial loss: 0.688255\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402274; batch adversarial loss: 0.481720\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409373; batch adversarial loss: 0.535460\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479805; batch adversarial loss: 0.489602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.465938; batch adversarial loss: 0.571519\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449955; batch adversarial loss: 0.572623\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359887; batch adversarial loss: 0.518038\n",
      "epoch 54; iter: 0; batch classifier loss: 0.466047; batch adversarial loss: 0.581027\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412101; batch adversarial loss: 0.533981\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451523; batch adversarial loss: 0.471321\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411360; batch adversarial loss: 0.490310\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420103; batch adversarial loss: 0.544259\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384823; batch adversarial loss: 0.571835\n",
      "epoch 60; iter: 0; batch classifier loss: 0.541393; batch adversarial loss: 0.472179\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380112; batch adversarial loss: 0.526873\n",
      "epoch 62; iter: 0; batch classifier loss: 0.464282; batch adversarial loss: 0.571480\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439469; batch adversarial loss: 0.553593\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402666; batch adversarial loss: 0.509027\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420586; batch adversarial loss: 0.500805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.353954; batch adversarial loss: 0.579136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426076; batch adversarial loss: 0.482151\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422989; batch adversarial loss: 0.624609\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392608; batch adversarial loss: 0.526681\n",
      "epoch 70; iter: 0; batch classifier loss: 0.310454; batch adversarial loss: 0.644820\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416618; batch adversarial loss: 0.516763\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400953; batch adversarial loss: 0.598548\n",
      "epoch 73; iter: 0; batch classifier loss: 0.399578; batch adversarial loss: 0.572144\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397234; batch adversarial loss: 0.518689\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443389; batch adversarial loss: 0.617759\n",
      "epoch 76; iter: 0; batch classifier loss: 0.348884; batch adversarial loss: 0.471712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.457936; batch adversarial loss: 0.608308\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461249; batch adversarial loss: 0.580421\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411245; batch adversarial loss: 0.599004\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409461; batch adversarial loss: 0.562749\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351966; batch adversarial loss: 0.598922\n",
      "epoch 82; iter: 0; batch classifier loss: 0.451992; batch adversarial loss: 0.590158\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396777; batch adversarial loss: 0.526720\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421837; batch adversarial loss: 0.580322\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400040; batch adversarial loss: 0.545270\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409981; batch adversarial loss: 0.552874\n",
      "epoch 87; iter: 0; batch classifier loss: 0.495958; batch adversarial loss: 0.525732\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367169; batch adversarial loss: 0.536203\n",
      "epoch 89; iter: 0; batch classifier loss: 0.507531; batch adversarial loss: 0.572712\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456188; batch adversarial loss: 0.580257\n",
      "epoch 91; iter: 0; batch classifier loss: 0.350593; batch adversarial loss: 0.534277\n",
      "epoch 92; iter: 0; batch classifier loss: 0.352892; batch adversarial loss: 0.526855\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439606; batch adversarial loss: 0.563727\n",
      "epoch 94; iter: 0; batch classifier loss: 0.486493; batch adversarial loss: 0.526333\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402500; batch adversarial loss: 0.572015\n",
      "epoch 96; iter: 0; batch classifier loss: 0.351362; batch adversarial loss: 0.535872\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359157; batch adversarial loss: 0.536047\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359945; batch adversarial loss: 0.562301\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361850; batch adversarial loss: 0.590556\n",
      "epoch 100; iter: 0; batch classifier loss: 0.466940; batch adversarial loss: 0.670355\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394996; batch adversarial loss: 0.507911\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392225; batch adversarial loss: 0.533984\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382466; batch adversarial loss: 0.596969\n",
      "epoch 104; iter: 0; batch classifier loss: 0.338182; batch adversarial loss: 0.570692\n",
      "epoch 105; iter: 0; batch classifier loss: 0.429967; batch adversarial loss: 0.544122\n",
      "epoch 106; iter: 0; batch classifier loss: 0.442590; batch adversarial loss: 0.498683\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447088; batch adversarial loss: 0.562747\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389798; batch adversarial loss: 0.488211\n",
      "epoch 109; iter: 0; batch classifier loss: 0.312678; batch adversarial loss: 0.610513\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429743; batch adversarial loss: 0.526299\n",
      "epoch 111; iter: 0; batch classifier loss: 0.351745; batch adversarial loss: 0.582390\n",
      "epoch 112; iter: 0; batch classifier loss: 0.335356; batch adversarial loss: 0.608654\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392100; batch adversarial loss: 0.554731\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391434; batch adversarial loss: 0.589104\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423626; batch adversarial loss: 0.563625\n",
      "epoch 116; iter: 0; batch classifier loss: 0.468311; batch adversarial loss: 0.526368\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357392; batch adversarial loss: 0.589516\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375936; batch adversarial loss: 0.535751\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323107; batch adversarial loss: 0.617194\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380890; batch adversarial loss: 0.544657\n",
      "epoch 121; iter: 0; batch classifier loss: 0.421014; batch adversarial loss: 0.536020\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380038; batch adversarial loss: 0.627305\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400884; batch adversarial loss: 0.508421\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340578; batch adversarial loss: 0.435971\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365938; batch adversarial loss: 0.471922\n",
      "epoch 126; iter: 0; batch classifier loss: 0.513844; batch adversarial loss: 0.536398\n",
      "epoch 127; iter: 0; batch classifier loss: 0.292637; batch adversarial loss: 0.544524\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403420; batch adversarial loss: 0.533490\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431084; batch adversarial loss: 0.472417\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408917; batch adversarial loss: 0.554061\n",
      "epoch 131; iter: 0; batch classifier loss: 0.417157; batch adversarial loss: 0.517077\n",
      "epoch 132; iter: 0; batch classifier loss: 0.438749; batch adversarial loss: 0.587736\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344830; batch adversarial loss: 0.517562\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399106; batch adversarial loss: 0.570789\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382306; batch adversarial loss: 0.634703\n",
      "epoch 136; iter: 0; batch classifier loss: 0.451143; batch adversarial loss: 0.517421\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400944; batch adversarial loss: 0.562981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.435631; batch adversarial loss: 0.546308\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428929; batch adversarial loss: 0.562712\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393101; batch adversarial loss: 0.607684\n",
      "epoch 141; iter: 0; batch classifier loss: 0.314202; batch adversarial loss: 0.616808\n",
      "epoch 142; iter: 0; batch classifier loss: 0.366291; batch adversarial loss: 0.608119\n",
      "epoch 143; iter: 0; batch classifier loss: 0.403008; batch adversarial loss: 0.546196\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398526; batch adversarial loss: 0.508584\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346258; batch adversarial loss: 0.562939\n",
      "epoch 146; iter: 0; batch classifier loss: 0.319594; batch adversarial loss: 0.607959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.440223; batch adversarial loss: 0.499386\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346506; batch adversarial loss: 0.562543\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409409; batch adversarial loss: 0.590109\n",
      "epoch 150; iter: 0; batch classifier loss: 0.335489; batch adversarial loss: 0.535866\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399726; batch adversarial loss: 0.509068\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353599; batch adversarial loss: 0.517626\n",
      "epoch 153; iter: 0; batch classifier loss: 0.425552; batch adversarial loss: 0.587200\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379650; batch adversarial loss: 0.625595\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369488; batch adversarial loss: 0.581256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.431614; batch adversarial loss: 0.581009\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353471; batch adversarial loss: 0.571912\n",
      "epoch 158; iter: 0; batch classifier loss: 0.292881; batch adversarial loss: 0.498895\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359673; batch adversarial loss: 0.562741\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319521; batch adversarial loss: 0.480777\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397641; batch adversarial loss: 0.544392\n",
      "epoch 162; iter: 0; batch classifier loss: 0.395094; batch adversarial loss: 0.589699\n",
      "epoch 163; iter: 0; batch classifier loss: 0.277361; batch adversarial loss: 0.544199\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409359; batch adversarial loss: 0.526085\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360513; batch adversarial loss: 0.517097\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373800; batch adversarial loss: 0.491578\n",
      "epoch 167; iter: 0; batch classifier loss: 0.436616; batch adversarial loss: 0.560626\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393285; batch adversarial loss: 0.623781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419803; batch adversarial loss: 0.527110\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398188; batch adversarial loss: 0.533802\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333810; batch adversarial loss: 0.581344\n",
      "epoch 172; iter: 0; batch classifier loss: 0.420193; batch adversarial loss: 0.599275\n",
      "epoch 173; iter: 0; batch classifier loss: 0.294127; batch adversarial loss: 0.544833\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364739; batch adversarial loss: 0.526778\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343279; batch adversarial loss: 0.581824\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383874; batch adversarial loss: 0.562240\n",
      "epoch 177; iter: 0; batch classifier loss: 0.353768; batch adversarial loss: 0.623130\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363455; batch adversarial loss: 0.489776\n",
      "epoch 179; iter: 0; batch classifier loss: 0.416203; batch adversarial loss: 0.544992\n",
      "epoch 180; iter: 0; batch classifier loss: 0.412360; batch adversarial loss: 0.590876\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333148; batch adversarial loss: 0.608041\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314882; batch adversarial loss: 0.481892\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348684; batch adversarial loss: 0.499780\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378075; batch adversarial loss: 0.535062\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399002; batch adversarial loss: 0.598579\n",
      "epoch 186; iter: 0; batch classifier loss: 0.320205; batch adversarial loss: 0.615219\n",
      "epoch 187; iter: 0; batch classifier loss: 0.309962; batch adversarial loss: 0.516815\n",
      "epoch 188; iter: 0; batch classifier loss: 0.401218; batch adversarial loss: 0.643967\n",
      "epoch 189; iter: 0; batch classifier loss: 0.393807; batch adversarial loss: 0.500497\n",
      "epoch 190; iter: 0; batch classifier loss: 0.353205; batch adversarial loss: 0.524920\n",
      "epoch 191; iter: 0; batch classifier loss: 0.371745; batch adversarial loss: 0.589759\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343061; batch adversarial loss: 0.535628\n",
      "epoch 193; iter: 0; batch classifier loss: 0.366996; batch adversarial loss: 0.517582\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365538; batch adversarial loss: 0.582307\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390708; batch adversarial loss: 0.563975\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341065; batch adversarial loss: 0.580777\n",
      "epoch 197; iter: 0; batch classifier loss: 0.359854; batch adversarial loss: 0.525160\n",
      "epoch 198; iter: 0; batch classifier loss: 0.464430; batch adversarial loss: 0.553422\n",
      "epoch 199; iter: 0; batch classifier loss: 0.368737; batch adversarial loss: 0.572709\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719725; batch adversarial loss: 0.586981\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649270; batch adversarial loss: 0.640089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625264; batch adversarial loss: 0.597726\n",
      "epoch 3; iter: 0; batch classifier loss: 0.574864; batch adversarial loss: 0.678144\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555119; batch adversarial loss: 0.654685\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581211; batch adversarial loss: 0.647403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559768; batch adversarial loss: 0.635258\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518229; batch adversarial loss: 0.628948\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579994; batch adversarial loss: 0.554178\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634459; batch adversarial loss: 0.590250\n",
      "epoch 10; iter: 0; batch classifier loss: 0.627296; batch adversarial loss: 0.594940\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539710; batch adversarial loss: 0.518853\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559392; batch adversarial loss: 0.557348\n",
      "epoch 13; iter: 0; batch classifier loss: 0.598371; batch adversarial loss: 0.556163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502500; batch adversarial loss: 0.602476\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529373; batch adversarial loss: 0.501667\n",
      "epoch 16; iter: 0; batch classifier loss: 0.611399; batch adversarial loss: 0.622440\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473976; batch adversarial loss: 0.599477\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465280; batch adversarial loss: 0.503934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491864; batch adversarial loss: 0.524955\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517833; batch adversarial loss: 0.617920\n",
      "epoch 21; iter: 0; batch classifier loss: 0.425158; batch adversarial loss: 0.536966\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502046; batch adversarial loss: 0.501643\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461221; batch adversarial loss: 0.567606\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436853; batch adversarial loss: 0.561036\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449161; batch adversarial loss: 0.621520\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498427; batch adversarial loss: 0.549392\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444339; batch adversarial loss: 0.639472\n",
      "epoch 28; iter: 0; batch classifier loss: 0.500154; batch adversarial loss: 0.521086\n",
      "epoch 29; iter: 0; batch classifier loss: 0.415377; batch adversarial loss: 0.555553\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466697; batch adversarial loss: 0.589092\n",
      "epoch 31; iter: 0; batch classifier loss: 0.394445; batch adversarial loss: 0.614974\n",
      "epoch 32; iter: 0; batch classifier loss: 0.406665; batch adversarial loss: 0.457891\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420285; batch adversarial loss: 0.511621\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476130; batch adversarial loss: 0.633767\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490062; batch adversarial loss: 0.571780\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468239; batch adversarial loss: 0.606055\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394685; batch adversarial loss: 0.597010\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420197; batch adversarial loss: 0.500996\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473700; batch adversarial loss: 0.536660\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459220; batch adversarial loss: 0.571740\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477578; batch adversarial loss: 0.553326\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471938; batch adversarial loss: 0.553596\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447230; batch adversarial loss: 0.607090\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467737; batch adversarial loss: 0.446413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.505312; batch adversarial loss: 0.553327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414383; batch adversarial loss: 0.500397\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423494; batch adversarial loss: 0.571373\n",
      "epoch 48; iter: 0; batch classifier loss: 0.476153; batch adversarial loss: 0.606259\n",
      "epoch 49; iter: 0; batch classifier loss: 0.344899; batch adversarial loss: 0.526810\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406254; batch adversarial loss: 0.544866\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420628; batch adversarial loss: 0.501143\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424477; batch adversarial loss: 0.606239\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397259; batch adversarial loss: 0.562364\n",
      "epoch 54; iter: 0; batch classifier loss: 0.441725; batch adversarial loss: 0.563310\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406094; batch adversarial loss: 0.511559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428962; batch adversarial loss: 0.570559\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450351; batch adversarial loss: 0.510559\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426383; batch adversarial loss: 0.518701\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383854; batch adversarial loss: 0.642750\n",
      "epoch 60; iter: 0; batch classifier loss: 0.458248; batch adversarial loss: 0.564619\n",
      "epoch 61; iter: 0; batch classifier loss: 0.360197; batch adversarial loss: 0.553289\n",
      "epoch 62; iter: 0; batch classifier loss: 0.536919; batch adversarial loss: 0.499773\n",
      "epoch 63; iter: 0; batch classifier loss: 0.332866; batch adversarial loss: 0.536038\n",
      "epoch 64; iter: 0; batch classifier loss: 0.396991; batch adversarial loss: 0.562790\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419893; batch adversarial loss: 0.545087\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389245; batch adversarial loss: 0.526957\n",
      "epoch 67; iter: 0; batch classifier loss: 0.348822; batch adversarial loss: 0.563248\n",
      "epoch 68; iter: 0; batch classifier loss: 0.537650; batch adversarial loss: 0.586751\n",
      "epoch 69; iter: 0; batch classifier loss: 0.471913; batch adversarial loss: 0.571722\n",
      "epoch 70; iter: 0; batch classifier loss: 0.463881; batch adversarial loss: 0.555608\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405759; batch adversarial loss: 0.508107\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444154; batch adversarial loss: 0.554256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425476; batch adversarial loss: 0.553785\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381301; batch adversarial loss: 0.446393\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404151; batch adversarial loss: 0.500192\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358279; batch adversarial loss: 0.615655\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411805; batch adversarial loss: 0.598116\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358307; batch adversarial loss: 0.429073\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369988; batch adversarial loss: 0.598462\n",
      "epoch 80; iter: 0; batch classifier loss: 0.318765; batch adversarial loss: 0.571546\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399225; batch adversarial loss: 0.508958\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400098; batch adversarial loss: 0.553490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.460070; batch adversarial loss: 0.597615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.414005; batch adversarial loss: 0.571243\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377024; batch adversarial loss: 0.632549\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353189; batch adversarial loss: 0.579678\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346199; batch adversarial loss: 0.499980\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392226; batch adversarial loss: 0.606185\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398534; batch adversarial loss: 0.561702\n",
      "epoch 90; iter: 0; batch classifier loss: 0.300155; batch adversarial loss: 0.519686\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365895; batch adversarial loss: 0.571778\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432366; batch adversarial loss: 0.492127\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337005; batch adversarial loss: 0.535347\n",
      "epoch 94; iter: 0; batch classifier loss: 0.481227; batch adversarial loss: 0.652262\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423962; batch adversarial loss: 0.606443\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401832; batch adversarial loss: 0.541708\n",
      "epoch 97; iter: 0; batch classifier loss: 0.347308; batch adversarial loss: 0.544083\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373940; batch adversarial loss: 0.544552\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460276; batch adversarial loss: 0.608463\n",
      "epoch 100; iter: 0; batch classifier loss: 0.430254; batch adversarial loss: 0.552960\n",
      "epoch 101; iter: 0; batch classifier loss: 0.424176; batch adversarial loss: 0.626078\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393950; batch adversarial loss: 0.588135\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429763; batch adversarial loss: 0.481517\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371472; batch adversarial loss: 0.544275\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410438; batch adversarial loss: 0.517846\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434560; batch adversarial loss: 0.587151\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358174; batch adversarial loss: 0.562259\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354235; batch adversarial loss: 0.562511\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396484; batch adversarial loss: 0.571395\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402385; batch adversarial loss: 0.534239\n",
      "epoch 111; iter: 0; batch classifier loss: 0.411787; batch adversarial loss: 0.573187\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375961; batch adversarial loss: 0.509191\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335735; batch adversarial loss: 0.539789\n",
      "epoch 114; iter: 0; batch classifier loss: 0.296315; batch adversarial loss: 0.536167\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396366; batch adversarial loss: 0.573285\n",
      "epoch 116; iter: 0; batch classifier loss: 0.296212; batch adversarial loss: 0.517986\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379490; batch adversarial loss: 0.571514\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391883; batch adversarial loss: 0.563046\n",
      "epoch 119; iter: 0; batch classifier loss: 0.460782; batch adversarial loss: 0.545013\n",
      "epoch 120; iter: 0; batch classifier loss: 0.325741; batch adversarial loss: 0.563033\n",
      "epoch 121; iter: 0; batch classifier loss: 0.473959; batch adversarial loss: 0.634911\n",
      "epoch 122; iter: 0; batch classifier loss: 0.431492; batch adversarial loss: 0.544561\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361429; batch adversarial loss: 0.517654\n",
      "epoch 124; iter: 0; batch classifier loss: 0.306044; batch adversarial loss: 0.544665\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411361; batch adversarial loss: 0.562847\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348343; batch adversarial loss: 0.544003\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362516; batch adversarial loss: 0.553027\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409051; batch adversarial loss: 0.536486\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329968; batch adversarial loss: 0.517602\n",
      "epoch 130; iter: 0; batch classifier loss: 0.524251; batch adversarial loss: 0.526098\n",
      "epoch 131; iter: 0; batch classifier loss: 0.415280; batch adversarial loss: 0.622170\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327329; batch adversarial loss: 0.572438\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357558; batch adversarial loss: 0.596752\n",
      "epoch 134; iter: 0; batch classifier loss: 0.290047; batch adversarial loss: 0.528179\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356207; batch adversarial loss: 0.499800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.344976; batch adversarial loss: 0.508774\n",
      "epoch 137; iter: 0; batch classifier loss: 0.422260; batch adversarial loss: 0.544717\n",
      "epoch 138; iter: 0; batch classifier loss: 0.336144; batch adversarial loss: 0.517729\n",
      "epoch 139; iter: 0; batch classifier loss: 0.329046; batch adversarial loss: 0.607056\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338344; batch adversarial loss: 0.508122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.365545; batch adversarial loss: 0.571215\n",
      "epoch 142; iter: 0; batch classifier loss: 0.323386; batch adversarial loss: 0.509045\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353325; batch adversarial loss: 0.508619\n",
      "epoch 144; iter: 0; batch classifier loss: 0.306238; batch adversarial loss: 0.580667\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366674; batch adversarial loss: 0.508785\n",
      "epoch 146; iter: 0; batch classifier loss: 0.429088; batch adversarial loss: 0.526820\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391234; batch adversarial loss: 0.508988\n",
      "epoch 148; iter: 0; batch classifier loss: 0.390675; batch adversarial loss: 0.615970\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351438; batch adversarial loss: 0.490448\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387028; batch adversarial loss: 0.491139\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357802; batch adversarial loss: 0.562539\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391527; batch adversarial loss: 0.509328\n",
      "epoch 153; iter: 0; batch classifier loss: 0.419160; batch adversarial loss: 0.633470\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385891; batch adversarial loss: 0.588971\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327995; batch adversarial loss: 0.508964\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379927; batch adversarial loss: 0.499962\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352572; batch adversarial loss: 0.517740\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360373; batch adversarial loss: 0.607506\n",
      "epoch 159; iter: 0; batch classifier loss: 0.358789; batch adversarial loss: 0.650952\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401833; batch adversarial loss: 0.491186\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363826; batch adversarial loss: 0.499977\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353730; batch adversarial loss: 0.535827\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367285; batch adversarial loss: 0.607404\n",
      "epoch 164; iter: 0; batch classifier loss: 0.370907; batch adversarial loss: 0.571930\n",
      "epoch 165; iter: 0; batch classifier loss: 0.298060; batch adversarial loss: 0.535790\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378814; batch adversarial loss: 0.607146\n",
      "epoch 167; iter: 0; batch classifier loss: 0.299114; batch adversarial loss: 0.500581\n",
      "epoch 168; iter: 0; batch classifier loss: 0.407001; batch adversarial loss: 0.589370\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371000; batch adversarial loss: 0.518259\n",
      "epoch 170; iter: 0; batch classifier loss: 0.460496; batch adversarial loss: 0.499991\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403690; batch adversarial loss: 0.615976\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359913; batch adversarial loss: 0.615869\n",
      "epoch 173; iter: 0; batch classifier loss: 0.426503; batch adversarial loss: 0.562418\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376936; batch adversarial loss: 0.509060\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344683; batch adversarial loss: 0.527444\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374331; batch adversarial loss: 0.491653\n",
      "epoch 177; iter: 0; batch classifier loss: 0.409837; batch adversarial loss: 0.544445\n",
      "epoch 178; iter: 0; batch classifier loss: 0.433920; batch adversarial loss: 0.553312\n",
      "epoch 179; iter: 0; batch classifier loss: 0.324285; batch adversarial loss: 0.553910\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387902; batch adversarial loss: 0.527192\n",
      "epoch 181; iter: 0; batch classifier loss: 0.434483; batch adversarial loss: 0.509077\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324455; batch adversarial loss: 0.509411\n",
      "epoch 183; iter: 0; batch classifier loss: 0.328211; batch adversarial loss: 0.544737\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355939; batch adversarial loss: 0.589144\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373979; batch adversarial loss: 0.500115\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396150; batch adversarial loss: 0.491287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.456292; batch adversarial loss: 0.553391\n",
      "epoch 188; iter: 0; batch classifier loss: 0.339622; batch adversarial loss: 0.527198\n",
      "epoch 189; iter: 0; batch classifier loss: 0.487035; batch adversarial loss: 0.518789\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349474; batch adversarial loss: 0.518076\n",
      "epoch 191; iter: 0; batch classifier loss: 0.385427; batch adversarial loss: 0.552983\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351833; batch adversarial loss: 0.553739\n",
      "epoch 193; iter: 0; batch classifier loss: 0.285964; batch adversarial loss: 0.562549\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403178; batch adversarial loss: 0.615656\n",
      "epoch 195; iter: 0; batch classifier loss: 0.315331; batch adversarial loss: 0.589135\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336906; batch adversarial loss: 0.500211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.432743; batch adversarial loss: 0.562637\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376441; batch adversarial loss: 0.543995\n",
      "epoch 199; iter: 0; batch classifier loss: 0.416145; batch adversarial loss: 0.562408\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676485; batch adversarial loss: 0.754078\n",
      "epoch 1; iter: 0; batch classifier loss: 0.699082; batch adversarial loss: 0.748904\n",
      "epoch 2; iter: 0; batch classifier loss: 0.702342; batch adversarial loss: 0.696991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.749362; batch adversarial loss: 0.642420\n",
      "epoch 4; iter: 0; batch classifier loss: 0.700378; batch adversarial loss: 0.593704\n",
      "epoch 5; iter: 0; batch classifier loss: 0.625319; batch adversarial loss: 0.611720\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563980; batch adversarial loss: 0.591986\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553209; batch adversarial loss: 0.610138\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581850; batch adversarial loss: 0.555207\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532566; batch adversarial loss: 0.570284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500456; batch adversarial loss: 0.523700\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549289; batch adversarial loss: 0.558477\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547516; batch adversarial loss: 0.577689\n",
      "epoch 13; iter: 0; batch classifier loss: 0.463917; batch adversarial loss: 0.560651\n",
      "epoch 14; iter: 0; batch classifier loss: 0.581778; batch adversarial loss: 0.512912\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505666; batch adversarial loss: 0.548629\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479256; batch adversarial loss: 0.593344\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531788; batch adversarial loss: 0.592879\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526880; batch adversarial loss: 0.580208\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480657; batch adversarial loss: 0.555367\n",
      "epoch 20; iter: 0; batch classifier loss: 0.531817; batch adversarial loss: 0.569518\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464463; batch adversarial loss: 0.573816\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447805; batch adversarial loss: 0.605630\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454654; batch adversarial loss: 0.633608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508765; batch adversarial loss: 0.545081\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474815; batch adversarial loss: 0.489940\n",
      "epoch 26; iter: 0; batch classifier loss: 0.558852; batch adversarial loss: 0.576029\n",
      "epoch 27; iter: 0; batch classifier loss: 0.423187; batch adversarial loss: 0.550374\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455673; batch adversarial loss: 0.556773\n",
      "epoch 29; iter: 0; batch classifier loss: 0.583060; batch adversarial loss: 0.491448\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486805; batch adversarial loss: 0.547041\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511505; batch adversarial loss: 0.538193\n",
      "epoch 32; iter: 0; batch classifier loss: 0.558682; batch adversarial loss: 0.596102\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457369; batch adversarial loss: 0.512462\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497603; batch adversarial loss: 0.536885\n",
      "epoch 35; iter: 0; batch classifier loss: 0.495516; batch adversarial loss: 0.615803\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451105; batch adversarial loss: 0.623908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.398294; batch adversarial loss: 0.518948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.433830; batch adversarial loss: 0.562515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424761; batch adversarial loss: 0.518459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417413; batch adversarial loss: 0.526948\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457806; batch adversarial loss: 0.625046\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424907; batch adversarial loss: 0.526299\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414224; batch adversarial loss: 0.508521\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463842; batch adversarial loss: 0.517687\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428552; batch adversarial loss: 0.580761\n",
      "epoch 46; iter: 0; batch classifier loss: 0.530213; batch adversarial loss: 0.544026\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406066; batch adversarial loss: 0.472417\n",
      "epoch 48; iter: 0; batch classifier loss: 0.539372; batch adversarial loss: 0.509132\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411716; batch adversarial loss: 0.543969\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424249; batch adversarial loss: 0.553346\n",
      "epoch 51; iter: 0; batch classifier loss: 0.366104; batch adversarial loss: 0.490182\n",
      "epoch 52; iter: 0; batch classifier loss: 0.474244; batch adversarial loss: 0.534439\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418124; batch adversarial loss: 0.553639\n",
      "epoch 54; iter: 0; batch classifier loss: 0.356956; batch adversarial loss: 0.637239\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414137; batch adversarial loss: 0.616998\n",
      "epoch 56; iter: 0; batch classifier loss: 0.521757; batch adversarial loss: 0.553870\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409138; batch adversarial loss: 0.535568\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402854; batch adversarial loss: 0.553030\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411213; batch adversarial loss: 0.607041\n",
      "epoch 60; iter: 0; batch classifier loss: 0.438829; batch adversarial loss: 0.563209\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424469; batch adversarial loss: 0.527489\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405877; batch adversarial loss: 0.597851\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461203; batch adversarial loss: 0.444611\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426592; batch adversarial loss: 0.501195\n",
      "epoch 65; iter: 0; batch classifier loss: 0.368255; batch adversarial loss: 0.544330\n",
      "epoch 66; iter: 0; batch classifier loss: 0.371900; batch adversarial loss: 0.617563\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363688; batch adversarial loss: 0.525734\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409375; batch adversarial loss: 0.628965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449413; batch adversarial loss: 0.553611\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404139; batch adversarial loss: 0.554651\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386773; batch adversarial loss: 0.544760\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401861; batch adversarial loss: 0.578457\n",
      "epoch 73; iter: 0; batch classifier loss: 0.452113; batch adversarial loss: 0.525757\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424523; batch adversarial loss: 0.597138\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370848; batch adversarial loss: 0.552124\n",
      "epoch 76; iter: 0; batch classifier loss: 0.446405; batch adversarial loss: 0.625057\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373328; batch adversarial loss: 0.472884\n",
      "epoch 78; iter: 0; batch classifier loss: 0.364746; batch adversarial loss: 0.499509\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409156; batch adversarial loss: 0.526792\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403030; batch adversarial loss: 0.516684\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402908; batch adversarial loss: 0.469388\n",
      "epoch 82; iter: 0; batch classifier loss: 0.472936; batch adversarial loss: 0.673652\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403875; batch adversarial loss: 0.596947\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413702; batch adversarial loss: 0.577633\n",
      "epoch 85; iter: 0; batch classifier loss: 0.509646; batch adversarial loss: 0.480117\n",
      "epoch 86; iter: 0; batch classifier loss: 0.477516; batch adversarial loss: 0.561093\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367702; batch adversarial loss: 0.573895\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358119; batch adversarial loss: 0.562796\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378153; batch adversarial loss: 0.526631\n",
      "epoch 90; iter: 0; batch classifier loss: 0.421799; batch adversarial loss: 0.517789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372319; batch adversarial loss: 0.517271\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354636; batch adversarial loss: 0.555345\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341712; batch adversarial loss: 0.527789\n",
      "epoch 94; iter: 0; batch classifier loss: 0.459835; batch adversarial loss: 0.517873\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427488; batch adversarial loss: 0.608866\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373409; batch adversarial loss: 0.480673\n",
      "epoch 97; iter: 0; batch classifier loss: 0.417346; batch adversarial loss: 0.588838\n",
      "epoch 98; iter: 0; batch classifier loss: 0.333881; batch adversarial loss: 0.516266\n",
      "epoch 99; iter: 0; batch classifier loss: 0.325138; batch adversarial loss: 0.571491\n",
      "epoch 100; iter: 0; batch classifier loss: 0.407531; batch adversarial loss: 0.561242\n",
      "epoch 101; iter: 0; batch classifier loss: 0.432248; batch adversarial loss: 0.515320\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381022; batch adversarial loss: 0.588574\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379121; batch adversarial loss: 0.587443\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385000; batch adversarial loss: 0.550826\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342849; batch adversarial loss: 0.571800\n",
      "epoch 106; iter: 0; batch classifier loss: 0.431864; batch adversarial loss: 0.533965\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357383; batch adversarial loss: 0.544796\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393163; batch adversarial loss: 0.572017\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407711; batch adversarial loss: 0.515291\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373673; batch adversarial loss: 0.554677\n",
      "epoch 111; iter: 0; batch classifier loss: 0.326037; batch adversarial loss: 0.598914\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391832; batch adversarial loss: 0.598626\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383634; batch adversarial loss: 0.651692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381953; batch adversarial loss: 0.462445\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383376; batch adversarial loss: 0.589639\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341191; batch adversarial loss: 0.518120\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411578; batch adversarial loss: 0.545666\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373242; batch adversarial loss: 0.526545\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395253; batch adversarial loss: 0.507458\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374954; batch adversarial loss: 0.562229\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307545; batch adversarial loss: 0.567585\n",
      "epoch 122; iter: 0; batch classifier loss: 0.438134; batch adversarial loss: 0.656163\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408287; batch adversarial loss: 0.581276\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379351; batch adversarial loss: 0.645897\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332595; batch adversarial loss: 0.587218\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372259; batch adversarial loss: 0.555071\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360143; batch adversarial loss: 0.600804\n",
      "epoch 128; iter: 0; batch classifier loss: 0.440494; batch adversarial loss: 0.453365\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391588; batch adversarial loss: 0.462586\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393088; batch adversarial loss: 0.598861\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382561; batch adversarial loss: 0.562074\n",
      "epoch 132; iter: 0; batch classifier loss: 0.422282; batch adversarial loss: 0.599925\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378938; batch adversarial loss: 0.524489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.396253; batch adversarial loss: 0.543667\n",
      "epoch 135; iter: 0; batch classifier loss: 0.344651; batch adversarial loss: 0.570404\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401084; batch adversarial loss: 0.497918\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305108; batch adversarial loss: 0.644233\n",
      "epoch 138; iter: 0; batch classifier loss: 0.383547; batch adversarial loss: 0.488055\n",
      "epoch 139; iter: 0; batch classifier loss: 0.411386; batch adversarial loss: 0.551502\n",
      "epoch 140; iter: 0; batch classifier loss: 0.453162; batch adversarial loss: 0.563380\n",
      "epoch 141; iter: 0; batch classifier loss: 0.321604; batch adversarial loss: 0.487540\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370688; batch adversarial loss: 0.573126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368191; batch adversarial loss: 0.544441\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329515; batch adversarial loss: 0.600237\n",
      "epoch 145; iter: 0; batch classifier loss: 0.491930; batch adversarial loss: 0.570618\n",
      "epoch 146; iter: 0; batch classifier loss: 0.453935; batch adversarial loss: 0.590625\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384891; batch adversarial loss: 0.515400\n",
      "epoch 148; iter: 0; batch classifier loss: 0.383470; batch adversarial loss: 0.552827\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375354; batch adversarial loss: 0.498357\n",
      "epoch 150; iter: 0; batch classifier loss: 0.420701; batch adversarial loss: 0.591066\n",
      "epoch 151; iter: 0; batch classifier loss: 0.287233; batch adversarial loss: 0.586888\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374308; batch adversarial loss: 0.547001\n",
      "epoch 153; iter: 0; batch classifier loss: 0.377253; batch adversarial loss: 0.469867\n",
      "epoch 154; iter: 0; batch classifier loss: 0.409781; batch adversarial loss: 0.552382\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354379; batch adversarial loss: 0.607124\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372955; batch adversarial loss: 0.544164\n",
      "epoch 157; iter: 0; batch classifier loss: 0.471286; batch adversarial loss: 0.579401\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375068; batch adversarial loss: 0.506323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341521; batch adversarial loss: 0.621478\n",
      "epoch 160; iter: 0; batch classifier loss: 0.455190; batch adversarial loss: 0.507718\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424474; batch adversarial loss: 0.525286\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326328; batch adversarial loss: 0.597674\n",
      "epoch 163; iter: 0; batch classifier loss: 0.398150; batch adversarial loss: 0.479912\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395447; batch adversarial loss: 0.507789\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382118; batch adversarial loss: 0.526170\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387008; batch adversarial loss: 0.639876\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370872; batch adversarial loss: 0.526002\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317701; batch adversarial loss: 0.674494\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365996; batch adversarial loss: 0.563158\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385220; batch adversarial loss: 0.510539\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338527; batch adversarial loss: 0.518879\n",
      "epoch 172; iter: 0; batch classifier loss: 0.296228; batch adversarial loss: 0.507943\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401678; batch adversarial loss: 0.562701\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374243; batch adversarial loss: 0.561700\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388280; batch adversarial loss: 0.608068\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356338; batch adversarial loss: 0.517520\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381200; batch adversarial loss: 0.523268\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331474; batch adversarial loss: 0.562721\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367371; batch adversarial loss: 0.535342\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359411; batch adversarial loss: 0.543288\n",
      "epoch 181; iter: 0; batch classifier loss: 0.378544; batch adversarial loss: 0.538024\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374848; batch adversarial loss: 0.553738\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355371; batch adversarial loss: 0.609807\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357934; batch adversarial loss: 0.524629\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321890; batch adversarial loss: 0.608269\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326970; batch adversarial loss: 0.598896\n",
      "epoch 187; iter: 0; batch classifier loss: 0.378626; batch adversarial loss: 0.533913\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314412; batch adversarial loss: 0.553050\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305987; batch adversarial loss: 0.618582\n",
      "epoch 190; iter: 0; batch classifier loss: 0.348337; batch adversarial loss: 0.588297\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351393; batch adversarial loss: 0.552103\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352499; batch adversarial loss: 0.607079\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398257; batch adversarial loss: 0.570497\n",
      "epoch 194; iter: 0; batch classifier loss: 0.370809; batch adversarial loss: 0.652242\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370895; batch adversarial loss: 0.580069\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358813; batch adversarial loss: 0.571909\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322325; batch adversarial loss: 0.619533\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323355; batch adversarial loss: 0.618102\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385305; batch adversarial loss: 0.648400\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747530; batch adversarial loss: 0.608467\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601102; batch adversarial loss: 0.649452\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565971; batch adversarial loss: 0.643666\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542606; batch adversarial loss: 0.654643\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606191; batch adversarial loss: 0.679169\n",
      "epoch 5; iter: 0; batch classifier loss: 0.481863; batch adversarial loss: 0.620943\n",
      "epoch 6; iter: 0; batch classifier loss: 0.668320; batch adversarial loss: 0.674728\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549316; batch adversarial loss: 0.660494\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600655; batch adversarial loss: 0.624743\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474756; batch adversarial loss: 0.657002\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592653; batch adversarial loss: 0.615617\n",
      "epoch 11; iter: 0; batch classifier loss: 0.602673; batch adversarial loss: 0.604376\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500948; batch adversarial loss: 0.582137\n",
      "epoch 13; iter: 0; batch classifier loss: 0.456162; batch adversarial loss: 0.565354\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477636; batch adversarial loss: 0.624959\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508287; batch adversarial loss: 0.567874\n",
      "epoch 16; iter: 0; batch classifier loss: 0.629854; batch adversarial loss: 0.625435\n",
      "epoch 17; iter: 0; batch classifier loss: 0.572792; batch adversarial loss: 0.587895\n",
      "epoch 18; iter: 0; batch classifier loss: 0.579584; batch adversarial loss: 0.524330\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536674; batch adversarial loss: 0.603610\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490508; batch adversarial loss: 0.541315\n",
      "epoch 21; iter: 0; batch classifier loss: 0.417421; batch adversarial loss: 0.603565\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501897; batch adversarial loss: 0.602914\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516961; batch adversarial loss: 0.603609\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491855; batch adversarial loss: 0.506101\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486582; batch adversarial loss: 0.627579\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543321; batch adversarial loss: 0.586905\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462648; batch adversarial loss: 0.545964\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484166; batch adversarial loss: 0.537165\n",
      "epoch 29; iter: 0; batch classifier loss: 0.400005; batch adversarial loss: 0.511365\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450961; batch adversarial loss: 0.519769\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439590; batch adversarial loss: 0.570480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.460698; batch adversarial loss: 0.450371\n",
      "epoch 33; iter: 0; batch classifier loss: 0.495801; batch adversarial loss: 0.579770\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467903; batch adversarial loss: 0.519122\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448351; batch adversarial loss: 0.621797\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441134; batch adversarial loss: 0.518871\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456521; batch adversarial loss: 0.528750\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432522; batch adversarial loss: 0.553707\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498345; batch adversarial loss: 0.527673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470825; batch adversarial loss: 0.571197\n",
      "epoch 41; iter: 0; batch classifier loss: 0.511506; batch adversarial loss: 0.571409\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448666; batch adversarial loss: 0.588888\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394704; batch adversarial loss: 0.561467\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462910; batch adversarial loss: 0.572198\n",
      "epoch 45; iter: 0; batch classifier loss: 0.551848; batch adversarial loss: 0.579959\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380404; batch adversarial loss: 0.535839\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386735; batch adversarial loss: 0.553435\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421554; batch adversarial loss: 0.666942\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436499; batch adversarial loss: 0.553655\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428108; batch adversarial loss: 0.544330\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463746; batch adversarial loss: 0.562088\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403269; batch adversarial loss: 0.552962\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.562104\n",
      "epoch 54; iter: 0; batch classifier loss: 0.456557; batch adversarial loss: 0.633508\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448558; batch adversarial loss: 0.553801\n",
      "epoch 56; iter: 0; batch classifier loss: 0.369564; batch adversarial loss: 0.605193\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379525; batch adversarial loss: 0.492522\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446405; batch adversarial loss: 0.589739\n",
      "epoch 59; iter: 0; batch classifier loss: 0.493376; batch adversarial loss: 0.569757\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442961; batch adversarial loss: 0.578970\n",
      "epoch 61; iter: 0; batch classifier loss: 0.384975; batch adversarial loss: 0.503373\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405592; batch adversarial loss: 0.492890\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384370; batch adversarial loss: 0.571182\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451490; batch adversarial loss: 0.517793\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450158; batch adversarial loss: 0.579703\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380686; batch adversarial loss: 0.543533\n",
      "epoch 67; iter: 0; batch classifier loss: 0.345435; batch adversarial loss: 0.578601\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389984; batch adversarial loss: 0.455766\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436966; batch adversarial loss: 0.589661\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409476; batch adversarial loss: 0.555490\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435315; batch adversarial loss: 0.569268\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403596; batch adversarial loss: 0.596376\n",
      "epoch 73; iter: 0; batch classifier loss: 0.462921; batch adversarial loss: 0.517834\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354161; batch adversarial loss: 0.528703\n",
      "epoch 75; iter: 0; batch classifier loss: 0.394513; batch adversarial loss: 0.506989\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380099; batch adversarial loss: 0.475570\n",
      "epoch 77; iter: 0; batch classifier loss: 0.354942; batch adversarial loss: 0.581743\n",
      "epoch 78; iter: 0; batch classifier loss: 0.339890; batch adversarial loss: 0.615926\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367031; batch adversarial loss: 0.464720\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399611; batch adversarial loss: 0.561236\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399538; batch adversarial loss: 0.588244\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353445; batch adversarial loss: 0.535469\n",
      "epoch 83; iter: 0; batch classifier loss: 0.342715; batch adversarial loss: 0.625925\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407990; batch adversarial loss: 0.543859\n",
      "epoch 85; iter: 0; batch classifier loss: 0.371246; batch adversarial loss: 0.553548\n",
      "epoch 86; iter: 0; batch classifier loss: 0.341623; batch adversarial loss: 0.535609\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427130; batch adversarial loss: 0.581670\n",
      "epoch 88; iter: 0; batch classifier loss: 0.390257; batch adversarial loss: 0.560917\n",
      "epoch 89; iter: 0; batch classifier loss: 0.337461; batch adversarial loss: 0.538284\n",
      "epoch 90; iter: 0; batch classifier loss: 0.421023; batch adversarial loss: 0.562423\n",
      "epoch 91; iter: 0; batch classifier loss: 0.432795; batch adversarial loss: 0.615497\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412961; batch adversarial loss: 0.590668\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437617; batch adversarial loss: 0.643288\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432285; batch adversarial loss: 0.581426\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377647; batch adversarial loss: 0.553394\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429131; batch adversarial loss: 0.534717\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430818; batch adversarial loss: 0.633597\n",
      "epoch 98; iter: 0; batch classifier loss: 0.313206; batch adversarial loss: 0.642663\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393908; batch adversarial loss: 0.634223\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385748; batch adversarial loss: 0.600087\n",
      "epoch 101; iter: 0; batch classifier loss: 0.454633; batch adversarial loss: 0.516418\n",
      "epoch 102; iter: 0; batch classifier loss: 0.342876; batch adversarial loss: 0.560352\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381522; batch adversarial loss: 0.534138\n",
      "epoch 104; iter: 0; batch classifier loss: 0.403099; batch adversarial loss: 0.614632\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409275; batch adversarial loss: 0.558823\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363707; batch adversarial loss: 0.579893\n",
      "epoch 107; iter: 0; batch classifier loss: 0.303627; batch adversarial loss: 0.612073\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403114; batch adversarial loss: 0.570881\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391955; batch adversarial loss: 0.565468\n",
      "epoch 110; iter: 0; batch classifier loss: 0.462721; batch adversarial loss: 0.614651\n",
      "epoch 111; iter: 0; batch classifier loss: 0.487269; batch adversarial loss: 0.608858\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330877; batch adversarial loss: 0.606676\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394683; batch adversarial loss: 0.544033\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381343; batch adversarial loss: 0.652103\n",
      "epoch 115; iter: 0; batch classifier loss: 0.285421; batch adversarial loss: 0.562650\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359963; batch adversarial loss: 0.545491\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388502; batch adversarial loss: 0.536064\n",
      "epoch 118; iter: 0; batch classifier loss: 0.428761; batch adversarial loss: 0.500123\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386204; batch adversarial loss: 0.562268\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388247; batch adversarial loss: 0.571311\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406694; batch adversarial loss: 0.517681\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388564; batch adversarial loss: 0.597698\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346947; batch adversarial loss: 0.623731\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342330; batch adversarial loss: 0.570335\n",
      "epoch 125; iter: 0; batch classifier loss: 0.291008; batch adversarial loss: 0.545549\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403944; batch adversarial loss: 0.640441\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383756; batch adversarial loss: 0.623675\n",
      "epoch 128; iter: 0; batch classifier loss: 0.384441; batch adversarial loss: 0.509090\n",
      "epoch 129; iter: 0; batch classifier loss: 0.426839; batch adversarial loss: 0.581062\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354509; batch adversarial loss: 0.568750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.346904; batch adversarial loss: 0.544287\n",
      "epoch 132; iter: 0; batch classifier loss: 0.399129; batch adversarial loss: 0.525903\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415982; batch adversarial loss: 0.596791\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399161; batch adversarial loss: 0.476301\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380930; batch adversarial loss: 0.507419\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333812; batch adversarial loss: 0.557101\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357855; batch adversarial loss: 0.605078\n",
      "epoch 138; iter: 0; batch classifier loss: 0.396170; batch adversarial loss: 0.546709\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399125; batch adversarial loss: 0.615256\n",
      "epoch 140; iter: 0; batch classifier loss: 0.431751; batch adversarial loss: 0.570827\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371126; batch adversarial loss: 0.564318\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372328; batch adversarial loss: 0.578413\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368099; batch adversarial loss: 0.491381\n",
      "epoch 144; iter: 0; batch classifier loss: 0.420407; batch adversarial loss: 0.533848\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339969; batch adversarial loss: 0.481619\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363931; batch adversarial loss: 0.670658\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408796; batch adversarial loss: 0.618241\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345845; batch adversarial loss: 0.536579\n",
      "epoch 149; iter: 0; batch classifier loss: 0.240189; batch adversarial loss: 0.519169\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355065; batch adversarial loss: 0.510847\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355673; batch adversarial loss: 0.554617\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355407; batch adversarial loss: 0.626656\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379522; batch adversarial loss: 0.553547\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361000; batch adversarial loss: 0.561257\n",
      "epoch 155; iter: 0; batch classifier loss: 0.400918; batch adversarial loss: 0.543987\n",
      "epoch 156; iter: 0; batch classifier loss: 0.285377; batch adversarial loss: 0.535851\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404090; batch adversarial loss: 0.491596\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345817; batch adversarial loss: 0.536227\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349414; batch adversarial loss: 0.509477\n",
      "epoch 160; iter: 0; batch classifier loss: 0.408456; batch adversarial loss: 0.543233\n",
      "epoch 161; iter: 0; batch classifier loss: 0.441625; batch adversarial loss: 0.687854\n",
      "epoch 162; iter: 0; batch classifier loss: 0.424121; batch adversarial loss: 0.490569\n",
      "epoch 163; iter: 0; batch classifier loss: 0.450702; batch adversarial loss: 0.581240\n",
      "epoch 164; iter: 0; batch classifier loss: 0.332952; batch adversarial loss: 0.457783\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330850; batch adversarial loss: 0.573080\n",
      "epoch 166; iter: 0; batch classifier loss: 0.273400; batch adversarial loss: 0.492490\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373929; batch adversarial loss: 0.535057\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326773; batch adversarial loss: 0.590190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381914; batch adversarial loss: 0.552886\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397306; batch adversarial loss: 0.597028\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381743; batch adversarial loss: 0.527025\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385149; batch adversarial loss: 0.624751\n",
      "epoch 173; iter: 0; batch classifier loss: 0.454378; batch adversarial loss: 0.534355\n",
      "epoch 174; iter: 0; batch classifier loss: 0.419858; batch adversarial loss: 0.517439\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364437; batch adversarial loss: 0.571006\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329744; batch adversarial loss: 0.570844\n",
      "epoch 177; iter: 0; batch classifier loss: 0.269628; batch adversarial loss: 0.514838\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355471; batch adversarial loss: 0.559504\n",
      "epoch 179; iter: 0; batch classifier loss: 0.287530; batch adversarial loss: 0.631136\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363197; batch adversarial loss: 0.526165\n",
      "epoch 181; iter: 0; batch classifier loss: 0.393216; batch adversarial loss: 0.553862\n",
      "epoch 182; iter: 0; batch classifier loss: 0.476875; batch adversarial loss: 0.571508\n",
      "epoch 183; iter: 0; batch classifier loss: 0.389705; batch adversarial loss: 0.640081\n",
      "epoch 184; iter: 0; batch classifier loss: 0.419190; batch adversarial loss: 0.510479\n",
      "epoch 185; iter: 0; batch classifier loss: 0.318429; batch adversarial loss: 0.593835\n",
      "epoch 186; iter: 0; batch classifier loss: 0.344240; batch adversarial loss: 0.537622\n",
      "epoch 187; iter: 0; batch classifier loss: 0.324086; batch adversarial loss: 0.561297\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335889; batch adversarial loss: 0.679340\n",
      "epoch 189; iter: 0; batch classifier loss: 0.457837; batch adversarial loss: 0.509013\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349440; batch adversarial loss: 0.526525\n",
      "epoch 191; iter: 0; batch classifier loss: 0.376272; batch adversarial loss: 0.502911\n",
      "epoch 192; iter: 0; batch classifier loss: 0.370338; batch adversarial loss: 0.529313\n",
      "epoch 193; iter: 0; batch classifier loss: 0.428683; batch adversarial loss: 0.562408\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359833; batch adversarial loss: 0.555546\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366523; batch adversarial loss: 0.543770\n",
      "epoch 196; iter: 0; batch classifier loss: 0.413070; batch adversarial loss: 0.605803\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394505; batch adversarial loss: 0.561152\n",
      "epoch 198; iter: 0; batch classifier loss: 0.303152; batch adversarial loss: 0.490442\n",
      "epoch 199; iter: 0; batch classifier loss: 0.282860; batch adversarial loss: 0.530369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679607; batch adversarial loss: 0.630829\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556188; batch adversarial loss: 0.655630\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558974; batch adversarial loss: 0.602282\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562977; batch adversarial loss: 0.569258\n",
      "epoch 4; iter: 0; batch classifier loss: 0.491972; batch adversarial loss: 0.626995\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552527; batch adversarial loss: 0.626874\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571720; batch adversarial loss: 0.592042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537219; batch adversarial loss: 0.583620\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550891; batch adversarial loss: 0.622126\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552254; batch adversarial loss: 0.569440\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584220; batch adversarial loss: 0.622367\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592497; batch adversarial loss: 0.491316\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553550; batch adversarial loss: 0.629113\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465649; batch adversarial loss: 0.623661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486569; batch adversarial loss: 0.548968\n",
      "epoch 15; iter: 0; batch classifier loss: 0.608467; batch adversarial loss: 0.551783\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454947; batch adversarial loss: 0.591419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505398; batch adversarial loss: 0.647129\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490800; batch adversarial loss: 0.619732\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484584; batch adversarial loss: 0.584087\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489288; batch adversarial loss: 0.547469\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502265; batch adversarial loss: 0.558089\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499121; batch adversarial loss: 0.576158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519151; batch adversarial loss: 0.533732\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422789; batch adversarial loss: 0.534695\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417789; batch adversarial loss: 0.545928\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455638; batch adversarial loss: 0.620641\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451698; batch adversarial loss: 0.501026\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452819; batch adversarial loss: 0.525622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.423065; batch adversarial loss: 0.561935\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487516; batch adversarial loss: 0.522214\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464023; batch adversarial loss: 0.589029\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478802; batch adversarial loss: 0.535600\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497612; batch adversarial loss: 0.484821\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482471; batch adversarial loss: 0.633489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.546699; batch adversarial loss: 0.623966\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441848; batch adversarial loss: 0.553181\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452046; batch adversarial loss: 0.580034\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467294; batch adversarial loss: 0.562841\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376888; batch adversarial loss: 0.526743\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495073; batch adversarial loss: 0.535865\n",
      "epoch 41; iter: 0; batch classifier loss: 0.373431; batch adversarial loss: 0.535749\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445573; batch adversarial loss: 0.589498\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438856; batch adversarial loss: 0.526561\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492165; batch adversarial loss: 0.580881\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466560; batch adversarial loss: 0.553564\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396944; batch adversarial loss: 0.608569\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447375; batch adversarial loss: 0.535832\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434820; batch adversarial loss: 0.517270\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503490; batch adversarial loss: 0.581438\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406690; batch adversarial loss: 0.561861\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383275; batch adversarial loss: 0.517807\n",
      "epoch 52; iter: 0; batch classifier loss: 0.378966; batch adversarial loss: 0.472322\n",
      "epoch 53; iter: 0; batch classifier loss: 0.392757; batch adversarial loss: 0.579715\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422797; batch adversarial loss: 0.535531\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434777; batch adversarial loss: 0.545156\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419724; batch adversarial loss: 0.536149\n",
      "epoch 57; iter: 0; batch classifier loss: 0.477923; batch adversarial loss: 0.599383\n",
      "epoch 58; iter: 0; batch classifier loss: 0.327169; batch adversarial loss: 0.544289\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401645; batch adversarial loss: 0.508045\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394279; batch adversarial loss: 0.570500\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373030; batch adversarial loss: 0.482023\n",
      "epoch 62; iter: 0; batch classifier loss: 0.512513; batch adversarial loss: 0.561799\n",
      "epoch 63; iter: 0; batch classifier loss: 0.451944; batch adversarial loss: 0.516332\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431053; batch adversarial loss: 0.571498\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382306; batch adversarial loss: 0.553625\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422746; batch adversarial loss: 0.581083\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400327; batch adversarial loss: 0.489552\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364822; batch adversarial loss: 0.591503\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411049; batch adversarial loss: 0.489814\n",
      "epoch 70; iter: 0; batch classifier loss: 0.389827; batch adversarial loss: 0.562629\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450302; batch adversarial loss: 0.508925\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435771; batch adversarial loss: 0.508585\n",
      "epoch 73; iter: 0; batch classifier loss: 0.346124; batch adversarial loss: 0.544794\n",
      "epoch 74; iter: 0; batch classifier loss: 0.459916; batch adversarial loss: 0.536138\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423231; batch adversarial loss: 0.588865\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396610; batch adversarial loss: 0.591104\n",
      "epoch 77; iter: 0; batch classifier loss: 0.352901; batch adversarial loss: 0.508843\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428083; batch adversarial loss: 0.536325\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404075; batch adversarial loss: 0.526613\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441876; batch adversarial loss: 0.625633\n",
      "epoch 81; iter: 0; batch classifier loss: 0.363304; batch adversarial loss: 0.590495\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380891; batch adversarial loss: 0.544622\n",
      "epoch 83; iter: 0; batch classifier loss: 0.502257; batch adversarial loss: 0.506704\n",
      "epoch 84; iter: 0; batch classifier loss: 0.424605; batch adversarial loss: 0.590123\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433391; batch adversarial loss: 0.607203\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372732; batch adversarial loss: 0.588469\n",
      "epoch 87; iter: 0; batch classifier loss: 0.431744; batch adversarial loss: 0.580938\n",
      "epoch 88; iter: 0; batch classifier loss: 0.439359; batch adversarial loss: 0.570782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422356; batch adversarial loss: 0.572454\n",
      "epoch 90; iter: 0; batch classifier loss: 0.484149; batch adversarial loss: 0.598910\n",
      "epoch 91; iter: 0; batch classifier loss: 0.344653; batch adversarial loss: 0.533667\n",
      "epoch 92; iter: 0; batch classifier loss: 0.431553; batch adversarial loss: 0.535251\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409713; batch adversarial loss: 0.571614\n",
      "epoch 94; iter: 0; batch classifier loss: 0.335331; batch adversarial loss: 0.572403\n",
      "epoch 95; iter: 0; batch classifier loss: 0.353012; batch adversarial loss: 0.572430\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405496; batch adversarial loss: 0.618604\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425748; batch adversarial loss: 0.534816\n",
      "epoch 98; iter: 0; batch classifier loss: 0.333990; batch adversarial loss: 0.615305\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386644; batch adversarial loss: 0.526898\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418213; batch adversarial loss: 0.578951\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391988; batch adversarial loss: 0.581010\n",
      "epoch 102; iter: 0; batch classifier loss: 0.430060; batch adversarial loss: 0.581116\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404789; batch adversarial loss: 0.562978\n",
      "epoch 104; iter: 0; batch classifier loss: 0.447691; batch adversarial loss: 0.490424\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363914; batch adversarial loss: 0.545755\n",
      "epoch 106; iter: 0; batch classifier loss: 0.416546; batch adversarial loss: 0.526696\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430953; batch adversarial loss: 0.580294\n",
      "epoch 108; iter: 0; batch classifier loss: 0.427799; batch adversarial loss: 0.507183\n",
      "epoch 109; iter: 0; batch classifier loss: 0.448274; batch adversarial loss: 0.598342\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351114; batch adversarial loss: 0.581848\n",
      "epoch 111; iter: 0; batch classifier loss: 0.435740; batch adversarial loss: 0.536472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.325111; batch adversarial loss: 0.625100\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415587; batch adversarial loss: 0.588688\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406650; batch adversarial loss: 0.553521\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398423; batch adversarial loss: 0.588989\n",
      "epoch 116; iter: 0; batch classifier loss: 0.279285; batch adversarial loss: 0.534994\n",
      "epoch 117; iter: 0; batch classifier loss: 0.435543; batch adversarial loss: 0.570340\n",
      "epoch 118; iter: 0; batch classifier loss: 0.301795; batch adversarial loss: 0.534777\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370905; batch adversarial loss: 0.507837\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399823; batch adversarial loss: 0.599312\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356174; batch adversarial loss: 0.636591\n",
      "epoch 122; iter: 0; batch classifier loss: 0.348321; batch adversarial loss: 0.517217\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359503; batch adversarial loss: 0.564269\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358424; batch adversarial loss: 0.509004\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332565; batch adversarial loss: 0.535620\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358790; batch adversarial loss: 0.543879\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417835; batch adversarial loss: 0.509528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.334761; batch adversarial loss: 0.543584\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363271; batch adversarial loss: 0.490742\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321156; batch adversarial loss: 0.626102\n",
      "epoch 131; iter: 0; batch classifier loss: 0.402218; batch adversarial loss: 0.573063\n",
      "epoch 132; iter: 0; batch classifier loss: 0.452974; batch adversarial loss: 0.527136\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344565; batch adversarial loss: 0.482311\n",
      "epoch 134; iter: 0; batch classifier loss: 0.316743; batch adversarial loss: 0.534635\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358047; batch adversarial loss: 0.543252\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390667; batch adversarial loss: 0.678188\n",
      "epoch 137; iter: 0; batch classifier loss: 0.339490; batch adversarial loss: 0.563400\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380331; batch adversarial loss: 0.561789\n",
      "epoch 139; iter: 0; batch classifier loss: 0.410474; batch adversarial loss: 0.436809\n",
      "epoch 140; iter: 0; batch classifier loss: 0.458026; batch adversarial loss: 0.490611\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357757; batch adversarial loss: 0.517674\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375991; batch adversarial loss: 0.507345\n",
      "epoch 143; iter: 0; batch classifier loss: 0.289875; batch adversarial loss: 0.524864\n",
      "epoch 144; iter: 0; batch classifier loss: 0.311511; batch adversarial loss: 0.597286\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363570; batch adversarial loss: 0.533574\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370491; batch adversarial loss: 0.535196\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368084; batch adversarial loss: 0.563669\n",
      "epoch 148; iter: 0; batch classifier loss: 0.507329; batch adversarial loss: 0.553734\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384239; batch adversarial loss: 0.541249\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413757; batch adversarial loss: 0.570351\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386279; batch adversarial loss: 0.536042\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368043; batch adversarial loss: 0.552602\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345739; batch adversarial loss: 0.581553\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362859; batch adversarial loss: 0.598352\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389779; batch adversarial loss: 0.482486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339004; batch adversarial loss: 0.517757\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386809; batch adversarial loss: 0.662518\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392208; batch adversarial loss: 0.519045\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350063; batch adversarial loss: 0.616653\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383892; batch adversarial loss: 0.445305\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370489; batch adversarial loss: 0.526751\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385405; batch adversarial loss: 0.535197\n",
      "epoch 163; iter: 0; batch classifier loss: 0.395339; batch adversarial loss: 0.590220\n",
      "epoch 164; iter: 0; batch classifier loss: 0.338140; batch adversarial loss: 0.525879\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365397; batch adversarial loss: 0.634621\n",
      "epoch 166; iter: 0; batch classifier loss: 0.379795; batch adversarial loss: 0.481953\n",
      "epoch 167; iter: 0; batch classifier loss: 0.404180; batch adversarial loss: 0.516458\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306433; batch adversarial loss: 0.527445\n",
      "epoch 169; iter: 0; batch classifier loss: 0.425391; batch adversarial loss: 0.535640\n",
      "epoch 170; iter: 0; batch classifier loss: 0.357363; batch adversarial loss: 0.497883\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347069; batch adversarial loss: 0.489936\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379214; batch adversarial loss: 0.518127\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329822; batch adversarial loss: 0.624973\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373460; batch adversarial loss: 0.490274\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322164; batch adversarial loss: 0.562762\n",
      "epoch 176; iter: 0; batch classifier loss: 0.291785; batch adversarial loss: 0.489183\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399471; batch adversarial loss: 0.509703\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345343; batch adversarial loss: 0.553682\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368811; batch adversarial loss: 0.562239\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371880; batch adversarial loss: 0.535424\n",
      "epoch 181; iter: 0; batch classifier loss: 0.431812; batch adversarial loss: 0.543798\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415003; batch adversarial loss: 0.580777\n",
      "epoch 183; iter: 0; batch classifier loss: 0.325453; batch adversarial loss: 0.499724\n",
      "epoch 184; iter: 0; batch classifier loss: 0.388300; batch adversarial loss: 0.553362\n",
      "epoch 185; iter: 0; batch classifier loss: 0.324793; batch adversarial loss: 0.508142\n",
      "epoch 186; iter: 0; batch classifier loss: 0.290674; batch adversarial loss: 0.490726\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333972; batch adversarial loss: 0.554334\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314717; batch adversarial loss: 0.642830\n",
      "epoch 189; iter: 0; batch classifier loss: 0.418044; batch adversarial loss: 0.527795\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314494; batch adversarial loss: 0.489817\n",
      "epoch 191; iter: 0; batch classifier loss: 0.293870; batch adversarial loss: 0.544726\n",
      "epoch 192; iter: 0; batch classifier loss: 0.429679; batch adversarial loss: 0.562878\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359720; batch adversarial loss: 0.553186\n",
      "epoch 194; iter: 0; batch classifier loss: 0.383293; batch adversarial loss: 0.635333\n",
      "epoch 195; iter: 0; batch classifier loss: 0.408949; batch adversarial loss: 0.518272\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363344; batch adversarial loss: 0.616930\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341684; batch adversarial loss: 0.572746\n",
      "epoch 198; iter: 0; batch classifier loss: 0.394880; batch adversarial loss: 0.526487\n",
      "epoch 199; iter: 0; batch classifier loss: 0.403542; batch adversarial loss: 0.588246\n",
      "epoch 0; iter: 0; batch classifier loss: 0.860452; batch adversarial loss: 0.911922\n",
      "epoch 1; iter: 0; batch classifier loss: 0.745578; batch adversarial loss: 0.907887\n",
      "epoch 2; iter: 0; batch classifier loss: 0.710695; batch adversarial loss: 0.827653\n",
      "epoch 3; iter: 0; batch classifier loss: 0.758289; batch adversarial loss: 0.752279\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576769; batch adversarial loss: 0.697074\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586093; batch adversarial loss: 0.653375\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553994; batch adversarial loss: 0.633146\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539673; batch adversarial loss: 0.619746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539504; batch adversarial loss: 0.594467\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493878; batch adversarial loss: 0.597398\n",
      "epoch 10; iter: 0; batch classifier loss: 0.618221; batch adversarial loss: 0.564621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.455940; batch adversarial loss: 0.612452\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519036; batch adversarial loss: 0.609339\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506271; batch adversarial loss: 0.631940\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473725; batch adversarial loss: 0.548327\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514668; batch adversarial loss: 0.565724\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518435; batch adversarial loss: 0.555856\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500929; batch adversarial loss: 0.577506\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531818; batch adversarial loss: 0.563707\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457144; batch adversarial loss: 0.576520\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515151; batch adversarial loss: 0.594963\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479985; batch adversarial loss: 0.558799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.504350; batch adversarial loss: 0.585129\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496454; batch adversarial loss: 0.518331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.538971; batch adversarial loss: 0.541583\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441887; batch adversarial loss: 0.615208\n",
      "epoch 26; iter: 0; batch classifier loss: 0.555010; batch adversarial loss: 0.586347\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450508; batch adversarial loss: 0.527977\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441225; batch adversarial loss: 0.547247\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512362; batch adversarial loss: 0.603120\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452685; batch adversarial loss: 0.566651\n",
      "epoch 31; iter: 0; batch classifier loss: 0.548137; batch adversarial loss: 0.518268\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438792; batch adversarial loss: 0.620923\n",
      "epoch 33; iter: 0; batch classifier loss: 0.381956; batch adversarial loss: 0.537659\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437159; batch adversarial loss: 0.531613\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469361; batch adversarial loss: 0.504866\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463214; batch adversarial loss: 0.554713\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445095; batch adversarial loss: 0.509229\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445819; batch adversarial loss: 0.612454\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497565; batch adversarial loss: 0.595732\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442773; batch adversarial loss: 0.538018\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431338; batch adversarial loss: 0.608039\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427511; batch adversarial loss: 0.525546\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430190; batch adversarial loss: 0.570577\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433539; batch adversarial loss: 0.538410\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480086; batch adversarial loss: 0.502190\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462553; batch adversarial loss: 0.492491\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426608; batch adversarial loss: 0.507923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450619; batch adversarial loss: 0.581010\n",
      "epoch 49; iter: 0; batch classifier loss: 0.482351; batch adversarial loss: 0.553566\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420343; batch adversarial loss: 0.631697\n",
      "epoch 51; iter: 0; batch classifier loss: 0.474462; batch adversarial loss: 0.463757\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431644; batch adversarial loss: 0.516269\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409795; batch adversarial loss: 0.534985\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404409; batch adversarial loss: 0.527848\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391252; batch adversarial loss: 0.519751\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427864; batch adversarial loss: 0.492568\n",
      "epoch 57; iter: 0; batch classifier loss: 0.455388; batch adversarial loss: 0.633987\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429421; batch adversarial loss: 0.516749\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394269; batch adversarial loss: 0.549948\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447016; batch adversarial loss: 0.502833\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413915; batch adversarial loss: 0.570795\n",
      "epoch 62; iter: 0; batch classifier loss: 0.365553; batch adversarial loss: 0.543660\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378132; batch adversarial loss: 0.579723\n",
      "epoch 64; iter: 0; batch classifier loss: 0.495104; batch adversarial loss: 0.572678\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435875; batch adversarial loss: 0.518603\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435792; batch adversarial loss: 0.599704\n",
      "epoch 67; iter: 0; batch classifier loss: 0.463432; batch adversarial loss: 0.510752\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407518; batch adversarial loss: 0.552788\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440063; batch adversarial loss: 0.571700\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438985; batch adversarial loss: 0.572802\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413096; batch adversarial loss: 0.603462\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403283; batch adversarial loss: 0.679187\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390369; batch adversarial loss: 0.618596\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374630; batch adversarial loss: 0.545722\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427811; batch adversarial loss: 0.581492\n",
      "epoch 76; iter: 0; batch classifier loss: 0.295966; batch adversarial loss: 0.534612\n",
      "epoch 77; iter: 0; batch classifier loss: 0.332998; batch adversarial loss: 0.528995\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412402; batch adversarial loss: 0.561273\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406952; batch adversarial loss: 0.569250\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393285; batch adversarial loss: 0.481839\n",
      "epoch 81; iter: 0; batch classifier loss: 0.377539; batch adversarial loss: 0.554818\n",
      "epoch 82; iter: 0; batch classifier loss: 0.424617; batch adversarial loss: 0.571613\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384531; batch adversarial loss: 0.516126\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421852; batch adversarial loss: 0.542759\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349623; batch adversarial loss: 0.526832\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345129; batch adversarial loss: 0.580483\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347668; batch adversarial loss: 0.518414\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363994; batch adversarial loss: 0.579036\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373783; batch adversarial loss: 0.553793\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381768; batch adversarial loss: 0.500745\n",
      "epoch 91; iter: 0; batch classifier loss: 0.339570; batch adversarial loss: 0.515619\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393148; batch adversarial loss: 0.517187\n",
      "epoch 93; iter: 0; batch classifier loss: 0.462553; batch adversarial loss: 0.509988\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380812; batch adversarial loss: 0.590089\n",
      "epoch 95; iter: 0; batch classifier loss: 0.340665; batch adversarial loss: 0.499523\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389201; batch adversarial loss: 0.597536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388380; batch adversarial loss: 0.536028\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383562; batch adversarial loss: 0.613230\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368211; batch adversarial loss: 0.488810\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396298; batch adversarial loss: 0.527087\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362153; batch adversarial loss: 0.542645\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415724; batch adversarial loss: 0.589182\n",
      "epoch 103; iter: 0; batch classifier loss: 0.368192; batch adversarial loss: 0.571927\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350876; batch adversarial loss: 0.508664\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394334; batch adversarial loss: 0.542301\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443201; batch adversarial loss: 0.571726\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382455; batch adversarial loss: 0.500742\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379410; batch adversarial loss: 0.536106\n",
      "epoch 109; iter: 0; batch classifier loss: 0.354839; batch adversarial loss: 0.542634\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346077; batch adversarial loss: 0.517058\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436587; batch adversarial loss: 0.554391\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394074; batch adversarial loss: 0.582298\n",
      "epoch 113; iter: 0; batch classifier loss: 0.328372; batch adversarial loss: 0.544111\n",
      "epoch 114; iter: 0; batch classifier loss: 0.319135; batch adversarial loss: 0.525734\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389200; batch adversarial loss: 0.653669\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388228; batch adversarial loss: 0.597567\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351488; batch adversarial loss: 0.582389\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398587; batch adversarial loss: 0.599092\n",
      "epoch 119; iter: 0; batch classifier loss: 0.438568; batch adversarial loss: 0.615869\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409945; batch adversarial loss: 0.535404\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400288; batch adversarial loss: 0.534128\n",
      "epoch 122; iter: 0; batch classifier loss: 0.347329; batch adversarial loss: 0.500155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.363840; batch adversarial loss: 0.490176\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364924; batch adversarial loss: 0.570152\n",
      "epoch 125; iter: 0; batch classifier loss: 0.431118; batch adversarial loss: 0.600078\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392173; batch adversarial loss: 0.510397\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358047; batch adversarial loss: 0.572801\n",
      "epoch 128; iter: 0; batch classifier loss: 0.380980; batch adversarial loss: 0.624011\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355891; batch adversarial loss: 0.615534\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368315; batch adversarial loss: 0.624816\n",
      "epoch 131; iter: 0; batch classifier loss: 0.299992; batch adversarial loss: 0.599322\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390013; batch adversarial loss: 0.554784\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314000; batch adversarial loss: 0.525588\n",
      "epoch 134; iter: 0; batch classifier loss: 0.347186; batch adversarial loss: 0.489731\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378662; batch adversarial loss: 0.552639\n",
      "epoch 136; iter: 0; batch classifier loss: 0.408577; batch adversarial loss: 0.570546\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348398; batch adversarial loss: 0.536261\n",
      "epoch 138; iter: 0; batch classifier loss: 0.295245; batch adversarial loss: 0.563210\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358162; batch adversarial loss: 0.545241\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376209; batch adversarial loss: 0.545996\n",
      "epoch 141; iter: 0; batch classifier loss: 0.405888; batch adversarial loss: 0.538233\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334365; batch adversarial loss: 0.597375\n",
      "epoch 143; iter: 0; batch classifier loss: 0.404953; batch adversarial loss: 0.555503\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312338; batch adversarial loss: 0.606374\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363683; batch adversarial loss: 0.559288\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343357; batch adversarial loss: 0.564649\n",
      "epoch 147; iter: 0; batch classifier loss: 0.315772; batch adversarial loss: 0.571134\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356782; batch adversarial loss: 0.566887\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360251; batch adversarial loss: 0.525786\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350857; batch adversarial loss: 0.587012\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347167; batch adversarial loss: 0.562380\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331146; batch adversarial loss: 0.499293\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374559; batch adversarial loss: 0.599977\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349103; batch adversarial loss: 0.558974\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323034; batch adversarial loss: 0.516732\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312210; batch adversarial loss: 0.517267\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329714; batch adversarial loss: 0.592981\n",
      "epoch 158; iter: 0; batch classifier loss: 0.326723; batch adversarial loss: 0.525830\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385084; batch adversarial loss: 0.545862\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361236; batch adversarial loss: 0.527560\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342475; batch adversarial loss: 0.581774\n",
      "epoch 162; iter: 0; batch classifier loss: 0.338786; batch adversarial loss: 0.463134\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388463; batch adversarial loss: 0.553681\n",
      "epoch 164; iter: 0; batch classifier loss: 0.326094; batch adversarial loss: 0.491811\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318467; batch adversarial loss: 0.576375\n",
      "epoch 166; iter: 0; batch classifier loss: 0.303671; batch adversarial loss: 0.560924\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365589; batch adversarial loss: 0.544629\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335209; batch adversarial loss: 0.554489\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350792; batch adversarial loss: 0.562959\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403276; batch adversarial loss: 0.605560\n",
      "epoch 171; iter: 0; batch classifier loss: 0.339664; batch adversarial loss: 0.554044\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387573; batch adversarial loss: 0.518799\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343819; batch adversarial loss: 0.589465\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380116; batch adversarial loss: 0.481167\n",
      "epoch 175; iter: 0; batch classifier loss: 0.334121; batch adversarial loss: 0.570937\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308035; batch adversarial loss: 0.588804\n",
      "epoch 177; iter: 0; batch classifier loss: 0.385939; batch adversarial loss: 0.561638\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316756; batch adversarial loss: 0.553609\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375631; batch adversarial loss: 0.564442\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360698; batch adversarial loss: 0.598424\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358941; batch adversarial loss: 0.569527\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370400; batch adversarial loss: 0.554286\n",
      "epoch 183; iter: 0; batch classifier loss: 0.401706; batch adversarial loss: 0.517126\n",
      "epoch 184; iter: 0; batch classifier loss: 0.426709; batch adversarial loss: 0.590115\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377919; batch adversarial loss: 0.619898\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407335; batch adversarial loss: 0.571122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325671; batch adversarial loss: 0.511770\n",
      "epoch 188; iter: 0; batch classifier loss: 0.421010; batch adversarial loss: 0.572116\n",
      "epoch 189; iter: 0; batch classifier loss: 0.425474; batch adversarial loss: 0.526288\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322773; batch adversarial loss: 0.509109\n",
      "epoch 191; iter: 0; batch classifier loss: 0.304087; batch adversarial loss: 0.517639\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335144; batch adversarial loss: 0.536933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317708; batch adversarial loss: 0.582560\n",
      "epoch 194; iter: 0; batch classifier loss: 0.355194; batch adversarial loss: 0.500484\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342452; batch adversarial loss: 0.553592\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381108; batch adversarial loss: 0.543292\n",
      "epoch 197; iter: 0; batch classifier loss: 0.447482; batch adversarial loss: 0.634583\n",
      "epoch 198; iter: 0; batch classifier loss: 0.288775; batch adversarial loss: 0.597556\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397223; batch adversarial loss: 0.589962\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667522; batch adversarial loss: 0.744040\n",
      "epoch 1; iter: 0; batch classifier loss: 0.640196; batch adversarial loss: 0.700184\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609183; batch adversarial loss: 0.654709\n",
      "epoch 3; iter: 0; batch classifier loss: 0.571532; batch adversarial loss: 0.639039\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610261; batch adversarial loss: 0.636152\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566858; batch adversarial loss: 0.614856\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524025; batch adversarial loss: 0.597246\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580633; batch adversarial loss: 0.600866\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521869; batch adversarial loss: 0.576669\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517762; batch adversarial loss: 0.667226\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519760; batch adversarial loss: 0.573227\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547370; batch adversarial loss: 0.573530\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503564; batch adversarial loss: 0.547718\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533673; batch adversarial loss: 0.549663\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528758; batch adversarial loss: 0.555336\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521675; batch adversarial loss: 0.555189\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475039; batch adversarial loss: 0.611809\n",
      "epoch 17; iter: 0; batch classifier loss: 0.452317; batch adversarial loss: 0.509258\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526510; batch adversarial loss: 0.534393\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498545; batch adversarial loss: 0.616293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.524623; batch adversarial loss: 0.548457\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537172; batch adversarial loss: 0.557553\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475345; batch adversarial loss: 0.549193\n",
      "epoch 23; iter: 0; batch classifier loss: 0.448285; batch adversarial loss: 0.564294\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479493; batch adversarial loss: 0.542483\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442652; batch adversarial loss: 0.468473\n",
      "epoch 26; iter: 0; batch classifier loss: 0.523239; batch adversarial loss: 0.484416\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428236; batch adversarial loss: 0.567285\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464498; batch adversarial loss: 0.540548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451879; batch adversarial loss: 0.553989\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456088; batch adversarial loss: 0.544211\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496915; batch adversarial loss: 0.543132\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470215; batch adversarial loss: 0.608151\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444660; batch adversarial loss: 0.530303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.518817; batch adversarial loss: 0.556867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463255; batch adversarial loss: 0.525065\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424418; batch adversarial loss: 0.588307\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464974; batch adversarial loss: 0.493345\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415382; batch adversarial loss: 0.590802\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432742; batch adversarial loss: 0.599001\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497124; batch adversarial loss: 0.553861\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420860; batch adversarial loss: 0.553310\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439930; batch adversarial loss: 0.597926\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486036; batch adversarial loss: 0.517856\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457492; batch adversarial loss: 0.517346\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460380; batch adversarial loss: 0.534284\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429403; batch adversarial loss: 0.544051\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426879; batch adversarial loss: 0.571533\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509176; batch adversarial loss: 0.533417\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421473; batch adversarial loss: 0.562342\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407728; batch adversarial loss: 0.554235\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443347; batch adversarial loss: 0.572314\n",
      "epoch 52; iter: 0; batch classifier loss: 0.497825; batch adversarial loss: 0.562015\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450457; batch adversarial loss: 0.489766\n",
      "epoch 54; iter: 0; batch classifier loss: 0.396951; batch adversarial loss: 0.589067\n",
      "epoch 55; iter: 0; batch classifier loss: 0.424627; batch adversarial loss: 0.552243\n",
      "epoch 56; iter: 0; batch classifier loss: 0.376686; batch adversarial loss: 0.488931\n",
      "epoch 57; iter: 0; batch classifier loss: 0.342454; batch adversarial loss: 0.672847\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415413; batch adversarial loss: 0.600072\n",
      "epoch 59; iter: 0; batch classifier loss: 0.453239; batch adversarial loss: 0.573035\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366976; batch adversarial loss: 0.598958\n",
      "epoch 61; iter: 0; batch classifier loss: 0.405756; batch adversarial loss: 0.590581\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452839; batch adversarial loss: 0.551835\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386471; batch adversarial loss: 0.524448\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398284; batch adversarial loss: 0.517479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.399060; batch adversarial loss: 0.524132\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445262; batch adversarial loss: 0.515348\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407822; batch adversarial loss: 0.607377\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406495; batch adversarial loss: 0.577445\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417266; batch adversarial loss: 0.540897\n",
      "epoch 70; iter: 0; batch classifier loss: 0.395092; batch adversarial loss: 0.533609\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413526; batch adversarial loss: 0.509333\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396116; batch adversarial loss: 0.517601\n",
      "epoch 73; iter: 0; batch classifier loss: 0.359761; batch adversarial loss: 0.550547\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432088; batch adversarial loss: 0.563307\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433072; batch adversarial loss: 0.481761\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404328; batch adversarial loss: 0.479150\n",
      "epoch 77; iter: 0; batch classifier loss: 0.537876; batch adversarial loss: 0.488239\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455141; batch adversarial loss: 0.402947\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416989; batch adversarial loss: 0.536664\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369322; batch adversarial loss: 0.544951\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394444; batch adversarial loss: 0.552628\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395236; batch adversarial loss: 0.611783\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367317; batch adversarial loss: 0.599557\n",
      "epoch 84; iter: 0; batch classifier loss: 0.456929; batch adversarial loss: 0.505978\n",
      "epoch 85; iter: 0; batch classifier loss: 0.470325; batch adversarial loss: 0.610434\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397336; batch adversarial loss: 0.555161\n",
      "epoch 87; iter: 0; batch classifier loss: 0.474781; batch adversarial loss: 0.471144\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418761; batch adversarial loss: 0.553607\n",
      "epoch 89; iter: 0; batch classifier loss: 0.284838; batch adversarial loss: 0.582324\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367900; batch adversarial loss: 0.609245\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412834; batch adversarial loss: 0.551072\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425440; batch adversarial loss: 0.533884\n",
      "epoch 93; iter: 0; batch classifier loss: 0.335345; batch adversarial loss: 0.534481\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385517; batch adversarial loss: 0.627288\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401436; batch adversarial loss: 0.505530\n",
      "epoch 96; iter: 0; batch classifier loss: 0.462892; batch adversarial loss: 0.471494\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315924; batch adversarial loss: 0.561989\n",
      "epoch 98; iter: 0; batch classifier loss: 0.433405; batch adversarial loss: 0.534605\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369023; batch adversarial loss: 0.542394\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420793; batch adversarial loss: 0.498703\n",
      "epoch 101; iter: 0; batch classifier loss: 0.440167; batch adversarial loss: 0.535493\n",
      "epoch 102; iter: 0; batch classifier loss: 0.431026; batch adversarial loss: 0.510826\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419186; batch adversarial loss: 0.572547\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391102; batch adversarial loss: 0.591555\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389996; batch adversarial loss: 0.563289\n",
      "epoch 106; iter: 0; batch classifier loss: 0.464088; batch adversarial loss: 0.525966\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384410; batch adversarial loss: 0.598526\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369709; batch adversarial loss: 0.489295\n",
      "epoch 109; iter: 0; batch classifier loss: 0.468603; batch adversarial loss: 0.498823\n",
      "epoch 110; iter: 0; batch classifier loss: 0.424650; batch adversarial loss: 0.581671\n",
      "epoch 111; iter: 0; batch classifier loss: 0.414750; batch adversarial loss: 0.559869\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330556; batch adversarial loss: 0.562859\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390361; batch adversarial loss: 0.517673\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380613; batch adversarial loss: 0.499234\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360411; batch adversarial loss: 0.542951\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395675; batch adversarial loss: 0.543546\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378889; batch adversarial loss: 0.647465\n",
      "epoch 118; iter: 0; batch classifier loss: 0.369796; batch adversarial loss: 0.592727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.402983; batch adversarial loss: 0.609519\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408675; batch adversarial loss: 0.554639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349671; batch adversarial loss: 0.518502\n",
      "epoch 122; iter: 0; batch classifier loss: 0.427681; batch adversarial loss: 0.536124\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327092; batch adversarial loss: 0.507300\n",
      "epoch 124; iter: 0; batch classifier loss: 0.430389; batch adversarial loss: 0.523431\n",
      "epoch 125; iter: 0; batch classifier loss: 0.286569; batch adversarial loss: 0.563706\n",
      "epoch 126; iter: 0; batch classifier loss: 0.418567; batch adversarial loss: 0.597286\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.546195\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356228; batch adversarial loss: 0.561929\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378393; batch adversarial loss: 0.600162\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352505; batch adversarial loss: 0.534926\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365102; batch adversarial loss: 0.574101\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387341; batch adversarial loss: 0.554310\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336865; batch adversarial loss: 0.453262\n",
      "epoch 134; iter: 0; batch classifier loss: 0.308666; batch adversarial loss: 0.472217\n",
      "epoch 135; iter: 0; batch classifier loss: 0.475542; batch adversarial loss: 0.573139\n",
      "epoch 136; iter: 0; batch classifier loss: 0.413562; batch adversarial loss: 0.543229\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354327; batch adversarial loss: 0.546655\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369364; batch adversarial loss: 0.609808\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408109; batch adversarial loss: 0.490001\n",
      "epoch 140; iter: 0; batch classifier loss: 0.320097; batch adversarial loss: 0.460726\n",
      "epoch 141; iter: 0; batch classifier loss: 0.405035; batch adversarial loss: 0.553116\n",
      "epoch 142; iter: 0; batch classifier loss: 0.388559; batch adversarial loss: 0.554300\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387380; batch adversarial loss: 0.443297\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372958; batch adversarial loss: 0.608068\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387660; batch adversarial loss: 0.535011\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387861; batch adversarial loss: 0.480294\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337525; batch adversarial loss: 0.538026\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374493; batch adversarial loss: 0.565312\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339932; batch adversarial loss: 0.517641\n",
      "epoch 150; iter: 0; batch classifier loss: 0.482741; batch adversarial loss: 0.571439\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422498; batch adversarial loss: 0.552618\n",
      "epoch 152; iter: 0; batch classifier loss: 0.473287; batch adversarial loss: 0.598839\n",
      "epoch 153; iter: 0; batch classifier loss: 0.309205; batch adversarial loss: 0.543762\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384603; batch adversarial loss: 0.490162\n",
      "epoch 155; iter: 0; batch classifier loss: 0.443351; batch adversarial loss: 0.545510\n",
      "epoch 156; iter: 0; batch classifier loss: 0.406596; batch adversarial loss: 0.514495\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369316; batch adversarial loss: 0.554052\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390186; batch adversarial loss: 0.654824\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334421; batch adversarial loss: 0.489343\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349307; batch adversarial loss: 0.553817\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339971; batch adversarial loss: 0.546010\n",
      "epoch 162; iter: 0; batch classifier loss: 0.404852; batch adversarial loss: 0.499136\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350938; batch adversarial loss: 0.564634\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337488; batch adversarial loss: 0.535357\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334531; batch adversarial loss: 0.518347\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377947; batch adversarial loss: 0.499970\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348272; batch adversarial loss: 0.508892\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323382; batch adversarial loss: 0.626747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372887; batch adversarial loss: 0.562448\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349453; batch adversarial loss: 0.597879\n",
      "epoch 171; iter: 0; batch classifier loss: 0.290517; batch adversarial loss: 0.617339\n",
      "epoch 172; iter: 0; batch classifier loss: 0.501867; batch adversarial loss: 0.471490\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357901; batch adversarial loss: 0.517451\n",
      "epoch 174; iter: 0; batch classifier loss: 0.277077; batch adversarial loss: 0.550601\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328934; batch adversarial loss: 0.552808\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339609; batch adversarial loss: 0.516232\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381002; batch adversarial loss: 0.624230\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358955; batch adversarial loss: 0.600580\n",
      "epoch 179; iter: 0; batch classifier loss: 0.419826; batch adversarial loss: 0.496762\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414810; batch adversarial loss: 0.507814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.486888; batch adversarial loss: 0.565468\n",
      "epoch 182; iter: 0; batch classifier loss: 0.353632; batch adversarial loss: 0.546927\n",
      "epoch 183; iter: 0; batch classifier loss: 0.406882; batch adversarial loss: 0.524576\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325015; batch adversarial loss: 0.572030\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348445; batch adversarial loss: 0.526698\n",
      "epoch 186; iter: 0; batch classifier loss: 0.378998; batch adversarial loss: 0.516653\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352495; batch adversarial loss: 0.533520\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318396; batch adversarial loss: 0.536323\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352719; batch adversarial loss: 0.526589\n",
      "epoch 190; iter: 0; batch classifier loss: 0.403372; batch adversarial loss: 0.590258\n",
      "epoch 191; iter: 0; batch classifier loss: 0.436509; batch adversarial loss: 0.637852\n",
      "epoch 192; iter: 0; batch classifier loss: 0.395301; batch adversarial loss: 0.554689\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348629; batch adversarial loss: 0.514776\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335591; batch adversarial loss: 0.591192\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339265; batch adversarial loss: 0.562155\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331983; batch adversarial loss: 0.574760\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381636; batch adversarial loss: 0.543356\n",
      "epoch 198; iter: 0; batch classifier loss: 0.294018; batch adversarial loss: 0.490812\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356368; batch adversarial loss: 0.545741\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712482; batch adversarial loss: 0.691161\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605401; batch adversarial loss: 0.653306\n",
      "epoch 2; iter: 0; batch classifier loss: 0.534622; batch adversarial loss: 0.641516\n",
      "epoch 3; iter: 0; batch classifier loss: 0.561162; batch adversarial loss: 0.651537\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616000; batch adversarial loss: 0.637909\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543934; batch adversarial loss: 0.607184\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551726; batch adversarial loss: 0.590669\n",
      "epoch 7; iter: 0; batch classifier loss: 0.483967; batch adversarial loss: 0.583096\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600035; batch adversarial loss: 0.591571\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547121; batch adversarial loss: 0.612165\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502233; batch adversarial loss: 0.549414\n",
      "epoch 11; iter: 0; batch classifier loss: 0.602018; batch adversarial loss: 0.598724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.605793; batch adversarial loss: 0.559955\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584084; batch adversarial loss: 0.554661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531683; batch adversarial loss: 0.565729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562920; batch adversarial loss: 0.567848\n",
      "epoch 16; iter: 0; batch classifier loss: 0.584328; batch adversarial loss: 0.601489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.550323; batch adversarial loss: 0.587951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544487; batch adversarial loss: 0.539060\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543501; batch adversarial loss: 0.565812\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475764; batch adversarial loss: 0.593597\n",
      "epoch 21; iter: 0; batch classifier loss: 0.505208; batch adversarial loss: 0.537838\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500623; batch adversarial loss: 0.565500\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518056; batch adversarial loss: 0.517524\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525611; batch adversarial loss: 0.578935\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528017; batch adversarial loss: 0.457839\n",
      "epoch 26; iter: 0; batch classifier loss: 0.515583; batch adversarial loss: 0.554545\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468130; batch adversarial loss: 0.494755\n",
      "epoch 28; iter: 0; batch classifier loss: 0.405671; batch adversarial loss: 0.443858\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504928; batch adversarial loss: 0.553996\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407519; batch adversarial loss: 0.518686\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425938; batch adversarial loss: 0.509277\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446521; batch adversarial loss: 0.544222\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498798; batch adversarial loss: 0.498818\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451538; batch adversarial loss: 0.479879\n",
      "epoch 35; iter: 0; batch classifier loss: 0.539078; batch adversarial loss: 0.469559\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458953; batch adversarial loss: 0.563092\n",
      "epoch 37; iter: 0; batch classifier loss: 0.391654; batch adversarial loss: 0.488154\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497411; batch adversarial loss: 0.581798\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407693; batch adversarial loss: 0.516638\n",
      "epoch 40; iter: 0; batch classifier loss: 0.384940; batch adversarial loss: 0.581418\n",
      "epoch 41; iter: 0; batch classifier loss: 0.374772; batch adversarial loss: 0.553715\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410473; batch adversarial loss: 0.535981\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402558; batch adversarial loss: 0.551051\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427253; batch adversarial loss: 0.551528\n",
      "epoch 45; iter: 0; batch classifier loss: 0.340427; batch adversarial loss: 0.486689\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409250; batch adversarial loss: 0.580182\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419968; batch adversarial loss: 0.542673\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404408; batch adversarial loss: 0.458677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423630; batch adversarial loss: 0.487026\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374566; batch adversarial loss: 0.537042\n",
      "epoch 51; iter: 0; batch classifier loss: 0.460029; batch adversarial loss: 0.522722\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457842; batch adversarial loss: 0.627601\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399155; batch adversarial loss: 0.593294\n",
      "epoch 54; iter: 0; batch classifier loss: 0.364753; batch adversarial loss: 0.610998\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396806; batch adversarial loss: 0.602084\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395211; batch adversarial loss: 0.533974\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364399; batch adversarial loss: 0.536816\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395145; batch adversarial loss: 0.508727\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444523; batch adversarial loss: 0.600005\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396248; batch adversarial loss: 0.550585\n",
      "epoch 61; iter: 0; batch classifier loss: 0.490929; batch adversarial loss: 0.567441\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452460; batch adversarial loss: 0.551896\n",
      "epoch 63; iter: 0; batch classifier loss: 0.325512; batch adversarial loss: 0.508539\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411088; batch adversarial loss: 0.600796\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416191; batch adversarial loss: 0.610499\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434633; batch adversarial loss: 0.561939\n",
      "epoch 67; iter: 0; batch classifier loss: 0.438563; batch adversarial loss: 0.528917\n",
      "epoch 68; iter: 0; batch classifier loss: 0.482620; batch adversarial loss: 0.504264\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431696; batch adversarial loss: 0.543912\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397948; batch adversarial loss: 0.507613\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365130; batch adversarial loss: 0.518252\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432110; batch adversarial loss: 0.573469\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368948; batch adversarial loss: 0.544374\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408401; batch adversarial loss: 0.571197\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407117; batch adversarial loss: 0.512159\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374281; batch adversarial loss: 0.579919\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420373; batch adversarial loss: 0.480389\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380945; batch adversarial loss: 0.519624\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399477; batch adversarial loss: 0.453286\n",
      "epoch 80; iter: 0; batch classifier loss: 0.319924; batch adversarial loss: 0.487846\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398189; batch adversarial loss: 0.534210\n",
      "epoch 82; iter: 0; batch classifier loss: 0.491087; batch adversarial loss: 0.500350\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381892; batch adversarial loss: 0.525462\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410067; batch adversarial loss: 0.543050\n",
      "epoch 85; iter: 0; batch classifier loss: 0.420260; batch adversarial loss: 0.592231\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369987; batch adversarial loss: 0.536515\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369395; batch adversarial loss: 0.447202\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397516; batch adversarial loss: 0.497467\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417012; batch adversarial loss: 0.630544\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380857; batch adversarial loss: 0.543808\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395099; batch adversarial loss: 0.589215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387014; batch adversarial loss: 0.563303\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342361; batch adversarial loss: 0.666294\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357115; batch adversarial loss: 0.544970\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375000; batch adversarial loss: 0.590120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.478495; batch adversarial loss: 0.517563\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369050; batch adversarial loss: 0.518719\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401231; batch adversarial loss: 0.457931\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360144; batch adversarial loss: 0.525321\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350112; batch adversarial loss: 0.486976\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401983; batch adversarial loss: 0.495043\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380540; batch adversarial loss: 0.515939\n",
      "epoch 103; iter: 0; batch classifier loss: 0.385115; batch adversarial loss: 0.527438\n",
      "epoch 104; iter: 0; batch classifier loss: 0.302723; batch adversarial loss: 0.649135\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371421; batch adversarial loss: 0.487623\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356516; batch adversarial loss: 0.499545\n",
      "epoch 107; iter: 0; batch classifier loss: 0.500555; batch adversarial loss: 0.505243\n",
      "epoch 108; iter: 0; batch classifier loss: 0.328509; batch adversarial loss: 0.599496\n",
      "epoch 109; iter: 0; batch classifier loss: 0.427295; batch adversarial loss: 0.523870\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389237; batch adversarial loss: 0.524187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389722; batch adversarial loss: 0.557390\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363827; batch adversarial loss: 0.541584\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345549; batch adversarial loss: 0.496408\n",
      "epoch 114; iter: 0; batch classifier loss: 0.317739; batch adversarial loss: 0.525136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115; iter: 0; batch classifier loss: 0.379747; batch adversarial loss: 0.517304\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348767; batch adversarial loss: 0.534876\n",
      "epoch 117; iter: 0; batch classifier loss: 0.506557; batch adversarial loss: 0.558448\n",
      "epoch 118; iter: 0; batch classifier loss: 0.318430; batch adversarial loss: 0.536774\n",
      "epoch 119; iter: 0; batch classifier loss: 0.467976; batch adversarial loss: 0.466496\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361346; batch adversarial loss: 0.533257\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321700; batch adversarial loss: 0.584484\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397540; batch adversarial loss: 0.450159\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369794; batch adversarial loss: 0.506357\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384647; batch adversarial loss: 0.447516\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372375; batch adversarial loss: 0.513009\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394398; batch adversarial loss: 0.495555\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358401; batch adversarial loss: 0.568665\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308317; batch adversarial loss: 0.612762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355355; batch adversarial loss: 0.560085\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393253; batch adversarial loss: 0.514399\n",
      "epoch 131; iter: 0; batch classifier loss: 0.395560; batch adversarial loss: 0.496482\n",
      "epoch 132; iter: 0; batch classifier loss: 0.348215; batch adversarial loss: 0.535896\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362892; batch adversarial loss: 0.517086\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344131; batch adversarial loss: 0.485969\n",
      "epoch 135; iter: 0; batch classifier loss: 0.327576; batch adversarial loss: 0.609263\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343169; batch adversarial loss: 0.507402\n",
      "epoch 137; iter: 0; batch classifier loss: 0.240532; batch adversarial loss: 0.504931\n",
      "epoch 138; iter: 0; batch classifier loss: 0.324266; batch adversarial loss: 0.486201\n",
      "epoch 139; iter: 0; batch classifier loss: 0.442605; batch adversarial loss: 0.585195\n",
      "epoch 140; iter: 0; batch classifier loss: 0.331466; batch adversarial loss: 0.542861\n",
      "epoch 141; iter: 0; batch classifier loss: 0.314695; batch adversarial loss: 0.562983\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389650; batch adversarial loss: 0.592011\n",
      "epoch 143; iter: 0; batch classifier loss: 0.340353; batch adversarial loss: 0.489015\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350249; batch adversarial loss: 0.478310\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342753; batch adversarial loss: 0.541800\n",
      "epoch 146; iter: 0; batch classifier loss: 0.340249; batch adversarial loss: 0.514476\n",
      "epoch 147; iter: 0; batch classifier loss: 0.375430; batch adversarial loss: 0.515942\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331931; batch adversarial loss: 0.598502\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314222; batch adversarial loss: 0.534630\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387408; batch adversarial loss: 0.521876\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408489; batch adversarial loss: 0.535788\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364320; batch adversarial loss: 0.577278\n",
      "epoch 153; iter: 0; batch classifier loss: 0.308502; batch adversarial loss: 0.532547\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298176; batch adversarial loss: 0.476616\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367578; batch adversarial loss: 0.555565\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313663; batch adversarial loss: 0.532731\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378481; batch adversarial loss: 0.540735\n",
      "epoch 158; iter: 0; batch classifier loss: 0.288951; batch adversarial loss: 0.586473\n",
      "epoch 159; iter: 0; batch classifier loss: 0.318378; batch adversarial loss: 0.543992\n",
      "epoch 160; iter: 0; batch classifier loss: 0.271803; batch adversarial loss: 0.520429\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311189; batch adversarial loss: 0.440895\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311658; batch adversarial loss: 0.510060\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400506; batch adversarial loss: 0.543322\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392400; batch adversarial loss: 0.557174\n",
      "epoch 165; iter: 0; batch classifier loss: 0.428974; batch adversarial loss: 0.651512\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340500; batch adversarial loss: 0.563923\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401089; batch adversarial loss: 0.589523\n",
      "epoch 168; iter: 0; batch classifier loss: 0.360443; batch adversarial loss: 0.510802\n",
      "epoch 169; iter: 0; batch classifier loss: 0.274332; batch adversarial loss: 0.588138\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345945; batch adversarial loss: 0.545100\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389207; batch adversarial loss: 0.709341\n",
      "epoch 172; iter: 0; batch classifier loss: 0.299316; batch adversarial loss: 0.524220\n",
      "epoch 173; iter: 0; batch classifier loss: 0.295158; batch adversarial loss: 0.556756\n",
      "epoch 174; iter: 0; batch classifier loss: 0.282373; batch adversarial loss: 0.557880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.399384; batch adversarial loss: 0.506688\n",
      "epoch 176; iter: 0; batch classifier loss: 0.312668; batch adversarial loss: 0.615503\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362706; batch adversarial loss: 0.572678\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364143; batch adversarial loss: 0.481904\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327482; batch adversarial loss: 0.571515\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382794; batch adversarial loss: 0.532107\n",
      "epoch 181; iter: 0; batch classifier loss: 0.304569; batch adversarial loss: 0.476752\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381122; batch adversarial loss: 0.495441\n",
      "epoch 183; iter: 0; batch classifier loss: 0.289977; batch adversarial loss: 0.541697\n",
      "epoch 184; iter: 0; batch classifier loss: 0.310645; batch adversarial loss: 0.571396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319056; batch adversarial loss: 0.496046\n",
      "epoch 186; iter: 0; batch classifier loss: 0.425537; batch adversarial loss: 0.519463\n",
      "epoch 187; iter: 0; batch classifier loss: 0.344441; batch adversarial loss: 0.691328\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379252; batch adversarial loss: 0.465110\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379127; batch adversarial loss: 0.429638\n",
      "epoch 190; iter: 0; batch classifier loss: 0.281780; batch adversarial loss: 0.522156\n",
      "epoch 191; iter: 0; batch classifier loss: 0.315123; batch adversarial loss: 0.558247\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364760; batch adversarial loss: 0.467681\n",
      "epoch 193; iter: 0; batch classifier loss: 0.266777; batch adversarial loss: 0.577183\n",
      "epoch 194; iter: 0; batch classifier loss: 0.435866; batch adversarial loss: 0.563316\n",
      "epoch 195; iter: 0; batch classifier loss: 0.282555; batch adversarial loss: 0.629135\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360337; batch adversarial loss: 0.480262\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336916; batch adversarial loss: 0.514205\n",
      "epoch 198; iter: 0; batch classifier loss: 0.327291; batch adversarial loss: 0.528921\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324349; batch adversarial loss: 0.597148\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707055; batch adversarial loss: 1.083673\n",
      "epoch 1; iter: 0; batch classifier loss: 0.882386; batch adversarial loss: 1.306656\n",
      "epoch 2; iter: 0; batch classifier loss: 1.111039; batch adversarial loss: 1.260817\n",
      "epoch 3; iter: 0; batch classifier loss: 1.178541; batch adversarial loss: 1.162493\n",
      "epoch 4; iter: 0; batch classifier loss: 1.162609; batch adversarial loss: 1.081689\n",
      "epoch 5; iter: 0; batch classifier loss: 1.214884; batch adversarial loss: 1.002820\n",
      "epoch 6; iter: 0; batch classifier loss: 1.161454; batch adversarial loss: 0.915011\n",
      "epoch 7; iter: 0; batch classifier loss: 1.179497; batch adversarial loss: 0.850207\n",
      "epoch 8; iter: 0; batch classifier loss: 1.229044; batch adversarial loss: 0.800474\n",
      "epoch 9; iter: 0; batch classifier loss: 1.085182; batch adversarial loss: 0.755574\n",
      "epoch 10; iter: 0; batch classifier loss: 1.198950; batch adversarial loss: 0.694127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 1.179308; batch adversarial loss: 0.634125\n",
      "epoch 12; iter: 0; batch classifier loss: 1.075372; batch adversarial loss: 0.614269\n",
      "epoch 13; iter: 0; batch classifier loss: 0.836065; batch adversarial loss: 0.594188\n",
      "epoch 14; iter: 0; batch classifier loss: 0.711434; batch adversarial loss: 0.592987\n",
      "epoch 15; iter: 0; batch classifier loss: 0.568563; batch adversarial loss: 0.561585\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485250; batch adversarial loss: 0.544975\n",
      "epoch 17; iter: 0; batch classifier loss: 0.549933; batch adversarial loss: 0.506337\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512866; batch adversarial loss: 0.609252\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535532; batch adversarial loss: 0.525450\n",
      "epoch 20; iter: 0; batch classifier loss: 0.536715; batch adversarial loss: 0.501656\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482496; batch adversarial loss: 0.497306\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476355; batch adversarial loss: 0.571484\n",
      "epoch 23; iter: 0; batch classifier loss: 0.552482; batch adversarial loss: 0.519692\n",
      "epoch 24; iter: 0; batch classifier loss: 0.542172; batch adversarial loss: 0.506820\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453577; batch adversarial loss: 0.513421\n",
      "epoch 26; iter: 0; batch classifier loss: 0.454092; batch adversarial loss: 0.619196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454144; batch adversarial loss: 0.508384\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456212; batch adversarial loss: 0.533669\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491096; batch adversarial loss: 0.548148\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512013; batch adversarial loss: 0.573191\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473485; batch adversarial loss: 0.618256\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513640; batch adversarial loss: 0.501208\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477222; batch adversarial loss: 0.540179\n",
      "epoch 34; iter: 0; batch classifier loss: 0.529269; batch adversarial loss: 0.545167\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457829; batch adversarial loss: 0.499508\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508840; batch adversarial loss: 0.499403\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445493; batch adversarial loss: 0.491162\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459091; batch adversarial loss: 0.526474\n",
      "epoch 39; iter: 0; batch classifier loss: 0.406370; batch adversarial loss: 0.549948\n",
      "epoch 40; iter: 0; batch classifier loss: 0.385857; batch adversarial loss: 0.499250\n",
      "epoch 41; iter: 0; batch classifier loss: 0.370161; batch adversarial loss: 0.545657\n",
      "epoch 42; iter: 0; batch classifier loss: 0.392553; batch adversarial loss: 0.548159\n",
      "epoch 43; iter: 0; batch classifier loss: 0.502808; batch adversarial loss: 0.554636\n",
      "epoch 44; iter: 0; batch classifier loss: 0.416376; batch adversarial loss: 0.537826\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383748; batch adversarial loss: 0.517119\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429794; batch adversarial loss: 0.588292\n",
      "epoch 47; iter: 0; batch classifier loss: 0.362486; batch adversarial loss: 0.558989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.506264; batch adversarial loss: 0.555133\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376287; batch adversarial loss: 0.537580\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443936; batch adversarial loss: 0.657295\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435997; batch adversarial loss: 0.510969\n",
      "epoch 52; iter: 0; batch classifier loss: 0.504716; batch adversarial loss: 0.475136\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428729; batch adversarial loss: 0.563082\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398998; batch adversarial loss: 0.618471\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432626; batch adversarial loss: 0.454320\n",
      "epoch 56; iter: 0; batch classifier loss: 0.491109; batch adversarial loss: 0.461209\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468011; batch adversarial loss: 0.590816\n",
      "epoch 58; iter: 0; batch classifier loss: 0.355672; batch adversarial loss: 0.500849\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431161; batch adversarial loss: 0.509466\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413439; batch adversarial loss: 0.518636\n",
      "epoch 61; iter: 0; batch classifier loss: 0.437735; batch adversarial loss: 0.472879\n",
      "epoch 62; iter: 0; batch classifier loss: 0.468690; batch adversarial loss: 0.437002\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416590; batch adversarial loss: 0.590086\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381762; batch adversarial loss: 0.572174\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385506; batch adversarial loss: 0.526565\n",
      "epoch 66; iter: 0; batch classifier loss: 0.484071; batch adversarial loss: 0.581228\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406354; batch adversarial loss: 0.580238\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401526; batch adversarial loss: 0.535052\n",
      "epoch 69; iter: 0; batch classifier loss: 0.327221; batch adversarial loss: 0.543992\n",
      "epoch 70; iter: 0; batch classifier loss: 0.395137; batch adversarial loss: 0.480757\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408879; batch adversarial loss: 0.516949\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427544; batch adversarial loss: 0.553351\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407449; batch adversarial loss: 0.563062\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383529; batch adversarial loss: 0.507186\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378161; batch adversarial loss: 0.543594\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394775; batch adversarial loss: 0.534573\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434330; batch adversarial loss: 0.599441\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400055; batch adversarial loss: 0.525500\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420488; batch adversarial loss: 0.552376\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412771; batch adversarial loss: 0.562564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.316942; batch adversarial loss: 0.507174\n",
      "epoch 82; iter: 0; batch classifier loss: 0.472833; batch adversarial loss: 0.508106\n",
      "epoch 83; iter: 0; batch classifier loss: 0.359659; batch adversarial loss: 0.489942\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369088; batch adversarial loss: 0.599522\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381909; batch adversarial loss: 0.616505\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398408; batch adversarial loss: 0.499763\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402507; batch adversarial loss: 0.497123\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389721; batch adversarial loss: 0.537589\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342245; batch adversarial loss: 0.543710\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417573; batch adversarial loss: 0.434704\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348816; batch adversarial loss: 0.554311\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362985; batch adversarial loss: 0.570858\n",
      "epoch 93; iter: 0; batch classifier loss: 0.355508; batch adversarial loss: 0.506580\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432043; batch adversarial loss: 0.543647\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380077; batch adversarial loss: 0.517647\n",
      "epoch 96; iter: 0; batch classifier loss: 0.360469; batch adversarial loss: 0.561047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372571; batch adversarial loss: 0.543296\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410709; batch adversarial loss: 0.546159\n",
      "epoch 99; iter: 0; batch classifier loss: 0.301073; batch adversarial loss: 0.599871\n",
      "epoch 100; iter: 0; batch classifier loss: 0.363603; batch adversarial loss: 0.536155\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395284; batch adversarial loss: 0.525179\n",
      "epoch 102; iter: 0; batch classifier loss: 0.457601; batch adversarial loss: 0.581174\n",
      "epoch 103; iter: 0; batch classifier loss: 0.283148; batch adversarial loss: 0.545956\n",
      "epoch 104; iter: 0; batch classifier loss: 0.512294; batch adversarial loss: 0.581916\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379721; batch adversarial loss: 0.583038\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343460; batch adversarial loss: 0.536584\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374154; batch adversarial loss: 0.482075\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336030; batch adversarial loss: 0.552087\n",
      "epoch 109; iter: 0; batch classifier loss: 0.442714; batch adversarial loss: 0.526693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.368007; batch adversarial loss: 0.580462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.364171; batch adversarial loss: 0.590418\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389146; batch adversarial loss: 0.562716\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370935; batch adversarial loss: 0.506395\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349534; batch adversarial loss: 0.524372\n",
      "epoch 115; iter: 0; batch classifier loss: 0.299653; batch adversarial loss: 0.460568\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370504; batch adversarial loss: 0.508323\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376640; batch adversarial loss: 0.515865\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342029; batch adversarial loss: 0.573363\n",
      "epoch 119; iter: 0; batch classifier loss: 0.325991; batch adversarial loss: 0.505069\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401818; batch adversarial loss: 0.459723\n",
      "epoch 121; iter: 0; batch classifier loss: 0.324295; batch adversarial loss: 0.579573\n",
      "epoch 122; iter: 0; batch classifier loss: 0.307522; batch adversarial loss: 0.443232\n",
      "epoch 123; iter: 0; batch classifier loss: 0.332076; batch adversarial loss: 0.563629\n",
      "epoch 124; iter: 0; batch classifier loss: 0.349488; batch adversarial loss: 0.543570\n",
      "epoch 125; iter: 0; batch classifier loss: 0.309186; batch adversarial loss: 0.599630\n",
      "epoch 126; iter: 0; batch classifier loss: 0.471834; batch adversarial loss: 0.535090\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384291; batch adversarial loss: 0.506136\n",
      "epoch 128; iter: 0; batch classifier loss: 0.450320; batch adversarial loss: 0.537012\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364913; batch adversarial loss: 0.526120\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353485; batch adversarial loss: 0.525274\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350717; batch adversarial loss: 0.554326\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365354; batch adversarial loss: 0.616367\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386886; batch adversarial loss: 0.588636\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372400; batch adversarial loss: 0.444034\n",
      "epoch 135; iter: 0; batch classifier loss: 0.269525; batch adversarial loss: 0.542436\n",
      "epoch 136; iter: 0; batch classifier loss: 0.295779; batch adversarial loss: 0.499165\n",
      "epoch 137; iter: 0; batch classifier loss: 0.406597; batch adversarial loss: 0.618976\n",
      "epoch 138; iter: 0; batch classifier loss: 0.331635; batch adversarial loss: 0.534324\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340018; batch adversarial loss: 0.555113\n",
      "epoch 140; iter: 0; batch classifier loss: 0.322941; batch adversarial loss: 0.561678\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351284; batch adversarial loss: 0.564756\n",
      "epoch 142; iter: 0; batch classifier loss: 0.401846; batch adversarial loss: 0.494039\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350547; batch adversarial loss: 0.591278\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341647; batch adversarial loss: 0.542828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412393; batch adversarial loss: 0.561958\n",
      "epoch 146; iter: 0; batch classifier loss: 0.296273; batch adversarial loss: 0.518368\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360722; batch adversarial loss: 0.542714\n",
      "epoch 148; iter: 0; batch classifier loss: 0.265738; batch adversarial loss: 0.533552\n",
      "epoch 149; iter: 0; batch classifier loss: 0.381883; batch adversarial loss: 0.505552\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359886; batch adversarial loss: 0.570975\n",
      "epoch 151; iter: 0; batch classifier loss: 0.252944; batch adversarial loss: 0.525783\n",
      "epoch 152; iter: 0; batch classifier loss: 0.312753; batch adversarial loss: 0.552507\n",
      "epoch 153; iter: 0; batch classifier loss: 0.401552; batch adversarial loss: 0.553605\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369693; batch adversarial loss: 0.499887\n",
      "epoch 155; iter: 0; batch classifier loss: 0.402690; batch adversarial loss: 0.666517\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390981; batch adversarial loss: 0.583397\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335679; batch adversarial loss: 0.526596\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354746; batch adversarial loss: 0.505676\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343232; batch adversarial loss: 0.488926\n",
      "epoch 160; iter: 0; batch classifier loss: 0.427503; batch adversarial loss: 0.497629\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339082; batch adversarial loss: 0.594053\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343010; batch adversarial loss: 0.611385\n",
      "epoch 163; iter: 0; batch classifier loss: 0.296481; batch adversarial loss: 0.499800\n",
      "epoch 164; iter: 0; batch classifier loss: 0.294992; batch adversarial loss: 0.551926\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321848; batch adversarial loss: 0.505570\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328090; batch adversarial loss: 0.588095\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336773; batch adversarial loss: 0.515345\n",
      "epoch 168; iter: 0; batch classifier loss: 0.270487; batch adversarial loss: 0.592352\n",
      "epoch 169; iter: 0; batch classifier loss: 0.305297; batch adversarial loss: 0.552725\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354770; batch adversarial loss: 0.508683\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327618; batch adversarial loss: 0.554219\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297862; batch adversarial loss: 0.516755\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301243; batch adversarial loss: 0.533125\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302606; batch adversarial loss: 0.517511\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357700; batch adversarial loss: 0.497863\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346284; batch adversarial loss: 0.594536\n",
      "epoch 177; iter: 0; batch classifier loss: 0.401062; batch adversarial loss: 0.562943\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320586; batch adversarial loss: 0.578877\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348334; batch adversarial loss: 0.532721\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322786; batch adversarial loss: 0.586775\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332264; batch adversarial loss: 0.527739\n",
      "epoch 182; iter: 0; batch classifier loss: 0.321183; batch adversarial loss: 0.535913\n",
      "epoch 183; iter: 0; batch classifier loss: 0.283807; batch adversarial loss: 0.541995\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344901; batch adversarial loss: 0.495673\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368046; batch adversarial loss: 0.543483\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340462; batch adversarial loss: 0.559879\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329200; batch adversarial loss: 0.645541\n",
      "epoch 188; iter: 0; batch classifier loss: 0.398434; batch adversarial loss: 0.541129\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351859; batch adversarial loss: 0.486518\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326203; batch adversarial loss: 0.544126\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340152; batch adversarial loss: 0.549876\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328689; batch adversarial loss: 0.561633\n",
      "epoch 193; iter: 0; batch classifier loss: 0.346905; batch adversarial loss: 0.620159\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348801; batch adversarial loss: 0.520483\n",
      "epoch 195; iter: 0; batch classifier loss: 0.262374; batch adversarial loss: 0.584123\n",
      "epoch 196; iter: 0; batch classifier loss: 0.418773; batch adversarial loss: 0.469431\n",
      "epoch 197; iter: 0; batch classifier loss: 0.380524; batch adversarial loss: 0.553838\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348226; batch adversarial loss: 0.482270\n",
      "epoch 199; iter: 0; batch classifier loss: 0.271403; batch adversarial loss: 0.507221\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700448; batch adversarial loss: 0.650282\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619926; batch adversarial loss: 0.664496\n",
      "epoch 2; iter: 0; batch classifier loss: 0.634314; batch adversarial loss: 0.641536\n",
      "epoch 3; iter: 0; batch classifier loss: 0.533410; batch adversarial loss: 0.663434\n",
      "epoch 4; iter: 0; batch classifier loss: 0.510795; batch adversarial loss: 0.655772\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518188; batch adversarial loss: 0.589195\n",
      "epoch 6; iter: 0; batch classifier loss: 0.471781; batch adversarial loss: 0.639044\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538624; batch adversarial loss: 0.631941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.492870; batch adversarial loss: 0.528246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565633; batch adversarial loss: 0.581112\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546354; batch adversarial loss: 0.567261\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564507; batch adversarial loss: 0.575951\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526119; batch adversarial loss: 0.567798\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599446; batch adversarial loss: 0.505691\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547034; batch adversarial loss: 0.574237\n",
      "epoch 15; iter: 0; batch classifier loss: 0.592498; batch adversarial loss: 0.602219\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481350; batch adversarial loss: 0.519055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479777; batch adversarial loss: 0.519467\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541899; batch adversarial loss: 0.609908\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480479; batch adversarial loss: 0.510924\n",
      "epoch 20; iter: 0; batch classifier loss: 0.535785; batch adversarial loss: 0.595912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429661; batch adversarial loss: 0.604729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486976; batch adversarial loss: 0.551386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496444; batch adversarial loss: 0.525800\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496473; batch adversarial loss: 0.512435\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511748; batch adversarial loss: 0.535145\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470003; batch adversarial loss: 0.572621\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473529; batch adversarial loss: 0.523947\n",
      "epoch 28; iter: 0; batch classifier loss: 0.411421; batch adversarial loss: 0.506483\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495232; batch adversarial loss: 0.530091\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489523; batch adversarial loss: 0.571371\n",
      "epoch 31; iter: 0; batch classifier loss: 0.575442; batch adversarial loss: 0.529305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439378; batch adversarial loss: 0.579317\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509462; batch adversarial loss: 0.580384\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464071; batch adversarial loss: 0.562946\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438307; batch adversarial loss: 0.571062\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438405; batch adversarial loss: 0.587676\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434013; batch adversarial loss: 0.561668\n",
      "epoch 38; iter: 0; batch classifier loss: 0.514925; batch adversarial loss: 0.501089\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421520; batch adversarial loss: 0.560383\n",
      "epoch 40; iter: 0; batch classifier loss: 0.366285; batch adversarial loss: 0.533171\n",
      "epoch 41; iter: 0; batch classifier loss: 0.330339; batch adversarial loss: 0.518284\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420262; batch adversarial loss: 0.462698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455240; batch adversarial loss: 0.542998\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420863; batch adversarial loss: 0.555399\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395308; batch adversarial loss: 0.568143\n",
      "epoch 46; iter: 0; batch classifier loss: 0.543733; batch adversarial loss: 0.586466\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478967; batch adversarial loss: 0.475275\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440561; batch adversarial loss: 0.505135\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463747; batch adversarial loss: 0.515827\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421366; batch adversarial loss: 0.567326\n",
      "epoch 51; iter: 0; batch classifier loss: 0.517394; batch adversarial loss: 0.571970\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430542; batch adversarial loss: 0.551418\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399223; batch adversarial loss: 0.616925\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448353; batch adversarial loss: 0.563205\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420473; batch adversarial loss: 0.560597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.496140; batch adversarial loss: 0.602697\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432021; batch adversarial loss: 0.583664\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396702; batch adversarial loss: 0.540183\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449547; batch adversarial loss: 0.517747\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425345; batch adversarial loss: 0.658662\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379369; batch adversarial loss: 0.552458\n",
      "epoch 62; iter: 0; batch classifier loss: 0.480216; batch adversarial loss: 0.499044\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387556; batch adversarial loss: 0.590618\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449388; batch adversarial loss: 0.495776\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365066; batch adversarial loss: 0.594920\n",
      "epoch 66; iter: 0; batch classifier loss: 0.490369; batch adversarial loss: 0.543415\n",
      "epoch 67; iter: 0; batch classifier loss: 0.369140; batch adversarial loss: 0.482218\n",
      "epoch 68; iter: 0; batch classifier loss: 0.504322; batch adversarial loss: 0.603810\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386824; batch adversarial loss: 0.551764\n",
      "epoch 70; iter: 0; batch classifier loss: 0.506575; batch adversarial loss: 0.472030\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417050; batch adversarial loss: 0.569270\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428405; batch adversarial loss: 0.535410\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447717; batch adversarial loss: 0.552215\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471351; batch adversarial loss: 0.505261\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375402; batch adversarial loss: 0.488790\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400243; batch adversarial loss: 0.500137\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413755; batch adversarial loss: 0.589232\n",
      "epoch 78; iter: 0; batch classifier loss: 0.452981; batch adversarial loss: 0.546083\n",
      "epoch 79; iter: 0; batch classifier loss: 0.348281; batch adversarial loss: 0.442220\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375433; batch adversarial loss: 0.490298\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463060; batch adversarial loss: 0.501789\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404485; batch adversarial loss: 0.573344\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444956; batch adversarial loss: 0.592067\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375397; batch adversarial loss: 0.583770\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431442; batch adversarial loss: 0.524786\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365731; batch adversarial loss: 0.499889\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429411; batch adversarial loss: 0.587487\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402401; batch adversarial loss: 0.500456\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419554; batch adversarial loss: 0.563483\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380793; batch adversarial loss: 0.486274\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374208; batch adversarial loss: 0.515682\n",
      "epoch 92; iter: 0; batch classifier loss: 0.489020; batch adversarial loss: 0.568172\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395273; batch adversarial loss: 0.575048\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410965; batch adversarial loss: 0.514703\n",
      "epoch 95; iter: 0; batch classifier loss: 0.443579; batch adversarial loss: 0.627861\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398730; batch adversarial loss: 0.535492\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455682; batch adversarial loss: 0.568671\n",
      "epoch 98; iter: 0; batch classifier loss: 0.489439; batch adversarial loss: 0.533872\n",
      "epoch 99; iter: 0; batch classifier loss: 0.421202; batch adversarial loss: 0.636787\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433749; batch adversarial loss: 0.629496\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434855; batch adversarial loss: 0.599627\n",
      "epoch 102; iter: 0; batch classifier loss: 0.459609; batch adversarial loss: 0.560205\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382252; batch adversarial loss: 0.661127\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350821; batch adversarial loss: 0.497842\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388850; batch adversarial loss: 0.493836\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394891; batch adversarial loss: 0.463033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.337566; batch adversarial loss: 0.599802\n",
      "epoch 108; iter: 0; batch classifier loss: 0.460384; batch adversarial loss: 0.536389\n",
      "epoch 109; iter: 0; batch classifier loss: 0.362785; batch adversarial loss: 0.501161\n",
      "epoch 110; iter: 0; batch classifier loss: 0.493527; batch adversarial loss: 0.592681\n",
      "epoch 111; iter: 0; batch classifier loss: 0.327843; batch adversarial loss: 0.665334\n",
      "epoch 112; iter: 0; batch classifier loss: 0.380401; batch adversarial loss: 0.620329\n",
      "epoch 113; iter: 0; batch classifier loss: 0.329209; batch adversarial loss: 0.589468\n",
      "epoch 114; iter: 0; batch classifier loss: 0.321304; batch adversarial loss: 0.545508\n",
      "epoch 115; iter: 0; batch classifier loss: 0.436612; batch adversarial loss: 0.637825\n",
      "epoch 116; iter: 0; batch classifier loss: 0.408366; batch adversarial loss: 0.550133\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391049; batch adversarial loss: 0.535028\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410326; batch adversarial loss: 0.443637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.316331; batch adversarial loss: 0.506430\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356867; batch adversarial loss: 0.543997\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361781; batch adversarial loss: 0.537321\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380871; batch adversarial loss: 0.588227\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365754; batch adversarial loss: 0.590931\n",
      "epoch 124; iter: 0; batch classifier loss: 0.464072; batch adversarial loss: 0.535771\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370044; batch adversarial loss: 0.506915\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350019; batch adversarial loss: 0.534546\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388183; batch adversarial loss: 0.480235\n",
      "epoch 128; iter: 0; batch classifier loss: 0.398676; batch adversarial loss: 0.585576\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362416; batch adversarial loss: 0.474131\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374529; batch adversarial loss: 0.531523\n",
      "epoch 131; iter: 0; batch classifier loss: 0.415496; batch adversarial loss: 0.505789\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407879; batch adversarial loss: 0.515829\n",
      "epoch 133; iter: 0; batch classifier loss: 0.478720; batch adversarial loss: 0.577490\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367009; batch adversarial loss: 0.542211\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382072; batch adversarial loss: 0.521775\n",
      "epoch 136; iter: 0; batch classifier loss: 0.400174; batch adversarial loss: 0.505780\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377011; batch adversarial loss: 0.452598\n",
      "epoch 138; iter: 0; batch classifier loss: 0.288982; batch adversarial loss: 0.539734\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369591; batch adversarial loss: 0.537381\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419596; batch adversarial loss: 0.590563\n",
      "epoch 141; iter: 0; batch classifier loss: 0.431966; batch adversarial loss: 0.511447\n",
      "epoch 142; iter: 0; batch classifier loss: 0.430752; batch adversarial loss: 0.579663\n",
      "epoch 143; iter: 0; batch classifier loss: 0.372346; batch adversarial loss: 0.519650\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350038; batch adversarial loss: 0.566085\n",
      "epoch 145; iter: 0; batch classifier loss: 0.336322; batch adversarial loss: 0.597500\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343870; batch adversarial loss: 0.611163\n",
      "epoch 147; iter: 0; batch classifier loss: 0.452758; batch adversarial loss: 0.516134\n",
      "epoch 148; iter: 0; batch classifier loss: 0.425530; batch adversarial loss: 0.603445\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418216; batch adversarial loss: 0.580192\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389022; batch adversarial loss: 0.539951\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365580; batch adversarial loss: 0.478975\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357853; batch adversarial loss: 0.489968\n",
      "epoch 153; iter: 0; batch classifier loss: 0.425444; batch adversarial loss: 0.517987\n",
      "epoch 154; iter: 0; batch classifier loss: 0.403077; batch adversarial loss: 0.546983\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383725; batch adversarial loss: 0.462422\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402903; batch adversarial loss: 0.619390\n",
      "epoch 157; iter: 0; batch classifier loss: 0.465016; batch adversarial loss: 0.561895\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361169; batch adversarial loss: 0.608860\n",
      "epoch 159; iter: 0; batch classifier loss: 0.320049; batch adversarial loss: 0.527285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.408874; batch adversarial loss: 0.591327\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369888; batch adversarial loss: 0.559742\n",
      "epoch 162; iter: 0; batch classifier loss: 0.469074; batch adversarial loss: 0.545373\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416287; batch adversarial loss: 0.663247\n",
      "epoch 164; iter: 0; batch classifier loss: 0.288224; batch adversarial loss: 0.606403\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358079; batch adversarial loss: 0.600203\n",
      "epoch 166; iter: 0; batch classifier loss: 0.439517; batch adversarial loss: 0.588053\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401040; batch adversarial loss: 0.581408\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392031; batch adversarial loss: 0.540913\n",
      "epoch 169; iter: 0; batch classifier loss: 0.441312; batch adversarial loss: 0.545633\n",
      "epoch 170; iter: 0; batch classifier loss: 0.394227; batch adversarial loss: 0.580265\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370568; batch adversarial loss: 0.614042\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398046; batch adversarial loss: 0.632720\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355876; batch adversarial loss: 0.600890\n",
      "epoch 174; iter: 0; batch classifier loss: 0.307370; batch adversarial loss: 0.556296\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349146; batch adversarial loss: 0.545888\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369415; batch adversarial loss: 0.624077\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354543; batch adversarial loss: 0.543549\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326171; batch adversarial loss: 0.520328\n",
      "epoch 179; iter: 0; batch classifier loss: 0.300688; batch adversarial loss: 0.539115\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396686; batch adversarial loss: 0.471431\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367789; batch adversarial loss: 0.479806\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339764; batch adversarial loss: 0.518657\n",
      "epoch 183; iter: 0; batch classifier loss: 0.446147; batch adversarial loss: 0.554100\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352130; batch adversarial loss: 0.570936\n",
      "epoch 185; iter: 0; batch classifier loss: 0.405814; batch adversarial loss: 0.532423\n",
      "epoch 186; iter: 0; batch classifier loss: 0.429858; batch adversarial loss: 0.529456\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393861; batch adversarial loss: 0.512516\n",
      "epoch 188; iter: 0; batch classifier loss: 0.441896; batch adversarial loss: 0.435693\n",
      "epoch 189; iter: 0; batch classifier loss: 0.419247; batch adversarial loss: 0.498536\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376376; batch adversarial loss: 0.525234\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335929; batch adversarial loss: 0.533782\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404218; batch adversarial loss: 0.600239\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382452; batch adversarial loss: 0.554638\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358840; batch adversarial loss: 0.527412\n",
      "epoch 195; iter: 0; batch classifier loss: 0.299525; batch adversarial loss: 0.426118\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343153; batch adversarial loss: 0.603193\n",
      "epoch 197; iter: 0; batch classifier loss: 0.359342; batch adversarial loss: 0.544734\n",
      "epoch 198; iter: 0; batch classifier loss: 0.282418; batch adversarial loss: 0.625051\n",
      "epoch 199; iter: 0; batch classifier loss: 0.406260; batch adversarial loss: 0.505562\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698508; batch adversarial loss: 0.605622\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538280; batch adversarial loss: 0.603132\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621891; batch adversarial loss: 0.585298\n",
      "epoch 3; iter: 0; batch classifier loss: 0.675718; batch adversarial loss: 0.645445\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621964; batch adversarial loss: 0.655061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.571225; batch adversarial loss: 0.648260\n",
      "epoch 6; iter: 0; batch classifier loss: 0.498870; batch adversarial loss: 0.616121\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548029; batch adversarial loss: 0.592566\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568197; batch adversarial loss: 0.603648\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571852; batch adversarial loss: 0.581036\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529421; batch adversarial loss: 0.579165\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504357; batch adversarial loss: 0.566057\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572058; batch adversarial loss: 0.566452\n",
      "epoch 13; iter: 0; batch classifier loss: 0.589845; batch adversarial loss: 0.592000\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515263; batch adversarial loss: 0.590309\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519930; batch adversarial loss: 0.602090\n",
      "epoch 16; iter: 0; batch classifier loss: 0.606803; batch adversarial loss: 0.556779\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508486; batch adversarial loss: 0.601144\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555705; batch adversarial loss: 0.585074\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520826; batch adversarial loss: 0.455163\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507613; batch adversarial loss: 0.561472\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487414; batch adversarial loss: 0.519137\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517520; batch adversarial loss: 0.619040\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494509; batch adversarial loss: 0.579638\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440967; batch adversarial loss: 0.563300\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489966; batch adversarial loss: 0.587354\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514969; batch adversarial loss: 0.504967\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462937; batch adversarial loss: 0.520724\n",
      "epoch 28; iter: 0; batch classifier loss: 0.503915; batch adversarial loss: 0.562737\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440699; batch adversarial loss: 0.458447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483854; batch adversarial loss: 0.570615\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400812; batch adversarial loss: 0.534527\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517508; batch adversarial loss: 0.473834\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498460; batch adversarial loss: 0.535375\n",
      "epoch 34; iter: 0; batch classifier loss: 0.518315; batch adversarial loss: 0.536825\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420956; batch adversarial loss: 0.518493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472067; batch adversarial loss: 0.482937\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460731; batch adversarial loss: 0.509258\n",
      "epoch 38; iter: 0; batch classifier loss: 0.479257; batch adversarial loss: 0.589981\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483233; batch adversarial loss: 0.571536\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464839; batch adversarial loss: 0.544075\n",
      "epoch 41; iter: 0; batch classifier loss: 0.495213; batch adversarial loss: 0.498998\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432741; batch adversarial loss: 0.553880\n",
      "epoch 43; iter: 0; batch classifier loss: 0.515473; batch adversarial loss: 0.589189\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440959; batch adversarial loss: 0.581180\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444014; batch adversarial loss: 0.517387\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425482; batch adversarial loss: 0.552478\n",
      "epoch 47; iter: 0; batch classifier loss: 0.363348; batch adversarial loss: 0.489489\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454630; batch adversarial loss: 0.580022\n",
      "epoch 49; iter: 0; batch classifier loss: 0.488813; batch adversarial loss: 0.573802\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462182; batch adversarial loss: 0.544368\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429415; batch adversarial loss: 0.507532\n",
      "epoch 52; iter: 0; batch classifier loss: 0.377404; batch adversarial loss: 0.517350\n",
      "epoch 53; iter: 0; batch classifier loss: 0.492246; batch adversarial loss: 0.554034\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395720; batch adversarial loss: 0.608609\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432326; batch adversarial loss: 0.563603\n",
      "epoch 56; iter: 0; batch classifier loss: 0.386145; batch adversarial loss: 0.616818\n",
      "epoch 57; iter: 0; batch classifier loss: 0.493757; batch adversarial loss: 0.554875\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396752; batch adversarial loss: 0.463264\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385925; batch adversarial loss: 0.498663\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386841; batch adversarial loss: 0.554035\n",
      "epoch 61; iter: 0; batch classifier loss: 0.361561; batch adversarial loss: 0.606984\n",
      "epoch 62; iter: 0; batch classifier loss: 0.461977; batch adversarial loss: 0.598935\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419473; batch adversarial loss: 0.480891\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440792; batch adversarial loss: 0.598823\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427072; batch adversarial loss: 0.570936\n",
      "epoch 66; iter: 0; batch classifier loss: 0.362619; batch adversarial loss: 0.544601\n",
      "epoch 67; iter: 0; batch classifier loss: 0.462810; batch adversarial loss: 0.544594\n",
      "epoch 68; iter: 0; batch classifier loss: 0.372679; batch adversarial loss: 0.535844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376396; batch adversarial loss: 0.527740\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431740; batch adversarial loss: 0.490807\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425830; batch adversarial loss: 0.509050\n",
      "epoch 72; iter: 0; batch classifier loss: 0.472666; batch adversarial loss: 0.508816\n",
      "epoch 73; iter: 0; batch classifier loss: 0.475675; batch adversarial loss: 0.535179\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394445; batch adversarial loss: 0.588568\n",
      "epoch 75; iter: 0; batch classifier loss: 0.297561; batch adversarial loss: 0.552398\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416911; batch adversarial loss: 0.552737\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393002; batch adversarial loss: 0.580529\n",
      "epoch 78; iter: 0; batch classifier loss: 0.449336; batch adversarial loss: 0.516262\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439157; batch adversarial loss: 0.526612\n",
      "epoch 80; iter: 0; batch classifier loss: 0.355331; batch adversarial loss: 0.524707\n",
      "epoch 81; iter: 0; batch classifier loss: 0.346752; batch adversarial loss: 0.554140\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435026; batch adversarial loss: 0.490846\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407295; batch adversarial loss: 0.526280\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388742; batch adversarial loss: 0.526205\n",
      "epoch 85; iter: 0; batch classifier loss: 0.470333; batch adversarial loss: 0.580996\n",
      "epoch 86; iter: 0; batch classifier loss: 0.434274; batch adversarial loss: 0.535254\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371601; batch adversarial loss: 0.517122\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371291; batch adversarial loss: 0.582048\n",
      "epoch 89; iter: 0; batch classifier loss: 0.442036; batch adversarial loss: 0.504384\n",
      "epoch 90; iter: 0; batch classifier loss: 0.346835; batch adversarial loss: 0.545149\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384610; batch adversarial loss: 0.554432\n",
      "epoch 92; iter: 0; batch classifier loss: 0.431645; batch adversarial loss: 0.552750\n",
      "epoch 93; iter: 0; batch classifier loss: 0.319694; batch adversarial loss: 0.589598\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383032; batch adversarial loss: 0.615919\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440893; batch adversarial loss: 0.508442\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418638; batch adversarial loss: 0.498902\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382646; batch adversarial loss: 0.509614\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358617; batch adversarial loss: 0.626993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400679; batch adversarial loss: 0.481921\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399930; batch adversarial loss: 0.614941\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347785; batch adversarial loss: 0.535501\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363500; batch adversarial loss: 0.535123\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363780; batch adversarial loss: 0.536572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.487540; batch adversarial loss: 0.545226\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384286; batch adversarial loss: 0.498045\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355459; batch adversarial loss: 0.571518\n",
      "epoch 107; iter: 0; batch classifier loss: 0.463824; batch adversarial loss: 0.535634\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384276; batch adversarial loss: 0.517144\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366411; batch adversarial loss: 0.509957\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368772; batch adversarial loss: 0.600206\n",
      "epoch 111; iter: 0; batch classifier loss: 0.392113; batch adversarial loss: 0.599119\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394505; batch adversarial loss: 0.634559\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383853; batch adversarial loss: 0.527210\n",
      "epoch 114; iter: 0; batch classifier loss: 0.482646; batch adversarial loss: 0.516909\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407182; batch adversarial loss: 0.489770\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356149; batch adversarial loss: 0.526000\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354906; batch adversarial loss: 0.570708\n",
      "epoch 118; iter: 0; batch classifier loss: 0.350627; batch adversarial loss: 0.553339\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441823; batch adversarial loss: 0.552818\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349120; batch adversarial loss: 0.526888\n",
      "epoch 121; iter: 0; batch classifier loss: 0.425968; batch adversarial loss: 0.606939\n",
      "epoch 122; iter: 0; batch classifier loss: 0.314461; batch adversarial loss: 0.589276\n",
      "epoch 123; iter: 0; batch classifier loss: 0.469531; batch adversarial loss: 0.590110\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338974; batch adversarial loss: 0.626446\n",
      "epoch 125; iter: 0; batch classifier loss: 0.357618; batch adversarial loss: 0.559910\n",
      "epoch 126; iter: 0; batch classifier loss: 0.454324; batch adversarial loss: 0.616653\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339251; batch adversarial loss: 0.571625\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360034; batch adversarial loss: 0.596878\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369882; batch adversarial loss: 0.536088\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393171; batch adversarial loss: 0.473381\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373993; batch adversarial loss: 0.524405\n",
      "epoch 132; iter: 0; batch classifier loss: 0.385757; batch adversarial loss: 0.573900\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404417; batch adversarial loss: 0.553076\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358491; batch adversarial loss: 0.498220\n",
      "epoch 135; iter: 0; batch classifier loss: 0.283880; batch adversarial loss: 0.571503\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371097; batch adversarial loss: 0.541396\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374478; batch adversarial loss: 0.616221\n",
      "epoch 138; iter: 0; batch classifier loss: 0.339337; batch adversarial loss: 0.526099\n",
      "epoch 139; iter: 0; batch classifier loss: 0.458923; batch adversarial loss: 0.555494\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409069; batch adversarial loss: 0.544486\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386280; batch adversarial loss: 0.551128\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334542; batch adversarial loss: 0.598072\n",
      "epoch 143; iter: 0; batch classifier loss: 0.340806; batch adversarial loss: 0.536710\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312415; batch adversarial loss: 0.534857\n",
      "epoch 145; iter: 0; batch classifier loss: 0.301256; batch adversarial loss: 0.563501\n",
      "epoch 146; iter: 0; batch classifier loss: 0.431190; batch adversarial loss: 0.590275\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337710; batch adversarial loss: 0.590004\n",
      "epoch 148; iter: 0; batch classifier loss: 0.414577; batch adversarial loss: 0.499198\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355915; batch adversarial loss: 0.555833\n",
      "epoch 150; iter: 0; batch classifier loss: 0.321962; batch adversarial loss: 0.517112\n",
      "epoch 151; iter: 0; batch classifier loss: 0.335734; batch adversarial loss: 0.448283\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362477; batch adversarial loss: 0.551911\n",
      "epoch 153; iter: 0; batch classifier loss: 0.340771; batch adversarial loss: 0.563461\n",
      "epoch 154; iter: 0; batch classifier loss: 0.297770; batch adversarial loss: 0.598220\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350725; batch adversarial loss: 0.553331\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392595; batch adversarial loss: 0.500473\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365569; batch adversarial loss: 0.619696\n",
      "epoch 158; iter: 0; batch classifier loss: 0.331208; batch adversarial loss: 0.622618\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389440; batch adversarial loss: 0.602146\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386234; batch adversarial loss: 0.499540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376611; batch adversarial loss: 0.535212\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368524; batch adversarial loss: 0.625180\n",
      "epoch 163; iter: 0; batch classifier loss: 0.443034; batch adversarial loss: 0.520779\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414836; batch adversarial loss: 0.542853\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361315; batch adversarial loss: 0.609532\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367347; batch adversarial loss: 0.528014\n",
      "epoch 167; iter: 0; batch classifier loss: 0.412048; batch adversarial loss: 0.506520\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356858; batch adversarial loss: 0.489334\n",
      "epoch 169; iter: 0; batch classifier loss: 0.401553; batch adversarial loss: 0.526976\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386422; batch adversarial loss: 0.502989\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370659; batch adversarial loss: 0.571470\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351747; batch adversarial loss: 0.680012\n",
      "epoch 173; iter: 0; batch classifier loss: 0.469852; batch adversarial loss: 0.541393\n",
      "epoch 174; iter: 0; batch classifier loss: 0.503644; batch adversarial loss: 0.480574\n",
      "epoch 175; iter: 0; batch classifier loss: 0.275479; batch adversarial loss: 0.557670\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319664; batch adversarial loss: 0.518927\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371358; batch adversarial loss: 0.588976\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417442; batch adversarial loss: 0.564670\n",
      "epoch 179; iter: 0; batch classifier loss: 0.435942; batch adversarial loss: 0.590754\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388722; batch adversarial loss: 0.489497\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338811; batch adversarial loss: 0.604421\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363557; batch adversarial loss: 0.477475\n",
      "epoch 183; iter: 0; batch classifier loss: 0.435286; batch adversarial loss: 0.532338\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413860; batch adversarial loss: 0.516526\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321631; batch adversarial loss: 0.597418\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398146; batch adversarial loss: 0.583815\n",
      "epoch 187; iter: 0; batch classifier loss: 0.296716; batch adversarial loss: 0.597900\n",
      "epoch 188; iter: 0; batch classifier loss: 0.327225; batch adversarial loss: 0.563016\n",
      "epoch 189; iter: 0; batch classifier loss: 0.326673; batch adversarial loss: 0.561175\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395538; batch adversarial loss: 0.561804\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374735; batch adversarial loss: 0.533610\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375787; batch adversarial loss: 0.558140\n",
      "epoch 193; iter: 0; batch classifier loss: 0.384246; batch adversarial loss: 0.560985\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365236; batch adversarial loss: 0.453529\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392867; batch adversarial loss: 0.479899\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310069; batch adversarial loss: 0.499907\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337067; batch adversarial loss: 0.536071\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352999; batch adversarial loss: 0.551409\n",
      "epoch 199; iter: 0; batch classifier loss: 0.405601; batch adversarial loss: 0.565889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.674225; batch adversarial loss: 0.688929\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631343; batch adversarial loss: 0.673872\n",
      "epoch 2; iter: 0; batch classifier loss: 0.620278; batch adversarial loss: 0.607447\n",
      "epoch 3; iter: 0; batch classifier loss: 0.521681; batch adversarial loss: 0.607313\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558292; batch adversarial loss: 0.612150\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546541; batch adversarial loss: 0.617826\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482153; batch adversarial loss: 0.621192\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605038; batch adversarial loss: 0.586710\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571904; batch adversarial loss: 0.579295\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462815; batch adversarial loss: 0.589952\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571165; batch adversarial loss: 0.612026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494807; batch adversarial loss: 0.590936\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544803; batch adversarial loss: 0.548238\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513738; batch adversarial loss: 0.600577\n",
      "epoch 14; iter: 0; batch classifier loss: 0.561176; batch adversarial loss: 0.609386\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527209; batch adversarial loss: 0.600470\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465915; batch adversarial loss: 0.578796\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533265; batch adversarial loss: 0.583622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544320; batch adversarial loss: 0.578803\n",
      "epoch 19; iter: 0; batch classifier loss: 0.589245; batch adversarial loss: 0.585199\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522076; batch adversarial loss: 0.595993\n",
      "epoch 21; iter: 0; batch classifier loss: 0.556272; batch adversarial loss: 0.623725\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479935; batch adversarial loss: 0.519297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487031; batch adversarial loss: 0.578339\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479367; batch adversarial loss: 0.565408\n",
      "epoch 25; iter: 0; batch classifier loss: 0.444689; batch adversarial loss: 0.590692\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492171; batch adversarial loss: 0.604031\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413215; batch adversarial loss: 0.524772\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416215; batch adversarial loss: 0.539546\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496466; batch adversarial loss: 0.603429\n",
      "epoch 30; iter: 0; batch classifier loss: 0.393530; batch adversarial loss: 0.579658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438142; batch adversarial loss: 0.537697\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457188; batch adversarial loss: 0.604812\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427670; batch adversarial loss: 0.604544\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461523; batch adversarial loss: 0.579875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445734; batch adversarial loss: 0.622503\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492297; batch adversarial loss: 0.640574\n",
      "epoch 37; iter: 0; batch classifier loss: 0.521881; batch adversarial loss: 0.579574\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482778; batch adversarial loss: 0.579550\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438409; batch adversarial loss: 0.517564\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492101; batch adversarial loss: 0.534486\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395269; batch adversarial loss: 0.562407\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439518; batch adversarial loss: 0.598762\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393408; batch adversarial loss: 0.588218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490483; batch adversarial loss: 0.615145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426048; batch adversarial loss: 0.499034\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440379; batch adversarial loss: 0.633264\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416417; batch adversarial loss: 0.562208\n",
      "epoch 48; iter: 0; batch classifier loss: 0.499127; batch adversarial loss: 0.563417\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416928; batch adversarial loss: 0.526516\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455838; batch adversarial loss: 0.510322\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457243; batch adversarial loss: 0.535102\n",
      "epoch 52; iter: 0; batch classifier loss: 0.343029; batch adversarial loss: 0.650399\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422945; batch adversarial loss: 0.562332\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388853; batch adversarial loss: 0.544552\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422523; batch adversarial loss: 0.507764\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387960; batch adversarial loss: 0.501088\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436489; batch adversarial loss: 0.456027\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428896; batch adversarial loss: 0.500654\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478188; batch adversarial loss: 0.491198\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385899; batch adversarial loss: 0.572035\n",
      "epoch 61; iter: 0; batch classifier loss: 0.482233; batch adversarial loss: 0.535505\n",
      "epoch 62; iter: 0; batch classifier loss: 0.431279; batch adversarial loss: 0.606228\n",
      "epoch 63; iter: 0; batch classifier loss: 0.367159; batch adversarial loss: 0.545096\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400507; batch adversarial loss: 0.588973\n",
      "epoch 65; iter: 0; batch classifier loss: 0.446212; batch adversarial loss: 0.472767\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416046; batch adversarial loss: 0.598399\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420692; batch adversarial loss: 0.517571\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442032; batch adversarial loss: 0.463663\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425407; batch adversarial loss: 0.473393\n",
      "epoch 70; iter: 0; batch classifier loss: 0.456617; batch adversarial loss: 0.580982\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402277; batch adversarial loss: 0.607522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.375800; batch adversarial loss: 0.579726\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448542; batch adversarial loss: 0.643009\n",
      "epoch 74; iter: 0; batch classifier loss: 0.484955; batch adversarial loss: 0.579631\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403152; batch adversarial loss: 0.562820\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405172; batch adversarial loss: 0.507966\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374673; batch adversarial loss: 0.571512\n",
      "epoch 78; iter: 0; batch classifier loss: 0.435700; batch adversarial loss: 0.499895\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366945; batch adversarial loss: 0.509381\n",
      "epoch 80; iter: 0; batch classifier loss: 0.373169; batch adversarial loss: 0.536220\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361465; batch adversarial loss: 0.553276\n",
      "epoch 82; iter: 0; batch classifier loss: 0.498133; batch adversarial loss: 0.500428\n",
      "epoch 83; iter: 0; batch classifier loss: 0.296746; batch adversarial loss: 0.518694\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410179; batch adversarial loss: 0.571548\n",
      "epoch 85; iter: 0; batch classifier loss: 0.444320; batch adversarial loss: 0.562728\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364777; batch adversarial loss: 0.544781\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356876; batch adversarial loss: 0.526465\n",
      "epoch 88; iter: 0; batch classifier loss: 0.364069; batch adversarial loss: 0.535322\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350972; batch adversarial loss: 0.581146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.287829; batch adversarial loss: 0.580945\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377226; batch adversarial loss: 0.518354\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383676; batch adversarial loss: 0.491197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429503; batch adversarial loss: 0.571638\n",
      "epoch 94; iter: 0; batch classifier loss: 0.412214; batch adversarial loss: 0.499846\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424449; batch adversarial loss: 0.623691\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408557; batch adversarial loss: 0.552882\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392082; batch adversarial loss: 0.613724\n",
      "epoch 98; iter: 0; batch classifier loss: 0.457357; batch adversarial loss: 0.533308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.399388; batch adversarial loss: 0.568431\n",
      "epoch 100; iter: 0; batch classifier loss: 0.464935; batch adversarial loss: 0.541666\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411638; batch adversarial loss: 0.581837\n",
      "epoch 102; iter: 0; batch classifier loss: 0.346155; batch adversarial loss: 0.509638\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396591; batch adversarial loss: 0.563544\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366058; batch adversarial loss: 0.516760\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384680; batch adversarial loss: 0.673658\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419206; batch adversarial loss: 0.608960\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352872; batch adversarial loss: 0.517411\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357380; batch adversarial loss: 0.508515\n",
      "epoch 109; iter: 0; batch classifier loss: 0.326042; batch adversarial loss: 0.544963\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427241; batch adversarial loss: 0.544352\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376566; batch adversarial loss: 0.589592\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412686; batch adversarial loss: 0.526531\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425487; batch adversarial loss: 0.697193\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402764; batch adversarial loss: 0.499869\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339058; batch adversarial loss: 0.526708\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356778; batch adversarial loss: 0.580538\n",
      "epoch 117; iter: 0; batch classifier loss: 0.336431; batch adversarial loss: 0.607330\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399138; batch adversarial loss: 0.508765\n",
      "epoch 119; iter: 0; batch classifier loss: 0.430481; batch adversarial loss: 0.553484\n",
      "epoch 120; iter: 0; batch classifier loss: 0.392799; batch adversarial loss: 0.553639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414413; batch adversarial loss: 0.535634\n",
      "epoch 122; iter: 0; batch classifier loss: 0.445405; batch adversarial loss: 0.481883\n",
      "epoch 123; iter: 0; batch classifier loss: 0.371137; batch adversarial loss: 0.571088\n",
      "epoch 124; iter: 0; batch classifier loss: 0.438451; batch adversarial loss: 0.517882\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391727; batch adversarial loss: 0.580551\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361029; batch adversarial loss: 0.571406\n",
      "epoch 127; iter: 0; batch classifier loss: 0.373075; batch adversarial loss: 0.455462\n",
      "epoch 128; iter: 0; batch classifier loss: 0.306824; batch adversarial loss: 0.598405\n",
      "epoch 129; iter: 0; batch classifier loss: 0.330672; batch adversarial loss: 0.687165\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356866; batch adversarial loss: 0.562875\n",
      "epoch 131; iter: 0; batch classifier loss: 0.449644; batch adversarial loss: 0.518126\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369511; batch adversarial loss: 0.545220\n",
      "epoch 133; iter: 0; batch classifier loss: 0.406534; batch adversarial loss: 0.544949\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394370; batch adversarial loss: 0.607129\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381835; batch adversarial loss: 0.579640\n",
      "epoch 136; iter: 0; batch classifier loss: 0.451877; batch adversarial loss: 0.526441\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.571564\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365207; batch adversarial loss: 0.508913\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374426; batch adversarial loss: 0.545155\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405283; batch adversarial loss: 0.634176\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387788; batch adversarial loss: 0.535545\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368754; batch adversarial loss: 0.597621\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332651; batch adversarial loss: 0.580469\n",
      "epoch 144; iter: 0; batch classifier loss: 0.423334; batch adversarial loss: 0.553364\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398734; batch adversarial loss: 0.580495\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385515; batch adversarial loss: 0.562247\n",
      "epoch 147; iter: 0; batch classifier loss: 0.411666; batch adversarial loss: 0.473448\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413926; batch adversarial loss: 0.535258\n",
      "epoch 149; iter: 0; batch classifier loss: 0.411463; batch adversarial loss: 0.580379\n",
      "epoch 150; iter: 0; batch classifier loss: 0.323085; batch adversarial loss: 0.588899\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353327; batch adversarial loss: 0.526165\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382416; batch adversarial loss: 0.526508\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335065; batch adversarial loss: 0.517777\n",
      "epoch 154; iter: 0; batch classifier loss: 0.380109; batch adversarial loss: 0.499794\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337057; batch adversarial loss: 0.518139\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313717; batch adversarial loss: 0.561778\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330640; batch adversarial loss: 0.570794\n",
      "epoch 158; iter: 0; batch classifier loss: 0.432841; batch adversarial loss: 0.607488\n",
      "epoch 159; iter: 0; batch classifier loss: 0.315254; batch adversarial loss: 0.572047\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413114; batch adversarial loss: 0.544619\n",
      "epoch 161; iter: 0; batch classifier loss: 0.427431; batch adversarial loss: 0.562207\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376357; batch adversarial loss: 0.579969\n",
      "epoch 163; iter: 0; batch classifier loss: 0.390603; batch adversarial loss: 0.464058\n",
      "epoch 164; iter: 0; batch classifier loss: 0.310233; batch adversarial loss: 0.589368\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377761; batch adversarial loss: 0.517808\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312966; batch adversarial loss: 0.509343\n",
      "epoch 167; iter: 0; batch classifier loss: 0.456546; batch adversarial loss: 0.544577\n",
      "epoch 168; iter: 0; batch classifier loss: 0.355628; batch adversarial loss: 0.535234\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403242; batch adversarial loss: 0.571469\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364720; batch adversarial loss: 0.625418\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388616; batch adversarial loss: 0.534827\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317935; batch adversarial loss: 0.500122\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354719; batch adversarial loss: 0.535545\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399780; batch adversarial loss: 0.570156\n",
      "epoch 175; iter: 0; batch classifier loss: 0.456208; batch adversarial loss: 0.570456\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387190; batch adversarial loss: 0.518092\n",
      "epoch 177; iter: 0; batch classifier loss: 0.297334; batch adversarial loss: 0.633513\n",
      "epoch 178; iter: 0; batch classifier loss: 0.402837; batch adversarial loss: 0.562217\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377565; batch adversarial loss: 0.518660\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356119; batch adversarial loss: 0.598670\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350049; batch adversarial loss: 0.553823\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346875; batch adversarial loss: 0.544079\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397612; batch adversarial loss: 0.544628\n",
      "epoch 184; iter: 0; batch classifier loss: 0.314693; batch adversarial loss: 0.455770\n",
      "epoch 185; iter: 0; batch classifier loss: 0.386050; batch adversarial loss: 0.589667\n",
      "epoch 186; iter: 0; batch classifier loss: 0.320032; batch adversarial loss: 0.553134\n",
      "epoch 187; iter: 0; batch classifier loss: 0.278653; batch adversarial loss: 0.553904\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374142; batch adversarial loss: 0.534945\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333734; batch adversarial loss: 0.588905\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386039; batch adversarial loss: 0.490648\n",
      "epoch 191; iter: 0; batch classifier loss: 0.283751; batch adversarial loss: 0.606722\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356029; batch adversarial loss: 0.580180\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389281; batch adversarial loss: 0.473941\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353314; batch adversarial loss: 0.553748\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339437; batch adversarial loss: 0.535728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.346029; batch adversarial loss: 0.518658\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385655; batch adversarial loss: 0.563639\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377790; batch adversarial loss: 0.544809\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350367; batch adversarial loss: 0.598289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680887; batch adversarial loss: 0.587523\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645009; batch adversarial loss: 0.661132\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600600; batch adversarial loss: 0.654733\n",
      "epoch 3; iter: 0; batch classifier loss: 0.611483; batch adversarial loss: 0.673902\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560444; batch adversarial loss: 0.670246\n",
      "epoch 5; iter: 0; batch classifier loss: 0.502322; batch adversarial loss: 0.682121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586649; batch adversarial loss: 0.599589\n",
      "epoch 7; iter: 0; batch classifier loss: 0.647270; batch adversarial loss: 0.608382\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539935; batch adversarial loss: 0.608346\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578194; batch adversarial loss: 0.564069\n",
      "epoch 10; iter: 0; batch classifier loss: 0.611428; batch adversarial loss: 0.593829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539979; batch adversarial loss: 0.643510\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560648; batch adversarial loss: 0.612483\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492267; batch adversarial loss: 0.539462\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491492; batch adversarial loss: 0.541547\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538031; batch adversarial loss: 0.564963\n",
      "epoch 16; iter: 0; batch classifier loss: 0.603196; batch adversarial loss: 0.518784\n",
      "epoch 17; iter: 0; batch classifier loss: 0.545245; batch adversarial loss: 0.604677\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557476; batch adversarial loss: 0.561495\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551182; batch adversarial loss: 0.552186\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434782; batch adversarial loss: 0.525821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541234; batch adversarial loss: 0.588824\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524809; batch adversarial loss: 0.555463\n",
      "epoch 23; iter: 0; batch classifier loss: 0.535872; batch adversarial loss: 0.521479\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495921; batch adversarial loss: 0.554658\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555727; batch adversarial loss: 0.545410\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475129; batch adversarial loss: 0.562273\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482233; batch adversarial loss: 0.518380\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489430; batch adversarial loss: 0.580115\n",
      "epoch 29; iter: 0; batch classifier loss: 0.517916; batch adversarial loss: 0.517715\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463284; batch adversarial loss: 0.534890\n",
      "epoch 31; iter: 0; batch classifier loss: 0.524824; batch adversarial loss: 0.553449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.535885; batch adversarial loss: 0.461993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.521022; batch adversarial loss: 0.507447\n",
      "epoch 34; iter: 0; batch classifier loss: 0.552411; batch adversarial loss: 0.572453\n",
      "epoch 35; iter: 0; batch classifier loss: 0.528980; batch adversarial loss: 0.516648\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487314; batch adversarial loss: 0.469715\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447246; batch adversarial loss: 0.554087\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458010; batch adversarial loss: 0.525565\n",
      "epoch 39; iter: 0; batch classifier loss: 0.507812; batch adversarial loss: 0.554872\n",
      "epoch 40; iter: 0; batch classifier loss: 0.483157; batch adversarial loss: 0.620998\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408494; batch adversarial loss: 0.525570\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416426; batch adversarial loss: 0.554001\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450331; batch adversarial loss: 0.573185\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450627; batch adversarial loss: 0.619169\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450980; batch adversarial loss: 0.609733\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476068; batch adversarial loss: 0.430995\n",
      "epoch 47; iter: 0; batch classifier loss: 0.539790; batch adversarial loss: 0.514685\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489997; batch adversarial loss: 0.516512\n",
      "epoch 49; iter: 0; batch classifier loss: 0.516315; batch adversarial loss: 0.497884\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438123; batch adversarial loss: 0.497523\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454963; batch adversarial loss: 0.448752\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442455; batch adversarial loss: 0.459072\n",
      "epoch 53; iter: 0; batch classifier loss: 0.463609; batch adversarial loss: 0.468330\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428180; batch adversarial loss: 0.582478\n",
      "epoch 55; iter: 0; batch classifier loss: 0.499653; batch adversarial loss: 0.588953\n",
      "epoch 56; iter: 0; batch classifier loss: 0.370023; batch adversarial loss: 0.490060\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423956; batch adversarial loss: 0.563461\n",
      "epoch 58; iter: 0; batch classifier loss: 0.476521; batch adversarial loss: 0.524643\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423325; batch adversarial loss: 0.582106\n",
      "epoch 60; iter: 0; batch classifier loss: 0.359715; batch adversarial loss: 0.513024\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441816; batch adversarial loss: 0.573294\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380070; batch adversarial loss: 0.577097\n",
      "epoch 63; iter: 0; batch classifier loss: 0.513951; batch adversarial loss: 0.590630\n",
      "epoch 64; iter: 0; batch classifier loss: 0.498977; batch adversarial loss: 0.466788\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467098; batch adversarial loss: 0.621387\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382709; batch adversarial loss: 0.506214\n",
      "epoch 67; iter: 0; batch classifier loss: 0.508711; batch adversarial loss: 0.545609\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422947; batch adversarial loss: 0.456899\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449631; batch adversarial loss: 0.544846\n",
      "epoch 70; iter: 0; batch classifier loss: 0.340376; batch adversarial loss: 0.438269\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381059; batch adversarial loss: 0.487428\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417764; batch adversarial loss: 0.504638\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418005; batch adversarial loss: 0.536512\n",
      "epoch 74; iter: 0; batch classifier loss: 0.479121; batch adversarial loss: 0.505991\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399545; batch adversarial loss: 0.552946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402266; batch adversarial loss: 0.542208\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411541; batch adversarial loss: 0.550328\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400612; batch adversarial loss: 0.470482\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404064; batch adversarial loss: 0.525684\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439640; batch adversarial loss: 0.557597\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426099; batch adversarial loss: 0.516095\n",
      "epoch 82; iter: 0; batch classifier loss: 0.472463; batch adversarial loss: 0.592996\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428663; batch adversarial loss: 0.555708\n",
      "epoch 84; iter: 0; batch classifier loss: 0.461782; batch adversarial loss: 0.526305\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438741; batch adversarial loss: 0.555814\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357341; batch adversarial loss: 0.506603\n",
      "epoch 87; iter: 0; batch classifier loss: 0.462059; batch adversarial loss: 0.526271\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418542; batch adversarial loss: 0.592954\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355520; batch adversarial loss: 0.523824\n",
      "epoch 90; iter: 0; batch classifier loss: 0.516473; batch adversarial loss: 0.575017\n",
      "epoch 91; iter: 0; batch classifier loss: 0.461280; batch adversarial loss: 0.486884\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407202; batch adversarial loss: 0.525785\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371171; batch adversarial loss: 0.515710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.354649; batch adversarial loss: 0.592503\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413393; batch adversarial loss: 0.477390\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370190; batch adversarial loss: 0.572124\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413567; batch adversarial loss: 0.488397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390543; batch adversarial loss: 0.515628\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390575; batch adversarial loss: 0.543408\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429423; batch adversarial loss: 0.552561\n",
      "epoch 101; iter: 0; batch classifier loss: 0.435264; batch adversarial loss: 0.555518\n",
      "epoch 102; iter: 0; batch classifier loss: 0.423790; batch adversarial loss: 0.556153\n",
      "epoch 103; iter: 0; batch classifier loss: 0.433857; batch adversarial loss: 0.477907\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358212; batch adversarial loss: 0.583420\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396893; batch adversarial loss: 0.555526\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333807; batch adversarial loss: 0.477974\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366428; batch adversarial loss: 0.516861\n",
      "epoch 108; iter: 0; batch classifier loss: 0.433170; batch adversarial loss: 0.533807\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396056; batch adversarial loss: 0.526768\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383915; batch adversarial loss: 0.544630\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342126; batch adversarial loss: 0.592881\n",
      "epoch 112; iter: 0; batch classifier loss: 0.453634; batch adversarial loss: 0.525785\n",
      "epoch 113; iter: 0; batch classifier loss: 0.300256; batch adversarial loss: 0.554839\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344470; batch adversarial loss: 0.554292\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380123; batch adversarial loss: 0.592849\n",
      "epoch 116; iter: 0; batch classifier loss: 0.294943; batch adversarial loss: 0.505985\n",
      "epoch 117; iter: 0; batch classifier loss: 0.455576; batch adversarial loss: 0.565062\n",
      "epoch 118; iter: 0; batch classifier loss: 0.323328; batch adversarial loss: 0.611723\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388970; batch adversarial loss: 0.574969\n",
      "epoch 120; iter: 0; batch classifier loss: 0.389558; batch adversarial loss: 0.514928\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368775; batch adversarial loss: 0.580686\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409253; batch adversarial loss: 0.583791\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423474; batch adversarial loss: 0.562500\n",
      "epoch 124; iter: 0; batch classifier loss: 0.400726; batch adversarial loss: 0.572491\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329285; batch adversarial loss: 0.516960\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404410; batch adversarial loss: 0.572769\n",
      "epoch 127; iter: 0; batch classifier loss: 0.458232; batch adversarial loss: 0.518369\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361986; batch adversarial loss: 0.535522\n",
      "epoch 129; iter: 0; batch classifier loss: 0.450244; batch adversarial loss: 0.524343\n",
      "epoch 130; iter: 0; batch classifier loss: 0.417165; batch adversarial loss: 0.575105\n",
      "epoch 131; iter: 0; batch classifier loss: 0.418428; batch adversarial loss: 0.524343\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414977; batch adversarial loss: 0.601104\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369952; batch adversarial loss: 0.542675\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361166; batch adversarial loss: 0.496062\n",
      "epoch 135; iter: 0; batch classifier loss: 0.414684; batch adversarial loss: 0.488007\n",
      "epoch 136; iter: 0; batch classifier loss: 0.309768; batch adversarial loss: 0.602989\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389238; batch adversarial loss: 0.573985\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404497; batch adversarial loss: 0.499759\n",
      "epoch 139; iter: 0; batch classifier loss: 0.432885; batch adversarial loss: 0.517683\n",
      "epoch 140; iter: 0; batch classifier loss: 0.474999; batch adversarial loss: 0.456876\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423144; batch adversarial loss: 0.544013\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381725; batch adversarial loss: 0.497345\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349167; batch adversarial loss: 0.543727\n",
      "epoch 144; iter: 0; batch classifier loss: 0.452867; batch adversarial loss: 0.608802\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403523; batch adversarial loss: 0.618527\n",
      "epoch 146; iter: 0; batch classifier loss: 0.304170; batch adversarial loss: 0.466402\n",
      "epoch 147; iter: 0; batch classifier loss: 0.415369; batch adversarial loss: 0.524528\n",
      "epoch 148; iter: 0; batch classifier loss: 0.429727; batch adversarial loss: 0.543081\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346881; batch adversarial loss: 0.540561\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376107; batch adversarial loss: 0.643992\n",
      "epoch 151; iter: 0; batch classifier loss: 0.419426; batch adversarial loss: 0.526662\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407277; batch adversarial loss: 0.489446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.418462; batch adversarial loss: 0.547246\n",
      "epoch 154; iter: 0; batch classifier loss: 0.392255; batch adversarial loss: 0.466806\n",
      "epoch 155; iter: 0; batch classifier loss: 0.432916; batch adversarial loss: 0.529051\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395763; batch adversarial loss: 0.566982\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382726; batch adversarial loss: 0.523736\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360879; batch adversarial loss: 0.603981\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379005; batch adversarial loss: 0.478750\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379529; batch adversarial loss: 0.495956\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416638; batch adversarial loss: 0.586712\n",
      "epoch 162; iter: 0; batch classifier loss: 0.449786; batch adversarial loss: 0.505395\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330766; batch adversarial loss: 0.457629\n",
      "epoch 164; iter: 0; batch classifier loss: 0.470736; batch adversarial loss: 0.526275\n",
      "epoch 165; iter: 0; batch classifier loss: 0.454467; batch adversarial loss: 0.524177\n",
      "epoch 166; iter: 0; batch classifier loss: 0.401660; batch adversarial loss: 0.514738\n",
      "epoch 167; iter: 0; batch classifier loss: 0.309977; batch adversarial loss: 0.536190\n",
      "epoch 168; iter: 0; batch classifier loss: 0.385651; batch adversarial loss: 0.513523\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368168; batch adversarial loss: 0.614794\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365399; batch adversarial loss: 0.533009\n",
      "epoch 171; iter: 0; batch classifier loss: 0.460436; batch adversarial loss: 0.524119\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398763; batch adversarial loss: 0.508984\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364715; batch adversarial loss: 0.544040\n",
      "epoch 174; iter: 0; batch classifier loss: 0.453097; batch adversarial loss: 0.552042\n",
      "epoch 175; iter: 0; batch classifier loss: 0.477044; batch adversarial loss: 0.552955\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344932; batch adversarial loss: 0.552790\n",
      "epoch 177; iter: 0; batch classifier loss: 0.465465; batch adversarial loss: 0.469312\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381425; batch adversarial loss: 0.534199\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354647; batch adversarial loss: 0.544973\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354187; batch adversarial loss: 0.514250\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346796; batch adversarial loss: 0.488958\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320800; batch adversarial loss: 0.514394\n",
      "epoch 183; iter: 0; batch classifier loss: 0.440829; batch adversarial loss: 0.525547\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366628; batch adversarial loss: 0.467595\n",
      "epoch 185; iter: 0; batch classifier loss: 0.318793; batch adversarial loss: 0.468733\n",
      "epoch 186; iter: 0; batch classifier loss: 0.450954; batch adversarial loss: 0.493764\n",
      "epoch 187; iter: 0; batch classifier loss: 0.486704; batch adversarial loss: 0.478751\n",
      "epoch 188; iter: 0; batch classifier loss: 0.412041; batch adversarial loss: 0.539981\n",
      "epoch 189; iter: 0; batch classifier loss: 0.389601; batch adversarial loss: 0.504320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.399640; batch adversarial loss: 0.555200\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350488; batch adversarial loss: 0.543269\n",
      "epoch 192; iter: 0; batch classifier loss: 0.453700; batch adversarial loss: 0.589933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343276; batch adversarial loss: 0.566352\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365217; batch adversarial loss: 0.610358\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382926; batch adversarial loss: 0.507790\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347050; batch adversarial loss: 0.604628\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327971; batch adversarial loss: 0.515036\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356246; batch adversarial loss: 0.543885\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332467; batch adversarial loss: 0.555398\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685676; batch adversarial loss: 1.075351\n",
      "epoch 1; iter: 0; batch classifier loss: 0.841493; batch adversarial loss: 1.405865\n",
      "epoch 2; iter: 0; batch classifier loss: 1.126812; batch adversarial loss: 1.434783\n",
      "epoch 3; iter: 0; batch classifier loss: 1.130000; batch adversarial loss: 1.307104\n",
      "epoch 4; iter: 0; batch classifier loss: 1.252340; batch adversarial loss: 1.239064\n",
      "epoch 5; iter: 0; batch classifier loss: 1.193068; batch adversarial loss: 1.137042\n",
      "epoch 6; iter: 0; batch classifier loss: 1.141557; batch adversarial loss: 1.012239\n",
      "epoch 7; iter: 0; batch classifier loss: 1.213516; batch adversarial loss: 0.955437\n",
      "epoch 8; iter: 0; batch classifier loss: 1.328627; batch adversarial loss: 0.901522\n",
      "epoch 9; iter: 0; batch classifier loss: 1.239794; batch adversarial loss: 0.828486\n",
      "epoch 10; iter: 0; batch classifier loss: 1.071485; batch adversarial loss: 0.759413\n",
      "epoch 11; iter: 0; batch classifier loss: 1.374793; batch adversarial loss: 0.732275\n",
      "epoch 12; iter: 0; batch classifier loss: 1.001688; batch adversarial loss: 0.695418\n",
      "epoch 13; iter: 0; batch classifier loss: 1.118259; batch adversarial loss: 0.631610\n",
      "epoch 14; iter: 0; batch classifier loss: 1.072641; batch adversarial loss: 0.584220\n",
      "epoch 15; iter: 0; batch classifier loss: 0.834454; batch adversarial loss: 0.633474\n",
      "epoch 16; iter: 0; batch classifier loss: 0.795439; batch adversarial loss: 0.584326\n",
      "epoch 17; iter: 0; batch classifier loss: 0.622859; batch adversarial loss: 0.563181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.510611; batch adversarial loss: 0.554131\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541848; batch adversarial loss: 0.618709\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503821; batch adversarial loss: 0.507770\n",
      "epoch 21; iter: 0; batch classifier loss: 0.570126; batch adversarial loss: 0.606409\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524112; batch adversarial loss: 0.534728\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506197; batch adversarial loss: 0.541185\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503663; batch adversarial loss: 0.508455\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483177; batch adversarial loss: 0.545128\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475582; batch adversarial loss: 0.600758\n",
      "epoch 27; iter: 0; batch classifier loss: 0.526907; batch adversarial loss: 0.498539\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478320; batch adversarial loss: 0.556290\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492054; batch adversarial loss: 0.548648\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468750; batch adversarial loss: 0.495872\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483267; batch adversarial loss: 0.529365\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495824; batch adversarial loss: 0.507450\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476137; batch adversarial loss: 0.571017\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509862; batch adversarial loss: 0.635623\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467764; batch adversarial loss: 0.563427\n",
      "epoch 36; iter: 0; batch classifier loss: 0.522061; batch adversarial loss: 0.548752\n",
      "epoch 37; iter: 0; batch classifier loss: 0.514202; batch adversarial loss: 0.539641\n",
      "epoch 38; iter: 0; batch classifier loss: 0.520613; batch adversarial loss: 0.491698\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403548; batch adversarial loss: 0.547458\n",
      "epoch 40; iter: 0; batch classifier loss: 0.386925; batch adversarial loss: 0.563634\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458461; batch adversarial loss: 0.537342\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474280; batch adversarial loss: 0.588935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432672; batch adversarial loss: 0.534625\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398918; batch adversarial loss: 0.523476\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411970; batch adversarial loss: 0.525660\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452439; batch adversarial loss: 0.567016\n",
      "epoch 47; iter: 0; batch classifier loss: 0.537657; batch adversarial loss: 0.555690\n",
      "epoch 48; iter: 0; batch classifier loss: 0.496484; batch adversarial loss: 0.513222\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438932; batch adversarial loss: 0.525206\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473153; batch adversarial loss: 0.563473\n",
      "epoch 51; iter: 0; batch classifier loss: 0.506643; batch adversarial loss: 0.524843\n",
      "epoch 52; iter: 0; batch classifier loss: 0.533887; batch adversarial loss: 0.561517\n",
      "epoch 53; iter: 0; batch classifier loss: 0.479230; batch adversarial loss: 0.574579\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464615; batch adversarial loss: 0.653092\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444933; batch adversarial loss: 0.599621\n",
      "epoch 56; iter: 0; batch classifier loss: 0.458237; batch adversarial loss: 0.609956\n",
      "epoch 57; iter: 0; batch classifier loss: 0.579423; batch adversarial loss: 0.597518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388623; batch adversarial loss: 0.566310\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411721; batch adversarial loss: 0.498157\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447266; batch adversarial loss: 0.537273\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439439; batch adversarial loss: 0.554797\n",
      "epoch 62; iter: 0; batch classifier loss: 0.306583; batch adversarial loss: 0.511045\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441357; batch adversarial loss: 0.490097\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408925; batch adversarial loss: 0.510705\n",
      "epoch 65; iter: 0; batch classifier loss: 0.456736; batch adversarial loss: 0.496034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384953; batch adversarial loss: 0.509370\n",
      "epoch 67; iter: 0; batch classifier loss: 0.488919; batch adversarial loss: 0.552776\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356318; batch adversarial loss: 0.518420\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413204; batch adversarial loss: 0.502180\n",
      "epoch 70; iter: 0; batch classifier loss: 0.375235; batch adversarial loss: 0.472433\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428716; batch adversarial loss: 0.526351\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417015; batch adversarial loss: 0.556628\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385215; batch adversarial loss: 0.651277\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386566; batch adversarial loss: 0.571966\n",
      "epoch 75; iter: 0; batch classifier loss: 0.470185; batch adversarial loss: 0.543562\n",
      "epoch 76; iter: 0; batch classifier loss: 0.352453; batch adversarial loss: 0.563139\n",
      "epoch 77; iter: 0; batch classifier loss: 0.370846; batch adversarial loss: 0.473825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378951; batch adversarial loss: 0.535815\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388622; batch adversarial loss: 0.562849\n",
      "epoch 80; iter: 0; batch classifier loss: 0.312889; batch adversarial loss: 0.572323\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370107; batch adversarial loss: 0.554230\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412529; batch adversarial loss: 0.553160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419859; batch adversarial loss: 0.597774\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396089; batch adversarial loss: 0.509280\n",
      "epoch 85; iter: 0; batch classifier loss: 0.470742; batch adversarial loss: 0.563051\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360133; batch adversarial loss: 0.545061\n",
      "epoch 87; iter: 0; batch classifier loss: 0.338713; batch adversarial loss: 0.500554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.347387; batch adversarial loss: 0.589252\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368771; batch adversarial loss: 0.517992\n",
      "epoch 90; iter: 0; batch classifier loss: 0.436266; batch adversarial loss: 0.571569\n",
      "epoch 91; iter: 0; batch classifier loss: 0.368898; batch adversarial loss: 0.562378\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419048; batch adversarial loss: 0.482366\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398214; batch adversarial loss: 0.607604\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408952; batch adversarial loss: 0.543596\n",
      "epoch 95; iter: 0; batch classifier loss: 0.439811; batch adversarial loss: 0.536146\n",
      "epoch 96; iter: 0; batch classifier loss: 0.409256; batch adversarial loss: 0.571575\n",
      "epoch 97; iter: 0; batch classifier loss: 0.407971; batch adversarial loss: 0.544249\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361874; batch adversarial loss: 0.625410\n",
      "epoch 99; iter: 0; batch classifier loss: 0.302516; batch adversarial loss: 0.562366\n",
      "epoch 100; iter: 0; batch classifier loss: 0.395239; batch adversarial loss: 0.562739\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383139; batch adversarial loss: 0.526399\n",
      "epoch 102; iter: 0; batch classifier loss: 0.303880; batch adversarial loss: 0.517758\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339552; batch adversarial loss: 0.508784\n",
      "epoch 104; iter: 0; batch classifier loss: 0.409893; batch adversarial loss: 0.571382\n",
      "epoch 105; iter: 0; batch classifier loss: 0.357670; batch adversarial loss: 0.543974\n",
      "epoch 106; iter: 0; batch classifier loss: 0.307296; batch adversarial loss: 0.508832\n",
      "epoch 107; iter: 0; batch classifier loss: 0.333969; batch adversarial loss: 0.589144\n",
      "epoch 108; iter: 0; batch classifier loss: 0.479438; batch adversarial loss: 0.491227\n",
      "epoch 109; iter: 0; batch classifier loss: 0.318060; batch adversarial loss: 0.580800\n",
      "epoch 110; iter: 0; batch classifier loss: 0.424114; batch adversarial loss: 0.517816\n",
      "epoch 111; iter: 0; batch classifier loss: 0.396989; batch adversarial loss: 0.508072\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362736; batch adversarial loss: 0.652057\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362364; batch adversarial loss: 0.490258\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378609; batch adversarial loss: 0.535650\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412179; batch adversarial loss: 0.536357\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359513; batch adversarial loss: 0.553532\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414559; batch adversarial loss: 0.590137\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343093; batch adversarial loss: 0.545149\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378744; batch adversarial loss: 0.580617\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362439; batch adversarial loss: 0.616438\n",
      "epoch 121; iter: 0; batch classifier loss: 0.326416; batch adversarial loss: 0.554034\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403592; batch adversarial loss: 0.562826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.305950; batch adversarial loss: 0.517543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.305354; batch adversarial loss: 0.507256\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387616; batch adversarial loss: 0.490940\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386188; batch adversarial loss: 0.527146\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376409; batch adversarial loss: 0.570965\n",
      "epoch 128; iter: 0; batch classifier loss: 0.412441; batch adversarial loss: 0.597667\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362898; batch adversarial loss: 0.615901\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397111; batch adversarial loss: 0.553359\n",
      "epoch 131; iter: 0; batch classifier loss: 0.315803; batch adversarial loss: 0.491158\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341518; batch adversarial loss: 0.517154\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350366; batch adversarial loss: 0.517720\n",
      "epoch 134; iter: 0; batch classifier loss: 0.293571; batch adversarial loss: 0.526894\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364979; batch adversarial loss: 0.578968\n",
      "epoch 136; iter: 0; batch classifier loss: 0.390824; batch adversarial loss: 0.561758\n",
      "epoch 137; iter: 0; batch classifier loss: 0.285626; batch adversarial loss: 0.562031\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345825; batch adversarial loss: 0.500358\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407123; batch adversarial loss: 0.580535\n",
      "epoch 140; iter: 0; batch classifier loss: 0.362676; batch adversarial loss: 0.536369\n",
      "epoch 141; iter: 0; batch classifier loss: 0.360274; batch adversarial loss: 0.552899\n",
      "epoch 142; iter: 0; batch classifier loss: 0.283631; batch adversarial loss: 0.634107\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394516; batch adversarial loss: 0.508937\n",
      "epoch 144; iter: 0; batch classifier loss: 0.319680; batch adversarial loss: 0.518261\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342622; batch adversarial loss: 0.563251\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330496; batch adversarial loss: 0.624422\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338755; batch adversarial loss: 0.608406\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380015; batch adversarial loss: 0.499109\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320920; batch adversarial loss: 0.616321\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311158; batch adversarial loss: 0.598818\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336800; batch adversarial loss: 0.627213\n",
      "epoch 152; iter: 0; batch classifier loss: 0.396688; batch adversarial loss: 0.553027\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329060; batch adversarial loss: 0.589240\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340918; batch adversarial loss: 0.517565\n",
      "epoch 155; iter: 0; batch classifier loss: 0.348351; batch adversarial loss: 0.473120\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396837; batch adversarial loss: 0.499638\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381084; batch adversarial loss: 0.579671\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352676; batch adversarial loss: 0.517642\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384686; batch adversarial loss: 0.499001\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327836; batch adversarial loss: 0.473339\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358335; batch adversarial loss: 0.472935\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387659; batch adversarial loss: 0.554624\n",
      "epoch 163; iter: 0; batch classifier loss: 0.431308; batch adversarial loss: 0.526298\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358344; batch adversarial loss: 0.660362\n",
      "epoch 165; iter: 0; batch classifier loss: 0.354162; batch adversarial loss: 0.581701\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356351; batch adversarial loss: 0.616223\n",
      "epoch 167; iter: 0; batch classifier loss: 0.351725; batch adversarial loss: 0.580432\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375749; batch adversarial loss: 0.481959\n",
      "epoch 169; iter: 0; batch classifier loss: 0.283360; batch adversarial loss: 0.455057\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326496; batch adversarial loss: 0.607516\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320813; batch adversarial loss: 0.526769\n",
      "epoch 172; iter: 0; batch classifier loss: 0.258025; batch adversarial loss: 0.561985\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354773; batch adversarial loss: 0.536181\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321151; batch adversarial loss: 0.597793\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331386; batch adversarial loss: 0.642173\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335668; batch adversarial loss: 0.562330\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291841; batch adversarial loss: 0.534038\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323995; batch adversarial loss: 0.625172\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340021; batch adversarial loss: 0.529413\n",
      "epoch 180; iter: 0; batch classifier loss: 0.330650; batch adversarial loss: 0.552869\n",
      "epoch 181; iter: 0; batch classifier loss: 0.280990; batch adversarial loss: 0.525260\n",
      "epoch 182; iter: 0; batch classifier loss: 0.347708; batch adversarial loss: 0.489156\n",
      "epoch 183; iter: 0; batch classifier loss: 0.405914; batch adversarial loss: 0.554206\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332133; batch adversarial loss: 0.473005\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315546; batch adversarial loss: 0.606050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.376061; batch adversarial loss: 0.518156\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373441; batch adversarial loss: 0.607226\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367764; batch adversarial loss: 0.535785\n",
      "epoch 189; iter: 0; batch classifier loss: 0.306415; batch adversarial loss: 0.616194\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360765; batch adversarial loss: 0.481752\n",
      "epoch 191; iter: 0; batch classifier loss: 0.298816; batch adversarial loss: 0.517513\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338877; batch adversarial loss: 0.526300\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314825; batch adversarial loss: 0.599784\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368253; batch adversarial loss: 0.564269\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350089; batch adversarial loss: 0.551410\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392291; batch adversarial loss: 0.553189\n",
      "epoch 197; iter: 0; batch classifier loss: 0.381028; batch adversarial loss: 0.526749\n",
      "epoch 198; iter: 0; batch classifier loss: 0.298462; batch adversarial loss: 0.545290\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314259; batch adversarial loss: 0.527440\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684120; batch adversarial loss: 0.800020\n",
      "epoch 1; iter: 0; batch classifier loss: 0.746107; batch adversarial loss: 0.827251\n",
      "epoch 2; iter: 0; batch classifier loss: 0.777974; batch adversarial loss: 0.757077\n",
      "epoch 3; iter: 0; batch classifier loss: 0.857505; batch adversarial loss: 0.726330\n",
      "epoch 4; iter: 0; batch classifier loss: 0.698508; batch adversarial loss: 0.661084\n",
      "epoch 5; iter: 0; batch classifier loss: 0.628814; batch adversarial loss: 0.617784\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562893; batch adversarial loss: 0.613084\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575019; batch adversarial loss: 0.612704\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573202; batch adversarial loss: 0.590630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614320; batch adversarial loss: 0.595141\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589928; batch adversarial loss: 0.572990\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511477; batch adversarial loss: 0.556450\n",
      "epoch 12; iter: 0; batch classifier loss: 0.524475; batch adversarial loss: 0.505815\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506356; batch adversarial loss: 0.563860\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506125; batch adversarial loss: 0.600853\n",
      "epoch 15; iter: 0; batch classifier loss: 0.612073; batch adversarial loss: 0.544639\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542221; batch adversarial loss: 0.549197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519085; batch adversarial loss: 0.626917\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444019; batch adversarial loss: 0.610357\n",
      "epoch 19; iter: 0; batch classifier loss: 0.577186; batch adversarial loss: 0.600715\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446221; batch adversarial loss: 0.516184\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513966; batch adversarial loss: 0.593024\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515907; batch adversarial loss: 0.527859\n",
      "epoch 23; iter: 0; batch classifier loss: 0.566926; batch adversarial loss: 0.582731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422122; batch adversarial loss: 0.498479\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503960; batch adversarial loss: 0.538962\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460602; batch adversarial loss: 0.508450\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501291; batch adversarial loss: 0.551492\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429306; batch adversarial loss: 0.523377\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502024; batch adversarial loss: 0.520442\n",
      "epoch 30; iter: 0; batch classifier loss: 0.559511; batch adversarial loss: 0.543386\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461703; batch adversarial loss: 0.496339\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482395; batch adversarial loss: 0.567702\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426431; batch adversarial loss: 0.518585\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470152; batch adversarial loss: 0.536621\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468310; batch adversarial loss: 0.568206\n",
      "epoch 36; iter: 0; batch classifier loss: 0.560117; batch adversarial loss: 0.537409\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455345; batch adversarial loss: 0.498975\n",
      "epoch 38; iter: 0; batch classifier loss: 0.534256; batch adversarial loss: 0.595884\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481584; batch adversarial loss: 0.535645\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421667; batch adversarial loss: 0.524417\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411729; batch adversarial loss: 0.551396\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458790; batch adversarial loss: 0.552966\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445719; batch adversarial loss: 0.647133\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472112; batch adversarial loss: 0.500900\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382657; batch adversarial loss: 0.552370\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438579; batch adversarial loss: 0.503096\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461326; batch adversarial loss: 0.556498\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433910; batch adversarial loss: 0.483680\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419625; batch adversarial loss: 0.562315\n",
      "epoch 50; iter: 0; batch classifier loss: 0.352366; batch adversarial loss: 0.546346\n",
      "epoch 51; iter: 0; batch classifier loss: 0.488380; batch adversarial loss: 0.520041\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432826; batch adversarial loss: 0.583258\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401062; batch adversarial loss: 0.544368\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428542; batch adversarial loss: 0.510313\n",
      "epoch 55; iter: 0; batch classifier loss: 0.457137; batch adversarial loss: 0.527064\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432182; batch adversarial loss: 0.536572\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404202; batch adversarial loss: 0.554080\n",
      "epoch 58; iter: 0; batch classifier loss: 0.485339; batch adversarial loss: 0.509250\n",
      "epoch 59; iter: 0; batch classifier loss: 0.365382; batch adversarial loss: 0.490503\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443411; batch adversarial loss: 0.499932\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381635; batch adversarial loss: 0.498746\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452320; batch adversarial loss: 0.654212\n",
      "epoch 63; iter: 0; batch classifier loss: 0.409988; batch adversarial loss: 0.554441\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393491; batch adversarial loss: 0.562533\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386326; batch adversarial loss: 0.598463\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374875; batch adversarial loss: 0.488823\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421189; batch adversarial loss: 0.517427\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380967; batch adversarial loss: 0.626242\n",
      "epoch 69; iter: 0; batch classifier loss: 0.365668; batch adversarial loss: 0.516534\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438488; batch adversarial loss: 0.499805\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391688; batch adversarial loss: 0.582102\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411842; batch adversarial loss: 0.600364\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398139; batch adversarial loss: 0.545129\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437759; batch adversarial loss: 0.526870\n",
      "epoch 75; iter: 0; batch classifier loss: 0.482057; batch adversarial loss: 0.516813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358375; batch adversarial loss: 0.619909\n",
      "epoch 77; iter: 0; batch classifier loss: 0.336673; batch adversarial loss: 0.563035\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378717; batch adversarial loss: 0.545289\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379973; batch adversarial loss: 0.508424\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380574; batch adversarial loss: 0.553282\n",
      "epoch 81; iter: 0; batch classifier loss: 0.451756; batch adversarial loss: 0.571961\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393391; batch adversarial loss: 0.562078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.346637; batch adversarial loss: 0.561885\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374594; batch adversarial loss: 0.608569\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427195; batch adversarial loss: 0.497926\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370432; batch adversarial loss: 0.562766\n",
      "epoch 87; iter: 0; batch classifier loss: 0.344638; batch adversarial loss: 0.617989\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357528; batch adversarial loss: 0.580743\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374421; batch adversarial loss: 0.554769\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370158; batch adversarial loss: 0.571195\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376977; batch adversarial loss: 0.564018\n",
      "epoch 92; iter: 0; batch classifier loss: 0.457499; batch adversarial loss: 0.554747\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361675; batch adversarial loss: 0.589139\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353942; batch adversarial loss: 0.564641\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409394; batch adversarial loss: 0.533201\n",
      "epoch 96; iter: 0; batch classifier loss: 0.353103; batch adversarial loss: 0.628722\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352330; batch adversarial loss: 0.534402\n",
      "epoch 98; iter: 0; batch classifier loss: 0.318984; batch adversarial loss: 0.562638\n",
      "epoch 99; iter: 0; batch classifier loss: 0.327253; batch adversarial loss: 0.563522\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375369; batch adversarial loss: 0.581580\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396496; batch adversarial loss: 0.589632\n",
      "epoch 102; iter: 0; batch classifier loss: 0.439955; batch adversarial loss: 0.554654\n",
      "epoch 103; iter: 0; batch classifier loss: 0.368579; batch adversarial loss: 0.488970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391130; batch adversarial loss: 0.516760\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418378; batch adversarial loss: 0.536941\n",
      "epoch 106; iter: 0; batch classifier loss: 0.403130; batch adversarial loss: 0.591166\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354642; batch adversarial loss: 0.461136\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364618; batch adversarial loss: 0.534532\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407864; batch adversarial loss: 0.553753\n",
      "epoch 110; iter: 0; batch classifier loss: 0.279777; batch adversarial loss: 0.570674\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395344; batch adversarial loss: 0.424839\n",
      "epoch 112; iter: 0; batch classifier loss: 0.373402; batch adversarial loss: 0.663379\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371754; batch adversarial loss: 0.552797\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406217; batch adversarial loss: 0.472587\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344711; batch adversarial loss: 0.544693\n",
      "epoch 116; iter: 0; batch classifier loss: 0.426762; batch adversarial loss: 0.536086\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408143; batch adversarial loss: 0.580483\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384947; batch adversarial loss: 0.534712\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382457; batch adversarial loss: 0.553151\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380459; batch adversarial loss: 0.528223\n",
      "epoch 121; iter: 0; batch classifier loss: 0.326281; batch adversarial loss: 0.518023\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386036; batch adversarial loss: 0.479908\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373066; batch adversarial loss: 0.554848\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402779; batch adversarial loss: 0.578726\n",
      "epoch 125; iter: 0; batch classifier loss: 0.427863; batch adversarial loss: 0.553069\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379738; batch adversarial loss: 0.580995\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375491; batch adversarial loss: 0.499888\n",
      "epoch 128; iter: 0; batch classifier loss: 0.378121; batch adversarial loss: 0.481779\n",
      "epoch 129; iter: 0; batch classifier loss: 0.421449; batch adversarial loss: 0.543606\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443460; batch adversarial loss: 0.562410\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387535; batch adversarial loss: 0.634874\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310796; batch adversarial loss: 0.627562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329602; batch adversarial loss: 0.525913\n",
      "epoch 134; iter: 0; batch classifier loss: 0.432687; batch adversarial loss: 0.581911\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335020; batch adversarial loss: 0.589202\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358881; batch adversarial loss: 0.506992\n",
      "epoch 137; iter: 0; batch classifier loss: 0.317895; batch adversarial loss: 0.554596\n",
      "epoch 138; iter: 0; batch classifier loss: 0.416834; batch adversarial loss: 0.480793\n",
      "epoch 139; iter: 0; batch classifier loss: 0.348945; batch adversarial loss: 0.543024\n",
      "epoch 140; iter: 0; batch classifier loss: 0.319475; batch adversarial loss: 0.545682\n",
      "epoch 141; iter: 0; batch classifier loss: 0.312682; batch adversarial loss: 0.507508\n",
      "epoch 142; iter: 0; batch classifier loss: 0.409257; batch adversarial loss: 0.561821\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373905; batch adversarial loss: 0.499472\n",
      "epoch 144; iter: 0; batch classifier loss: 0.280916; batch adversarial loss: 0.463470\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323737; batch adversarial loss: 0.544454\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373391; batch adversarial loss: 0.581879\n",
      "epoch 147; iter: 0; batch classifier loss: 0.311319; batch adversarial loss: 0.516446\n",
      "epoch 148; iter: 0; batch classifier loss: 0.363616; batch adversarial loss: 0.508581\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316426; batch adversarial loss: 0.563040\n",
      "epoch 150; iter: 0; batch classifier loss: 0.383939; batch adversarial loss: 0.526273\n",
      "epoch 151; iter: 0; batch classifier loss: 0.318099; batch adversarial loss: 0.571596\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349085; batch adversarial loss: 0.599616\n",
      "epoch 153; iter: 0; batch classifier loss: 0.283542; batch adversarial loss: 0.506638\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353626; batch adversarial loss: 0.535466\n",
      "epoch 155; iter: 0; batch classifier loss: 0.395154; batch adversarial loss: 0.592316\n",
      "epoch 156; iter: 0; batch classifier loss: 0.432360; batch adversarial loss: 0.536320\n",
      "epoch 157; iter: 0; batch classifier loss: 0.453029; batch adversarial loss: 0.472114\n",
      "epoch 158; iter: 0; batch classifier loss: 0.287451; batch adversarial loss: 0.617729\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341787; batch adversarial loss: 0.553322\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313114; batch adversarial loss: 0.480908\n",
      "epoch 161; iter: 0; batch classifier loss: 0.297628; batch adversarial loss: 0.499588\n",
      "epoch 162; iter: 0; batch classifier loss: 0.291424; batch adversarial loss: 0.506482\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375342; batch adversarial loss: 0.470550\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356877; batch adversarial loss: 0.600897\n",
      "epoch 165; iter: 0; batch classifier loss: 0.296984; batch adversarial loss: 0.645812\n",
      "epoch 166; iter: 0; batch classifier loss: 0.450636; batch adversarial loss: 0.554414\n",
      "epoch 167; iter: 0; batch classifier loss: 0.427804; batch adversarial loss: 0.524528\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347087; batch adversarial loss: 0.617396\n",
      "epoch 169; iter: 0; batch classifier loss: 0.258989; batch adversarial loss: 0.489622\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367963; batch adversarial loss: 0.471271\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382428; batch adversarial loss: 0.489883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372995; batch adversarial loss: 0.488030\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373789; batch adversarial loss: 0.554195\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395015; batch adversarial loss: 0.573426\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294387; batch adversarial loss: 0.580970\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366034; batch adversarial loss: 0.527285\n",
      "epoch 177; iter: 0; batch classifier loss: 0.297851; batch adversarial loss: 0.543860\n",
      "epoch 178; iter: 0; batch classifier loss: 0.324234; batch adversarial loss: 0.536831\n",
      "epoch 179; iter: 0; batch classifier loss: 0.385539; batch adversarial loss: 0.590258\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358971; batch adversarial loss: 0.471438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.353493; batch adversarial loss: 0.525290\n",
      "epoch 182; iter: 0; batch classifier loss: 0.280633; batch adversarial loss: 0.562847\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392844; batch adversarial loss: 0.554257\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336045; batch adversarial loss: 0.569890\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367847; batch adversarial loss: 0.579838\n",
      "epoch 186; iter: 0; batch classifier loss: 0.281645; batch adversarial loss: 0.536373\n",
      "epoch 187; iter: 0; batch classifier loss: 0.412854; batch adversarial loss: 0.518326\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350937; batch adversarial loss: 0.562285\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295463; batch adversarial loss: 0.516302\n",
      "epoch 190; iter: 0; batch classifier loss: 0.330209; batch adversarial loss: 0.516867\n",
      "epoch 191; iter: 0; batch classifier loss: 0.353886; batch adversarial loss: 0.524077\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305177; batch adversarial loss: 0.561595\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364675; batch adversarial loss: 0.526679\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368124; batch adversarial loss: 0.508671\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296044; batch adversarial loss: 0.552563\n",
      "epoch 196; iter: 0; batch classifier loss: 0.416985; batch adversarial loss: 0.553984\n",
      "epoch 197; iter: 0; batch classifier loss: 0.333372; batch adversarial loss: 0.572337\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382099; batch adversarial loss: 0.471119\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309435; batch adversarial loss: 0.506545\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709614; batch adversarial loss: 1.039944\n",
      "epoch 1; iter: 0; batch classifier loss: 0.829431; batch adversarial loss: 1.188724\n",
      "epoch 2; iter: 0; batch classifier loss: 0.961592; batch adversarial loss: 1.166832\n",
      "epoch 3; iter: 0; batch classifier loss: 1.055832; batch adversarial loss: 1.117408\n",
      "epoch 4; iter: 0; batch classifier loss: 1.007671; batch adversarial loss: 1.015913\n",
      "epoch 5; iter: 0; batch classifier loss: 1.078504; batch adversarial loss: 0.947383\n",
      "epoch 6; iter: 0; batch classifier loss: 1.221715; batch adversarial loss: 0.894142\n",
      "epoch 7; iter: 0; batch classifier loss: 1.048133; batch adversarial loss: 0.803483\n",
      "epoch 8; iter: 0; batch classifier loss: 1.033122; batch adversarial loss: 0.753929\n",
      "epoch 9; iter: 0; batch classifier loss: 0.964005; batch adversarial loss: 0.713651\n",
      "epoch 10; iter: 0; batch classifier loss: 0.809806; batch adversarial loss: 0.631625\n",
      "epoch 11; iter: 0; batch classifier loss: 0.647178; batch adversarial loss: 0.620471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545862; batch adversarial loss: 0.573003\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600155; batch adversarial loss: 0.628453\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557184; batch adversarial loss: 0.567185\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529913; batch adversarial loss: 0.575179\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520482; batch adversarial loss: 0.619835\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559998; batch adversarial loss: 0.555117\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520957; batch adversarial loss: 0.555100\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461740; batch adversarial loss: 0.600369\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528269; batch adversarial loss: 0.587121\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514810; batch adversarial loss: 0.506746\n",
      "epoch 22; iter: 0; batch classifier loss: 0.534901; batch adversarial loss: 0.564764\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520735; batch adversarial loss: 0.587545\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515894; batch adversarial loss: 0.577943\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531166; batch adversarial loss: 0.522008\n",
      "epoch 26; iter: 0; batch classifier loss: 0.526876; batch adversarial loss: 0.625095\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503345; batch adversarial loss: 0.569850\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456792; batch adversarial loss: 0.605440\n",
      "epoch 29; iter: 0; batch classifier loss: 0.562449; batch adversarial loss: 0.571384\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504860; batch adversarial loss: 0.486765\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481674; batch adversarial loss: 0.551653\n",
      "epoch 32; iter: 0; batch classifier loss: 0.542180; batch adversarial loss: 0.533089\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501009; batch adversarial loss: 0.511066\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429302; batch adversarial loss: 0.551016\n",
      "epoch 35; iter: 0; batch classifier loss: 0.493210; batch adversarial loss: 0.479518\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496474; batch adversarial loss: 0.562325\n",
      "epoch 37; iter: 0; batch classifier loss: 0.498121; batch adversarial loss: 0.528805\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431283; batch adversarial loss: 0.496568\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442450; batch adversarial loss: 0.575563\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473049; batch adversarial loss: 0.511626\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470879; batch adversarial loss: 0.594099\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441443; batch adversarial loss: 0.504314\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461101; batch adversarial loss: 0.546133\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414611; batch adversarial loss: 0.617581\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470024; batch adversarial loss: 0.529222\n",
      "epoch 46; iter: 0; batch classifier loss: 0.581334; batch adversarial loss: 0.546738\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511268; batch adversarial loss: 0.522375\n",
      "epoch 48; iter: 0; batch classifier loss: 0.492199; batch adversarial loss: 0.519791\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382565; batch adversarial loss: 0.584678\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471750; batch adversarial loss: 0.489787\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444357; batch adversarial loss: 0.572801\n",
      "epoch 52; iter: 0; batch classifier loss: 0.370161; batch adversarial loss: 0.633340\n",
      "epoch 53; iter: 0; batch classifier loss: 0.501929; batch adversarial loss: 0.571424\n",
      "epoch 54; iter: 0; batch classifier loss: 0.505077; batch adversarial loss: 0.491401\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411524; batch adversarial loss: 0.527750\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399487; batch adversarial loss: 0.698825\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438798; batch adversarial loss: 0.477347\n",
      "epoch 58; iter: 0; batch classifier loss: 0.454691; batch adversarial loss: 0.555984\n",
      "epoch 59; iter: 0; batch classifier loss: 0.355734; batch adversarial loss: 0.614194\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425679; batch adversarial loss: 0.580652\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397498; batch adversarial loss: 0.509953\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377914; batch adversarial loss: 0.554415\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376096; batch adversarial loss: 0.581959\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428268; batch adversarial loss: 0.518302\n",
      "epoch 65; iter: 0; batch classifier loss: 0.392095; batch adversarial loss: 0.589501\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419585; batch adversarial loss: 0.534815\n",
      "epoch 67; iter: 0; batch classifier loss: 0.476628; batch adversarial loss: 0.599937\n",
      "epoch 68; iter: 0; batch classifier loss: 0.360179; batch adversarial loss: 0.565107\n",
      "epoch 69; iter: 0; batch classifier loss: 0.434692; batch adversarial loss: 0.535792\n",
      "epoch 70; iter: 0; batch classifier loss: 0.520830; batch adversarial loss: 0.429718\n",
      "epoch 71; iter: 0; batch classifier loss: 0.459581; batch adversarial loss: 0.500285\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404298; batch adversarial loss: 0.553524\n",
      "epoch 73; iter: 0; batch classifier loss: 0.324934; batch adversarial loss: 0.561871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.429786; batch adversarial loss: 0.497368\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404179; batch adversarial loss: 0.488824\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427323; batch adversarial loss: 0.608021\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376683; batch adversarial loss: 0.516154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.377685; batch adversarial loss: 0.498796\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394423; batch adversarial loss: 0.560575\n",
      "epoch 80; iter: 0; batch classifier loss: 0.388130; batch adversarial loss: 0.577583\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371911; batch adversarial loss: 0.571029\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413588; batch adversarial loss: 0.549473\n",
      "epoch 83; iter: 0; batch classifier loss: 0.418811; batch adversarial loss: 0.535844\n",
      "epoch 84; iter: 0; batch classifier loss: 0.327050; batch adversarial loss: 0.518806\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401869; batch adversarial loss: 0.563084\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451269; batch adversarial loss: 0.551222\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415392; batch adversarial loss: 0.524353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.343262; batch adversarial loss: 0.536826\n",
      "epoch 89; iter: 0; batch classifier loss: 0.321994; batch adversarial loss: 0.577681\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371194; batch adversarial loss: 0.561443\n",
      "epoch 91; iter: 0; batch classifier loss: 0.276217; batch adversarial loss: 0.669948\n",
      "epoch 92; iter: 0; batch classifier loss: 0.361531; batch adversarial loss: 0.562476\n",
      "epoch 93; iter: 0; batch classifier loss: 0.373386; batch adversarial loss: 0.553354\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352029; batch adversarial loss: 0.546025\n",
      "epoch 95; iter: 0; batch classifier loss: 0.366323; batch adversarial loss: 0.490473\n",
      "epoch 96; iter: 0; batch classifier loss: 0.315723; batch adversarial loss: 0.615696\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378466; batch adversarial loss: 0.486977\n",
      "epoch 98; iter: 0; batch classifier loss: 0.451849; batch adversarial loss: 0.537815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.390935; batch adversarial loss: 0.585375\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350124; batch adversarial loss: 0.487373\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405757; batch adversarial loss: 0.608450\n",
      "epoch 102; iter: 0; batch classifier loss: 0.316339; batch adversarial loss: 0.571023\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335952; batch adversarial loss: 0.523589\n",
      "epoch 104; iter: 0; batch classifier loss: 0.380727; batch adversarial loss: 0.539825\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392744; batch adversarial loss: 0.552920\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352222; batch adversarial loss: 0.590718\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431837; batch adversarial loss: 0.604743\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392803; batch adversarial loss: 0.567924\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372035; batch adversarial loss: 0.614993\n",
      "epoch 110; iter: 0; batch classifier loss: 0.366476; batch adversarial loss: 0.498850\n",
      "epoch 111; iter: 0; batch classifier loss: 0.451145; batch adversarial loss: 0.530172\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415095; batch adversarial loss: 0.620588\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360794; batch adversarial loss: 0.569834\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398073; batch adversarial loss: 0.560210\n",
      "epoch 115; iter: 0; batch classifier loss: 0.319844; batch adversarial loss: 0.517592\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402829; batch adversarial loss: 0.561291\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383038; batch adversarial loss: 0.605952\n",
      "epoch 118; iter: 0; batch classifier loss: 0.380149; batch adversarial loss: 0.524577\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388368; batch adversarial loss: 0.518089\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360939; batch adversarial loss: 0.533471\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338294; batch adversarial loss: 0.568200\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408583; batch adversarial loss: 0.501415\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342188; batch adversarial loss: 0.607048\n",
      "epoch 124; iter: 0; batch classifier loss: 0.284289; batch adversarial loss: 0.544967\n",
      "epoch 125; iter: 0; batch classifier loss: 0.322825; batch adversarial loss: 0.554562\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372965; batch adversarial loss: 0.526401\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372671; batch adversarial loss: 0.525696\n",
      "epoch 128; iter: 0; batch classifier loss: 0.374520; batch adversarial loss: 0.533310\n",
      "epoch 129; iter: 0; batch classifier loss: 0.314802; batch adversarial loss: 0.528033\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359351; batch adversarial loss: 0.517696\n",
      "epoch 131; iter: 0; batch classifier loss: 0.308876; batch adversarial loss: 0.527064\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346653; batch adversarial loss: 0.572148\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358469; batch adversarial loss: 0.556565\n",
      "epoch 134; iter: 0; batch classifier loss: 0.418004; batch adversarial loss: 0.585918\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337629; batch adversarial loss: 0.464495\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327791; batch adversarial loss: 0.562614\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340708; batch adversarial loss: 0.580765\n",
      "epoch 138; iter: 0; batch classifier loss: 0.439010; batch adversarial loss: 0.600425\n",
      "epoch 139; iter: 0; batch classifier loss: 0.298114; batch adversarial loss: 0.553242\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344784; batch adversarial loss: 0.584440\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342061; batch adversarial loss: 0.535295\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334309; batch adversarial loss: 0.500414\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382173; batch adversarial loss: 0.533442\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337883; batch adversarial loss: 0.506022\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339684; batch adversarial loss: 0.506976\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361929; batch adversarial loss: 0.501421\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358996; batch adversarial loss: 0.586694\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373487; batch adversarial loss: 0.541711\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324477; batch adversarial loss: 0.594190\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353569; batch adversarial loss: 0.527558\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345275; batch adversarial loss: 0.555030\n",
      "epoch 152; iter: 0; batch classifier loss: 0.389813; batch adversarial loss: 0.496061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352044; batch adversarial loss: 0.571323\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337418; batch adversarial loss: 0.560364\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419195; batch adversarial loss: 0.519266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351360; batch adversarial loss: 0.532226\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369559; batch adversarial loss: 0.537016\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364443; batch adversarial loss: 0.561643\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331837; batch adversarial loss: 0.509954\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379259; batch adversarial loss: 0.599038\n",
      "epoch 161; iter: 0; batch classifier loss: 0.389277; batch adversarial loss: 0.478492\n",
      "epoch 162; iter: 0; batch classifier loss: 0.285705; batch adversarial loss: 0.509864\n",
      "epoch 163; iter: 0; batch classifier loss: 0.405122; batch adversarial loss: 0.499978\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381696; batch adversarial loss: 0.464009\n",
      "epoch 165; iter: 0; batch classifier loss: 0.314150; batch adversarial loss: 0.561203\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317262; batch adversarial loss: 0.483820\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288375; batch adversarial loss: 0.596608\n",
      "epoch 168; iter: 0; batch classifier loss: 0.371515; batch adversarial loss: 0.608897\n",
      "epoch 169; iter: 0; batch classifier loss: 0.361901; batch adversarial loss: 0.542837\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297040; batch adversarial loss: 0.462148\n",
      "epoch 171; iter: 0; batch classifier loss: 0.404413; batch adversarial loss: 0.558502\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349578; batch adversarial loss: 0.621611\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385759; batch adversarial loss: 0.590828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.349836; batch adversarial loss: 0.506988\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338645; batch adversarial loss: 0.470797\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330328; batch adversarial loss: 0.581476\n",
      "epoch 177; iter: 0; batch classifier loss: 0.287606; batch adversarial loss: 0.577271\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287231; batch adversarial loss: 0.481511\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395983; batch adversarial loss: 0.509360\n",
      "epoch 180; iter: 0; batch classifier loss: 0.262080; batch adversarial loss: 0.651263\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350232; batch adversarial loss: 0.621967\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381685; batch adversarial loss: 0.550295\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356870; batch adversarial loss: 0.480496\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389570; batch adversarial loss: 0.478145\n",
      "epoch 185; iter: 0; batch classifier loss: 0.263374; batch adversarial loss: 0.572108\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330734; batch adversarial loss: 0.480744\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317431; batch adversarial loss: 0.590347\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369393; batch adversarial loss: 0.533519\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297140; batch adversarial loss: 0.576242\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371607; batch adversarial loss: 0.566548\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351976; batch adversarial loss: 0.590095\n",
      "epoch 192; iter: 0; batch classifier loss: 0.283315; batch adversarial loss: 0.525834\n",
      "epoch 193; iter: 0; batch classifier loss: 0.363736; batch adversarial loss: 0.577058\n",
      "epoch 194; iter: 0; batch classifier loss: 0.297858; batch adversarial loss: 0.555301\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331753; batch adversarial loss: 0.550932\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310063; batch adversarial loss: 0.561374\n",
      "epoch 197; iter: 0; batch classifier loss: 0.282574; batch adversarial loss: 0.531268\n",
      "epoch 198; iter: 0; batch classifier loss: 0.226720; batch adversarial loss: 0.570204\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349532; batch adversarial loss: 0.536751\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718497; batch adversarial loss: 0.811679\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637775; batch adversarial loss: 0.779448\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609559; batch adversarial loss: 0.746972\n",
      "epoch 3; iter: 0; batch classifier loss: 0.658198; batch adversarial loss: 0.710957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.504649; batch adversarial loss: 0.670041\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534887; batch adversarial loss: 0.666718\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574703; batch adversarial loss: 0.638581\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557443; batch adversarial loss: 0.613096\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520892; batch adversarial loss: 0.641232\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584655; batch adversarial loss: 0.596362\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549658; batch adversarial loss: 0.566217\n",
      "epoch 11; iter: 0; batch classifier loss: 0.485145; batch adversarial loss: 0.576183\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526732; batch adversarial loss: 0.527066\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539615; batch adversarial loss: 0.589267\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509371; batch adversarial loss: 0.559506\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481438; batch adversarial loss: 0.548765\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486636; batch adversarial loss: 0.516992\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514971; batch adversarial loss: 0.564321\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512056; batch adversarial loss: 0.566402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523261; batch adversarial loss: 0.587488\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470056; batch adversarial loss: 0.566958\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503647; batch adversarial loss: 0.561528\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573398; batch adversarial loss: 0.565297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473412; batch adversarial loss: 0.542616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505749; batch adversarial loss: 0.587138\n",
      "epoch 25; iter: 0; batch classifier loss: 0.427204; batch adversarial loss: 0.530688\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484650; batch adversarial loss: 0.603052\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424608; batch adversarial loss: 0.567868\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490069; batch adversarial loss: 0.532030\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471758; batch adversarial loss: 0.575811\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510899; batch adversarial loss: 0.645651\n",
      "epoch 31; iter: 0; batch classifier loss: 0.504387; batch adversarial loss: 0.613113\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473405; batch adversarial loss: 0.524747\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437153; batch adversarial loss: 0.664286\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474718; batch adversarial loss: 0.528771\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444989; batch adversarial loss: 0.511139\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499612; batch adversarial loss: 0.579210\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416925; batch adversarial loss: 0.497313\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431746; batch adversarial loss: 0.633659\n",
      "epoch 39; iter: 0; batch classifier loss: 0.475054; batch adversarial loss: 0.553740\n",
      "epoch 40; iter: 0; batch classifier loss: 0.540009; batch adversarial loss: 0.535470\n",
      "epoch 41; iter: 0; batch classifier loss: 0.513532; batch adversarial loss: 0.605780\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464222; batch adversarial loss: 0.527599\n",
      "epoch 43; iter: 0; batch classifier loss: 0.485573; batch adversarial loss: 0.564680\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435195; batch adversarial loss: 0.464795\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429462; batch adversarial loss: 0.535934\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497306; batch adversarial loss: 0.642513\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397589; batch adversarial loss: 0.615726\n",
      "epoch 48; iter: 0; batch classifier loss: 0.503650; batch adversarial loss: 0.580045\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447671; batch adversarial loss: 0.607708\n",
      "epoch 50; iter: 0; batch classifier loss: 0.514811; batch adversarial loss: 0.526739\n",
      "epoch 51; iter: 0; batch classifier loss: 0.508052; batch adversarial loss: 0.535598\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467897; batch adversarial loss: 0.535815\n",
      "epoch 53; iter: 0; batch classifier loss: 0.365044; batch adversarial loss: 0.526445\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393416; batch adversarial loss: 0.535558\n",
      "epoch 55; iter: 0; batch classifier loss: 0.334394; batch adversarial loss: 0.517224\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441622; batch adversarial loss: 0.590100\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437810; batch adversarial loss: 0.498595\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419430; batch adversarial loss: 0.535212\n",
      "epoch 59; iter: 0; batch classifier loss: 0.499065; batch adversarial loss: 0.590079\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392678; batch adversarial loss: 0.544169\n",
      "epoch 61; iter: 0; batch classifier loss: 0.368911; batch adversarial loss: 0.507761\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417659; batch adversarial loss: 0.544497\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378770; batch adversarial loss: 0.672167\n",
      "epoch 64; iter: 0; batch classifier loss: 0.475421; batch adversarial loss: 0.599450\n",
      "epoch 65; iter: 0; batch classifier loss: 0.459966; batch adversarial loss: 0.590317\n",
      "epoch 66; iter: 0; batch classifier loss: 0.442616; batch adversarial loss: 0.516070\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443844; batch adversarial loss: 0.560925\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422433; batch adversarial loss: 0.583753\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449263; batch adversarial loss: 0.544388\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419031; batch adversarial loss: 0.467552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.371824; batch adversarial loss: 0.601207\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416172; batch adversarial loss: 0.545414\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425713; batch adversarial loss: 0.603952\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367822; batch adversarial loss: 0.525000\n",
      "epoch 75; iter: 0; batch classifier loss: 0.444498; batch adversarial loss: 0.582913\n",
      "epoch 76; iter: 0; batch classifier loss: 0.463248; batch adversarial loss: 0.571883\n",
      "epoch 77; iter: 0; batch classifier loss: 0.444273; batch adversarial loss: 0.544810\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406142; batch adversarial loss: 0.617938\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366372; batch adversarial loss: 0.572069\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427161; batch adversarial loss: 0.508693\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361849; batch adversarial loss: 0.571690\n",
      "epoch 82; iter: 0; batch classifier loss: 0.364492; batch adversarial loss: 0.598649\n",
      "epoch 83; iter: 0; batch classifier loss: 0.379890; batch adversarial loss: 0.508587\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391626; batch adversarial loss: 0.534966\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402553; batch adversarial loss: 0.527640\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405003; batch adversarial loss: 0.545241\n",
      "epoch 87; iter: 0; batch classifier loss: 0.451550; batch adversarial loss: 0.506531\n",
      "epoch 88; iter: 0; batch classifier loss: 0.410648; batch adversarial loss: 0.571996\n",
      "epoch 89; iter: 0; batch classifier loss: 0.473923; batch adversarial loss: 0.582187\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399620; batch adversarial loss: 0.581716\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408116; batch adversarial loss: 0.489053\n",
      "epoch 92; iter: 0; batch classifier loss: 0.356962; batch adversarial loss: 0.488451\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410543; batch adversarial loss: 0.526273\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373319; batch adversarial loss: 0.572252\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374277; batch adversarial loss: 0.544330\n",
      "epoch 96; iter: 0; batch classifier loss: 0.318201; batch adversarial loss: 0.498264\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410953; batch adversarial loss: 0.572037\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380155; batch adversarial loss: 0.442722\n",
      "epoch 99; iter: 0; batch classifier loss: 0.423448; batch adversarial loss: 0.498406\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366616; batch adversarial loss: 0.534946\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421702; batch adversarial loss: 0.572325\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350678; batch adversarial loss: 0.543586\n",
      "epoch 103; iter: 0; batch classifier loss: 0.305628; batch adversarial loss: 0.563219\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446513; batch adversarial loss: 0.618650\n",
      "epoch 105; iter: 0; batch classifier loss: 0.440542; batch adversarial loss: 0.525321\n",
      "epoch 106; iter: 0; batch classifier loss: 0.440895; batch adversarial loss: 0.545118\n",
      "epoch 107; iter: 0; batch classifier loss: 0.435947; batch adversarial loss: 0.526311\n",
      "epoch 108; iter: 0; batch classifier loss: 0.458335; batch adversarial loss: 0.553668\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413648; batch adversarial loss: 0.553346\n",
      "epoch 110; iter: 0; batch classifier loss: 0.444606; batch adversarial loss: 0.544186\n",
      "epoch 111; iter: 0; batch classifier loss: 0.404624; batch adversarial loss: 0.554061\n",
      "epoch 112; iter: 0; batch classifier loss: 0.419912; batch adversarial loss: 0.553531\n",
      "epoch 113; iter: 0; batch classifier loss: 0.313388; batch adversarial loss: 0.562133\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374172; batch adversarial loss: 0.662009\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403850; batch adversarial loss: 0.553420\n",
      "epoch 116; iter: 0; batch classifier loss: 0.407957; batch adversarial loss: 0.663275\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373548; batch adversarial loss: 0.544682\n",
      "epoch 118; iter: 0; batch classifier loss: 0.402793; batch adversarial loss: 0.544579\n",
      "epoch 119; iter: 0; batch classifier loss: 0.322432; batch adversarial loss: 0.498706\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360546; batch adversarial loss: 0.489285\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341843; batch adversarial loss: 0.590677\n",
      "epoch 122; iter: 0; batch classifier loss: 0.428420; batch adversarial loss: 0.608846\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415492; batch adversarial loss: 0.544718\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381154; batch adversarial loss: 0.497670\n",
      "epoch 125; iter: 0; batch classifier loss: 0.321483; batch adversarial loss: 0.600155\n",
      "epoch 126; iter: 0; batch classifier loss: 0.447788; batch adversarial loss: 0.590852\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381325; batch adversarial loss: 0.498303\n",
      "epoch 128; iter: 0; batch classifier loss: 0.425778; batch adversarial loss: 0.489137\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374479; batch adversarial loss: 0.609122\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356771; batch adversarial loss: 0.507893\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340664; batch adversarial loss: 0.516338\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345217; batch adversarial loss: 0.637179\n",
      "epoch 133; iter: 0; batch classifier loss: 0.348519; batch adversarial loss: 0.590450\n",
      "epoch 134; iter: 0; batch classifier loss: 0.388544; batch adversarial loss: 0.526198\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350209; batch adversarial loss: 0.581468\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425295; batch adversarial loss: 0.599820\n",
      "epoch 137; iter: 0; batch classifier loss: 0.337292; batch adversarial loss: 0.563242\n",
      "epoch 138; iter: 0; batch classifier loss: 0.316766; batch adversarial loss: 0.461092\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334531; batch adversarial loss: 0.508252\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396820; batch adversarial loss: 0.581845\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359755; batch adversarial loss: 0.489498\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355207; batch adversarial loss: 0.572701\n",
      "epoch 143; iter: 0; batch classifier loss: 0.404645; batch adversarial loss: 0.499065\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359135; batch adversarial loss: 0.526957\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379723; batch adversarial loss: 0.638040\n",
      "epoch 146; iter: 0; batch classifier loss: 0.390655; batch adversarial loss: 0.590025\n",
      "epoch 147; iter: 0; batch classifier loss: 0.396360; batch adversarial loss: 0.552383\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312781; batch adversarial loss: 0.599013\n",
      "epoch 149; iter: 0; batch classifier loss: 0.275622; batch adversarial loss: 0.608099\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379990; batch adversarial loss: 0.526062\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384645; batch adversarial loss: 0.590402\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351118; batch adversarial loss: 0.636010\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352834; batch adversarial loss: 0.571912\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358667; batch adversarial loss: 0.508178\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398123; batch adversarial loss: 0.517240\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338293; batch adversarial loss: 0.571932\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366670; batch adversarial loss: 0.526274\n",
      "epoch 158; iter: 0; batch classifier loss: 0.283796; batch adversarial loss: 0.498839\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370657; batch adversarial loss: 0.498676\n",
      "epoch 160; iter: 0; batch classifier loss: 0.473581; batch adversarial loss: 0.581166\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374884; batch adversarial loss: 0.553853\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357065; batch adversarial loss: 0.535630\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385370; batch adversarial loss: 0.525988\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362429; batch adversarial loss: 0.535306\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365942; batch adversarial loss: 0.535015\n",
      "epoch 166; iter: 0; batch classifier loss: 0.400447; batch adversarial loss: 0.489379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.400853; batch adversarial loss: 0.571868\n",
      "epoch 168; iter: 0; batch classifier loss: 0.365184; batch adversarial loss: 0.571949\n",
      "epoch 169; iter: 0; batch classifier loss: 0.336675; batch adversarial loss: 0.591010\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382983; batch adversarial loss: 0.590201\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313466; batch adversarial loss: 0.544354\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389863; batch adversarial loss: 0.480321\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392254; batch adversarial loss: 0.544451\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422679; batch adversarial loss: 0.609297\n",
      "epoch 175; iter: 0; batch classifier loss: 0.394931; batch adversarial loss: 0.452334\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319161; batch adversarial loss: 0.516859\n",
      "epoch 177; iter: 0; batch classifier loss: 0.299827; batch adversarial loss: 0.424132\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330530; batch adversarial loss: 0.554124\n",
      "epoch 179; iter: 0; batch classifier loss: 0.400378; batch adversarial loss: 0.544454\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353438; batch adversarial loss: 0.590464\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345153; batch adversarial loss: 0.646151\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348031; batch adversarial loss: 0.553476\n",
      "epoch 183; iter: 0; batch classifier loss: 0.289721; batch adversarial loss: 0.489294\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355811; batch adversarial loss: 0.443255\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399641; batch adversarial loss: 0.599783\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382841; batch adversarial loss: 0.553768\n",
      "epoch 187; iter: 0; batch classifier loss: 0.337028; batch adversarial loss: 0.571909\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387086; batch adversarial loss: 0.599546\n",
      "epoch 189; iter: 0; batch classifier loss: 0.287700; batch adversarial loss: 0.618121\n",
      "epoch 190; iter: 0; batch classifier loss: 0.387258; batch adversarial loss: 0.562837\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339062; batch adversarial loss: 0.517126\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353873; batch adversarial loss: 0.535450\n",
      "epoch 193; iter: 0; batch classifier loss: 0.455880; batch adversarial loss: 0.581162\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354970; batch adversarial loss: 0.462115\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370756; batch adversarial loss: 0.553747\n",
      "epoch 196; iter: 0; batch classifier loss: 0.406652; batch adversarial loss: 0.544514\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313920; batch adversarial loss: 0.471304\n",
      "epoch 198; iter: 0; batch classifier loss: 0.308236; batch adversarial loss: 0.599608\n",
      "epoch 199; iter: 0; batch classifier loss: 0.311331; batch adversarial loss: 0.507649\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663257; batch adversarial loss: 0.751188\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606036; batch adversarial loss: 0.732083\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567227; batch adversarial loss: 0.693654\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555888; batch adversarial loss: 0.666151\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575131; batch adversarial loss: 0.661927\n",
      "epoch 5; iter: 0; batch classifier loss: 0.479165; batch adversarial loss: 0.639184\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525957; batch adversarial loss: 0.616174\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522162; batch adversarial loss: 0.573024\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489758; batch adversarial loss: 0.590868\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549269; batch adversarial loss: 0.602194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575342; batch adversarial loss: 0.564294\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590173; batch adversarial loss: 0.538698\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575379; batch adversarial loss: 0.542680\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554252; batch adversarial loss: 0.518828\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516828; batch adversarial loss: 0.561182\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510040; batch adversarial loss: 0.603782\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516027; batch adversarial loss: 0.539422\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504601; batch adversarial loss: 0.591034\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515886; batch adversarial loss: 0.637292\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534274; batch adversarial loss: 0.562157\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498596; batch adversarial loss: 0.618819\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474980; batch adversarial loss: 0.608514\n",
      "epoch 22; iter: 0; batch classifier loss: 0.540069; batch adversarial loss: 0.601997\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462271; batch adversarial loss: 0.535899\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508926; batch adversarial loss: 0.561810\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471310; batch adversarial loss: 0.493395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497716; batch adversarial loss: 0.634959\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510098; batch adversarial loss: 0.580994\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451118; batch adversarial loss: 0.479012\n",
      "epoch 29; iter: 0; batch classifier loss: 0.545052; batch adversarial loss: 0.566252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470896; batch adversarial loss: 0.579330\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458707; batch adversarial loss: 0.559854\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482987; batch adversarial loss: 0.468820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504798; batch adversarial loss: 0.545657\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456941; batch adversarial loss: 0.562273\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496915; batch adversarial loss: 0.615138\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474157; batch adversarial loss: 0.557080\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470040; batch adversarial loss: 0.553659\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414045; batch adversarial loss: 0.535698\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419614; batch adversarial loss: 0.567085\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391884; batch adversarial loss: 0.544588\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458890; batch adversarial loss: 0.482880\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482187; batch adversarial loss: 0.550681\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413180; batch adversarial loss: 0.554739\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441700; batch adversarial loss: 0.541265\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498535; batch adversarial loss: 0.627030\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383059; batch adversarial loss: 0.509259\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479463; batch adversarial loss: 0.533233\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443080; batch adversarial loss: 0.538265\n",
      "epoch 49; iter: 0; batch classifier loss: 0.490113; batch adversarial loss: 0.539645\n",
      "epoch 50; iter: 0; batch classifier loss: 0.394014; batch adversarial loss: 0.587959\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481268; batch adversarial loss: 0.516383\n",
      "epoch 52; iter: 0; batch classifier loss: 0.395464; batch adversarial loss: 0.528867\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393311; batch adversarial loss: 0.562786\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419806; batch adversarial loss: 0.481682\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439269; batch adversarial loss: 0.572416\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429955; batch adversarial loss: 0.536992\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445555; batch adversarial loss: 0.458233\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408226; batch adversarial loss: 0.584018\n",
      "epoch 59; iter: 0; batch classifier loss: 0.395612; batch adversarial loss: 0.623033\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421167; batch adversarial loss: 0.505216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380528; batch adversarial loss: 0.562034\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423901; batch adversarial loss: 0.545221\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441194; batch adversarial loss: 0.462101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.443224; batch adversarial loss: 0.550852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424688; batch adversarial loss: 0.572733\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439864; batch adversarial loss: 0.607758\n",
      "epoch 67; iter: 0; batch classifier loss: 0.531417; batch adversarial loss: 0.500565\n",
      "epoch 68; iter: 0; batch classifier loss: 0.462591; batch adversarial loss: 0.555607\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415231; batch adversarial loss: 0.569502\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418442; batch adversarial loss: 0.608720\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370851; batch adversarial loss: 0.551364\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413884; batch adversarial loss: 0.516440\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408438; batch adversarial loss: 0.588802\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395156; batch adversarial loss: 0.655919\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353659; batch adversarial loss: 0.524992\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462087; batch adversarial loss: 0.564292\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373627; batch adversarial loss: 0.591411\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457256; batch adversarial loss: 0.510721\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407395; batch adversarial loss: 0.545496\n",
      "epoch 80; iter: 0; batch classifier loss: 0.368217; batch adversarial loss: 0.633898\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404394; batch adversarial loss: 0.553840\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410971; batch adversarial loss: 0.562202\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370387; batch adversarial loss: 0.537752\n",
      "epoch 84; iter: 0; batch classifier loss: 0.484178; batch adversarial loss: 0.523703\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389292; batch adversarial loss: 0.513721\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383604; batch adversarial loss: 0.563641\n",
      "epoch 87; iter: 0; batch classifier loss: 0.302026; batch adversarial loss: 0.508348\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423059; batch adversarial loss: 0.501378\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406554; batch adversarial loss: 0.562393\n",
      "epoch 90; iter: 0; batch classifier loss: 0.502040; batch adversarial loss: 0.613880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.368812; batch adversarial loss: 0.579289\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376505; batch adversarial loss: 0.615622\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353438; batch adversarial loss: 0.599905\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415487; batch adversarial loss: 0.518809\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379863; batch adversarial loss: 0.515688\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345576; batch adversarial loss: 0.596597\n",
      "epoch 97; iter: 0; batch classifier loss: 0.407878; batch adversarial loss: 0.494159\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349710; batch adversarial loss: 0.592669\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388930; batch adversarial loss: 0.599167\n",
      "epoch 100; iter: 0; batch classifier loss: 0.518667; batch adversarial loss: 0.535738\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405124; batch adversarial loss: 0.529347\n",
      "epoch 102; iter: 0; batch classifier loss: 0.484600; batch adversarial loss: 0.490207\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386580; batch adversarial loss: 0.570843\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413074; batch adversarial loss: 0.505947\n",
      "epoch 105; iter: 0; batch classifier loss: 0.533881; batch adversarial loss: 0.519425\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330373; batch adversarial loss: 0.495644\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361330; batch adversarial loss: 0.540451\n",
      "epoch 108; iter: 0; batch classifier loss: 0.445598; batch adversarial loss: 0.583354\n",
      "epoch 109; iter: 0; batch classifier loss: 0.421046; batch adversarial loss: 0.496379\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347956; batch adversarial loss: 0.556049\n",
      "epoch 111; iter: 0; batch classifier loss: 0.453986; batch adversarial loss: 0.516919\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351123; batch adversarial loss: 0.492842\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399315; batch adversarial loss: 0.518485\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420294; batch adversarial loss: 0.577977\n",
      "epoch 115; iter: 0; batch classifier loss: 0.373765; batch adversarial loss: 0.602276\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365739; batch adversarial loss: 0.554877\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363463; batch adversarial loss: 0.554717\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361765; batch adversarial loss: 0.531336\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356555; batch adversarial loss: 0.634377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.516456; batch adversarial loss: 0.613306\n",
      "epoch 121; iter: 0; batch classifier loss: 0.343944; batch adversarial loss: 0.584196\n",
      "epoch 122; iter: 0; batch classifier loss: 0.445358; batch adversarial loss: 0.493971\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350623; batch adversarial loss: 0.549549\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329096; batch adversarial loss: 0.510320\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394672; batch adversarial loss: 0.549702\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372178; batch adversarial loss: 0.591971\n",
      "epoch 127; iter: 0; batch classifier loss: 0.413675; batch adversarial loss: 0.546833\n",
      "epoch 128; iter: 0; batch classifier loss: 0.323907; batch adversarial loss: 0.530186\n",
      "epoch 129; iter: 0; batch classifier loss: 0.438408; batch adversarial loss: 0.572650\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374627; batch adversarial loss: 0.494766\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339378; batch adversarial loss: 0.517939\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376854; batch adversarial loss: 0.606125\n",
      "epoch 133; iter: 0; batch classifier loss: 0.312021; batch adversarial loss: 0.644653\n",
      "epoch 134; iter: 0; batch classifier loss: 0.427949; batch adversarial loss: 0.559879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376670; batch adversarial loss: 0.601400\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349423; batch adversarial loss: 0.499560\n",
      "epoch 137; iter: 0; batch classifier loss: 0.420866; batch adversarial loss: 0.562434\n",
      "epoch 138; iter: 0; batch classifier loss: 0.453115; batch adversarial loss: 0.570227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.449492; batch adversarial loss: 0.501954\n",
      "epoch 140; iter: 0; batch classifier loss: 0.394602; batch adversarial loss: 0.575633\n",
      "epoch 141; iter: 0; batch classifier loss: 0.490874; batch adversarial loss: 0.576485\n",
      "epoch 142; iter: 0; batch classifier loss: 0.429744; batch adversarial loss: 0.576678\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352001; batch adversarial loss: 0.588144\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411109; batch adversarial loss: 0.532952\n",
      "epoch 145; iter: 0; batch classifier loss: 0.321347; batch adversarial loss: 0.571542\n",
      "epoch 146; iter: 0; batch classifier loss: 0.342676; batch adversarial loss: 0.555493\n",
      "epoch 147; iter: 0; batch classifier loss: 0.418509; batch adversarial loss: 0.585299\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365098; batch adversarial loss: 0.495739\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324129; batch adversarial loss: 0.501236\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362173; batch adversarial loss: 0.542444\n",
      "epoch 151; iter: 0; batch classifier loss: 0.423232; batch adversarial loss: 0.571388\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397707; batch adversarial loss: 0.537127\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337003; batch adversarial loss: 0.596548\n",
      "epoch 154; iter: 0; batch classifier loss: 0.324667; batch adversarial loss: 0.603679\n",
      "epoch 155; iter: 0; batch classifier loss: 0.318258; batch adversarial loss: 0.526660\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379910; batch adversarial loss: 0.549154\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369681; batch adversarial loss: 0.551246\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323514; batch adversarial loss: 0.534096\n",
      "epoch 159; iter: 0; batch classifier loss: 0.440080; batch adversarial loss: 0.575901\n",
      "epoch 160; iter: 0; batch classifier loss: 0.432664; batch adversarial loss: 0.516863\n",
      "epoch 161; iter: 0; batch classifier loss: 0.404670; batch adversarial loss: 0.532106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.432116; batch adversarial loss: 0.608982\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336927; batch adversarial loss: 0.551405\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371085; batch adversarial loss: 0.560406\n",
      "epoch 165; iter: 0; batch classifier loss: 0.328557; batch adversarial loss: 0.554564\n",
      "epoch 166; iter: 0; batch classifier loss: 0.421606; batch adversarial loss: 0.560989\n",
      "epoch 167; iter: 0; batch classifier loss: 0.410188; batch adversarial loss: 0.533423\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326742; batch adversarial loss: 0.496557\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358377; batch adversarial loss: 0.501676\n",
      "epoch 170; iter: 0; batch classifier loss: 0.340517; batch adversarial loss: 0.560695\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347770; batch adversarial loss: 0.551754\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375335; batch adversarial loss: 0.627327\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403859; batch adversarial loss: 0.491544\n",
      "epoch 174; iter: 0; batch classifier loss: 0.301497; batch adversarial loss: 0.542825\n",
      "epoch 175; iter: 0; batch classifier loss: 0.320954; batch adversarial loss: 0.506844\n",
      "epoch 176; iter: 0; batch classifier loss: 0.288610; batch adversarial loss: 0.598525\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380002; batch adversarial loss: 0.522405\n",
      "epoch 178; iter: 0; batch classifier loss: 0.404079; batch adversarial loss: 0.576308\n",
      "epoch 179; iter: 0; batch classifier loss: 0.433506; batch adversarial loss: 0.527434\n",
      "epoch 180; iter: 0; batch classifier loss: 0.431519; batch adversarial loss: 0.569903\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339003; batch adversarial loss: 0.557041\n",
      "epoch 182; iter: 0; batch classifier loss: 0.326452; batch adversarial loss: 0.591496\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375336; batch adversarial loss: 0.502270\n",
      "epoch 184; iter: 0; batch classifier loss: 0.480921; batch adversarial loss: 0.649765\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373891; batch adversarial loss: 0.593163\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323085; batch adversarial loss: 0.510840\n",
      "epoch 187; iter: 0; batch classifier loss: 0.451285; batch adversarial loss: 0.571532\n",
      "epoch 188; iter: 0; batch classifier loss: 0.437955; batch adversarial loss: 0.573709\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355555; batch adversarial loss: 0.538029\n",
      "epoch 190; iter: 0; batch classifier loss: 0.458223; batch adversarial loss: 0.566579\n",
      "epoch 191; iter: 0; batch classifier loss: 0.308353; batch adversarial loss: 0.584218\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367150; batch adversarial loss: 0.519634\n",
      "epoch 193; iter: 0; batch classifier loss: 0.476976; batch adversarial loss: 0.562177\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364861; batch adversarial loss: 0.543260\n",
      "epoch 195; iter: 0; batch classifier loss: 0.417887; batch adversarial loss: 0.606016\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364989; batch adversarial loss: 0.564433\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383957; batch adversarial loss: 0.585558\n",
      "epoch 198; iter: 0; batch classifier loss: 0.410315; batch adversarial loss: 0.488901\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332278; batch adversarial loss: 0.527772\n",
      "epoch 0; iter: 0; batch classifier loss: 0.767688; batch adversarial loss: 1.188596\n",
      "epoch 1; iter: 0; batch classifier loss: 0.808555; batch adversarial loss: 1.181425\n",
      "epoch 2; iter: 0; batch classifier loss: 0.865005; batch adversarial loss: 1.209856\n",
      "epoch 3; iter: 0; batch classifier loss: 0.878208; batch adversarial loss: 1.140575\n",
      "epoch 4; iter: 0; batch classifier loss: 0.912345; batch adversarial loss: 0.999991\n",
      "epoch 5; iter: 0; batch classifier loss: 0.777075; batch adversarial loss: 0.896930\n",
      "epoch 6; iter: 0; batch classifier loss: 0.675229; batch adversarial loss: 0.845373\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624308; batch adversarial loss: 0.743448\n",
      "epoch 8; iter: 0; batch classifier loss: 0.646037; batch adversarial loss: 0.686249\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589401; batch adversarial loss: 0.665632\n",
      "epoch 10; iter: 0; batch classifier loss: 0.609298; batch adversarial loss: 0.660075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585419; batch adversarial loss: 0.651156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571241; batch adversarial loss: 0.591065\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503958; batch adversarial loss: 0.581010\n",
      "epoch 14; iter: 0; batch classifier loss: 0.482402; batch adversarial loss: 0.544383\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502781; batch adversarial loss: 0.548318\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529978; batch adversarial loss: 0.560071\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519194; batch adversarial loss: 0.569203\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518740; batch adversarial loss: 0.617638\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479180; batch adversarial loss: 0.522841\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477749; batch adversarial loss: 0.582057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479640; batch adversarial loss: 0.593442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492199; batch adversarial loss: 0.569109\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476670; batch adversarial loss: 0.510661\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526062; batch adversarial loss: 0.524426\n",
      "epoch 25; iter: 0; batch classifier loss: 0.575755; batch adversarial loss: 0.529698\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500431; batch adversarial loss: 0.578522\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537793; batch adversarial loss: 0.582637\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438431; batch adversarial loss: 0.489073\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511896; batch adversarial loss: 0.543901\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454041; batch adversarial loss: 0.481261\n",
      "epoch 31; iter: 0; batch classifier loss: 0.407740; batch adversarial loss: 0.633583\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506220; batch adversarial loss: 0.556949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.527019; batch adversarial loss: 0.581134\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536491; batch adversarial loss: 0.545391\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465909; batch adversarial loss: 0.506720\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458189; batch adversarial loss: 0.510911\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443604; batch adversarial loss: 0.552564\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481790; batch adversarial loss: 0.601301\n",
      "epoch 39; iter: 0; batch classifier loss: 0.348012; batch adversarial loss: 0.607014\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463821; batch adversarial loss: 0.463256\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396472; batch adversarial loss: 0.534195\n",
      "epoch 42; iter: 0; batch classifier loss: 0.360467; batch adversarial loss: 0.554179\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467876; batch adversarial loss: 0.494680\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433172; batch adversarial loss: 0.510294\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458960; batch adversarial loss: 0.530997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430101; batch adversarial loss: 0.559742\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444745; batch adversarial loss: 0.488640\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495351; batch adversarial loss: 0.509367\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389678; batch adversarial loss: 0.558641\n",
      "epoch 50; iter: 0; batch classifier loss: 0.385154; batch adversarial loss: 0.540436\n",
      "epoch 51; iter: 0; batch classifier loss: 0.347263; batch adversarial loss: 0.607277\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435674; batch adversarial loss: 0.535218\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452950; batch adversarial loss: 0.491078\n",
      "epoch 54; iter: 0; batch classifier loss: 0.366998; batch adversarial loss: 0.494631\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423923; batch adversarial loss: 0.514922\n",
      "epoch 56; iter: 0; batch classifier loss: 0.488795; batch adversarial loss: 0.537021\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400011; batch adversarial loss: 0.497053\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426255; batch adversarial loss: 0.568540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.445297; batch adversarial loss: 0.545238\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445978; batch adversarial loss: 0.589247\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475664; batch adversarial loss: 0.513931\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430791; batch adversarial loss: 0.531307\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415696; batch adversarial loss: 0.468931\n",
      "epoch 64; iter: 0; batch classifier loss: 0.399493; batch adversarial loss: 0.576159\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398460; batch adversarial loss: 0.452034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.383303; batch adversarial loss: 0.530738\n",
      "epoch 67; iter: 0; batch classifier loss: 0.383019; batch adversarial loss: 0.630337\n",
      "epoch 68; iter: 0; batch classifier loss: 0.351847; batch adversarial loss: 0.545513\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426888; batch adversarial loss: 0.525517\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398196; batch adversarial loss: 0.536607\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417005; batch adversarial loss: 0.496569\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393708; batch adversarial loss: 0.553011\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428802; batch adversarial loss: 0.517276\n",
      "epoch 74; iter: 0; batch classifier loss: 0.328520; batch adversarial loss: 0.555370\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403737; batch adversarial loss: 0.552511\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374145; batch adversarial loss: 0.572579\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389731; batch adversarial loss: 0.573644\n",
      "epoch 78; iter: 0; batch classifier loss: 0.430356; batch adversarial loss: 0.498028\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381255; batch adversarial loss: 0.552169\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427336; batch adversarial loss: 0.544606\n",
      "epoch 81; iter: 0; batch classifier loss: 0.456052; batch adversarial loss: 0.571220\n",
      "epoch 82; iter: 0; batch classifier loss: 0.437518; batch adversarial loss: 0.488016\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413580; batch adversarial loss: 0.582484\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355276; batch adversarial loss: 0.630636\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408128; batch adversarial loss: 0.523860\n",
      "epoch 86; iter: 0; batch classifier loss: 0.486565; batch adversarial loss: 0.506536\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345650; batch adversarial loss: 0.498423\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394701; batch adversarial loss: 0.523047\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398557; batch adversarial loss: 0.515587\n",
      "epoch 90; iter: 0; batch classifier loss: 0.483608; batch adversarial loss: 0.564178\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438219; batch adversarial loss: 0.535569\n",
      "epoch 92; iter: 0; batch classifier loss: 0.472244; batch adversarial loss: 0.517075\n",
      "epoch 93; iter: 0; batch classifier loss: 0.415140; batch adversarial loss: 0.582385\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360770; batch adversarial loss: 0.584375\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430584; batch adversarial loss: 0.488457\n",
      "epoch 96; iter: 0; batch classifier loss: 0.479645; batch adversarial loss: 0.535805\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404863; batch adversarial loss: 0.498189\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412227; batch adversarial loss: 0.545398\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397955; batch adversarial loss: 0.534936\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393120; batch adversarial loss: 0.457164\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384255; batch adversarial loss: 0.448184\n",
      "epoch 102; iter: 0; batch classifier loss: 0.403740; batch adversarial loss: 0.551687\n",
      "epoch 103; iter: 0; batch classifier loss: 0.336002; batch adversarial loss: 0.541932\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341346; batch adversarial loss: 0.502549\n",
      "epoch 105; iter: 0; batch classifier loss: 0.375792; batch adversarial loss: 0.553185\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404845; batch adversarial loss: 0.546139\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374162; batch adversarial loss: 0.486967\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398076; batch adversarial loss: 0.601234\n",
      "epoch 109; iter: 0; batch classifier loss: 0.458440; batch adversarial loss: 0.505219\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387492; batch adversarial loss: 0.497837\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380997; batch adversarial loss: 0.538404\n",
      "epoch 112; iter: 0; batch classifier loss: 0.428827; batch adversarial loss: 0.520360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.494720; batch adversarial loss: 0.551380\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393875; batch adversarial loss: 0.561441\n",
      "epoch 115; iter: 0; batch classifier loss: 0.455824; batch adversarial loss: 0.501884\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377743; batch adversarial loss: 0.460230\n",
      "epoch 117; iter: 0; batch classifier loss: 0.256627; batch adversarial loss: 0.551990\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378235; batch adversarial loss: 0.526065\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353535; batch adversarial loss: 0.531905\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316975; batch adversarial loss: 0.440803\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412791; batch adversarial loss: 0.546228\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402193; batch adversarial loss: 0.553193\n",
      "epoch 123; iter: 0; batch classifier loss: 0.450941; batch adversarial loss: 0.488290\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337079; batch adversarial loss: 0.507228\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356133; batch adversarial loss: 0.590590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391552; batch adversarial loss: 0.551251\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383598; batch adversarial loss: 0.505147\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402046; batch adversarial loss: 0.612800\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386200; batch adversarial loss: 0.539429\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359623; batch adversarial loss: 0.580554\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414849; batch adversarial loss: 0.556686\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342222; batch adversarial loss: 0.489542\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379293; batch adversarial loss: 0.448730\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405885; batch adversarial loss: 0.584666\n",
      "epoch 135; iter: 0; batch classifier loss: 0.342780; batch adversarial loss: 0.485478\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360545; batch adversarial loss: 0.623050\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379044; batch adversarial loss: 0.515975\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379830; batch adversarial loss: 0.527135\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331309; batch adversarial loss: 0.534925\n",
      "epoch 140; iter: 0; batch classifier loss: 0.447847; batch adversarial loss: 0.479120\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349908; batch adversarial loss: 0.572721\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345644; batch adversarial loss: 0.629120\n",
      "epoch 143; iter: 0; batch classifier loss: 0.407976; batch adversarial loss: 0.560242\n",
      "epoch 144; iter: 0; batch classifier loss: 0.433768; batch adversarial loss: 0.563280\n",
      "epoch 145; iter: 0; batch classifier loss: 0.316629; batch adversarial loss: 0.543586\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332960; batch adversarial loss: 0.528443\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319955; batch adversarial loss: 0.605336\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362601; batch adversarial loss: 0.452690\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322506; batch adversarial loss: 0.494643\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381023; batch adversarial loss: 0.592584\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327268; batch adversarial loss: 0.487257\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344121; batch adversarial loss: 0.560603\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381884; batch adversarial loss: 0.598132\n",
      "epoch 154; iter: 0; batch classifier loss: 0.327635; batch adversarial loss: 0.544697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.410078; batch adversarial loss: 0.544965\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358743; batch adversarial loss: 0.621295\n",
      "epoch 157; iter: 0; batch classifier loss: 0.348419; batch adversarial loss: 0.657330\n",
      "epoch 158; iter: 0; batch classifier loss: 0.408034; batch adversarial loss: 0.458953\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415922; batch adversarial loss: 0.581756\n",
      "epoch 160; iter: 0; batch classifier loss: 0.329974; batch adversarial loss: 0.555270\n",
      "epoch 161; iter: 0; batch classifier loss: 0.332741; batch adversarial loss: 0.595506\n",
      "epoch 162; iter: 0; batch classifier loss: 0.434001; batch adversarial loss: 0.571469\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340895; batch adversarial loss: 0.487002\n",
      "epoch 164; iter: 0; batch classifier loss: 0.282520; batch adversarial loss: 0.523740\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360705; batch adversarial loss: 0.563574\n",
      "epoch 166; iter: 0; batch classifier loss: 0.402648; batch adversarial loss: 0.542840\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352913; batch adversarial loss: 0.514155\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347562; batch adversarial loss: 0.499272\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356778; batch adversarial loss: 0.525330\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330272; batch adversarial loss: 0.509666\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353532; batch adversarial loss: 0.538157\n",
      "epoch 172; iter: 0; batch classifier loss: 0.414298; batch adversarial loss: 0.544024\n",
      "epoch 173; iter: 0; batch classifier loss: 0.447797; batch adversarial loss: 0.525449\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371038; batch adversarial loss: 0.507115\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356498; batch adversarial loss: 0.524211\n",
      "epoch 176; iter: 0; batch classifier loss: 0.391136; batch adversarial loss: 0.553077\n",
      "epoch 177; iter: 0; batch classifier loss: 0.297374; batch adversarial loss: 0.498045\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405080; batch adversarial loss: 0.571728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.445048; batch adversarial loss: 0.542049\n",
      "epoch 180; iter: 0; batch classifier loss: 0.397074; batch adversarial loss: 0.563135\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305194; batch adversarial loss: 0.499142\n",
      "epoch 182; iter: 0; batch classifier loss: 0.306580; batch adversarial loss: 0.457085\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356178; batch adversarial loss: 0.517022\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336562; batch adversarial loss: 0.505745\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361152; batch adversarial loss: 0.475899\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377387; batch adversarial loss: 0.598520\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326055; batch adversarial loss: 0.553885\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350476; batch adversarial loss: 0.532182\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322818; batch adversarial loss: 0.478780\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384231; batch adversarial loss: 0.406216\n",
      "epoch 191; iter: 0; batch classifier loss: 0.395661; batch adversarial loss: 0.488981\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344358; batch adversarial loss: 0.571039\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300050; batch adversarial loss: 0.452369\n",
      "epoch 194; iter: 0; batch classifier loss: 0.334743; batch adversarial loss: 0.560310\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370502; batch adversarial loss: 0.551092\n",
      "epoch 196; iter: 0; batch classifier loss: 0.443259; batch adversarial loss: 0.487629\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329674; batch adversarial loss: 0.588815\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366660; batch adversarial loss: 0.533635\n",
      "epoch 199; iter: 0; batch classifier loss: 0.377384; batch adversarial loss: 0.507178\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723706; batch adversarial loss: 0.545706\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602095; batch adversarial loss: 0.665311\n",
      "epoch 2; iter: 0; batch classifier loss: 0.635908; batch adversarial loss: 0.696918\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568174; batch adversarial loss: 0.682533\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640561; batch adversarial loss: 0.636141\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544011; batch adversarial loss: 0.675353\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554927; batch adversarial loss: 0.633822\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562966; batch adversarial loss: 0.609097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522022; batch adversarial loss: 0.617385\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522322; batch adversarial loss: 0.596678\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568744; batch adversarial loss: 0.606984\n",
      "epoch 11; iter: 0; batch classifier loss: 0.610034; batch adversarial loss: 0.561052\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567417; batch adversarial loss: 0.576557\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570477; batch adversarial loss: 0.576295\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515535; batch adversarial loss: 0.592400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470544; batch adversarial loss: 0.566608\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506523; batch adversarial loss: 0.583151\n",
      "epoch 17; iter: 0; batch classifier loss: 0.454046; batch adversarial loss: 0.588013\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513180; batch adversarial loss: 0.492890\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482490; batch adversarial loss: 0.534572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457439; batch adversarial loss: 0.564849\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476513; batch adversarial loss: 0.595891\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465649; batch adversarial loss: 0.588979\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426923; batch adversarial loss: 0.594171\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464337; batch adversarial loss: 0.596892\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497503; batch adversarial loss: 0.569423\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536314; batch adversarial loss: 0.546504\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458206; batch adversarial loss: 0.484939\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496627; batch adversarial loss: 0.527878\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492760; batch adversarial loss: 0.587695\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449865; batch adversarial loss: 0.648096\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414033; batch adversarial loss: 0.579164\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488367; batch adversarial loss: 0.553679\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466241; batch adversarial loss: 0.623230\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421265; batch adversarial loss: 0.543835\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476583; batch adversarial loss: 0.528247\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428060; batch adversarial loss: 0.570953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471520; batch adversarial loss: 0.519555\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488969; batch adversarial loss: 0.545192\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477313; batch adversarial loss: 0.579006\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493423; batch adversarial loss: 0.517464\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430152; batch adversarial loss: 0.561349\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390599; batch adversarial loss: 0.651658\n",
      "epoch 43; iter: 0; batch classifier loss: 0.500611; batch adversarial loss: 0.527132\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430866; batch adversarial loss: 0.562401\n",
      "epoch 45; iter: 0; batch classifier loss: 0.486839; batch adversarial loss: 0.543300\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447352; batch adversarial loss: 0.655189\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442708; batch adversarial loss: 0.578710\n",
      "epoch 48; iter: 0; batch classifier loss: 0.504930; batch adversarial loss: 0.475369\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422581; batch adversarial loss: 0.579455\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454933; batch adversarial loss: 0.509619\n",
      "epoch 51; iter: 0; batch classifier loss: 0.336130; batch adversarial loss: 0.569368\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456993; batch adversarial loss: 0.525942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.470405; batch adversarial loss: 0.553484\n",
      "epoch 54; iter: 0; batch classifier loss: 0.458044; batch adversarial loss: 0.573191\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453484; batch adversarial loss: 0.574110\n",
      "epoch 56; iter: 0; batch classifier loss: 0.360691; batch adversarial loss: 0.543332\n",
      "epoch 57; iter: 0; batch classifier loss: 0.367629; batch adversarial loss: 0.543325\n",
      "epoch 58; iter: 0; batch classifier loss: 0.367548; batch adversarial loss: 0.554545\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425395; batch adversarial loss: 0.517467\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457776; batch adversarial loss: 0.526955\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390098; batch adversarial loss: 0.536633\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387653; batch adversarial loss: 0.544553\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410870; batch adversarial loss: 0.606799\n",
      "epoch 64; iter: 0; batch classifier loss: 0.476932; batch adversarial loss: 0.552545\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455162; batch adversarial loss: 0.535639\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441126; batch adversarial loss: 0.605383\n",
      "epoch 67; iter: 0; batch classifier loss: 0.452957; batch adversarial loss: 0.579216\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363799; batch adversarial loss: 0.473027\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420168; batch adversarial loss: 0.482142\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476815; batch adversarial loss: 0.562267\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406269; batch adversarial loss: 0.567428\n",
      "epoch 72; iter: 0; batch classifier loss: 0.340541; batch adversarial loss: 0.534562\n",
      "epoch 73; iter: 0; batch classifier loss: 0.399108; batch adversarial loss: 0.560830\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391819; batch adversarial loss: 0.549805\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441972; batch adversarial loss: 0.564907\n",
      "epoch 76; iter: 0; batch classifier loss: 0.458717; batch adversarial loss: 0.532262\n",
      "epoch 77; iter: 0; batch classifier loss: 0.456086; batch adversarial loss: 0.624014\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389702; batch adversarial loss: 0.528735\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433606; batch adversarial loss: 0.526305\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398418; batch adversarial loss: 0.535037\n",
      "epoch 81; iter: 0; batch classifier loss: 0.439375; batch adversarial loss: 0.589998\n",
      "epoch 82; iter: 0; batch classifier loss: 0.449702; batch adversarial loss: 0.562211\n",
      "epoch 83; iter: 0; batch classifier loss: 0.408507; batch adversarial loss: 0.607871\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430063; batch adversarial loss: 0.543314\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383378; batch adversarial loss: 0.525005\n",
      "epoch 86; iter: 0; batch classifier loss: 0.443221; batch adversarial loss: 0.491041\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411278; batch adversarial loss: 0.466519\n",
      "epoch 88; iter: 0; batch classifier loss: 0.364350; batch adversarial loss: 0.570973\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433105; batch adversarial loss: 0.499684\n",
      "epoch 90; iter: 0; batch classifier loss: 0.528810; batch adversarial loss: 0.545506\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416833; batch adversarial loss: 0.509634\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407714; batch adversarial loss: 0.561886\n",
      "epoch 93; iter: 0; batch classifier loss: 0.336613; batch adversarial loss: 0.546010\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370896; batch adversarial loss: 0.559821\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392909; batch adversarial loss: 0.550439\n",
      "epoch 96; iter: 0; batch classifier loss: 0.323326; batch adversarial loss: 0.500607\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388475; batch adversarial loss: 0.552407\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412056; batch adversarial loss: 0.651551\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441794; batch adversarial loss: 0.531098\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418072; batch adversarial loss: 0.545584\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374878; batch adversarial loss: 0.598636\n",
      "epoch 102; iter: 0; batch classifier loss: 0.471874; batch adversarial loss: 0.527453\n",
      "epoch 103; iter: 0; batch classifier loss: 0.450241; batch adversarial loss: 0.489273\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366111; batch adversarial loss: 0.555269\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363787; batch adversarial loss: 0.613791\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387587; batch adversarial loss: 0.589228\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348520; batch adversarial loss: 0.588050\n",
      "epoch 108; iter: 0; batch classifier loss: 0.442768; batch adversarial loss: 0.615935\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422226; batch adversarial loss: 0.563471\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357970; batch adversarial loss: 0.561451\n",
      "epoch 111; iter: 0; batch classifier loss: 0.370614; batch adversarial loss: 0.577126\n",
      "epoch 112; iter: 0; batch classifier loss: 0.448238; batch adversarial loss: 0.555005\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377108; batch adversarial loss: 0.466601\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394560; batch adversarial loss: 0.543059\n",
      "epoch 115; iter: 0; batch classifier loss: 0.441596; batch adversarial loss: 0.524051\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350458; batch adversarial loss: 0.544523\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396055; batch adversarial loss: 0.552118\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340011; batch adversarial loss: 0.614359\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417735; batch adversarial loss: 0.467049\n",
      "epoch 120; iter: 0; batch classifier loss: 0.475165; batch adversarial loss: 0.615710\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368284; batch adversarial loss: 0.599376\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369513; batch adversarial loss: 0.626611\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354468; batch adversarial loss: 0.613222\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379525; batch adversarial loss: 0.562619\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344469; batch adversarial loss: 0.525419\n",
      "epoch 126; iter: 0; batch classifier loss: 0.389750; batch adversarial loss: 0.554039\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394856; batch adversarial loss: 0.596205\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352297; batch adversarial loss: 0.606795\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413369; batch adversarial loss: 0.520654\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357844; batch adversarial loss: 0.553848\n",
      "epoch 131; iter: 0; batch classifier loss: 0.451390; batch adversarial loss: 0.628867\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330319; batch adversarial loss: 0.529862\n",
      "epoch 133; iter: 0; batch classifier loss: 0.468797; batch adversarial loss: 0.457224\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397252; batch adversarial loss: 0.579778\n",
      "epoch 135; iter: 0; batch classifier loss: 0.392186; batch adversarial loss: 0.553420\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340532; batch adversarial loss: 0.562329\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389533; batch adversarial loss: 0.535861\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359402; batch adversarial loss: 0.562474\n",
      "epoch 139; iter: 0; batch classifier loss: 0.400979; batch adversarial loss: 0.499628\n",
      "epoch 140; iter: 0; batch classifier loss: 0.414633; batch adversarial loss: 0.642092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.418086; batch adversarial loss: 0.483689\n",
      "epoch 142; iter: 0; batch classifier loss: 0.388296; batch adversarial loss: 0.588554\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349895; batch adversarial loss: 0.529012\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366925; batch adversarial loss: 0.536342\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404827; batch adversarial loss: 0.536493\n",
      "epoch 146; iter: 0; batch classifier loss: 0.303776; batch adversarial loss: 0.537777\n",
      "epoch 147; iter: 0; batch classifier loss: 0.440310; batch adversarial loss: 0.480790\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365719; batch adversarial loss: 0.596795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.376070; batch adversarial loss: 0.580131\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337504; batch adversarial loss: 0.491206\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387236; batch adversarial loss: 0.561461\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348498; batch adversarial loss: 0.586523\n",
      "epoch 153; iter: 0; batch classifier loss: 0.439114; batch adversarial loss: 0.551407\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389667; batch adversarial loss: 0.587390\n",
      "epoch 155; iter: 0; batch classifier loss: 0.361881; batch adversarial loss: 0.520436\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379916; batch adversarial loss: 0.537227\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374861; batch adversarial loss: 0.572234\n",
      "epoch 158; iter: 0; batch classifier loss: 0.377401; batch adversarial loss: 0.562573\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290244; batch adversarial loss: 0.563022\n",
      "epoch 160; iter: 0; batch classifier loss: 0.407054; batch adversarial loss: 0.543633\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322569; batch adversarial loss: 0.518324\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358558; batch adversarial loss: 0.508392\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345590; batch adversarial loss: 0.473036\n",
      "epoch 164; iter: 0; batch classifier loss: 0.364409; batch adversarial loss: 0.551822\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357100; batch adversarial loss: 0.491218\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349876; batch adversarial loss: 0.559981\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345957; batch adversarial loss: 0.569183\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373425; batch adversarial loss: 0.570988\n",
      "epoch 169; iter: 0; batch classifier loss: 0.418203; batch adversarial loss: 0.511726\n",
      "epoch 170; iter: 0; batch classifier loss: 0.446056; batch adversarial loss: 0.500181\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401580; batch adversarial loss: 0.571410\n",
      "epoch 172; iter: 0; batch classifier loss: 0.390911; batch adversarial loss: 0.447358\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323102; batch adversarial loss: 0.552066\n",
      "epoch 174; iter: 0; batch classifier loss: 0.312509; batch adversarial loss: 0.509177\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335188; batch adversarial loss: 0.544893\n",
      "epoch 176; iter: 0; batch classifier loss: 0.461727; batch adversarial loss: 0.570159\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387238; batch adversarial loss: 0.562989\n",
      "epoch 178; iter: 0; batch classifier loss: 0.395064; batch adversarial loss: 0.605492\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350981; batch adversarial loss: 0.517221\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318915; batch adversarial loss: 0.582061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.437133; batch adversarial loss: 0.587256\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408406; batch adversarial loss: 0.563205\n",
      "epoch 183; iter: 0; batch classifier loss: 0.319830; batch adversarial loss: 0.509101\n",
      "epoch 184; iter: 0; batch classifier loss: 0.417806; batch adversarial loss: 0.499602\n",
      "epoch 185; iter: 0; batch classifier loss: 0.424767; batch adversarial loss: 0.613762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.282734; batch adversarial loss: 0.571485\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389513; batch adversarial loss: 0.536865\n",
      "epoch 188; iter: 0; batch classifier loss: 0.461049; batch adversarial loss: 0.564812\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375545; batch adversarial loss: 0.474774\n",
      "epoch 190; iter: 0; batch classifier loss: 0.522418; batch adversarial loss: 0.509148\n",
      "epoch 191; iter: 0; batch classifier loss: 0.439444; batch adversarial loss: 0.624604\n",
      "epoch 192; iter: 0; batch classifier loss: 0.414160; batch adversarial loss: 0.614698\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378994; batch adversarial loss: 0.560154\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396968; batch adversarial loss: 0.548904\n",
      "epoch 195; iter: 0; batch classifier loss: 0.299084; batch adversarial loss: 0.560224\n",
      "epoch 196; iter: 0; batch classifier loss: 0.293284; batch adversarial loss: 0.535513\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345436; batch adversarial loss: 0.616475\n",
      "epoch 198; iter: 0; batch classifier loss: 0.423032; batch adversarial loss: 0.535483\n",
      "epoch 199; iter: 0; batch classifier loss: 0.320411; batch adversarial loss: 0.606091\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702351; batch adversarial loss: 0.584598\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599228; batch adversarial loss: 0.657446\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589269; batch adversarial loss: 0.657449\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557896; batch adversarial loss: 0.666976\n",
      "epoch 4; iter: 0; batch classifier loss: 0.637551; batch adversarial loss: 0.638998\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580369; batch adversarial loss: 0.670370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.602748; batch adversarial loss: 0.663996\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509731; batch adversarial loss: 0.601878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579551; batch adversarial loss: 0.578364\n",
      "epoch 9; iter: 0; batch classifier loss: 0.583515; batch adversarial loss: 0.600836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576800; batch adversarial loss: 0.606059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.677583; batch adversarial loss: 0.608014\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538469; batch adversarial loss: 0.573906\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498486; batch adversarial loss: 0.522870\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528573; batch adversarial loss: 0.542703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538736; batch adversarial loss: 0.536974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512940; batch adversarial loss: 0.507999\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482512; batch adversarial loss: 0.529000\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535766; batch adversarial loss: 0.595840\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496632; batch adversarial loss: 0.608209\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457102; batch adversarial loss: 0.551752\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493094; batch adversarial loss: 0.541192\n",
      "epoch 22; iter: 0; batch classifier loss: 0.580656; batch adversarial loss: 0.531662\n",
      "epoch 23; iter: 0; batch classifier loss: 0.541268; batch adversarial loss: 0.578573\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514946; batch adversarial loss: 0.537949\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525761; batch adversarial loss: 0.553709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406455; batch adversarial loss: 0.564041\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427222; batch adversarial loss: 0.505941\n",
      "epoch 28; iter: 0; batch classifier loss: 0.436530; batch adversarial loss: 0.554076\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441099; batch adversarial loss: 0.529165\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415544; batch adversarial loss: 0.554319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.423474; batch adversarial loss: 0.529562\n",
      "epoch 32; iter: 0; batch classifier loss: 0.413563; batch adversarial loss: 0.580520\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460492; batch adversarial loss: 0.571921\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477048; batch adversarial loss: 0.639457\n",
      "epoch 35; iter: 0; batch classifier loss: 0.541790; batch adversarial loss: 0.502158\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494328; batch adversarial loss: 0.546741\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452710; batch adversarial loss: 0.553235\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452303; batch adversarial loss: 0.519204\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468440; batch adversarial loss: 0.553121\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399067; batch adversarial loss: 0.562090\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440393; batch adversarial loss: 0.500859\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423440; batch adversarial loss: 0.484248\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463528; batch adversarial loss: 0.535554\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435637; batch adversarial loss: 0.571177\n",
      "epoch 45; iter: 0; batch classifier loss: 0.483123; batch adversarial loss: 0.519006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 0; batch classifier loss: 0.438986; batch adversarial loss: 0.605676\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446046; batch adversarial loss: 0.467350\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375051; batch adversarial loss: 0.588215\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442430; batch adversarial loss: 0.492930\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423285; batch adversarial loss: 0.569836\n",
      "epoch 51; iter: 0; batch classifier loss: 0.388832; batch adversarial loss: 0.573198\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476802; batch adversarial loss: 0.476127\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454642; batch adversarial loss: 0.544646\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451456; batch adversarial loss: 0.606877\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420080; batch adversarial loss: 0.642589\n",
      "epoch 56; iter: 0; batch classifier loss: 0.458277; batch adversarial loss: 0.536568\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398237; batch adversarial loss: 0.570353\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389519; batch adversarial loss: 0.589372\n",
      "epoch 59; iter: 0; batch classifier loss: 0.509807; batch adversarial loss: 0.501091\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423367; batch adversarial loss: 0.552912\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402187; batch adversarial loss: 0.527843\n",
      "epoch 62; iter: 0; batch classifier loss: 0.481630; batch adversarial loss: 0.595797\n",
      "epoch 63; iter: 0; batch classifier loss: 0.326750; batch adversarial loss: 0.439058\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398605; batch adversarial loss: 0.588617\n",
      "epoch 65; iter: 0; batch classifier loss: 0.355224; batch adversarial loss: 0.544967\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417179; batch adversarial loss: 0.544984\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377706; batch adversarial loss: 0.543906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364696; batch adversarial loss: 0.526965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.473139; batch adversarial loss: 0.528025\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446687; batch adversarial loss: 0.508569\n",
      "epoch 71; iter: 0; batch classifier loss: 0.350030; batch adversarial loss: 0.596603\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433967; batch adversarial loss: 0.483149\n",
      "epoch 73; iter: 0; batch classifier loss: 0.435242; batch adversarial loss: 0.491437\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391993; batch adversarial loss: 0.485009\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377699; batch adversarial loss: 0.636106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411222; batch adversarial loss: 0.537214\n",
      "epoch 77; iter: 0; batch classifier loss: 0.443548; batch adversarial loss: 0.573450\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428413; batch adversarial loss: 0.509078\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418536; batch adversarial loss: 0.551023\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401551; batch adversarial loss: 0.572492\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463055; batch adversarial loss: 0.606410\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443934; batch adversarial loss: 0.579752\n",
      "epoch 83; iter: 0; batch classifier loss: 0.484763; batch adversarial loss: 0.544025\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401422; batch adversarial loss: 0.533761\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385600; batch adversarial loss: 0.473793\n",
      "epoch 86; iter: 0; batch classifier loss: 0.500389; batch adversarial loss: 0.544264\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380920; batch adversarial loss: 0.526728\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381843; batch adversarial loss: 0.526129\n",
      "epoch 89; iter: 0; batch classifier loss: 0.439748; batch adversarial loss: 0.553907\n",
      "epoch 90; iter: 0; batch classifier loss: 0.328324; batch adversarial loss: 0.546127\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427462; batch adversarial loss: 0.660465\n",
      "epoch 92; iter: 0; batch classifier loss: 0.422173; batch adversarial loss: 0.562328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.331570; batch adversarial loss: 0.571396\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446578; batch adversarial loss: 0.509901\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428696; batch adversarial loss: 0.553173\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384000; batch adversarial loss: 0.563120\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394034; batch adversarial loss: 0.606669\n",
      "epoch 98; iter: 0; batch classifier loss: 0.428669; batch adversarial loss: 0.589044\n",
      "epoch 99; iter: 0; batch classifier loss: 0.321149; batch adversarial loss: 0.579265\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417065; batch adversarial loss: 0.535576\n",
      "epoch 101; iter: 0; batch classifier loss: 0.456123; batch adversarial loss: 0.526518\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364783; batch adversarial loss: 0.632949\n",
      "epoch 103; iter: 0; batch classifier loss: 0.437354; batch adversarial loss: 0.501998\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354360; batch adversarial loss: 0.571510\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414409; batch adversarial loss: 0.570947\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362899; batch adversarial loss: 0.526920\n",
      "epoch 107; iter: 0; batch classifier loss: 0.462285; batch adversarial loss: 0.535401\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353335; batch adversarial loss: 0.528257\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352443; batch adversarial loss: 0.545259\n",
      "epoch 110; iter: 0; batch classifier loss: 0.444277; batch adversarial loss: 0.517597\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405929; batch adversarial loss: 0.571074\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363952; batch adversarial loss: 0.588607\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373439; batch adversarial loss: 0.519668\n",
      "epoch 114; iter: 0; batch classifier loss: 0.457010; batch adversarial loss: 0.561634\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338487; batch adversarial loss: 0.615783\n",
      "epoch 116; iter: 0; batch classifier loss: 0.333091; batch adversarial loss: 0.509387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370111; batch adversarial loss: 0.622461\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354763; batch adversarial loss: 0.562794\n",
      "epoch 119; iter: 0; batch classifier loss: 0.307838; batch adversarial loss: 0.544227\n",
      "epoch 120; iter: 0; batch classifier loss: 0.336899; batch adversarial loss: 0.492430\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375194; batch adversarial loss: 0.519645\n",
      "epoch 122; iter: 0; batch classifier loss: 0.467315; batch adversarial loss: 0.508885\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347940; batch adversarial loss: 0.546478\n",
      "epoch 124; iter: 0; batch classifier loss: 0.396191; batch adversarial loss: 0.553934\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411490; batch adversarial loss: 0.570895\n",
      "epoch 126; iter: 0; batch classifier loss: 0.448429; batch adversarial loss: 0.570276\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367146; batch adversarial loss: 0.580262\n",
      "epoch 128; iter: 0; batch classifier loss: 0.512808; batch adversarial loss: 0.562539\n",
      "epoch 129; iter: 0; batch classifier loss: 0.396353; batch adversarial loss: 0.483566\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341188; batch adversarial loss: 0.493138\n",
      "epoch 131; iter: 0; batch classifier loss: 0.358536; batch adversarial loss: 0.561847\n",
      "epoch 132; iter: 0; batch classifier loss: 0.435702; batch adversarial loss: 0.552742\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402284; batch adversarial loss: 0.554055\n",
      "epoch 134; iter: 0; batch classifier loss: 0.325321; batch adversarial loss: 0.544137\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348718; batch adversarial loss: 0.552601\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383123; batch adversarial loss: 0.508626\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392024; batch adversarial loss: 0.483237\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367147; batch adversarial loss: 0.518890\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350768; batch adversarial loss: 0.484243\n",
      "epoch 140; iter: 0; batch classifier loss: 0.421242; batch adversarial loss: 0.569901\n",
      "epoch 141; iter: 0; batch classifier loss: 0.355002; batch adversarial loss: 0.624344\n",
      "epoch 142; iter: 0; batch classifier loss: 0.429070; batch adversarial loss: 0.518563\n",
      "epoch 143; iter: 0; batch classifier loss: 0.392838; batch adversarial loss: 0.571475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.348108; batch adversarial loss: 0.536090\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400789; batch adversarial loss: 0.518849\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418422; batch adversarial loss: 0.545678\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369636; batch adversarial loss: 0.456307\n",
      "epoch 148; iter: 0; batch classifier loss: 0.321175; batch adversarial loss: 0.483853\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398587; batch adversarial loss: 0.510065\n",
      "epoch 150; iter: 0; batch classifier loss: 0.422983; batch adversarial loss: 0.588475\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358288; batch adversarial loss: 0.605090\n",
      "epoch 152; iter: 0; batch classifier loss: 0.401604; batch adversarial loss: 0.553180\n",
      "epoch 153; iter: 0; batch classifier loss: 0.411459; batch adversarial loss: 0.536883\n",
      "epoch 154; iter: 0; batch classifier loss: 0.447787; batch adversarial loss: 0.474364\n",
      "epoch 155; iter: 0; batch classifier loss: 0.308640; batch adversarial loss: 0.578770\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344604; batch adversarial loss: 0.483907\n",
      "epoch 157; iter: 0; batch classifier loss: 0.402644; batch adversarial loss: 0.571464\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342285; batch adversarial loss: 0.544806\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349390; batch adversarial loss: 0.571122\n",
      "epoch 160; iter: 0; batch classifier loss: 0.450127; batch adversarial loss: 0.580182\n",
      "epoch 161; iter: 0; batch classifier loss: 0.405342; batch adversarial loss: 0.535253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.420381; batch adversarial loss: 0.492803\n",
      "epoch 163; iter: 0; batch classifier loss: 0.405340; batch adversarial loss: 0.572386\n",
      "epoch 164; iter: 0; batch classifier loss: 0.314234; batch adversarial loss: 0.527807\n",
      "epoch 165; iter: 0; batch classifier loss: 0.325421; batch adversarial loss: 0.589084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367722; batch adversarial loss: 0.545949\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393319; batch adversarial loss: 0.501448\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378467; batch adversarial loss: 0.561921\n",
      "epoch 169; iter: 0; batch classifier loss: 0.315208; batch adversarial loss: 0.526574\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339342; batch adversarial loss: 0.510063\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329895; batch adversarial loss: 0.606209\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322063; batch adversarial loss: 0.518696\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382032; batch adversarial loss: 0.519150\n",
      "epoch 174; iter: 0; batch classifier loss: 0.383068; batch adversarial loss: 0.552683\n",
      "epoch 175; iter: 0; batch classifier loss: 0.424301; batch adversarial loss: 0.553529\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327168; batch adversarial loss: 0.589048\n",
      "epoch 177; iter: 0; batch classifier loss: 0.408223; batch adversarial loss: 0.614353\n",
      "epoch 178; iter: 0; batch classifier loss: 0.478097; batch adversarial loss: 0.633592\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370450; batch adversarial loss: 0.562767\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379565; batch adversarial loss: 0.554249\n",
      "epoch 181; iter: 0; batch classifier loss: 0.318408; batch adversarial loss: 0.571412\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355076; batch adversarial loss: 0.527225\n",
      "epoch 183; iter: 0; batch classifier loss: 0.401431; batch adversarial loss: 0.579919\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325084; batch adversarial loss: 0.510894\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348695; batch adversarial loss: 0.586663\n",
      "epoch 186; iter: 0; batch classifier loss: 0.411365; batch adversarial loss: 0.570702\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375775; batch adversarial loss: 0.553761\n",
      "epoch 188; iter: 0; batch classifier loss: 0.351113; batch adversarial loss: 0.501112\n",
      "epoch 189; iter: 0; batch classifier loss: 0.463693; batch adversarial loss: 0.579491\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371700; batch adversarial loss: 0.614371\n",
      "epoch 191; iter: 0; batch classifier loss: 0.450906; batch adversarial loss: 0.570687\n",
      "epoch 192; iter: 0; batch classifier loss: 0.444347; batch adversarial loss: 0.579753\n",
      "epoch 193; iter: 0; batch classifier loss: 0.374920; batch adversarial loss: 0.509699\n",
      "epoch 194; iter: 0; batch classifier loss: 0.410909; batch adversarial loss: 0.580658\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328324; batch adversarial loss: 0.589213\n",
      "epoch 196; iter: 0; batch classifier loss: 0.430362; batch adversarial loss: 0.613770\n",
      "epoch 197; iter: 0; batch classifier loss: 0.345332; batch adversarial loss: 0.527054\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404536; batch adversarial loss: 0.543618\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312246; batch adversarial loss: 0.569327\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695927; batch adversarial loss: 0.840137\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637631; batch adversarial loss: 0.803469\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553138; batch adversarial loss: 0.748335\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588959; batch adversarial loss: 0.700253\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550541; batch adversarial loss: 0.680102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557114; batch adversarial loss: 0.643722\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533142; batch adversarial loss: 0.632568\n",
      "epoch 7; iter: 0; batch classifier loss: 0.577681; batch adversarial loss: 0.635758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546914; batch adversarial loss: 0.615858\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568454; batch adversarial loss: 0.631891\n",
      "epoch 10; iter: 0; batch classifier loss: 0.613510; batch adversarial loss: 0.600595\n",
      "epoch 11; iter: 0; batch classifier loss: 0.455853; batch adversarial loss: 0.630832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518793; batch adversarial loss: 0.550846\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494750; batch adversarial loss: 0.546603\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499136; batch adversarial loss: 0.657116\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493170; batch adversarial loss: 0.589977\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496285; batch adversarial loss: 0.576958\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501285; batch adversarial loss: 0.568583\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469412; batch adversarial loss: 0.558853\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513641; batch adversarial loss: 0.554157\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430165; batch adversarial loss: 0.528832\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473718; batch adversarial loss: 0.601010\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492230; batch adversarial loss: 0.590806\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491406; batch adversarial loss: 0.553026\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468521; batch adversarial loss: 0.539542\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521845; batch adversarial loss: 0.553211\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506545; batch adversarial loss: 0.606224\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511542; batch adversarial loss: 0.556966\n",
      "epoch 28; iter: 0; batch classifier loss: 0.563154; batch adversarial loss: 0.519752\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466085; batch adversarial loss: 0.526825\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468985; batch adversarial loss: 0.552480\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498379; batch adversarial loss: 0.565342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415242; batch adversarial loss: 0.576248\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467149; batch adversarial loss: 0.654877\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392569; batch adversarial loss: 0.524187\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414460; batch adversarial loss: 0.502866\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446477; batch adversarial loss: 0.564591\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480132; batch adversarial loss: 0.578995\n",
      "epoch 38; iter: 0; batch classifier loss: 0.396804; batch adversarial loss: 0.576110\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485354; batch adversarial loss: 0.564079\n",
      "epoch 40; iter: 0; batch classifier loss: 0.362251; batch adversarial loss: 0.589211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.448010; batch adversarial loss: 0.581100\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403692; batch adversarial loss: 0.521090\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450668; batch adversarial loss: 0.644301\n",
      "epoch 44; iter: 0; batch classifier loss: 0.523874; batch adversarial loss: 0.590802\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430552; batch adversarial loss: 0.527258\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406105; batch adversarial loss: 0.580070\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441131; batch adversarial loss: 0.588808\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452771; batch adversarial loss: 0.516646\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418592; batch adversarial loss: 0.526715\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391747; batch adversarial loss: 0.480891\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408367; batch adversarial loss: 0.553671\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431275; batch adversarial loss: 0.498925\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396348; batch adversarial loss: 0.552906\n",
      "epoch 54; iter: 0; batch classifier loss: 0.527196; batch adversarial loss: 0.508126\n",
      "epoch 55; iter: 0; batch classifier loss: 0.473051; batch adversarial loss: 0.572535\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412650; batch adversarial loss: 0.461359\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456444; batch adversarial loss: 0.563287\n",
      "epoch 58; iter: 0; batch classifier loss: 0.387142; batch adversarial loss: 0.581138\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404977; batch adversarial loss: 0.526346\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434853; batch adversarial loss: 0.507556\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451482; batch adversarial loss: 0.571886\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415618; batch adversarial loss: 0.526030\n",
      "epoch 63; iter: 0; batch classifier loss: 0.354013; batch adversarial loss: 0.526470\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381247; batch adversarial loss: 0.572361\n",
      "epoch 65; iter: 0; batch classifier loss: 0.337310; batch adversarial loss: 0.608682\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449601; batch adversarial loss: 0.571883\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436245; batch adversarial loss: 0.627220\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441962; batch adversarial loss: 0.590557\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431316; batch adversarial loss: 0.637248\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424999; batch adversarial loss: 0.609542\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395438; batch adversarial loss: 0.553571\n",
      "epoch 72; iter: 0; batch classifier loss: 0.363224; batch adversarial loss: 0.581466\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390788; batch adversarial loss: 0.507618\n",
      "epoch 74; iter: 0; batch classifier loss: 0.376826; batch adversarial loss: 0.452772\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370864; batch adversarial loss: 0.571880\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468535; batch adversarial loss: 0.526657\n",
      "epoch 77; iter: 0; batch classifier loss: 0.449526; batch adversarial loss: 0.617214\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399916; batch adversarial loss: 0.544340\n",
      "epoch 79; iter: 0; batch classifier loss: 0.427839; batch adversarial loss: 0.624036\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381501; batch adversarial loss: 0.534935\n",
      "epoch 81; iter: 0; batch classifier loss: 0.522603; batch adversarial loss: 0.568623\n",
      "epoch 82; iter: 0; batch classifier loss: 0.284879; batch adversarial loss: 0.538922\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396390; batch adversarial loss: 0.498638\n",
      "epoch 84; iter: 0; batch classifier loss: 0.351621; batch adversarial loss: 0.599740\n",
      "epoch 85; iter: 0; batch classifier loss: 0.454780; batch adversarial loss: 0.553925\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429596; batch adversarial loss: 0.535618\n",
      "epoch 87; iter: 0; batch classifier loss: 0.434745; batch adversarial loss: 0.589389\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411721; batch adversarial loss: 0.571336\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415879; batch adversarial loss: 0.535159\n",
      "epoch 90; iter: 0; batch classifier loss: 0.475500; batch adversarial loss: 0.573325\n",
      "epoch 91; iter: 0; batch classifier loss: 0.475363; batch adversarial loss: 0.544997\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417036; batch adversarial loss: 0.646349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420406; batch adversarial loss: 0.544493\n",
      "epoch 94; iter: 0; batch classifier loss: 0.482780; batch adversarial loss: 0.648458\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409221; batch adversarial loss: 0.545316\n",
      "epoch 96; iter: 0; batch classifier loss: 0.426535; batch adversarial loss: 0.573379\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365714; batch adversarial loss: 0.535113\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373078; batch adversarial loss: 0.525719\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389885; batch adversarial loss: 0.535230\n",
      "epoch 100; iter: 0; batch classifier loss: 0.319237; batch adversarial loss: 0.571913\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356124; batch adversarial loss: 0.571637\n",
      "epoch 102; iter: 0; batch classifier loss: 0.438210; batch adversarial loss: 0.433543\n",
      "epoch 103; iter: 0; batch classifier loss: 0.459024; batch adversarial loss: 0.563022\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344780; batch adversarial loss: 0.461522\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417057; batch adversarial loss: 0.590269\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402684; batch adversarial loss: 0.443308\n",
      "epoch 107; iter: 0; batch classifier loss: 0.420283; batch adversarial loss: 0.591186\n",
      "epoch 108; iter: 0; batch classifier loss: 0.456264; batch adversarial loss: 0.627100\n",
      "epoch 109; iter: 0; batch classifier loss: 0.448294; batch adversarial loss: 0.554023\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346598; batch adversarial loss: 0.535674\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348208; batch adversarial loss: 0.619874\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402164; batch adversarial loss: 0.559953\n",
      "epoch 113; iter: 0; batch classifier loss: 0.321841; batch adversarial loss: 0.579523\n",
      "epoch 114; iter: 0; batch classifier loss: 0.463294; batch adversarial loss: 0.552473\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379932; batch adversarial loss: 0.607944\n",
      "epoch 116; iter: 0; batch classifier loss: 0.320555; batch adversarial loss: 0.579726\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338090; batch adversarial loss: 0.551479\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405036; batch adversarial loss: 0.573560\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397938; batch adversarial loss: 0.566848\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364363; batch adversarial loss: 0.535924\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389260; batch adversarial loss: 0.554306\n",
      "epoch 122; iter: 0; batch classifier loss: 0.338311; batch adversarial loss: 0.609093\n",
      "epoch 123; iter: 0; batch classifier loss: 0.304394; batch adversarial loss: 0.562426\n",
      "epoch 124; iter: 0; batch classifier loss: 0.414103; batch adversarial loss: 0.544132\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368704; batch adversarial loss: 0.525339\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344026; batch adversarial loss: 0.544637\n",
      "epoch 127; iter: 0; batch classifier loss: 0.343975; batch adversarial loss: 0.523654\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418124; batch adversarial loss: 0.599438\n",
      "epoch 129; iter: 0; batch classifier loss: 0.328688; batch adversarial loss: 0.561947\n",
      "epoch 130; iter: 0; batch classifier loss: 0.399703; batch adversarial loss: 0.478585\n",
      "epoch 131; iter: 0; batch classifier loss: 0.425243; batch adversarial loss: 0.570802\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341604; batch adversarial loss: 0.617726\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374019; batch adversarial loss: 0.501217\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350661; batch adversarial loss: 0.555329\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362826; batch adversarial loss: 0.554554\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339719; batch adversarial loss: 0.553664\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334052; batch adversarial loss: 0.489255\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382841; batch adversarial loss: 0.505937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.438028; batch adversarial loss: 0.514113\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405735; batch adversarial loss: 0.532548\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364461; batch adversarial loss: 0.585512\n",
      "epoch 142; iter: 0; batch classifier loss: 0.393154; batch adversarial loss: 0.617578\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376820; batch adversarial loss: 0.589323\n",
      "epoch 144; iter: 0; batch classifier loss: 0.289951; batch adversarial loss: 0.572918\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360736; batch adversarial loss: 0.581278\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387121; batch adversarial loss: 0.656017\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394279; batch adversarial loss: 0.515099\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379412; batch adversarial loss: 0.582236\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344224; batch adversarial loss: 0.565266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433168; batch adversarial loss: 0.515435\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386793; batch adversarial loss: 0.478520\n",
      "epoch 152; iter: 0; batch classifier loss: 0.386033; batch adversarial loss: 0.509101\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367372; batch adversarial loss: 0.555227\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400096; batch adversarial loss: 0.469987\n",
      "epoch 155; iter: 0; batch classifier loss: 0.409152; batch adversarial loss: 0.603165\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334774; batch adversarial loss: 0.620606\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381943; batch adversarial loss: 0.535260\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380346; batch adversarial loss: 0.451223\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349666; batch adversarial loss: 0.619059\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339858; batch adversarial loss: 0.535878\n",
      "epoch 161; iter: 0; batch classifier loss: 0.431161; batch adversarial loss: 0.506591\n",
      "epoch 162; iter: 0; batch classifier loss: 0.416109; batch adversarial loss: 0.544738\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388923; batch adversarial loss: 0.580734\n",
      "epoch 164; iter: 0; batch classifier loss: 0.292534; batch adversarial loss: 0.619236\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303329; batch adversarial loss: 0.490062\n",
      "epoch 166; iter: 0; batch classifier loss: 0.462973; batch adversarial loss: 0.600034\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341697; batch adversarial loss: 0.627585\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359131; batch adversarial loss: 0.628725\n",
      "epoch 169; iter: 0; batch classifier loss: 0.498136; batch adversarial loss: 0.581842\n",
      "epoch 170; iter: 0; batch classifier loss: 0.307616; batch adversarial loss: 0.488661\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317839; batch adversarial loss: 0.571713\n",
      "epoch 172; iter: 0; batch classifier loss: 0.316131; batch adversarial loss: 0.562504\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362850; batch adversarial loss: 0.580263\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361135; batch adversarial loss: 0.553782\n",
      "epoch 175; iter: 0; batch classifier loss: 0.354443; batch adversarial loss: 0.535368\n",
      "epoch 176; iter: 0; batch classifier loss: 0.333239; batch adversarial loss: 0.526315\n",
      "epoch 177; iter: 0; batch classifier loss: 0.278267; batch adversarial loss: 0.516696\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332517; batch adversarial loss: 0.553894\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356689; batch adversarial loss: 0.571445\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381824; batch adversarial loss: 0.533676\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344473; batch adversarial loss: 0.554039\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342263; batch adversarial loss: 0.609358\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409318; batch adversarial loss: 0.517193\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339041; batch adversarial loss: 0.544382\n",
      "epoch 185; iter: 0; batch classifier loss: 0.337197; batch adversarial loss: 0.515948\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308219; batch adversarial loss: 0.526456\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373230; batch adversarial loss: 0.545409\n",
      "epoch 188; iter: 0; batch classifier loss: 0.418125; batch adversarial loss: 0.553292\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311828; batch adversarial loss: 0.487776\n",
      "epoch 190; iter: 0; batch classifier loss: 0.425392; batch adversarial loss: 0.617731\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387907; batch adversarial loss: 0.498304\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363500; batch adversarial loss: 0.554036\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392207; batch adversarial loss: 0.488550\n",
      "epoch 194; iter: 0; batch classifier loss: 0.422973; batch adversarial loss: 0.599329\n",
      "epoch 195; iter: 0; batch classifier loss: 0.305262; batch adversarial loss: 0.591638\n",
      "epoch 196; iter: 0; batch classifier loss: 0.277960; batch adversarial loss: 0.499083\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322547; batch adversarial loss: 0.580714\n",
      "epoch 198; iter: 0; batch classifier loss: 0.318796; batch adversarial loss: 0.497942\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365417; batch adversarial loss: 0.598989\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719633; batch adversarial loss: 0.747741\n",
      "epoch 1; iter: 0; batch classifier loss: 0.695383; batch adversarial loss: 0.700302\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563696; batch adversarial loss: 0.660680\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610398; batch adversarial loss: 0.651580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.592006; batch adversarial loss: 0.635965\n",
      "epoch 5; iter: 0; batch classifier loss: 0.545808; batch adversarial loss: 0.643009\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529845; batch adversarial loss: 0.599085\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575340; batch adversarial loss: 0.546528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515731; batch adversarial loss: 0.602269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511316; batch adversarial loss: 0.637076\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480443; batch adversarial loss: 0.547016\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605010; batch adversarial loss: 0.563566\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518171; batch adversarial loss: 0.547702\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551429; batch adversarial loss: 0.525508\n",
      "epoch 14; iter: 0; batch classifier loss: 0.492844; batch adversarial loss: 0.613762\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483032; batch adversarial loss: 0.513930\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480939; batch adversarial loss: 0.475910\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497911; batch adversarial loss: 0.529784\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519823; batch adversarial loss: 0.509654\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480734; batch adversarial loss: 0.545108\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433266; batch adversarial loss: 0.531146\n",
      "epoch 21; iter: 0; batch classifier loss: 0.556008; batch adversarial loss: 0.537654\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503228; batch adversarial loss: 0.563114\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454349; batch adversarial loss: 0.536383\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509979; batch adversarial loss: 0.585232\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440278; batch adversarial loss: 0.529993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475876; batch adversarial loss: 0.591734\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461737; batch adversarial loss: 0.582996\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419817; batch adversarial loss: 0.518491\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471568; batch adversarial loss: 0.582020\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462091; batch adversarial loss: 0.576344\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452234; batch adversarial loss: 0.590119\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499593; batch adversarial loss: 0.601742\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491098; batch adversarial loss: 0.574241\n",
      "epoch 34; iter: 0; batch classifier loss: 0.527067; batch adversarial loss: 0.484309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.427196; batch adversarial loss: 0.503186\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487479; batch adversarial loss: 0.528152\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381201; batch adversarial loss: 0.579998\n",
      "epoch 38; iter: 0; batch classifier loss: 0.388276; batch adversarial loss: 0.561978\n",
      "epoch 39; iter: 0; batch classifier loss: 0.469888; batch adversarial loss: 0.509407\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431819; batch adversarial loss: 0.544809\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435627; batch adversarial loss: 0.562257\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448254; batch adversarial loss: 0.616058\n",
      "epoch 43; iter: 0; batch classifier loss: 0.371832; batch adversarial loss: 0.553544\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485916; batch adversarial loss: 0.490740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413969; batch adversarial loss: 0.461816\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424343; batch adversarial loss: 0.668789\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484545; batch adversarial loss: 0.554402\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481016; batch adversarial loss: 0.561820\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366341; batch adversarial loss: 0.469902\n",
      "epoch 50; iter: 0; batch classifier loss: 0.380433; batch adversarial loss: 0.562745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446776; batch adversarial loss: 0.498432\n",
      "epoch 52; iter: 0; batch classifier loss: 0.338103; batch adversarial loss: 0.507350\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450892; batch adversarial loss: 0.497037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.373433; batch adversarial loss: 0.525201\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412224; batch adversarial loss: 0.561962\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366816; batch adversarial loss: 0.629183\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416656; batch adversarial loss: 0.518292\n",
      "epoch 58; iter: 0; batch classifier loss: 0.344646; batch adversarial loss: 0.497333\n",
      "epoch 59; iter: 0; batch classifier loss: 0.486396; batch adversarial loss: 0.570702\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401272; batch adversarial loss: 0.618290\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425510; batch adversarial loss: 0.515356\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407964; batch adversarial loss: 0.498827\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407431; batch adversarial loss: 0.533249\n",
      "epoch 64; iter: 0; batch classifier loss: 0.355265; batch adversarial loss: 0.591060\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449324; batch adversarial loss: 0.534866\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438002; batch adversarial loss: 0.518055\n",
      "epoch 67; iter: 0; batch classifier loss: 0.484999; batch adversarial loss: 0.499042\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428887; batch adversarial loss: 0.486441\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410589; batch adversarial loss: 0.528010\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455889; batch adversarial loss: 0.571294\n",
      "epoch 71; iter: 0; batch classifier loss: 0.452177; batch adversarial loss: 0.572057\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455292; batch adversarial loss: 0.565011\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422152; batch adversarial loss: 0.552623\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437431; batch adversarial loss: 0.495442\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391750; batch adversarial loss: 0.487711\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386408; batch adversarial loss: 0.467491\n",
      "epoch 77; iter: 0; batch classifier loss: 0.465044; batch adversarial loss: 0.573995\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351797; batch adversarial loss: 0.468646\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382711; batch adversarial loss: 0.655525\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377555; batch adversarial loss: 0.560746\n",
      "epoch 81; iter: 0; batch classifier loss: 0.425035; batch adversarial loss: 0.505962\n",
      "epoch 82; iter: 0; batch classifier loss: 0.463408; batch adversarial loss: 0.531423\n",
      "epoch 83; iter: 0; batch classifier loss: 0.325268; batch adversarial loss: 0.572531\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435481; batch adversarial loss: 0.606723\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350072; batch adversarial loss: 0.579194\n",
      "epoch 86; iter: 0; batch classifier loss: 0.363789; batch adversarial loss: 0.533535\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377283; batch adversarial loss: 0.541916\n",
      "epoch 88; iter: 0; batch classifier loss: 0.505776; batch adversarial loss: 0.544647\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362348; batch adversarial loss: 0.536602\n",
      "epoch 90; iter: 0; batch classifier loss: 0.438439; batch adversarial loss: 0.532840\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410082; batch adversarial loss: 0.543352\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421813; batch adversarial loss: 0.574005\n",
      "epoch 93; iter: 0; batch classifier loss: 0.419246; batch adversarial loss: 0.542955\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383644; batch adversarial loss: 0.514562\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422821; batch adversarial loss: 0.573525\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423041; batch adversarial loss: 0.557746\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364830; batch adversarial loss: 0.480936\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418137; batch adversarial loss: 0.588296\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413458; batch adversarial loss: 0.515352\n",
      "epoch 100; iter: 0; batch classifier loss: 0.437755; batch adversarial loss: 0.524918\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398409; batch adversarial loss: 0.454945\n",
      "epoch 102; iter: 0; batch classifier loss: 0.406077; batch adversarial loss: 0.555742\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395829; batch adversarial loss: 0.574974\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420085; batch adversarial loss: 0.545640\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414841; batch adversarial loss: 0.501380\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419506; batch adversarial loss: 0.581927\n",
      "epoch 107; iter: 0; batch classifier loss: 0.409637; batch adversarial loss: 0.514791\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396934; batch adversarial loss: 0.552107\n",
      "epoch 109; iter: 0; batch classifier loss: 0.481606; batch adversarial loss: 0.517138\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391848; batch adversarial loss: 0.573627\n",
      "epoch 111; iter: 0; batch classifier loss: 0.273666; batch adversarial loss: 0.507910\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371227; batch adversarial loss: 0.510400\n",
      "epoch 113; iter: 0; batch classifier loss: 0.443753; batch adversarial loss: 0.548672\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329543; batch adversarial loss: 0.515032\n",
      "epoch 115; iter: 0; batch classifier loss: 0.385246; batch adversarial loss: 0.570163\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415125; batch adversarial loss: 0.532420\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354095; batch adversarial loss: 0.563822\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360339; batch adversarial loss: 0.453280\n",
      "epoch 119; iter: 0; batch classifier loss: 0.445795; batch adversarial loss: 0.460833\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406986; batch adversarial loss: 0.495634\n",
      "epoch 121; iter: 0; batch classifier loss: 0.352998; batch adversarial loss: 0.499992\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378403; batch adversarial loss: 0.634798\n",
      "epoch 123; iter: 0; batch classifier loss: 0.312987; batch adversarial loss: 0.505396\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408061; batch adversarial loss: 0.533614\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355844; batch adversarial loss: 0.535709\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390961; batch adversarial loss: 0.603018\n",
      "epoch 127; iter: 0; batch classifier loss: 0.460881; batch adversarial loss: 0.561854\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329439; batch adversarial loss: 0.636103\n",
      "epoch 129; iter: 0; batch classifier loss: 0.447498; batch adversarial loss: 0.599200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.416080; batch adversarial loss: 0.492011\n",
      "epoch 131; iter: 0; batch classifier loss: 0.454215; batch adversarial loss: 0.580402\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402066; batch adversarial loss: 0.587799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.553291\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394575; batch adversarial loss: 0.534224\n",
      "epoch 135; iter: 0; batch classifier loss: 0.463407; batch adversarial loss: 0.515493\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380587; batch adversarial loss: 0.481061\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370665; batch adversarial loss: 0.526627\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357739; batch adversarial loss: 0.636537\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357484; batch adversarial loss: 0.545359\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368243; batch adversarial loss: 0.516160\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341346; batch adversarial loss: 0.532778\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395936; batch adversarial loss: 0.500583\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394635; batch adversarial loss: 0.449061\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372340; batch adversarial loss: 0.563668\n",
      "epoch 145; iter: 0; batch classifier loss: 0.345037; batch adversarial loss: 0.524063\n",
      "epoch 146; iter: 0; batch classifier loss: 0.439467; batch adversarial loss: 0.506761\n",
      "epoch 147; iter: 0; batch classifier loss: 0.352685; batch adversarial loss: 0.536358\n",
      "epoch 148; iter: 0; batch classifier loss: 0.313476; batch adversarial loss: 0.573869\n",
      "epoch 149; iter: 0; batch classifier loss: 0.451089; batch adversarial loss: 0.536624\n",
      "epoch 150; iter: 0; batch classifier loss: 0.425689; batch adversarial loss: 0.569348\n",
      "epoch 151; iter: 0; batch classifier loss: 0.483275; batch adversarial loss: 0.532534\n",
      "epoch 152; iter: 0; batch classifier loss: 0.440286; batch adversarial loss: 0.539840\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404480; batch adversarial loss: 0.498269\n",
      "epoch 154; iter: 0; batch classifier loss: 0.422091; batch adversarial loss: 0.508878\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370637; batch adversarial loss: 0.544824\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378707; batch adversarial loss: 0.492740\n",
      "epoch 157; iter: 0; batch classifier loss: 0.417867; batch adversarial loss: 0.552507\n",
      "epoch 158; iter: 0; batch classifier loss: 0.351694; batch adversarial loss: 0.591496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.433685; batch adversarial loss: 0.488649\n",
      "epoch 160; iter: 0; batch classifier loss: 0.445671; batch adversarial loss: 0.587607\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354183; batch adversarial loss: 0.615831\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358489; batch adversarial loss: 0.534731\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391719; batch adversarial loss: 0.583136\n",
      "epoch 164; iter: 0; batch classifier loss: 0.432961; batch adversarial loss: 0.515834\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366829; batch adversarial loss: 0.595724\n",
      "epoch 166; iter: 0; batch classifier loss: 0.315238; batch adversarial loss: 0.516125\n",
      "epoch 167; iter: 0; batch classifier loss: 0.475001; batch adversarial loss: 0.508556\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390649; batch adversarial loss: 0.517398\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352318; batch adversarial loss: 0.525427\n",
      "epoch 170; iter: 0; batch classifier loss: 0.418369; batch adversarial loss: 0.611581\n",
      "epoch 171; iter: 0; batch classifier loss: 0.300098; batch adversarial loss: 0.544466\n",
      "epoch 172; iter: 0; batch classifier loss: 0.296537; batch adversarial loss: 0.562421\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349654; batch adversarial loss: 0.578301\n",
      "epoch 174; iter: 0; batch classifier loss: 0.478922; batch adversarial loss: 0.516695\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351460; batch adversarial loss: 0.554039\n",
      "epoch 176; iter: 0; batch classifier loss: 0.359894; batch adversarial loss: 0.574103\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327809; batch adversarial loss: 0.543725\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417758; batch adversarial loss: 0.516681\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341583; batch adversarial loss: 0.542703\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318838; batch adversarial loss: 0.553184\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349603; batch adversarial loss: 0.565400\n",
      "epoch 182; iter: 0; batch classifier loss: 0.398845; batch adversarial loss: 0.524217\n",
      "epoch 183; iter: 0; batch classifier loss: 0.375506; batch adversarial loss: 0.471634\n",
      "epoch 184; iter: 0; batch classifier loss: 0.419702; batch adversarial loss: 0.631116\n",
      "epoch 185; iter: 0; batch classifier loss: 0.404856; batch adversarial loss: 0.525048\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332897; batch adversarial loss: 0.514937\n",
      "epoch 187; iter: 0; batch classifier loss: 0.461088; batch adversarial loss: 0.591173\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353960; batch adversarial loss: 0.516650\n",
      "epoch 189; iter: 0; batch classifier loss: 0.405682; batch adversarial loss: 0.518460\n",
      "epoch 190; iter: 0; batch classifier loss: 0.412562; batch adversarial loss: 0.573372\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386933; batch adversarial loss: 0.508749\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378489; batch adversarial loss: 0.515758\n",
      "epoch 193; iter: 0; batch classifier loss: 0.404423; batch adversarial loss: 0.517050\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351402; batch adversarial loss: 0.470098\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323364; batch adversarial loss: 0.565127\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330003; batch adversarial loss: 0.544321\n",
      "epoch 197; iter: 0; batch classifier loss: 0.338747; batch adversarial loss: 0.479570\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335560; batch adversarial loss: 0.578419\n",
      "epoch 199; iter: 0; batch classifier loss: 0.287370; batch adversarial loss: 0.607694\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680047; batch adversarial loss: 0.689420\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594924; batch adversarial loss: 0.671663\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556206; batch adversarial loss: 0.646162\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541845; batch adversarial loss: 0.635576\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580069; batch adversarial loss: 0.633751\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528081; batch adversarial loss: 0.626018\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538252; batch adversarial loss: 0.606684\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541634; batch adversarial loss: 0.595215\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528915; batch adversarial loss: 0.583859\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534137; batch adversarial loss: 0.575163\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511351; batch adversarial loss: 0.566894\n",
      "epoch 11; iter: 0; batch classifier loss: 0.487791; batch adversarial loss: 0.600026\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504730; batch adversarial loss: 0.559008\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515340; batch adversarial loss: 0.539810\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523304; batch adversarial loss: 0.615948\n",
      "epoch 15; iter: 0; batch classifier loss: 0.587016; batch adversarial loss: 0.667997\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531941; batch adversarial loss: 0.579149\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462156; batch adversarial loss: 0.571657\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526031; batch adversarial loss: 0.522844\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495916; batch adversarial loss: 0.555624\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470147; batch adversarial loss: 0.547896\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540308; batch adversarial loss: 0.524235\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489139; batch adversarial loss: 0.542463\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539067; batch adversarial loss: 0.554060\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465765; batch adversarial loss: 0.555728\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453669; batch adversarial loss: 0.540240\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522351; batch adversarial loss: 0.567466\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424963; batch adversarial loss: 0.522647\n",
      "epoch 28; iter: 0; batch classifier loss: 0.395548; batch adversarial loss: 0.577992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.478235; batch adversarial loss: 0.535496\n",
      "epoch 30; iter: 0; batch classifier loss: 0.539368; batch adversarial loss: 0.496758\n",
      "epoch 31; iter: 0; batch classifier loss: 0.377550; batch adversarial loss: 0.587398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.601053; batch adversarial loss: 0.597052\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455316; batch adversarial loss: 0.527700\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502408; batch adversarial loss: 0.475917\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421772; batch adversarial loss: 0.527605\n",
      "epoch 36; iter: 0; batch classifier loss: 0.399938; batch adversarial loss: 0.597056\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481736; batch adversarial loss: 0.580074\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419504; batch adversarial loss: 0.642292\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483632; batch adversarial loss: 0.589136\n",
      "epoch 40; iter: 0; batch classifier loss: 0.479056; batch adversarial loss: 0.491042\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458280; batch adversarial loss: 0.499562\n",
      "epoch 42; iter: 0; batch classifier loss: 0.487922; batch adversarial loss: 0.544391\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391923; batch adversarial loss: 0.608562\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481728; batch adversarial loss: 0.535603\n",
      "epoch 45; iter: 0; batch classifier loss: 0.361362; batch adversarial loss: 0.472403\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496165; batch adversarial loss: 0.535425\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412409; batch adversarial loss: 0.552905\n",
      "epoch 48; iter: 0; batch classifier loss: 0.462682; batch adversarial loss: 0.517336\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446700; batch adversarial loss: 0.608346\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406240; batch adversarial loss: 0.562875\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425272; batch adversarial loss: 0.563777\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418613; batch adversarial loss: 0.552576\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424249; batch adversarial loss: 0.544437\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412731; batch adversarial loss: 0.499833\n",
      "epoch 55; iter: 0; batch classifier loss: 0.365222; batch adversarial loss: 0.634445\n",
      "epoch 56; iter: 0; batch classifier loss: 0.479906; batch adversarial loss: 0.518185\n",
      "epoch 57; iter: 0; batch classifier loss: 0.433433; batch adversarial loss: 0.500000\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424219; batch adversarial loss: 0.553421\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433482; batch adversarial loss: 0.553354\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477047; batch adversarial loss: 0.578525\n",
      "epoch 61; iter: 0; batch classifier loss: 0.465763; batch adversarial loss: 0.528016\n",
      "epoch 62; iter: 0; batch classifier loss: 0.366095; batch adversarial loss: 0.535949\n",
      "epoch 63; iter: 0; batch classifier loss: 0.343404; batch adversarial loss: 0.563526\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408441; batch adversarial loss: 0.554192\n",
      "epoch 65; iter: 0; batch classifier loss: 0.311119; batch adversarial loss: 0.535500\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446712; batch adversarial loss: 0.499355\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385994; batch adversarial loss: 0.482804\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399642; batch adversarial loss: 0.496439\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384548; batch adversarial loss: 0.489893\n",
      "epoch 70; iter: 0; batch classifier loss: 0.495006; batch adversarial loss: 0.600379\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381747; batch adversarial loss: 0.601337\n",
      "epoch 72; iter: 0; batch classifier loss: 0.438467; batch adversarial loss: 0.529088\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376495; batch adversarial loss: 0.524929\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460873; batch adversarial loss: 0.581805\n",
      "epoch 75; iter: 0; batch classifier loss: 0.437124; batch adversarial loss: 0.598238\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378055; batch adversarial loss: 0.534370\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378017; batch adversarial loss: 0.526394\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387689; batch adversarial loss: 0.506063\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359698; batch adversarial loss: 0.579719\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460572; batch adversarial loss: 0.570085\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433253; batch adversarial loss: 0.543513\n",
      "epoch 82; iter: 0; batch classifier loss: 0.464320; batch adversarial loss: 0.546371\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409944; batch adversarial loss: 0.510633\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392059; batch adversarial loss: 0.508195\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378100; batch adversarial loss: 0.489870\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412361; batch adversarial loss: 0.534791\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372058; batch adversarial loss: 0.681157\n",
      "epoch 88; iter: 0; batch classifier loss: 0.410440; batch adversarial loss: 0.533040\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428789; batch adversarial loss: 0.577317\n",
      "epoch 90; iter: 0; batch classifier loss: 0.474154; batch adversarial loss: 0.553486\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362525; batch adversarial loss: 0.534383\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407354; batch adversarial loss: 0.589631\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420217; batch adversarial loss: 0.545896\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420770; batch adversarial loss: 0.571464\n",
      "epoch 95; iter: 0; batch classifier loss: 0.438969; batch adversarial loss: 0.490888\n",
      "epoch 96; iter: 0; batch classifier loss: 0.460917; batch adversarial loss: 0.535958\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456631; batch adversarial loss: 0.536432\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376084; batch adversarial loss: 0.509984\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456212; batch adversarial loss: 0.536284\n",
      "epoch 100; iter: 0; batch classifier loss: 0.414337; batch adversarial loss: 0.487795\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335243; batch adversarial loss: 0.589977\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426207; batch adversarial loss: 0.499232\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409479; batch adversarial loss: 0.516820\n",
      "epoch 104; iter: 0; batch classifier loss: 0.447584; batch adversarial loss: 0.607014\n",
      "epoch 105; iter: 0; batch classifier loss: 0.387335; batch adversarial loss: 0.552561\n",
      "epoch 106; iter: 0; batch classifier loss: 0.418270; batch adversarial loss: 0.573160\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354153; batch adversarial loss: 0.551112\n",
      "epoch 108; iter: 0; batch classifier loss: 0.428093; batch adversarial loss: 0.538051\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364367; batch adversarial loss: 0.564370\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439409; batch adversarial loss: 0.543307\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398167; batch adversarial loss: 0.481666\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371321; batch adversarial loss: 0.553493\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403907; batch adversarial loss: 0.498875\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408852; batch adversarial loss: 0.551957\n",
      "epoch 115; iter: 0; batch classifier loss: 0.338803; batch adversarial loss: 0.554079\n",
      "epoch 116; iter: 0; batch classifier loss: 0.442372; batch adversarial loss: 0.574685\n",
      "epoch 117; iter: 0; batch classifier loss: 0.427982; batch adversarial loss: 0.581397\n",
      "epoch 118; iter: 0; batch classifier loss: 0.458645; batch adversarial loss: 0.498776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.426172; batch adversarial loss: 0.597656\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360975; batch adversarial loss: 0.526480\n",
      "epoch 121; iter: 0; batch classifier loss: 0.363012; batch adversarial loss: 0.574685\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382289; batch adversarial loss: 0.552961\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415516; batch adversarial loss: 0.563351\n",
      "epoch 124; iter: 0; batch classifier loss: 0.430648; batch adversarial loss: 0.525063\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356003; batch adversarial loss: 0.489053\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422869; batch adversarial loss: 0.516058\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384660; batch adversarial loss: 0.562933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.377788; batch adversarial loss: 0.561322\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401456; batch adversarial loss: 0.554459\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352607; batch adversarial loss: 0.584269\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345851; batch adversarial loss: 0.545562\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389861; batch adversarial loss: 0.506649\n",
      "epoch 133; iter: 0; batch classifier loss: 0.373385; batch adversarial loss: 0.546600\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343841; batch adversarial loss: 0.627166\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347383; batch adversarial loss: 0.555958\n",
      "epoch 136; iter: 0; batch classifier loss: 0.310408; batch adversarial loss: 0.463177\n",
      "epoch 137; iter: 0; batch classifier loss: 0.444425; batch adversarial loss: 0.508174\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414549; batch adversarial loss: 0.525537\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360313; batch adversarial loss: 0.517518\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361922; batch adversarial loss: 0.563330\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391747; batch adversarial loss: 0.617287\n",
      "epoch 142; iter: 0; batch classifier loss: 0.272864; batch adversarial loss: 0.614561\n",
      "epoch 143; iter: 0; batch classifier loss: 0.461728; batch adversarial loss: 0.527360\n",
      "epoch 144; iter: 0; batch classifier loss: 0.402793; batch adversarial loss: 0.525517\n",
      "epoch 145; iter: 0; batch classifier loss: 0.438245; batch adversarial loss: 0.545633\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333280; batch adversarial loss: 0.564476\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358865; batch adversarial loss: 0.628924\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392616; batch adversarial loss: 0.591795\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418110; batch adversarial loss: 0.516311\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396446; batch adversarial loss: 0.561563\n",
      "epoch 151; iter: 0; batch classifier loss: 0.342008; batch adversarial loss: 0.489131\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348394; batch adversarial loss: 0.554313\n",
      "epoch 153; iter: 0; batch classifier loss: 0.359615; batch adversarial loss: 0.536121\n",
      "epoch 154; iter: 0; batch classifier loss: 0.269438; batch adversarial loss: 0.546677\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419348; batch adversarial loss: 0.523691\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373528; batch adversarial loss: 0.563373\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361225; batch adversarial loss: 0.592650\n",
      "epoch 158; iter: 0; batch classifier loss: 0.359725; batch adversarial loss: 0.457340\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311135; batch adversarial loss: 0.512972\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375659; batch adversarial loss: 0.508396\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362922; batch adversarial loss: 0.552943\n",
      "epoch 162; iter: 0; batch classifier loss: 0.280201; batch adversarial loss: 0.544907\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362457; batch adversarial loss: 0.560122\n",
      "epoch 164; iter: 0; batch classifier loss: 0.365719; batch adversarial loss: 0.506937\n",
      "epoch 165; iter: 0; batch classifier loss: 0.439034; batch adversarial loss: 0.649064\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357122; batch adversarial loss: 0.618270\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374993; batch adversarial loss: 0.654001\n",
      "epoch 168; iter: 0; batch classifier loss: 0.403462; batch adversarial loss: 0.497554\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405899; batch adversarial loss: 0.473565\n",
      "epoch 170; iter: 0; batch classifier loss: 0.431292; batch adversarial loss: 0.581586\n",
      "epoch 171; iter: 0; batch classifier loss: 0.314431; batch adversarial loss: 0.517127\n",
      "epoch 172; iter: 0; batch classifier loss: 0.415838; batch adversarial loss: 0.596731\n",
      "epoch 173; iter: 0; batch classifier loss: 0.417012; batch adversarial loss: 0.600500\n",
      "epoch 174; iter: 0; batch classifier loss: 0.479775; batch adversarial loss: 0.572377\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365254; batch adversarial loss: 0.525556\n",
      "epoch 176; iter: 0; batch classifier loss: 0.425281; batch adversarial loss: 0.598559\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381817; batch adversarial loss: 0.553425\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320259; batch adversarial loss: 0.441924\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369780; batch adversarial loss: 0.569456\n",
      "epoch 180; iter: 0; batch classifier loss: 0.330357; batch adversarial loss: 0.545488\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320820; batch adversarial loss: 0.542131\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339335; batch adversarial loss: 0.554501\n",
      "epoch 183; iter: 0; batch classifier loss: 0.419631; batch adversarial loss: 0.471586\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318733; batch adversarial loss: 0.542313\n",
      "epoch 185; iter: 0; batch classifier loss: 0.363953; batch adversarial loss: 0.613625\n",
      "epoch 186; iter: 0; batch classifier loss: 0.415606; batch adversarial loss: 0.454095\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340883; batch adversarial loss: 0.592379\n",
      "epoch 188; iter: 0; batch classifier loss: 0.297991; batch adversarial loss: 0.576834\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376203; batch adversarial loss: 0.507959\n",
      "epoch 190; iter: 0; batch classifier loss: 0.412712; batch adversarial loss: 0.592355\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322350; batch adversarial loss: 0.551972\n",
      "epoch 192; iter: 0; batch classifier loss: 0.454413; batch adversarial loss: 0.519468\n",
      "epoch 193; iter: 0; batch classifier loss: 0.369143; batch adversarial loss: 0.618092\n",
      "epoch 194; iter: 0; batch classifier loss: 0.471668; batch adversarial loss: 0.554354\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382280; batch adversarial loss: 0.616673\n",
      "epoch 196; iter: 0; batch classifier loss: 0.483952; batch adversarial loss: 0.494700\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337038; batch adversarial loss: 0.497093\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353023; batch adversarial loss: 0.572996\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388404; batch adversarial loss: 0.554973\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691502; batch adversarial loss: 0.660875\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537600; batch adversarial loss: 0.656856\n",
      "epoch 2; iter: 0; batch classifier loss: 0.529778; batch adversarial loss: 0.649667\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589628; batch adversarial loss: 0.636276\n",
      "epoch 4; iter: 0; batch classifier loss: 0.643036; batch adversarial loss: 0.599592\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576852; batch adversarial loss: 0.636006\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538755; batch adversarial loss: 0.627886\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537145; batch adversarial loss: 0.618562\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507137; batch adversarial loss: 0.597324\n",
      "epoch 9; iter: 0; batch classifier loss: 0.592522; batch adversarial loss: 0.566723\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540057; batch adversarial loss: 0.593710\n",
      "epoch 11; iter: 0; batch classifier loss: 0.485582; batch adversarial loss: 0.535779\n",
      "epoch 12; iter: 0; batch classifier loss: 0.594876; batch adversarial loss: 0.547644\n",
      "epoch 13; iter: 0; batch classifier loss: 0.589037; batch adversarial loss: 0.532868\n",
      "epoch 14; iter: 0; batch classifier loss: 0.580268; batch adversarial loss: 0.558634\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485042; batch adversarial loss: 0.547642\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497194; batch adversarial loss: 0.555013\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424888; batch adversarial loss: 0.568684\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513952; batch adversarial loss: 0.580883\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440207; batch adversarial loss: 0.561108\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507152; batch adversarial loss: 0.493238\n",
      "epoch 21; iter: 0; batch classifier loss: 0.570149; batch adversarial loss: 0.564100\n",
      "epoch 22; iter: 0; batch classifier loss: 0.537396; batch adversarial loss: 0.535040\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488304; batch adversarial loss: 0.624701\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492639; batch adversarial loss: 0.656641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.496523; batch adversarial loss: 0.626496\n",
      "epoch 26; iter: 0; batch classifier loss: 0.548616; batch adversarial loss: 0.515509\n",
      "epoch 27; iter: 0; batch classifier loss: 0.526915; batch adversarial loss: 0.554757\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506531; batch adversarial loss: 0.505605\n",
      "epoch 29; iter: 0; batch classifier loss: 0.409535; batch adversarial loss: 0.504811\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431430; batch adversarial loss: 0.570505\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489220; batch adversarial loss: 0.545948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452188; batch adversarial loss: 0.619610\n",
      "epoch 33; iter: 0; batch classifier loss: 0.382355; batch adversarial loss: 0.570388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452639; batch adversarial loss: 0.578403\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438607; batch adversarial loss: 0.561092\n",
      "epoch 36; iter: 0; batch classifier loss: 0.513402; batch adversarial loss: 0.561349\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495262; batch adversarial loss: 0.554839\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482028; batch adversarial loss: 0.554783\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447264; batch adversarial loss: 0.615009\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463874; batch adversarial loss: 0.596972\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454518; batch adversarial loss: 0.590083\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438615; batch adversarial loss: 0.577439\n",
      "epoch 43; iter: 0; batch classifier loss: 0.468925; batch adversarial loss: 0.616659\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462021; batch adversarial loss: 0.537372\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399491; batch adversarial loss: 0.564322\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436904; batch adversarial loss: 0.528077\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490097; batch adversarial loss: 0.597684\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452258; batch adversarial loss: 0.595590\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438456; batch adversarial loss: 0.544973\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465557; batch adversarial loss: 0.551685\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405732; batch adversarial loss: 0.624172\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464312; batch adversarial loss: 0.618103\n",
      "epoch 53; iter: 0; batch classifier loss: 0.347156; batch adversarial loss: 0.640976\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393955; batch adversarial loss: 0.582968\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423976; batch adversarial loss: 0.590812\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437003; batch adversarial loss: 0.569131\n",
      "epoch 57; iter: 0; batch classifier loss: 0.481621; batch adversarial loss: 0.533437\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466362; batch adversarial loss: 0.582692\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422776; batch adversarial loss: 0.539329\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443516; batch adversarial loss: 0.606097\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464305; batch adversarial loss: 0.595346\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370185; batch adversarial loss: 0.573083\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401946; batch adversarial loss: 0.584257\n",
      "epoch 64; iter: 0; batch classifier loss: 0.512058; batch adversarial loss: 0.506867\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450029; batch adversarial loss: 0.587547\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398057; batch adversarial loss: 0.573697\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413741; batch adversarial loss: 0.582067\n",
      "epoch 68; iter: 0; batch classifier loss: 0.449762; batch adversarial loss: 0.603286\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422646; batch adversarial loss: 0.625852\n",
      "epoch 70; iter: 0; batch classifier loss: 0.351724; batch adversarial loss: 0.530794\n",
      "epoch 71; iter: 0; batch classifier loss: 0.356329; batch adversarial loss: 0.553164\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393363; batch adversarial loss: 0.587073\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393925; batch adversarial loss: 0.580550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424828; batch adversarial loss: 0.596776\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435157; batch adversarial loss: 0.583097\n",
      "epoch 76; iter: 0; batch classifier loss: 0.467840; batch adversarial loss: 0.545124\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420478; batch adversarial loss: 0.616922\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386301; batch adversarial loss: 0.551390\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430590; batch adversarial loss: 0.562916\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376116; batch adversarial loss: 0.575693\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385068; batch adversarial loss: 0.551917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366702; batch adversarial loss: 0.620171\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377269; batch adversarial loss: 0.537677\n",
      "epoch 84; iter: 0; batch classifier loss: 0.420791; batch adversarial loss: 0.580835\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413225; batch adversarial loss: 0.528412\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386207; batch adversarial loss: 0.656126\n",
      "epoch 87; iter: 0; batch classifier loss: 0.408146; batch adversarial loss: 0.553125\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424179; batch adversarial loss: 0.562851\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409129; batch adversarial loss: 0.579116\n",
      "epoch 90; iter: 0; batch classifier loss: 0.437046; batch adversarial loss: 0.574820\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455235; batch adversarial loss: 0.552884\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404604; batch adversarial loss: 0.487590\n",
      "epoch 93; iter: 0; batch classifier loss: 0.445887; batch adversarial loss: 0.558179\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411341; batch adversarial loss: 0.508032\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408878; batch adversarial loss: 0.631168\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404750; batch adversarial loss: 0.536987\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359692; batch adversarial loss: 0.585729\n",
      "epoch 98; iter: 0; batch classifier loss: 0.457224; batch adversarial loss: 0.606815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.448182; batch adversarial loss: 0.560542\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351072; batch adversarial loss: 0.571349\n",
      "epoch 101; iter: 0; batch classifier loss: 0.436250; batch adversarial loss: 0.536108\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399486; batch adversarial loss: 0.532651\n",
      "epoch 103; iter: 0; batch classifier loss: 0.444130; batch adversarial loss: 0.535098\n",
      "epoch 104; iter: 0; batch classifier loss: 0.332898; batch adversarial loss: 0.539723\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343591; batch adversarial loss: 0.599037\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388908; batch adversarial loss: 0.528017\n",
      "epoch 107; iter: 0; batch classifier loss: 0.395497; batch adversarial loss: 0.586779\n",
      "epoch 108; iter: 0; batch classifier loss: 0.434748; batch adversarial loss: 0.544579\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372882; batch adversarial loss: 0.553543\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400676; batch adversarial loss: 0.613217\n",
      "epoch 111; iter: 0; batch classifier loss: 0.332857; batch adversarial loss: 0.604624\n",
      "epoch 112; iter: 0; batch classifier loss: 0.417234; batch adversarial loss: 0.550601\n",
      "epoch 113; iter: 0; batch classifier loss: 0.409453; batch adversarial loss: 0.534430\n",
      "epoch 114; iter: 0; batch classifier loss: 0.441225; batch adversarial loss: 0.624509\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382350; batch adversarial loss: 0.573651\n",
      "epoch 116; iter: 0; batch classifier loss: 0.463914; batch adversarial loss: 0.615644\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342708; batch adversarial loss: 0.598539\n",
      "epoch 118; iter: 0; batch classifier loss: 0.439283; batch adversarial loss: 0.623334\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383791; batch adversarial loss: 0.590685\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394169; batch adversarial loss: 0.588771\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370406; batch adversarial loss: 0.594807\n",
      "epoch 122; iter: 0; batch classifier loss: 0.299664; batch adversarial loss: 0.503109\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400295; batch adversarial loss: 0.582905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.426248; batch adversarial loss: 0.508859\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397131; batch adversarial loss: 0.532967\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399547; batch adversarial loss: 0.519000\n",
      "epoch 127; iter: 0; batch classifier loss: 0.418463; batch adversarial loss: 0.539089\n",
      "epoch 128; iter: 0; batch classifier loss: 0.447543; batch adversarial loss: 0.564759\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406488; batch adversarial loss: 0.503853\n",
      "epoch 130; iter: 0; batch classifier loss: 0.323634; batch adversarial loss: 0.492997\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387615; batch adversarial loss: 0.511790\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431533; batch adversarial loss: 0.522222\n",
      "epoch 133; iter: 0; batch classifier loss: 0.404606; batch adversarial loss: 0.604777\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349114; batch adversarial loss: 0.563069\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386238; batch adversarial loss: 0.562727\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348779; batch adversarial loss: 0.631182\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367122; batch adversarial loss: 0.600963\n",
      "epoch 138; iter: 0; batch classifier loss: 0.448964; batch adversarial loss: 0.569179\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341951; batch adversarial loss: 0.572900\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381773; batch adversarial loss: 0.551326\n",
      "epoch 141; iter: 0; batch classifier loss: 0.275837; batch adversarial loss: 0.517782\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412084; batch adversarial loss: 0.503439\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378774; batch adversarial loss: 0.496438\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341876; batch adversarial loss: 0.580636\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407474; batch adversarial loss: 0.564016\n",
      "epoch 146; iter: 0; batch classifier loss: 0.324410; batch adversarial loss: 0.559449\n",
      "epoch 147; iter: 0; batch classifier loss: 0.434052; batch adversarial loss: 0.539486\n",
      "epoch 148; iter: 0; batch classifier loss: 0.454601; batch adversarial loss: 0.518876\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375290; batch adversarial loss: 0.587706\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392525; batch adversarial loss: 0.509349\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330084; batch adversarial loss: 0.610936\n",
      "epoch 152; iter: 0; batch classifier loss: 0.402825; batch adversarial loss: 0.552939\n",
      "epoch 153; iter: 0; batch classifier loss: 0.419211; batch adversarial loss: 0.488066\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385414; batch adversarial loss: 0.543215\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374632; batch adversarial loss: 0.607924\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371200; batch adversarial loss: 0.565193\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375864; batch adversarial loss: 0.497890\n",
      "epoch 158; iter: 0; batch classifier loss: 0.439642; batch adversarial loss: 0.554970\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369513; batch adversarial loss: 0.543435\n",
      "epoch 160; iter: 0; batch classifier loss: 0.388139; batch adversarial loss: 0.514259\n",
      "epoch 161; iter: 0; batch classifier loss: 0.438204; batch adversarial loss: 0.546509\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369231; batch adversarial loss: 0.534705\n",
      "epoch 163; iter: 0; batch classifier loss: 0.261960; batch adversarial loss: 0.625195\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386607; batch adversarial loss: 0.489198\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392175; batch adversarial loss: 0.524879\n",
      "epoch 166; iter: 0; batch classifier loss: 0.337208; batch adversarial loss: 0.548569\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365192; batch adversarial loss: 0.539957\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322076; batch adversarial loss: 0.570399\n",
      "epoch 169; iter: 0; batch classifier loss: 0.430312; batch adversarial loss: 0.545622\n",
      "epoch 170; iter: 0; batch classifier loss: 0.452166; batch adversarial loss: 0.501990\n",
      "epoch 171; iter: 0; batch classifier loss: 0.345187; batch adversarial loss: 0.621164\n",
      "epoch 172; iter: 0; batch classifier loss: 0.347341; batch adversarial loss: 0.625431\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367793; batch adversarial loss: 0.527195\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393469; batch adversarial loss: 0.594301\n",
      "epoch 175; iter: 0; batch classifier loss: 0.403016; batch adversarial loss: 0.506595\n",
      "epoch 176; iter: 0; batch classifier loss: 0.391673; batch adversarial loss: 0.548414\n",
      "epoch 177; iter: 0; batch classifier loss: 0.401296; batch adversarial loss: 0.627264\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336282; batch adversarial loss: 0.553025\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349598; batch adversarial loss: 0.517990\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391921; batch adversarial loss: 0.525471\n",
      "epoch 181; iter: 0; batch classifier loss: 0.421713; batch adversarial loss: 0.656372\n",
      "epoch 182; iter: 0; batch classifier loss: 0.425525; batch adversarial loss: 0.558670\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366738; batch adversarial loss: 0.561056\n",
      "epoch 184; iter: 0; batch classifier loss: 0.271044; batch adversarial loss: 0.504928\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321091; batch adversarial loss: 0.585126\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390898; batch adversarial loss: 0.585486\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365922; batch adversarial loss: 0.543161\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391627; batch adversarial loss: 0.599494\n",
      "epoch 189; iter: 0; batch classifier loss: 0.400089; batch adversarial loss: 0.549895\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322837; batch adversarial loss: 0.518139\n",
      "epoch 191; iter: 0; batch classifier loss: 0.311980; batch adversarial loss: 0.573126\n",
      "epoch 192; iter: 0; batch classifier loss: 0.422601; batch adversarial loss: 0.617023\n",
      "epoch 193; iter: 0; batch classifier loss: 0.396367; batch adversarial loss: 0.457144\n",
      "epoch 194; iter: 0; batch classifier loss: 0.381545; batch adversarial loss: 0.584123\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387938; batch adversarial loss: 0.545693\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380698; batch adversarial loss: 0.595825\n",
      "epoch 197; iter: 0; batch classifier loss: 0.363016; batch adversarial loss: 0.532206\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375361; batch adversarial loss: 0.603330\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360175; batch adversarial loss: 0.582895\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690890; batch adversarial loss: 0.590333\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585409; batch adversarial loss: 0.617622\n",
      "epoch 2; iter: 0; batch classifier loss: 0.660948; batch adversarial loss: 0.647858\n",
      "epoch 3; iter: 0; batch classifier loss: 0.545094; batch adversarial loss: 0.663182\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590007; batch adversarial loss: 0.631738\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574325; batch adversarial loss: 0.655864\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525341; batch adversarial loss: 0.635318\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553385; batch adversarial loss: 0.619191\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528068; batch adversarial loss: 0.558218\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505171; batch adversarial loss: 0.578483\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535163; batch adversarial loss: 0.530429\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586326; batch adversarial loss: 0.611893\n",
      "epoch 12; iter: 0; batch classifier loss: 0.642542; batch adversarial loss: 0.561831\n",
      "epoch 13; iter: 0; batch classifier loss: 0.561724; batch adversarial loss: 0.557041\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547836; batch adversarial loss: 0.536085\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463690; batch adversarial loss: 0.534944\n",
      "epoch 16; iter: 0; batch classifier loss: 0.568493; batch adversarial loss: 0.577746\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507573; batch adversarial loss: 0.559553\n",
      "epoch 18; iter: 0; batch classifier loss: 0.566021; batch adversarial loss: 0.506221\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472135; batch adversarial loss: 0.633164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.465015; batch adversarial loss: 0.498723\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521036; batch adversarial loss: 0.562770\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507399; batch adversarial loss: 0.540577\n",
      "epoch 23; iter: 0; batch classifier loss: 0.408675; batch adversarial loss: 0.564017\n",
      "epoch 24; iter: 0; batch classifier loss: 0.529436; batch adversarial loss: 0.556195\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442746; batch adversarial loss: 0.555204\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500809; batch adversarial loss: 0.529120\n",
      "epoch 27; iter: 0; batch classifier loss: 0.585083; batch adversarial loss: 0.553921\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495379; batch adversarial loss: 0.526806\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448214; batch adversarial loss: 0.580064\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490270; batch adversarial loss: 0.624852\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443434; batch adversarial loss: 0.490378\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403908; batch adversarial loss: 0.589545\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492835; batch adversarial loss: 0.526523\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441674; batch adversarial loss: 0.607991\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445710; batch adversarial loss: 0.554341\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445744; batch adversarial loss: 0.469368\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386104; batch adversarial loss: 0.551878\n",
      "epoch 38; iter: 0; batch classifier loss: 0.490099; batch adversarial loss: 0.458689\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445415; batch adversarial loss: 0.611384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495467; batch adversarial loss: 0.572078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438951; batch adversarial loss: 0.582411\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463334; batch adversarial loss: 0.515093\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496112; batch adversarial loss: 0.513313\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504766; batch adversarial loss: 0.535325\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461062; batch adversarial loss: 0.592828\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377119; batch adversarial loss: 0.477214\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444970; batch adversarial loss: 0.561689\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387035; batch adversarial loss: 0.645014\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439838; batch adversarial loss: 0.561826\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395049; batch adversarial loss: 0.592433\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454123; batch adversarial loss: 0.560761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437408; batch adversarial loss: 0.578141\n",
      "epoch 53; iter: 0; batch classifier loss: 0.459178; batch adversarial loss: 0.533432\n",
      "epoch 54; iter: 0; batch classifier loss: 0.374294; batch adversarial loss: 0.567488\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419329; batch adversarial loss: 0.535284\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394032; batch adversarial loss: 0.582955\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472389; batch adversarial loss: 0.533502\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409138; batch adversarial loss: 0.485972\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467281; batch adversarial loss: 0.596936\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388477; batch adversarial loss: 0.563273\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445393; batch adversarial loss: 0.586950\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368171; batch adversarial loss: 0.536006\n",
      "epoch 63; iter: 0; batch classifier loss: 0.456878; batch adversarial loss: 0.556153\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377401; batch adversarial loss: 0.541919\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433528; batch adversarial loss: 0.578612\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407329; batch adversarial loss: 0.535617\n",
      "epoch 67; iter: 0; batch classifier loss: 0.345156; batch adversarial loss: 0.491008\n",
      "epoch 68; iter: 0; batch classifier loss: 0.452576; batch adversarial loss: 0.506392\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360780; batch adversarial loss: 0.581817\n",
      "epoch 70; iter: 0; batch classifier loss: 0.333428; batch adversarial loss: 0.561399\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387494; batch adversarial loss: 0.506477\n",
      "epoch 72; iter: 0; batch classifier loss: 0.479684; batch adversarial loss: 0.528688\n",
      "epoch 73; iter: 0; batch classifier loss: 0.490544; batch adversarial loss: 0.568040\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392093; batch adversarial loss: 0.548600\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397566; batch adversarial loss: 0.519347\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421213; batch adversarial loss: 0.489259\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422592; batch adversarial loss: 0.543708\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467484; batch adversarial loss: 0.560677\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370114; batch adversarial loss: 0.431232\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395627; batch adversarial loss: 0.556203\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381243; batch adversarial loss: 0.511171\n",
      "epoch 82; iter: 0; batch classifier loss: 0.467314; batch adversarial loss: 0.494527\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434556; batch adversarial loss: 0.588214\n",
      "epoch 84; iter: 0; batch classifier loss: 0.414432; batch adversarial loss: 0.562430\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397438; batch adversarial loss: 0.507425\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435099; batch adversarial loss: 0.554845\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428380; batch adversarial loss: 0.504137\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408709; batch adversarial loss: 0.471512\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404489; batch adversarial loss: 0.487784\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391763; batch adversarial loss: 0.466994\n",
      "epoch 91; iter: 0; batch classifier loss: 0.329015; batch adversarial loss: 0.573470\n",
      "epoch 92; iter: 0; batch classifier loss: 0.336237; batch adversarial loss: 0.506574\n",
      "epoch 93; iter: 0; batch classifier loss: 0.477636; batch adversarial loss: 0.547489\n",
      "epoch 94; iter: 0; batch classifier loss: 0.301773; batch adversarial loss: 0.471702\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378914; batch adversarial loss: 0.545230\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355811; batch adversarial loss: 0.589567\n",
      "epoch 97; iter: 0; batch classifier loss: 0.406650; batch adversarial loss: 0.504124\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364977; batch adversarial loss: 0.472407\n",
      "epoch 99; iter: 0; batch classifier loss: 0.466735; batch adversarial loss: 0.533397\n",
      "epoch 100; iter: 0; batch classifier loss: 0.456875; batch adversarial loss: 0.478840\n",
      "epoch 101; iter: 0; batch classifier loss: 0.493613; batch adversarial loss: 0.561140\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397534; batch adversarial loss: 0.547069\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391633; batch adversarial loss: 0.574373\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434897; batch adversarial loss: 0.468172\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331533; batch adversarial loss: 0.564917\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355360; batch adversarial loss: 0.559781\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371327; batch adversarial loss: 0.532479\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375139; batch adversarial loss: 0.600903\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375166; batch adversarial loss: 0.489646\n",
      "epoch 110; iter: 0; batch classifier loss: 0.460542; batch adversarial loss: 0.526368\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418950; batch adversarial loss: 0.568206\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402085; batch adversarial loss: 0.481800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.331146; batch adversarial loss: 0.517862\n",
      "epoch 114; iter: 0; batch classifier loss: 0.413381; batch adversarial loss: 0.519493\n",
      "epoch 115; iter: 0; batch classifier loss: 0.450943; batch adversarial loss: 0.484877\n",
      "epoch 116; iter: 0; batch classifier loss: 0.431571; batch adversarial loss: 0.491994\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386497; batch adversarial loss: 0.541668\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427471; batch adversarial loss: 0.525800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.409514; batch adversarial loss: 0.572146\n",
      "epoch 120; iter: 0; batch classifier loss: 0.326112; batch adversarial loss: 0.580147\n",
      "epoch 121; iter: 0; batch classifier loss: 0.444356; batch adversarial loss: 0.565741\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353704; batch adversarial loss: 0.513801\n",
      "epoch 123; iter: 0; batch classifier loss: 0.391231; batch adversarial loss: 0.550031\n",
      "epoch 124; iter: 0; batch classifier loss: 0.305139; batch adversarial loss: 0.575622\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373082; batch adversarial loss: 0.572295\n",
      "epoch 126; iter: 0; batch classifier loss: 0.307603; batch adversarial loss: 0.627253\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405226; batch adversarial loss: 0.473933\n",
      "epoch 128; iter: 0; batch classifier loss: 0.408205; batch adversarial loss: 0.411969\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394177; batch adversarial loss: 0.523830\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398097; batch adversarial loss: 0.448472\n",
      "epoch 131; iter: 0; batch classifier loss: 0.437092; batch adversarial loss: 0.523668\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390042; batch adversarial loss: 0.526669\n",
      "epoch 133; iter: 0; batch classifier loss: 0.313546; batch adversarial loss: 0.496884\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375652; batch adversarial loss: 0.536438\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376479; batch adversarial loss: 0.551667\n",
      "epoch 136; iter: 0; batch classifier loss: 0.278894; batch adversarial loss: 0.555885\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348831; batch adversarial loss: 0.595996\n",
      "epoch 138; iter: 0; batch classifier loss: 0.361733; batch adversarial loss: 0.562551\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386548; batch adversarial loss: 0.542339\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395351; batch adversarial loss: 0.474559\n",
      "epoch 141; iter: 0; batch classifier loss: 0.454150; batch adversarial loss: 0.574716\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345380; batch adversarial loss: 0.481601\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375246; batch adversarial loss: 0.532617\n",
      "epoch 144; iter: 0; batch classifier loss: 0.446073; batch adversarial loss: 0.527722\n",
      "epoch 145; iter: 0; batch classifier loss: 0.463111; batch adversarial loss: 0.574441\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373917; batch adversarial loss: 0.565536\n",
      "epoch 147; iter: 0; batch classifier loss: 0.271822; batch adversarial loss: 0.540102\n",
      "epoch 148; iter: 0; batch classifier loss: 0.314375; batch adversarial loss: 0.554449\n",
      "epoch 149; iter: 0; batch classifier loss: 0.420033; batch adversarial loss: 0.479067\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394092; batch adversarial loss: 0.491521\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375256; batch adversarial loss: 0.560293\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332522; batch adversarial loss: 0.606013\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380256; batch adversarial loss: 0.505318\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375553; batch adversarial loss: 0.562978\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366561; batch adversarial loss: 0.616469\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373751; batch adversarial loss: 0.430484\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383473; batch adversarial loss: 0.519430\n",
      "epoch 158; iter: 0; batch classifier loss: 0.443602; batch adversarial loss: 0.575917\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351439; batch adversarial loss: 0.577587\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350030; batch adversarial loss: 0.565918\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391969; batch adversarial loss: 0.553258\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360945; batch adversarial loss: 0.575684\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400368; batch adversarial loss: 0.450080\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400388; batch adversarial loss: 0.618558\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359686; batch adversarial loss: 0.412752\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323964; batch adversarial loss: 0.623525\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393124; batch adversarial loss: 0.523224\n",
      "epoch 168; iter: 0; batch classifier loss: 0.328629; batch adversarial loss: 0.615857\n",
      "epoch 169; iter: 0; batch classifier loss: 0.308988; batch adversarial loss: 0.555290\n",
      "epoch 170; iter: 0; batch classifier loss: 0.414467; batch adversarial loss: 0.573670\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367763; batch adversarial loss: 0.534865\n",
      "epoch 172; iter: 0; batch classifier loss: 0.374061; batch adversarial loss: 0.537326\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360637; batch adversarial loss: 0.526749\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358932; batch adversarial loss: 0.553644\n",
      "epoch 175; iter: 0; batch classifier loss: 0.415586; batch adversarial loss: 0.511668\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362931; batch adversarial loss: 0.499341\n",
      "epoch 177; iter: 0; batch classifier loss: 0.413769; batch adversarial loss: 0.503685\n",
      "epoch 178; iter: 0; batch classifier loss: 0.445878; batch adversarial loss: 0.512570\n",
      "epoch 179; iter: 0; batch classifier loss: 0.434284; batch adversarial loss: 0.504492\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315501; batch adversarial loss: 0.516667\n",
      "epoch 181; iter: 0; batch classifier loss: 0.351560; batch adversarial loss: 0.534035\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390539; batch adversarial loss: 0.478826\n",
      "epoch 183; iter: 0; batch classifier loss: 0.454000; batch adversarial loss: 0.524238\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319650; batch adversarial loss: 0.497343\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364043; batch adversarial loss: 0.512356\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348958; batch adversarial loss: 0.603527\n",
      "epoch 187; iter: 0; batch classifier loss: 0.426771; batch adversarial loss: 0.557892\n",
      "epoch 188; iter: 0; batch classifier loss: 0.331841; batch adversarial loss: 0.536086\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361840; batch adversarial loss: 0.620436\n",
      "epoch 190; iter: 0; batch classifier loss: 0.399504; batch adversarial loss: 0.513414\n",
      "epoch 191; iter: 0; batch classifier loss: 0.327213; batch adversarial loss: 0.515701\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332158; batch adversarial loss: 0.578276\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344617; batch adversarial loss: 0.513417\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379372; batch adversarial loss: 0.515491\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374344; batch adversarial loss: 0.498795\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373244; batch adversarial loss: 0.521758\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405182; batch adversarial loss: 0.562787\n",
      "epoch 198; iter: 0; batch classifier loss: 0.337836; batch adversarial loss: 0.491671\n",
      "epoch 199; iter: 0; batch classifier loss: 0.421566; batch adversarial loss: 0.566058\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666457; batch adversarial loss: 0.765118\n",
      "epoch 1; iter: 0; batch classifier loss: 0.793904; batch adversarial loss: 0.862830\n",
      "epoch 2; iter: 0; batch classifier loss: 0.871391; batch adversarial loss: 0.796883\n",
      "epoch 3; iter: 0; batch classifier loss: 0.896108; batch adversarial loss: 0.730899\n",
      "epoch 4; iter: 0; batch classifier loss: 0.818483; batch adversarial loss: 0.664034\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633376; batch adversarial loss: 0.630337\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527753; batch adversarial loss: 0.599355\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548402; batch adversarial loss: 0.580387\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521126; batch adversarial loss: 0.593501\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567280; batch adversarial loss: 0.582346\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587305; batch adversarial loss: 0.610352\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577769; batch adversarial loss: 0.555696\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517910; batch adversarial loss: 0.556038\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504358; batch adversarial loss: 0.638293\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509413; batch adversarial loss: 0.604994\n",
      "epoch 15; iter: 0; batch classifier loss: 0.461804; batch adversarial loss: 0.596456\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528319; batch adversarial loss: 0.515877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.583502; batch adversarial loss: 0.632342\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485619; batch adversarial loss: 0.594594\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515622; batch adversarial loss: 0.637545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471574; batch adversarial loss: 0.578921\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509310; batch adversarial loss: 0.624382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481211; batch adversarial loss: 0.540040\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485557; batch adversarial loss: 0.583781\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531487; batch adversarial loss: 0.582401\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493925; batch adversarial loss: 0.521101\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516866; batch adversarial loss: 0.520165\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458581; batch adversarial loss: 0.475458\n",
      "epoch 28; iter: 0; batch classifier loss: 0.426242; batch adversarial loss: 0.595529\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432774; batch adversarial loss: 0.604465\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481799; batch adversarial loss: 0.560368\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496415; batch adversarial loss: 0.548202\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436093; batch adversarial loss: 0.504479\n",
      "epoch 33; iter: 0; batch classifier loss: 0.385830; batch adversarial loss: 0.538508\n",
      "epoch 34; iter: 0; batch classifier loss: 0.529951; batch adversarial loss: 0.578116\n",
      "epoch 35; iter: 0; batch classifier loss: 0.387028; batch adversarial loss: 0.545979\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427380; batch adversarial loss: 0.546210\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476368; batch adversarial loss: 0.621859\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428699; batch adversarial loss: 0.587968\n",
      "epoch 39; iter: 0; batch classifier loss: 0.522534; batch adversarial loss: 0.571059\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487332; batch adversarial loss: 0.563522\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488095; batch adversarial loss: 0.485369\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450268; batch adversarial loss: 0.562870\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375562; batch adversarial loss: 0.527761\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383642; batch adversarial loss: 0.536729\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520991; batch adversarial loss: 0.518845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459581; batch adversarial loss: 0.579946\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439097; batch adversarial loss: 0.640195\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451376; batch adversarial loss: 0.554803\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445234; batch adversarial loss: 0.562251\n",
      "epoch 50; iter: 0; batch classifier loss: 0.425487; batch adversarial loss: 0.572360\n",
      "epoch 51; iter: 0; batch classifier loss: 0.386922; batch adversarial loss: 0.509995\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390323; batch adversarial loss: 0.588776\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445169; batch adversarial loss: 0.562538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454170; batch adversarial loss: 0.536229\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458660; batch adversarial loss: 0.483440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.376288; batch adversarial loss: 0.482246\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393445; batch adversarial loss: 0.535735\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386773; batch adversarial loss: 0.607116\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420063; batch adversarial loss: 0.494033\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407140; batch adversarial loss: 0.572094\n",
      "epoch 61; iter: 0; batch classifier loss: 0.370695; batch adversarial loss: 0.559391\n",
      "epoch 62; iter: 0; batch classifier loss: 0.371192; batch adversarial loss: 0.606267\n",
      "epoch 63; iter: 0; batch classifier loss: 0.347840; batch adversarial loss: 0.640956\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437094; batch adversarial loss: 0.493596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450017; batch adversarial loss: 0.499094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.455984; batch adversarial loss: 0.570168\n",
      "epoch 67; iter: 0; batch classifier loss: 0.322042; batch adversarial loss: 0.502635\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423398; batch adversarial loss: 0.544770\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400137; batch adversarial loss: 0.509855\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386757; batch adversarial loss: 0.579808\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372689; batch adversarial loss: 0.559708\n",
      "epoch 72; iter: 0; batch classifier loss: 0.423736; batch adversarial loss: 0.516540\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358458; batch adversarial loss: 0.643296\n",
      "epoch 74; iter: 0; batch classifier loss: 0.319715; batch adversarial loss: 0.570556\n",
      "epoch 75; iter: 0; batch classifier loss: 0.347057; batch adversarial loss: 0.534927\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419756; batch adversarial loss: 0.623058\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378842; batch adversarial loss: 0.500839\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457113; batch adversarial loss: 0.569292\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391429; batch adversarial loss: 0.581899\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358365; batch adversarial loss: 0.581358\n",
      "epoch 81; iter: 0; batch classifier loss: 0.306237; batch adversarial loss: 0.624384\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409607; batch adversarial loss: 0.543020\n",
      "epoch 83; iter: 0; batch classifier loss: 0.348153; batch adversarial loss: 0.635666\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408514; batch adversarial loss: 0.574779\n",
      "epoch 85; iter: 0; batch classifier loss: 0.421746; batch adversarial loss: 0.608348\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471877; batch adversarial loss: 0.517195\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389163; batch adversarial loss: 0.564516\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420413; batch adversarial loss: 0.515457\n",
      "epoch 89; iter: 0; batch classifier loss: 0.457154; batch adversarial loss: 0.463187\n",
      "epoch 90; iter: 0; batch classifier loss: 0.502539; batch adversarial loss: 0.554483\n",
      "epoch 91; iter: 0; batch classifier loss: 0.326616; batch adversarial loss: 0.641950\n",
      "epoch 92; iter: 0; batch classifier loss: 0.321935; batch adversarial loss: 0.441993\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420939; batch adversarial loss: 0.581734\n",
      "epoch 94; iter: 0; batch classifier loss: 0.403415; batch adversarial loss: 0.517126\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364644; batch adversarial loss: 0.516745\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416363; batch adversarial loss: 0.529335\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364472; batch adversarial loss: 0.481148\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388042; batch adversarial loss: 0.544581\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398195; batch adversarial loss: 0.598636\n",
      "epoch 100; iter: 0; batch classifier loss: 0.451376; batch adversarial loss: 0.658207\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434950; batch adversarial loss: 0.563059\n",
      "epoch 102; iter: 0; batch classifier loss: 0.315859; batch adversarial loss: 0.587984\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429377; batch adversarial loss: 0.585282\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374903; batch adversarial loss: 0.587571\n",
      "epoch 105; iter: 0; batch classifier loss: 0.333426; batch adversarial loss: 0.535329\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393510; batch adversarial loss: 0.562676\n",
      "epoch 107; iter: 0; batch classifier loss: 0.324927; batch adversarial loss: 0.633291\n",
      "epoch 108; iter: 0; batch classifier loss: 0.471045; batch adversarial loss: 0.601013\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383729; batch adversarial loss: 0.527358\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373469; batch adversarial loss: 0.618829\n",
      "epoch 111; iter: 0; batch classifier loss: 0.493396; batch adversarial loss: 0.543806\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355549; batch adversarial loss: 0.480973\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340822; batch adversarial loss: 0.554883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.358562; batch adversarial loss: 0.554147\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372541; batch adversarial loss: 0.550804\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372973; batch adversarial loss: 0.644600\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363592; batch adversarial loss: 0.440300\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356512; batch adversarial loss: 0.546392\n",
      "epoch 119; iter: 0; batch classifier loss: 0.310163; batch adversarial loss: 0.456046\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361906; batch adversarial loss: 0.544000\n",
      "epoch 121; iter: 0; batch classifier loss: 0.305024; batch adversarial loss: 0.510240\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377095; batch adversarial loss: 0.542715\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408129; batch adversarial loss: 0.576727\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370716; batch adversarial loss: 0.601495\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326543; batch adversarial loss: 0.534932\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376987; batch adversarial loss: 0.571822\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341896; batch adversarial loss: 0.571532\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313920; batch adversarial loss: 0.569904\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397388; batch adversarial loss: 0.499210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.335987; batch adversarial loss: 0.538319\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359516; batch adversarial loss: 0.457281\n",
      "epoch 132; iter: 0; batch classifier loss: 0.356817; batch adversarial loss: 0.598828\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377546; batch adversarial loss: 0.536615\n",
      "epoch 134; iter: 0; batch classifier loss: 0.304369; batch adversarial loss: 0.504016\n",
      "epoch 135; iter: 0; batch classifier loss: 0.440674; batch adversarial loss: 0.542183\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404318; batch adversarial loss: 0.535112\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386849; batch adversarial loss: 0.569621\n",
      "epoch 138; iter: 0; batch classifier loss: 0.324984; batch adversarial loss: 0.527771\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402746; batch adversarial loss: 0.511499\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374319; batch adversarial loss: 0.593209\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328800; batch adversarial loss: 0.535016\n",
      "epoch 142; iter: 0; batch classifier loss: 0.329867; batch adversarial loss: 0.635626\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369014; batch adversarial loss: 0.501237\n",
      "epoch 144; iter: 0; batch classifier loss: 0.353768; batch adversarial loss: 0.516796\n",
      "epoch 145; iter: 0; batch classifier loss: 0.386683; batch adversarial loss: 0.514026\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339130; batch adversarial loss: 0.524843\n",
      "epoch 147; iter: 0; batch classifier loss: 0.405101; batch adversarial loss: 0.549701\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380373; batch adversarial loss: 0.598136\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345696; batch adversarial loss: 0.519419\n",
      "epoch 150; iter: 0; batch classifier loss: 0.374772; batch adversarial loss: 0.626985\n",
      "epoch 151; iter: 0; batch classifier loss: 0.296166; batch adversarial loss: 0.582665\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384517; batch adversarial loss: 0.573151\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381486; batch adversarial loss: 0.558598\n",
      "epoch 154; iter: 0; batch classifier loss: 0.307799; batch adversarial loss: 0.567745\n",
      "epoch 155; iter: 0; batch classifier loss: 0.288165; batch adversarial loss: 0.563614\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334690; batch adversarial loss: 0.525147\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341040; batch adversarial loss: 0.579287\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330258; batch adversarial loss: 0.559647\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353463; batch adversarial loss: 0.535667\n",
      "epoch 160; iter: 0; batch classifier loss: 0.392893; batch adversarial loss: 0.480508\n",
      "epoch 161; iter: 0; batch classifier loss: 0.425504; batch adversarial loss: 0.591502\n",
      "epoch 162; iter: 0; batch classifier loss: 0.335621; batch adversarial loss: 0.532952\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380538; batch adversarial loss: 0.582475\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333349; batch adversarial loss: 0.458429\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371653; batch adversarial loss: 0.589954\n",
      "epoch 166; iter: 0; batch classifier loss: 0.304987; batch adversarial loss: 0.595580\n",
      "epoch 167; iter: 0; batch classifier loss: 0.412348; batch adversarial loss: 0.516229\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317883; batch adversarial loss: 0.552291\n",
      "epoch 169; iter: 0; batch classifier loss: 0.410637; batch adversarial loss: 0.561202\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345185; batch adversarial loss: 0.538406\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340714; batch adversarial loss: 0.583825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.414433; batch adversarial loss: 0.575841\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362316; batch adversarial loss: 0.516914\n",
      "epoch 174; iter: 0; batch classifier loss: 0.314934; batch adversarial loss: 0.554236\n",
      "epoch 175; iter: 0; batch classifier loss: 0.429162; batch adversarial loss: 0.552727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.311881; batch adversarial loss: 0.563525\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291648; batch adversarial loss: 0.572183\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342961; batch adversarial loss: 0.537186\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341788; batch adversarial loss: 0.558049\n",
      "epoch 180; iter: 0; batch classifier loss: 0.317967; batch adversarial loss: 0.551415\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374494; batch adversarial loss: 0.589346\n",
      "epoch 182; iter: 0; batch classifier loss: 0.384524; batch adversarial loss: 0.629728\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373667; batch adversarial loss: 0.442757\n",
      "epoch 184; iter: 0; batch classifier loss: 0.271755; batch adversarial loss: 0.543081\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326914; batch adversarial loss: 0.536083\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367944; batch adversarial loss: 0.576160\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355861; batch adversarial loss: 0.502447\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336370; batch adversarial loss: 0.488308\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297144; batch adversarial loss: 0.566601\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323776; batch adversarial loss: 0.477945\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358718; batch adversarial loss: 0.613772\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403930; batch adversarial loss: 0.575252\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392877; batch adversarial loss: 0.592768\n",
      "epoch 194; iter: 0; batch classifier loss: 0.291045; batch adversarial loss: 0.559138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353909; batch adversarial loss: 0.614643\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362825; batch adversarial loss: 0.587956\n",
      "epoch 197; iter: 0; batch classifier loss: 0.294270; batch adversarial loss: 0.588015\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335013; batch adversarial loss: 0.572284\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353743; batch adversarial loss: 0.567766\n",
      "epoch 0; iter: 0; batch classifier loss: 0.656303; batch adversarial loss: 0.823151\n",
      "epoch 1; iter: 0; batch classifier loss: 0.775685; batch adversarial loss: 0.947995\n",
      "epoch 2; iter: 0; batch classifier loss: 0.765525; batch adversarial loss: 0.930873\n",
      "epoch 3; iter: 0; batch classifier loss: 0.838541; batch adversarial loss: 0.815874\n",
      "epoch 4; iter: 0; batch classifier loss: 0.725136; batch adversarial loss: 0.776966\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597359; batch adversarial loss: 0.682912\n",
      "epoch 6; iter: 0; batch classifier loss: 0.629790; batch adversarial loss: 0.646798\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513241; batch adversarial loss: 0.629910\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553340; batch adversarial loss: 0.630974\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518307; batch adversarial loss: 0.577903\n",
      "epoch 10; iter: 0; batch classifier loss: 0.483258; batch adversarial loss: 0.609934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.525950; batch adversarial loss: 0.577697\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552258; batch adversarial loss: 0.581475\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543304; batch adversarial loss: 0.545983\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430144; batch adversarial loss: 0.609131\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525834; batch adversarial loss: 0.563939\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503326; batch adversarial loss: 0.574862\n",
      "epoch 17; iter: 0; batch classifier loss: 0.573909; batch adversarial loss: 0.546194\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493511; batch adversarial loss: 0.563485\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496182; batch adversarial loss: 0.560552\n",
      "epoch 20; iter: 0; batch classifier loss: 0.467487; batch adversarial loss: 0.492429\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540686; batch adversarial loss: 0.593561\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458373; batch adversarial loss: 0.573926\n",
      "epoch 23; iter: 0; batch classifier loss: 0.557945; batch adversarial loss: 0.578711\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455676; batch adversarial loss: 0.578728\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483301; batch adversarial loss: 0.483830\n",
      "epoch 26; iter: 0; batch classifier loss: 0.550564; batch adversarial loss: 0.547065\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450296; batch adversarial loss: 0.545464\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529732; batch adversarial loss: 0.546128\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454820; batch adversarial loss: 0.573547\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444757; batch adversarial loss: 0.611306\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490419; batch adversarial loss: 0.575066\n",
      "epoch 32; iter: 0; batch classifier loss: 0.585267; batch adversarial loss: 0.535523\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476291; batch adversarial loss: 0.606040\n",
      "epoch 34; iter: 0; batch classifier loss: 0.513618; batch adversarial loss: 0.598486\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423370; batch adversarial loss: 0.546782\n",
      "epoch 36; iter: 0; batch classifier loss: 0.525712; batch adversarial loss: 0.556529\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442560; batch adversarial loss: 0.582461\n",
      "epoch 38; iter: 0; batch classifier loss: 0.421758; batch adversarial loss: 0.563718\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411743; batch adversarial loss: 0.588183\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465108; batch adversarial loss: 0.520020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.490151; batch adversarial loss: 0.457402\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403098; batch adversarial loss: 0.616148\n",
      "epoch 43; iter: 0; batch classifier loss: 0.405739; batch adversarial loss: 0.543954\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467207; batch adversarial loss: 0.536536\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420609; batch adversarial loss: 0.570863\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408162; batch adversarial loss: 0.562327\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451059; batch adversarial loss: 0.651001\n",
      "epoch 48; iter: 0; batch classifier loss: 0.358329; batch adversarial loss: 0.545034\n",
      "epoch 49; iter: 0; batch classifier loss: 0.490424; batch adversarial loss: 0.554507\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424251; batch adversarial loss: 0.562754\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430067; batch adversarial loss: 0.500836\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428826; batch adversarial loss: 0.581099\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429690; batch adversarial loss: 0.544536\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464840; batch adversarial loss: 0.607085\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432582; batch adversarial loss: 0.553608\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429821; batch adversarial loss: 0.571799\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391067; batch adversarial loss: 0.508590\n",
      "epoch 58; iter: 0; batch classifier loss: 0.531821; batch adversarial loss: 0.571898\n",
      "epoch 59; iter: 0; batch classifier loss: 0.475281; batch adversarial loss: 0.490078\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414265; batch adversarial loss: 0.517124\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467275; batch adversarial loss: 0.481406\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422706; batch adversarial loss: 0.536067\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371313; batch adversarial loss: 0.535687\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410799; batch adversarial loss: 0.590076\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369020; batch adversarial loss: 0.553489\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417670; batch adversarial loss: 0.490178\n",
      "epoch 67; iter: 0; batch classifier loss: 0.448883; batch adversarial loss: 0.499314\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380479; batch adversarial loss: 0.571718\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402494; batch adversarial loss: 0.535431\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359023; batch adversarial loss: 0.589800\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412347; batch adversarial loss: 0.581053\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430652; batch adversarial loss: 0.580751\n",
      "epoch 73; iter: 0; batch classifier loss: 0.464565; batch adversarial loss: 0.544600\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378505; batch adversarial loss: 0.553597\n",
      "epoch 75; iter: 0; batch classifier loss: 0.473958; batch adversarial loss: 0.490386\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440708; batch adversarial loss: 0.526587\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362643; batch adversarial loss: 0.544538\n",
      "epoch 78; iter: 0; batch classifier loss: 0.336958; batch adversarial loss: 0.525837\n",
      "epoch 79; iter: 0; batch classifier loss: 0.361569; batch adversarial loss: 0.581155\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398102; batch adversarial loss: 0.518154\n",
      "epoch 81; iter: 0; batch classifier loss: 0.464259; batch adversarial loss: 0.571475\n",
      "epoch 82; iter: 0; batch classifier loss: 0.491307; batch adversarial loss: 0.491033\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401187; batch adversarial loss: 0.589294\n",
      "epoch 84; iter: 0; batch classifier loss: 0.425976; batch adversarial loss: 0.598684\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378965; batch adversarial loss: 0.527312\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401743; batch adversarial loss: 0.454212\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421365; batch adversarial loss: 0.499995\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425706; batch adversarial loss: 0.544017\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402884; batch adversarial loss: 0.545265\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404644; batch adversarial loss: 0.410028\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414008; batch adversarial loss: 0.472833\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419443; batch adversarial loss: 0.590083\n",
      "epoch 93; iter: 0; batch classifier loss: 0.435593; batch adversarial loss: 0.544157\n",
      "epoch 94; iter: 0; batch classifier loss: 0.455400; batch adversarial loss: 0.455151\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412956; batch adversarial loss: 0.565780\n",
      "epoch 96; iter: 0; batch classifier loss: 0.461375; batch adversarial loss: 0.608710\n",
      "epoch 97; iter: 0; batch classifier loss: 0.321040; batch adversarial loss: 0.535849\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334603; batch adversarial loss: 0.526090\n",
      "epoch 99; iter: 0; batch classifier loss: 0.472612; batch adversarial loss: 0.535184\n",
      "epoch 100; iter: 0; batch classifier loss: 0.437573; batch adversarial loss: 0.535424\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413411; batch adversarial loss: 0.661782\n",
      "epoch 102; iter: 0; batch classifier loss: 0.421615; batch adversarial loss: 0.453740\n",
      "epoch 103; iter: 0; batch classifier loss: 0.490309; batch adversarial loss: 0.553682\n",
      "epoch 104; iter: 0; batch classifier loss: 0.418772; batch adversarial loss: 0.562718\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400192; batch adversarial loss: 0.562597\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443322; batch adversarial loss: 0.571880\n",
      "epoch 107; iter: 0; batch classifier loss: 0.328454; batch adversarial loss: 0.553634\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.599102\n",
      "epoch 109; iter: 0; batch classifier loss: 0.303519; batch adversarial loss: 0.562693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.422080; batch adversarial loss: 0.589148\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337140; batch adversarial loss: 0.535235\n",
      "epoch 112; iter: 0; batch classifier loss: 0.315979; batch adversarial loss: 0.606374\n",
      "epoch 113; iter: 0; batch classifier loss: 0.331123; batch adversarial loss: 0.581340\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364828; batch adversarial loss: 0.570941\n",
      "epoch 115; iter: 0; batch classifier loss: 0.421349; batch adversarial loss: 0.534894\n",
      "epoch 116; iter: 0; batch classifier loss: 0.383463; batch adversarial loss: 0.589990\n",
      "epoch 117; iter: 0; batch classifier loss: 0.463288; batch adversarial loss: 0.535999\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405813; batch adversarial loss: 0.562684\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380904; batch adversarial loss: 0.535189\n",
      "epoch 120; iter: 0; batch classifier loss: 0.317774; batch adversarial loss: 0.580727\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406948; batch adversarial loss: 0.508928\n",
      "epoch 122; iter: 0; batch classifier loss: 0.390919; batch adversarial loss: 0.562851\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400347; batch adversarial loss: 0.536479\n",
      "epoch 124; iter: 0; batch classifier loss: 0.423804; batch adversarial loss: 0.499121\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326165; batch adversarial loss: 0.515334\n",
      "epoch 126; iter: 0; batch classifier loss: 0.313552; batch adversarial loss: 0.516670\n",
      "epoch 127; iter: 0; batch classifier loss: 0.320141; batch adversarial loss: 0.589630\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381049; batch adversarial loss: 0.478184\n",
      "epoch 129; iter: 0; batch classifier loss: 0.442890; batch adversarial loss: 0.599146\n",
      "epoch 130; iter: 0; batch classifier loss: 0.367557; batch adversarial loss: 0.553683\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385899; batch adversarial loss: 0.526029\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323843; batch adversarial loss: 0.534858\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329997; batch adversarial loss: 0.571826\n",
      "epoch 134; iter: 0; batch classifier loss: 0.476113; batch adversarial loss: 0.563154\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366525; batch adversarial loss: 0.562886\n",
      "epoch 136; iter: 0; batch classifier loss: 0.447109; batch adversarial loss: 0.544557\n",
      "epoch 137; iter: 0; batch classifier loss: 0.494868; batch adversarial loss: 0.553377\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357491; batch adversarial loss: 0.626847\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384953; batch adversarial loss: 0.471505\n",
      "epoch 140; iter: 0; batch classifier loss: 0.362221; batch adversarial loss: 0.507909\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337690; batch adversarial loss: 0.617249\n",
      "epoch 142; iter: 0; batch classifier loss: 0.461625; batch adversarial loss: 0.589584\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397388; batch adversarial loss: 0.535521\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401446; batch adversarial loss: 0.481399\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365654; batch adversarial loss: 0.634887\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367110; batch adversarial loss: 0.544685\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377180; batch adversarial loss: 0.508762\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412958; batch adversarial loss: 0.499632\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358358; batch adversarial loss: 0.599014\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347512; batch adversarial loss: 0.526561\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370081; batch adversarial loss: 0.544198\n",
      "epoch 152; iter: 0; batch classifier loss: 0.371370; batch adversarial loss: 0.553614\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343677; batch adversarial loss: 0.590067\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346832; batch adversarial loss: 0.535227\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389142; batch adversarial loss: 0.562343\n",
      "epoch 156; iter: 0; batch classifier loss: 0.394828; batch adversarial loss: 0.571741\n",
      "epoch 157; iter: 0; batch classifier loss: 0.426317; batch adversarial loss: 0.580649\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384489; batch adversarial loss: 0.535843\n",
      "epoch 159; iter: 0; batch classifier loss: 0.328556; batch adversarial loss: 0.534656\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383166; batch adversarial loss: 0.517920\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334235; batch adversarial loss: 0.562435\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360015; batch adversarial loss: 0.489741\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361366; batch adversarial loss: 0.517812\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339291; batch adversarial loss: 0.481080\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363036; batch adversarial loss: 0.508185\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351387; batch adversarial loss: 0.643930\n",
      "epoch 167; iter: 0; batch classifier loss: 0.378506; batch adversarial loss: 0.508736\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376796; batch adversarial loss: 0.553357\n",
      "epoch 169; iter: 0; batch classifier loss: 0.434690; batch adversarial loss: 0.490235\n",
      "epoch 170; iter: 0; batch classifier loss: 0.427932; batch adversarial loss: 0.499689\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343805; batch adversarial loss: 0.580821\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344120; batch adversarial loss: 0.635133\n",
      "epoch 173; iter: 0; batch classifier loss: 0.449944; batch adversarial loss: 0.607713\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326418; batch adversarial loss: 0.616953\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306616; batch adversarial loss: 0.617056\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348395; batch adversarial loss: 0.553471\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406995; batch adversarial loss: 0.553980\n",
      "epoch 178; iter: 0; batch classifier loss: 0.346045; batch adversarial loss: 0.507886\n",
      "epoch 179; iter: 0; batch classifier loss: 0.414872; batch adversarial loss: 0.526930\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395469; batch adversarial loss: 0.481260\n",
      "epoch 181; iter: 0; batch classifier loss: 0.380447; batch adversarial loss: 0.525851\n",
      "epoch 182; iter: 0; batch classifier loss: 0.430571; batch adversarial loss: 0.598558\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384090; batch adversarial loss: 0.498718\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380417; batch adversarial loss: 0.572820\n",
      "epoch 185; iter: 0; batch classifier loss: 0.428918; batch adversarial loss: 0.462744\n",
      "epoch 186; iter: 0; batch classifier loss: 0.413959; batch adversarial loss: 0.535292\n",
      "epoch 187; iter: 0; batch classifier loss: 0.401364; batch adversarial loss: 0.580611\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336313; batch adversarial loss: 0.499425\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414163; batch adversarial loss: 0.516464\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390829; batch adversarial loss: 0.572476\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321436; batch adversarial loss: 0.581115\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398108; batch adversarial loss: 0.544220\n",
      "epoch 193; iter: 0; batch classifier loss: 0.425126; batch adversarial loss: 0.671854\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324371; batch adversarial loss: 0.580684\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308976; batch adversarial loss: 0.635403\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354586; batch adversarial loss: 0.517497\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339357; batch adversarial loss: 0.562614\n",
      "epoch 198; iter: 0; batch classifier loss: 0.421079; batch adversarial loss: 0.526428\n",
      "epoch 199; iter: 0; batch classifier loss: 0.274974; batch adversarial loss: 0.517249\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734266; batch adversarial loss: 0.640256\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604106; batch adversarial loss: 0.654284\n",
      "epoch 2; iter: 0; batch classifier loss: 0.549904; batch adversarial loss: 0.649266\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563732; batch adversarial loss: 0.645932\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573568; batch adversarial loss: 0.642937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536994; batch adversarial loss: 0.640110\n",
      "epoch 6; iter: 0; batch classifier loss: 0.530035; batch adversarial loss: 0.589848\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536981; batch adversarial loss: 0.584253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.530379; batch adversarial loss: 0.582860\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537029; batch adversarial loss: 0.589920\n",
      "epoch 10; iter: 0; batch classifier loss: 0.638092; batch adversarial loss: 0.613235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525509; batch adversarial loss: 0.590590\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599274; batch adversarial loss: 0.577617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494936; batch adversarial loss: 0.532312\n",
      "epoch 14; iter: 0; batch classifier loss: 0.422810; batch adversarial loss: 0.575603\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494333; batch adversarial loss: 0.618342\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498273; batch adversarial loss: 0.523728\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516694; batch adversarial loss: 0.532484\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517482; batch adversarial loss: 0.558132\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486644; batch adversarial loss: 0.554758\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523181; batch adversarial loss: 0.523113\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508294; batch adversarial loss: 0.543759\n",
      "epoch 22; iter: 0; batch classifier loss: 0.444411; batch adversarial loss: 0.587391\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430293; batch adversarial loss: 0.527549\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464594; batch adversarial loss: 0.555831\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433322; batch adversarial loss: 0.562079\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460342; batch adversarial loss: 0.616471\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453393; batch adversarial loss: 0.590075\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469133; batch adversarial loss: 0.585022\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430225; batch adversarial loss: 0.521437\n",
      "epoch 30; iter: 0; batch classifier loss: 0.429722; batch adversarial loss: 0.581655\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429342; batch adversarial loss: 0.568896\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468128; batch adversarial loss: 0.485024\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414802; batch adversarial loss: 0.520274\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488331; batch adversarial loss: 0.564413\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421237; batch adversarial loss: 0.490900\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451714; batch adversarial loss: 0.600530\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408813; batch adversarial loss: 0.520452\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434547; batch adversarial loss: 0.526165\n",
      "epoch 39; iter: 0; batch classifier loss: 0.352421; batch adversarial loss: 0.564141\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450964; batch adversarial loss: 0.527223\n",
      "epoch 41; iter: 0; batch classifier loss: 0.518203; batch adversarial loss: 0.527368\n",
      "epoch 42; iter: 0; batch classifier loss: 0.520214; batch adversarial loss: 0.571199\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443420; batch adversarial loss: 0.482638\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444232; batch adversarial loss: 0.606912\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392260; batch adversarial loss: 0.544633\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464800; batch adversarial loss: 0.535787\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404463; batch adversarial loss: 0.562180\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410024; batch adversarial loss: 0.561929\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416727; batch adversarial loss: 0.571071\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491989; batch adversarial loss: 0.590129\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400807; batch adversarial loss: 0.508204\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405532; batch adversarial loss: 0.434392\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402449; batch adversarial loss: 0.571886\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421435; batch adversarial loss: 0.597939\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425718; batch adversarial loss: 0.556699\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437875; batch adversarial loss: 0.479008\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412145; batch adversarial loss: 0.544120\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472440; batch adversarial loss: 0.525546\n",
      "epoch 59; iter: 0; batch classifier loss: 0.479293; batch adversarial loss: 0.599243\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397893; batch adversarial loss: 0.483369\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432657; batch adversarial loss: 0.563054\n",
      "epoch 62; iter: 0; batch classifier loss: 0.369756; batch adversarial loss: 0.598892\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395436; batch adversarial loss: 0.536344\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473487; batch adversarial loss: 0.543396\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435946; batch adversarial loss: 0.581319\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452549; batch adversarial loss: 0.581962\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445450; batch adversarial loss: 0.490815\n",
      "epoch 68; iter: 0; batch classifier loss: 0.474836; batch adversarial loss: 0.473362\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355651; batch adversarial loss: 0.562624\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385302; batch adversarial loss: 0.500217\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409931; batch adversarial loss: 0.553549\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404704; batch adversarial loss: 0.625305\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441631; batch adversarial loss: 0.544502\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425861; batch adversarial loss: 0.535624\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372020; batch adversarial loss: 0.526728\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419125; batch adversarial loss: 0.481535\n",
      "epoch 77; iter: 0; batch classifier loss: 0.438628; batch adversarial loss: 0.525949\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416795; batch adversarial loss: 0.481016\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406949; batch adversarial loss: 0.526554\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392541; batch adversarial loss: 0.563312\n",
      "epoch 81; iter: 0; batch classifier loss: 0.346183; batch adversarial loss: 0.562204\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426033; batch adversarial loss: 0.535239\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385478; batch adversarial loss: 0.553845\n",
      "epoch 84; iter: 0; batch classifier loss: 0.347200; batch adversarial loss: 0.545280\n",
      "epoch 85; iter: 0; batch classifier loss: 0.420524; batch adversarial loss: 0.491210\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397334; batch adversarial loss: 0.580658\n",
      "epoch 87; iter: 0; batch classifier loss: 0.460460; batch adversarial loss: 0.517282\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393219; batch adversarial loss: 0.616528\n",
      "epoch 89; iter: 0; batch classifier loss: 0.456785; batch adversarial loss: 0.508486\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425539; batch adversarial loss: 0.526747\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382081; batch adversarial loss: 0.625054\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353565; batch adversarial loss: 0.634511\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429315; batch adversarial loss: 0.598401\n",
      "epoch 94; iter: 0; batch classifier loss: 0.459528; batch adversarial loss: 0.536077\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393159; batch adversarial loss: 0.580447\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443914; batch adversarial loss: 0.580632\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394483; batch adversarial loss: 0.544848\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367682; batch adversarial loss: 0.589927\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375692; batch adversarial loss: 0.481754\n",
      "epoch 100; iter: 0; batch classifier loss: 0.435502; batch adversarial loss: 0.553745\n",
      "epoch 101; iter: 0; batch classifier loss: 0.419947; batch adversarial loss: 0.581171\n",
      "epoch 102; iter: 0; batch classifier loss: 0.329047; batch adversarial loss: 0.589582\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371008; batch adversarial loss: 0.490305\n",
      "epoch 104; iter: 0; batch classifier loss: 0.445888; batch adversarial loss: 0.499107\n",
      "epoch 105; iter: 0; batch classifier loss: 0.440478; batch adversarial loss: 0.617369\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434565; batch adversarial loss: 0.490646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.458812; batch adversarial loss: 0.571568\n",
      "epoch 108; iter: 0; batch classifier loss: 0.444474; batch adversarial loss: 0.598481\n",
      "epoch 109; iter: 0; batch classifier loss: 0.414687; batch adversarial loss: 0.589518\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378019; batch adversarial loss: 0.553544\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436257; batch adversarial loss: 0.580747\n",
      "epoch 112; iter: 0; batch classifier loss: 0.428686; batch adversarial loss: 0.580970\n",
      "epoch 113; iter: 0; batch classifier loss: 0.521762; batch adversarial loss: 0.580703\n",
      "epoch 114; iter: 0; batch classifier loss: 0.465515; batch adversarial loss: 0.571282\n",
      "epoch 115; iter: 0; batch classifier loss: 0.408596; batch adversarial loss: 0.490415\n",
      "epoch 116; iter: 0; batch classifier loss: 0.263491; batch adversarial loss: 0.652732\n",
      "epoch 117; iter: 0; batch classifier loss: 0.445690; batch adversarial loss: 0.580612\n",
      "epoch 118; iter: 0; batch classifier loss: 0.415127; batch adversarial loss: 0.526737\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390424; batch adversarial loss: 0.517093\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378890; batch adversarial loss: 0.544907\n",
      "epoch 121; iter: 0; batch classifier loss: 0.463908; batch adversarial loss: 0.544411\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358130; batch adversarial loss: 0.472687\n",
      "epoch 123; iter: 0; batch classifier loss: 0.463809; batch adversarial loss: 0.535732\n",
      "epoch 124; iter: 0; batch classifier loss: 0.495073; batch adversarial loss: 0.571661\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374820; batch adversarial loss: 0.579801\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388654; batch adversarial loss: 0.517452\n",
      "epoch 127; iter: 0; batch classifier loss: 0.448689; batch adversarial loss: 0.562596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366289; batch adversarial loss: 0.535494\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359760; batch adversarial loss: 0.580562\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349092; batch adversarial loss: 0.526343\n",
      "epoch 131; iter: 0; batch classifier loss: 0.433190; batch adversarial loss: 0.490121\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401646; batch adversarial loss: 0.589171\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425560; batch adversarial loss: 0.571627\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440754; batch adversarial loss: 0.598335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347088; batch adversarial loss: 0.517588\n",
      "epoch 136; iter: 0; batch classifier loss: 0.466662; batch adversarial loss: 0.634504\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362830; batch adversarial loss: 0.508857\n",
      "epoch 138; iter: 0; batch classifier loss: 0.303699; batch adversarial loss: 0.517428\n",
      "epoch 139; iter: 0; batch classifier loss: 0.307227; batch adversarial loss: 0.517512\n",
      "epoch 140; iter: 0; batch classifier loss: 0.453079; batch adversarial loss: 0.536016\n",
      "epoch 141; iter: 0; batch classifier loss: 0.320444; batch adversarial loss: 0.535515\n",
      "epoch 142; iter: 0; batch classifier loss: 0.316001; batch adversarial loss: 0.580362\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375953; batch adversarial loss: 0.526514\n",
      "epoch 144; iter: 0; batch classifier loss: 0.386206; batch adversarial loss: 0.571695\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366081; batch adversarial loss: 0.581236\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349138; batch adversarial loss: 0.580347\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342590; batch adversarial loss: 0.527123\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350375; batch adversarial loss: 0.517393\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383683; batch adversarial loss: 0.615741\n",
      "epoch 150; iter: 0; batch classifier loss: 0.457180; batch adversarial loss: 0.589466\n",
      "epoch 151; iter: 0; batch classifier loss: 0.445927; batch adversarial loss: 0.535620\n",
      "epoch 152; iter: 0; batch classifier loss: 0.409283; batch adversarial loss: 0.625902\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430271; batch adversarial loss: 0.498769\n",
      "epoch 154; iter: 0; batch classifier loss: 0.314197; batch adversarial loss: 0.535154\n",
      "epoch 155; iter: 0; batch classifier loss: 0.382879; batch adversarial loss: 0.571302\n",
      "epoch 156; iter: 0; batch classifier loss: 0.481074; batch adversarial loss: 0.553910\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399630; batch adversarial loss: 0.607820\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380610; batch adversarial loss: 0.625299\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375362; batch adversarial loss: 0.553691\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364991; batch adversarial loss: 0.535543\n",
      "epoch 161; iter: 0; batch classifier loss: 0.290805; batch adversarial loss: 0.544299\n",
      "epoch 162; iter: 0; batch classifier loss: 0.355767; batch adversarial loss: 0.562561\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382338; batch adversarial loss: 0.517812\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354803; batch adversarial loss: 0.607660\n",
      "epoch 165; iter: 0; batch classifier loss: 0.276669; batch adversarial loss: 0.571824\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331642; batch adversarial loss: 0.598542\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380700; batch adversarial loss: 0.508544\n",
      "epoch 168; iter: 0; batch classifier loss: 0.412050; batch adversarial loss: 0.571743\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372302; batch adversarial loss: 0.562510\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397536; batch adversarial loss: 0.590015\n",
      "epoch 171; iter: 0; batch classifier loss: 0.447966; batch adversarial loss: 0.535844\n",
      "epoch 172; iter: 0; batch classifier loss: 0.281458; batch adversarial loss: 0.562825\n",
      "epoch 173; iter: 0; batch classifier loss: 0.384024; batch adversarial loss: 0.553579\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310413; batch adversarial loss: 0.535428\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314012; batch adversarial loss: 0.562804\n",
      "epoch 176; iter: 0; batch classifier loss: 0.449219; batch adversarial loss: 0.481243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386499; batch adversarial loss: 0.526387\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416764; batch adversarial loss: 0.490780\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372485; batch adversarial loss: 0.553531\n",
      "epoch 180; iter: 0; batch classifier loss: 0.455480; batch adversarial loss: 0.508805\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373080; batch adversarial loss: 0.571424\n",
      "epoch 182; iter: 0; batch classifier loss: 0.444469; batch adversarial loss: 0.616532\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396019; batch adversarial loss: 0.607336\n",
      "epoch 184; iter: 0; batch classifier loss: 0.448614; batch adversarial loss: 0.517497\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319746; batch adversarial loss: 0.634413\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377090; batch adversarial loss: 0.526402\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371450; batch adversarial loss: 0.526332\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387430; batch adversarial loss: 0.572152\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370084; batch adversarial loss: 0.490151\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343610; batch adversarial loss: 0.553878\n",
      "epoch 191; iter: 0; batch classifier loss: 0.404291; batch adversarial loss: 0.580773\n",
      "epoch 192; iter: 0; batch classifier loss: 0.434624; batch adversarial loss: 0.544675\n",
      "epoch 193; iter: 0; batch classifier loss: 0.408799; batch adversarial loss: 0.544665\n",
      "epoch 194; iter: 0; batch classifier loss: 0.371038; batch adversarial loss: 0.571501\n",
      "epoch 195; iter: 0; batch classifier loss: 0.378680; batch adversarial loss: 0.589585\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370281; batch adversarial loss: 0.508953\n",
      "epoch 197; iter: 0; batch classifier loss: 0.444589; batch adversarial loss: 0.482249\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382070; batch adversarial loss: 0.616737\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362465; batch adversarial loss: 0.508646\n",
      "epoch 0; iter: 0; batch classifier loss: 0.754024; batch adversarial loss: 0.867848\n",
      "epoch 1; iter: 0; batch classifier loss: 0.758035; batch adversarial loss: 0.903611\n",
      "epoch 2; iter: 0; batch classifier loss: 0.791825; batch adversarial loss: 0.852938\n",
      "epoch 3; iter: 0; batch classifier loss: 0.834627; batch adversarial loss: 0.778495\n",
      "epoch 4; iter: 0; batch classifier loss: 0.709942; batch adversarial loss: 0.731581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.714406; batch adversarial loss: 0.668866\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609758; batch adversarial loss: 0.630435\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557762; batch adversarial loss: 0.625906\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525357; batch adversarial loss: 0.606831\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568200; batch adversarial loss: 0.624895\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575559; batch adversarial loss: 0.593209\n",
      "epoch 11; iter: 0; batch classifier loss: 0.640856; batch adversarial loss: 0.573263\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548926; batch adversarial loss: 0.551447\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544406; batch adversarial loss: 0.558667\n",
      "epoch 14; iter: 0; batch classifier loss: 0.494583; batch adversarial loss: 0.540000\n",
      "epoch 15; iter: 0; batch classifier loss: 0.545689; batch adversarial loss: 0.517509\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493555; batch adversarial loss: 0.540971\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560285; batch adversarial loss: 0.534277\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533241; batch adversarial loss: 0.579369\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527292; batch adversarial loss: 0.528336\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486004; batch adversarial loss: 0.620845\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543707; batch adversarial loss: 0.553311\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463858; batch adversarial loss: 0.616201\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484526; batch adversarial loss: 0.554692\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524373; batch adversarial loss: 0.586036\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516794; batch adversarial loss: 0.538366\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459565; batch adversarial loss: 0.576970\n",
      "epoch 27; iter: 0; batch classifier loss: 0.599739; batch adversarial loss: 0.554422\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446796; batch adversarial loss: 0.516898\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534651; batch adversarial loss: 0.630201\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431529; batch adversarial loss: 0.480501\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469617; batch adversarial loss: 0.598370\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525251; batch adversarial loss: 0.609857\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450186; batch adversarial loss: 0.518595\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390676; batch adversarial loss: 0.619838\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511504; batch adversarial loss: 0.514330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484986; batch adversarial loss: 0.522101\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452350; batch adversarial loss: 0.561472\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455721; batch adversarial loss: 0.554441\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432669; batch adversarial loss: 0.502353\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441007; batch adversarial loss: 0.520662\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476098; batch adversarial loss: 0.553558\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445564; batch adversarial loss: 0.518907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424400; batch adversarial loss: 0.597744\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424055; batch adversarial loss: 0.501024\n",
      "epoch 45; iter: 0; batch classifier loss: 0.359258; batch adversarial loss: 0.615708\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418133; batch adversarial loss: 0.561889\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451862; batch adversarial loss: 0.580270\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470036; batch adversarial loss: 0.562218\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456863; batch adversarial loss: 0.517208\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412403; batch adversarial loss: 0.590273\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374938; batch adversarial loss: 0.500651\n",
      "epoch 52; iter: 0; batch classifier loss: 0.359804; batch adversarial loss: 0.607612\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383957; batch adversarial loss: 0.526723\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426509; batch adversarial loss: 0.579797\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429506; batch adversarial loss: 0.589259\n",
      "epoch 56; iter: 0; batch classifier loss: 0.402781; batch adversarial loss: 0.552759\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386371; batch adversarial loss: 0.500522\n",
      "epoch 58; iter: 0; batch classifier loss: 0.415158; batch adversarial loss: 0.480628\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404458; batch adversarial loss: 0.544373\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396750; batch adversarial loss: 0.535904\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411877; batch adversarial loss: 0.454569\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401520; batch adversarial loss: 0.552707\n",
      "epoch 63; iter: 0; batch classifier loss: 0.495692; batch adversarial loss: 0.551862\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489041; batch adversarial loss: 0.571816\n",
      "epoch 65; iter: 0; batch classifier loss: 0.482159; batch adversarial loss: 0.471867\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392233; batch adversarial loss: 0.526455\n",
      "epoch 67; iter: 0; batch classifier loss: 0.348943; batch adversarial loss: 0.501013\n",
      "epoch 68; iter: 0; batch classifier loss: 0.518326; batch adversarial loss: 0.454673\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401736; batch adversarial loss: 0.554339\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403332; batch adversarial loss: 0.527053\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390256; batch adversarial loss: 0.444571\n",
      "epoch 72; iter: 0; batch classifier loss: 0.350422; batch adversarial loss: 0.539018\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388990; batch adversarial loss: 0.563408\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413989; batch adversarial loss: 0.523575\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402215; batch adversarial loss: 0.507591\n",
      "epoch 76; iter: 0; batch classifier loss: 0.506423; batch adversarial loss: 0.581886\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404250; batch adversarial loss: 0.554779\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371633; batch adversarial loss: 0.550601\n",
      "epoch 79; iter: 0; batch classifier loss: 0.338255; batch adversarial loss: 0.533552\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363852; batch adversarial loss: 0.552566\n",
      "epoch 81; iter: 0; batch classifier loss: 0.363724; batch adversarial loss: 0.471462\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390303; batch adversarial loss: 0.535136\n",
      "epoch 83; iter: 0; batch classifier loss: 0.328205; batch adversarial loss: 0.523215\n",
      "epoch 84; iter: 0; batch classifier loss: 0.334551; batch adversarial loss: 0.552462\n",
      "epoch 85; iter: 0; batch classifier loss: 0.436492; batch adversarial loss: 0.485006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398569; batch adversarial loss: 0.545946\n",
      "epoch 87; iter: 0; batch classifier loss: 0.472415; batch adversarial loss: 0.579373\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372325; batch adversarial loss: 0.572439\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367595; batch adversarial loss: 0.614406\n",
      "epoch 90; iter: 0; batch classifier loss: 0.478225; batch adversarial loss: 0.570484\n",
      "epoch 91; iter: 0; batch classifier loss: 0.344022; batch adversarial loss: 0.510567\n",
      "epoch 92; iter: 0; batch classifier loss: 0.359233; batch adversarial loss: 0.535366\n",
      "epoch 93; iter: 0; batch classifier loss: 0.350570; batch adversarial loss: 0.545002\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434715; batch adversarial loss: 0.488879\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417758; batch adversarial loss: 0.552832\n",
      "epoch 96; iter: 0; batch classifier loss: 0.440669; batch adversarial loss: 0.605388\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404027; batch adversarial loss: 0.523855\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439557; batch adversarial loss: 0.562577\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368127; batch adversarial loss: 0.544011\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403800; batch adversarial loss: 0.563103\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400847; batch adversarial loss: 0.559122\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386498; batch adversarial loss: 0.536183\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339923; batch adversarial loss: 0.544544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.370643; batch adversarial loss: 0.536179\n",
      "epoch 105; iter: 0; batch classifier loss: 0.376594; batch adversarial loss: 0.571176\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326721; batch adversarial loss: 0.578943\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355040; batch adversarial loss: 0.491997\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366112; batch adversarial loss: 0.472135\n",
      "epoch 109; iter: 0; batch classifier loss: 0.326113; batch adversarial loss: 0.560202\n",
      "epoch 110; iter: 0; batch classifier loss: 0.284228; batch adversarial loss: 0.613919\n",
      "epoch 111; iter: 0; batch classifier loss: 0.417515; batch adversarial loss: 0.547258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359733; batch adversarial loss: 0.481008\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364587; batch adversarial loss: 0.545440\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402284; batch adversarial loss: 0.534043\n",
      "epoch 115; iter: 0; batch classifier loss: 0.454444; batch adversarial loss: 0.500841\n",
      "epoch 116; iter: 0; batch classifier loss: 0.333710; batch adversarial loss: 0.509299\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367142; batch adversarial loss: 0.498945\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384839; batch adversarial loss: 0.595396\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381458; batch adversarial loss: 0.561807\n",
      "epoch 120; iter: 0; batch classifier loss: 0.460785; batch adversarial loss: 0.475320\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371516; batch adversarial loss: 0.516611\n",
      "epoch 122; iter: 0; batch classifier loss: 0.435291; batch adversarial loss: 0.482822\n",
      "epoch 123; iter: 0; batch classifier loss: 0.326032; batch adversarial loss: 0.572350\n",
      "epoch 124; iter: 0; batch classifier loss: 0.459031; batch adversarial loss: 0.580569\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371929; batch adversarial loss: 0.526699\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348426; batch adversarial loss: 0.510140\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392685; batch adversarial loss: 0.552674\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354842; batch adversarial loss: 0.606976\n",
      "epoch 129; iter: 0; batch classifier loss: 0.295503; batch adversarial loss: 0.535707\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341171; batch adversarial loss: 0.553355\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353334; batch adversarial loss: 0.605231\n",
      "epoch 132; iter: 0; batch classifier loss: 0.366994; batch adversarial loss: 0.552840\n",
      "epoch 133; iter: 0; batch classifier loss: 0.424000; batch adversarial loss: 0.572440\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393017; batch adversarial loss: 0.508280\n",
      "epoch 135; iter: 0; batch classifier loss: 0.383440; batch adversarial loss: 0.577351\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421558; batch adversarial loss: 0.597623\n",
      "epoch 137; iter: 0; batch classifier loss: 0.303743; batch adversarial loss: 0.555541\n",
      "epoch 138; iter: 0; batch classifier loss: 0.310683; batch adversarial loss: 0.605503\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328209; batch adversarial loss: 0.595006\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368365; batch adversarial loss: 0.570771\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332739; batch adversarial loss: 0.491467\n",
      "epoch 142; iter: 0; batch classifier loss: 0.434276; batch adversarial loss: 0.544869\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406787; batch adversarial loss: 0.526273\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424422; batch adversarial loss: 0.579086\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371459; batch adversarial loss: 0.609837\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389016; batch adversarial loss: 0.577993\n",
      "epoch 147; iter: 0; batch classifier loss: 0.371525; batch adversarial loss: 0.523973\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374391; batch adversarial loss: 0.536806\n",
      "epoch 149; iter: 0; batch classifier loss: 0.364295; batch adversarial loss: 0.497332\n",
      "epoch 150; iter: 0; batch classifier loss: 0.436973; batch adversarial loss: 0.527979\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362000; batch adversarial loss: 0.546250\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391930; batch adversarial loss: 0.527324\n",
      "epoch 153; iter: 0; batch classifier loss: 0.308762; batch adversarial loss: 0.568794\n",
      "epoch 154; iter: 0; batch classifier loss: 0.303520; batch adversarial loss: 0.526712\n",
      "epoch 155; iter: 0; batch classifier loss: 0.315466; batch adversarial loss: 0.565016\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385855; batch adversarial loss: 0.571281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.442394; batch adversarial loss: 0.535011\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367923; batch adversarial loss: 0.518476\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368239; batch adversarial loss: 0.590876\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386497; batch adversarial loss: 0.500894\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334526; batch adversarial loss: 0.482931\n",
      "epoch 162; iter: 0; batch classifier loss: 0.294426; batch adversarial loss: 0.577215\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362479; batch adversarial loss: 0.568181\n",
      "epoch 164; iter: 0; batch classifier loss: 0.319252; batch adversarial loss: 0.516578\n",
      "epoch 165; iter: 0; batch classifier loss: 0.476375; batch adversarial loss: 0.480328\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317881; batch adversarial loss: 0.499209\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365519; batch adversarial loss: 0.553337\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329278; batch adversarial loss: 0.543536\n",
      "epoch 169; iter: 0; batch classifier loss: 0.311601; batch adversarial loss: 0.540401\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371911; batch adversarial loss: 0.547968\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358959; batch adversarial loss: 0.564184\n",
      "epoch 172; iter: 0; batch classifier loss: 0.444036; batch adversarial loss: 0.626406\n",
      "epoch 173; iter: 0; batch classifier loss: 0.294674; batch adversarial loss: 0.623310\n",
      "epoch 174; iter: 0; batch classifier loss: 0.265681; batch adversarial loss: 0.553618\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339552; batch adversarial loss: 0.461906\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364701; batch adversarial loss: 0.583220\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330775; batch adversarial loss: 0.463307\n",
      "epoch 178; iter: 0; batch classifier loss: 0.297456; batch adversarial loss: 0.565632\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318661; batch adversarial loss: 0.636395\n",
      "epoch 180; iter: 0; batch classifier loss: 0.292584; batch adversarial loss: 0.482260\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374590; batch adversarial loss: 0.571581\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367759; batch adversarial loss: 0.592366\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382134; batch adversarial loss: 0.584969\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337978; batch adversarial loss: 0.498677\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391913; batch adversarial loss: 0.652631\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346038; batch adversarial loss: 0.489510\n",
      "epoch 187; iter: 0; batch classifier loss: 0.291296; batch adversarial loss: 0.537611\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336001; batch adversarial loss: 0.545067\n",
      "epoch 189; iter: 0; batch classifier loss: 0.279022; batch adversarial loss: 0.553571\n",
      "epoch 190; iter: 0; batch classifier loss: 0.330309; batch adversarial loss: 0.506462\n",
      "epoch 191; iter: 0; batch classifier loss: 0.342956; batch adversarial loss: 0.528514\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297534; batch adversarial loss: 0.593394\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284945; batch adversarial loss: 0.542649\n",
      "epoch 194; iter: 0; batch classifier loss: 0.293301; batch adversarial loss: 0.533348\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353765; batch adversarial loss: 0.583268\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326226; batch adversarial loss: 0.537480\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393666; batch adversarial loss: 0.525371\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366391; batch adversarial loss: 0.505891\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332205; batch adversarial loss: 0.524897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.785336; batch adversarial loss: 0.811198\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597012; batch adversarial loss: 0.705313\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570855; batch adversarial loss: 0.687909\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593034; batch adversarial loss: 0.658986\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525050; batch adversarial loss: 0.678334\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578588; batch adversarial loss: 0.641979\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510796; batch adversarial loss: 0.609804\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563614; batch adversarial loss: 0.624944\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517035; batch adversarial loss: 0.567295\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577071; batch adversarial loss: 0.576911\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568286; batch adversarial loss: 0.574071\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492314; batch adversarial loss: 0.533617\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553971; batch adversarial loss: 0.599992\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511024; batch adversarial loss: 0.507228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464314; batch adversarial loss: 0.533824\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484341; batch adversarial loss: 0.604662\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471275; batch adversarial loss: 0.545632\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520437; batch adversarial loss: 0.661669\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529392; batch adversarial loss: 0.571196\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487984; batch adversarial loss: 0.620789\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524180; batch adversarial loss: 0.571733\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536729; batch adversarial loss: 0.555477\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489431; batch adversarial loss: 0.543010\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522369; batch adversarial loss: 0.518143\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479238; batch adversarial loss: 0.538190\n",
      "epoch 25; iter: 0; batch classifier loss: 0.529156; batch adversarial loss: 0.615391\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494966; batch adversarial loss: 0.585589\n",
      "epoch 27; iter: 0; batch classifier loss: 0.515499; batch adversarial loss: 0.513481\n",
      "epoch 28; iter: 0; batch classifier loss: 0.545079; batch adversarial loss: 0.576577\n",
      "epoch 29; iter: 0; batch classifier loss: 0.529532; batch adversarial loss: 0.584496\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422194; batch adversarial loss: 0.514652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435708; batch adversarial loss: 0.507609\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443739; batch adversarial loss: 0.544020\n",
      "epoch 33; iter: 0; batch classifier loss: 0.413903; batch adversarial loss: 0.493874\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398091; batch adversarial loss: 0.581697\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504702; batch adversarial loss: 0.538279\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423374; batch adversarial loss: 0.577547\n",
      "epoch 37; iter: 0; batch classifier loss: 0.515600; batch adversarial loss: 0.544969\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415383; batch adversarial loss: 0.483739\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463418; batch adversarial loss: 0.536689\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443165; batch adversarial loss: 0.484692\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441104; batch adversarial loss: 0.608449\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459072; batch adversarial loss: 0.562780\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427042; batch adversarial loss: 0.470915\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366394; batch adversarial loss: 0.469375\n",
      "epoch 45; iter: 0; batch classifier loss: 0.406753; batch adversarial loss: 0.536440\n",
      "epoch 46; iter: 0; batch classifier loss: 0.358202; batch adversarial loss: 0.524566\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407869; batch adversarial loss: 0.544218\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414573; batch adversarial loss: 0.563378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433046; batch adversarial loss: 0.554772\n",
      "epoch 50; iter: 0; batch classifier loss: 0.369666; batch adversarial loss: 0.452794\n",
      "epoch 51; iter: 0; batch classifier loss: 0.507120; batch adversarial loss: 0.600251\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461682; batch adversarial loss: 0.590307\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391351; batch adversarial loss: 0.534360\n",
      "epoch 54; iter: 0; batch classifier loss: 0.389423; batch adversarial loss: 0.601126\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419274; batch adversarial loss: 0.553628\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430061; batch adversarial loss: 0.543366\n",
      "epoch 57; iter: 0; batch classifier loss: 0.367891; batch adversarial loss: 0.591606\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402120; batch adversarial loss: 0.572876\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408412; batch adversarial loss: 0.506469\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426868; batch adversarial loss: 0.582875\n",
      "epoch 61; iter: 0; batch classifier loss: 0.485182; batch adversarial loss: 0.582438\n",
      "epoch 62; iter: 0; batch classifier loss: 0.431471; batch adversarial loss: 0.517485\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402014; batch adversarial loss: 0.638043\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408645; batch adversarial loss: 0.571977\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379859; batch adversarial loss: 0.587774\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426683; batch adversarial loss: 0.480091\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381978; batch adversarial loss: 0.469501\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378186; batch adversarial loss: 0.515126\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404206; batch adversarial loss: 0.581870\n",
      "epoch 70; iter: 0; batch classifier loss: 0.336939; batch adversarial loss: 0.534631\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417066; batch adversarial loss: 0.544665\n",
      "epoch 72; iter: 0; batch classifier loss: 0.331700; batch adversarial loss: 0.516952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374748; batch adversarial loss: 0.535032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412204; batch adversarial loss: 0.544719\n",
      "epoch 75; iter: 0; batch classifier loss: 0.488107; batch adversarial loss: 0.562442\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402475; batch adversarial loss: 0.555247\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422099; batch adversarial loss: 0.499456\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351692; batch adversarial loss: 0.632266\n",
      "epoch 79; iter: 0; batch classifier loss: 0.454328; batch adversarial loss: 0.543315\n",
      "epoch 80; iter: 0; batch classifier loss: 0.443486; batch adversarial loss: 0.507745\n",
      "epoch 81; iter: 0; batch classifier loss: 0.437318; batch adversarial loss: 0.629107\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362887; batch adversarial loss: 0.706543\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387323; batch adversarial loss: 0.563913\n",
      "epoch 84; iter: 0; batch classifier loss: 0.347141; batch adversarial loss: 0.535216\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381153; batch adversarial loss: 0.638402\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355157; batch adversarial loss: 0.560358\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430841; batch adversarial loss: 0.561947\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360946; batch adversarial loss: 0.563414\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393925; batch adversarial loss: 0.572849\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434065; batch adversarial loss: 0.562814\n",
      "epoch 91; iter: 0; batch classifier loss: 0.285942; batch adversarial loss: 0.496998\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392916; batch adversarial loss: 0.525589\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423137; batch adversarial loss: 0.487608\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402251; batch adversarial loss: 0.521555\n",
      "epoch 95; iter: 0; batch classifier loss: 0.351701; batch adversarial loss: 0.572181\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369589; batch adversarial loss: 0.582197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.370929; batch adversarial loss: 0.568549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.295431; batch adversarial loss: 0.608931\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395659; batch adversarial loss: 0.460926\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352894; batch adversarial loss: 0.505837\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344426; batch adversarial loss: 0.557164\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415766; batch adversarial loss: 0.534669\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371569; batch adversarial loss: 0.543844\n",
      "epoch 104; iter: 0; batch classifier loss: 0.461549; batch adversarial loss: 0.552790\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383231; batch adversarial loss: 0.469143\n",
      "epoch 106; iter: 0; batch classifier loss: 0.460827; batch adversarial loss: 0.486618\n",
      "epoch 107; iter: 0; batch classifier loss: 0.370049; batch adversarial loss: 0.488847\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352275; batch adversarial loss: 0.506641\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413743; batch adversarial loss: 0.581853\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363325; batch adversarial loss: 0.523197\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366402; batch adversarial loss: 0.572357\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349802; batch adversarial loss: 0.543225\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418843; batch adversarial loss: 0.507584\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422707; batch adversarial loss: 0.554368\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333644; batch adversarial loss: 0.555946\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398143; batch adversarial loss: 0.552364\n",
      "epoch 117; iter: 0; batch classifier loss: 0.327331; batch adversarial loss: 0.638065\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427652; batch adversarial loss: 0.469263\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349082; batch adversarial loss: 0.517045\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408819; batch adversarial loss: 0.535347\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416706; batch adversarial loss: 0.505636\n",
      "epoch 122; iter: 0; batch classifier loss: 0.323906; batch adversarial loss: 0.543503\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387301; batch adversarial loss: 0.524536\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392697; batch adversarial loss: 0.516495\n",
      "epoch 125; iter: 0; batch classifier loss: 0.314883; batch adversarial loss: 0.555409\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402679; batch adversarial loss: 0.478859\n",
      "epoch 127; iter: 0; batch classifier loss: 0.449418; batch adversarial loss: 0.525428\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328953; batch adversarial loss: 0.497183\n",
      "epoch 129; iter: 0; batch classifier loss: 0.404214; batch adversarial loss: 0.527498\n",
      "epoch 130; iter: 0; batch classifier loss: 0.308049; batch adversarial loss: 0.599053\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331407; batch adversarial loss: 0.581718\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367557; batch adversarial loss: 0.564619\n",
      "epoch 133; iter: 0; batch classifier loss: 0.413216; batch adversarial loss: 0.563589\n",
      "epoch 134; iter: 0; batch classifier loss: 0.457881; batch adversarial loss: 0.471342\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346100; batch adversarial loss: 0.496487\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373577; batch adversarial loss: 0.517549\n",
      "epoch 137; iter: 0; batch classifier loss: 0.284935; batch adversarial loss: 0.497696\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342330; batch adversarial loss: 0.588793\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388386; batch adversarial loss: 0.560006\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338095; batch adversarial loss: 0.515633\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404203; batch adversarial loss: 0.534824\n",
      "epoch 142; iter: 0; batch classifier loss: 0.259170; batch adversarial loss: 0.601974\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327216; batch adversarial loss: 0.544972\n",
      "epoch 144; iter: 0; batch classifier loss: 0.293596; batch adversarial loss: 0.497660\n",
      "epoch 145; iter: 0; batch classifier loss: 0.294910; batch adversarial loss: 0.580555\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313302; batch adversarial loss: 0.607325\n",
      "epoch 147; iter: 0; batch classifier loss: 0.412727; batch adversarial loss: 0.544593\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368313; batch adversarial loss: 0.503108\n",
      "epoch 149; iter: 0; batch classifier loss: 0.356226; batch adversarial loss: 0.542894\n",
      "epoch 150; iter: 0; batch classifier loss: 0.366937; batch adversarial loss: 0.543662\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395017; batch adversarial loss: 0.572183\n",
      "epoch 152; iter: 0; batch classifier loss: 0.269405; batch adversarial loss: 0.562454\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352158; batch adversarial loss: 0.522898\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306592; batch adversarial loss: 0.497415\n",
      "epoch 155; iter: 0; batch classifier loss: 0.441590; batch adversarial loss: 0.590576\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346567; batch adversarial loss: 0.496534\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344214; batch adversarial loss: 0.534588\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373967; batch adversarial loss: 0.526068\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324442; batch adversarial loss: 0.514294\n",
      "epoch 160; iter: 0; batch classifier loss: 0.410394; batch adversarial loss: 0.572384\n",
      "epoch 161; iter: 0; batch classifier loss: 0.292593; batch adversarial loss: 0.543863\n",
      "epoch 162; iter: 0; batch classifier loss: 0.395266; batch adversarial loss: 0.500050\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331368; batch adversarial loss: 0.534047\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348128; batch adversarial loss: 0.608257\n",
      "epoch 165; iter: 0; batch classifier loss: 0.310891; batch adversarial loss: 0.603211\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347745; batch adversarial loss: 0.535615\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336560; batch adversarial loss: 0.543150\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386551; batch adversarial loss: 0.602690\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345713; batch adversarial loss: 0.572154\n",
      "epoch 170; iter: 0; batch classifier loss: 0.274881; batch adversarial loss: 0.468396\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336961; batch adversarial loss: 0.479303\n",
      "epoch 172; iter: 0; batch classifier loss: 0.386702; batch adversarial loss: 0.563630\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378230; batch adversarial loss: 0.536808\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377673; batch adversarial loss: 0.573440\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400515; batch adversarial loss: 0.506307\n",
      "epoch 176; iter: 0; batch classifier loss: 0.318751; batch adversarial loss: 0.543245\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333871; batch adversarial loss: 0.544846\n",
      "epoch 178; iter: 0; batch classifier loss: 0.290329; batch adversarial loss: 0.593887\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354946; batch adversarial loss: 0.555706\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396030; batch adversarial loss: 0.488406\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357236; batch adversarial loss: 0.563176\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337091; batch adversarial loss: 0.610921\n",
      "epoch 183; iter: 0; batch classifier loss: 0.305487; batch adversarial loss: 0.572885\n",
      "epoch 184; iter: 0; batch classifier loss: 0.291500; batch adversarial loss: 0.523615\n",
      "epoch 185; iter: 0; batch classifier loss: 0.400921; batch adversarial loss: 0.509149\n",
      "epoch 186; iter: 0; batch classifier loss: 0.446387; batch adversarial loss: 0.514793\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393468; batch adversarial loss: 0.562692\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374657; batch adversarial loss: 0.573148\n",
      "epoch 189; iter: 0; batch classifier loss: 0.314929; batch adversarial loss: 0.542459\n",
      "epoch 190; iter: 0; batch classifier loss: 0.275574; batch adversarial loss: 0.519345\n",
      "epoch 191; iter: 0; batch classifier loss: 0.419111; batch adversarial loss: 0.516625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.230381; batch adversarial loss: 0.506313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.342722; batch adversarial loss: 0.573680\n",
      "epoch 194; iter: 0; batch classifier loss: 0.289278; batch adversarial loss: 0.467940\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361121; batch adversarial loss: 0.563852\n",
      "epoch 196; iter: 0; batch classifier loss: 0.329437; batch adversarial loss: 0.538025\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360293; batch adversarial loss: 0.588533\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348532; batch adversarial loss: 0.543410\n",
      "epoch 199; iter: 0; batch classifier loss: 0.354540; batch adversarial loss: 0.515218\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713157; batch adversarial loss: 0.623935\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567084; batch adversarial loss: 0.652615\n",
      "epoch 2; iter: 0; batch classifier loss: 0.519705; batch adversarial loss: 0.643249\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588255; batch adversarial loss: 0.654868\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557034; batch adversarial loss: 0.669015\n",
      "epoch 5; iter: 0; batch classifier loss: 0.634656; batch adversarial loss: 0.634461\n",
      "epoch 6; iter: 0; batch classifier loss: 0.614729; batch adversarial loss: 0.635254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568448; batch adversarial loss: 0.636814\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590344; batch adversarial loss: 0.652978\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521729; batch adversarial loss: 0.606332\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539144; batch adversarial loss: 0.601260\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515950; batch adversarial loss: 0.559276\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485019; batch adversarial loss: 0.612009\n",
      "epoch 13; iter: 0; batch classifier loss: 0.444171; batch adversarial loss: 0.513839\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560921; batch adversarial loss: 0.508564\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509269; batch adversarial loss: 0.544905\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485205; batch adversarial loss: 0.566426\n",
      "epoch 17; iter: 0; batch classifier loss: 0.414946; batch adversarial loss: 0.610335\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485361; batch adversarial loss: 0.565949\n",
      "epoch 19; iter: 0; batch classifier loss: 0.615102; batch adversarial loss: 0.527682\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437656; batch adversarial loss: 0.522274\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492971; batch adversarial loss: 0.581968\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482379; batch adversarial loss: 0.540812\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471148; batch adversarial loss: 0.565402\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482480; batch adversarial loss: 0.539616\n",
      "epoch 25; iter: 0; batch classifier loss: 0.538649; batch adversarial loss: 0.572314\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438188; batch adversarial loss: 0.578515\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474755; batch adversarial loss: 0.497464\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432330; batch adversarial loss: 0.595783\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452424; batch adversarial loss: 0.521334\n",
      "epoch 30; iter: 0; batch classifier loss: 0.497657; batch adversarial loss: 0.512073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.482737; batch adversarial loss: 0.579621\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469449; batch adversarial loss: 0.537824\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478021; batch adversarial loss: 0.570559\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427914; batch adversarial loss: 0.552954\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450244; batch adversarial loss: 0.561392\n",
      "epoch 36; iter: 0; batch classifier loss: 0.566960; batch adversarial loss: 0.571080\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424422; batch adversarial loss: 0.588138\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483701; batch adversarial loss: 0.527467\n",
      "epoch 39; iter: 0; batch classifier loss: 0.406206; batch adversarial loss: 0.598682\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489933; batch adversarial loss: 0.509270\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430403; batch adversarial loss: 0.490379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406734; batch adversarial loss: 0.569908\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495051; batch adversarial loss: 0.588959\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456478; batch adversarial loss: 0.527336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445950; batch adversarial loss: 0.579233\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372966; batch adversarial loss: 0.598028\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446787; batch adversarial loss: 0.599097\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461448; batch adversarial loss: 0.590968\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473613; batch adversarial loss: 0.561351\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424887; batch adversarial loss: 0.535174\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490099; batch adversarial loss: 0.525676\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399144; batch adversarial loss: 0.648772\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432622; batch adversarial loss: 0.508878\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434852; batch adversarial loss: 0.517547\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476994; batch adversarial loss: 0.581198\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426470; batch adversarial loss: 0.517657\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403138; batch adversarial loss: 0.543902\n",
      "epoch 58; iter: 0; batch classifier loss: 0.366098; batch adversarial loss: 0.552468\n",
      "epoch 59; iter: 0; batch classifier loss: 0.459327; batch adversarial loss: 0.579758\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432657; batch adversarial loss: 0.498340\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451648; batch adversarial loss: 0.587514\n",
      "epoch 62; iter: 0; batch classifier loss: 0.470686; batch adversarial loss: 0.524762\n",
      "epoch 63; iter: 0; batch classifier loss: 0.464097; batch adversarial loss: 0.561616\n",
      "epoch 64; iter: 0; batch classifier loss: 0.301721; batch adversarial loss: 0.560215\n",
      "epoch 65; iter: 0; batch classifier loss: 0.485866; batch adversarial loss: 0.617030\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431830; batch adversarial loss: 0.501013\n",
      "epoch 67; iter: 0; batch classifier loss: 0.344690; batch adversarial loss: 0.589670\n",
      "epoch 68; iter: 0; batch classifier loss: 0.458190; batch adversarial loss: 0.534137\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359767; batch adversarial loss: 0.499858\n",
      "epoch 70; iter: 0; batch classifier loss: 0.329885; batch adversarial loss: 0.518489\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410881; batch adversarial loss: 0.577363\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381274; batch adversarial loss: 0.526349\n",
      "epoch 73; iter: 0; batch classifier loss: 0.463811; batch adversarial loss: 0.607257\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427322; batch adversarial loss: 0.590059\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401950; batch adversarial loss: 0.524211\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441520; batch adversarial loss: 0.534781\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408026; batch adversarial loss: 0.568870\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453849; batch adversarial loss: 0.490699\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424202; batch adversarial loss: 0.498909\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419809; batch adversarial loss: 0.559956\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407163; batch adversarial loss: 0.545323\n",
      "epoch 82; iter: 0; batch classifier loss: 0.486113; batch adversarial loss: 0.537842\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426117; batch adversarial loss: 0.607155\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437277; batch adversarial loss: 0.570521\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425520; batch adversarial loss: 0.590150\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409553; batch adversarial loss: 0.571444\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365307; batch adversarial loss: 0.561414\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363637; batch adversarial loss: 0.590660\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366502; batch adversarial loss: 0.527180\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397854; batch adversarial loss: 0.572754\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441791; batch adversarial loss: 0.563369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.466845; batch adversarial loss: 0.523259\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393497; batch adversarial loss: 0.507159\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394680; batch adversarial loss: 0.535340\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431549; batch adversarial loss: 0.571311\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392931; batch adversarial loss: 0.627563\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411299; batch adversarial loss: 0.566652\n",
      "epoch 98; iter: 0; batch classifier loss: 0.436750; batch adversarial loss: 0.632098\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378445; batch adversarial loss: 0.511541\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420573; batch adversarial loss: 0.572133\n",
      "epoch 101; iter: 0; batch classifier loss: 0.436615; batch adversarial loss: 0.471527\n",
      "epoch 102; iter: 0; batch classifier loss: 0.425933; batch adversarial loss: 0.572121\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376921; batch adversarial loss: 0.581249\n",
      "epoch 104; iter: 0; batch classifier loss: 0.337223; batch adversarial loss: 0.563500\n",
      "epoch 105; iter: 0; batch classifier loss: 0.441290; batch adversarial loss: 0.546328\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402837; batch adversarial loss: 0.552395\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355392; batch adversarial loss: 0.524568\n",
      "epoch 108; iter: 0; batch classifier loss: 0.486460; batch adversarial loss: 0.505277\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361419; batch adversarial loss: 0.538484\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348598; batch adversarial loss: 0.480078\n",
      "epoch 111; iter: 0; batch classifier loss: 0.464925; batch adversarial loss: 0.554133\n",
      "epoch 112; iter: 0; batch classifier loss: 0.298618; batch adversarial loss: 0.490527\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390557; batch adversarial loss: 0.527740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384448; batch adversarial loss: 0.570761\n",
      "epoch 115; iter: 0; batch classifier loss: 0.488047; batch adversarial loss: 0.573181\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401049; batch adversarial loss: 0.584038\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381422; batch adversarial loss: 0.571000\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382589; batch adversarial loss: 0.537467\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379337; batch adversarial loss: 0.553758\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374347; batch adversarial loss: 0.609145\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383945; batch adversarial loss: 0.479793\n",
      "epoch 122; iter: 0; batch classifier loss: 0.443135; batch adversarial loss: 0.545389\n",
      "epoch 123; iter: 0; batch classifier loss: 0.358876; batch adversarial loss: 0.518390\n",
      "epoch 124; iter: 0; batch classifier loss: 0.356590; batch adversarial loss: 0.482540\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382799; batch adversarial loss: 0.564353\n",
      "epoch 126; iter: 0; batch classifier loss: 0.352894; batch adversarial loss: 0.535997\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381721; batch adversarial loss: 0.488981\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392419; batch adversarial loss: 0.566623\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391486; batch adversarial loss: 0.573508\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391407; batch adversarial loss: 0.596397\n",
      "epoch 131; iter: 0; batch classifier loss: 0.314245; batch adversarial loss: 0.508539\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401390; batch adversarial loss: 0.499946\n",
      "epoch 133; iter: 0; batch classifier loss: 0.436750; batch adversarial loss: 0.615301\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360866; batch adversarial loss: 0.562351\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389433; batch adversarial loss: 0.488673\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396809; batch adversarial loss: 0.553206\n",
      "epoch 137; iter: 0; batch classifier loss: 0.411490; batch adversarial loss: 0.488271\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351973; batch adversarial loss: 0.535008\n",
      "epoch 139; iter: 0; batch classifier loss: 0.389220; batch adversarial loss: 0.536787\n",
      "epoch 140; iter: 0; batch classifier loss: 0.316923; batch adversarial loss: 0.445825\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379738; batch adversarial loss: 0.454638\n",
      "epoch 142; iter: 0; batch classifier loss: 0.302764; batch adversarial loss: 0.548153\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371279; batch adversarial loss: 0.517079\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382347; batch adversarial loss: 0.617143\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364499; batch adversarial loss: 0.697527\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348243; batch adversarial loss: 0.605942\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344443; batch adversarial loss: 0.582460\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371228; batch adversarial loss: 0.589426\n",
      "epoch 149; iter: 0; batch classifier loss: 0.412664; batch adversarial loss: 0.580083\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382548; batch adversarial loss: 0.556375\n",
      "epoch 151; iter: 0; batch classifier loss: 0.295475; batch adversarial loss: 0.615356\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352953; batch adversarial loss: 0.514079\n",
      "epoch 153; iter: 0; batch classifier loss: 0.332966; batch adversarial loss: 0.507705\n",
      "epoch 154; iter: 0; batch classifier loss: 0.420376; batch adversarial loss: 0.597147\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362016; batch adversarial loss: 0.562405\n",
      "epoch 156; iter: 0; batch classifier loss: 0.287570; batch adversarial loss: 0.562599\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341047; batch adversarial loss: 0.571616\n",
      "epoch 158; iter: 0; batch classifier loss: 0.298874; batch adversarial loss: 0.555403\n",
      "epoch 159; iter: 0; batch classifier loss: 0.318760; batch adversarial loss: 0.545190\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374762; batch adversarial loss: 0.508917\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400052; batch adversarial loss: 0.572323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381434; batch adversarial loss: 0.537382\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419635; batch adversarial loss: 0.552805\n",
      "epoch 164; iter: 0; batch classifier loss: 0.396539; batch adversarial loss: 0.501662\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361241; batch adversarial loss: 0.551881\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364857; batch adversarial loss: 0.510279\n",
      "epoch 167; iter: 0; batch classifier loss: 0.429860; batch adversarial loss: 0.531576\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383281; batch adversarial loss: 0.599876\n",
      "epoch 169; iter: 0; batch classifier loss: 0.338088; batch adversarial loss: 0.498392\n",
      "epoch 170; iter: 0; batch classifier loss: 0.387519; batch adversarial loss: 0.541762\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351938; batch adversarial loss: 0.581382\n",
      "epoch 172; iter: 0; batch classifier loss: 0.457535; batch adversarial loss: 0.580729\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377487; batch adversarial loss: 0.596884\n",
      "epoch 174; iter: 0; batch classifier loss: 0.309736; batch adversarial loss: 0.499549\n",
      "epoch 175; iter: 0; batch classifier loss: 0.312005; batch adversarial loss: 0.589060\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343541; batch adversarial loss: 0.587483\n",
      "epoch 177; iter: 0; batch classifier loss: 0.357995; batch adversarial loss: 0.571023\n",
      "epoch 178; iter: 0; batch classifier loss: 0.435388; batch adversarial loss: 0.516663\n",
      "epoch 179; iter: 0; batch classifier loss: 0.311648; batch adversarial loss: 0.533354\n",
      "epoch 180; iter: 0; batch classifier loss: 0.410923; batch adversarial loss: 0.525409\n",
      "epoch 181; iter: 0; batch classifier loss: 0.391276; batch adversarial loss: 0.519245\n",
      "epoch 182; iter: 0; batch classifier loss: 0.410016; batch adversarial loss: 0.523485\n",
      "epoch 183; iter: 0; batch classifier loss: 0.418167; batch adversarial loss: 0.612841\n",
      "epoch 184; iter: 0; batch classifier loss: 0.469133; batch adversarial loss: 0.616907\n",
      "epoch 185; iter: 0; batch classifier loss: 0.395029; batch adversarial loss: 0.563795\n",
      "epoch 186; iter: 0; batch classifier loss: 0.362100; batch adversarial loss: 0.599398\n",
      "epoch 187; iter: 0; batch classifier loss: 0.436507; batch adversarial loss: 0.495277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.339653; batch adversarial loss: 0.581141\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381377; batch adversarial loss: 0.498928\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357592; batch adversarial loss: 0.578079\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339132; batch adversarial loss: 0.523702\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355061; batch adversarial loss: 0.446326\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296940; batch adversarial loss: 0.599085\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329056; batch adversarial loss: 0.561712\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399547; batch adversarial loss: 0.546081\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369411; batch adversarial loss: 0.532017\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336279; batch adversarial loss: 0.577459\n",
      "epoch 198; iter: 0; batch classifier loss: 0.267059; batch adversarial loss: 0.577486\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397786; batch adversarial loss: 0.642852\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726083; batch adversarial loss: 0.961920\n",
      "epoch 1; iter: 0; batch classifier loss: 0.899666; batch adversarial loss: 1.060873\n",
      "epoch 2; iter: 0; batch classifier loss: 1.005060; batch adversarial loss: 0.971541\n",
      "epoch 3; iter: 0; batch classifier loss: 1.018213; batch adversarial loss: 0.877970\n",
      "epoch 4; iter: 0; batch classifier loss: 1.147943; batch adversarial loss: 0.829274\n",
      "epoch 5; iter: 0; batch classifier loss: 1.007674; batch adversarial loss: 0.765136\n",
      "epoch 6; iter: 0; batch classifier loss: 0.928619; batch adversarial loss: 0.702104\n",
      "epoch 7; iter: 0; batch classifier loss: 0.691601; batch adversarial loss: 0.644172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578419; batch adversarial loss: 0.609074\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520951; batch adversarial loss: 0.575024\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559469; batch adversarial loss: 0.594785\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509673; batch adversarial loss: 0.597202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505514; batch adversarial loss: 0.581351\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549424; batch adversarial loss: 0.516776\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559996; batch adversarial loss: 0.560312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433696; batch adversarial loss: 0.562998\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528708; batch adversarial loss: 0.541019\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484159; batch adversarial loss: 0.524451\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525307; batch adversarial loss: 0.575214\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498885; batch adversarial loss: 0.575644\n",
      "epoch 20; iter: 0; batch classifier loss: 0.620940; batch adversarial loss: 0.553788\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519709; batch adversarial loss: 0.562910\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485754; batch adversarial loss: 0.601195\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526166; batch adversarial loss: 0.524838\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508768; batch adversarial loss: 0.546230\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449380; batch adversarial loss: 0.570571\n",
      "epoch 26; iter: 0; batch classifier loss: 0.558421; batch adversarial loss: 0.480891\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454243; batch adversarial loss: 0.511087\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456853; batch adversarial loss: 0.510095\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507162; batch adversarial loss: 0.493663\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491455; batch adversarial loss: 0.530760\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483148; batch adversarial loss: 0.521628\n",
      "epoch 32; iter: 0; batch classifier loss: 0.557667; batch adversarial loss: 0.557604\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439148; batch adversarial loss: 0.583379\n",
      "epoch 34; iter: 0; batch classifier loss: 0.506169; batch adversarial loss: 0.570574\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469291; batch adversarial loss: 0.519319\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453632; batch adversarial loss: 0.546485\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452407; batch adversarial loss: 0.598233\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441194; batch adversarial loss: 0.622686\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420889; batch adversarial loss: 0.559727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425496; batch adversarial loss: 0.573369\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449336; batch adversarial loss: 0.509740\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419731; batch adversarial loss: 0.601926\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480223; batch adversarial loss: 0.652417\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388636; batch adversarial loss: 0.481722\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478150; batch adversarial loss: 0.553091\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438071; batch adversarial loss: 0.525968\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397588; batch adversarial loss: 0.636934\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402229; batch adversarial loss: 0.645439\n",
      "epoch 49; iter: 0; batch classifier loss: 0.490566; batch adversarial loss: 0.516950\n",
      "epoch 50; iter: 0; batch classifier loss: 0.385180; batch adversarial loss: 0.617625\n",
      "epoch 51; iter: 0; batch classifier loss: 0.355775; batch adversarial loss: 0.490370\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383944; batch adversarial loss: 0.563166\n",
      "epoch 53; iter: 0; batch classifier loss: 0.440456; batch adversarial loss: 0.564318\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467975; batch adversarial loss: 0.554962\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476553; batch adversarial loss: 0.563111\n",
      "epoch 56; iter: 0; batch classifier loss: 0.402081; batch adversarial loss: 0.581220\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407313; batch adversarial loss: 0.508212\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418932; batch adversarial loss: 0.552760\n",
      "epoch 59; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.553882\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437862; batch adversarial loss: 0.525146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421573; batch adversarial loss: 0.486839\n",
      "epoch 62; iter: 0; batch classifier loss: 0.476811; batch adversarial loss: 0.582392\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390917; batch adversarial loss: 0.587880\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382474; batch adversarial loss: 0.554105\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415744; batch adversarial loss: 0.535319\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435327; batch adversarial loss: 0.526861\n",
      "epoch 67; iter: 0; batch classifier loss: 0.473875; batch adversarial loss: 0.480709\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408097; batch adversarial loss: 0.545180\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447327; batch adversarial loss: 0.572799\n",
      "epoch 70; iter: 0; batch classifier loss: 0.367441; batch adversarial loss: 0.578423\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395765; batch adversarial loss: 0.555338\n",
      "epoch 72; iter: 0; batch classifier loss: 0.375339; batch adversarial loss: 0.499810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423524; batch adversarial loss: 0.666214\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444062; batch adversarial loss: 0.551312\n",
      "epoch 75; iter: 0; batch classifier loss: 0.461132; batch adversarial loss: 0.654200\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390932; batch adversarial loss: 0.617829\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406159; batch adversarial loss: 0.619077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444394; batch adversarial loss: 0.535724\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394123; batch adversarial loss: 0.488398\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400586; batch adversarial loss: 0.479534\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375393; batch adversarial loss: 0.537342\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390439; batch adversarial loss: 0.479942\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399694; batch adversarial loss: 0.572419\n",
      "epoch 84; iter: 0; batch classifier loss: 0.359543; batch adversarial loss: 0.570833\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342833; batch adversarial loss: 0.489313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.386467; batch adversarial loss: 0.589082\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367210; batch adversarial loss: 0.563807\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424620; batch adversarial loss: 0.537417\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391989; batch adversarial loss: 0.538367\n",
      "epoch 90; iter: 0; batch classifier loss: 0.519107; batch adversarial loss: 0.463903\n",
      "epoch 91; iter: 0; batch classifier loss: 0.346409; batch adversarial loss: 0.579522\n",
      "epoch 92; iter: 0; batch classifier loss: 0.415097; batch adversarial loss: 0.570679\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413067; batch adversarial loss: 0.587103\n",
      "epoch 94; iter: 0; batch classifier loss: 0.313828; batch adversarial loss: 0.571613\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322928; batch adversarial loss: 0.481878\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361436; batch adversarial loss: 0.517021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.441572; batch adversarial loss: 0.579194\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402812; batch adversarial loss: 0.542732\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382941; batch adversarial loss: 0.561183\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429582; batch adversarial loss: 0.600085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387966; batch adversarial loss: 0.639299\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359715; batch adversarial loss: 0.519390\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346771; batch adversarial loss: 0.540909\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390628; batch adversarial loss: 0.514909\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407955; batch adversarial loss: 0.542866\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382847; batch adversarial loss: 0.590739\n",
      "epoch 107; iter: 0; batch classifier loss: 0.398883; batch adversarial loss: 0.532735\n",
      "epoch 108; iter: 0; batch classifier loss: 0.311204; batch adversarial loss: 0.526263\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345477; batch adversarial loss: 0.504924\n",
      "epoch 110; iter: 0; batch classifier loss: 0.340591; batch adversarial loss: 0.555500\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382579; batch adversarial loss: 0.551926\n",
      "epoch 112; iter: 0; batch classifier loss: 0.407110; batch adversarial loss: 0.496047\n",
      "epoch 113; iter: 0; batch classifier loss: 0.385335; batch adversarial loss: 0.586271\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375322; batch adversarial loss: 0.470007\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407030; batch adversarial loss: 0.584615\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345728; batch adversarial loss: 0.609022\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383569; batch adversarial loss: 0.553521\n",
      "epoch 118; iter: 0; batch classifier loss: 0.428206; batch adversarial loss: 0.556964\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353034; batch adversarial loss: 0.598504\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333006; batch adversarial loss: 0.552364\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376164; batch adversarial loss: 0.494966\n",
      "epoch 122; iter: 0; batch classifier loss: 0.342159; batch adversarial loss: 0.480965\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363462; batch adversarial loss: 0.575169\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329686; batch adversarial loss: 0.655271\n",
      "epoch 125; iter: 0; batch classifier loss: 0.445834; batch adversarial loss: 0.575057\n",
      "epoch 126; iter: 0; batch classifier loss: 0.378909; batch adversarial loss: 0.469485\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346316; batch adversarial loss: 0.571963\n",
      "epoch 128; iter: 0; batch classifier loss: 0.450202; batch adversarial loss: 0.517041\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339073; batch adversarial loss: 0.640162\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354421; batch adversarial loss: 0.628295\n",
      "epoch 131; iter: 0; batch classifier loss: 0.310141; batch adversarial loss: 0.515003\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333868; batch adversarial loss: 0.565178\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341985; batch adversarial loss: 0.467260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382762; batch adversarial loss: 0.570544\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420483; batch adversarial loss: 0.571065\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371514; batch adversarial loss: 0.544973\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370542; batch adversarial loss: 0.599383\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320957; batch adversarial loss: 0.407120\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357278; batch adversarial loss: 0.616820\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366609; batch adversarial loss: 0.608945\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353605; batch adversarial loss: 0.564897\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428197; batch adversarial loss: 0.562370\n",
      "epoch 143; iter: 0; batch classifier loss: 0.278528; batch adversarial loss: 0.536455\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388096; batch adversarial loss: 0.515464\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338899; batch adversarial loss: 0.563896\n",
      "epoch 146; iter: 0; batch classifier loss: 0.301664; batch adversarial loss: 0.562558\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365259; batch adversarial loss: 0.486532\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341651; batch adversarial loss: 0.487741\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315136; batch adversarial loss: 0.480454\n",
      "epoch 150; iter: 0; batch classifier loss: 0.310057; batch adversarial loss: 0.581092\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349030; batch adversarial loss: 0.537934\n",
      "epoch 152; iter: 0; batch classifier loss: 0.293897; batch adversarial loss: 0.537151\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322311; batch adversarial loss: 0.547916\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298989; batch adversarial loss: 0.599943\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352392; batch adversarial loss: 0.552948\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373839; batch adversarial loss: 0.571059\n",
      "epoch 157; iter: 0; batch classifier loss: 0.387038; batch adversarial loss: 0.566408\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391535; batch adversarial loss: 0.478950\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382779; batch adversarial loss: 0.537571\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323498; batch adversarial loss: 0.524474\n",
      "epoch 161; iter: 0; batch classifier loss: 0.302883; batch adversarial loss: 0.536561\n",
      "epoch 162; iter: 0; batch classifier loss: 0.310771; batch adversarial loss: 0.634113\n",
      "epoch 163; iter: 0; batch classifier loss: 0.302068; batch adversarial loss: 0.580702\n",
      "epoch 164; iter: 0; batch classifier loss: 0.307935; batch adversarial loss: 0.531009\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374375; batch adversarial loss: 0.555153\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341865; batch adversarial loss: 0.511119\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328742; batch adversarial loss: 0.515808\n",
      "epoch 168; iter: 0; batch classifier loss: 0.405137; batch adversarial loss: 0.563406\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330325; batch adversarial loss: 0.500364\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329241; batch adversarial loss: 0.528203\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325907; batch adversarial loss: 0.574117\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332950; batch adversarial loss: 0.488035\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345996; batch adversarial loss: 0.561851\n",
      "epoch 174; iter: 0; batch classifier loss: 0.382164; batch adversarial loss: 0.552474\n",
      "epoch 175; iter: 0; batch classifier loss: 0.447059; batch adversarial loss: 0.482030\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378272; batch adversarial loss: 0.592662\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356862; batch adversarial loss: 0.609863\n",
      "epoch 178; iter: 0; batch classifier loss: 0.327012; batch adversarial loss: 0.578511\n",
      "epoch 179; iter: 0; batch classifier loss: 0.261144; batch adversarial loss: 0.589463\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315965; batch adversarial loss: 0.514700\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384027; batch adversarial loss: 0.500034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.282429; batch adversarial loss: 0.533375\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366889; batch adversarial loss: 0.507512\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331214; batch adversarial loss: 0.545725\n",
      "epoch 185; iter: 0; batch classifier loss: 0.304759; batch adversarial loss: 0.581738\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346190; batch adversarial loss: 0.506874\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353794; batch adversarial loss: 0.498439\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314104; batch adversarial loss: 0.496551\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358712; batch adversarial loss: 0.556460\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386466; batch adversarial loss: 0.534504\n",
      "epoch 191; iter: 0; batch classifier loss: 0.288406; batch adversarial loss: 0.562774\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357205; batch adversarial loss: 0.472042\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314781; batch adversarial loss: 0.509600\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314047; batch adversarial loss: 0.478240\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325827; batch adversarial loss: 0.477861\n",
      "epoch 196; iter: 0; batch classifier loss: 0.317129; batch adversarial loss: 0.488247\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318811; batch adversarial loss: 0.544107\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347801; batch adversarial loss: 0.579288\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323788; batch adversarial loss: 0.504202\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677662; batch adversarial loss: 0.612911\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621991; batch adversarial loss: 0.658445\n",
      "epoch 2; iter: 0; batch classifier loss: 0.538423; batch adversarial loss: 0.653758\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588685; batch adversarial loss: 0.631748\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557397; batch adversarial loss: 0.609634\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544114; batch adversarial loss: 0.618963\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567530; batch adversarial loss: 0.612268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556208; batch adversarial loss: 0.631190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514857; batch adversarial loss: 0.632457\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598633; batch adversarial loss: 0.615996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507022; batch adversarial loss: 0.598341\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563678; batch adversarial loss: 0.597879\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525074; batch adversarial loss: 0.585103\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483155; batch adversarial loss: 0.609667\n",
      "epoch 14; iter: 0; batch classifier loss: 0.460544; batch adversarial loss: 0.528650\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578464; batch adversarial loss: 0.558478\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564148; batch adversarial loss: 0.530860\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477808; batch adversarial loss: 0.498170\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518083; batch adversarial loss: 0.552281\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465870; batch adversarial loss: 0.495589\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484858; batch adversarial loss: 0.588535\n",
      "epoch 21; iter: 0; batch classifier loss: 0.449277; batch adversarial loss: 0.544920\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573149; batch adversarial loss: 0.556725\n",
      "epoch 23; iter: 0; batch classifier loss: 0.575049; batch adversarial loss: 0.562137\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433236; batch adversarial loss: 0.581107\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455991; batch adversarial loss: 0.506493\n",
      "epoch 26; iter: 0; batch classifier loss: 0.538986; batch adversarial loss: 0.571059\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518484; batch adversarial loss: 0.570504\n",
      "epoch 28; iter: 0; batch classifier loss: 0.536684; batch adversarial loss: 0.545443\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450334; batch adversarial loss: 0.519297\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458929; batch adversarial loss: 0.493397\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435331; batch adversarial loss: 0.562462\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430308; batch adversarial loss: 0.527507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.533603; batch adversarial loss: 0.580281\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453397; batch adversarial loss: 0.632340\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452482; batch adversarial loss: 0.587814\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473664; batch adversarial loss: 0.560161\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456883; batch adversarial loss: 0.577653\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474696; batch adversarial loss: 0.606038\n",
      "epoch 39; iter: 0; batch classifier loss: 0.394191; batch adversarial loss: 0.595583\n",
      "epoch 40; iter: 0; batch classifier loss: 0.357758; batch adversarial loss: 0.519113\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446406; batch adversarial loss: 0.577098\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429340; batch adversarial loss: 0.527162\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438453; batch adversarial loss: 0.537006\n",
      "epoch 44; iter: 0; batch classifier loss: 0.380315; batch adversarial loss: 0.513490\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426792; batch adversarial loss: 0.586053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440192; batch adversarial loss: 0.441028\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407477; batch adversarial loss: 0.530072\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495531; batch adversarial loss: 0.509522\n",
      "epoch 49; iter: 0; batch classifier loss: 0.501555; batch adversarial loss: 0.542733\n",
      "epoch 50; iter: 0; batch classifier loss: 0.500635; batch adversarial loss: 0.599113\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438267; batch adversarial loss: 0.540815\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439182; batch adversarial loss: 0.597485\n",
      "epoch 53; iter: 0; batch classifier loss: 0.453725; batch adversarial loss: 0.597574\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425817; batch adversarial loss: 0.527650\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440538; batch adversarial loss: 0.470355\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409527; batch adversarial loss: 0.594352\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399245; batch adversarial loss: 0.535093\n",
      "epoch 58; iter: 0; batch classifier loss: 0.346414; batch adversarial loss: 0.487429\n",
      "epoch 59; iter: 0; batch classifier loss: 0.486112; batch adversarial loss: 0.506551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467355; batch adversarial loss: 0.543696\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430682; batch adversarial loss: 0.478687\n",
      "epoch 62; iter: 0; batch classifier loss: 0.469323; batch adversarial loss: 0.545375\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377225; batch adversarial loss: 0.610991\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372708; batch adversarial loss: 0.507740\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411293; batch adversarial loss: 0.562366\n",
      "epoch 66; iter: 0; batch classifier loss: 0.394059; batch adversarial loss: 0.581795\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429919; batch adversarial loss: 0.487335\n",
      "epoch 68; iter: 0; batch classifier loss: 0.457065; batch adversarial loss: 0.543988\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418956; batch adversarial loss: 0.518421\n",
      "epoch 70; iter: 0; batch classifier loss: 0.530329; batch adversarial loss: 0.508455\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414321; batch adversarial loss: 0.555095\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447150; batch adversarial loss: 0.590053\n",
      "epoch 73; iter: 0; batch classifier loss: 0.307134; batch adversarial loss: 0.561604\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389688; batch adversarial loss: 0.571634\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373584; batch adversarial loss: 0.627920\n",
      "epoch 76; iter: 0; batch classifier loss: 0.428988; batch adversarial loss: 0.536394\n",
      "epoch 77; iter: 0; batch classifier loss: 0.447065; batch adversarial loss: 0.553628\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379761; batch adversarial loss: 0.629139\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393998; batch adversarial loss: 0.580404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.403764; batch adversarial loss: 0.499673\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421256; batch adversarial loss: 0.490743\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408426; batch adversarial loss: 0.558503\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378895; batch adversarial loss: 0.560949\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372415; batch adversarial loss: 0.498080\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452734; batch adversarial loss: 0.505425\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411219; batch adversarial loss: 0.478237\n",
      "epoch 87; iter: 0; batch classifier loss: 0.459939; batch adversarial loss: 0.563513\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377126; batch adversarial loss: 0.572876\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388300; batch adversarial loss: 0.515998\n",
      "epoch 90; iter: 0; batch classifier loss: 0.446655; batch adversarial loss: 0.574049\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372677; batch adversarial loss: 0.473492\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373474; batch adversarial loss: 0.561643\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400814; batch adversarial loss: 0.498688\n",
      "epoch 94; iter: 0; batch classifier loss: 0.330898; batch adversarial loss: 0.638436\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395249; batch adversarial loss: 0.554218\n",
      "epoch 96; iter: 0; batch classifier loss: 0.533444; batch adversarial loss: 0.487397\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405342; batch adversarial loss: 0.598887\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406030; batch adversarial loss: 0.497330\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357386; batch adversarial loss: 0.508149\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424130; batch adversarial loss: 0.516086\n",
      "epoch 101; iter: 0; batch classifier loss: 0.432389; batch adversarial loss: 0.555822\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394004; batch adversarial loss: 0.488083\n",
      "epoch 103; iter: 0; batch classifier loss: 0.495863; batch adversarial loss: 0.562432\n",
      "epoch 104; iter: 0; batch classifier loss: 0.449403; batch adversarial loss: 0.599426\n",
      "epoch 105; iter: 0; batch classifier loss: 0.321727; batch adversarial loss: 0.535280\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385707; batch adversarial loss: 0.507858\n",
      "epoch 107; iter: 0; batch classifier loss: 0.408103; batch adversarial loss: 0.543260\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421246; batch adversarial loss: 0.564973\n",
      "epoch 109; iter: 0; batch classifier loss: 0.335684; batch adversarial loss: 0.551119\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350606; batch adversarial loss: 0.634743\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318550; batch adversarial loss: 0.524451\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376608; batch adversarial loss: 0.535357\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335152; batch adversarial loss: 0.497132\n",
      "epoch 114; iter: 0; batch classifier loss: 0.336957; batch adversarial loss: 0.601115\n",
      "epoch 115; iter: 0; batch classifier loss: 0.484473; batch adversarial loss: 0.589243\n",
      "epoch 116; iter: 0; batch classifier loss: 0.454692; batch adversarial loss: 0.495963\n",
      "epoch 117; iter: 0; batch classifier loss: 0.453546; batch adversarial loss: 0.544456\n",
      "epoch 118; iter: 0; batch classifier loss: 0.431276; batch adversarial loss: 0.563324\n",
      "epoch 119; iter: 0; batch classifier loss: 0.411948; batch adversarial loss: 0.544363\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407211; batch adversarial loss: 0.537391\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346284; batch adversarial loss: 0.515900\n",
      "epoch 122; iter: 0; batch classifier loss: 0.319418; batch adversarial loss: 0.610628\n",
      "epoch 123; iter: 0; batch classifier loss: 0.471189; batch adversarial loss: 0.573811\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365995; batch adversarial loss: 0.619163\n",
      "epoch 125; iter: 0; batch classifier loss: 0.319322; batch adversarial loss: 0.553990\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330289; batch adversarial loss: 0.588384\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370514; batch adversarial loss: 0.543783\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381234; batch adversarial loss: 0.552722\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377336; batch adversarial loss: 0.580352\n",
      "epoch 130; iter: 0; batch classifier loss: 0.451094; batch adversarial loss: 0.534872\n",
      "epoch 131; iter: 0; batch classifier loss: 0.416135; batch adversarial loss: 0.517440\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384804; batch adversarial loss: 0.508339\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360442; batch adversarial loss: 0.571137\n",
      "epoch 134; iter: 0; batch classifier loss: 0.412016; batch adversarial loss: 0.526903\n",
      "epoch 135; iter: 0; batch classifier loss: 0.418124; batch adversarial loss: 0.527438\n",
      "epoch 136; iter: 0; batch classifier loss: 0.419447; batch adversarial loss: 0.471298\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390842; batch adversarial loss: 0.554147\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370013; batch adversarial loss: 0.525107\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428352; batch adversarial loss: 0.609129\n",
      "epoch 140; iter: 0; batch classifier loss: 0.453290; batch adversarial loss: 0.526891\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346294; batch adversarial loss: 0.610381\n",
      "epoch 142; iter: 0; batch classifier loss: 0.382904; batch adversarial loss: 0.497684\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401450; batch adversarial loss: 0.525715\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366598; batch adversarial loss: 0.526048\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359454; batch adversarial loss: 0.588948\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359795; batch adversarial loss: 0.527030\n",
      "epoch 147; iter: 0; batch classifier loss: 0.487323; batch adversarial loss: 0.534098\n",
      "epoch 148; iter: 0; batch classifier loss: 0.406873; batch adversarial loss: 0.533444\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350783; batch adversarial loss: 0.526518\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372392; batch adversarial loss: 0.535339\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330317; batch adversarial loss: 0.506152\n",
      "epoch 152; iter: 0; batch classifier loss: 0.421923; batch adversarial loss: 0.533991\n",
      "epoch 153; iter: 0; batch classifier loss: 0.319445; batch adversarial loss: 0.523416\n",
      "epoch 154; iter: 0; batch classifier loss: 0.442506; batch adversarial loss: 0.497178\n",
      "epoch 155; iter: 0; batch classifier loss: 0.375178; batch adversarial loss: 0.534945\n",
      "epoch 156; iter: 0; batch classifier loss: 0.290492; batch adversarial loss: 0.562536\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351803; batch adversarial loss: 0.459971\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345068; batch adversarial loss: 0.619519\n",
      "epoch 159; iter: 0; batch classifier loss: 0.437522; batch adversarial loss: 0.599117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351172; batch adversarial loss: 0.572709\n",
      "epoch 161; iter: 0; batch classifier loss: 0.352667; batch adversarial loss: 0.545809\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344892; batch adversarial loss: 0.490985\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355478; batch adversarial loss: 0.544574\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313027; batch adversarial loss: 0.451364\n",
      "epoch 165; iter: 0; batch classifier loss: 0.290887; batch adversarial loss: 0.583930\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312130; batch adversarial loss: 0.529615\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364690; batch adversarial loss: 0.542801\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401782; batch adversarial loss: 0.559391\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355058; batch adversarial loss: 0.553631\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315897; batch adversarial loss: 0.517180\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385841; batch adversarial loss: 0.561375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328210; batch adversarial loss: 0.497841\n",
      "epoch 173; iter: 0; batch classifier loss: 0.330076; batch adversarial loss: 0.537703\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373565; batch adversarial loss: 0.507799\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382276; batch adversarial loss: 0.487008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.407247; batch adversarial loss: 0.599838\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381521; batch adversarial loss: 0.507462\n",
      "epoch 178; iter: 0; batch classifier loss: 0.319408; batch adversarial loss: 0.496215\n",
      "epoch 179; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.544459\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364014; batch adversarial loss: 0.460299\n",
      "epoch 181; iter: 0; batch classifier loss: 0.417112; batch adversarial loss: 0.488704\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352526; batch adversarial loss: 0.600604\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367456; batch adversarial loss: 0.525387\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348730; batch adversarial loss: 0.609056\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332438; batch adversarial loss: 0.571818\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400258; batch adversarial loss: 0.523356\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329828; batch adversarial loss: 0.611929\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353507; batch adversarial loss: 0.591798\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375763; batch adversarial loss: 0.525241\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379963; batch adversarial loss: 0.600234\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352548; batch adversarial loss: 0.617783\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396316; batch adversarial loss: 0.552657\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390649; batch adversarial loss: 0.499112\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332556; batch adversarial loss: 0.583527\n",
      "epoch 195; iter: 0; batch classifier loss: 0.417682; batch adversarial loss: 0.533856\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360454; batch adversarial loss: 0.580199\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340902; batch adversarial loss: 0.515102\n",
      "epoch 198; iter: 0; batch classifier loss: 0.275031; batch adversarial loss: 0.534454\n",
      "epoch 199; iter: 0; batch classifier loss: 0.355975; batch adversarial loss: 0.516155\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653335; batch adversarial loss: 0.674871\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571656; batch adversarial loss: 0.659778\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553935; batch adversarial loss: 0.656071\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586558; batch adversarial loss: 0.609996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596442; batch adversarial loss: 0.586432\n",
      "epoch 5; iter: 0; batch classifier loss: 0.618584; batch adversarial loss: 0.617791\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573012; batch adversarial loss: 0.638401\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508881; batch adversarial loss: 0.589691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538616; batch adversarial loss: 0.634738\n",
      "epoch 9; iter: 0; batch classifier loss: 0.617719; batch adversarial loss: 0.590779\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551680; batch adversarial loss: 0.605619\n",
      "epoch 11; iter: 0; batch classifier loss: 0.479464; batch adversarial loss: 0.559392\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506017; batch adversarial loss: 0.576271\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502694; batch adversarial loss: 0.588992\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498959; batch adversarial loss: 0.655100\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550826; batch adversarial loss: 0.567752\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508585; batch adversarial loss: 0.631291\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481554; batch adversarial loss: 0.601597\n",
      "epoch 18; iter: 0; batch classifier loss: 0.447301; batch adversarial loss: 0.562830\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487790; batch adversarial loss: 0.562109\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492898; batch adversarial loss: 0.637366\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403601; batch adversarial loss: 0.586822\n",
      "epoch 22; iter: 0; batch classifier loss: 0.537485; batch adversarial loss: 0.556311\n",
      "epoch 23; iter: 0; batch classifier loss: 0.424526; batch adversarial loss: 0.567690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487475; batch adversarial loss: 0.564734\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436982; batch adversarial loss: 0.513981\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560027; batch adversarial loss: 0.544128\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467288; batch adversarial loss: 0.488158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441048; batch adversarial loss: 0.587129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509770; batch adversarial loss: 0.556335\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428189; batch adversarial loss: 0.588074\n",
      "epoch 31; iter: 0; batch classifier loss: 0.404841; batch adversarial loss: 0.594758\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439824; batch adversarial loss: 0.596784\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462236; batch adversarial loss: 0.588193\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501499; batch adversarial loss: 0.570824\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457795; batch adversarial loss: 0.577971\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418948; batch adversarial loss: 0.588352\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477173; batch adversarial loss: 0.620201\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418695; batch adversarial loss: 0.529308\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451837; batch adversarial loss: 0.613604\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413585; batch adversarial loss: 0.550296\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499287; batch adversarial loss: 0.612717\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497702; batch adversarial loss: 0.527585\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491627; batch adversarial loss: 0.538283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358062; batch adversarial loss: 0.563127\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477563; batch adversarial loss: 0.554521\n",
      "epoch 46; iter: 0; batch classifier loss: 0.472401; batch adversarial loss: 0.546696\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421019; batch adversarial loss: 0.606086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418006; batch adversarial loss: 0.494162\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385097; batch adversarial loss: 0.537561\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378756; batch adversarial loss: 0.597552\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447105; batch adversarial loss: 0.562919\n",
      "epoch 52; iter: 0; batch classifier loss: 0.453551; batch adversarial loss: 0.587795\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393440; batch adversarial loss: 0.572216\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439296; batch adversarial loss: 0.581148\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465746; batch adversarial loss: 0.522553\n",
      "epoch 56; iter: 0; batch classifier loss: 0.295894; batch adversarial loss: 0.594028\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390750; batch adversarial loss: 0.588228\n",
      "epoch 58; iter: 0; batch classifier loss: 0.334092; batch adversarial loss: 0.595879\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433222; batch adversarial loss: 0.493649\n",
      "epoch 60; iter: 0; batch classifier loss: 0.507865; batch adversarial loss: 0.572540\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417264; batch adversarial loss: 0.603881\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417703; batch adversarial loss: 0.603398\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406642; batch adversarial loss: 0.527187\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408939; batch adversarial loss: 0.572154\n",
      "epoch 65; iter: 0; batch classifier loss: 0.494760; batch adversarial loss: 0.449049\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430500; batch adversarial loss: 0.554103\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385110; batch adversarial loss: 0.536298\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402326; batch adversarial loss: 0.520243\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436645; batch adversarial loss: 0.623228\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465017; batch adversarial loss: 0.582267\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426954; batch adversarial loss: 0.494793\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391737; batch adversarial loss: 0.580043\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380647; batch adversarial loss: 0.603354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.449739; batch adversarial loss: 0.597063\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371280; batch adversarial loss: 0.562665\n",
      "epoch 76; iter: 0; batch classifier loss: 0.455323; batch adversarial loss: 0.623504\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364478; batch adversarial loss: 0.536476\n",
      "epoch 78; iter: 0; batch classifier loss: 0.318543; batch adversarial loss: 0.544831\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378466; batch adversarial loss: 0.597110\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437623; batch adversarial loss: 0.610414\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427477; batch adversarial loss: 0.520536\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421688; batch adversarial loss: 0.542823\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384275; batch adversarial loss: 0.573334\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354427; batch adversarial loss: 0.537727\n",
      "epoch 85; iter: 0; batch classifier loss: 0.265693; batch adversarial loss: 0.595554\n",
      "epoch 86; iter: 0; batch classifier loss: 0.460915; batch adversarial loss: 0.563789\n",
      "epoch 87; iter: 0; batch classifier loss: 0.338054; batch adversarial loss: 0.544416\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349242; batch adversarial loss: 0.606716\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428285; batch adversarial loss: 0.588291\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368311; batch adversarial loss: 0.543291\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364782; batch adversarial loss: 0.561829\n",
      "epoch 92; iter: 0; batch classifier loss: 0.335565; batch adversarial loss: 0.711566\n",
      "epoch 93; iter: 0; batch classifier loss: 0.459640; batch adversarial loss: 0.607097\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430711; batch adversarial loss: 0.509484\n",
      "epoch 95; iter: 0; batch classifier loss: 0.297026; batch adversarial loss: 0.564943\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367361; batch adversarial loss: 0.605368\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378830; batch adversarial loss: 0.542755\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376952; batch adversarial loss: 0.536776\n",
      "epoch 99; iter: 0; batch classifier loss: 0.372833; batch adversarial loss: 0.594698\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393013; batch adversarial loss: 0.620960\n",
      "epoch 101; iter: 0; batch classifier loss: 0.331133; batch adversarial loss: 0.613983\n",
      "epoch 102; iter: 0; batch classifier loss: 0.434551; batch adversarial loss: 0.596166\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377669; batch adversarial loss: 0.603606\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390034; batch adversarial loss: 0.553058\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352504; batch adversarial loss: 0.520095\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398436; batch adversarial loss: 0.520206\n",
      "epoch 107; iter: 0; batch classifier loss: 0.395540; batch adversarial loss: 0.538376\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351219; batch adversarial loss: 0.552327\n",
      "epoch 109; iter: 0; batch classifier loss: 0.425255; batch adversarial loss: 0.645247\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372976; batch adversarial loss: 0.588622\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386539; batch adversarial loss: 0.551362\n",
      "epoch 112; iter: 0; batch classifier loss: 0.373386; batch adversarial loss: 0.532430\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396403; batch adversarial loss: 0.649386\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386716; batch adversarial loss: 0.519034\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352836; batch adversarial loss: 0.555932\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390090; batch adversarial loss: 0.516241\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367014; batch adversarial loss: 0.590087\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326583; batch adversarial loss: 0.532045\n",
      "epoch 119; iter: 0; batch classifier loss: 0.401280; batch adversarial loss: 0.629520\n",
      "epoch 120; iter: 0; batch classifier loss: 0.296346; batch adversarial loss: 0.536967\n",
      "epoch 121; iter: 0; batch classifier loss: 0.327852; batch adversarial loss: 0.501736\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383705; batch adversarial loss: 0.527516\n",
      "epoch 123; iter: 0; batch classifier loss: 0.417560; batch adversarial loss: 0.527642\n",
      "epoch 124; iter: 0; batch classifier loss: 0.455691; batch adversarial loss: 0.584396\n",
      "epoch 125; iter: 0; batch classifier loss: 0.358447; batch adversarial loss: 0.564812\n",
      "epoch 126; iter: 0; batch classifier loss: 0.417623; batch adversarial loss: 0.625254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369292; batch adversarial loss: 0.573488\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381511; batch adversarial loss: 0.595041\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372761; batch adversarial loss: 0.582737\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355434; batch adversarial loss: 0.574879\n",
      "epoch 131; iter: 0; batch classifier loss: 0.423696; batch adversarial loss: 0.547863\n",
      "epoch 132; iter: 0; batch classifier loss: 0.433181; batch adversarial loss: 0.544990\n",
      "epoch 133; iter: 0; batch classifier loss: 0.307842; batch adversarial loss: 0.618254\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368287; batch adversarial loss: 0.572294\n",
      "epoch 135; iter: 0; batch classifier loss: 0.355299; batch adversarial loss: 0.548833\n",
      "epoch 136; iter: 0; batch classifier loss: 0.301964; batch adversarial loss: 0.547420\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382707; batch adversarial loss: 0.547337\n",
      "epoch 138; iter: 0; batch classifier loss: 0.316802; batch adversarial loss: 0.510759\n",
      "epoch 139; iter: 0; batch classifier loss: 0.424152; batch adversarial loss: 0.519707\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348483; batch adversarial loss: 0.524660\n",
      "epoch 141; iter: 0; batch classifier loss: 0.270132; batch adversarial loss: 0.591154\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392360; batch adversarial loss: 0.568064\n",
      "epoch 143; iter: 0; batch classifier loss: 0.323924; batch adversarial loss: 0.596224\n",
      "epoch 144; iter: 0; batch classifier loss: 0.436484; batch adversarial loss: 0.525093\n",
      "epoch 145; iter: 0; batch classifier loss: 0.395091; batch adversarial loss: 0.614698\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352720; batch adversarial loss: 0.555942\n",
      "epoch 147; iter: 0; batch classifier loss: 0.451250; batch adversarial loss: 0.494594\n",
      "epoch 148; iter: 0; batch classifier loss: 0.419153; batch adversarial loss: 0.595098\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375434; batch adversarial loss: 0.512513\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388094; batch adversarial loss: 0.587660\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374484; batch adversarial loss: 0.602578\n",
      "epoch 152; iter: 0; batch classifier loss: 0.285368; batch adversarial loss: 0.546611\n",
      "epoch 153; iter: 0; batch classifier loss: 0.416373; batch adversarial loss: 0.625170\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394870; batch adversarial loss: 0.578537\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324109; batch adversarial loss: 0.659848\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403674; batch adversarial loss: 0.571515\n",
      "epoch 157; iter: 0; batch classifier loss: 0.275484; batch adversarial loss: 0.601918\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345797; batch adversarial loss: 0.590068\n",
      "epoch 159; iter: 0; batch classifier loss: 0.318993; batch adversarial loss: 0.613389\n",
      "epoch 160; iter: 0; batch classifier loss: 0.291856; batch adversarial loss: 0.593663\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355162; batch adversarial loss: 0.535057\n",
      "epoch 162; iter: 0; batch classifier loss: 0.338390; batch adversarial loss: 0.519127\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331214; batch adversarial loss: 0.636899\n",
      "epoch 164; iter: 0; batch classifier loss: 0.273627; batch adversarial loss: 0.620841\n",
      "epoch 165; iter: 0; batch classifier loss: 0.422891; batch adversarial loss: 0.556514\n",
      "epoch 166; iter: 0; batch classifier loss: 0.428567; batch adversarial loss: 0.567410\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382492; batch adversarial loss: 0.560351\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345797; batch adversarial loss: 0.537286\n",
      "epoch 169; iter: 0; batch classifier loss: 0.345813; batch adversarial loss: 0.615048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.419481; batch adversarial loss: 0.573751\n",
      "epoch 171; iter: 0; batch classifier loss: 0.461486; batch adversarial loss: 0.534691\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322111; batch adversarial loss: 0.608886\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392815; batch adversarial loss: 0.502342\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377267; batch adversarial loss: 0.556004\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321974; batch adversarial loss: 0.610688\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358306; batch adversarial loss: 0.594810\n",
      "epoch 177; iter: 0; batch classifier loss: 0.311096; batch adversarial loss: 0.524902\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317306; batch adversarial loss: 0.581367\n",
      "epoch 179; iter: 0; batch classifier loss: 0.276706; batch adversarial loss: 0.535549\n",
      "epoch 180; iter: 0; batch classifier loss: 0.283934; batch adversarial loss: 0.680922\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377347; batch adversarial loss: 0.518723\n",
      "epoch 182; iter: 0; batch classifier loss: 0.392511; batch adversarial loss: 0.576403\n",
      "epoch 183; iter: 0; batch classifier loss: 0.472011; batch adversarial loss: 0.517072\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351134; batch adversarial loss: 0.588441\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402191; batch adversarial loss: 0.594916\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381419; batch adversarial loss: 0.544117\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398210; batch adversarial loss: 0.627265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369931; batch adversarial loss: 0.568713\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350001; batch adversarial loss: 0.631822\n",
      "epoch 190; iter: 0; batch classifier loss: 0.388955; batch adversarial loss: 0.569974\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337014; batch adversarial loss: 0.575502\n",
      "epoch 192; iter: 0; batch classifier loss: 0.283884; batch adversarial loss: 0.543161\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370190; batch adversarial loss: 0.535750\n",
      "epoch 194; iter: 0; batch classifier loss: 0.459829; batch adversarial loss: 0.502314\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349851; batch adversarial loss: 0.606706\n",
      "epoch 196; iter: 0; batch classifier loss: 0.397164; batch adversarial loss: 0.547189\n",
      "epoch 197; iter: 0; batch classifier loss: 0.428014; batch adversarial loss: 0.610852\n",
      "epoch 198; iter: 0; batch classifier loss: 0.344585; batch adversarial loss: 0.544285\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328887; batch adversarial loss: 0.462208\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692448; batch adversarial loss: 0.635413\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581936; batch adversarial loss: 0.666462\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571048; batch adversarial loss: 0.663233\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637210; batch adversarial loss: 0.612236\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590152; batch adversarial loss: 0.614670\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643921; batch adversarial loss: 0.583994\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584741; batch adversarial loss: 0.670593\n",
      "epoch 7; iter: 0; batch classifier loss: 0.585970; batch adversarial loss: 0.600596\n",
      "epoch 8; iter: 0; batch classifier loss: 0.647192; batch adversarial loss: 0.618226\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520019; batch adversarial loss: 0.607467\n",
      "epoch 10; iter: 0; batch classifier loss: 0.598744; batch adversarial loss: 0.609218\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574829; batch adversarial loss: 0.579732\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502018; batch adversarial loss: 0.610365\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549678; batch adversarial loss: 0.571284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477320; batch adversarial loss: 0.596054\n",
      "epoch 15; iter: 0; batch classifier loss: 0.595580; batch adversarial loss: 0.625974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538286; batch adversarial loss: 0.596051\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528549; batch adversarial loss: 0.609312\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464112; batch adversarial loss: 0.560573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426833; batch adversarial loss: 0.601864\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436191; batch adversarial loss: 0.588469\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525269; batch adversarial loss: 0.575187\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469829; batch adversarial loss: 0.567496\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488103; batch adversarial loss: 0.611531\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514986; batch adversarial loss: 0.475814\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417507; batch adversarial loss: 0.539151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465853; batch adversarial loss: 0.490648\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499154; batch adversarial loss: 0.528578\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484787; batch adversarial loss: 0.550661\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440266; batch adversarial loss: 0.504048\n",
      "epoch 30; iter: 0; batch classifier loss: 0.447821; batch adversarial loss: 0.573244\n",
      "epoch 31; iter: 0; batch classifier loss: 0.540791; batch adversarial loss: 0.500269\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438162; batch adversarial loss: 0.553985\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433965; batch adversarial loss: 0.474706\n",
      "epoch 34; iter: 0; batch classifier loss: 0.525099; batch adversarial loss: 0.543386\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504053; batch adversarial loss: 0.428266\n",
      "epoch 36; iter: 0; batch classifier loss: 0.411856; batch adversarial loss: 0.571177\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462324; batch adversarial loss: 0.500227\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464244; batch adversarial loss: 0.580881\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503454; batch adversarial loss: 0.499751\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407875; batch adversarial loss: 0.563443\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425270; batch adversarial loss: 0.535916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452906; batch adversarial loss: 0.553342\n",
      "epoch 43; iter: 0; batch classifier loss: 0.507732; batch adversarial loss: 0.553997\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462339; batch adversarial loss: 0.572661\n",
      "epoch 45; iter: 0; batch classifier loss: 0.356926; batch adversarial loss: 0.470292\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428717; batch adversarial loss: 0.462013\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393700; batch adversarial loss: 0.589736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454540; batch adversarial loss: 0.536581\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451238; batch adversarial loss: 0.553821\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441287; batch adversarial loss: 0.562816\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441957; batch adversarial loss: 0.572129\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375317; batch adversarial loss: 0.675167\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383262; batch adversarial loss: 0.553554\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412235; batch adversarial loss: 0.536219\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440711; batch adversarial loss: 0.498087\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417048; batch adversarial loss: 0.553239\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457218; batch adversarial loss: 0.554327\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442707; batch adversarial loss: 0.507575\n",
      "epoch 59; iter: 0; batch classifier loss: 0.405984; batch adversarial loss: 0.552875\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386341; batch adversarial loss: 0.545918\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428396; batch adversarial loss: 0.517516\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438271; batch adversarial loss: 0.592885\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428864; batch adversarial loss: 0.489372\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411928; batch adversarial loss: 0.535373\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441000; batch adversarial loss: 0.535656\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400849; batch adversarial loss: 0.499235\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460790; batch adversarial loss: 0.508660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.419824; batch adversarial loss: 0.554328\n",
      "epoch 69; iter: 0; batch classifier loss: 0.458941; batch adversarial loss: 0.469043\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464325; batch adversarial loss: 0.694097\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351493; batch adversarial loss: 0.497465\n",
      "epoch 72; iter: 0; batch classifier loss: 0.514525; batch adversarial loss: 0.460117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.364074; batch adversarial loss: 0.553595\n",
      "epoch 74; iter: 0; batch classifier loss: 0.503738; batch adversarial loss: 0.563680\n",
      "epoch 75; iter: 0; batch classifier loss: 0.302695; batch adversarial loss: 0.609764\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412034; batch adversarial loss: 0.497433\n",
      "epoch 77; iter: 0; batch classifier loss: 0.446600; batch adversarial loss: 0.544161\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405892; batch adversarial loss: 0.525876\n",
      "epoch 79; iter: 0; batch classifier loss: 0.442674; batch adversarial loss: 0.563145\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394183; batch adversarial loss: 0.451608\n",
      "epoch 81; iter: 0; batch classifier loss: 0.490534; batch adversarial loss: 0.647326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.449110; batch adversarial loss: 0.544159\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358419; batch adversarial loss: 0.562909\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378350; batch adversarial loss: 0.498185\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381753; batch adversarial loss: 0.516533\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432512; batch adversarial loss: 0.655515\n",
      "epoch 87; iter: 0; batch classifier loss: 0.349954; batch adversarial loss: 0.600272\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413839; batch adversarial loss: 0.553910\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410672; batch adversarial loss: 0.571222\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430209; batch adversarial loss: 0.498896\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400292; batch adversarial loss: 0.617582\n",
      "epoch 92; iter: 0; batch classifier loss: 0.461687; batch adversarial loss: 0.535788\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397975; batch adversarial loss: 0.535066\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396276; batch adversarial loss: 0.506519\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419139; batch adversarial loss: 0.525004\n",
      "epoch 96; iter: 0; batch classifier loss: 0.427819; batch adversarial loss: 0.561881\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365678; batch adversarial loss: 0.544653\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368874; batch adversarial loss: 0.609976\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399895; batch adversarial loss: 0.543794\n",
      "epoch 100; iter: 0; batch classifier loss: 0.369578; batch adversarial loss: 0.546271\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324140; batch adversarial loss: 0.468662\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412209; batch adversarial loss: 0.526040\n",
      "epoch 103; iter: 0; batch classifier loss: 0.293977; batch adversarial loss: 0.544628\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415583; batch adversarial loss: 0.573160\n",
      "epoch 105; iter: 0; batch classifier loss: 0.457698; batch adversarial loss: 0.535182\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374634; batch adversarial loss: 0.516805\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353389; batch adversarial loss: 0.525386\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395475; batch adversarial loss: 0.590891\n",
      "epoch 109; iter: 0; batch classifier loss: 0.398654; batch adversarial loss: 0.553802\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359653; batch adversarial loss: 0.469837\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391772; batch adversarial loss: 0.497901\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406604; batch adversarial loss: 0.544542\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380740; batch adversarial loss: 0.488485\n",
      "epoch 114; iter: 0; batch classifier loss: 0.414512; batch adversarial loss: 0.516732\n",
      "epoch 115; iter: 0; batch classifier loss: 0.322101; batch adversarial loss: 0.497881\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423746; batch adversarial loss: 0.563473\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333045; batch adversarial loss: 0.526286\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384029; batch adversarial loss: 0.489622\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388032; batch adversarial loss: 0.607668\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371180; batch adversarial loss: 0.607137\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391159; batch adversarial loss: 0.561872\n",
      "epoch 122; iter: 0; batch classifier loss: 0.422510; batch adversarial loss: 0.513721\n",
      "epoch 123; iter: 0; batch classifier loss: 0.392568; batch adversarial loss: 0.548338\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391966; batch adversarial loss: 0.551517\n",
      "epoch 125; iter: 0; batch classifier loss: 0.322260; batch adversarial loss: 0.552738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.497413; batch adversarial loss: 0.600418\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407037; batch adversarial loss: 0.545837\n",
      "epoch 128; iter: 0; batch classifier loss: 0.336557; batch adversarial loss: 0.526922\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374824; batch adversarial loss: 0.517102\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321322; batch adversarial loss: 0.516416\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399664; batch adversarial loss: 0.489699\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355142; batch adversarial loss: 0.562157\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371872; batch adversarial loss: 0.546506\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339302; batch adversarial loss: 0.582345\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335811; batch adversarial loss: 0.563751\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358401; batch adversarial loss: 0.592061\n",
      "epoch 137; iter: 0; batch classifier loss: 0.434089; batch adversarial loss: 0.591202\n",
      "epoch 138; iter: 0; batch classifier loss: 0.469069; batch adversarial loss: 0.546116\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403980; batch adversarial loss: 0.470979\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334791; batch adversarial loss: 0.534310\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335576; batch adversarial loss: 0.487938\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395249; batch adversarial loss: 0.430215\n",
      "epoch 143; iter: 0; batch classifier loss: 0.403976; batch adversarial loss: 0.503949\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302674; batch adversarial loss: 0.545263\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384494; batch adversarial loss: 0.548773\n",
      "epoch 146; iter: 0; batch classifier loss: 0.390964; batch adversarial loss: 0.544385\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346776; batch adversarial loss: 0.500210\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412850; batch adversarial loss: 0.561013\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328569; batch adversarial loss: 0.525581\n",
      "epoch 150; iter: 0; batch classifier loss: 0.416827; batch adversarial loss: 0.476535\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355393; batch adversarial loss: 0.600644\n",
      "epoch 152; iter: 0; batch classifier loss: 0.426122; batch adversarial loss: 0.584904\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400419; batch adversarial loss: 0.580622\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340758; batch adversarial loss: 0.625680\n",
      "epoch 155; iter: 0; batch classifier loss: 0.416232; batch adversarial loss: 0.507569\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362688; batch adversarial loss: 0.515074\n",
      "epoch 157; iter: 0; batch classifier loss: 0.345501; batch adversarial loss: 0.565983\n",
      "epoch 158; iter: 0; batch classifier loss: 0.406422; batch adversarial loss: 0.545767\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323928; batch adversarial loss: 0.656298\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326108; batch adversarial loss: 0.515187\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391006; batch adversarial loss: 0.545361\n",
      "epoch 162; iter: 0; batch classifier loss: 0.421517; batch adversarial loss: 0.521616\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419452; batch adversarial loss: 0.481400\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312497; batch adversarial loss: 0.581023\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402136; batch adversarial loss: 0.551324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.304743; batch adversarial loss: 0.542762\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339250; batch adversarial loss: 0.554348\n",
      "epoch 168; iter: 0; batch classifier loss: 0.406779; batch adversarial loss: 0.479190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385773; batch adversarial loss: 0.599624\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410618; batch adversarial loss: 0.601533\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343373; batch adversarial loss: 0.516066\n",
      "epoch 172; iter: 0; batch classifier loss: 0.296740; batch adversarial loss: 0.430960\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404692; batch adversarial loss: 0.545184\n",
      "epoch 174; iter: 0; batch classifier loss: 0.419480; batch adversarial loss: 0.553586\n",
      "epoch 175; iter: 0; batch classifier loss: 0.476090; batch adversarial loss: 0.487733\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377726; batch adversarial loss: 0.609701\n",
      "epoch 177; iter: 0; batch classifier loss: 0.397095; batch adversarial loss: 0.496952\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376649; batch adversarial loss: 0.569519\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407664; batch adversarial loss: 0.582068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390767; batch adversarial loss: 0.498419\n",
      "epoch 181; iter: 0; batch classifier loss: 0.469017; batch adversarial loss: 0.561123\n",
      "epoch 182; iter: 0; batch classifier loss: 0.307907; batch adversarial loss: 0.580818\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349120; batch adversarial loss: 0.539925\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377483; batch adversarial loss: 0.544453\n",
      "epoch 185; iter: 0; batch classifier loss: 0.327551; batch adversarial loss: 0.585857\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385903; batch adversarial loss: 0.534541\n",
      "epoch 187; iter: 0; batch classifier loss: 0.282631; batch adversarial loss: 0.505945\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387062; batch adversarial loss: 0.527245\n",
      "epoch 189; iter: 0; batch classifier loss: 0.372671; batch adversarial loss: 0.497634\n",
      "epoch 190; iter: 0; batch classifier loss: 0.378763; batch adversarial loss: 0.574329\n",
      "epoch 191; iter: 0; batch classifier loss: 0.439618; batch adversarial loss: 0.523666\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351749; batch adversarial loss: 0.525670\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338221; batch adversarial loss: 0.551511\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354341; batch adversarial loss: 0.591008\n",
      "epoch 195; iter: 0; batch classifier loss: 0.274297; batch adversarial loss: 0.553738\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347658; batch adversarial loss: 0.478433\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412323; batch adversarial loss: 0.575043\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341473; batch adversarial loss: 0.563360\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360335; batch adversarial loss: 0.462391\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741308; batch adversarial loss: 0.722929\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598704; batch adversarial loss: 0.660632\n",
      "epoch 2; iter: 0; batch classifier loss: 0.646677; batch adversarial loss: 0.647624\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589158; batch adversarial loss: 0.639516\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615302; batch adversarial loss: 0.642820\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526365; batch adversarial loss: 0.643857\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568694; batch adversarial loss: 0.615505\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524365; batch adversarial loss: 0.564495\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503188; batch adversarial loss: 0.584520\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567904; batch adversarial loss: 0.560842\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549078; batch adversarial loss: 0.568505\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507751; batch adversarial loss: 0.564348\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495375; batch adversarial loss: 0.624489\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536382; batch adversarial loss: 0.545698\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481004; batch adversarial loss: 0.573796\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552423; batch adversarial loss: 0.530104\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481565; batch adversarial loss: 0.638687\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486155; batch adversarial loss: 0.545793\n",
      "epoch 18; iter: 0; batch classifier loss: 0.564751; batch adversarial loss: 0.549477\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490743; batch adversarial loss: 0.590298\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514242; batch adversarial loss: 0.515185\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477534; batch adversarial loss: 0.547978\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478861; batch adversarial loss: 0.522020\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473531; batch adversarial loss: 0.517437\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445118; batch adversarial loss: 0.508695\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524629; batch adversarial loss: 0.598974\n",
      "epoch 26; iter: 0; batch classifier loss: 0.507686; batch adversarial loss: 0.584777\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455935; batch adversarial loss: 0.538236\n",
      "epoch 28; iter: 0; batch classifier loss: 0.519496; batch adversarial loss: 0.514680\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486703; batch adversarial loss: 0.537253\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514134; batch adversarial loss: 0.573043\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416765; batch adversarial loss: 0.562758\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422999; batch adversarial loss: 0.562991\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419628; batch adversarial loss: 0.526602\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511804; batch adversarial loss: 0.481236\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457584; batch adversarial loss: 0.508835\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474656; batch adversarial loss: 0.506878\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409051; batch adversarial loss: 0.563124\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488975; batch adversarial loss: 0.508388\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450672; batch adversarial loss: 0.507798\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459843; batch adversarial loss: 0.554571\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432240; batch adversarial loss: 0.572000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489871; batch adversarial loss: 0.600289\n",
      "epoch 43; iter: 0; batch classifier loss: 0.515064; batch adversarial loss: 0.573261\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454154; batch adversarial loss: 0.563973\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371140; batch adversarial loss: 0.535956\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466439; batch adversarial loss: 0.518047\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483154; batch adversarial loss: 0.515245\n",
      "epoch 48; iter: 0; batch classifier loss: 0.523535; batch adversarial loss: 0.507622\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467851; batch adversarial loss: 0.478576\n",
      "epoch 50; iter: 0; batch classifier loss: 0.369882; batch adversarial loss: 0.583131\n",
      "epoch 51; iter: 0; batch classifier loss: 0.330178; batch adversarial loss: 0.504874\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387963; batch adversarial loss: 0.523516\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431998; batch adversarial loss: 0.505077\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393215; batch adversarial loss: 0.619786\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441489; batch adversarial loss: 0.515331\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396405; batch adversarial loss: 0.544788\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407152; batch adversarial loss: 0.601870\n",
      "epoch 58; iter: 0; batch classifier loss: 0.383928; batch adversarial loss: 0.524339\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385173; batch adversarial loss: 0.552252\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432813; batch adversarial loss: 0.582273\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436874; batch adversarial loss: 0.469477\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440549; batch adversarial loss: 0.477796\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377512; batch adversarial loss: 0.507806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.364836; batch adversarial loss: 0.451879\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412060; batch adversarial loss: 0.487167\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.574624\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445812; batch adversarial loss: 0.563201\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386488; batch adversarial loss: 0.478647\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403103; batch adversarial loss: 0.595836\n",
      "epoch 70; iter: 0; batch classifier loss: 0.484729; batch adversarial loss: 0.466920\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402003; batch adversarial loss: 0.545445\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408948; batch adversarial loss: 0.535229\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367540; batch adversarial loss: 0.581070\n",
      "epoch 74; iter: 0; batch classifier loss: 0.484861; batch adversarial loss: 0.516070\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429384; batch adversarial loss: 0.498648\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436569; batch adversarial loss: 0.535625\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415213; batch adversarial loss: 0.608862\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415312; batch adversarial loss: 0.545884\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407507; batch adversarial loss: 0.551675\n",
      "epoch 80; iter: 0; batch classifier loss: 0.456797; batch adversarial loss: 0.556438\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365094; batch adversarial loss: 0.515308\n",
      "epoch 82; iter: 0; batch classifier loss: 0.432857; batch adversarial loss: 0.603550\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373862; batch adversarial loss: 0.486706\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407121; batch adversarial loss: 0.563947\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393943; batch adversarial loss: 0.456575\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412016; batch adversarial loss: 0.585048\n",
      "epoch 87; iter: 0; batch classifier loss: 0.436557; batch adversarial loss: 0.517236\n",
      "epoch 88; iter: 0; batch classifier loss: 0.403696; batch adversarial loss: 0.503437\n",
      "epoch 89; iter: 0; batch classifier loss: 0.347630; batch adversarial loss: 0.651657\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417095; batch adversarial loss: 0.555661\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417105; batch adversarial loss: 0.564210\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353432; batch adversarial loss: 0.495872\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447698; batch adversarial loss: 0.534364\n",
      "epoch 94; iter: 0; batch classifier loss: 0.428454; batch adversarial loss: 0.502610\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381403; batch adversarial loss: 0.587715\n",
      "epoch 96; iter: 0; batch classifier loss: 0.451274; batch adversarial loss: 0.458492\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425853; batch adversarial loss: 0.471896\n",
      "epoch 98; iter: 0; batch classifier loss: 0.265676; batch adversarial loss: 0.451727\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385304; batch adversarial loss: 0.559850\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427118; batch adversarial loss: 0.543085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349528; batch adversarial loss: 0.592208\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355571; batch adversarial loss: 0.487291\n",
      "epoch 103; iter: 0; batch classifier loss: 0.336257; batch adversarial loss: 0.574831\n",
      "epoch 104; iter: 0; batch classifier loss: 0.457643; batch adversarial loss: 0.582290\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432048; batch adversarial loss: 0.566097\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365850; batch adversarial loss: 0.547203\n",
      "epoch 107; iter: 0; batch classifier loss: 0.459150; batch adversarial loss: 0.514231\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398138; batch adversarial loss: 0.568961\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396597; batch adversarial loss: 0.543841\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398919; batch adversarial loss: 0.512480\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412377; batch adversarial loss: 0.514512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368563; batch adversarial loss: 0.548730\n",
      "epoch 113; iter: 0; batch classifier loss: 0.388902; batch adversarial loss: 0.572922\n",
      "epoch 114; iter: 0; batch classifier loss: 0.480482; batch adversarial loss: 0.526906\n",
      "epoch 115; iter: 0; batch classifier loss: 0.441363; batch adversarial loss: 0.516857\n",
      "epoch 116; iter: 0; batch classifier loss: 0.363797; batch adversarial loss: 0.524794\n",
      "epoch 117; iter: 0; batch classifier loss: 0.355683; batch adversarial loss: 0.518330\n",
      "epoch 118; iter: 0; batch classifier loss: 0.396971; batch adversarial loss: 0.553656\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363663; batch adversarial loss: 0.583559\n",
      "epoch 120; iter: 0; batch classifier loss: 0.443862; batch adversarial loss: 0.505219\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378478; batch adversarial loss: 0.567615\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343325; batch adversarial loss: 0.565522\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336490; batch adversarial loss: 0.516251\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336089; batch adversarial loss: 0.597599\n",
      "epoch 125; iter: 0; batch classifier loss: 0.301917; batch adversarial loss: 0.580513\n",
      "epoch 126; iter: 0; batch classifier loss: 0.410597; batch adversarial loss: 0.604586\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344504; batch adversarial loss: 0.571008\n",
      "epoch 128; iter: 0; batch classifier loss: 0.319887; batch adversarial loss: 0.610716\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413621; batch adversarial loss: 0.513874\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398212; batch adversarial loss: 0.500237\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388644; batch adversarial loss: 0.499372\n",
      "epoch 132; iter: 0; batch classifier loss: 0.410893; batch adversarial loss: 0.517412\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397155; batch adversarial loss: 0.477526\n",
      "epoch 134; iter: 0; batch classifier loss: 0.283539; batch adversarial loss: 0.555504\n",
      "epoch 135; iter: 0; batch classifier loss: 0.443555; batch adversarial loss: 0.516954\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340393; batch adversarial loss: 0.505427\n",
      "epoch 137; iter: 0; batch classifier loss: 0.283516; batch adversarial loss: 0.469124\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359043; batch adversarial loss: 0.562077\n",
      "epoch 139; iter: 0; batch classifier loss: 0.438160; batch adversarial loss: 0.573088\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375303; batch adversarial loss: 0.566256\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379694; batch adversarial loss: 0.449813\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386353; batch adversarial loss: 0.551204\n",
      "epoch 143; iter: 0; batch classifier loss: 0.468089; batch adversarial loss: 0.525845\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354449; batch adversarial loss: 0.535923\n",
      "epoch 145; iter: 0; batch classifier loss: 0.315666; batch adversarial loss: 0.483683\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396379; batch adversarial loss: 0.514530\n",
      "epoch 147; iter: 0; batch classifier loss: 0.306679; batch adversarial loss: 0.541882\n",
      "epoch 148; iter: 0; batch classifier loss: 0.458246; batch adversarial loss: 0.574621\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322377; batch adversarial loss: 0.504612\n",
      "epoch 150; iter: 0; batch classifier loss: 0.411628; batch adversarial loss: 0.495040\n",
      "epoch 151; iter: 0; batch classifier loss: 0.285546; batch adversarial loss: 0.577143\n",
      "epoch 152; iter: 0; batch classifier loss: 0.305923; batch adversarial loss: 0.525632\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384294; batch adversarial loss: 0.601618\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389690; batch adversarial loss: 0.570732\n",
      "epoch 155; iter: 0; batch classifier loss: 0.378667; batch adversarial loss: 0.586366\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317105; batch adversarial loss: 0.543609\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394386; batch adversarial loss: 0.439191\n",
      "epoch 158; iter: 0; batch classifier loss: 0.394529; batch adversarial loss: 0.575471\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354959; batch adversarial loss: 0.509855\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308483; batch adversarial loss: 0.447937\n",
      "epoch 161; iter: 0; batch classifier loss: 0.348874; batch adversarial loss: 0.466361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.402561; batch adversarial loss: 0.547012\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338503; batch adversarial loss: 0.580699\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356642; batch adversarial loss: 0.500482\n",
      "epoch 165; iter: 0; batch classifier loss: 0.304370; batch adversarial loss: 0.495788\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312499; batch adversarial loss: 0.524813\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407685; batch adversarial loss: 0.513638\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352641; batch adversarial loss: 0.572686\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372872; batch adversarial loss: 0.476844\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383818; batch adversarial loss: 0.554941\n",
      "epoch 171; iter: 0; batch classifier loss: 0.429149; batch adversarial loss: 0.562382\n",
      "epoch 172; iter: 0; batch classifier loss: 0.429067; batch adversarial loss: 0.535452\n",
      "epoch 173; iter: 0; batch classifier loss: 0.488324; batch adversarial loss: 0.469932\n",
      "epoch 174; iter: 0; batch classifier loss: 0.270045; batch adversarial loss: 0.535986\n",
      "epoch 175; iter: 0; batch classifier loss: 0.451990; batch adversarial loss: 0.623177\n",
      "epoch 176; iter: 0; batch classifier loss: 0.284609; batch adversarial loss: 0.496179\n",
      "epoch 177; iter: 0; batch classifier loss: 0.442006; batch adversarial loss: 0.599675\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318582; batch adversarial loss: 0.534312\n",
      "epoch 179; iter: 0; batch classifier loss: 0.385471; batch adversarial loss: 0.403070\n",
      "epoch 180; iter: 0; batch classifier loss: 0.339466; batch adversarial loss: 0.610682\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328350; batch adversarial loss: 0.544529\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370739; batch adversarial loss: 0.477436\n",
      "epoch 183; iter: 0; batch classifier loss: 0.443461; batch adversarial loss: 0.524873\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374646; batch adversarial loss: 0.548298\n",
      "epoch 185; iter: 0; batch classifier loss: 0.337277; batch adversarial loss: 0.560844\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330203; batch adversarial loss: 0.581744\n",
      "epoch 187; iter: 0; batch classifier loss: 0.428010; batch adversarial loss: 0.597037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.258272; batch adversarial loss: 0.591076\n",
      "epoch 189; iter: 0; batch classifier loss: 0.419491; batch adversarial loss: 0.497641\n",
      "epoch 190; iter: 0; batch classifier loss: 0.329433; batch adversarial loss: 0.425745\n",
      "epoch 191; iter: 0; batch classifier loss: 0.383160; batch adversarial loss: 0.580817\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361998; batch adversarial loss: 0.468134\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367980; batch adversarial loss: 0.512690\n",
      "epoch 194; iter: 0; batch classifier loss: 0.291910; batch adversarial loss: 0.584015\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382496; batch adversarial loss: 0.554169\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338794; batch adversarial loss: 0.526221\n",
      "epoch 197; iter: 0; batch classifier loss: 0.469679; batch adversarial loss: 0.446976\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397935; batch adversarial loss: 0.634768\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314984; batch adversarial loss: 0.490746\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696132; batch adversarial loss: 0.601126\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637983; batch adversarial loss: 0.645273\n",
      "epoch 2; iter: 0; batch classifier loss: 0.520629; batch adversarial loss: 0.667843\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568834; batch adversarial loss: 0.638198\n",
      "epoch 4; iter: 0; batch classifier loss: 0.608966; batch adversarial loss: 0.706522\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635548; batch adversarial loss: 0.701071\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526595; batch adversarial loss: 0.632160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549970; batch adversarial loss: 0.610038\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586828; batch adversarial loss: 0.645882\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547225; batch adversarial loss: 0.607898\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545798; batch adversarial loss: 0.650415\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537665; batch adversarial loss: 0.573003\n",
      "epoch 12; iter: 0; batch classifier loss: 0.595777; batch adversarial loss: 0.633072\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553070; batch adversarial loss: 0.604636\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530635; batch adversarial loss: 0.571813\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566907; batch adversarial loss: 0.550115\n",
      "epoch 16; iter: 0; batch classifier loss: 0.569176; batch adversarial loss: 0.602405\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517722; batch adversarial loss: 0.538786\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512503; batch adversarial loss: 0.590614\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498943; batch adversarial loss: 0.596206\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507737; batch adversarial loss: 0.552868\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513724; batch adversarial loss: 0.581208\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437715; batch adversarial loss: 0.546567\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494525; batch adversarial loss: 0.513421\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495685; batch adversarial loss: 0.572041\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461954; batch adversarial loss: 0.623353\n",
      "epoch 26; iter: 0; batch classifier loss: 0.417958; batch adversarial loss: 0.556104\n",
      "epoch 27; iter: 0; batch classifier loss: 0.524457; batch adversarial loss: 0.506152\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469828; batch adversarial loss: 0.621153\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483816; batch adversarial loss: 0.538460\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444108; batch adversarial loss: 0.470850\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483269; batch adversarial loss: 0.527011\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536457; batch adversarial loss: 0.596817\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426858; batch adversarial loss: 0.541805\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408248; batch adversarial loss: 0.536876\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474735; batch adversarial loss: 0.526243\n",
      "epoch 36; iter: 0; batch classifier loss: 0.412436; batch adversarial loss: 0.482928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480186; batch adversarial loss: 0.609426\n",
      "epoch 38; iter: 0; batch classifier loss: 0.553975; batch adversarial loss: 0.476133\n",
      "epoch 39; iter: 0; batch classifier loss: 0.366280; batch adversarial loss: 0.561521\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484880; batch adversarial loss: 0.545092\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403051; batch adversarial loss: 0.471974\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423926; batch adversarial loss: 0.562063\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430834; batch adversarial loss: 0.535312\n",
      "epoch 44; iter: 0; batch classifier loss: 0.535736; batch adversarial loss: 0.562028\n",
      "epoch 45; iter: 0; batch classifier loss: 0.494977; batch adversarial loss: 0.569528\n",
      "epoch 46; iter: 0; batch classifier loss: 0.524529; batch adversarial loss: 0.525322\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505726; batch adversarial loss: 0.544861\n",
      "epoch 48; iter: 0; batch classifier loss: 0.458132; batch adversarial loss: 0.561367\n",
      "epoch 49; iter: 0; batch classifier loss: 0.517228; batch adversarial loss: 0.483358\n",
      "epoch 50; iter: 0; batch classifier loss: 0.456506; batch adversarial loss: 0.523735\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434623; batch adversarial loss: 0.536627\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432144; batch adversarial loss: 0.562839\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438386; batch adversarial loss: 0.480177\n",
      "epoch 54; iter: 0; batch classifier loss: 0.574773; batch adversarial loss: 0.557074\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441088; batch adversarial loss: 0.599600\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371162; batch adversarial loss: 0.606833\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398601; batch adversarial loss: 0.651836\n",
      "epoch 58; iter: 0; batch classifier loss: 0.346549; batch adversarial loss: 0.572667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.436276; batch adversarial loss: 0.532063\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480874; batch adversarial loss: 0.597729\n",
      "epoch 61; iter: 0; batch classifier loss: 0.297790; batch adversarial loss: 0.602331\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392588; batch adversarial loss: 0.538752\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385202; batch adversarial loss: 0.613687\n",
      "epoch 64; iter: 0; batch classifier loss: 0.366313; batch adversarial loss: 0.508574\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395415; batch adversarial loss: 0.633521\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434442; batch adversarial loss: 0.526718\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436436; batch adversarial loss: 0.615601\n",
      "epoch 68; iter: 0; batch classifier loss: 0.429110; batch adversarial loss: 0.526997\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388142; batch adversarial loss: 0.547166\n",
      "epoch 70; iter: 0; batch classifier loss: 0.484461; batch adversarial loss: 0.527548\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349016; batch adversarial loss: 0.584857\n",
      "epoch 72; iter: 0; batch classifier loss: 0.493470; batch adversarial loss: 0.491462\n",
      "epoch 73; iter: 0; batch classifier loss: 0.473594; batch adversarial loss: 0.535751\n",
      "epoch 74; iter: 0; batch classifier loss: 0.371396; batch adversarial loss: 0.577164\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401041; batch adversarial loss: 0.636039\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439208; batch adversarial loss: 0.565366\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375169; batch adversarial loss: 0.553295\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377457; batch adversarial loss: 0.526213\n",
      "epoch 79; iter: 0; batch classifier loss: 0.442281; batch adversarial loss: 0.571440\n",
      "epoch 80; iter: 0; batch classifier loss: 0.464430; batch adversarial loss: 0.492612\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368785; batch adversarial loss: 0.581473\n",
      "epoch 82; iter: 0; batch classifier loss: 0.332110; batch adversarial loss: 0.543071\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360516; batch adversarial loss: 0.489436\n",
      "epoch 84; iter: 0; batch classifier loss: 0.334911; batch adversarial loss: 0.555299\n",
      "epoch 85; iter: 0; batch classifier loss: 0.430207; batch adversarial loss: 0.524311\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397750; batch adversarial loss: 0.572769\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370856; batch adversarial loss: 0.544717\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429086; batch adversarial loss: 0.570400\n",
      "epoch 89; iter: 0; batch classifier loss: 0.276863; batch adversarial loss: 0.482648\n",
      "epoch 90; iter: 0; batch classifier loss: 0.356247; batch adversarial loss: 0.575319\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380421; batch adversarial loss: 0.507242\n",
      "epoch 92; iter: 0; batch classifier loss: 0.493467; batch adversarial loss: 0.567689\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370400; batch adversarial loss: 0.566320\n",
      "epoch 94; iter: 0; batch classifier loss: 0.361519; batch adversarial loss: 0.582599\n",
      "epoch 95; iter: 0; batch classifier loss: 0.324895; batch adversarial loss: 0.552314\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414134; batch adversarial loss: 0.500497\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350979; batch adversarial loss: 0.514552\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379439; batch adversarial loss: 0.536376\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405604; batch adversarial loss: 0.518738\n",
      "epoch 100; iter: 0; batch classifier loss: 0.452089; batch adversarial loss: 0.537317\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399995; batch adversarial loss: 0.517339\n",
      "epoch 102; iter: 0; batch classifier loss: 0.365672; batch adversarial loss: 0.578767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.457979; batch adversarial loss: 0.548190\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370900; batch adversarial loss: 0.591963\n",
      "epoch 105; iter: 0; batch classifier loss: 0.450298; batch adversarial loss: 0.530107\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370951; batch adversarial loss: 0.568179\n",
      "epoch 107; iter: 0; batch classifier loss: 0.446280; batch adversarial loss: 0.514199\n",
      "epoch 108; iter: 0; batch classifier loss: 0.337853; batch adversarial loss: 0.572623\n",
      "epoch 109; iter: 0; batch classifier loss: 0.452320; batch adversarial loss: 0.604618\n",
      "epoch 110; iter: 0; batch classifier loss: 0.431811; batch adversarial loss: 0.539862\n",
      "epoch 111; iter: 0; batch classifier loss: 0.314152; batch adversarial loss: 0.514383\n",
      "epoch 112; iter: 0; batch classifier loss: 0.416770; batch adversarial loss: 0.527762\n",
      "epoch 113; iter: 0; batch classifier loss: 0.367601; batch adversarial loss: 0.534819\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362835; batch adversarial loss: 0.577551\n",
      "epoch 115; iter: 0; batch classifier loss: 0.427660; batch adversarial loss: 0.529089\n",
      "epoch 116; iter: 0; batch classifier loss: 0.464242; batch adversarial loss: 0.518514\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410705; batch adversarial loss: 0.534756\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403381; batch adversarial loss: 0.551979\n",
      "epoch 119; iter: 0; batch classifier loss: 0.429251; batch adversarial loss: 0.571555\n",
      "epoch 120; iter: 0; batch classifier loss: 0.342862; batch adversarial loss: 0.634016\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390057; batch adversarial loss: 0.522097\n",
      "epoch 122; iter: 0; batch classifier loss: 0.456040; batch adversarial loss: 0.532636\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327799; batch adversarial loss: 0.543300\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401762; batch adversarial loss: 0.589546\n",
      "epoch 125; iter: 0; batch classifier loss: 0.312799; batch adversarial loss: 0.620525\n",
      "epoch 126; iter: 0; batch classifier loss: 0.313682; batch adversarial loss: 0.524284\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353901; batch adversarial loss: 0.510219\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369883; batch adversarial loss: 0.500359\n",
      "epoch 129; iter: 0; batch classifier loss: 0.419877; batch adversarial loss: 0.514686\n",
      "epoch 130; iter: 0; batch classifier loss: 0.333275; batch adversarial loss: 0.588788\n",
      "epoch 131; iter: 0; batch classifier loss: 0.309651; batch adversarial loss: 0.582280\n",
      "epoch 132; iter: 0; batch classifier loss: 0.432236; batch adversarial loss: 0.567373\n",
      "epoch 133; iter: 0; batch classifier loss: 0.345800; batch adversarial loss: 0.580143\n",
      "epoch 134; iter: 0; batch classifier loss: 0.441363; batch adversarial loss: 0.501442\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369086; batch adversarial loss: 0.553239\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383417; batch adversarial loss: 0.619515\n",
      "epoch 137; iter: 0; batch classifier loss: 0.498125; batch adversarial loss: 0.510074\n",
      "epoch 138; iter: 0; batch classifier loss: 0.421853; batch adversarial loss: 0.560833\n",
      "epoch 139; iter: 0; batch classifier loss: 0.364223; batch adversarial loss: 0.608437\n",
      "epoch 140; iter: 0; batch classifier loss: 0.406189; batch adversarial loss: 0.581558\n",
      "epoch 141; iter: 0; batch classifier loss: 0.410917; batch adversarial loss: 0.589082\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389982; batch adversarial loss: 0.612513\n",
      "epoch 143; iter: 0; batch classifier loss: 0.439695; batch adversarial loss: 0.591321\n",
      "epoch 144; iter: 0; batch classifier loss: 0.309029; batch adversarial loss: 0.471714\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355472; batch adversarial loss: 0.541376\n",
      "epoch 146; iter: 0; batch classifier loss: 0.476479; batch adversarial loss: 0.538976\n",
      "epoch 147; iter: 0; batch classifier loss: 0.416904; batch adversarial loss: 0.515916\n",
      "epoch 148; iter: 0; batch classifier loss: 0.462102; batch adversarial loss: 0.562993\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363701; batch adversarial loss: 0.518947\n",
      "epoch 150; iter: 0; batch classifier loss: 0.398978; batch adversarial loss: 0.553200\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351665; batch adversarial loss: 0.482880\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398742; batch adversarial loss: 0.575095\n",
      "epoch 153; iter: 0; batch classifier loss: 0.319152; batch adversarial loss: 0.586594\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400854; batch adversarial loss: 0.552404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.340585; batch adversarial loss: 0.589005\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347452; batch adversarial loss: 0.556367\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393623; batch adversarial loss: 0.615983\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369061; batch adversarial loss: 0.488585\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352576; batch adversarial loss: 0.561936\n",
      "epoch 160; iter: 0; batch classifier loss: 0.394443; batch adversarial loss: 0.537680\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397579; batch adversarial loss: 0.615681\n",
      "epoch 162; iter: 0; batch classifier loss: 0.451162; batch adversarial loss: 0.502689\n",
      "epoch 163; iter: 0; batch classifier loss: 0.416617; batch adversarial loss: 0.541524\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376108; batch adversarial loss: 0.543816\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339768; batch adversarial loss: 0.610519\n",
      "epoch 166; iter: 0; batch classifier loss: 0.337003; batch adversarial loss: 0.509007\n",
      "epoch 167; iter: 0; batch classifier loss: 0.320784; batch adversarial loss: 0.574605\n",
      "epoch 168; iter: 0; batch classifier loss: 0.431152; batch adversarial loss: 0.493724\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394404; batch adversarial loss: 0.578815\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383412; batch adversarial loss: 0.569633\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340777; batch adversarial loss: 0.508692\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341346; batch adversarial loss: 0.553749\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365563; batch adversarial loss: 0.566464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.408357; batch adversarial loss: 0.505151\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342210; batch adversarial loss: 0.527342\n",
      "epoch 176; iter: 0; batch classifier loss: 0.301576; batch adversarial loss: 0.528770\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315080; batch adversarial loss: 0.565504\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350361; batch adversarial loss: 0.641698\n",
      "epoch 179; iter: 0; batch classifier loss: 0.416226; batch adversarial loss: 0.592553\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388425; batch adversarial loss: 0.481647\n",
      "epoch 181; iter: 0; batch classifier loss: 0.412434; batch adversarial loss: 0.499359\n",
      "epoch 182; iter: 0; batch classifier loss: 0.417910; batch adversarial loss: 0.540767\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347012; batch adversarial loss: 0.580160\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397902; batch adversarial loss: 0.558191\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370997; batch adversarial loss: 0.584284\n",
      "epoch 186; iter: 0; batch classifier loss: 0.320449; batch adversarial loss: 0.481710\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363651; batch adversarial loss: 0.613900\n",
      "epoch 188; iter: 0; batch classifier loss: 0.411210; batch adversarial loss: 0.534235\n",
      "epoch 189; iter: 0; batch classifier loss: 0.406774; batch adversarial loss: 0.529811\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360681; batch adversarial loss: 0.598886\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321212; batch adversarial loss: 0.508201\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336938; batch adversarial loss: 0.623492\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368335; batch adversarial loss: 0.497801\n",
      "epoch 194; iter: 0; batch classifier loss: 0.448509; batch adversarial loss: 0.532296\n",
      "epoch 195; iter: 0; batch classifier loss: 0.434528; batch adversarial loss: 0.541743\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394621; batch adversarial loss: 0.483403\n",
      "epoch 197; iter: 0; batch classifier loss: 0.343363; batch adversarial loss: 0.537782\n",
      "epoch 198; iter: 0; batch classifier loss: 0.395116; batch adversarial loss: 0.597294\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388706; batch adversarial loss: 0.556860\n",
      "epoch 0; iter: 0; batch classifier loss: 0.766894; batch adversarial loss: 0.811215\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676317; batch adversarial loss: 0.783070\n",
      "epoch 2; iter: 0; batch classifier loss: 0.807072; batch adversarial loss: 0.733838\n",
      "epoch 3; iter: 0; batch classifier loss: 0.864970; batch adversarial loss: 0.677095\n",
      "epoch 4; iter: 0; batch classifier loss: 0.753509; batch adversarial loss: 0.630375\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526738; batch adversarial loss: 0.624183\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513257; batch adversarial loss: 0.624910\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568507; batch adversarial loss: 0.646783\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550436; batch adversarial loss: 0.597394\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514003; batch adversarial loss: 0.596619\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517715; batch adversarial loss: 0.555603\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605667; batch adversarial loss: 0.565385\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553256; batch adversarial loss: 0.557202\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534864; batch adversarial loss: 0.564889\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538936; batch adversarial loss: 0.524684\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533802; batch adversarial loss: 0.581373\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504448; batch adversarial loss: 0.555728\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523257; batch adversarial loss: 0.548363\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540892; batch adversarial loss: 0.540115\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499464; batch adversarial loss: 0.521434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471746; batch adversarial loss: 0.626006\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513193; batch adversarial loss: 0.578880\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496838; batch adversarial loss: 0.539852\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510757; batch adversarial loss: 0.552028\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426880; batch adversarial loss: 0.493433\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491933; batch adversarial loss: 0.531418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.431938; batch adversarial loss: 0.590948\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495751; batch adversarial loss: 0.612228\n",
      "epoch 28; iter: 0; batch classifier loss: 0.449269; batch adversarial loss: 0.499222\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411328; batch adversarial loss: 0.563829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.530643; batch adversarial loss: 0.485128\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441016; batch adversarial loss: 0.565145\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473882; batch adversarial loss: 0.600834\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421256; batch adversarial loss: 0.539039\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543196; batch adversarial loss: 0.534115\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497686; batch adversarial loss: 0.478308\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406128; batch adversarial loss: 0.553589\n",
      "epoch 37; iter: 0; batch classifier loss: 0.510160; batch adversarial loss: 0.532482\n",
      "epoch 38; iter: 0; batch classifier loss: 0.536022; batch adversarial loss: 0.617377\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460334; batch adversarial loss: 0.526839\n",
      "epoch 40; iter: 0; batch classifier loss: 0.485999; batch adversarial loss: 0.590939\n",
      "epoch 41; iter: 0; batch classifier loss: 0.480794; batch adversarial loss: 0.515704\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447309; batch adversarial loss: 0.574780\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431213; batch adversarial loss: 0.543062\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417228; batch adversarial loss: 0.545599\n",
      "epoch 45; iter: 0; batch classifier loss: 0.452830; batch adversarial loss: 0.546099\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431642; batch adversarial loss: 0.469243\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399625; batch adversarial loss: 0.593611\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426691; batch adversarial loss: 0.517633\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456124; batch adversarial loss: 0.497489\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431906; batch adversarial loss: 0.515424\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463890; batch adversarial loss: 0.536239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.424243; batch adversarial loss: 0.573958\n",
      "epoch 53; iter: 0; batch classifier loss: 0.308345; batch adversarial loss: 0.525454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474122; batch adversarial loss: 0.573504\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458362; batch adversarial loss: 0.525729\n",
      "epoch 56; iter: 0; batch classifier loss: 0.465221; batch adversarial loss: 0.534895\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422846; batch adversarial loss: 0.486767\n",
      "epoch 58; iter: 0; batch classifier loss: 0.499722; batch adversarial loss: 0.564716\n",
      "epoch 59; iter: 0; batch classifier loss: 0.490899; batch adversarial loss: 0.525677\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435331; batch adversarial loss: 0.411146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449174; batch adversarial loss: 0.515913\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424400; batch adversarial loss: 0.516519\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394568; batch adversarial loss: 0.572913\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385336; batch adversarial loss: 0.555173\n",
      "epoch 65; iter: 0; batch classifier loss: 0.342082; batch adversarial loss: 0.477224\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445021; batch adversarial loss: 0.534593\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391334; batch adversarial loss: 0.535338\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342104; batch adversarial loss: 0.544692\n",
      "epoch 69; iter: 0; batch classifier loss: 0.379385; batch adversarial loss: 0.495805\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399885; batch adversarial loss: 0.496754\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400276; batch adversarial loss: 0.505618\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369261; batch adversarial loss: 0.525372\n",
      "epoch 73; iter: 0; batch classifier loss: 0.463151; batch adversarial loss: 0.563762\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390745; batch adversarial loss: 0.562109\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411395; batch adversarial loss: 0.552386\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441773; batch adversarial loss: 0.542231\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398372; batch adversarial loss: 0.628945\n",
      "epoch 78; iter: 0; batch classifier loss: 0.432093; batch adversarial loss: 0.450451\n",
      "epoch 79; iter: 0; batch classifier loss: 0.539351; batch adversarial loss: 0.631248\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349826; batch adversarial loss: 0.573613\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386864; batch adversarial loss: 0.506147\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356502; batch adversarial loss: 0.572037\n",
      "epoch 83; iter: 0; batch classifier loss: 0.469417; batch adversarial loss: 0.571761\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353806; batch adversarial loss: 0.535821\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431864; batch adversarial loss: 0.476918\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406524; batch adversarial loss: 0.517939\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375988; batch adversarial loss: 0.525372\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372224; batch adversarial loss: 0.525111\n",
      "epoch 89; iter: 0; batch classifier loss: 0.345626; batch adversarial loss: 0.514814\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408244; batch adversarial loss: 0.515059\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359383; batch adversarial loss: 0.526655\n",
      "epoch 92; iter: 0; batch classifier loss: 0.357705; batch adversarial loss: 0.541570\n",
      "epoch 93; iter: 0; batch classifier loss: 0.321084; batch adversarial loss: 0.611488\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420575; batch adversarial loss: 0.564164\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408761; batch adversarial loss: 0.496179\n",
      "epoch 96; iter: 0; batch classifier loss: 0.331856; batch adversarial loss: 0.418677\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399379; batch adversarial loss: 0.506069\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349977; batch adversarial loss: 0.506142\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429371; batch adversarial loss: 0.574122\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385292; batch adversarial loss: 0.515803\n",
      "epoch 101; iter: 0; batch classifier loss: 0.340538; batch adversarial loss: 0.564623\n",
      "epoch 102; iter: 0; batch classifier loss: 0.375676; batch adversarial loss: 0.545199\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372878; batch adversarial loss: 0.505923\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398910; batch adversarial loss: 0.506230\n",
      "epoch 105; iter: 0; batch classifier loss: 0.381820; batch adversarial loss: 0.535284\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367116; batch adversarial loss: 0.535686\n",
      "epoch 107; iter: 0; batch classifier loss: 0.327556; batch adversarial loss: 0.545409\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391109; batch adversarial loss: 0.554331\n",
      "epoch 109; iter: 0; batch classifier loss: 0.473884; batch adversarial loss: 0.544536\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391333; batch adversarial loss: 0.496408\n",
      "epoch 111; iter: 0; batch classifier loss: 0.321786; batch adversarial loss: 0.486897\n",
      "epoch 112; iter: 0; batch classifier loss: 0.393958; batch adversarial loss: 0.573851\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380210; batch adversarial loss: 0.564352\n",
      "epoch 114; iter: 0; batch classifier loss: 0.311377; batch adversarial loss: 0.515818\n",
      "epoch 115; iter: 0; batch classifier loss: 0.440370; batch adversarial loss: 0.651240\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335384; batch adversarial loss: 0.506516\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319608; batch adversarial loss: 0.563780\n",
      "epoch 118; iter: 0; batch classifier loss: 0.353183; batch adversarial loss: 0.515812\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349612; batch adversarial loss: 0.525376\n",
      "epoch 120; iter: 0; batch classifier loss: 0.356102; batch adversarial loss: 0.506313\n",
      "epoch 121; iter: 0; batch classifier loss: 0.340358; batch adversarial loss: 0.505970\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350366; batch adversarial loss: 0.592515\n",
      "epoch 123; iter: 0; batch classifier loss: 0.335031; batch adversarial loss: 0.477509\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385063; batch adversarial loss: 0.496782\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398569; batch adversarial loss: 0.660480\n",
      "epoch 126; iter: 0; batch classifier loss: 0.409579; batch adversarial loss: 0.506342\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346334; batch adversarial loss: 0.525520\n",
      "epoch 128; iter: 0; batch classifier loss: 0.309565; batch adversarial loss: 0.506766\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416840; batch adversarial loss: 0.477543\n",
      "epoch 130; iter: 0; batch classifier loss: 0.399236; batch adversarial loss: 0.477841\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363066; batch adversarial loss: 0.573774\n",
      "epoch 132; iter: 0; batch classifier loss: 0.337724; batch adversarial loss: 0.544537\n",
      "epoch 133; iter: 0; batch classifier loss: 0.325395; batch adversarial loss: 0.525278\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356674; batch adversarial loss: 0.515957\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360356; batch adversarial loss: 0.505882\n",
      "epoch 136; iter: 0; batch classifier loss: 0.276824; batch adversarial loss: 0.592981\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399145; batch adversarial loss: 0.478116\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338258; batch adversarial loss: 0.525466\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360766; batch adversarial loss: 0.544634\n",
      "epoch 140; iter: 0; batch classifier loss: 0.279473; batch adversarial loss: 0.525421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383624; batch adversarial loss: 0.554652\n",
      "epoch 142; iter: 0; batch classifier loss: 0.299024; batch adversarial loss: 0.515809\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380719; batch adversarial loss: 0.554502\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384329; batch adversarial loss: 0.573693\n",
      "epoch 145; iter: 0; batch classifier loss: 0.336491; batch adversarial loss: 0.554180\n",
      "epoch 146; iter: 0; batch classifier loss: 0.320334; batch adversarial loss: 0.487083\n",
      "epoch 147; iter: 0; batch classifier loss: 0.309962; batch adversarial loss: 0.525452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.397582; batch adversarial loss: 0.496741\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342927; batch adversarial loss: 0.506165\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387631; batch adversarial loss: 0.467818\n",
      "epoch 151; iter: 0; batch classifier loss: 0.388525; batch adversarial loss: 0.640722\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341621; batch adversarial loss: 0.477668\n",
      "epoch 153; iter: 0; batch classifier loss: 0.418275; batch adversarial loss: 0.515814\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325486; batch adversarial loss: 0.534850\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369040; batch adversarial loss: 0.534981\n",
      "epoch 156; iter: 0; batch classifier loss: 0.290039; batch adversarial loss: 0.583188\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386498; batch adversarial loss: 0.525655\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366293; batch adversarial loss: 0.487202\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393634; batch adversarial loss: 0.554089\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357190; batch adversarial loss: 0.554511\n",
      "epoch 161; iter: 0; batch classifier loss: 0.301291; batch adversarial loss: 0.621776\n",
      "epoch 162; iter: 0; batch classifier loss: 0.304636; batch adversarial loss: 0.573723\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366752; batch adversarial loss: 0.525367\n",
      "epoch 164; iter: 0; batch classifier loss: 0.271567; batch adversarial loss: 0.554352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410098; batch adversarial loss: 0.592809\n",
      "epoch 166; iter: 0; batch classifier loss: 0.277991; batch adversarial loss: 0.506149\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406683; batch adversarial loss: 0.515892\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317644; batch adversarial loss: 0.515859\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368618; batch adversarial loss: 0.496782\n",
      "epoch 170; iter: 0; batch classifier loss: 0.294054; batch adversarial loss: 0.563887\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358119; batch adversarial loss: 0.573964\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385282; batch adversarial loss: 0.515665\n",
      "epoch 173; iter: 0; batch classifier loss: 0.309362; batch adversarial loss: 0.611871\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396053; batch adversarial loss: 0.525594\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329897; batch adversarial loss: 0.515923\n",
      "epoch 176; iter: 0; batch classifier loss: 0.284020; batch adversarial loss: 0.544664\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396024; batch adversarial loss: 0.476923\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370428; batch adversarial loss: 0.563983\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349059; batch adversarial loss: 0.544598\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383561; batch adversarial loss: 0.544836\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366186; batch adversarial loss: 0.496949\n",
      "epoch 182; iter: 0; batch classifier loss: 0.335122; batch adversarial loss: 0.554539\n",
      "epoch 183; iter: 0; batch classifier loss: 0.293020; batch adversarial loss: 0.535394\n",
      "epoch 184; iter: 0; batch classifier loss: 0.369438; batch adversarial loss: 0.554096\n",
      "epoch 185; iter: 0; batch classifier loss: 0.448628; batch adversarial loss: 0.515652\n",
      "epoch 186; iter: 0; batch classifier loss: 0.290705; batch adversarial loss: 0.592577\n",
      "epoch 187; iter: 0; batch classifier loss: 0.380890; batch adversarial loss: 0.515916\n",
      "epoch 188; iter: 0; batch classifier loss: 0.402390; batch adversarial loss: 0.515981\n",
      "epoch 189; iter: 0; batch classifier loss: 0.422605; batch adversarial loss: 0.439111\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343546; batch adversarial loss: 0.544468\n",
      "epoch 191; iter: 0; batch classifier loss: 0.401488; batch adversarial loss: 0.564107\n",
      "epoch 192; iter: 0; batch classifier loss: 0.418590; batch adversarial loss: 0.515912\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333333; batch adversarial loss: 0.506633\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395839; batch adversarial loss: 0.515856\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296461; batch adversarial loss: 0.409807\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314166; batch adversarial loss: 0.496468\n",
      "epoch 197; iter: 0; batch classifier loss: 0.305370; batch adversarial loss: 0.534987\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342964; batch adversarial loss: 0.515972\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309731; batch adversarial loss: 0.544793\n",
      "epoch 0; iter: 0; batch classifier loss: 0.633847; batch adversarial loss: 0.647075\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573317; batch adversarial loss: 0.638590\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587570; batch adversarial loss: 0.627020\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564049; batch adversarial loss: 0.642171\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594678; batch adversarial loss: 0.622975\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571070; batch adversarial loss: 0.595326\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584649; batch adversarial loss: 0.639062\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583467; batch adversarial loss: 0.599405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564390; batch adversarial loss: 0.611495\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570904; batch adversarial loss: 0.571856\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510971; batch adversarial loss: 0.554317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502600; batch adversarial loss: 0.614697\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492620; batch adversarial loss: 0.565097\n",
      "epoch 13; iter: 0; batch classifier loss: 0.577362; batch adversarial loss: 0.537455\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518902; batch adversarial loss: 0.603014\n",
      "epoch 15; iter: 0; batch classifier loss: 0.586367; batch adversarial loss: 0.550265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521769; batch adversarial loss: 0.566029\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529819; batch adversarial loss: 0.549341\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456791; batch adversarial loss: 0.553040\n",
      "epoch 19; iter: 0; batch classifier loss: 0.460177; batch adversarial loss: 0.491286\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495497; batch adversarial loss: 0.565635\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517448; batch adversarial loss: 0.610352\n",
      "epoch 22; iter: 0; batch classifier loss: 0.562996; batch adversarial loss: 0.526352\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534293; batch adversarial loss: 0.464275\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497373; batch adversarial loss: 0.541046\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490343; batch adversarial loss: 0.516091\n",
      "epoch 26; iter: 0; batch classifier loss: 0.518261; batch adversarial loss: 0.615462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390141; batch adversarial loss: 0.555117\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479410; batch adversarial loss: 0.495190\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483061; batch adversarial loss: 0.491675\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480409; batch adversarial loss: 0.511190\n",
      "epoch 31; iter: 0; batch classifier loss: 0.592057; batch adversarial loss: 0.565214\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477929; batch adversarial loss: 0.562217\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405944; batch adversarial loss: 0.551546\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468998; batch adversarial loss: 0.500935\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435146; batch adversarial loss: 0.606202\n",
      "epoch 36; iter: 0; batch classifier loss: 0.416869; batch adversarial loss: 0.552253\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460254; batch adversarial loss: 0.491331\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448000; batch adversarial loss: 0.524557\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458261; batch adversarial loss: 0.553942\n",
      "epoch 40; iter: 0; batch classifier loss: 0.528042; batch adversarial loss: 0.626068\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454461; batch adversarial loss: 0.499396\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464478; batch adversarial loss: 0.563642\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459034; batch adversarial loss: 0.582731\n",
      "epoch 44; iter: 0; batch classifier loss: 0.496086; batch adversarial loss: 0.563739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.459643; batch adversarial loss: 0.645789\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394786; batch adversarial loss: 0.470673\n",
      "epoch 47; iter: 0; batch classifier loss: 0.397014; batch adversarial loss: 0.488971\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379684; batch adversarial loss: 0.526043\n",
      "epoch 49; iter: 0; batch classifier loss: 0.457187; batch adversarial loss: 0.563678\n",
      "epoch 50; iter: 0; batch classifier loss: 0.487922; batch adversarial loss: 0.526733\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390260; batch adversarial loss: 0.572389\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449794; batch adversarial loss: 0.553584\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450105; batch adversarial loss: 0.525792\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421706; batch adversarial loss: 0.507578\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447601; batch adversarial loss: 0.497978\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433181; batch adversarial loss: 0.488514\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410578; batch adversarial loss: 0.553373\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427402; batch adversarial loss: 0.451551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435167; batch adversarial loss: 0.507889\n",
      "epoch 60; iter: 0; batch classifier loss: 0.497529; batch adversarial loss: 0.581938\n",
      "epoch 61; iter: 0; batch classifier loss: 0.550804; batch adversarial loss: 0.459281\n",
      "epoch 62; iter: 0; batch classifier loss: 0.520367; batch adversarial loss: 0.507693\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438899; batch adversarial loss: 0.479108\n",
      "epoch 64; iter: 0; batch classifier loss: 0.464726; batch adversarial loss: 0.600294\n",
      "epoch 65; iter: 0; batch classifier loss: 0.484816; batch adversarial loss: 0.535362\n",
      "epoch 66; iter: 0; batch classifier loss: 0.486184; batch adversarial loss: 0.424992\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379791; batch adversarial loss: 0.507993\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410054; batch adversarial loss: 0.572197\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439223; batch adversarial loss: 0.544753\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387658; batch adversarial loss: 0.581866\n",
      "epoch 71; iter: 0; batch classifier loss: 0.339909; batch adversarial loss: 0.563042\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417739; batch adversarial loss: 0.525914\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387230; batch adversarial loss: 0.488895\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391905; batch adversarial loss: 0.563250\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452416; batch adversarial loss: 0.451367\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399863; batch adversarial loss: 0.665214\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442256; batch adversarial loss: 0.535211\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405247; batch adversarial loss: 0.535949\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436860; batch adversarial loss: 0.440676\n",
      "epoch 80; iter: 0; batch classifier loss: 0.448251; batch adversarial loss: 0.552463\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441323; batch adversarial loss: 0.560670\n",
      "epoch 82; iter: 0; batch classifier loss: 0.526224; batch adversarial loss: 0.566772\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413883; batch adversarial loss: 0.417969\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403711; batch adversarial loss: 0.498277\n",
      "epoch 85; iter: 0; batch classifier loss: 0.356957; batch adversarial loss: 0.527194\n",
      "epoch 86; iter: 0; batch classifier loss: 0.346941; batch adversarial loss: 0.533871\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391917; batch adversarial loss: 0.564185\n",
      "epoch 88; iter: 0; batch classifier loss: 0.498953; batch adversarial loss: 0.490851\n",
      "epoch 89; iter: 0; batch classifier loss: 0.474419; batch adversarial loss: 0.524301\n",
      "epoch 90; iter: 0; batch classifier loss: 0.454528; batch adversarial loss: 0.562011\n",
      "epoch 91; iter: 0; batch classifier loss: 0.453836; batch adversarial loss: 0.481977\n",
      "epoch 92; iter: 0; batch classifier loss: 0.465828; batch adversarial loss: 0.515437\n",
      "epoch 93; iter: 0; batch classifier loss: 0.419400; batch adversarial loss: 0.524504\n",
      "epoch 94; iter: 0; batch classifier loss: 0.454556; batch adversarial loss: 0.498030\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428735; batch adversarial loss: 0.544996\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394242; batch adversarial loss: 0.582768\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338407; batch adversarial loss: 0.523048\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358877; batch adversarial loss: 0.471622\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355432; batch adversarial loss: 0.552424\n",
      "epoch 100; iter: 0; batch classifier loss: 0.354495; batch adversarial loss: 0.450354\n",
      "epoch 101; iter: 0; batch classifier loss: 0.452281; batch adversarial loss: 0.581301\n",
      "epoch 102; iter: 0; batch classifier loss: 0.456441; batch adversarial loss: 0.543859\n",
      "epoch 103; iter: 0; batch classifier loss: 0.452988; batch adversarial loss: 0.596587\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423890; batch adversarial loss: 0.552222\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379545; batch adversarial loss: 0.527109\n",
      "epoch 106; iter: 0; batch classifier loss: 0.422144; batch adversarial loss: 0.627957\n",
      "epoch 107; iter: 0; batch classifier loss: 0.369090; batch adversarial loss: 0.517935\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379254; batch adversarial loss: 0.534140\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377209; batch adversarial loss: 0.517432\n",
      "epoch 110; iter: 0; batch classifier loss: 0.354704; batch adversarial loss: 0.585971\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401816; batch adversarial loss: 0.525758\n",
      "epoch 112; iter: 0; batch classifier loss: 0.465398; batch adversarial loss: 0.590443\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419786; batch adversarial loss: 0.479985\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358006; batch adversarial loss: 0.582029\n",
      "epoch 115; iter: 0; batch classifier loss: 0.459560; batch adversarial loss: 0.470432\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351336; batch adversarial loss: 0.527033\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388573; batch adversarial loss: 0.545084\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341830; batch adversarial loss: 0.571828\n",
      "epoch 119; iter: 0; batch classifier loss: 0.454319; batch adversarial loss: 0.534377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400859; batch adversarial loss: 0.479375\n",
      "epoch 121; iter: 0; batch classifier loss: 0.415273; batch adversarial loss: 0.572331\n",
      "epoch 122; iter: 0; batch classifier loss: 0.337522; batch adversarial loss: 0.544394\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381190; batch adversarial loss: 0.543152\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329894; batch adversarial loss: 0.516552\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369925; batch adversarial loss: 0.443647\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317267; batch adversarial loss: 0.572453\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401484; batch adversarial loss: 0.487816\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355616; batch adversarial loss: 0.579782\n",
      "epoch 129; iter: 0; batch classifier loss: 0.407114; batch adversarial loss: 0.571021\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388945; batch adversarial loss: 0.535649\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321224; batch adversarial loss: 0.598649\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380480; batch adversarial loss: 0.561356\n",
      "epoch 133; iter: 0; batch classifier loss: 0.405027; batch adversarial loss: 0.591577\n",
      "epoch 134; iter: 0; batch classifier loss: 0.436959; batch adversarial loss: 0.536008\n",
      "epoch 135; iter: 0; batch classifier loss: 0.482850; batch adversarial loss: 0.497348\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333818; batch adversarial loss: 0.535637\n",
      "epoch 137; iter: 0; batch classifier loss: 0.450960; batch adversarial loss: 0.590997\n",
      "epoch 138; iter: 0; batch classifier loss: 0.389909; batch adversarial loss: 0.487959\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384246; batch adversarial loss: 0.665996\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352519; batch adversarial loss: 0.554815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.384113; batch adversarial loss: 0.589707\n",
      "epoch 142; iter: 0; batch classifier loss: 0.411806; batch adversarial loss: 0.572258\n",
      "epoch 143; iter: 0; batch classifier loss: 0.293709; batch adversarial loss: 0.562945\n",
      "epoch 144; iter: 0; batch classifier loss: 0.283627; batch adversarial loss: 0.536391\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371024; batch adversarial loss: 0.526664\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376379; batch adversarial loss: 0.599369\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340882; batch adversarial loss: 0.572348\n",
      "epoch 148; iter: 0; batch classifier loss: 0.421508; batch adversarial loss: 0.488870\n",
      "epoch 149; iter: 0; batch classifier loss: 0.399841; batch adversarial loss: 0.562777\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341593; batch adversarial loss: 0.543723\n",
      "epoch 151; iter: 0; batch classifier loss: 0.321907; batch adversarial loss: 0.488454\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364764; batch adversarial loss: 0.554011\n",
      "epoch 153; iter: 0; batch classifier loss: 0.406760; batch adversarial loss: 0.590098\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376741; batch adversarial loss: 0.553136\n",
      "epoch 155; iter: 0; batch classifier loss: 0.279036; batch adversarial loss: 0.563839\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352225; batch adversarial loss: 0.506734\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418211; batch adversarial loss: 0.573432\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343030; batch adversarial loss: 0.571601\n",
      "epoch 159; iter: 0; batch classifier loss: 0.320028; batch adversarial loss: 0.488355\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349264; batch adversarial loss: 0.478036\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424345; batch adversarial loss: 0.545339\n",
      "epoch 162; iter: 0; batch classifier loss: 0.335989; batch adversarial loss: 0.517014\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354835; batch adversarial loss: 0.581585\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328942; batch adversarial loss: 0.607886\n",
      "epoch 165; iter: 0; batch classifier loss: 0.406947; batch adversarial loss: 0.533847\n",
      "epoch 166; iter: 0; batch classifier loss: 0.272002; batch adversarial loss: 0.543320\n",
      "epoch 167; iter: 0; batch classifier loss: 0.357968; batch adversarial loss: 0.514726\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354383; batch adversarial loss: 0.573888\n",
      "epoch 169; iter: 0; batch classifier loss: 0.461247; batch adversarial loss: 0.533431\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366845; batch adversarial loss: 0.533129\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372603; batch adversarial loss: 0.536831\n",
      "epoch 172; iter: 0; batch classifier loss: 0.440610; batch adversarial loss: 0.601052\n",
      "epoch 173; iter: 0; batch classifier loss: 0.352292; batch adversarial loss: 0.551232\n",
      "epoch 174; iter: 0; batch classifier loss: 0.319959; batch adversarial loss: 0.583265\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368759; batch adversarial loss: 0.554730\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323897; batch adversarial loss: 0.518885\n",
      "epoch 177; iter: 0; batch classifier loss: 0.443980; batch adversarial loss: 0.561107\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328045; batch adversarial loss: 0.499834\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353346; batch adversarial loss: 0.535261\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391517; batch adversarial loss: 0.499024\n",
      "epoch 181; iter: 0; batch classifier loss: 0.340694; batch adversarial loss: 0.471860\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340491; batch adversarial loss: 0.535760\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342399; batch adversarial loss: 0.533890\n",
      "epoch 184; iter: 0; batch classifier loss: 0.368228; batch adversarial loss: 0.525983\n",
      "epoch 185; iter: 0; batch classifier loss: 0.464486; batch adversarial loss: 0.513979\n",
      "epoch 186; iter: 0; batch classifier loss: 0.321750; batch adversarial loss: 0.543049\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364930; batch adversarial loss: 0.535813\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334444; batch adversarial loss: 0.534675\n",
      "epoch 189; iter: 0; batch classifier loss: 0.512775; batch adversarial loss: 0.535475\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367149; batch adversarial loss: 0.459681\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368085; batch adversarial loss: 0.516775\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346593; batch adversarial loss: 0.627596\n",
      "epoch 193; iter: 0; batch classifier loss: 0.427181; batch adversarial loss: 0.554682\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364509; batch adversarial loss: 0.491120\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399584; batch adversarial loss: 0.573219\n",
      "epoch 196; iter: 0; batch classifier loss: 0.382472; batch adversarial loss: 0.609945\n",
      "epoch 197; iter: 0; batch classifier loss: 0.442463; batch adversarial loss: 0.544536\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397826; batch adversarial loss: 0.497367\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356183; batch adversarial loss: 0.544863\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb43e5",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "443add40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9be106d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a18a9",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a721b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59930abc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e766402b",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66b5de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a212294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5963e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
