{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "302e2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3766619a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941e56fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73acdde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b267524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621d630c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563dd827",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258fe0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSPublicCoverageDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15cfa70",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65bdaf58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_pubcov'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_CA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09ad24",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d757bfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f3cfa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cb104f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bf843ff8-62e9-4aac-83bc-d805e3299fdc\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6cad9",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31752c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>ESR</th>\n",
       "      <th>ST</th>\n",
       "      <th>FER</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL MAR SEX DIS ESP CIT MIG MIL ANC NATIVITY DEAR DEYE DREM ESR ST FER  \\\n",
       "0   19   5   1   2   0   1   3   4   1        1    2    2    2   6  6   0   \n",
       "1   16   5   1   2   0   3   3   4   4        1    2    2    2   1  6   0   \n",
       "2   13   5   2   2   1   1   1   0   2        1    2    2    2   6  6   2   \n",
       "3   20   1   2   2   0   4   1   4   1        2    2    2    2   6  6   2   \n",
       "4   16   1   2   2   0   4   1   4   1        2    2    2    2   6  6   0   \n",
       "\n",
       "  RAC1P  AGEP   PINCP  \n",
       "0     1    21  3150.0  \n",
       "1     9    18  1600.0  \n",
       "2     1    16     0.0  \n",
       "3     8    43     0.0  \n",
       "4     6    54     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSPublicCoverageDataset(state=['CA'], year=2018, with_nulls=False,\n",
    "                                       subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b22bdbf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e0ae06",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21254493",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3f611d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b500e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': '84eeb5f0-4ebe-4d9f-94ef-53ae302c2264'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0774252fc3d84263b3f1952d6646e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb71fcf4f547769fec45358ef2d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81e93a7c9ca4b759124ebae6b6a39d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2024-01-08 14:47:02.022905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706076; batch adversarial loss: 0.692046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528616; batch adversarial loss: 0.690824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437058; batch adversarial loss: 0.641205\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374626; batch adversarial loss: 0.591401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.578531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.540871\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253209; batch adversarial loss: 0.536458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249384; batch adversarial loss: 0.510654\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222574; batch adversarial loss: 0.526174\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231929; batch adversarial loss: 0.544187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269365; batch adversarial loss: 0.530938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.269131; batch adversarial loss: 0.499622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209271; batch adversarial loss: 0.500838\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232830; batch adversarial loss: 0.522906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200820; batch adversarial loss: 0.444583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175221; batch adversarial loss: 0.468809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195260; batch adversarial loss: 0.487876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.108377; batch adversarial loss: 0.462686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.154744; batch adversarial loss: 0.465643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.114956; batch adversarial loss: 0.518928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185771; batch adversarial loss: 0.457848\n",
      "epoch 21; iter: 0; batch classifier loss: 0.114915; batch adversarial loss: 0.514133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.135782; batch adversarial loss: 0.513373\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134654; batch adversarial loss: 0.569677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175153; batch adversarial loss: 0.454520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180932; batch adversarial loss: 0.524089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194350; batch adversarial loss: 0.554577\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175350; batch adversarial loss: 0.572550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203875; batch adversarial loss: 0.621340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.584977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192389; batch adversarial loss: 0.494302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166049; batch adversarial loss: 0.488495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181273; batch adversarial loss: 0.477612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197128; batch adversarial loss: 0.508084\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233774; batch adversarial loss: 0.480641\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171880; batch adversarial loss: 0.430034\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272469; batch adversarial loss: 0.529935\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227646; batch adversarial loss: 0.448445\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163945; batch adversarial loss: 0.406804\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079406; batch adversarial loss: 0.448137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091811; batch adversarial loss: 0.446052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.067578; batch adversarial loss: 0.525227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.059282; batch adversarial loss: 0.496629\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104444; batch adversarial loss: 0.455580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119299; batch adversarial loss: 0.454710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076554; batch adversarial loss: 0.489845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086420; batch adversarial loss: 0.475786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067454; batch adversarial loss: 0.383989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099616; batch adversarial loss: 0.504962\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129307; batch adversarial loss: 0.369170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074693; batch adversarial loss: 0.344991\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073794; batch adversarial loss: 0.533122\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101932; batch adversarial loss: 0.551938\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079983; batch adversarial loss: 0.460136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074297; batch adversarial loss: 0.473660\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119616; batch adversarial loss: 0.417397\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096468; batch adversarial loss: 0.344682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112178; batch adversarial loss: 0.483005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097981; batch adversarial loss: 0.495853\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082937; batch adversarial loss: 0.485810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061327; batch adversarial loss: 0.522080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090307; batch adversarial loss: 0.448743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047843; batch adversarial loss: 0.452977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065588; batch adversarial loss: 0.387373\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098521; batch adversarial loss: 0.422866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058718; batch adversarial loss: 0.489143\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089657; batch adversarial loss: 0.364338\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069073; batch adversarial loss: 0.508808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079268; batch adversarial loss: 0.435710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075794; batch adversarial loss: 0.451353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103014; batch adversarial loss: 0.524944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079265; batch adversarial loss: 0.458990\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054589; batch adversarial loss: 0.416570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.571959\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075297; batch adversarial loss: 0.431452\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071271; batch adversarial loss: 0.468172\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070982; batch adversarial loss: 0.451261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076285; batch adversarial loss: 0.433854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062035; batch adversarial loss: 0.504788\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075761; batch adversarial loss: 0.467174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098143; batch adversarial loss: 0.505237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084273; batch adversarial loss: 0.357909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071487; batch adversarial loss: 0.473864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121158; batch adversarial loss: 0.486395\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.409071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065818; batch adversarial loss: 0.503372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082517; batch adversarial loss: 0.587905\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.466063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.564533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089993; batch adversarial loss: 0.390280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082860; batch adversarial loss: 0.463198\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047112; batch adversarial loss: 0.537224\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101391; batch adversarial loss: 0.538014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.131220; batch adversarial loss: 0.459360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.109573; batch adversarial loss: 0.465781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054340; batch adversarial loss: 0.397680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.495775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062126; batch adversarial loss: 0.498909\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.431311\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102993; batch adversarial loss: 0.376494\n",
      "epoch 100; iter: 0; batch classifier loss: 0.102044; batch adversarial loss: 0.357074\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054333; batch adversarial loss: 0.467210\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054543; batch adversarial loss: 0.427762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.450090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065666; batch adversarial loss: 0.440686\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081424; batch adversarial loss: 0.314604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067678; batch adversarial loss: 0.510275\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063083; batch adversarial loss: 0.474941\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019212; batch adversarial loss: 0.407522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034522; batch adversarial loss: 0.409571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058404; batch adversarial loss: 0.502819\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040291; batch adversarial loss: 0.444476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042527; batch adversarial loss: 0.447824\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.419865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054878; batch adversarial loss: 0.463392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053708; batch adversarial loss: 0.508642\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035963; batch adversarial loss: 0.455745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072132; batch adversarial loss: 0.499220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043367; batch adversarial loss: 0.420356\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048310; batch adversarial loss: 0.492525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074792; batch adversarial loss: 0.405318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.584632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066402; batch adversarial loss: 0.514826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.436852\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040002; batch adversarial loss: 0.377582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017416; batch adversarial loss: 0.497774\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071384; batch adversarial loss: 0.499982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037890; batch adversarial loss: 0.466903\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.433337\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043349; batch adversarial loss: 0.491828\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017410; batch adversarial loss: 0.436271\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050517; batch adversarial loss: 0.450991\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047536; batch adversarial loss: 0.512238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013396; batch adversarial loss: 0.419450\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069495; batch adversarial loss: 0.453873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.442644\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.452397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046000; batch adversarial loss: 0.442586\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029759; batch adversarial loss: 0.361690\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037082; batch adversarial loss: 0.530520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061619; batch adversarial loss: 0.476281\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027611; batch adversarial loss: 0.463160\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.430123\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.542561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.402583\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.458558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052981; batch adversarial loss: 0.499904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052879; batch adversarial loss: 0.468605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.437735\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013094; batch adversarial loss: 0.392392\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054930; batch adversarial loss: 0.392228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033070; batch adversarial loss: 0.429573\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013686; batch adversarial loss: 0.480302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025517; batch adversarial loss: 0.474301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026941; batch adversarial loss: 0.397288\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021937; batch adversarial loss: 0.382238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.386828\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029149; batch adversarial loss: 0.362087\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032100; batch adversarial loss: 0.514566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026255; batch adversarial loss: 0.514117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030920; batch adversarial loss: 0.367334\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015507; batch adversarial loss: 0.385345\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041188; batch adversarial loss: 0.557631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038723; batch adversarial loss: 0.467234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.458803\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.389683\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.340316\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030933; batch adversarial loss: 0.488713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.493203\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040985; batch adversarial loss: 0.462638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028517; batch adversarial loss: 0.418939\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026486; batch adversarial loss: 0.536990\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020521; batch adversarial loss: 0.486689\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030953; batch adversarial loss: 0.454736\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006511; batch adversarial loss: 0.437390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016025; batch adversarial loss: 0.431013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.506947\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.402723\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.441069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010429; batch adversarial loss: 0.496293\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.415183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021063; batch adversarial loss: 0.424210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.479177\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011231; batch adversarial loss: 0.444569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027491; batch adversarial loss: 0.465693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033915; batch adversarial loss: 0.559489\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023120; batch adversarial loss: 0.453808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012470; batch adversarial loss: 0.402795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.427348\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041508; batch adversarial loss: 0.460209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.323445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039655; batch adversarial loss: 0.390811\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015852; batch adversarial loss: 0.466843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035564; batch adversarial loss: 0.504015\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008910; batch adversarial loss: 0.485968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056930; batch adversarial loss: 0.580673\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.370200\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.446720\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041652; batch adversarial loss: 0.417590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012187; batch adversarial loss: 0.526439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:38.105341: W tensorflow/c/c_api.cc:304] Operation '{name:'04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:784 op device:{requested: '', assigned: ''} def:{{{node 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706066; batch adversarial loss: 0.736104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530403; batch adversarial loss: 0.678148\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459406; batch adversarial loss: 0.631632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.603996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406459; batch adversarial loss: 0.622275\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.592824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326480; batch adversarial loss: 0.557714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264814; batch adversarial loss: 0.563979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309007; batch adversarial loss: 0.561000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337536; batch adversarial loss: 0.511946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.497081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326900; batch adversarial loss: 0.521918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282505; batch adversarial loss: 0.507427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.319482; batch adversarial loss: 0.490685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297245; batch adversarial loss: 0.530186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348114; batch adversarial loss: 0.492884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315601; batch adversarial loss: 0.543774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353514; batch adversarial loss: 0.479612\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284691; batch adversarial loss: 0.557426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321636; batch adversarial loss: 0.461743\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313884; batch adversarial loss: 0.535758\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.452499\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307755; batch adversarial loss: 0.462012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.481600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280347; batch adversarial loss: 0.487124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349690; batch adversarial loss: 0.456283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296061; batch adversarial loss: 0.497201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.333900; batch adversarial loss: 0.465661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244060; batch adversarial loss: 0.450193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281684; batch adversarial loss: 0.416492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234843; batch adversarial loss: 0.482024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302185; batch adversarial loss: 0.407197\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187466; batch adversarial loss: 0.474231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230678; batch adversarial loss: 0.523563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241098; batch adversarial loss: 0.496128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299920; batch adversarial loss: 0.424774\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261082; batch adversarial loss: 0.428908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260111; batch adversarial loss: 0.474318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284937; batch adversarial loss: 0.372036\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288252; batch adversarial loss: 0.389466\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252943; batch adversarial loss: 0.422020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203067; batch adversarial loss: 0.377419\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247434; batch adversarial loss: 0.503243\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251894; batch adversarial loss: 0.407028\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323468; batch adversarial loss: 0.434153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277021; batch adversarial loss: 0.421189\n",
      "epoch 46; iter: 0; batch classifier loss: 0.304496; batch adversarial loss: 0.501504\n",
      "epoch 47; iter: 0; batch classifier loss: 0.246984; batch adversarial loss: 0.447492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231022; batch adversarial loss: 0.519735\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179348; batch adversarial loss: 0.410107\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257322; batch adversarial loss: 0.496071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267536; batch adversarial loss: 0.423316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.341285; batch adversarial loss: 0.459359\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095520; batch adversarial loss: 0.458750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.434297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125691; batch adversarial loss: 0.351374\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099187; batch adversarial loss: 0.398515\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078252; batch adversarial loss: 0.323342\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138991; batch adversarial loss: 0.535808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090362; batch adversarial loss: 0.529794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081609; batch adversarial loss: 0.375216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.478639\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108687; batch adversarial loss: 0.408623\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104107; batch adversarial loss: 0.481544\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044141; batch adversarial loss: 0.368196\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082003; batch adversarial loss: 0.465862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105736; batch adversarial loss: 0.443595\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073735; batch adversarial loss: 0.489333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060975; batch adversarial loss: 0.436080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.429296\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049926; batch adversarial loss: 0.365259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083830; batch adversarial loss: 0.494927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074709; batch adversarial loss: 0.461633\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111192; batch adversarial loss: 0.433871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039334; batch adversarial loss: 0.515788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071055; batch adversarial loss: 0.406289\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082684; batch adversarial loss: 0.357580\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067315; batch adversarial loss: 0.511623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069397; batch adversarial loss: 0.385906\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075082; batch adversarial loss: 0.456910\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048823; batch adversarial loss: 0.406157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081523; batch adversarial loss: 0.411017\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091294; batch adversarial loss: 0.499160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064026; batch adversarial loss: 0.350682\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042356; batch adversarial loss: 0.517212\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.350081\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035308; batch adversarial loss: 0.443477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.374428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.407967\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102669; batch adversarial loss: 0.389595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099464; batch adversarial loss: 0.437800\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056865; batch adversarial loss: 0.437627\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.460328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036856; batch adversarial loss: 0.436436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.363280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105770; batch adversarial loss: 0.378147\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056142; batch adversarial loss: 0.399404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037050; batch adversarial loss: 0.386856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067514; batch adversarial loss: 0.414906\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097396; batch adversarial loss: 0.436210\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066562; batch adversarial loss: 0.466013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042754; batch adversarial loss: 0.375284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046262; batch adversarial loss: 0.387627\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060422; batch adversarial loss: 0.400367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047418; batch adversarial loss: 0.438297\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084870; batch adversarial loss: 0.451563\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083724; batch adversarial loss: 0.437510\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024412; batch adversarial loss: 0.500079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077510; batch adversarial loss: 0.362601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072262; batch adversarial loss: 0.485094\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028390; batch adversarial loss: 0.414303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066319; batch adversarial loss: 0.512818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047636; batch adversarial loss: 0.424238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041746; batch adversarial loss: 0.410702\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.448275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.529532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065540; batch adversarial loss: 0.429329\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055839; batch adversarial loss: 0.436495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044993; batch adversarial loss: 0.402658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073519; batch adversarial loss: 0.378357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068609; batch adversarial loss: 0.464458\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.518541\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059184; batch adversarial loss: 0.345951\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.421292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041276; batch adversarial loss: 0.383915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049520; batch adversarial loss: 0.421313\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.363910\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.449873\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.476491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.436265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.083309; batch adversarial loss: 0.409344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066746; batch adversarial loss: 0.464579\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066838; batch adversarial loss: 0.375523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060657; batch adversarial loss: 0.382825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.450408\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059749; batch adversarial loss: 0.403990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.450985\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.574739\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065396; batch adversarial loss: 0.398369\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.476669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.481624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.499269\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049504; batch adversarial loss: 0.316459\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070289; batch adversarial loss: 0.535042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.366865\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046085; batch adversarial loss: 0.375202\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.446702\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.384226\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049078; batch adversarial loss: 0.387665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039845; batch adversarial loss: 0.441024\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.414215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038650; batch adversarial loss: 0.382847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031766; batch adversarial loss: 0.458061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022421; batch adversarial loss: 0.437063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039472; batch adversarial loss: 0.480207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034906; batch adversarial loss: 0.514492\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.377841\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028500; batch adversarial loss: 0.396452\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.453429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033487; batch adversarial loss: 0.445524\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044612; batch adversarial loss: 0.459001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017963; batch adversarial loss: 0.343711\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052142; batch adversarial loss: 0.403664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.421914\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032402; batch adversarial loss: 0.472692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.418011\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.452449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.458858\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.402869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.471132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.480702\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014721; batch adversarial loss: 0.471981\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034698; batch adversarial loss: 0.427563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026398; batch adversarial loss: 0.372757\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.371487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039552; batch adversarial loss: 0.394009\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.377999\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029643; batch adversarial loss: 0.450269\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.445277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.446072\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.375977\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025078; batch adversarial loss: 0.362209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031550; batch adversarial loss: 0.392815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.382241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027336; batch adversarial loss: 0.445629\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022268; batch adversarial loss: 0.451700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025109; batch adversarial loss: 0.451593\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.427051\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013901; batch adversarial loss: 0.616939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016848; batch adversarial loss: 0.451149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016180; batch adversarial loss: 0.478983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.362182\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.432742\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.409336\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.408788\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013846; batch adversarial loss: 0.398356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.364331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007561; batch adversarial loss: 0.454264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007466; batch adversarial loss: 0.421940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035742; batch adversarial loss: 0.398075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:13.265192: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:1591 op device:{requested: '', assigned: ''} def:{{{node 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688129; batch adversarial loss: 0.582458\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418286; batch adversarial loss: 0.582047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525055; batch adversarial loss: 0.583817\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428255; batch adversarial loss: 0.520912\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.566984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340495; batch adversarial loss: 0.611152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408788; batch adversarial loss: 0.555860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.536746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377252; batch adversarial loss: 0.547035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416875; batch adversarial loss: 0.571816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458405; batch adversarial loss: 0.447826\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361180; batch adversarial loss: 0.517236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285615; batch adversarial loss: 0.506002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346196; batch adversarial loss: 0.575380\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283920; batch adversarial loss: 0.515648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200360; batch adversarial loss: 0.501168\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243708; batch adversarial loss: 0.432575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178450; batch adversarial loss: 0.420903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254595; batch adversarial loss: 0.438466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257026; batch adversarial loss: 0.496501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.502721\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232064; batch adversarial loss: 0.468430\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189602; batch adversarial loss: 0.435759\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213089; batch adversarial loss: 0.513310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195573; batch adversarial loss: 0.461283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202941; batch adversarial loss: 0.458565\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216715; batch adversarial loss: 0.509816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226038; batch adversarial loss: 0.503132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185449; batch adversarial loss: 0.474548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197551; batch adversarial loss: 0.513540\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198968; batch adversarial loss: 0.444631\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178431; batch adversarial loss: 0.418701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165924; batch adversarial loss: 0.471863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200710; batch adversarial loss: 0.389130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215499; batch adversarial loss: 0.398050\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148965; batch adversarial loss: 0.436479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.196180; batch adversarial loss: 0.435999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219984; batch adversarial loss: 0.414746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253643; batch adversarial loss: 0.502879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148975; batch adversarial loss: 0.460152\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182249; batch adversarial loss: 0.430215\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212471; batch adversarial loss: 0.516455\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204900; batch adversarial loss: 0.486186\n",
      "epoch 43; iter: 0; batch classifier loss: 0.273834; batch adversarial loss: 0.370007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.184662; batch adversarial loss: 0.446620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211863; batch adversarial loss: 0.532505\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246754; batch adversarial loss: 0.378046\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.432995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217221; batch adversarial loss: 0.504403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199260; batch adversarial loss: 0.494291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225734; batch adversarial loss: 0.469332\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280469; batch adversarial loss: 0.450357\n",
      "epoch 52; iter: 0; batch classifier loss: 0.256328; batch adversarial loss: 0.400179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.235736; batch adversarial loss: 0.472313\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268841; batch adversarial loss: 0.423809\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215488; batch adversarial loss: 0.494381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.156838; batch adversarial loss: 0.493873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067571; batch adversarial loss: 0.446264\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103650; batch adversarial loss: 0.479958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080905; batch adversarial loss: 0.476880\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087581; batch adversarial loss: 0.438387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.527533\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069701; batch adversarial loss: 0.451979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092830; batch adversarial loss: 0.408839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179970; batch adversarial loss: 0.439693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190992; batch adversarial loss: 0.491628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146571; batch adversarial loss: 0.574472\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124498; batch adversarial loss: 0.413266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.170022; batch adversarial loss: 0.442749\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124150; batch adversarial loss: 0.469246\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086658; batch adversarial loss: 0.446183\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097854; batch adversarial loss: 0.510166\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098005; batch adversarial loss: 0.506230\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103036; batch adversarial loss: 0.476823\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119643; batch adversarial loss: 0.513143\n",
      "epoch 75; iter: 0; batch classifier loss: 0.154620; batch adversarial loss: 0.419525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.417197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090060; batch adversarial loss: 0.433126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108649; batch adversarial loss: 0.491992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072665; batch adversarial loss: 0.427414\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078432; batch adversarial loss: 0.416684\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081628; batch adversarial loss: 0.618467\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081460; batch adversarial loss: 0.451962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083842; batch adversarial loss: 0.409290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065025; batch adversarial loss: 0.527774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076811; batch adversarial loss: 0.395808\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080542; batch adversarial loss: 0.426802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035755; batch adversarial loss: 0.457259\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075089; batch adversarial loss: 0.522649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073160; batch adversarial loss: 0.524856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075504; batch adversarial loss: 0.454985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082712; batch adversarial loss: 0.468551\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081159; batch adversarial loss: 0.424298\n",
      "epoch 93; iter: 0; batch classifier loss: 0.105341; batch adversarial loss: 0.483678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103236; batch adversarial loss: 0.413750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.477983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096910; batch adversarial loss: 0.419712\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088785; batch adversarial loss: 0.338753\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056480; batch adversarial loss: 0.493365\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078842; batch adversarial loss: 0.472535\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.404357\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062635; batch adversarial loss: 0.445790\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078453; batch adversarial loss: 0.472064\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038869; batch adversarial loss: 0.438187\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.479073\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.491621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031616; batch adversarial loss: 0.548412\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.448620\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.465527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.452133\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.402920\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019532; batch adversarial loss: 0.465544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056462; batch adversarial loss: 0.441909\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072204; batch adversarial loss: 0.602850\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.479939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050471; batch adversarial loss: 0.433319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060567; batch adversarial loss: 0.398176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047180; batch adversarial loss: 0.439185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029035; batch adversarial loss: 0.418488\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033030; batch adversarial loss: 0.450658\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051230; batch adversarial loss: 0.409980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034502; batch adversarial loss: 0.483479\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066685; batch adversarial loss: 0.415055\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036303; batch adversarial loss: 0.464543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.493312\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030684; batch adversarial loss: 0.400999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.445230\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032854; batch adversarial loss: 0.453296\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026536; batch adversarial loss: 0.507458\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.440097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.370093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036277; batch adversarial loss: 0.417342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.464351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032374; batch adversarial loss: 0.545062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.349027\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016774; batch adversarial loss: 0.495524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030935; batch adversarial loss: 0.449530\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.456351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013323; batch adversarial loss: 0.456658\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030194; batch adversarial loss: 0.510743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021454; batch adversarial loss: 0.356752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028846; batch adversarial loss: 0.352905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023706; batch adversarial loss: 0.536787\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019686; batch adversarial loss: 0.470078\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041820; batch adversarial loss: 0.487558\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011119; batch adversarial loss: 0.483874\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030574; batch adversarial loss: 0.457222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024936; batch adversarial loss: 0.558170\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.372945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.432468\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023059; batch adversarial loss: 0.319447\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.445123\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013528; batch adversarial loss: 0.437946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.482155\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012327; batch adversarial loss: 0.448138\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.413030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040082; batch adversarial loss: 0.496351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021876; batch adversarial loss: 0.453756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029481; batch adversarial loss: 0.465553\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004143; batch adversarial loss: 0.414448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013102; batch adversarial loss: 0.464395\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008841; batch adversarial loss: 0.449652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.577473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012078; batch adversarial loss: 0.431391\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005280; batch adversarial loss: 0.348936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.531446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007558; batch adversarial loss: 0.368732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007948; batch adversarial loss: 0.418823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011378; batch adversarial loss: 0.462137\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012475; batch adversarial loss: 0.522107\n",
      "epoch 170; iter: 0; batch classifier loss: 0.089205; batch adversarial loss: 0.425102\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013193; batch adversarial loss: 0.438883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.464129\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.464161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.416692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.454887\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003722; batch adversarial loss: 0.416714\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009313; batch adversarial loss: 0.439547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013868; batch adversarial loss: 0.486130\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022029; batch adversarial loss: 0.498505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008864; batch adversarial loss: 0.420729\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038184; batch adversarial loss: 0.417415\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.408334\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026545; batch adversarial loss: 0.569768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006229; batch adversarial loss: 0.342425\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011448; batch adversarial loss: 0.482688\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023002; batch adversarial loss: 0.445266\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004066; batch adversarial loss: 0.428464\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003665; batch adversarial loss: 0.430902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027354; batch adversarial loss: 0.399141\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005157; batch adversarial loss: 0.474395\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.400792\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050361; batch adversarial loss: 0.441677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.475218\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006026; batch adversarial loss: 0.468294\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.498031\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.443660\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005842; batch adversarial loss: 0.529499\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009330; batch adversarial loss: 0.451309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.396820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:49.999533: W tensorflow/c/c_api.cc:304] Operation '{name:'04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:2398 op device:{requested: '', assigned: ''} def:{{{node 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709423; batch adversarial loss: 0.826485\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589269; batch adversarial loss: 0.774333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.757826; batch adversarial loss: 0.757554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651808; batch adversarial loss: 0.683050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559073; batch adversarial loss: 0.616526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383718; batch adversarial loss: 0.587390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361682; batch adversarial loss: 0.608442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300812; batch adversarial loss: 0.533616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428041; batch adversarial loss: 0.522132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334713; batch adversarial loss: 0.554177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.478305\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403465; batch adversarial loss: 0.537060\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316303; batch adversarial loss: 0.511609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331920; batch adversarial loss: 0.503228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314666; batch adversarial loss: 0.467400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338908; batch adversarial loss: 0.471192\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334456; batch adversarial loss: 0.463481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237582; batch adversarial loss: 0.487386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243639; batch adversarial loss: 0.559268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223562; batch adversarial loss: 0.497359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.560765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308990; batch adversarial loss: 0.482442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294239; batch adversarial loss: 0.508942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245820; batch adversarial loss: 0.469365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199940; batch adversarial loss: 0.491858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237852; batch adversarial loss: 0.483418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248950; batch adversarial loss: 0.494269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215890; batch adversarial loss: 0.493594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219729; batch adversarial loss: 0.477457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219291; batch adversarial loss: 0.576004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205509; batch adversarial loss: 0.407661\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229055; batch adversarial loss: 0.420588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231041; batch adversarial loss: 0.436854\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188074; batch adversarial loss: 0.454388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252571; batch adversarial loss: 0.415374\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175120; batch adversarial loss: 0.415148\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156770; batch adversarial loss: 0.482264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153350; batch adversarial loss: 0.431682\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211564; batch adversarial loss: 0.467146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260667; batch adversarial loss: 0.425384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224133; batch adversarial loss: 0.424066\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186538; batch adversarial loss: 0.481687\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217674; batch adversarial loss: 0.570059\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.480069\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287237; batch adversarial loss: 0.476578\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318581; batch adversarial loss: 0.362229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227443; batch adversarial loss: 0.465089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194799; batch adversarial loss: 0.446107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306833; batch adversarial loss: 0.507393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202465; batch adversarial loss: 0.537706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223188; batch adversarial loss: 0.423028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225845; batch adversarial loss: 0.447576\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155381; batch adversarial loss: 0.486634\n",
      "epoch 53; iter: 0; batch classifier loss: 0.203742; batch adversarial loss: 0.445566\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250815; batch adversarial loss: 0.460954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182396; batch adversarial loss: 0.564597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178321; batch adversarial loss: 0.466417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135660; batch adversarial loss: 0.492085\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227268; batch adversarial loss: 0.379017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185556; batch adversarial loss: 0.459743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153740; batch adversarial loss: 0.510053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155630; batch adversarial loss: 0.541576\n",
      "epoch 62; iter: 0; batch classifier loss: 0.116137; batch adversarial loss: 0.521728\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178817; batch adversarial loss: 0.517786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213310; batch adversarial loss: 0.396766\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174103; batch adversarial loss: 0.519237\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168989; batch adversarial loss: 0.469374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.438444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227675; batch adversarial loss: 0.382676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129285; batch adversarial loss: 0.448061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153188; batch adversarial loss: 0.513892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189201; batch adversarial loss: 0.483813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143782; batch adversarial loss: 0.399117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.194640; batch adversarial loss: 0.492915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222503; batch adversarial loss: 0.506290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192905; batch adversarial loss: 0.444399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.185618; batch adversarial loss: 0.465811\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102490; batch adversarial loss: 0.387088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.260674; batch adversarial loss: 0.397151\n",
      "epoch 79; iter: 0; batch classifier loss: 0.162815; batch adversarial loss: 0.474389\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195085; batch adversarial loss: 0.410728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132135; batch adversarial loss: 0.481101\n",
      "epoch 82; iter: 0; batch classifier loss: 0.157003; batch adversarial loss: 0.405431\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114738; batch adversarial loss: 0.472957\n",
      "epoch 84; iter: 0; batch classifier loss: 0.124425; batch adversarial loss: 0.469340\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133828; batch adversarial loss: 0.459536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127560; batch adversarial loss: 0.468921\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106405; batch adversarial loss: 0.604421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144443; batch adversarial loss: 0.520639\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117262; batch adversarial loss: 0.506146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087750; batch adversarial loss: 0.443731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113289; batch adversarial loss: 0.463015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128436; batch adversarial loss: 0.406349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095744; batch adversarial loss: 0.532681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072927; batch adversarial loss: 0.510598\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050717; batch adversarial loss: 0.512368\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103528; batch adversarial loss: 0.485659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055867; batch adversarial loss: 0.489014\n",
      "epoch 98; iter: 0; batch classifier loss: 0.119304; batch adversarial loss: 0.409256\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058918; batch adversarial loss: 0.356944\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078266; batch adversarial loss: 0.489582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100184; batch adversarial loss: 0.437631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.432486\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076005; batch adversarial loss: 0.420993\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023383; batch adversarial loss: 0.489630\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.427848\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057579; batch adversarial loss: 0.446779\n",
      "epoch 107; iter: 0; batch classifier loss: 0.016594; batch adversarial loss: 0.571494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043061; batch adversarial loss: 0.435629\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.449064\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.429082\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064466; batch adversarial loss: 0.544246\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.414706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.438979\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041520; batch adversarial loss: 0.450136\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039195; batch adversarial loss: 0.526165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046723; batch adversarial loss: 0.487179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028024; batch adversarial loss: 0.413543\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043546; batch adversarial loss: 0.430986\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042654; batch adversarial loss: 0.482377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.380076\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046653; batch adversarial loss: 0.495118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.513909\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023094; batch adversarial loss: 0.336286\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063677; batch adversarial loss: 0.488526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023231; batch adversarial loss: 0.407590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.499945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025814; batch adversarial loss: 0.477885\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016976; batch adversarial loss: 0.424454\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.436375\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017588; batch adversarial loss: 0.497257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035290; batch adversarial loss: 0.445353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.495507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.398855\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.477906\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012807; batch adversarial loss: 0.425623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030065; batch adversarial loss: 0.464185\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.495098\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036601; batch adversarial loss: 0.409268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009201; batch adversarial loss: 0.415366\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010369; batch adversarial loss: 0.548791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.535071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036020; batch adversarial loss: 0.589606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015933; batch adversarial loss: 0.460440\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012548; batch adversarial loss: 0.467244\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013664; batch adversarial loss: 0.545864\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026615; batch adversarial loss: 0.433055\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026677; batch adversarial loss: 0.394158\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015726; batch adversarial loss: 0.499501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.500811\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023914; batch adversarial loss: 0.507878\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023069; batch adversarial loss: 0.444022\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015060; batch adversarial loss: 0.406906\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.431451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029299; batch adversarial loss: 0.384312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.425266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010244; batch adversarial loss: 0.462371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013574; batch adversarial loss: 0.496028\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.442006\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011610; batch adversarial loss: 0.426134\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.502678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007833; batch adversarial loss: 0.470883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020268; batch adversarial loss: 0.378876\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024588; batch adversarial loss: 0.436137\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023924; batch adversarial loss: 0.466352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030063; batch adversarial loss: 0.400956\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.604907\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008819; batch adversarial loss: 0.359732\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005808; batch adversarial loss: 0.514479\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026108; batch adversarial loss: 0.435591\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.438637\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025742; batch adversarial loss: 0.494849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024279; batch adversarial loss: 0.371164\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.457860\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007689; batch adversarial loss: 0.433103\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013153; batch adversarial loss: 0.531247\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007330; batch adversarial loss: 0.419843\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.491824\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.441699\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.515906\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031273; batch adversarial loss: 0.458018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.432972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.494271\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028760; batch adversarial loss: 0.477630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003358; batch adversarial loss: 0.410230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008431; batch adversarial loss: 0.415887\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012250; batch adversarial loss: 0.528063\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018286; batch adversarial loss: 0.525953\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012842; batch adversarial loss: 0.436430\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.486868\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016325; batch adversarial loss: 0.362743\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025971; batch adversarial loss: 0.450625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002842; batch adversarial loss: 0.520413\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.450268\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011491; batch adversarial loss: 0.497005\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.466075\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.474331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.001744; batch adversarial loss: 0.376615\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002974; batch adversarial loss: 0.495768\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006627; batch adversarial loss: 0.450932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:49:25.594013: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:3205 op device:{requested: '', assigned: ''} def:{{{node 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.683073; batch adversarial loss: 0.620856\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440653; batch adversarial loss: 0.621911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365344; batch adversarial loss: 0.600834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300769; batch adversarial loss: 0.601682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.272899; batch adversarial loss: 0.534356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387933; batch adversarial loss: 0.513569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376173; batch adversarial loss: 0.530133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.561520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275634; batch adversarial loss: 0.532561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282988; batch adversarial loss: 0.506175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250687; batch adversarial loss: 0.404790\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310366; batch adversarial loss: 0.531628\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267975; batch adversarial loss: 0.560586\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.544327\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312451; batch adversarial loss: 0.493957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489029; batch adversarial loss: 0.491952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488049; batch adversarial loss: 0.555351\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559185; batch adversarial loss: 0.456053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281974; batch adversarial loss: 0.509155\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237257; batch adversarial loss: 0.485235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170045; batch adversarial loss: 0.451948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208757; batch adversarial loss: 0.488383\n",
      "epoch 22; iter: 0; batch classifier loss: 0.176183; batch adversarial loss: 0.451187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195614; batch adversarial loss: 0.419134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.445964\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174144; batch adversarial loss: 0.449422\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182457; batch adversarial loss: 0.482860\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198129; batch adversarial loss: 0.478548\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212512; batch adversarial loss: 0.394042\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183227; batch adversarial loss: 0.388321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174824; batch adversarial loss: 0.420980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156038; batch adversarial loss: 0.456845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223948; batch adversarial loss: 0.470265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105976; batch adversarial loss: 0.556003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142961; batch adversarial loss: 0.437921\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196068; batch adversarial loss: 0.411923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141115; batch adversarial loss: 0.470426\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165741; batch adversarial loss: 0.353729\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152037; batch adversarial loss: 0.526223\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099027; batch adversarial loss: 0.464474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110921; batch adversarial loss: 0.452975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089708; batch adversarial loss: 0.475388\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117443; batch adversarial loss: 0.463111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081043; batch adversarial loss: 0.560608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120436; batch adversarial loss: 0.472981\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098060; batch adversarial loss: 0.487844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127252; batch adversarial loss: 0.368227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155660; batch adversarial loss: 0.397125\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104707; batch adversarial loss: 0.495177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094743; batch adversarial loss: 0.437039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128758; batch adversarial loss: 0.367638\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070209; batch adversarial loss: 0.419098\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121524; batch adversarial loss: 0.511020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109622; batch adversarial loss: 0.444450\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133209; batch adversarial loss: 0.376170\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119858; batch adversarial loss: 0.415048\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084955; batch adversarial loss: 0.505013\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079445; batch adversarial loss: 0.437708\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173282; batch adversarial loss: 0.451169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167735; batch adversarial loss: 0.457671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118800; batch adversarial loss: 0.457323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104539; batch adversarial loss: 0.457290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104589; batch adversarial loss: 0.386224\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178848; batch adversarial loss: 0.489418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118512; batch adversarial loss: 0.493791\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118857; batch adversarial loss: 0.426787\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088094; batch adversarial loss: 0.422159\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.431979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.475427\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085103; batch adversarial loss: 0.465173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144985; batch adversarial loss: 0.411650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137528; batch adversarial loss: 0.399713\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100343; batch adversarial loss: 0.345952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114244; batch adversarial loss: 0.513249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079822; batch adversarial loss: 0.488730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163532; batch adversarial loss: 0.430517\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106552; batch adversarial loss: 0.413256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108928; batch adversarial loss: 0.469671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.419774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080087; batch adversarial loss: 0.451439\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133886; batch adversarial loss: 0.384145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108813; batch adversarial loss: 0.489638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127258; batch adversarial loss: 0.392087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086930; batch adversarial loss: 0.473320\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.472512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.449457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.437829\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079782; batch adversarial loss: 0.453353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.143531; batch adversarial loss: 0.466258\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069261; batch adversarial loss: 0.354200\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.470479\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062476; batch adversarial loss: 0.541695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082710; batch adversarial loss: 0.480140\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.473447\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075548; batch adversarial loss: 0.447946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058477; batch adversarial loss: 0.426762\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.453171\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.335832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053453; batch adversarial loss: 0.476380\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073238; batch adversarial loss: 0.586781\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.427228\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042540; batch adversarial loss: 0.432745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071360; batch adversarial loss: 0.362941\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093896; batch adversarial loss: 0.463941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057524; batch adversarial loss: 0.437521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051401; batch adversarial loss: 0.405707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.473556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065696; batch adversarial loss: 0.484608\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.450714\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050737; batch adversarial loss: 0.470143\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064994; batch adversarial loss: 0.515462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064557; batch adversarial loss: 0.451665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038048; batch adversarial loss: 0.495670\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069824; batch adversarial loss: 0.392696\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.484216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044866; batch adversarial loss: 0.430529\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073175; batch adversarial loss: 0.408202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.107425; batch adversarial loss: 0.540736\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043385; batch adversarial loss: 0.383689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049156; batch adversarial loss: 0.482229\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043849; batch adversarial loss: 0.469089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058626; batch adversarial loss: 0.445064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015754; batch adversarial loss: 0.330612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.485688\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.408941\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.451863\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019002; batch adversarial loss: 0.464778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026591; batch adversarial loss: 0.464596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.404924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.422667\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.410978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.448252\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026199; batch adversarial loss: 0.412464\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039348; batch adversarial loss: 0.566884\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051199; batch adversarial loss: 0.374595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.502335\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086487; batch adversarial loss: 0.358220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060143; batch adversarial loss: 0.515063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053990; batch adversarial loss: 0.432021\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.428206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.459213\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.467816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.384554\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.339316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024966; batch adversarial loss: 0.508985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.497956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026609; batch adversarial loss: 0.396169\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042491; batch adversarial loss: 0.516891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.594180\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040416; batch adversarial loss: 0.530106\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020989; batch adversarial loss: 0.460259\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008401; batch adversarial loss: 0.446931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014468; batch adversarial loss: 0.462676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.427720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067858; batch adversarial loss: 0.356513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.426754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.408194\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024619; batch adversarial loss: 0.531720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044226; batch adversarial loss: 0.399916\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024355; batch adversarial loss: 0.398681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.469875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043514; batch adversarial loss: 0.437727\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.424770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.405221\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023990; batch adversarial loss: 0.350152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040421; batch adversarial loss: 0.382282\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045091; batch adversarial loss: 0.472792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046813; batch adversarial loss: 0.379816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026784; batch adversarial loss: 0.394039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.414904\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.413440\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013882; batch adversarial loss: 0.478051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.448272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.448238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065883; batch adversarial loss: 0.425081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.481297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.461707\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051299; batch adversarial loss: 0.391626\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021155; batch adversarial loss: 0.433748\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028798; batch adversarial loss: 0.413467\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019515; batch adversarial loss: 0.445502\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012136; batch adversarial loss: 0.463219\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.507201\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012701; batch adversarial loss: 0.405407\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.458699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.426156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.356023\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017771; batch adversarial loss: 0.448996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058177; batch adversarial loss: 0.411220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014598; batch adversarial loss: 0.374938\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023809; batch adversarial loss: 0.396063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017848; batch adversarial loss: 0.529327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005764; batch adversarial loss: 0.395014\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005059; batch adversarial loss: 0.442585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016724; batch adversarial loss: 0.405878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024334; batch adversarial loss: 0.359202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006897; batch adversarial loss: 0.479158\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007722; batch adversarial loss: 0.473242\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028269; batch adversarial loss: 0.322968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.561645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:50:02.788655: W tensorflow/c/c_api.cc:304] Operation '{name:'04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:4012 op device:{requested: '', assigned: ''} def:{{{node 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688715; batch adversarial loss: 0.983039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628121; batch adversarial loss: 1.100539\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900819; batch adversarial loss: 1.126426\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017392; batch adversarial loss: 1.014833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997079; batch adversarial loss: 0.934127\n",
      "epoch 5; iter: 0; batch classifier loss: 0.972972; batch adversarial loss: 0.840362\n",
      "epoch 6; iter: 0; batch classifier loss: 1.035811; batch adversarial loss: 0.765038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.989932; batch adversarial loss: 0.694059\n",
      "epoch 8; iter: 0; batch classifier loss: 1.016223; batch adversarial loss: 0.648634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.816278; batch adversarial loss: 0.583646\n",
      "epoch 10; iter: 0; batch classifier loss: 0.814806; batch adversarial loss: 0.581283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388503; batch adversarial loss: 0.534007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460209; batch adversarial loss: 0.522313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363631; batch adversarial loss: 0.483172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334066; batch adversarial loss: 0.538998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330832; batch adversarial loss: 0.503753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335103; batch adversarial loss: 0.460181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217084; batch adversarial loss: 0.449338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222560; batch adversarial loss: 0.452156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253071; batch adversarial loss: 0.532440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192251; batch adversarial loss: 0.515274\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195617; batch adversarial loss: 0.457270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.116874; batch adversarial loss: 0.416551\n",
      "epoch 23; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.418451\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130526; batch adversarial loss: 0.442453\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148387; batch adversarial loss: 0.546933\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121442; batch adversarial loss: 0.433987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.104637; batch adversarial loss: 0.486104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.091559; batch adversarial loss: 0.451715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.084214; batch adversarial loss: 0.447392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.066105; batch adversarial loss: 0.413685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.391311\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114118; batch adversarial loss: 0.363025\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084376; batch adversarial loss: 0.496647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109469; batch adversarial loss: 0.473723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130510; batch adversarial loss: 0.433919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102940; batch adversarial loss: 0.484450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109572; batch adversarial loss: 0.418393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.059485; batch adversarial loss: 0.538812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107677; batch adversarial loss: 0.465860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131476; batch adversarial loss: 0.472353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.057669; batch adversarial loss: 0.450761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082112; batch adversarial loss: 0.501039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063107; batch adversarial loss: 0.426068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101416; batch adversarial loss: 0.474336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090052; batch adversarial loss: 0.427132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081061; batch adversarial loss: 0.443573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100561; batch adversarial loss: 0.462411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082665; batch adversarial loss: 0.528099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080586; batch adversarial loss: 0.463851\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.467955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065128; batch adversarial loss: 0.363463\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065074; batch adversarial loss: 0.505935\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062227; batch adversarial loss: 0.450037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082096; batch adversarial loss: 0.483712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098301; batch adversarial loss: 0.472368\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.470020\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061266; batch adversarial loss: 0.469520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091018; batch adversarial loss: 0.460826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088777; batch adversarial loss: 0.368837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072266; batch adversarial loss: 0.417231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088821; batch adversarial loss: 0.371266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084045; batch adversarial loss: 0.388032\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099800; batch adversarial loss: 0.480330\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070695; batch adversarial loss: 0.464629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.461426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091146; batch adversarial loss: 0.408800\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106377; batch adversarial loss: 0.504875\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043170; batch adversarial loss: 0.464844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072073; batch adversarial loss: 0.433548\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.480371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057055; batch adversarial loss: 0.423309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088492; batch adversarial loss: 0.363886\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047265; batch adversarial loss: 0.382111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040557; batch adversarial loss: 0.378222\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.436483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047782; batch adversarial loss: 0.469712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.431864\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059991; batch adversarial loss: 0.420678\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064905; batch adversarial loss: 0.493314\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.376153\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050206; batch adversarial loss: 0.409281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046113; batch adversarial loss: 0.467115\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035233; batch adversarial loss: 0.469703\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029775; batch adversarial loss: 0.505177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042924; batch adversarial loss: 0.485360\n",
      "epoch 86; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.443047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.547391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.348584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.445219\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048613; batch adversarial loss: 0.498932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028670; batch adversarial loss: 0.392131\n",
      "epoch 92; iter: 0; batch classifier loss: 0.024187; batch adversarial loss: 0.528975\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032129; batch adversarial loss: 0.476735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.491378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.406544\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035445; batch adversarial loss: 0.499140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063905; batch adversarial loss: 0.452456\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.370576\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046255; batch adversarial loss: 0.461843\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.526640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037838; batch adversarial loss: 0.428831\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029502; batch adversarial loss: 0.517934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036693; batch adversarial loss: 0.479803\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.462126\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022528; batch adversarial loss: 0.480492\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051269; batch adversarial loss: 0.390230\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.428924\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042159; batch adversarial loss: 0.443559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021290; batch adversarial loss: 0.487578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023505; batch adversarial loss: 0.492512\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017535; batch adversarial loss: 0.410937\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.450347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038833; batch adversarial loss: 0.396705\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033631; batch adversarial loss: 0.478048\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033618; batch adversarial loss: 0.445996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021869; batch adversarial loss: 0.450988\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025700; batch adversarial loss: 0.489628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052874; batch adversarial loss: 0.503270\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044407; batch adversarial loss: 0.487963\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.468673\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042812; batch adversarial loss: 0.489505\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.412301\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036888; batch adversarial loss: 0.312297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.461313\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038236; batch adversarial loss: 0.519647\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039189; batch adversarial loss: 0.494202\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.501105\n",
      "epoch 128; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.499304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018803; batch adversarial loss: 0.537932\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061528; batch adversarial loss: 0.496497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.009915; batch adversarial loss: 0.458411\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034905; batch adversarial loss: 0.429200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.538931\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020050; batch adversarial loss: 0.378343\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036235; batch adversarial loss: 0.495071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033578; batch adversarial loss: 0.513097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.465550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021714; batch adversarial loss: 0.450820\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014111; batch adversarial loss: 0.409608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.388635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.446668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048083; batch adversarial loss: 0.429200\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025612; batch adversarial loss: 0.396818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.315482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024941; batch adversarial loss: 0.376494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041394; batch adversarial loss: 0.386173\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024354; batch adversarial loss: 0.495191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014848; batch adversarial loss: 0.530843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.405986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053988; batch adversarial loss: 0.362676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024418; batch adversarial loss: 0.431975\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030281; batch adversarial loss: 0.427211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.485753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040641; batch adversarial loss: 0.496311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024292; batch adversarial loss: 0.391502\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.431918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.478216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.474453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026862; batch adversarial loss: 0.497809\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.467878\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010025; batch adversarial loss: 0.482063\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.359276\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006330; batch adversarial loss: 0.433474\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029055; batch adversarial loss: 0.578649\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.478374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024393; batch adversarial loss: 0.476705\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.578530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.552534\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.532417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.422551\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.436369\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031451; batch adversarial loss: 0.428115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.416464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021471; batch adversarial loss: 0.379303\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009096; batch adversarial loss: 0.368390\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.411759\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008289; batch adversarial loss: 0.522269\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c4366",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c415b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a06662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb933b4632f547a3ba8301fd5364c345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fe8f8b2384482bacdbfb5f813ffc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce3377f82a7496e821f1474f8b313b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.792746; batch adversarial loss: 1.005012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.949620; batch adversarial loss: 1.258500\n",
      "epoch 2; iter: 0; batch classifier loss: 1.028043; batch adversarial loss: 1.144422\n",
      "epoch 3; iter: 0; batch classifier loss: 1.045848; batch adversarial loss: 1.075771\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997219; batch adversarial loss: 0.978551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.916257; batch adversarial loss: 0.886703\n",
      "epoch 6; iter: 0; batch classifier loss: 0.807742; batch adversarial loss: 0.777476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.756174; batch adversarial loss: 0.765084\n",
      "epoch 8; iter: 0; batch classifier loss: 0.751323; batch adversarial loss: 0.715508\n",
      "epoch 9; iter: 0; batch classifier loss: 0.661528; batch adversarial loss: 0.746465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532497; batch adversarial loss: 0.583311\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556063; batch adversarial loss: 0.609865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509892; batch adversarial loss: 0.630546\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474373; batch adversarial loss: 0.588323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566039; batch adversarial loss: 0.598633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544423; batch adversarial loss: 0.595941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478303; batch adversarial loss: 0.716907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506884; batch adversarial loss: 0.531912\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484061; batch adversarial loss: 0.641703\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484366; batch adversarial loss: 0.609042\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496752; batch adversarial loss: 0.581835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515339; batch adversarial loss: 0.610445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452971; batch adversarial loss: 0.628669\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523714; batch adversarial loss: 0.573860\n",
      "epoch 24; iter: 0; batch classifier loss: 0.551954; batch adversarial loss: 0.637055\n",
      "epoch 25; iter: 0; batch classifier loss: 0.537276; batch adversarial loss: 0.581752\n",
      "epoch 26; iter: 0; batch classifier loss: 0.547402; batch adversarial loss: 0.506395\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469819; batch adversarial loss: 0.534220\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416812; batch adversarial loss: 0.551036\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493869; batch adversarial loss: 0.641932\n",
      "epoch 30; iter: 0; batch classifier loss: 0.531708; batch adversarial loss: 0.561309\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442668; batch adversarial loss: 0.527495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443271; batch adversarial loss: 0.580057\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460209; batch adversarial loss: 0.542188\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452728; batch adversarial loss: 0.526725\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446739; batch adversarial loss: 0.535396\n",
      "epoch 36; iter: 0; batch classifier loss: 0.411418; batch adversarial loss: 0.526741\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381183; batch adversarial loss: 0.591350\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474144; batch adversarial loss: 0.542272\n",
      "epoch 39; iter: 0; batch classifier loss: 0.391220; batch adversarial loss: 0.563944\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457932; batch adversarial loss: 0.532903\n",
      "epoch 41; iter: 0; batch classifier loss: 0.553918; batch adversarial loss: 0.549861\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425170; batch adversarial loss: 0.678241\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447300; batch adversarial loss: 0.573554\n",
      "epoch 44; iter: 0; batch classifier loss: 0.487224; batch adversarial loss: 0.578148\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441893; batch adversarial loss: 0.535556\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458372; batch adversarial loss: 0.556930\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457635; batch adversarial loss: 0.514858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418339; batch adversarial loss: 0.536949\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440917; batch adversarial loss: 0.434020\n",
      "epoch 50; iter: 0; batch classifier loss: 0.377271; batch adversarial loss: 0.489559\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428185; batch adversarial loss: 0.621327\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423307; batch adversarial loss: 0.528065\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379282; batch adversarial loss: 0.603769\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410244; batch adversarial loss: 0.483613\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485713; batch adversarial loss: 0.650918\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435522; batch adversarial loss: 0.614729\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441903; batch adversarial loss: 0.481872\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436907; batch adversarial loss: 0.602565\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466588; batch adversarial loss: 0.537676\n",
      "epoch 60; iter: 0; batch classifier loss: 0.408782; batch adversarial loss: 0.490292\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383416; batch adversarial loss: 0.679512\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432280; batch adversarial loss: 0.493169\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410255; batch adversarial loss: 0.553618\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432599; batch adversarial loss: 0.491637\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411249; batch adversarial loss: 0.644309\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363241; batch adversarial loss: 0.502999\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365622; batch adversarial loss: 0.607404\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412539; batch adversarial loss: 0.518989\n",
      "epoch 69; iter: 0; batch classifier loss: 0.510808; batch adversarial loss: 0.608353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393746; batch adversarial loss: 0.589765\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370487; batch adversarial loss: 0.662113\n",
      "epoch 72; iter: 0; batch classifier loss: 0.503937; batch adversarial loss: 0.563139\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398913; batch adversarial loss: 0.501849\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388977; batch adversarial loss: 0.581100\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457719; batch adversarial loss: 0.599704\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381257; batch adversarial loss: 0.545170\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441764; batch adversarial loss: 0.563725\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401026; batch adversarial loss: 0.544496\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375301; batch adversarial loss: 0.562372\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458166; batch adversarial loss: 0.625902\n",
      "epoch 81; iter: 0; batch classifier loss: 0.293904; batch adversarial loss: 0.571688\n",
      "epoch 82; iter: 0; batch classifier loss: 0.434551; batch adversarial loss: 0.589588\n",
      "epoch 83; iter: 0; batch classifier loss: 0.467505; batch adversarial loss: 0.553599\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367660; batch adversarial loss: 0.517243\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399351; batch adversarial loss: 0.615958\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435392; batch adversarial loss: 0.616422\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392126; batch adversarial loss: 0.562062\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385007; batch adversarial loss: 0.571566\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422730; batch adversarial loss: 0.680019\n",
      "epoch 90; iter: 0; batch classifier loss: 0.441370; batch adversarial loss: 0.571333\n",
      "epoch 91; iter: 0; batch classifier loss: 0.333632; batch adversarial loss: 0.482774\n",
      "epoch 92; iter: 0; batch classifier loss: 0.455177; batch adversarial loss: 0.562915\n",
      "epoch 93; iter: 0; batch classifier loss: 0.350951; batch adversarial loss: 0.500439\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410363; batch adversarial loss: 0.642440\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410284; batch adversarial loss: 0.511220\n",
      "epoch 96; iter: 0; batch classifier loss: 0.440273; batch adversarial loss: 0.572571\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355679; batch adversarial loss: 0.499952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.408597; batch adversarial loss: 0.527218\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409771; batch adversarial loss: 0.661661\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387957; batch adversarial loss: 0.562960\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383119; batch adversarial loss: 0.617024\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362735; batch adversarial loss: 0.571171\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384924; batch adversarial loss: 0.509317\n",
      "epoch 104; iter: 0; batch classifier loss: 0.357425; batch adversarial loss: 0.577868\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331985; batch adversarial loss: 0.588871\n",
      "epoch 106; iter: 0; batch classifier loss: 0.348432; batch adversarial loss: 0.562043\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417535; batch adversarial loss: 0.509644\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352475; batch adversarial loss: 0.615173\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397855; batch adversarial loss: 0.490755\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408315; batch adversarial loss: 0.535877\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418956; batch adversarial loss: 0.593150\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363280; batch adversarial loss: 0.553769\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340140; batch adversarial loss: 0.546551\n",
      "epoch 114; iter: 0; batch classifier loss: 0.340254; batch adversarial loss: 0.518401\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382778; batch adversarial loss: 0.534319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370773; batch adversarial loss: 0.545085\n",
      "epoch 117; iter: 0; batch classifier loss: 0.387719; batch adversarial loss: 0.624741\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389891; batch adversarial loss: 0.579838\n",
      "epoch 119; iter: 0; batch classifier loss: 0.405038; batch adversarial loss: 0.569515\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343304; batch adversarial loss: 0.545338\n",
      "epoch 121; iter: 0; batch classifier loss: 0.304512; batch adversarial loss: 0.596456\n",
      "epoch 122; iter: 0; batch classifier loss: 0.401133; batch adversarial loss: 0.553357\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357089; batch adversarial loss: 0.516609\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323539; batch adversarial loss: 0.479819\n",
      "epoch 125; iter: 0; batch classifier loss: 0.318797; batch adversarial loss: 0.572204\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346201; batch adversarial loss: 0.527107\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370571; batch adversarial loss: 0.519100\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415310; batch adversarial loss: 0.553051\n",
      "epoch 129; iter: 0; batch classifier loss: 0.440670; batch adversarial loss: 0.606733\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389937; batch adversarial loss: 0.633120\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381532; batch adversarial loss: 0.520653\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317884; batch adversarial loss: 0.596701\n",
      "epoch 133; iter: 0; batch classifier loss: 0.466919; batch adversarial loss: 0.516368\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379933; batch adversarial loss: 0.499558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336475; batch adversarial loss: 0.553109\n",
      "epoch 136; iter: 0; batch classifier loss: 0.344173; batch adversarial loss: 0.562563\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402033; batch adversarial loss: 0.563698\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362046; batch adversarial loss: 0.588715\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416216; batch adversarial loss: 0.508974\n",
      "epoch 140; iter: 0; batch classifier loss: 0.282010; batch adversarial loss: 0.526813\n",
      "epoch 141; iter: 0; batch classifier loss: 0.317849; batch adversarial loss: 0.493263\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376823; batch adversarial loss: 0.591261\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352923; batch adversarial loss: 0.624663\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376967; batch adversarial loss: 0.526505\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356659; batch adversarial loss: 0.552752\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375727; batch adversarial loss: 0.572609\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353755; batch adversarial loss: 0.517194\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326451; batch adversarial loss: 0.554565\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322982; batch adversarial loss: 0.562466\n",
      "epoch 150; iter: 0; batch classifier loss: 0.316851; batch adversarial loss: 0.483361\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374922; batch adversarial loss: 0.562106\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349805; batch adversarial loss: 0.596980\n",
      "epoch 153; iter: 0; batch classifier loss: 0.453783; batch adversarial loss: 0.579623\n",
      "epoch 154; iter: 0; batch classifier loss: 0.474171; batch adversarial loss: 0.571323\n",
      "epoch 155; iter: 0; batch classifier loss: 0.472129; batch adversarial loss: 0.588584\n",
      "epoch 156; iter: 0; batch classifier loss: 0.277689; batch adversarial loss: 0.618020\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315715; batch adversarial loss: 0.507968\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352015; batch adversarial loss: 0.545039\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346656; batch adversarial loss: 0.588239\n",
      "epoch 160; iter: 0; batch classifier loss: 0.443520; batch adversarial loss: 0.562132\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375364; batch adversarial loss: 0.535807\n",
      "epoch 162; iter: 0; batch classifier loss: 0.405361; batch adversarial loss: 0.553308\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354409; batch adversarial loss: 0.528282\n",
      "epoch 164; iter: 0; batch classifier loss: 0.286711; batch adversarial loss: 0.580280\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352111; batch adversarial loss: 0.569734\n",
      "epoch 166; iter: 0; batch classifier loss: 0.327304; batch adversarial loss: 0.570938\n",
      "epoch 167; iter: 0; batch classifier loss: 0.312895; batch adversarial loss: 0.517989\n",
      "epoch 168; iter: 0; batch classifier loss: 0.290780; batch adversarial loss: 0.670783\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339308; batch adversarial loss: 0.599116\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330708; batch adversarial loss: 0.596336\n",
      "epoch 171; iter: 0; batch classifier loss: 0.319622; batch adversarial loss: 0.625761\n",
      "epoch 172; iter: 0; batch classifier loss: 0.305029; batch adversarial loss: 0.525315\n",
      "epoch 173; iter: 0; batch classifier loss: 0.331930; batch adversarial loss: 0.519023\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363221; batch adversarial loss: 0.437345\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348359; batch adversarial loss: 0.676041\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396965; batch adversarial loss: 0.541569\n",
      "epoch 177; iter: 0; batch classifier loss: 0.349969; batch adversarial loss: 0.543002\n",
      "epoch 178; iter: 0; batch classifier loss: 0.257802; batch adversarial loss: 0.597362\n",
      "epoch 179; iter: 0; batch classifier loss: 0.420722; batch adversarial loss: 0.543257\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343157; batch adversarial loss: 0.535168\n",
      "epoch 181; iter: 0; batch classifier loss: 0.416328; batch adversarial loss: 0.589875\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334964; batch adversarial loss: 0.562881\n",
      "epoch 183; iter: 0; batch classifier loss: 0.425445; batch adversarial loss: 0.499158\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302184; batch adversarial loss: 0.507374\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332612; batch adversarial loss: 0.542375\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312987; batch adversarial loss: 0.526172\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329478; batch adversarial loss: 0.591646\n",
      "epoch 188; iter: 0; batch classifier loss: 0.474426; batch adversarial loss: 0.516758\n",
      "epoch 189; iter: 0; batch classifier loss: 0.372245; batch adversarial loss: 0.580783\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359063; batch adversarial loss: 0.564720\n",
      "epoch 191; iter: 0; batch classifier loss: 0.317432; batch adversarial loss: 0.525909\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337221; batch adversarial loss: 0.527014\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378222; batch adversarial loss: 0.569263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.371907; batch adversarial loss: 0.589575\n",
      "epoch 195; iter: 0; batch classifier loss: 0.304151; batch adversarial loss: 0.688162\n",
      "epoch 196; iter: 0; batch classifier loss: 0.307844; batch adversarial loss: 0.560986\n",
      "epoch 197; iter: 0; batch classifier loss: 0.417679; batch adversarial loss: 0.606851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.426258; batch adversarial loss: 0.583019\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343495; batch adversarial loss: 0.560613\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673667; batch adversarial loss: 0.670502\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632493; batch adversarial loss: 0.676883\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579212; batch adversarial loss: 0.648372\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542527; batch adversarial loss: 0.618207\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538050; batch adversarial loss: 0.610739\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518505; batch adversarial loss: 0.586016\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603675; batch adversarial loss: 0.559497\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531423; batch adversarial loss: 0.538833\n",
      "epoch 8; iter: 0; batch classifier loss: 0.594266; batch adversarial loss: 0.613619\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543167; batch adversarial loss: 0.621328\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471359; batch adversarial loss: 0.545104\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564170; batch adversarial loss: 0.682387\n",
      "epoch 12; iter: 0; batch classifier loss: 0.610926; batch adversarial loss: 0.604325\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567377; batch adversarial loss: 0.599090\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499914; batch adversarial loss: 0.643820\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537718; batch adversarial loss: 0.606820\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501671; batch adversarial loss: 0.564569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513447; batch adversarial loss: 0.557361\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507641; batch adversarial loss: 0.576140\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510778; batch adversarial loss: 0.582815\n",
      "epoch 20; iter: 0; batch classifier loss: 0.421943; batch adversarial loss: 0.588262\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493731; batch adversarial loss: 0.577626\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524734; batch adversarial loss: 0.570104\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493178; batch adversarial loss: 0.537321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533129; batch adversarial loss: 0.548029\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480455; batch adversarial loss: 0.496850\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485961; batch adversarial loss: 0.560719\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449076; batch adversarial loss: 0.518814\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419385; batch adversarial loss: 0.547918\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521834; batch adversarial loss: 0.687638\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487587; batch adversarial loss: 0.590336\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435071; batch adversarial loss: 0.530535\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568942; batch adversarial loss: 0.528596\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458006; batch adversarial loss: 0.612954\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461267; batch adversarial loss: 0.530020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.399748; batch adversarial loss: 0.536409\n",
      "epoch 36; iter: 0; batch classifier loss: 0.384136; batch adversarial loss: 0.537438\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456985; batch adversarial loss: 0.519222\n",
      "epoch 38; iter: 0; batch classifier loss: 0.387827; batch adversarial loss: 0.589461\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432875; batch adversarial loss: 0.544262\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464410; batch adversarial loss: 0.491794\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476286; batch adversarial loss: 0.561427\n",
      "epoch 42; iter: 0; batch classifier loss: 0.578439; batch adversarial loss: 0.544809\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391519; batch adversarial loss: 0.508654\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390641; batch adversarial loss: 0.571455\n",
      "epoch 45; iter: 0; batch classifier loss: 0.486359; batch adversarial loss: 0.473579\n",
      "epoch 46; iter: 0; batch classifier loss: 0.413159; batch adversarial loss: 0.571834\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370871; batch adversarial loss: 0.552855\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420943; batch adversarial loss: 0.428429\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467858; batch adversarial loss: 0.509477\n",
      "epoch 50; iter: 0; batch classifier loss: 0.387251; batch adversarial loss: 0.536096\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413170; batch adversarial loss: 0.448044\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444226; batch adversarial loss: 0.526870\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461778; batch adversarial loss: 0.580267\n",
      "epoch 54; iter: 0; batch classifier loss: 0.396667; batch adversarial loss: 0.555270\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410809; batch adversarial loss: 0.588568\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404955; batch adversarial loss: 0.553569\n",
      "epoch 57; iter: 0; batch classifier loss: 0.368226; batch adversarial loss: 0.509474\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471385; batch adversarial loss: 0.471223\n",
      "epoch 59; iter: 0; batch classifier loss: 0.471967; batch adversarial loss: 0.624793\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382481; batch adversarial loss: 0.581131\n",
      "epoch 61; iter: 0; batch classifier loss: 0.450968; batch adversarial loss: 0.517017\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416774; batch adversarial loss: 0.481708\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436408; batch adversarial loss: 0.606242\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427180; batch adversarial loss: 0.492857\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449871; batch adversarial loss: 0.615364\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407454; batch adversarial loss: 0.569947\n",
      "epoch 67; iter: 0; batch classifier loss: 0.369199; batch adversarial loss: 0.553789\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364673; batch adversarial loss: 0.642723\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390919; batch adversarial loss: 0.563440\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353506; batch adversarial loss: 0.599127\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406010; batch adversarial loss: 0.544261\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398466; batch adversarial loss: 0.561370\n",
      "epoch 73; iter: 0; batch classifier loss: 0.334801; batch adversarial loss: 0.535468\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364753; batch adversarial loss: 0.618024\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389764; batch adversarial loss: 0.471962\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422150; batch adversarial loss: 0.615131\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355421; batch adversarial loss: 0.588234\n",
      "epoch 78; iter: 0; batch classifier loss: 0.344156; batch adversarial loss: 0.581223\n",
      "epoch 79; iter: 0; batch classifier loss: 0.360902; batch adversarial loss: 0.500149\n",
      "epoch 80; iter: 0; batch classifier loss: 0.313061; batch adversarial loss: 0.582046\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431904; batch adversarial loss: 0.615041\n",
      "epoch 82; iter: 0; batch classifier loss: 0.392494; batch adversarial loss: 0.636856\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369910; batch adversarial loss: 0.516651\n",
      "epoch 84; iter: 0; batch classifier loss: 0.456941; batch adversarial loss: 0.569498\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377370; batch adversarial loss: 0.578806\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425378; batch adversarial loss: 0.534943\n",
      "epoch 87; iter: 0; batch classifier loss: 0.314761; batch adversarial loss: 0.619484\n",
      "epoch 88; iter: 0; batch classifier loss: 0.331036; batch adversarial loss: 0.620680\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365473; batch adversarial loss: 0.498987\n",
      "epoch 90; iter: 0; batch classifier loss: 0.455163; batch adversarial loss: 0.553940\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352321; batch adversarial loss: 0.588648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.393672; batch adversarial loss: 0.532584\n",
      "epoch 93; iter: 0; batch classifier loss: 0.440971; batch adversarial loss: 0.464149\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360513; batch adversarial loss: 0.634899\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352241; batch adversarial loss: 0.582176\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341644; batch adversarial loss: 0.563756\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410395; batch adversarial loss: 0.490477\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391188; batch adversarial loss: 0.581880\n",
      "epoch 99; iter: 0; batch classifier loss: 0.442515; batch adversarial loss: 0.525861\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376398; batch adversarial loss: 0.526521\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408007; batch adversarial loss: 0.554036\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359916; batch adversarial loss: 0.581168\n",
      "epoch 103; iter: 0; batch classifier loss: 0.466330; batch adversarial loss: 0.516804\n",
      "epoch 104; iter: 0; batch classifier loss: 0.488511; batch adversarial loss: 0.597053\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400185; batch adversarial loss: 0.527787\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330989; batch adversarial loss: 0.515637\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346378; batch adversarial loss: 0.507770\n",
      "epoch 108; iter: 0; batch classifier loss: 0.325915; batch adversarial loss: 0.554045\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357592; batch adversarial loss: 0.615543\n",
      "epoch 110; iter: 0; batch classifier loss: 0.329374; batch adversarial loss: 0.617133\n",
      "epoch 111; iter: 0; batch classifier loss: 0.321857; batch adversarial loss: 0.527187\n",
      "epoch 112; iter: 0; batch classifier loss: 0.434409; batch adversarial loss: 0.554141\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371169; batch adversarial loss: 0.518685\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344755; batch adversarial loss: 0.508978\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341562; batch adversarial loss: 0.600173\n",
      "epoch 116; iter: 0; batch classifier loss: 0.443135; batch adversarial loss: 0.559080\n",
      "epoch 117; iter: 0; batch classifier loss: 0.330283; batch adversarial loss: 0.555293\n",
      "epoch 118; iter: 0; batch classifier loss: 0.329658; batch adversarial loss: 0.537376\n",
      "epoch 119; iter: 0; batch classifier loss: 0.297520; batch adversarial loss: 0.571596\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398454; batch adversarial loss: 0.587768\n",
      "epoch 121; iter: 0; batch classifier loss: 0.446649; batch adversarial loss: 0.533926\n",
      "epoch 122; iter: 0; batch classifier loss: 0.316638; batch adversarial loss: 0.544950\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336559; batch adversarial loss: 0.592284\n",
      "epoch 124; iter: 0; batch classifier loss: 0.440623; batch adversarial loss: 0.509191\n",
      "epoch 125; iter: 0; batch classifier loss: 0.428097; batch adversarial loss: 0.543752\n",
      "epoch 126; iter: 0; batch classifier loss: 0.301868; batch adversarial loss: 0.581976\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381467; batch adversarial loss: 0.582126\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365434; batch adversarial loss: 0.490378\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365115; batch adversarial loss: 0.587527\n",
      "epoch 130; iter: 0; batch classifier loss: 0.435084; batch adversarial loss: 0.570464\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328559; batch adversarial loss: 0.499305\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342770; batch adversarial loss: 0.546688\n",
      "epoch 133; iter: 0; batch classifier loss: 0.432221; batch adversarial loss: 0.426968\n",
      "epoch 134; iter: 0; batch classifier loss: 0.403103; batch adversarial loss: 0.564160\n",
      "epoch 135; iter: 0; batch classifier loss: 0.435410; batch adversarial loss: 0.634894\n",
      "epoch 136; iter: 0; batch classifier loss: 0.317849; batch adversarial loss: 0.543829\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341681; batch adversarial loss: 0.524427\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314363; batch adversarial loss: 0.624299\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401635; batch adversarial loss: 0.542115\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344040; batch adversarial loss: 0.534442\n",
      "epoch 141; iter: 0; batch classifier loss: 0.327571; batch adversarial loss: 0.559885\n",
      "epoch 142; iter: 0; batch classifier loss: 0.439709; batch adversarial loss: 0.585982\n",
      "epoch 143; iter: 0; batch classifier loss: 0.323785; batch adversarial loss: 0.582056\n",
      "epoch 144; iter: 0; batch classifier loss: 0.448414; batch adversarial loss: 0.534351\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358024; batch adversarial loss: 0.472887\n",
      "epoch 146; iter: 0; batch classifier loss: 0.344645; batch adversarial loss: 0.565031\n",
      "epoch 147; iter: 0; batch classifier loss: 0.367574; batch adversarial loss: 0.543329\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396170; batch adversarial loss: 0.524077\n",
      "epoch 149; iter: 0; batch classifier loss: 0.424041; batch adversarial loss: 0.482478\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348471; batch adversarial loss: 0.643522\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390635; batch adversarial loss: 0.555112\n",
      "epoch 152; iter: 0; batch classifier loss: 0.457314; batch adversarial loss: 0.588994\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357087; batch adversarial loss: 0.588929\n",
      "epoch 154; iter: 0; batch classifier loss: 0.414437; batch adversarial loss: 0.553393\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333160; batch adversarial loss: 0.598592\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418789; batch adversarial loss: 0.526564\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336628; batch adversarial loss: 0.563044\n",
      "epoch 158; iter: 0; batch classifier loss: 0.417903; batch adversarial loss: 0.511188\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331319; batch adversarial loss: 0.524986\n",
      "epoch 160; iter: 0; batch classifier loss: 0.377643; batch adversarial loss: 0.523875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.352107; batch adversarial loss: 0.579775\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353191; batch adversarial loss: 0.562367\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384015; batch adversarial loss: 0.563407\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386933; batch adversarial loss: 0.506900\n",
      "epoch 165; iter: 0; batch classifier loss: 0.296228; batch adversarial loss: 0.514597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.437361; batch adversarial loss: 0.554488\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356791; batch adversarial loss: 0.610429\n",
      "epoch 168; iter: 0; batch classifier loss: 0.328398; batch adversarial loss: 0.514893\n",
      "epoch 169; iter: 0; batch classifier loss: 0.335261; batch adversarial loss: 0.599369\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348116; batch adversarial loss: 0.544279\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386233; batch adversarial loss: 0.525743\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332105; batch adversarial loss: 0.552439\n",
      "epoch 173; iter: 0; batch classifier loss: 0.465367; batch adversarial loss: 0.506593\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344575; batch adversarial loss: 0.570934\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382710; batch adversarial loss: 0.581155\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358140; batch adversarial loss: 0.455391\n",
      "epoch 177; iter: 0; batch classifier loss: 0.292578; batch adversarial loss: 0.543013\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326787; batch adversarial loss: 0.572848\n",
      "epoch 179; iter: 0; batch classifier loss: 0.272447; batch adversarial loss: 0.604721\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379673; batch adversarial loss: 0.475008\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337036; batch adversarial loss: 0.598127\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373205; batch adversarial loss: 0.653372\n",
      "epoch 183; iter: 0; batch classifier loss: 0.435371; batch adversarial loss: 0.629148\n",
      "epoch 184; iter: 0; batch classifier loss: 0.361670; batch adversarial loss: 0.625120\n",
      "epoch 185; iter: 0; batch classifier loss: 0.335175; batch adversarial loss: 0.499314\n",
      "epoch 186; iter: 0; batch classifier loss: 0.251363; batch adversarial loss: 0.585647\n",
      "epoch 187; iter: 0; batch classifier loss: 0.429358; batch adversarial loss: 0.554388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.346604; batch adversarial loss: 0.569610\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292645; batch adversarial loss: 0.544838\n",
      "epoch 190; iter: 0; batch classifier loss: 0.387751; batch adversarial loss: 0.508016\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365793; batch adversarial loss: 0.560129\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347485; batch adversarial loss: 0.536308\n",
      "epoch 193; iter: 0; batch classifier loss: 0.420301; batch adversarial loss: 0.526411\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324711; batch adversarial loss: 0.601286\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390995; batch adversarial loss: 0.506614\n",
      "epoch 196; iter: 0; batch classifier loss: 0.365368; batch adversarial loss: 0.543974\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355566; batch adversarial loss: 0.520225\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322014; batch adversarial loss: 0.525772\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388743; batch adversarial loss: 0.581499\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657958; batch adversarial loss: 0.633675\n",
      "epoch 1; iter: 0; batch classifier loss: 0.666468; batch adversarial loss: 0.691994\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597885; batch adversarial loss: 0.621605\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556136; batch adversarial loss: 0.648245\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619503; batch adversarial loss: 0.647955\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608741; batch adversarial loss: 0.662771\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639181; batch adversarial loss: 0.673461\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561807; batch adversarial loss: 0.575928\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566795; batch adversarial loss: 0.580632\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493821; batch adversarial loss: 0.564091\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505075; batch adversarial loss: 0.607433\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573561; batch adversarial loss: 0.571176\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509998; batch adversarial loss: 0.578630\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499557; batch adversarial loss: 0.579353\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484926; batch adversarial loss: 0.567214\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539540; batch adversarial loss: 0.547579\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542564; batch adversarial loss: 0.508719\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498139; batch adversarial loss: 0.562511\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559787; batch adversarial loss: 0.570303\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511316; batch adversarial loss: 0.503819\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480481; batch adversarial loss: 0.499646\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519788; batch adversarial loss: 0.604933\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491802; batch adversarial loss: 0.598740\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526824; batch adversarial loss: 0.572196\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490403; batch adversarial loss: 0.551710\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472479; batch adversarial loss: 0.596763\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460647; batch adversarial loss: 0.531619\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472316; batch adversarial loss: 0.584902\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490805; batch adversarial loss: 0.556469\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496367; batch adversarial loss: 0.620971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.398151; batch adversarial loss: 0.612733\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454699; batch adversarial loss: 0.621249\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500440; batch adversarial loss: 0.594413\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420104; batch adversarial loss: 0.570436\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412421; batch adversarial loss: 0.622372\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448870; batch adversarial loss: 0.551930\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456893; batch adversarial loss: 0.577914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.512221; batch adversarial loss: 0.596355\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473948; batch adversarial loss: 0.527134\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459415; batch adversarial loss: 0.613283\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466221; batch adversarial loss: 0.494209\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453143; batch adversarial loss: 0.596003\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448597; batch adversarial loss: 0.561395\n",
      "epoch 43; iter: 0; batch classifier loss: 0.511129; batch adversarial loss: 0.612685\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394684; batch adversarial loss: 0.663691\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472733; batch adversarial loss: 0.520061\n",
      "epoch 46; iter: 0; batch classifier loss: 0.442467; batch adversarial loss: 0.536045\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462755; batch adversarial loss: 0.605494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477887; batch adversarial loss: 0.562055\n",
      "epoch 49; iter: 0; batch classifier loss: 0.499467; batch adversarial loss: 0.587951\n",
      "epoch 50; iter: 0; batch classifier loss: 0.501197; batch adversarial loss: 0.561920\n",
      "epoch 51; iter: 0; batch classifier loss: 0.372615; batch adversarial loss: 0.536092\n",
      "epoch 52; iter: 0; batch classifier loss: 0.519880; batch adversarial loss: 0.578309\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461249; batch adversarial loss: 0.511050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379387; batch adversarial loss: 0.596384\n",
      "epoch 55; iter: 0; batch classifier loss: 0.499916; batch adversarial loss: 0.536992\n",
      "epoch 56; iter: 0; batch classifier loss: 0.464896; batch adversarial loss: 0.623251\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475672; batch adversarial loss: 0.639760\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439453; batch adversarial loss: 0.526968\n",
      "epoch 59; iter: 0; batch classifier loss: 0.496208; batch adversarial loss: 0.595302\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400144; batch adversarial loss: 0.503677\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389288; batch adversarial loss: 0.588374\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457153; batch adversarial loss: 0.508700\n",
      "epoch 63; iter: 0; batch classifier loss: 0.492161; batch adversarial loss: 0.519352\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380251; batch adversarial loss: 0.615412\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391285; batch adversarial loss: 0.624229\n",
      "epoch 66; iter: 0; batch classifier loss: 0.356356; batch adversarial loss: 0.553161\n",
      "epoch 67; iter: 0; batch classifier loss: 0.457225; batch adversarial loss: 0.623867\n",
      "epoch 68; iter: 0; batch classifier loss: 0.509146; batch adversarial loss: 0.562718\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366372; batch adversarial loss: 0.580400\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436569; batch adversarial loss: 0.527715\n",
      "epoch 71; iter: 0; batch classifier loss: 0.439792; batch adversarial loss: 0.527838\n",
      "epoch 72; iter: 0; batch classifier loss: 0.494324; batch adversarial loss: 0.553478\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391816; batch adversarial loss: 0.638713\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430456; batch adversarial loss: 0.586579\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362163; batch adversarial loss: 0.621561\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454952; batch adversarial loss: 0.554402\n",
      "epoch 77; iter: 0; batch classifier loss: 0.459330; batch adversarial loss: 0.553074\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376777; batch adversarial loss: 0.494929\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387337; batch adversarial loss: 0.631680\n",
      "epoch 80; iter: 0; batch classifier loss: 0.452992; batch adversarial loss: 0.536194\n",
      "epoch 81; iter: 0; batch classifier loss: 0.554762; batch adversarial loss: 0.614618\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356401; batch adversarial loss: 0.527475\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361637; batch adversarial loss: 0.630461\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440801; batch adversarial loss: 0.596599\n",
      "epoch 85; iter: 0; batch classifier loss: 0.449248; batch adversarial loss: 0.594620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.441639; batch adversarial loss: 0.639096\n",
      "epoch 87; iter: 0; batch classifier loss: 0.464642; batch adversarial loss: 0.611161\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460843; batch adversarial loss: 0.603242\n",
      "epoch 89; iter: 0; batch classifier loss: 0.392886; batch adversarial loss: 0.637401\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383136; batch adversarial loss: 0.629805\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427682; batch adversarial loss: 0.614414\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351906; batch adversarial loss: 0.501886\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405939; batch adversarial loss: 0.545107\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374071; batch adversarial loss: 0.597275\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400966; batch adversarial loss: 0.588302\n",
      "epoch 96; iter: 0; batch classifier loss: 0.404336; batch adversarial loss: 0.579354\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400362; batch adversarial loss: 0.552501\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382182; batch adversarial loss: 0.510694\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361584; batch adversarial loss: 0.616219\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409198; batch adversarial loss: 0.628747\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394660; batch adversarial loss: 0.546165\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381420; batch adversarial loss: 0.579556\n",
      "epoch 103; iter: 0; batch classifier loss: 0.357350; batch adversarial loss: 0.552376\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366977; batch adversarial loss: 0.501977\n",
      "epoch 105; iter: 0; batch classifier loss: 0.457525; batch adversarial loss: 0.459340\n",
      "epoch 106; iter: 0; batch classifier loss: 0.478911; batch adversarial loss: 0.641786\n",
      "epoch 107; iter: 0; batch classifier loss: 0.432731; batch adversarial loss: 0.588859\n",
      "epoch 108; iter: 0; batch classifier loss: 0.432902; batch adversarial loss: 0.544917\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433771; batch adversarial loss: 0.562065\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421211; batch adversarial loss: 0.527917\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433312; batch adversarial loss: 0.579297\n",
      "epoch 112; iter: 0; batch classifier loss: 0.442243; batch adversarial loss: 0.579319\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387851; batch adversarial loss: 0.613746\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359047; batch adversarial loss: 0.597046\n",
      "epoch 115; iter: 0; batch classifier loss: 0.408407; batch adversarial loss: 0.588724\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372234; batch adversarial loss: 0.527737\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402006; batch adversarial loss: 0.588196\n",
      "epoch 118; iter: 0; batch classifier loss: 0.293361; batch adversarial loss: 0.527931\n",
      "epoch 119; iter: 0; batch classifier loss: 0.521378; batch adversarial loss: 0.579339\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351886; batch adversarial loss: 0.613797\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353734; batch adversarial loss: 0.588049\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388773; batch adversarial loss: 0.605005\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423037; batch adversarial loss: 0.544771\n",
      "epoch 124; iter: 0; batch classifier loss: 0.423399; batch adversarial loss: 0.596910\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386019; batch adversarial loss: 0.553292\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383279; batch adversarial loss: 0.536812\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354523; batch adversarial loss: 0.596485\n",
      "epoch 128; iter: 0; batch classifier loss: 0.473764; batch adversarial loss: 0.588255\n",
      "epoch 129; iter: 0; batch classifier loss: 0.366453; batch adversarial loss: 0.519074\n",
      "epoch 130; iter: 0; batch classifier loss: 0.451225; batch adversarial loss: 0.502125\n",
      "epoch 131; iter: 0; batch classifier loss: 0.470495; batch adversarial loss: 0.596652\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406278; batch adversarial loss: 0.545243\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390069; batch adversarial loss: 0.587866\n",
      "epoch 134; iter: 0; batch classifier loss: 0.435049; batch adversarial loss: 0.510833\n",
      "epoch 135; iter: 0; batch classifier loss: 0.342591; batch adversarial loss: 0.648470\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405188; batch adversarial loss: 0.622577\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389531; batch adversarial loss: 0.501759\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394700; batch adversarial loss: 0.579651\n",
      "epoch 139; iter: 0; batch classifier loss: 0.391457; batch adversarial loss: 0.553577\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357135; batch adversarial loss: 0.494237\n",
      "epoch 141; iter: 0; batch classifier loss: 0.406613; batch adversarial loss: 0.528229\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362889; batch adversarial loss: 0.605287\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387537; batch adversarial loss: 0.570904\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357506; batch adversarial loss: 0.605282\n",
      "epoch 145; iter: 0; batch classifier loss: 0.455382; batch adversarial loss: 0.467982\n",
      "epoch 146; iter: 0; batch classifier loss: 0.333336; batch adversarial loss: 0.511196\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347189; batch adversarial loss: 0.519682\n",
      "epoch 148; iter: 0; batch classifier loss: 0.460344; batch adversarial loss: 0.545346\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391456; batch adversarial loss: 0.682070\n",
      "epoch 150; iter: 0; batch classifier loss: 0.448005; batch adversarial loss: 0.562570\n",
      "epoch 151; iter: 0; batch classifier loss: 0.410556; batch adversarial loss: 0.639194\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322539; batch adversarial loss: 0.570848\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329628; batch adversarial loss: 0.520413\n",
      "epoch 154; iter: 0; batch classifier loss: 0.407359; batch adversarial loss: 0.570727\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411244; batch adversarial loss: 0.699531\n",
      "epoch 156; iter: 0; batch classifier loss: 0.460406; batch adversarial loss: 0.527640\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351368; batch adversarial loss: 0.527880\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384035; batch adversarial loss: 0.536469\n",
      "epoch 159; iter: 0; batch classifier loss: 0.442650; batch adversarial loss: 0.519290\n",
      "epoch 160; iter: 0; batch classifier loss: 0.430161; batch adversarial loss: 0.510926\n",
      "epoch 161; iter: 0; batch classifier loss: 0.437757; batch adversarial loss: 0.605333\n",
      "epoch 162; iter: 0; batch classifier loss: 0.424729; batch adversarial loss: 0.545176\n",
      "epoch 163; iter: 0; batch classifier loss: 0.301992; batch adversarial loss: 0.510737\n",
      "epoch 164; iter: 0; batch classifier loss: 0.317402; batch adversarial loss: 0.656655\n",
      "epoch 165; iter: 0; batch classifier loss: 0.322452; batch adversarial loss: 0.587646\n",
      "epoch 166; iter: 0; batch classifier loss: 0.439167; batch adversarial loss: 0.561655\n",
      "epoch 167; iter: 0; batch classifier loss: 0.350312; batch adversarial loss: 0.603394\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362912; batch adversarial loss: 0.586837\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390741; batch adversarial loss: 0.571906\n",
      "epoch 170; iter: 0; batch classifier loss: 0.414687; batch adversarial loss: 0.588632\n",
      "epoch 171; iter: 0; batch classifier loss: 0.398194; batch adversarial loss: 0.570948\n",
      "epoch 172; iter: 0; batch classifier loss: 0.437695; batch adversarial loss: 0.536139\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348323; batch adversarial loss: 0.614187\n",
      "epoch 174; iter: 0; batch classifier loss: 0.414898; batch adversarial loss: 0.467570\n",
      "epoch 175; iter: 0; batch classifier loss: 0.431860; batch adversarial loss: 0.588172\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387562; batch adversarial loss: 0.553582\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319708; batch adversarial loss: 0.528305\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340904; batch adversarial loss: 0.587322\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392905; batch adversarial loss: 0.571303\n",
      "epoch 180; iter: 0; batch classifier loss: 0.406843; batch adversarial loss: 0.631592\n",
      "epoch 181; iter: 0; batch classifier loss: 0.398431; batch adversarial loss: 0.536634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.360301; batch adversarial loss: 0.596680\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365937; batch adversarial loss: 0.605280\n",
      "epoch 184; iter: 0; batch classifier loss: 0.286384; batch adversarial loss: 0.553860\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316200; batch adversarial loss: 0.561947\n",
      "epoch 186; iter: 0; batch classifier loss: 0.421641; batch adversarial loss: 0.588234\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392919; batch adversarial loss: 0.621659\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375220; batch adversarial loss: 0.570361\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391288; batch adversarial loss: 0.613430\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306816; batch adversarial loss: 0.648205\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362098; batch adversarial loss: 0.535726\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404479; batch adversarial loss: 0.570840\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362693; batch adversarial loss: 0.553793\n",
      "epoch 194; iter: 0; batch classifier loss: 0.334173; batch adversarial loss: 0.604695\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327757; batch adversarial loss: 0.570956\n",
      "epoch 196; iter: 0; batch classifier loss: 0.426382; batch adversarial loss: 0.536966\n",
      "epoch 197; iter: 0; batch classifier loss: 0.395163; batch adversarial loss: 0.562320\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306506; batch adversarial loss: 0.553765\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339036; batch adversarial loss: 0.553896\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663254; batch adversarial loss: 0.674319\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581186; batch adversarial loss: 0.639279\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583175; batch adversarial loss: 0.629939\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594671; batch adversarial loss: 0.614455\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532389; batch adversarial loss: 0.612416\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563076; batch adversarial loss: 0.594643\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516461; batch adversarial loss: 0.594077\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520429; batch adversarial loss: 0.592748\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581117; batch adversarial loss: 0.598297\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543025; batch adversarial loss: 0.584214\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592198; batch adversarial loss: 0.590947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524216; batch adversarial loss: 0.654880\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559706; batch adversarial loss: 0.577062\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509170; batch adversarial loss: 0.548090\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534508; batch adversarial loss: 0.655331\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495873; batch adversarial loss: 0.563725\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495517; batch adversarial loss: 0.597806\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477194; batch adversarial loss: 0.531006\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501292; batch adversarial loss: 0.590122\n",
      "epoch 19; iter: 0; batch classifier loss: 0.578672; batch adversarial loss: 0.563013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.537434; batch adversarial loss: 0.641991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532474; batch adversarial loss: 0.578651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.552630; batch adversarial loss: 0.618825\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501187; batch adversarial loss: 0.595795\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515834; batch adversarial loss: 0.528877\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472894; batch adversarial loss: 0.513493\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508552; batch adversarial loss: 0.558496\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518718; batch adversarial loss: 0.607612\n",
      "epoch 28; iter: 0; batch classifier loss: 0.444691; batch adversarial loss: 0.578425\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458657; batch adversarial loss: 0.555164\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450167; batch adversarial loss: 0.572518\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462931; batch adversarial loss: 0.588278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427592; batch adversarial loss: 0.589416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472620; batch adversarial loss: 0.588984\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416988; batch adversarial loss: 0.571486\n",
      "epoch 35; iter: 0; batch classifier loss: 0.388581; batch adversarial loss: 0.544960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406153; batch adversarial loss: 0.553656\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497756; batch adversarial loss: 0.544560\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473986; batch adversarial loss: 0.553734\n",
      "epoch 39; iter: 0; batch classifier loss: 0.391271; batch adversarial loss: 0.508302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488746; batch adversarial loss: 0.535509\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420381; batch adversarial loss: 0.517113\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422008; batch adversarial loss: 0.526189\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384699; batch adversarial loss: 0.535000\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440260; batch adversarial loss: 0.572091\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429096; batch adversarial loss: 0.544223\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437792; batch adversarial loss: 0.517246\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487820; batch adversarial loss: 0.516169\n",
      "epoch 48; iter: 0; batch classifier loss: 0.506875; batch adversarial loss: 0.608769\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444669; batch adversarial loss: 0.572398\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432755; batch adversarial loss: 0.489627\n",
      "epoch 51; iter: 0; batch classifier loss: 0.528033; batch adversarial loss: 0.516619\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372796; batch adversarial loss: 0.535721\n",
      "epoch 53; iter: 0; batch classifier loss: 0.541402; batch adversarial loss: 0.526261\n",
      "epoch 54; iter: 0; batch classifier loss: 0.436863; batch adversarial loss: 0.552797\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443569; batch adversarial loss: 0.526115\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391640; batch adversarial loss: 0.620490\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393620; batch adversarial loss: 0.552805\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464589; batch adversarial loss: 0.469568\n",
      "epoch 59; iter: 0; batch classifier loss: 0.510822; batch adversarial loss: 0.524497\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391674; batch adversarial loss: 0.555017\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446832; batch adversarial loss: 0.570322\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453079; batch adversarial loss: 0.616590\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374659; batch adversarial loss: 0.533108\n",
      "epoch 64; iter: 0; batch classifier loss: 0.455593; batch adversarial loss: 0.553482\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432585; batch adversarial loss: 0.507927\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397899; batch adversarial loss: 0.516022\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423759; batch adversarial loss: 0.525177\n",
      "epoch 68; iter: 0; batch classifier loss: 0.466325; batch adversarial loss: 0.553592\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425452; batch adversarial loss: 0.619794\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462664; batch adversarial loss: 0.590125\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349326; batch adversarial loss: 0.545140\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358737; batch adversarial loss: 0.471867\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402339; batch adversarial loss: 0.590215\n",
      "epoch 74; iter: 0; batch classifier loss: 0.377783; batch adversarial loss: 0.635346\n",
      "epoch 75; iter: 0; batch classifier loss: 0.419852; batch adversarial loss: 0.562836\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377157; batch adversarial loss: 0.517098\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458362; batch adversarial loss: 0.516864\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415292; batch adversarial loss: 0.535290\n",
      "epoch 79; iter: 0; batch classifier loss: 0.339094; batch adversarial loss: 0.526295\n",
      "epoch 80; iter: 0; batch classifier loss: 0.299452; batch adversarial loss: 0.526115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.419315; batch adversarial loss: 0.526021\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415843; batch adversarial loss: 0.471177\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425004; batch adversarial loss: 0.507574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380157; batch adversarial loss: 0.453831\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412058; batch adversarial loss: 0.553136\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371935; batch adversarial loss: 0.545039\n",
      "epoch 87; iter: 0; batch classifier loss: 0.426862; batch adversarial loss: 0.553774\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397997; batch adversarial loss: 0.498318\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329351; batch adversarial loss: 0.600376\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426780; batch adversarial loss: 0.461570\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381612; batch adversarial loss: 0.655379\n",
      "epoch 92; iter: 0; batch classifier loss: 0.345099; batch adversarial loss: 0.535355\n",
      "epoch 93; iter: 0; batch classifier loss: 0.499740; batch adversarial loss: 0.525416\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410509; batch adversarial loss: 0.572038\n",
      "epoch 95; iter: 0; batch classifier loss: 0.366719; batch adversarial loss: 0.460999\n",
      "epoch 96; iter: 0; batch classifier loss: 0.327368; batch adversarial loss: 0.563086\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364720; batch adversarial loss: 0.507495\n",
      "epoch 98; iter: 0; batch classifier loss: 0.419437; batch adversarial loss: 0.423907\n",
      "epoch 99; iter: 0; batch classifier loss: 0.439578; batch adversarial loss: 0.517100\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415234; batch adversarial loss: 0.544220\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399995; batch adversarial loss: 0.553886\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397262; batch adversarial loss: 0.590019\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339779; batch adversarial loss: 0.534733\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428757; batch adversarial loss: 0.488363\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355700; batch adversarial loss: 0.535414\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407197; batch adversarial loss: 0.628405\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372968; batch adversarial loss: 0.525891\n",
      "epoch 108; iter: 0; batch classifier loss: 0.433161; batch adversarial loss: 0.497885\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379499; batch adversarial loss: 0.498130\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396165; batch adversarial loss: 0.535279\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405249; batch adversarial loss: 0.517128\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385925; batch adversarial loss: 0.516963\n",
      "epoch 113; iter: 0; batch classifier loss: 0.489710; batch adversarial loss: 0.526127\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383337; batch adversarial loss: 0.600427\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396508; batch adversarial loss: 0.507012\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357862; batch adversarial loss: 0.488743\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374061; batch adversarial loss: 0.506927\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345411; batch adversarial loss: 0.572106\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404945; batch adversarial loss: 0.554650\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346362; batch adversarial loss: 0.479571\n",
      "epoch 121; iter: 0; batch classifier loss: 0.309002; batch adversarial loss: 0.516585\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369741; batch adversarial loss: 0.572792\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377977; batch adversarial loss: 0.553652\n",
      "epoch 124; iter: 0; batch classifier loss: 0.316300; batch adversarial loss: 0.470669\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329374; batch adversarial loss: 0.563229\n",
      "epoch 126; iter: 0; batch classifier loss: 0.469678; batch adversarial loss: 0.498133\n",
      "epoch 127; iter: 0; batch classifier loss: 0.393260; batch adversarial loss: 0.470344\n",
      "epoch 128; iter: 0; batch classifier loss: 0.436013; batch adversarial loss: 0.563210\n",
      "epoch 129; iter: 0; batch classifier loss: 0.341254; batch adversarial loss: 0.507218\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365501; batch adversarial loss: 0.535223\n",
      "epoch 131; iter: 0; batch classifier loss: 0.325051; batch adversarial loss: 0.441752\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415352; batch adversarial loss: 0.591073\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355167; batch adversarial loss: 0.516580\n",
      "epoch 134; iter: 0; batch classifier loss: 0.407673; batch adversarial loss: 0.497426\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325608; batch adversarial loss: 0.553486\n",
      "epoch 136; iter: 0; batch classifier loss: 0.424609; batch adversarial loss: 0.544478\n",
      "epoch 137; iter: 0; batch classifier loss: 0.370841; batch adversarial loss: 0.479059\n",
      "epoch 138; iter: 0; batch classifier loss: 0.419923; batch adversarial loss: 0.526384\n",
      "epoch 139; iter: 0; batch classifier loss: 0.437999; batch adversarial loss: 0.461395\n",
      "epoch 140; iter: 0; batch classifier loss: 0.424127; batch adversarial loss: 0.627767\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349873; batch adversarial loss: 0.507777\n",
      "epoch 142; iter: 0; batch classifier loss: 0.389751; batch adversarial loss: 0.599753\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385685; batch adversarial loss: 0.516720\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394305; batch adversarial loss: 0.572190\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391494; batch adversarial loss: 0.590672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.415218; batch adversarial loss: 0.572138\n",
      "epoch 147; iter: 0; batch classifier loss: 0.493809; batch adversarial loss: 0.535182\n",
      "epoch 148; iter: 0; batch classifier loss: 0.385032; batch adversarial loss: 0.507401\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314228; batch adversarial loss: 0.581103\n",
      "epoch 150; iter: 0; batch classifier loss: 0.484504; batch adversarial loss: 0.572377\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359376; batch adversarial loss: 0.553788\n",
      "epoch 152; iter: 0; batch classifier loss: 0.297805; batch adversarial loss: 0.554070\n",
      "epoch 153; iter: 0; batch classifier loss: 0.433246; batch adversarial loss: 0.600332\n",
      "epoch 154; iter: 0; batch classifier loss: 0.386906; batch adversarial loss: 0.563193\n",
      "epoch 155; iter: 0; batch classifier loss: 0.390366; batch adversarial loss: 0.544434\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404055; batch adversarial loss: 0.498001\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374413; batch adversarial loss: 0.702384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381225; batch adversarial loss: 0.627504\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360554; batch adversarial loss: 0.544543\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386575; batch adversarial loss: 0.553503\n",
      "epoch 161; iter: 0; batch classifier loss: 0.382393; batch adversarial loss: 0.480298\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348377; batch adversarial loss: 0.480191\n",
      "epoch 163; iter: 0; batch classifier loss: 0.433430; batch adversarial loss: 0.581649\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328786; batch adversarial loss: 0.572443\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379167; batch adversarial loss: 0.599874\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324098; batch adversarial loss: 0.535107\n",
      "epoch 167; iter: 0; batch classifier loss: 0.354851; batch adversarial loss: 0.609641\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373374; batch adversarial loss: 0.591154\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376678; batch adversarial loss: 0.553742\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318037; batch adversarial loss: 0.488726\n",
      "epoch 171; iter: 0; batch classifier loss: 0.294390; batch adversarial loss: 0.609654\n",
      "epoch 172; iter: 0; batch classifier loss: 0.307646; batch adversarial loss: 0.535331\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360359; batch adversarial loss: 0.600010\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381395; batch adversarial loss: 0.572338\n",
      "epoch 175; iter: 0; batch classifier loss: 0.421670; batch adversarial loss: 0.544811\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380019; batch adversarial loss: 0.498550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.404989; batch adversarial loss: 0.609532\n",
      "epoch 178; iter: 0; batch classifier loss: 0.269471; batch adversarial loss: 0.480289\n",
      "epoch 179; iter: 0; batch classifier loss: 0.412480; batch adversarial loss: 0.507891\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387438; batch adversarial loss: 0.516191\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367288; batch adversarial loss: 0.461322\n",
      "epoch 182; iter: 0; batch classifier loss: 0.335498; batch adversarial loss: 0.451898\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371861; batch adversarial loss: 0.609167\n",
      "epoch 184; iter: 0; batch classifier loss: 0.433051; batch adversarial loss: 0.479093\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379864; batch adversarial loss: 0.544621\n",
      "epoch 186; iter: 0; batch classifier loss: 0.329223; batch adversarial loss: 0.646686\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336615; batch adversarial loss: 0.498458\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346062; batch adversarial loss: 0.545124\n",
      "epoch 189; iter: 0; batch classifier loss: 0.288427; batch adversarial loss: 0.524094\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372252; batch adversarial loss: 0.572597\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381857; batch adversarial loss: 0.488386\n",
      "epoch 192; iter: 0; batch classifier loss: 0.409941; batch adversarial loss: 0.507158\n",
      "epoch 193; iter: 0; batch classifier loss: 0.429454; batch adversarial loss: 0.545705\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386579; batch adversarial loss: 0.675847\n",
      "epoch 195; iter: 0; batch classifier loss: 0.269599; batch adversarial loss: 0.527024\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403782; batch adversarial loss: 0.563627\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335539; batch adversarial loss: 0.563761\n",
      "epoch 198; iter: 0; batch classifier loss: 0.450347; batch adversarial loss: 0.479468\n",
      "epoch 199; iter: 0; batch classifier loss: 0.289534; batch adversarial loss: 0.498776\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691955; batch adversarial loss: 0.859135\n",
      "epoch 1; iter: 0; batch classifier loss: 0.774928; batch adversarial loss: 0.992651\n",
      "epoch 2; iter: 0; batch classifier loss: 0.915208; batch adversarial loss: 0.933308\n",
      "epoch 3; iter: 0; batch classifier loss: 0.888573; batch adversarial loss: 0.879229\n",
      "epoch 4; iter: 0; batch classifier loss: 0.786067; batch adversarial loss: 0.788663\n",
      "epoch 5; iter: 0; batch classifier loss: 0.689743; batch adversarial loss: 0.725663\n",
      "epoch 6; iter: 0; batch classifier loss: 0.645843; batch adversarial loss: 0.688889\n",
      "epoch 7; iter: 0; batch classifier loss: 0.502846; batch adversarial loss: 0.654245\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467744; batch adversarial loss: 0.610678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548075; batch adversarial loss: 0.599074\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507834; batch adversarial loss: 0.617773\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522915; batch adversarial loss: 0.587959\n",
      "epoch 12; iter: 0; batch classifier loss: 0.655482; batch adversarial loss: 0.579152\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491232; batch adversarial loss: 0.587651\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527490; batch adversarial loss: 0.559754\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515043; batch adversarial loss: 0.627248\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477378; batch adversarial loss: 0.552787\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531839; batch adversarial loss: 0.596942\n",
      "epoch 18; iter: 0; batch classifier loss: 0.451788; batch adversarial loss: 0.589230\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475055; batch adversarial loss: 0.585900\n",
      "epoch 20; iter: 0; batch classifier loss: 0.561182; batch adversarial loss: 0.535386\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511880; batch adversarial loss: 0.557547\n",
      "epoch 22; iter: 0; batch classifier loss: 0.586508; batch adversarial loss: 0.550092\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454364; batch adversarial loss: 0.501044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518743; batch adversarial loss: 0.594807\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492898; batch adversarial loss: 0.533040\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510868; batch adversarial loss: 0.576335\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465735; batch adversarial loss: 0.546473\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483419; batch adversarial loss: 0.519136\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460844; batch adversarial loss: 0.582492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481927; batch adversarial loss: 0.571812\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445051; batch adversarial loss: 0.575474\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432178; batch adversarial loss: 0.508999\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440178; batch adversarial loss: 0.504700\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492812; batch adversarial loss: 0.621297\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473628; batch adversarial loss: 0.521657\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479399; batch adversarial loss: 0.528330\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497576; batch adversarial loss: 0.519300\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482134; batch adversarial loss: 0.581225\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470637; batch adversarial loss: 0.500684\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467319; batch adversarial loss: 0.509368\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388494; batch adversarial loss: 0.562897\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477972; batch adversarial loss: 0.514043\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430879; batch adversarial loss: 0.498193\n",
      "epoch 44; iter: 0; batch classifier loss: 0.486564; batch adversarial loss: 0.545447\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502736; batch adversarial loss: 0.545883\n",
      "epoch 46; iter: 0; batch classifier loss: 0.421351; batch adversarial loss: 0.475979\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432027; batch adversarial loss: 0.641867\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486418; batch adversarial loss: 0.499746\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433917; batch adversarial loss: 0.645444\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423645; batch adversarial loss: 0.497285\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422781; batch adversarial loss: 0.581804\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387410; batch adversarial loss: 0.482566\n",
      "epoch 53; iter: 0; batch classifier loss: 0.387091; batch adversarial loss: 0.573010\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431259; batch adversarial loss: 0.490325\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403194; batch adversarial loss: 0.518067\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473316; batch adversarial loss: 0.582297\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432344; batch adversarial loss: 0.562124\n",
      "epoch 58; iter: 0; batch classifier loss: 0.443003; batch adversarial loss: 0.543757\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409258; batch adversarial loss: 0.599574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.358621; batch adversarial loss: 0.561762\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402286; batch adversarial loss: 0.527636\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410513; batch adversarial loss: 0.543589\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426887; batch adversarial loss: 0.506076\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408353; batch adversarial loss: 0.554033\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398727; batch adversarial loss: 0.654902\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377170; batch adversarial loss: 0.560983\n",
      "epoch 67; iter: 0; batch classifier loss: 0.382496; batch adversarial loss: 0.590742\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388226; batch adversarial loss: 0.501119\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439138; batch adversarial loss: 0.544952\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411020; batch adversarial loss: 0.581074\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365190; batch adversarial loss: 0.535217\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383123; batch adversarial loss: 0.554018\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403373; batch adversarial loss: 0.490082\n",
      "epoch 74; iter: 0; batch classifier loss: 0.373122; batch adversarial loss: 0.480566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.452004; batch adversarial loss: 0.534719\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461849; batch adversarial loss: 0.545251\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429535; batch adversarial loss: 0.535797\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355461; batch adversarial loss: 0.525484\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426128; batch adversarial loss: 0.527586\n",
      "epoch 80; iter: 0; batch classifier loss: 0.342151; batch adversarial loss: 0.562323\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434444; batch adversarial loss: 0.645618\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387252; batch adversarial loss: 0.552581\n",
      "epoch 83; iter: 0; batch classifier loss: 0.339460; batch adversarial loss: 0.561372\n",
      "epoch 84; iter: 0; batch classifier loss: 0.427669; batch adversarial loss: 0.479427\n",
      "epoch 85; iter: 0; batch classifier loss: 0.506177; batch adversarial loss: 0.609217\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421802; batch adversarial loss: 0.628119\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340071; batch adversarial loss: 0.571538\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362753; batch adversarial loss: 0.525333\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412124; batch adversarial loss: 0.547020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.436499; batch adversarial loss: 0.515838\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391438; batch adversarial loss: 0.607695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.345407; batch adversarial loss: 0.518223\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422112; batch adversarial loss: 0.524817\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354992; batch adversarial loss: 0.489881\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334008; batch adversarial loss: 0.443142\n",
      "epoch 96; iter: 0; batch classifier loss: 0.301969; batch adversarial loss: 0.574212\n",
      "epoch 97; iter: 0; batch classifier loss: 0.290995; batch adversarial loss: 0.544453\n",
      "epoch 98; iter: 0; batch classifier loss: 0.340393; batch adversarial loss: 0.609080\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417364; batch adversarial loss: 0.480371\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350558; batch adversarial loss: 0.517308\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390854; batch adversarial loss: 0.581332\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348586; batch adversarial loss: 0.544766\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350011; batch adversarial loss: 0.673110\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395056; batch adversarial loss: 0.553441\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358817; batch adversarial loss: 0.635916\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413120; batch adversarial loss: 0.534374\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406943; batch adversarial loss: 0.581338\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372846; batch adversarial loss: 0.506356\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387898; batch adversarial loss: 0.480598\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389135; batch adversarial loss: 0.596579\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350959; batch adversarial loss: 0.525600\n",
      "epoch 112; iter: 0; batch classifier loss: 0.421494; batch adversarial loss: 0.553497\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350294; batch adversarial loss: 0.553225\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349014; batch adversarial loss: 0.527399\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390602; batch adversarial loss: 0.490052\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357490; batch adversarial loss: 0.480493\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350526; batch adversarial loss: 0.590418\n",
      "epoch 118; iter: 0; batch classifier loss: 0.364465; batch adversarial loss: 0.527789\n",
      "epoch 119; iter: 0; batch classifier loss: 0.332917; batch adversarial loss: 0.607907\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388122; batch adversarial loss: 0.618654\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368552; batch adversarial loss: 0.573194\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371826; batch adversarial loss: 0.601373\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423523; batch adversarial loss: 0.498248\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395204; batch adversarial loss: 0.498424\n",
      "epoch 125; iter: 0; batch classifier loss: 0.275797; batch adversarial loss: 0.525345\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334808; batch adversarial loss: 0.571537\n",
      "epoch 127; iter: 0; batch classifier loss: 0.451726; batch adversarial loss: 0.563597\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340382; batch adversarial loss: 0.535491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.411626; batch adversarial loss: 0.506937\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384514; batch adversarial loss: 0.555835\n",
      "epoch 131; iter: 0; batch classifier loss: 0.310025; batch adversarial loss: 0.500019\n",
      "epoch 132; iter: 0; batch classifier loss: 0.299583; batch adversarial loss: 0.588754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.366219; batch adversarial loss: 0.554778\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354065; batch adversarial loss: 0.517453\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388914; batch adversarial loss: 0.444948\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355124; batch adversarial loss: 0.499205\n",
      "epoch 137; iter: 0; batch classifier loss: 0.395341; batch adversarial loss: 0.525172\n",
      "epoch 138; iter: 0; batch classifier loss: 0.371784; batch adversarial loss: 0.581017\n",
      "epoch 139; iter: 0; batch classifier loss: 0.284541; batch adversarial loss: 0.553310\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346835; batch adversarial loss: 0.563324\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365435; batch adversarial loss: 0.536775\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420771; batch adversarial loss: 0.554928\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399324; batch adversarial loss: 0.571582\n",
      "epoch 144; iter: 0; batch classifier loss: 0.432447; batch adversarial loss: 0.534716\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341692; batch adversarial loss: 0.590569\n",
      "epoch 146; iter: 0; batch classifier loss: 0.305533; batch adversarial loss: 0.552188\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355816; batch adversarial loss: 0.625817\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346140; batch adversarial loss: 0.543378\n",
      "epoch 149; iter: 0; batch classifier loss: 0.280722; batch adversarial loss: 0.543126\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349150; batch adversarial loss: 0.499502\n",
      "epoch 151; iter: 0; batch classifier loss: 0.403047; batch adversarial loss: 0.508092\n",
      "epoch 152; iter: 0; batch classifier loss: 0.309607; batch adversarial loss: 0.582999\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372470; batch adversarial loss: 0.551434\n",
      "epoch 154; iter: 0; batch classifier loss: 0.405132; batch adversarial loss: 0.572737\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371511; batch adversarial loss: 0.526535\n",
      "epoch 156; iter: 0; batch classifier loss: 0.269766; batch adversarial loss: 0.553478\n",
      "epoch 157; iter: 0; batch classifier loss: 0.290615; batch adversarial loss: 0.543142\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391237; batch adversarial loss: 0.573870\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350104; batch adversarial loss: 0.544096\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335933; batch adversarial loss: 0.553926\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385948; batch adversarial loss: 0.525376\n",
      "epoch 162; iter: 0; batch classifier loss: 0.384429; batch adversarial loss: 0.535487\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402265; batch adversarial loss: 0.462267\n",
      "epoch 164; iter: 0; batch classifier loss: 0.307388; batch adversarial loss: 0.588734\n",
      "epoch 165; iter: 0; batch classifier loss: 0.293562; batch adversarial loss: 0.552371\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321641; batch adversarial loss: 0.545817\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353066; batch adversarial loss: 0.517758\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.463051\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326840; batch adversarial loss: 0.590892\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336736; batch adversarial loss: 0.471958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.348149; batch adversarial loss: 0.580225\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354956; batch adversarial loss: 0.509456\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302899; batch adversarial loss: 0.516325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334053; batch adversarial loss: 0.617174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380930; batch adversarial loss: 0.480701\n",
      "epoch 176; iter: 0; batch classifier loss: 0.419987; batch adversarial loss: 0.552765\n",
      "epoch 177; iter: 0; batch classifier loss: 0.365811; batch adversarial loss: 0.572031\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345463; batch adversarial loss: 0.572434\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323353; batch adversarial loss: 0.470478\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346600; batch adversarial loss: 0.527700\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353170; batch adversarial loss: 0.534238\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365803; batch adversarial loss: 0.580562\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388856; batch adversarial loss: 0.552735\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359281; batch adversarial loss: 0.488748\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388886; batch adversarial loss: 0.611040\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334753; batch adversarial loss: 0.552553\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367058; batch adversarial loss: 0.608529\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367843; batch adversarial loss: 0.527350\n",
      "epoch 189; iter: 0; batch classifier loss: 0.324309; batch adversarial loss: 0.597671\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344001; batch adversarial loss: 0.553883\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356940; batch adversarial loss: 0.515538\n",
      "epoch 192; iter: 0; batch classifier loss: 0.341551; batch adversarial loss: 0.617358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341624; batch adversarial loss: 0.544695\n",
      "epoch 194; iter: 0; batch classifier loss: 0.286915; batch adversarial loss: 0.507172\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317837; batch adversarial loss: 0.510458\n",
      "epoch 196; iter: 0; batch classifier loss: 0.390471; batch adversarial loss: 0.453975\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328856; batch adversarial loss: 0.600320\n",
      "epoch 198; iter: 0; batch classifier loss: 0.281706; batch adversarial loss: 0.517706\n",
      "epoch 199; iter: 0; batch classifier loss: 0.291306; batch adversarial loss: 0.581883\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667573; batch adversarial loss: 0.760492\n",
      "epoch 1; iter: 0; batch classifier loss: 0.612755; batch adversarial loss: 0.740645\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589999; batch adversarial loss: 0.711092\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530462; batch adversarial loss: 0.708864\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538584; batch adversarial loss: 0.665478\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590384; batch adversarial loss: 0.647487\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564270; batch adversarial loss: 0.641978\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543508; batch adversarial loss: 0.621006\n",
      "epoch 8; iter: 0; batch classifier loss: 0.502513; batch adversarial loss: 0.630085\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549427; batch adversarial loss: 0.608701\n",
      "epoch 10; iter: 0; batch classifier loss: 0.608652; batch adversarial loss: 0.609895\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464362; batch adversarial loss: 0.569068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503597; batch adversarial loss: 0.543641\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505628; batch adversarial loss: 0.534584\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522532; batch adversarial loss: 0.587377\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527662; batch adversarial loss: 0.614763\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486154; batch adversarial loss: 0.548256\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557514; batch adversarial loss: 0.576974\n",
      "epoch 18; iter: 0; batch classifier loss: 0.451715; batch adversarial loss: 0.617369\n",
      "epoch 19; iter: 0; batch classifier loss: 0.587569; batch adversarial loss: 0.556152\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515735; batch adversarial loss: 0.565802\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513591; batch adversarial loss: 0.628819\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456450; batch adversarial loss: 0.579029\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463955; batch adversarial loss: 0.570273\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482780; batch adversarial loss: 0.524718\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515722; batch adversarial loss: 0.569417\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514128; batch adversarial loss: 0.566918\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474766; batch adversarial loss: 0.526250\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483315; batch adversarial loss: 0.518369\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506863; batch adversarial loss: 0.548443\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479918; batch adversarial loss: 0.563658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.411196; batch adversarial loss: 0.602994\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458352; batch adversarial loss: 0.586300\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432076; batch adversarial loss: 0.570112\n",
      "epoch 34; iter: 0; batch classifier loss: 0.341668; batch adversarial loss: 0.586893\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435300; batch adversarial loss: 0.588391\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462335; batch adversarial loss: 0.554080\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445580; batch adversarial loss: 0.641585\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469943; batch adversarial loss: 0.672827\n",
      "epoch 39; iter: 0; batch classifier loss: 0.371242; batch adversarial loss: 0.535055\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459122; batch adversarial loss: 0.535208\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487600; batch adversarial loss: 0.538169\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447545; batch adversarial loss: 0.589794\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474058; batch adversarial loss: 0.533278\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447582; batch adversarial loss: 0.598944\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393636; batch adversarial loss: 0.554632\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425910; batch adversarial loss: 0.514394\n",
      "epoch 47; iter: 0; batch classifier loss: 0.346889; batch adversarial loss: 0.528933\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418780; batch adversarial loss: 0.552741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.374983; batch adversarial loss: 0.601760\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410967; batch adversarial loss: 0.563230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.389095; batch adversarial loss: 0.504710\n",
      "epoch 52; iter: 0; batch classifier loss: 0.483180; batch adversarial loss: 0.536609\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412068; batch adversarial loss: 0.525247\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413516; batch adversarial loss: 0.554614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445810; batch adversarial loss: 0.544844\n",
      "epoch 56; iter: 0; batch classifier loss: 0.496805; batch adversarial loss: 0.599069\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429251; batch adversarial loss: 0.521967\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410555; batch adversarial loss: 0.572580\n",
      "epoch 59; iter: 0; batch classifier loss: 0.472468; batch adversarial loss: 0.486322\n",
      "epoch 60; iter: 0; batch classifier loss: 0.387709; batch adversarial loss: 0.596108\n",
      "epoch 61; iter: 0; batch classifier loss: 0.368974; batch adversarial loss: 0.501756\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482109; batch adversarial loss: 0.510473\n",
      "epoch 63; iter: 0; batch classifier loss: 0.331028; batch adversarial loss: 0.527347\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435656; batch adversarial loss: 0.588637\n",
      "epoch 65; iter: 0; batch classifier loss: 0.460501; batch adversarial loss: 0.579267\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454311; batch adversarial loss: 0.571634\n",
      "epoch 67; iter: 0; batch classifier loss: 0.331199; batch adversarial loss: 0.526548\n",
      "epoch 68; iter: 0; batch classifier loss: 0.362007; batch adversarial loss: 0.596187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.385869; batch adversarial loss: 0.553230\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430398; batch adversarial loss: 0.491547\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406606; batch adversarial loss: 0.552092\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380038; batch adversarial loss: 0.528019\n",
      "epoch 73; iter: 0; batch classifier loss: 0.356862; batch adversarial loss: 0.519883\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405929; batch adversarial loss: 0.615234\n",
      "epoch 75; iter: 0; batch classifier loss: 0.320123; batch adversarial loss: 0.599445\n",
      "epoch 76; iter: 0; batch classifier loss: 0.428319; batch adversarial loss: 0.571213\n",
      "epoch 77; iter: 0; batch classifier loss: 0.460983; batch adversarial loss: 0.517370\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347029; batch adversarial loss: 0.614123\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367138; batch adversarial loss: 0.611301\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398365; batch adversarial loss: 0.479451\n",
      "epoch 81; iter: 0; batch classifier loss: 0.380742; batch adversarial loss: 0.578633\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435528; batch adversarial loss: 0.546936\n",
      "epoch 83; iter: 0; batch classifier loss: 0.454718; batch adversarial loss: 0.507866\n",
      "epoch 84; iter: 0; batch classifier loss: 0.494519; batch adversarial loss: 0.615441\n",
      "epoch 85; iter: 0; batch classifier loss: 0.333740; batch adversarial loss: 0.510796\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343304; batch adversarial loss: 0.467065\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374198; batch adversarial loss: 0.560850\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413452; batch adversarial loss: 0.586725\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371756; batch adversarial loss: 0.583320\n",
      "epoch 90; iter: 0; batch classifier loss: 0.342709; batch adversarial loss: 0.596500\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360126; batch adversarial loss: 0.612799\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413145; batch adversarial loss: 0.502361\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363083; batch adversarial loss: 0.558799\n",
      "epoch 94; iter: 0; batch classifier loss: 0.481505; batch adversarial loss: 0.563528\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396796; batch adversarial loss: 0.615939\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369146; batch adversarial loss: 0.555120\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393630; batch adversarial loss: 0.472398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.454963; batch adversarial loss: 0.579724\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434870; batch adversarial loss: 0.544861\n",
      "epoch 100; iter: 0; batch classifier loss: 0.436757; batch adversarial loss: 0.552600\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410662; batch adversarial loss: 0.545776\n",
      "epoch 102; iter: 0; batch classifier loss: 0.476530; batch adversarial loss: 0.562567\n",
      "epoch 103; iter: 0; batch classifier loss: 0.445312; batch adversarial loss: 0.501534\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371579; batch adversarial loss: 0.571667\n",
      "epoch 105; iter: 0; batch classifier loss: 0.290479; batch adversarial loss: 0.510554\n",
      "epoch 106; iter: 0; batch classifier loss: 0.411361; batch adversarial loss: 0.484210\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374402; batch adversarial loss: 0.526395\n",
      "epoch 108; iter: 0; batch classifier loss: 0.426824; batch adversarial loss: 0.614809\n",
      "epoch 109; iter: 0; batch classifier loss: 0.395868; batch adversarial loss: 0.578859\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353036; batch adversarial loss: 0.600037\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405763; batch adversarial loss: 0.588744\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387890; batch adversarial loss: 0.584991\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357670; batch adversarial loss: 0.537418\n",
      "epoch 114; iter: 0; batch classifier loss: 0.379330; batch adversarial loss: 0.525260\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360470; batch adversarial loss: 0.507874\n",
      "epoch 116; iter: 0; batch classifier loss: 0.293273; batch adversarial loss: 0.536531\n",
      "epoch 117; iter: 0; batch classifier loss: 0.292597; batch adversarial loss: 0.585616\n",
      "epoch 118; iter: 0; batch classifier loss: 0.419898; batch adversarial loss: 0.482241\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337691; batch adversarial loss: 0.480924\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416863; batch adversarial loss: 0.561752\n",
      "epoch 121; iter: 0; batch classifier loss: 0.340736; batch adversarial loss: 0.618249\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352281; batch adversarial loss: 0.589723\n",
      "epoch 123; iter: 0; batch classifier loss: 0.358764; batch adversarial loss: 0.563463\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366200; batch adversarial loss: 0.510080\n",
      "epoch 125; iter: 0; batch classifier loss: 0.464267; batch adversarial loss: 0.558739\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402935; batch adversarial loss: 0.564148\n",
      "epoch 127; iter: 0; batch classifier loss: 0.361192; batch adversarial loss: 0.563468\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355003; batch adversarial loss: 0.561513\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379131; batch adversarial loss: 0.608850\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382242; batch adversarial loss: 0.562603\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343885; batch adversarial loss: 0.532046\n",
      "epoch 132; iter: 0; batch classifier loss: 0.420148; batch adversarial loss: 0.520590\n",
      "epoch 133; iter: 0; batch classifier loss: 0.445135; batch adversarial loss: 0.564101\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385558; batch adversarial loss: 0.587834\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352134; batch adversarial loss: 0.571077\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370949; batch adversarial loss: 0.570600\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416848; batch adversarial loss: 0.502211\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334211; batch adversarial loss: 0.509821\n",
      "epoch 139; iter: 0; batch classifier loss: 0.330491; batch adversarial loss: 0.623695\n",
      "epoch 140; iter: 0; batch classifier loss: 0.385323; batch adversarial loss: 0.570455\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370688; batch adversarial loss: 0.642569\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397057; batch adversarial loss: 0.527167\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378248; batch adversarial loss: 0.552978\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374252; batch adversarial loss: 0.615294\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350414; batch adversarial loss: 0.561706\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416761; batch adversarial loss: 0.597328\n",
      "epoch 147; iter: 0; batch classifier loss: 0.389241; batch adversarial loss: 0.570417\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279541; batch adversarial loss: 0.607509\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337902; batch adversarial loss: 0.543590\n",
      "epoch 150; iter: 0; batch classifier loss: 0.458285; batch adversarial loss: 0.561225\n",
      "epoch 151; iter: 0; batch classifier loss: 0.421978; batch adversarial loss: 0.518614\n",
      "epoch 152; iter: 0; batch classifier loss: 0.467705; batch adversarial loss: 0.604644\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362319; batch adversarial loss: 0.579150\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347265; batch adversarial loss: 0.632127\n",
      "epoch 155; iter: 0; batch classifier loss: 0.487821; batch adversarial loss: 0.527969\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367282; batch adversarial loss: 0.527291\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352212; batch adversarial loss: 0.519855\n",
      "epoch 158; iter: 0; batch classifier loss: 0.420896; batch adversarial loss: 0.482653\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391613; batch adversarial loss: 0.596605\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337895; batch adversarial loss: 0.525729\n",
      "epoch 161; iter: 0; batch classifier loss: 0.371883; batch adversarial loss: 0.551376\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363784; batch adversarial loss: 0.606068\n",
      "epoch 163; iter: 0; batch classifier loss: 0.295726; batch adversarial loss: 0.527832\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333413; batch adversarial loss: 0.572916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.410544; batch adversarial loss: 0.589189\n",
      "epoch 166; iter: 0; batch classifier loss: 0.320514; batch adversarial loss: 0.632785\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363797; batch adversarial loss: 0.546505\n",
      "epoch 168; iter: 0; batch classifier loss: 0.429374; batch adversarial loss: 0.597097\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405687; batch adversarial loss: 0.560347\n",
      "epoch 170; iter: 0; batch classifier loss: 0.350621; batch adversarial loss: 0.561423\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335600; batch adversarial loss: 0.542724\n",
      "epoch 172; iter: 0; batch classifier loss: 0.301953; batch adversarial loss: 0.551972\n",
      "epoch 173; iter: 0; batch classifier loss: 0.402668; batch adversarial loss: 0.554060\n",
      "epoch 174; iter: 0; batch classifier loss: 0.287738; batch adversarial loss: 0.569679\n",
      "epoch 175; iter: 0; batch classifier loss: 0.437647; batch adversarial loss: 0.552287\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382955; batch adversarial loss: 0.599794\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343862; batch adversarial loss: 0.623295\n",
      "epoch 178; iter: 0; batch classifier loss: 0.408776; batch adversarial loss: 0.593456\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330692; batch adversarial loss: 0.518503\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372739; batch adversarial loss: 0.652451\n",
      "epoch 181; iter: 0; batch classifier loss: 0.449443; batch adversarial loss: 0.564746\n",
      "epoch 182; iter: 0; batch classifier loss: 0.428390; batch adversarial loss: 0.528501\n",
      "epoch 183; iter: 0; batch classifier loss: 0.334437; batch adversarial loss: 0.607292\n",
      "epoch 184; iter: 0; batch classifier loss: 0.323458; batch adversarial loss: 0.543887\n",
      "epoch 185; iter: 0; batch classifier loss: 0.270235; batch adversarial loss: 0.545317\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359182; batch adversarial loss: 0.546415\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357295; batch adversarial loss: 0.692876\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363987; batch adversarial loss: 0.553384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332656; batch adversarial loss: 0.483566\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341884; batch adversarial loss: 0.544587\n",
      "epoch 191; iter: 0; batch classifier loss: 0.274308; batch adversarial loss: 0.501760\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343908; batch adversarial loss: 0.535198\n",
      "epoch 193; iter: 0; batch classifier loss: 0.256386; batch adversarial loss: 0.483469\n",
      "epoch 194; iter: 0; batch classifier loss: 0.412874; batch adversarial loss: 0.562650\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360853; batch adversarial loss: 0.597074\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335750; batch adversarial loss: 0.561427\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328717; batch adversarial loss: 0.571485\n",
      "epoch 198; iter: 0; batch classifier loss: 0.429646; batch adversarial loss: 0.571627\n",
      "epoch 199; iter: 0; batch classifier loss: 0.426465; batch adversarial loss: 0.570766\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710917; batch adversarial loss: 0.718953\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637399; batch adversarial loss: 0.681657\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567022; batch adversarial loss: 0.644689\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543001; batch adversarial loss: 0.658095\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553491; batch adversarial loss: 0.646468\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540699; batch adversarial loss: 0.644140\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590761; batch adversarial loss: 0.609889\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485050; batch adversarial loss: 0.650639\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579911; batch adversarial loss: 0.607775\n",
      "epoch 9; iter: 0; batch classifier loss: 0.497238; batch adversarial loss: 0.580134\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579564; batch adversarial loss: 0.550767\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544237; batch adversarial loss: 0.557965\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567000; batch adversarial loss: 0.578596\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552554; batch adversarial loss: 0.664818\n",
      "epoch 14; iter: 0; batch classifier loss: 0.536203; batch adversarial loss: 0.579732\n",
      "epoch 15; iter: 0; batch classifier loss: 0.583586; batch adversarial loss: 0.586969\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526572; batch adversarial loss: 0.551681\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539130; batch adversarial loss: 0.593858\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472092; batch adversarial loss: 0.547702\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515916; batch adversarial loss: 0.564923\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487682; batch adversarial loss: 0.556033\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536161; batch adversarial loss: 0.568231\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521037; batch adversarial loss: 0.510543\n",
      "epoch 23; iter: 0; batch classifier loss: 0.419522; batch adversarial loss: 0.539228\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547212; batch adversarial loss: 0.515793\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449254; batch adversarial loss: 0.565402\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520723; batch adversarial loss: 0.489147\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455843; batch adversarial loss: 0.556679\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470101; batch adversarial loss: 0.562940\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514829; batch adversarial loss: 0.524372\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415724; batch adversarial loss: 0.596235\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467000; batch adversarial loss: 0.554407\n",
      "epoch 32; iter: 0; batch classifier loss: 0.376366; batch adversarial loss: 0.569263\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466903; batch adversarial loss: 0.577273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501546; batch adversarial loss: 0.547413\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429871; batch adversarial loss: 0.527353\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434162; batch adversarial loss: 0.525233\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473429; batch adversarial loss: 0.643449\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434477; batch adversarial loss: 0.572429\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447298; batch adversarial loss: 0.606055\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489456; batch adversarial loss: 0.599303\n",
      "epoch 41; iter: 0; batch classifier loss: 0.524566; batch adversarial loss: 0.511610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427033; batch adversarial loss: 0.546147\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414586; batch adversarial loss: 0.529190\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431204; batch adversarial loss: 0.553547\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420316; batch adversarial loss: 0.612708\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405849; batch adversarial loss: 0.569797\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472135; batch adversarial loss: 0.562431\n",
      "epoch 48; iter: 0; batch classifier loss: 0.480359; batch adversarial loss: 0.536763\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447638; batch adversarial loss: 0.587884\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443656; batch adversarial loss: 0.580546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455064; batch adversarial loss: 0.474669\n",
      "epoch 52; iter: 0; batch classifier loss: 0.505953; batch adversarial loss: 0.606807\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428633; batch adversarial loss: 0.536004\n",
      "epoch 54; iter: 0; batch classifier loss: 0.377340; batch adversarial loss: 0.580283\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430450; batch adversarial loss: 0.500545\n",
      "epoch 56; iter: 0; batch classifier loss: 0.475225; batch adversarial loss: 0.562502\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427387; batch adversarial loss: 0.571416\n",
      "epoch 58; iter: 0; batch classifier loss: 0.348841; batch adversarial loss: 0.553286\n",
      "epoch 59; iter: 0; batch classifier loss: 0.496446; batch adversarial loss: 0.544522\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435170; batch adversarial loss: 0.606171\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466109; batch adversarial loss: 0.551072\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421871; batch adversarial loss: 0.478772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.374453; batch adversarial loss: 0.532858\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412340; batch adversarial loss: 0.509971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419809; batch adversarial loss: 0.518677\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434452; batch adversarial loss: 0.642720\n",
      "epoch 67; iter: 0; batch classifier loss: 0.455665; batch adversarial loss: 0.562282\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421700; batch adversarial loss: 0.465133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.514372; batch adversarial loss: 0.571640\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422275; batch adversarial loss: 0.519459\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436189; batch adversarial loss: 0.563099\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386550; batch adversarial loss: 0.589151\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373493; batch adversarial loss: 0.562529\n",
      "epoch 74; iter: 0; batch classifier loss: 0.442434; batch adversarial loss: 0.517316\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362303; batch adversarial loss: 0.553424\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371721; batch adversarial loss: 0.651444\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376523; batch adversarial loss: 0.580285\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421431; batch adversarial loss: 0.500346\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393991; batch adversarial loss: 0.579879\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410831; batch adversarial loss: 0.571314\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405334; batch adversarial loss: 0.500081\n",
      "epoch 82; iter: 0; batch classifier loss: 0.339457; batch adversarial loss: 0.624966\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420868; batch adversarial loss: 0.518397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.320955; batch adversarial loss: 0.464409\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370304; batch adversarial loss: 0.535757\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384848; batch adversarial loss: 0.606809\n",
      "epoch 87; iter: 0; batch classifier loss: 0.313777; batch adversarial loss: 0.571464\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440285; batch adversarial loss: 0.500631\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397365; batch adversarial loss: 0.580865\n",
      "epoch 90; iter: 0; batch classifier loss: 0.356688; batch adversarial loss: 0.491501\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358336; batch adversarial loss: 0.562069\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375277; batch adversarial loss: 0.562757\n",
      "epoch 93; iter: 0; batch classifier loss: 0.414472; batch adversarial loss: 0.562429\n",
      "epoch 94; iter: 0; batch classifier loss: 0.329326; batch adversarial loss: 0.527279\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409291; batch adversarial loss: 0.570949\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377898; batch adversarial loss: 0.580554\n",
      "epoch 97; iter: 0; batch classifier loss: 0.449269; batch adversarial loss: 0.500535\n",
      "epoch 98; iter: 0; batch classifier loss: 0.348848; batch adversarial loss: 0.597872\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387763; batch adversarial loss: 0.588687\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411509; batch adversarial loss: 0.544401\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385022; batch adversarial loss: 0.482632\n",
      "epoch 102; iter: 0; batch classifier loss: 0.428432; batch adversarial loss: 0.580823\n",
      "epoch 103; iter: 0; batch classifier loss: 0.280834; batch adversarial loss: 0.491931\n",
      "epoch 104; iter: 0; batch classifier loss: 0.330690; batch adversarial loss: 0.536242\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394998; batch adversarial loss: 0.482385\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407035; batch adversarial loss: 0.588774\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400227; batch adversarial loss: 0.526656\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370514; batch adversarial loss: 0.545318\n",
      "epoch 109; iter: 0; batch classifier loss: 0.320311; batch adversarial loss: 0.580093\n",
      "epoch 110; iter: 0; batch classifier loss: 0.361484; batch adversarial loss: 0.633838\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388300; batch adversarial loss: 0.598413\n",
      "epoch 112; iter: 0; batch classifier loss: 0.380367; batch adversarial loss: 0.580282\n",
      "epoch 113; iter: 0; batch classifier loss: 0.308668; batch adversarial loss: 0.563371\n",
      "epoch 114; iter: 0; batch classifier loss: 0.395486; batch adversarial loss: 0.545027\n",
      "epoch 115; iter: 0; batch classifier loss: 0.351326; batch adversarial loss: 0.474132\n",
      "epoch 116; iter: 0; batch classifier loss: 0.344506; batch adversarial loss: 0.518287\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401112; batch adversarial loss: 0.624260\n",
      "epoch 118; iter: 0; batch classifier loss: 0.413948; batch adversarial loss: 0.545149\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342294; batch adversarial loss: 0.492253\n",
      "epoch 120; iter: 0; batch classifier loss: 0.292822; batch adversarial loss: 0.598727\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349417; batch adversarial loss: 0.570775\n",
      "epoch 122; iter: 0; batch classifier loss: 0.504914; batch adversarial loss: 0.570649\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362717; batch adversarial loss: 0.598209\n",
      "epoch 124; iter: 0; batch classifier loss: 0.424533; batch adversarial loss: 0.527291\n",
      "epoch 125; iter: 0; batch classifier loss: 0.366035; batch adversarial loss: 0.562809\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373888; batch adversarial loss: 0.571832\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379040; batch adversarial loss: 0.526845\n",
      "epoch 128; iter: 0; batch classifier loss: 0.457166; batch adversarial loss: 0.481963\n",
      "epoch 129; iter: 0; batch classifier loss: 0.257340; batch adversarial loss: 0.535276\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377821; batch adversarial loss: 0.607512\n",
      "epoch 131; iter: 0; batch classifier loss: 0.432287; batch adversarial loss: 0.589060\n",
      "epoch 132; iter: 0; batch classifier loss: 0.385706; batch adversarial loss: 0.589618\n",
      "epoch 133; iter: 0; batch classifier loss: 0.299901; batch adversarial loss: 0.517891\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400285; batch adversarial loss: 0.526488\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377558; batch adversarial loss: 0.491778\n",
      "epoch 136; iter: 0; batch classifier loss: 0.325585; batch adversarial loss: 0.572098\n",
      "epoch 137; iter: 0; batch classifier loss: 0.315542; batch adversarial loss: 0.527472\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394133; batch adversarial loss: 0.607003\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384810; batch adversarial loss: 0.563193\n",
      "epoch 140; iter: 0; batch classifier loss: 0.477471; batch adversarial loss: 0.526944\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398530; batch adversarial loss: 0.589089\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369332; batch adversarial loss: 0.501103\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342934; batch adversarial loss: 0.597611\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405527; batch adversarial loss: 0.553687\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404304; batch adversarial loss: 0.590033\n",
      "epoch 146; iter: 0; batch classifier loss: 0.414386; batch adversarial loss: 0.571207\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348197; batch adversarial loss: 0.607623\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.597943\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388915; batch adversarial loss: 0.572307\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360224; batch adversarial loss: 0.598741\n",
      "epoch 151; iter: 0; batch classifier loss: 0.332734; batch adversarial loss: 0.598581\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353389; batch adversarial loss: 0.463780\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345694; batch adversarial loss: 0.624653\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362820; batch adversarial loss: 0.598572\n",
      "epoch 155; iter: 0; batch classifier loss: 0.430251; batch adversarial loss: 0.563342\n",
      "epoch 156; iter: 0; batch classifier loss: 0.360886; batch adversarial loss: 0.596632\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334693; batch adversarial loss: 0.544675\n",
      "epoch 158; iter: 0; batch classifier loss: 0.283755; batch adversarial loss: 0.517599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.375082; batch adversarial loss: 0.642951\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344616; batch adversarial loss: 0.633219\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373030; batch adversarial loss: 0.579282\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370168; batch adversarial loss: 0.535954\n",
      "epoch 163; iter: 0; batch classifier loss: 0.300462; batch adversarial loss: 0.563006\n",
      "epoch 164; iter: 0; batch classifier loss: 0.357898; batch adversarial loss: 0.544639\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315564; batch adversarial loss: 0.527163\n",
      "epoch 166; iter: 0; batch classifier loss: 0.458180; batch adversarial loss: 0.580665\n",
      "epoch 167; iter: 0; batch classifier loss: 0.315388; batch adversarial loss: 0.597658\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349350; batch adversarial loss: 0.553921\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316483; batch adversarial loss: 0.615860\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412946; batch adversarial loss: 0.570743\n",
      "epoch 171; iter: 0; batch classifier loss: 0.311588; batch adversarial loss: 0.472784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.390178; batch adversarial loss: 0.527159\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343188; batch adversarial loss: 0.553743\n",
      "epoch 174; iter: 0; batch classifier loss: 0.304184; batch adversarial loss: 0.544588\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345277; batch adversarial loss: 0.536323\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349610; batch adversarial loss: 0.544285\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335083; batch adversarial loss: 0.570703\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309676; batch adversarial loss: 0.499771\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308742; batch adversarial loss: 0.509068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372425; batch adversarial loss: 0.545277\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377893; batch adversarial loss: 0.527458\n",
      "epoch 182; iter: 0; batch classifier loss: 0.362035; batch adversarial loss: 0.508880\n",
      "epoch 183; iter: 0; batch classifier loss: 0.473247; batch adversarial loss: 0.580085\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354077; batch adversarial loss: 0.535252\n",
      "epoch 185; iter: 0; batch classifier loss: 0.312648; batch adversarial loss: 0.526537\n",
      "epoch 186; iter: 0; batch classifier loss: 0.297478; batch adversarial loss: 0.598097\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334698; batch adversarial loss: 0.579968\n",
      "epoch 188; iter: 0; batch classifier loss: 0.493718; batch adversarial loss: 0.562726\n",
      "epoch 189; iter: 0; batch classifier loss: 0.392537; batch adversarial loss: 0.606698\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340288; batch adversarial loss: 0.526724\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391298; batch adversarial loss: 0.571599\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293726; batch adversarial loss: 0.615436\n",
      "epoch 193; iter: 0; batch classifier loss: 0.299325; batch adversarial loss: 0.589509\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347565; batch adversarial loss: 0.607869\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364393; batch adversarial loss: 0.536327\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335167; batch adversarial loss: 0.588089\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318805; batch adversarial loss: 0.509160\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358183; batch adversarial loss: 0.553565\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333070; batch adversarial loss: 0.562523\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760974; batch adversarial loss: 0.673410\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571060; batch adversarial loss: 0.679813\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542352; batch adversarial loss: 0.657467\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550367; batch adversarial loss: 0.619394\n",
      "epoch 4; iter: 0; batch classifier loss: 0.684155; batch adversarial loss: 0.634321\n",
      "epoch 5; iter: 0; batch classifier loss: 0.456285; batch adversarial loss: 0.620100\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569933; batch adversarial loss: 0.589570\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531810; batch adversarial loss: 0.604399\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601354; batch adversarial loss: 0.623865\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510792; batch adversarial loss: 0.586822\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533211; batch adversarial loss: 0.601797\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441537; batch adversarial loss: 0.564703\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523193; batch adversarial loss: 0.645505\n",
      "epoch 13; iter: 0; batch classifier loss: 0.458591; batch adversarial loss: 0.604123\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541296; batch adversarial loss: 0.582428\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555768; batch adversarial loss: 0.510971\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511396; batch adversarial loss: 0.555840\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468410; batch adversarial loss: 0.597632\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462332; batch adversarial loss: 0.520009\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502573; batch adversarial loss: 0.574397\n",
      "epoch 20; iter: 0; batch classifier loss: 0.563128; batch adversarial loss: 0.561023\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507036; batch adversarial loss: 0.580823\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535353; batch adversarial loss: 0.521536\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513747; batch adversarial loss: 0.582991\n",
      "epoch 24; iter: 0; batch classifier loss: 0.549355; batch adversarial loss: 0.574504\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466200; batch adversarial loss: 0.582805\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495332; batch adversarial loss: 0.626786\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488317; batch adversarial loss: 0.498155\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480159; batch adversarial loss: 0.536066\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510165; batch adversarial loss: 0.489581\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479472; batch adversarial loss: 0.679722\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483390; batch adversarial loss: 0.511337\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415421; batch adversarial loss: 0.477437\n",
      "epoch 33; iter: 0; batch classifier loss: 0.500888; batch adversarial loss: 0.588895\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448421; batch adversarial loss: 0.511283\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504707; batch adversarial loss: 0.580082\n",
      "epoch 36; iter: 0; batch classifier loss: 0.507193; batch adversarial loss: 0.544870\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432069; batch adversarial loss: 0.536257\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482578; batch adversarial loss: 0.518779\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434785; batch adversarial loss: 0.612378\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405360; batch adversarial loss: 0.552751\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413715; batch adversarial loss: 0.597894\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501875; batch adversarial loss: 0.518263\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412466; batch adversarial loss: 0.597031\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412070; batch adversarial loss: 0.524954\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416244; batch adversarial loss: 0.562990\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440745; batch adversarial loss: 0.501754\n",
      "epoch 47; iter: 0; batch classifier loss: 0.353320; batch adversarial loss: 0.527454\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370920; batch adversarial loss: 0.551536\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431337; batch adversarial loss: 0.571928\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459699; batch adversarial loss: 0.554189\n",
      "epoch 51; iter: 0; batch classifier loss: 0.500360; batch adversarial loss: 0.489439\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510644; batch adversarial loss: 0.489433\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461899; batch adversarial loss: 0.526682\n",
      "epoch 54; iter: 0; batch classifier loss: 0.485749; batch adversarial loss: 0.572688\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423086; batch adversarial loss: 0.509421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.442297; batch adversarial loss: 0.534810\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418156; batch adversarial loss: 0.561596\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436850; batch adversarial loss: 0.472488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438746; batch adversarial loss: 0.563730\n",
      "epoch 60; iter: 0; batch classifier loss: 0.372193; batch adversarial loss: 0.598886\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410995; batch adversarial loss: 0.509879\n",
      "epoch 62; iter: 0; batch classifier loss: 0.471390; batch adversarial loss: 0.500168\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423332; batch adversarial loss: 0.518088\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403533; batch adversarial loss: 0.589758\n",
      "epoch 65; iter: 0; batch classifier loss: 0.501457; batch adversarial loss: 0.563924\n",
      "epoch 66; iter: 0; batch classifier loss: 0.341905; batch adversarial loss: 0.626599\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386410; batch adversarial loss: 0.599166\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356080; batch adversarial loss: 0.518358\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417766; batch adversarial loss: 0.571317\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438302; batch adversarial loss: 0.596965\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390035; batch adversarial loss: 0.526763\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364382; batch adversarial loss: 0.545019\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403469; batch adversarial loss: 0.464665\n",
      "epoch 74; iter: 0; batch classifier loss: 0.350256; batch adversarial loss: 0.528491\n",
      "epoch 75; iter: 0; batch classifier loss: 0.410875; batch adversarial loss: 0.562309\n",
      "epoch 76; iter: 0; batch classifier loss: 0.344969; batch adversarial loss: 0.519852\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434784; batch adversarial loss: 0.616866\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390937; batch adversarial loss: 0.519679\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368131; batch adversarial loss: 0.482335\n",
      "epoch 80; iter: 0; batch classifier loss: 0.404238; batch adversarial loss: 0.498320\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358781; batch adversarial loss: 0.518069\n",
      "epoch 82; iter: 0; batch classifier loss: 0.425917; batch adversarial loss: 0.536317\n",
      "epoch 83; iter: 0; batch classifier loss: 0.314361; batch adversarial loss: 0.554834\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405733; batch adversarial loss: 0.599512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381800; batch adversarial loss: 0.556176\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424561; batch adversarial loss: 0.516951\n",
      "epoch 87; iter: 0; batch classifier loss: 0.469577; batch adversarial loss: 0.579808\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360285; batch adversarial loss: 0.507713\n",
      "epoch 89; iter: 0; batch classifier loss: 0.348657; batch adversarial loss: 0.498241\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359824; batch adversarial loss: 0.500350\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381625; batch adversarial loss: 0.544240\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404899; batch adversarial loss: 0.571289\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455806; batch adversarial loss: 0.606400\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396137; batch adversarial loss: 0.500509\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352766; batch adversarial loss: 0.536551\n",
      "epoch 96; iter: 0; batch classifier loss: 0.343936; batch adversarial loss: 0.562617\n",
      "epoch 97; iter: 0; batch classifier loss: 0.357352; batch adversarial loss: 0.544525\n",
      "epoch 98; iter: 0; batch classifier loss: 0.413786; batch adversarial loss: 0.581584\n",
      "epoch 99; iter: 0; batch classifier loss: 0.338382; batch adversarial loss: 0.553877\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402972; batch adversarial loss: 0.572416\n",
      "epoch 101; iter: 0; batch classifier loss: 0.300022; batch adversarial loss: 0.508531\n",
      "epoch 102; iter: 0; batch classifier loss: 0.378656; batch adversarial loss: 0.587930\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409178; batch adversarial loss: 0.589806\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373928; batch adversarial loss: 0.509038\n",
      "epoch 105; iter: 0; batch classifier loss: 0.428690; batch adversarial loss: 0.509428\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395312; batch adversarial loss: 0.572500\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380586; batch adversarial loss: 0.515335\n",
      "epoch 108; iter: 0; batch classifier loss: 0.432098; batch adversarial loss: 0.553415\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361032; batch adversarial loss: 0.569986\n",
      "epoch 110; iter: 0; batch classifier loss: 0.423148; batch adversarial loss: 0.553538\n",
      "epoch 111; iter: 0; batch classifier loss: 0.280522; batch adversarial loss: 0.551095\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415187; batch adversarial loss: 0.582727\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378738; batch adversarial loss: 0.588847\n",
      "epoch 114; iter: 0; batch classifier loss: 0.432024; batch adversarial loss: 0.597793\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340699; batch adversarial loss: 0.607007\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356315; batch adversarial loss: 0.516516\n",
      "epoch 117; iter: 0; batch classifier loss: 0.473393; batch adversarial loss: 0.499765\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404828; batch adversarial loss: 0.587705\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392549; batch adversarial loss: 0.535230\n",
      "epoch 120; iter: 0; batch classifier loss: 0.339440; batch adversarial loss: 0.563568\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350896; batch adversarial loss: 0.588652\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409941; batch adversarial loss: 0.553472\n",
      "epoch 123; iter: 0; batch classifier loss: 0.466342; batch adversarial loss: 0.535454\n",
      "epoch 124; iter: 0; batch classifier loss: 0.333296; batch adversarial loss: 0.535313\n",
      "epoch 125; iter: 0; batch classifier loss: 0.341718; batch adversarial loss: 0.509670\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372873; batch adversarial loss: 0.543254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397947; batch adversarial loss: 0.509443\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422732; batch adversarial loss: 0.588103\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355759; batch adversarial loss: 0.551900\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368171; batch adversarial loss: 0.560819\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360987; batch adversarial loss: 0.572927\n",
      "epoch 132; iter: 0; batch classifier loss: 0.385613; batch adversarial loss: 0.536703\n",
      "epoch 133; iter: 0; batch classifier loss: 0.462137; batch adversarial loss: 0.517334\n",
      "epoch 134; iter: 0; batch classifier loss: 0.424692; batch adversarial loss: 0.563895\n",
      "epoch 135; iter: 0; batch classifier loss: 0.405358; batch adversarial loss: 0.489374\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359051; batch adversarial loss: 0.451683\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376049; batch adversarial loss: 0.518491\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388201; batch adversarial loss: 0.508856\n",
      "epoch 139; iter: 0; batch classifier loss: 0.396740; batch adversarial loss: 0.562127\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342339; batch adversarial loss: 0.562611\n",
      "epoch 141; iter: 0; batch classifier loss: 0.402965; batch adversarial loss: 0.554125\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358397; batch adversarial loss: 0.572434\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405514; batch adversarial loss: 0.588599\n",
      "epoch 144; iter: 0; batch classifier loss: 0.413083; batch adversarial loss: 0.552878\n",
      "epoch 145; iter: 0; batch classifier loss: 0.329191; batch adversarial loss: 0.644710\n",
      "epoch 146; iter: 0; batch classifier loss: 0.432480; batch adversarial loss: 0.517687\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347646; batch adversarial loss: 0.615006\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342370; batch adversarial loss: 0.627540\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339193; batch adversarial loss: 0.571131\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382360; batch adversarial loss: 0.526789\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334268; batch adversarial loss: 0.537321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.298251; batch adversarial loss: 0.525099\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302253; batch adversarial loss: 0.543494\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322815; batch adversarial loss: 0.517723\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411321; batch adversarial loss: 0.535932\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404087; batch adversarial loss: 0.500329\n",
      "epoch 157; iter: 0; batch classifier loss: 0.263541; batch adversarial loss: 0.627763\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378021; batch adversarial loss: 0.580114\n",
      "epoch 159; iter: 0; batch classifier loss: 0.355289; batch adversarial loss: 0.536704\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365617; batch adversarial loss: 0.447058\n",
      "epoch 161; iter: 0; batch classifier loss: 0.398587; batch adversarial loss: 0.525815\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372867; batch adversarial loss: 0.527463\n",
      "epoch 163; iter: 0; batch classifier loss: 0.408662; batch adversarial loss: 0.543349\n",
      "epoch 164; iter: 0; batch classifier loss: 0.472120; batch adversarial loss: 0.571321\n",
      "epoch 165; iter: 0; batch classifier loss: 0.404148; batch adversarial loss: 0.552941\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361691; batch adversarial loss: 0.544669\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371934; batch adversarial loss: 0.571998\n",
      "epoch 168; iter: 0; batch classifier loss: 0.424407; batch adversarial loss: 0.544717\n",
      "epoch 169; iter: 0; batch classifier loss: 0.282376; batch adversarial loss: 0.563994\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388479; batch adversarial loss: 0.553944\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390184; batch adversarial loss: 0.570668\n",
      "epoch 172; iter: 0; batch classifier loss: 0.429096; batch adversarial loss: 0.581535\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414879; batch adversarial loss: 0.562363\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353315; batch adversarial loss: 0.599012\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351976; batch adversarial loss: 0.571483\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408373; batch adversarial loss: 0.518132\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358902; batch adversarial loss: 0.509256\n",
      "epoch 178; iter: 0; batch classifier loss: 0.440371; batch adversarial loss: 0.517699\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334726; batch adversarial loss: 0.519940\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372543; batch adversarial loss: 0.570390\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319653; batch adversarial loss: 0.572267\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373089; batch adversarial loss: 0.498603\n",
      "epoch 183; iter: 0; batch classifier loss: 0.318433; batch adversarial loss: 0.590696\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302651; batch adversarial loss: 0.579866\n",
      "epoch 185; iter: 0; batch classifier loss: 0.344751; batch adversarial loss: 0.564027\n",
      "epoch 186; iter: 0; batch classifier loss: 0.438344; batch adversarial loss: 0.565737\n",
      "epoch 187; iter: 0; batch classifier loss: 0.412927; batch adversarial loss: 0.580193\n",
      "epoch 188; iter: 0; batch classifier loss: 0.405430; batch adversarial loss: 0.501828\n",
      "epoch 189; iter: 0; batch classifier loss: 0.393529; batch adversarial loss: 0.597074\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321985; batch adversarial loss: 0.634043\n",
      "epoch 191; iter: 0; batch classifier loss: 0.404585; batch adversarial loss: 0.436221\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328566; batch adversarial loss: 0.562756\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284458; batch adversarial loss: 0.490685\n",
      "epoch 194; iter: 0; batch classifier loss: 0.520403; batch adversarial loss: 0.599395\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361734; batch adversarial loss: 0.543836\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347172; batch adversarial loss: 0.564011\n",
      "epoch 197; iter: 0; batch classifier loss: 0.464481; batch adversarial loss: 0.572093\n",
      "epoch 198; iter: 0; batch classifier loss: 0.398943; batch adversarial loss: 0.563680\n",
      "epoch 199; iter: 0; batch classifier loss: 0.302863; batch adversarial loss: 0.551155\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710187; batch adversarial loss: 0.648378\n",
      "epoch 1; iter: 0; batch classifier loss: 0.611982; batch adversarial loss: 0.652373\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596117; batch adversarial loss: 0.606486\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575851; batch adversarial loss: 0.627388\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559271; batch adversarial loss: 0.618599\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551658; batch adversarial loss: 0.648356\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586019; batch adversarial loss: 0.627727\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582066; batch adversarial loss: 0.549927\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619391; batch adversarial loss: 0.633758\n",
      "epoch 9; iter: 0; batch classifier loss: 0.615782; batch adversarial loss: 0.602504\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556114; batch adversarial loss: 0.583292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547623; batch adversarial loss: 0.610146\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502670; batch adversarial loss: 0.572479\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495696; batch adversarial loss: 0.569906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466035; batch adversarial loss: 0.626698\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556569; batch adversarial loss: 0.580539\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529688; batch adversarial loss: 0.590428\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556139; batch adversarial loss: 0.551614\n",
      "epoch 18; iter: 0; batch classifier loss: 0.587030; batch adversarial loss: 0.521099\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491474; batch adversarial loss: 0.548825\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503824; batch adversarial loss: 0.486115\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492314; batch adversarial loss: 0.578014\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440215; batch adversarial loss: 0.491648\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470112; batch adversarial loss: 0.529769\n",
      "epoch 24; iter: 0; batch classifier loss: 0.538313; batch adversarial loss: 0.461133\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453432; batch adversarial loss: 0.469504\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455664; batch adversarial loss: 0.600276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473781; batch adversarial loss: 0.619394\n",
      "epoch 28; iter: 0; batch classifier loss: 0.420770; batch adversarial loss: 0.533862\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480658; batch adversarial loss: 0.521092\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435091; batch adversarial loss: 0.567045\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471084; batch adversarial loss: 0.590874\n",
      "epoch 32; iter: 0; batch classifier loss: 0.526626; batch adversarial loss: 0.513828\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494107; batch adversarial loss: 0.556502\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457381; batch adversarial loss: 0.545244\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445088; batch adversarial loss: 0.491894\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437920; batch adversarial loss: 0.562840\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470750; batch adversarial loss: 0.581151\n",
      "epoch 38; iter: 0; batch classifier loss: 0.456759; batch adversarial loss: 0.607622\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423786; batch adversarial loss: 0.534528\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419367; batch adversarial loss: 0.567346\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464590; batch adversarial loss: 0.552828\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463995; batch adversarial loss: 0.545031\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465097; batch adversarial loss: 0.527906\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408033; batch adversarial loss: 0.569770\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456845; batch adversarial loss: 0.553632\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445169; batch adversarial loss: 0.545312\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416889; batch adversarial loss: 0.474214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.416418; batch adversarial loss: 0.563009\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442572; batch adversarial loss: 0.507999\n",
      "epoch 50; iter: 0; batch classifier loss: 0.384824; batch adversarial loss: 0.508893\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497898; batch adversarial loss: 0.553266\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439483; batch adversarial loss: 0.552177\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402355; batch adversarial loss: 0.534957\n",
      "epoch 54; iter: 0; batch classifier loss: 0.487251; batch adversarial loss: 0.561731\n",
      "epoch 55; iter: 0; batch classifier loss: 0.316734; batch adversarial loss: 0.545096\n",
      "epoch 56; iter: 0; batch classifier loss: 0.407030; batch adversarial loss: 0.478610\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435705; batch adversarial loss: 0.638699\n",
      "epoch 58; iter: 0; batch classifier loss: 0.369617; batch adversarial loss: 0.561021\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418913; batch adversarial loss: 0.591352\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403129; batch adversarial loss: 0.570566\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436342; batch adversarial loss: 0.578435\n",
      "epoch 62; iter: 0; batch classifier loss: 0.473466; batch adversarial loss: 0.590766\n",
      "epoch 63; iter: 0; batch classifier loss: 0.513146; batch adversarial loss: 0.534646\n",
      "epoch 64; iter: 0; batch classifier loss: 0.453087; batch adversarial loss: 0.534282\n",
      "epoch 65; iter: 0; batch classifier loss: 0.473832; batch adversarial loss: 0.482508\n",
      "epoch 66; iter: 0; batch classifier loss: 0.364125; batch adversarial loss: 0.624905\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406193; batch adversarial loss: 0.466058\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401448; batch adversarial loss: 0.526796\n",
      "epoch 69; iter: 0; batch classifier loss: 0.463486; batch adversarial loss: 0.536069\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411217; batch adversarial loss: 0.562102\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378576; batch adversarial loss: 0.589188\n",
      "epoch 72; iter: 0; batch classifier loss: 0.470943; batch adversarial loss: 0.622764\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433372; batch adversarial loss: 0.535317\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386252; batch adversarial loss: 0.543114\n",
      "epoch 75; iter: 0; batch classifier loss: 0.473427; batch adversarial loss: 0.545331\n",
      "epoch 76; iter: 0; batch classifier loss: 0.452154; batch adversarial loss: 0.554270\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422143; batch adversarial loss: 0.527311\n",
      "epoch 78; iter: 0; batch classifier loss: 0.533215; batch adversarial loss: 0.489237\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437008; batch adversarial loss: 0.452828\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390050; batch adversarial loss: 0.517755\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424870; batch adversarial loss: 0.544780\n",
      "epoch 82; iter: 0; batch classifier loss: 0.364021; batch adversarial loss: 0.564528\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416772; batch adversarial loss: 0.599280\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395430; batch adversarial loss: 0.625861\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431734; batch adversarial loss: 0.618561\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371629; batch adversarial loss: 0.582066\n",
      "epoch 87; iter: 0; batch classifier loss: 0.332289; batch adversarial loss: 0.553382\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396204; batch adversarial loss: 0.656158\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429913; batch adversarial loss: 0.609548\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418483; batch adversarial loss: 0.581957\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398169; batch adversarial loss: 0.535005\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386693; batch adversarial loss: 0.508102\n",
      "epoch 93; iter: 0; batch classifier loss: 0.388228; batch adversarial loss: 0.516136\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404239; batch adversarial loss: 0.562656\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440922; batch adversarial loss: 0.544287\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401430; batch adversarial loss: 0.507683\n",
      "epoch 97; iter: 0; batch classifier loss: 0.464804; batch adversarial loss: 0.555283\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334852; batch adversarial loss: 0.608566\n",
      "epoch 99; iter: 0; batch classifier loss: 0.343252; batch adversarial loss: 0.535560\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388527; batch adversarial loss: 0.535660\n",
      "epoch 101; iter: 0; batch classifier loss: 0.419036; batch adversarial loss: 0.525944\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416221; batch adversarial loss: 0.535951\n",
      "epoch 103; iter: 0; batch classifier loss: 0.439372; batch adversarial loss: 0.425058\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393602; batch adversarial loss: 0.571926\n",
      "epoch 105; iter: 0; batch classifier loss: 0.459019; batch adversarial loss: 0.598979\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387864; batch adversarial loss: 0.543961\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367295; batch adversarial loss: 0.489278\n",
      "epoch 108; iter: 0; batch classifier loss: 0.452769; batch adversarial loss: 0.525551\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361085; batch adversarial loss: 0.526249\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346939; batch adversarial loss: 0.517523\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.516562\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356696; batch adversarial loss: 0.536148\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382097; batch adversarial loss: 0.617721\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426893; batch adversarial loss: 0.554366\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340778; batch adversarial loss: 0.599037\n",
      "epoch 116; iter: 0; batch classifier loss: 0.450931; batch adversarial loss: 0.590476\n",
      "epoch 117; iter: 0; batch classifier loss: 0.460733; batch adversarial loss: 0.526773\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351343; batch adversarial loss: 0.507782\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373662; batch adversarial loss: 0.608494\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422696; batch adversarial loss: 0.544503\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395587; batch adversarial loss: 0.526704\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388433; batch adversarial loss: 0.589835\n",
      "epoch 123; iter: 0; batch classifier loss: 0.319268; batch adversarial loss: 0.507612\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380481; batch adversarial loss: 0.544563\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369743; batch adversarial loss: 0.553533\n",
      "epoch 126; iter: 0; batch classifier loss: 0.407586; batch adversarial loss: 0.554326\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352678; batch adversarial loss: 0.673938\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390885; batch adversarial loss: 0.552711\n",
      "epoch 129; iter: 0; batch classifier loss: 0.509353; batch adversarial loss: 0.535585\n",
      "epoch 130; iter: 0; batch classifier loss: 0.423797; batch adversarial loss: 0.554307\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343727; batch adversarial loss: 0.535499\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339696; batch adversarial loss: 0.553610\n",
      "epoch 133; iter: 0; batch classifier loss: 0.315797; batch adversarial loss: 0.498729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383998; batch adversarial loss: 0.535561\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403650; batch adversarial loss: 0.599819\n",
      "epoch 136; iter: 0; batch classifier loss: 0.453284; batch adversarial loss: 0.562144\n",
      "epoch 137; iter: 0; batch classifier loss: 0.364494; batch adversarial loss: 0.525900\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375240; batch adversarial loss: 0.517784\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345276; batch adversarial loss: 0.608005\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402404; batch adversarial loss: 0.544356\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308820; batch adversarial loss: 0.571352\n",
      "epoch 142; iter: 0; batch classifier loss: 0.327752; batch adversarial loss: 0.563066\n",
      "epoch 143; iter: 0; batch classifier loss: 0.326977; batch adversarial loss: 0.553380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.368596; batch adversarial loss: 0.535019\n",
      "epoch 145; iter: 0; batch classifier loss: 0.423908; batch adversarial loss: 0.571461\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401247; batch adversarial loss: 0.526219\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382085; batch adversarial loss: 0.626636\n",
      "epoch 148; iter: 0; batch classifier loss: 0.383008; batch adversarial loss: 0.544523\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315064; batch adversarial loss: 0.507594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.305575; batch adversarial loss: 0.544333\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349940; batch adversarial loss: 0.561366\n",
      "epoch 152; iter: 0; batch classifier loss: 0.337802; batch adversarial loss: 0.480614\n",
      "epoch 153; iter: 0; batch classifier loss: 0.455720; batch adversarial loss: 0.509355\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320504; batch adversarial loss: 0.516860\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412630; batch adversarial loss: 0.489392\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362310; batch adversarial loss: 0.544427\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374263; batch adversarial loss: 0.526608\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380768; batch adversarial loss: 0.599320\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407123; batch adversarial loss: 0.508267\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362728; batch adversarial loss: 0.636459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361135; batch adversarial loss: 0.581433\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369991; batch adversarial loss: 0.581630\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366134; batch adversarial loss: 0.480039\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361802; batch adversarial loss: 0.553488\n",
      "epoch 165; iter: 0; batch classifier loss: 0.444329; batch adversarial loss: 0.506990\n",
      "epoch 166; iter: 0; batch classifier loss: 0.298101; batch adversarial loss: 0.517295\n",
      "epoch 167; iter: 0; batch classifier loss: 0.410397; batch adversarial loss: 0.462951\n",
      "epoch 168; iter: 0; batch classifier loss: 0.427819; batch adversarial loss: 0.489382\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382318; batch adversarial loss: 0.488992\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348474; batch adversarial loss: 0.563207\n",
      "epoch 171; iter: 0; batch classifier loss: 0.318435; batch adversarial loss: 0.508265\n",
      "epoch 172; iter: 0; batch classifier loss: 0.314709; batch adversarial loss: 0.608836\n",
      "epoch 173; iter: 0; batch classifier loss: 0.317032; batch adversarial loss: 0.600486\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385259; batch adversarial loss: 0.617204\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335287; batch adversarial loss: 0.543846\n",
      "epoch 176; iter: 0; batch classifier loss: 0.350874; batch adversarial loss: 0.573067\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363534; batch adversarial loss: 0.507234\n",
      "epoch 178; iter: 0; batch classifier loss: 0.386438; batch adversarial loss: 0.553260\n",
      "epoch 179; iter: 0; batch classifier loss: 0.408952; batch adversarial loss: 0.562888\n",
      "epoch 180; iter: 0; batch classifier loss: 0.409181; batch adversarial loss: 0.563487\n",
      "epoch 181; iter: 0; batch classifier loss: 0.415904; batch adversarial loss: 0.553131\n",
      "epoch 182; iter: 0; batch classifier loss: 0.426628; batch adversarial loss: 0.574008\n",
      "epoch 183; iter: 0; batch classifier loss: 0.405501; batch adversarial loss: 0.500614\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302048; batch adversarial loss: 0.562139\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392987; batch adversarial loss: 0.543791\n",
      "epoch 186; iter: 0; batch classifier loss: 0.277200; batch adversarial loss: 0.571865\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335461; batch adversarial loss: 0.534648\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326853; batch adversarial loss: 0.535472\n",
      "epoch 189; iter: 0; batch classifier loss: 0.403178; batch adversarial loss: 0.573500\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384177; batch adversarial loss: 0.544080\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397754; batch adversarial loss: 0.462524\n",
      "epoch 192; iter: 0; batch classifier loss: 0.370562; batch adversarial loss: 0.471126\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343640; batch adversarial loss: 0.608822\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376347; batch adversarial loss: 0.580399\n",
      "epoch 195; iter: 0; batch classifier loss: 0.289217; batch adversarial loss: 0.563461\n",
      "epoch 196; iter: 0; batch classifier loss: 0.296950; batch adversarial loss: 0.508289\n",
      "epoch 197; iter: 0; batch classifier loss: 0.423445; batch adversarial loss: 0.636063\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328754; batch adversarial loss: 0.505949\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330051; batch adversarial loss: 0.471982\n",
      "epoch 0; iter: 0; batch classifier loss: 0.840709; batch adversarial loss: 0.709833\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583857; batch adversarial loss: 0.654904\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581742; batch adversarial loss: 0.647215\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573804; batch adversarial loss: 0.607066\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577031; batch adversarial loss: 0.638568\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580805; batch adversarial loss: 0.635380\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534519; batch adversarial loss: 0.589257\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560554; batch adversarial loss: 0.625569\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551883; batch adversarial loss: 0.596452\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553155; batch adversarial loss: 0.607382\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518151; batch adversarial loss: 0.518603\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588327; batch adversarial loss: 0.570255\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483824; batch adversarial loss: 0.589734\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593947; batch adversarial loss: 0.576610\n",
      "epoch 14; iter: 0; batch classifier loss: 0.575416; batch adversarial loss: 0.543001\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558930; batch adversarial loss: 0.523422\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455517; batch adversarial loss: 0.610978\n",
      "epoch 17; iter: 0; batch classifier loss: 0.440733; batch adversarial loss: 0.600723\n",
      "epoch 18; iter: 0; batch classifier loss: 0.457218; batch adversarial loss: 0.595927\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499154; batch adversarial loss: 0.567407\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449215; batch adversarial loss: 0.523786\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498882; batch adversarial loss: 0.572239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513091; batch adversarial loss: 0.592061\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462402; batch adversarial loss: 0.561599\n",
      "epoch 24; iter: 0; batch classifier loss: 0.430452; batch adversarial loss: 0.551660\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489435; batch adversarial loss: 0.569327\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450791; batch adversarial loss: 0.525665\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470736; batch adversarial loss: 0.515752\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474037; batch adversarial loss: 0.606427\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477804; batch adversarial loss: 0.551006\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489210; batch adversarial loss: 0.488361\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489537; batch adversarial loss: 0.528540\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484628; batch adversarial loss: 0.572386\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452121; batch adversarial loss: 0.492811\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415554; batch adversarial loss: 0.554297\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397493; batch adversarial loss: 0.536687\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410193; batch adversarial loss: 0.606694\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472925; batch adversarial loss: 0.545232\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475925; batch adversarial loss: 0.518532\n",
      "epoch 39; iter: 0; batch classifier loss: 0.511706; batch adversarial loss: 0.499793\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461782; batch adversarial loss: 0.553838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.502351; batch adversarial loss: 0.544661\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457092; batch adversarial loss: 0.481788\n",
      "epoch 43; iter: 0; batch classifier loss: 0.376896; batch adversarial loss: 0.553697\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424493; batch adversarial loss: 0.563256\n",
      "epoch 45; iter: 0; batch classifier loss: 0.375623; batch adversarial loss: 0.606793\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426537; batch adversarial loss: 0.589038\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383903; batch adversarial loss: 0.562698\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465608; batch adversarial loss: 0.543706\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416384; batch adversarial loss: 0.516612\n",
      "epoch 50; iter: 0; batch classifier loss: 0.362829; batch adversarial loss: 0.472608\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464915; batch adversarial loss: 0.588668\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466924; batch adversarial loss: 0.568831\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436331; batch adversarial loss: 0.561009\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417526; batch adversarial loss: 0.608954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432502; batch adversarial loss: 0.535222\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391856; batch adversarial loss: 0.553114\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402738; batch adversarial loss: 0.561176\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401008; batch adversarial loss: 0.482479\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435372; batch adversarial loss: 0.516667\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393361; batch adversarial loss: 0.526948\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407918; batch adversarial loss: 0.581173\n",
      "epoch 62; iter: 0; batch classifier loss: 0.384914; batch adversarial loss: 0.580991\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404169; batch adversarial loss: 0.597207\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437955; batch adversarial loss: 0.636141\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433575; batch adversarial loss: 0.507436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405735; batch adversarial loss: 0.565274\n",
      "epoch 67; iter: 0; batch classifier loss: 0.493039; batch adversarial loss: 0.579166\n",
      "epoch 68; iter: 0; batch classifier loss: 0.478716; batch adversarial loss: 0.554314\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386906; batch adversarial loss: 0.599953\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444458; batch adversarial loss: 0.561762\n",
      "epoch 71; iter: 0; batch classifier loss: 0.513652; batch adversarial loss: 0.525697\n",
      "epoch 72; iter: 0; batch classifier loss: 0.340328; batch adversarial loss: 0.551208\n",
      "epoch 73; iter: 0; batch classifier loss: 0.451103; batch adversarial loss: 0.489677\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415789; batch adversarial loss: 0.508246\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407521; batch adversarial loss: 0.552389\n",
      "epoch 76; iter: 0; batch classifier loss: 0.361058; batch adversarial loss: 0.570664\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396055; batch adversarial loss: 0.559833\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407900; batch adversarial loss: 0.457037\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406577; batch adversarial loss: 0.546066\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389903; batch adversarial loss: 0.462201\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443131; batch adversarial loss: 0.526097\n",
      "epoch 82; iter: 0; batch classifier loss: 0.475390; batch adversarial loss: 0.561780\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376331; batch adversarial loss: 0.583839\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384581; batch adversarial loss: 0.566084\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407243; batch adversarial loss: 0.536512\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400888; batch adversarial loss: 0.607802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.419628; batch adversarial loss: 0.563869\n",
      "epoch 88; iter: 0; batch classifier loss: 0.447365; batch adversarial loss: 0.507503\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370530; batch adversarial loss: 0.616905\n",
      "epoch 90; iter: 0; batch classifier loss: 0.487687; batch adversarial loss: 0.517909\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400017; batch adversarial loss: 0.537315\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399792; batch adversarial loss: 0.571051\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387471; batch adversarial loss: 0.536739\n",
      "epoch 94; iter: 0; batch classifier loss: 0.413928; batch adversarial loss: 0.635242\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371780; batch adversarial loss: 0.590878\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414504; batch adversarial loss: 0.517893\n",
      "epoch 97; iter: 0; batch classifier loss: 0.417469; batch adversarial loss: 0.505658\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400712; batch adversarial loss: 0.498774\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401983; batch adversarial loss: 0.598911\n",
      "epoch 100; iter: 0; batch classifier loss: 0.465185; batch adversarial loss: 0.536033\n",
      "epoch 101; iter: 0; batch classifier loss: 0.330002; batch adversarial loss: 0.595864\n",
      "epoch 102; iter: 0; batch classifier loss: 0.444156; batch adversarial loss: 0.555201\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377990; batch adversarial loss: 0.564451\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370793; batch adversarial loss: 0.551155\n",
      "epoch 105; iter: 0; batch classifier loss: 0.341669; batch adversarial loss: 0.571158\n",
      "epoch 106; iter: 0; batch classifier loss: 0.359465; batch adversarial loss: 0.553111\n",
      "epoch 107; iter: 0; batch classifier loss: 0.466899; batch adversarial loss: 0.518215\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384505; batch adversarial loss: 0.615378\n",
      "epoch 109; iter: 0; batch classifier loss: 0.329185; batch adversarial loss: 0.518003\n",
      "epoch 110; iter: 0; batch classifier loss: 0.345946; batch adversarial loss: 0.597243\n",
      "epoch 111; iter: 0; batch classifier loss: 0.338240; batch adversarial loss: 0.606945\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359089; batch adversarial loss: 0.581333\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345394; batch adversarial loss: 0.569664\n",
      "epoch 114; iter: 0; batch classifier loss: 0.339826; batch adversarial loss: 0.518202\n",
      "epoch 115; iter: 0; batch classifier loss: 0.444007; batch adversarial loss: 0.500662\n",
      "epoch 116; iter: 0; batch classifier loss: 0.465147; batch adversarial loss: 0.518355\n",
      "epoch 117; iter: 0; batch classifier loss: 0.483293; batch adversarial loss: 0.516523\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417610; batch adversarial loss: 0.571196\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339232; batch adversarial loss: 0.624012\n",
      "epoch 120; iter: 0; batch classifier loss: 0.305295; batch adversarial loss: 0.561611\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359742; batch adversarial loss: 0.488950\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385735; batch adversarial loss: 0.499231\n",
      "epoch 123; iter: 0; batch classifier loss: 0.391588; batch adversarial loss: 0.527240\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411860; batch adversarial loss: 0.506499\n",
      "epoch 125; iter: 0; batch classifier loss: 0.435144; batch adversarial loss: 0.555614\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419554; batch adversarial loss: 0.519423\n",
      "epoch 127; iter: 0; batch classifier loss: 0.440164; batch adversarial loss: 0.518570\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349893; batch adversarial loss: 0.628942\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370983; batch adversarial loss: 0.515198\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339138; batch adversarial loss: 0.527907\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438874; batch adversarial loss: 0.517094\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421041; batch adversarial loss: 0.480217\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412221; batch adversarial loss: 0.550455\n",
      "epoch 134; iter: 0; batch classifier loss: 0.422664; batch adversarial loss: 0.599555\n",
      "epoch 135; iter: 0; batch classifier loss: 0.322591; batch adversarial loss: 0.574660\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361634; batch adversarial loss: 0.507300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.429620; batch adversarial loss: 0.498259\n",
      "epoch 138; iter: 0; batch classifier loss: 0.520608; batch adversarial loss: 0.654259\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313488; batch adversarial loss: 0.572234\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344737; batch adversarial loss: 0.508143\n",
      "epoch 141; iter: 0; batch classifier loss: 0.324184; batch adversarial loss: 0.572275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.308805; batch adversarial loss: 0.572853\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354505; batch adversarial loss: 0.536988\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341620; batch adversarial loss: 0.482024\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331661; batch adversarial loss: 0.673095\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411662; batch adversarial loss: 0.536049\n",
      "epoch 147; iter: 0; batch classifier loss: 0.436581; batch adversarial loss: 0.562698\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381856; batch adversarial loss: 0.542383\n",
      "epoch 149; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.501461\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368070; batch adversarial loss: 0.568582\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378112; batch adversarial loss: 0.598478\n",
      "epoch 152; iter: 0; batch classifier loss: 0.464247; batch adversarial loss: 0.536156\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342083; batch adversarial loss: 0.563587\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317959; batch adversarial loss: 0.571591\n",
      "epoch 155; iter: 0; batch classifier loss: 0.380948; batch adversarial loss: 0.554263\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359536; batch adversarial loss: 0.537641\n",
      "epoch 157; iter: 0; batch classifier loss: 0.343799; batch adversarial loss: 0.536765\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367814; batch adversarial loss: 0.536719\n",
      "epoch 159; iter: 0; batch classifier loss: 0.335465; batch adversarial loss: 0.527627\n",
      "epoch 160; iter: 0; batch classifier loss: 0.421616; batch adversarial loss: 0.634353\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349693; batch adversarial loss: 0.526295\n",
      "epoch 162; iter: 0; batch classifier loss: 0.293627; batch adversarial loss: 0.659699\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336277; batch adversarial loss: 0.592068\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345006; batch adversarial loss: 0.581122\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389077; batch adversarial loss: 0.552230\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382311; batch adversarial loss: 0.582335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398153; batch adversarial loss: 0.568125\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331148; batch adversarial loss: 0.536673\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349835; batch adversarial loss: 0.617995\n",
      "epoch 170; iter: 0; batch classifier loss: 0.416524; batch adversarial loss: 0.462715\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321356; batch adversarial loss: 0.578453\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346980; batch adversarial loss: 0.589805\n",
      "epoch 173; iter: 0; batch classifier loss: 0.411057; batch adversarial loss: 0.553466\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374679; batch adversarial loss: 0.549685\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337222; batch adversarial loss: 0.553934\n",
      "epoch 176; iter: 0; batch classifier loss: 0.399883; batch adversarial loss: 0.525351\n",
      "epoch 177; iter: 0; batch classifier loss: 0.407664; batch adversarial loss: 0.481545\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340609; batch adversarial loss: 0.532086\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341229; batch adversarial loss: 0.454427\n",
      "epoch 180; iter: 0; batch classifier loss: 0.450928; batch adversarial loss: 0.524231\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357986; batch adversarial loss: 0.526858\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365476; batch adversarial loss: 0.598595\n",
      "epoch 183; iter: 0; batch classifier loss: 0.359147; batch adversarial loss: 0.488418\n",
      "epoch 184; iter: 0; batch classifier loss: 0.459265; batch adversarial loss: 0.572145\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372392; batch adversarial loss: 0.541786\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363737; batch adversarial loss: 0.517305\n",
      "epoch 187; iter: 0; batch classifier loss: 0.407994; batch adversarial loss: 0.536332\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395732; batch adversarial loss: 0.545525\n",
      "epoch 189; iter: 0; batch classifier loss: 0.415864; batch adversarial loss: 0.582661\n",
      "epoch 190; iter: 0; batch classifier loss: 0.424774; batch adversarial loss: 0.561287\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340618; batch adversarial loss: 0.561632\n",
      "epoch 192; iter: 0; batch classifier loss: 0.442715; batch adversarial loss: 0.581207\n",
      "epoch 193; iter: 0; batch classifier loss: 0.404488; batch adversarial loss: 0.535295\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354744; batch adversarial loss: 0.533848\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351072; batch adversarial loss: 0.544191\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335922; batch adversarial loss: 0.589212\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309463; batch adversarial loss: 0.560259\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342770; batch adversarial loss: 0.563105\n",
      "epoch 199; iter: 0; batch classifier loss: 0.419615; batch adversarial loss: 0.472880\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642809; batch adversarial loss: 0.664864\n",
      "epoch 1; iter: 0; batch classifier loss: 0.612727; batch adversarial loss: 0.672465\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616348; batch adversarial loss: 0.653343\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607769; batch adversarial loss: 0.639157\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548196; batch adversarial loss: 0.570388\n",
      "epoch 5; iter: 0; batch classifier loss: 0.529996; batch adversarial loss: 0.594345\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536118; batch adversarial loss: 0.561195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571119; batch adversarial loss: 0.634077\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539855; batch adversarial loss: 0.633632\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569843; batch adversarial loss: 0.662598\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576560; batch adversarial loss: 0.610049\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607160; batch adversarial loss: 0.556875\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577728; batch adversarial loss: 0.563889\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546563; batch adversarial loss: 0.589046\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502124; batch adversarial loss: 0.577093\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549254; batch adversarial loss: 0.636080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552946; batch adversarial loss: 0.564831\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485954; batch adversarial loss: 0.572138\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536203; batch adversarial loss: 0.627811\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526420; batch adversarial loss: 0.578191\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453153; batch adversarial loss: 0.525019\n",
      "epoch 21; iter: 0; batch classifier loss: 0.466526; batch adversarial loss: 0.559793\n",
      "epoch 22; iter: 0; batch classifier loss: 0.538682; batch adversarial loss: 0.591915\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520498; batch adversarial loss: 0.625654\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500193; batch adversarial loss: 0.546411\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508026; batch adversarial loss: 0.523820\n",
      "epoch 26; iter: 0; batch classifier loss: 0.544382; batch adversarial loss: 0.476082\n",
      "epoch 27; iter: 0; batch classifier loss: 0.565244; batch adversarial loss: 0.611050\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514904; batch adversarial loss: 0.539628\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473263; batch adversarial loss: 0.561813\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480267; batch adversarial loss: 0.515462\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474477; batch adversarial loss: 0.531270\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454341; batch adversarial loss: 0.519439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.429965; batch adversarial loss: 0.565424\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414559; batch adversarial loss: 0.604581\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397013; batch adversarial loss: 0.529991\n",
      "epoch 36; iter: 0; batch classifier loss: 0.564302; batch adversarial loss: 0.535045\n",
      "epoch 37; iter: 0; batch classifier loss: 0.396742; batch adversarial loss: 0.562986\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408826; batch adversarial loss: 0.518210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464155; batch adversarial loss: 0.553839\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466292; batch adversarial loss: 0.527459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.399813; batch adversarial loss: 0.535174\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496652; batch adversarial loss: 0.491539\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431205; batch adversarial loss: 0.589537\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427294; batch adversarial loss: 0.544588\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438380; batch adversarial loss: 0.553164\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444263; batch adversarial loss: 0.606550\n",
      "epoch 47; iter: 0; batch classifier loss: 0.360235; batch adversarial loss: 0.562429\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372944; batch adversarial loss: 0.588587\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406197; batch adversarial loss: 0.483180\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428736; batch adversarial loss: 0.571584\n",
      "epoch 51; iter: 0; batch classifier loss: 0.473156; batch adversarial loss: 0.598557\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410315; batch adversarial loss: 0.508441\n",
      "epoch 53; iter: 0; batch classifier loss: 0.382454; batch adversarial loss: 0.534155\n",
      "epoch 54; iter: 0; batch classifier loss: 0.480825; batch adversarial loss: 0.482553\n",
      "epoch 55; iter: 0; batch classifier loss: 0.371755; batch adversarial loss: 0.516520\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450076; batch adversarial loss: 0.499945\n",
      "epoch 57; iter: 0; batch classifier loss: 0.353060; batch adversarial loss: 0.503787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430241; batch adversarial loss: 0.598056\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409337; batch adversarial loss: 0.607431\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427237; batch adversarial loss: 0.572528\n",
      "epoch 61; iter: 0; batch classifier loss: 0.506414; batch adversarial loss: 0.609593\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417246; batch adversarial loss: 0.674448\n",
      "epoch 63; iter: 0; batch classifier loss: 0.484639; batch adversarial loss: 0.526083\n",
      "epoch 64; iter: 0; batch classifier loss: 0.355612; batch adversarial loss: 0.553819\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387597; batch adversarial loss: 0.526137\n",
      "epoch 66; iter: 0; batch classifier loss: 0.497336; batch adversarial loss: 0.516984\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420436; batch adversarial loss: 0.517233\n",
      "epoch 68; iter: 0; batch classifier loss: 0.366005; batch adversarial loss: 0.608750\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422491; batch adversarial loss: 0.599515\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392100; batch adversarial loss: 0.544598\n",
      "epoch 71; iter: 0; batch classifier loss: 0.351015; batch adversarial loss: 0.534558\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390528; batch adversarial loss: 0.526084\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446859; batch adversarial loss: 0.582587\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456246; batch adversarial loss: 0.499871\n",
      "epoch 75; iter: 0; batch classifier loss: 0.454888; batch adversarial loss: 0.570895\n",
      "epoch 76; iter: 0; batch classifier loss: 0.458057; batch adversarial loss: 0.526586\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386795; batch adversarial loss: 0.562414\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412754; batch adversarial loss: 0.518320\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382551; batch adversarial loss: 0.632832\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438962; batch adversarial loss: 0.634469\n",
      "epoch 81; iter: 0; batch classifier loss: 0.335348; batch adversarial loss: 0.527286\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331128; batch adversarial loss: 0.490874\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371803; batch adversarial loss: 0.563276\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402100; batch adversarial loss: 0.562315\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412914; batch adversarial loss: 0.518821\n",
      "epoch 86; iter: 0; batch classifier loss: 0.481599; batch adversarial loss: 0.526231\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373687; batch adversarial loss: 0.526463\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445408; batch adversarial loss: 0.653619\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400749; batch adversarial loss: 0.553446\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358070; batch adversarial loss: 0.543549\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393712; batch adversarial loss: 0.545060\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384436; batch adversarial loss: 0.534795\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418773; batch adversarial loss: 0.599512\n",
      "epoch 94; iter: 0; batch classifier loss: 0.481537; batch adversarial loss: 0.517994\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400024; batch adversarial loss: 0.671356\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390273; batch adversarial loss: 0.443746\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385968; batch adversarial loss: 0.471779\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446694; batch adversarial loss: 0.570772\n",
      "epoch 99; iter: 0; batch classifier loss: 0.485005; batch adversarial loss: 0.472600\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418497; batch adversarial loss: 0.616178\n",
      "epoch 101; iter: 0; batch classifier loss: 0.425210; batch adversarial loss: 0.581226\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384355; batch adversarial loss: 0.607348\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429270; batch adversarial loss: 0.535338\n",
      "epoch 104; iter: 0; batch classifier loss: 0.441884; batch adversarial loss: 0.573187\n",
      "epoch 105; iter: 0; batch classifier loss: 0.346022; batch adversarial loss: 0.543074\n",
      "epoch 106; iter: 0; batch classifier loss: 0.337404; batch adversarial loss: 0.534818\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367644; batch adversarial loss: 0.507350\n",
      "epoch 108; iter: 0; batch classifier loss: 0.339653; batch adversarial loss: 0.525803\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415294; batch adversarial loss: 0.580515\n",
      "epoch 110; iter: 0; batch classifier loss: 0.336407; batch adversarial loss: 0.580625\n",
      "epoch 111; iter: 0; batch classifier loss: 0.396079; batch adversarial loss: 0.517891\n",
      "epoch 112; iter: 0; batch classifier loss: 0.313081; batch adversarial loss: 0.517677\n",
      "epoch 113; iter: 0; batch classifier loss: 0.321966; batch adversarial loss: 0.518342\n",
      "epoch 114; iter: 0; batch classifier loss: 0.328067; batch adversarial loss: 0.687997\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388987; batch adversarial loss: 0.606077\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358811; batch adversarial loss: 0.643275\n",
      "epoch 117; iter: 0; batch classifier loss: 0.336745; batch adversarial loss: 0.599089\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374080; batch adversarial loss: 0.526322\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415316; batch adversarial loss: 0.562286\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383309; batch adversarial loss: 0.555128\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412567; batch adversarial loss: 0.634915\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417240; batch adversarial loss: 0.579485\n",
      "epoch 123; iter: 0; batch classifier loss: 0.374305; batch adversarial loss: 0.606534\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361909; batch adversarial loss: 0.597872\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340699; batch adversarial loss: 0.535086\n",
      "epoch 126; iter: 0; batch classifier loss: 0.469229; batch adversarial loss: 0.563561\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365570; batch adversarial loss: 0.517189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.413631; batch adversarial loss: 0.562089\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377544; batch adversarial loss: 0.590285\n",
      "epoch 130; iter: 0; batch classifier loss: 0.266983; batch adversarial loss: 0.481546\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364270; batch adversarial loss: 0.517977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.382428; batch adversarial loss: 0.535541\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367794; batch adversarial loss: 0.553922\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352588; batch adversarial loss: 0.543544\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424216; batch adversarial loss: 0.598182\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402580; batch adversarial loss: 0.607677\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424756; batch adversarial loss: 0.526087\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381201; batch adversarial loss: 0.463048\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415676; batch adversarial loss: 0.572173\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356025; batch adversarial loss: 0.490350\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375227; batch adversarial loss: 0.507996\n",
      "epoch 142; iter: 0; batch classifier loss: 0.401993; batch adversarial loss: 0.525993\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366269; batch adversarial loss: 0.563752\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388553; batch adversarial loss: 0.590659\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355847; batch adversarial loss: 0.553324\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325335; batch adversarial loss: 0.552780\n",
      "epoch 147; iter: 0; batch classifier loss: 0.370309; batch adversarial loss: 0.563061\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349326; batch adversarial loss: 0.561080\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349206; batch adversarial loss: 0.535188\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337716; batch adversarial loss: 0.582169\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405723; batch adversarial loss: 0.508051\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377253; batch adversarial loss: 0.572254\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380970; batch adversarial loss: 0.554594\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317779; batch adversarial loss: 0.499636\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359584; batch adversarial loss: 0.544876\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384806; batch adversarial loss: 0.564231\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375002; batch adversarial loss: 0.608550\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346308; batch adversarial loss: 0.561235\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384012; batch adversarial loss: 0.526089\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368185; batch adversarial loss: 0.572596\n",
      "epoch 161; iter: 0; batch classifier loss: 0.427587; batch adversarial loss: 0.479996\n",
      "epoch 162; iter: 0; batch classifier loss: 0.418710; batch adversarial loss: 0.507822\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325790; batch adversarial loss: 0.536528\n",
      "epoch 164; iter: 0; batch classifier loss: 0.430815; batch adversarial loss: 0.426942\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382315; batch adversarial loss: 0.572704\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358826; batch adversarial loss: 0.591395\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347412; batch adversarial loss: 0.535915\n",
      "epoch 168; iter: 0; batch classifier loss: 0.425438; batch adversarial loss: 0.536698\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403828; batch adversarial loss: 0.572822\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333041; batch adversarial loss: 0.500006\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369063; batch adversarial loss: 0.508136\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341549; batch adversarial loss: 0.607320\n",
      "epoch 173; iter: 0; batch classifier loss: 0.407390; batch adversarial loss: 0.581281\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341783; batch adversarial loss: 0.534289\n",
      "epoch 175; iter: 0; batch classifier loss: 0.286773; batch adversarial loss: 0.445161\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400566; batch adversarial loss: 0.537911\n",
      "epoch 177; iter: 0; batch classifier loss: 0.395919; batch adversarial loss: 0.553304\n",
      "epoch 178; iter: 0; batch classifier loss: 0.462303; batch adversarial loss: 0.471833\n",
      "epoch 179; iter: 0; batch classifier loss: 0.328646; batch adversarial loss: 0.507519\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337653; batch adversarial loss: 0.518130\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364837; batch adversarial loss: 0.543456\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365546; batch adversarial loss: 0.555372\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333911; batch adversarial loss: 0.617057\n",
      "epoch 184; iter: 0; batch classifier loss: 0.395996; batch adversarial loss: 0.544991\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316556; batch adversarial loss: 0.471547\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400320; batch adversarial loss: 0.580466\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322850; batch adversarial loss: 0.561663\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362293; batch adversarial loss: 0.490266\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383145; batch adversarial loss: 0.660026\n",
      "epoch 190; iter: 0; batch classifier loss: 0.258678; batch adversarial loss: 0.572332\n",
      "epoch 191; iter: 0; batch classifier loss: 0.452497; batch adversarial loss: 0.508855\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389659; batch adversarial loss: 0.545667\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356040; batch adversarial loss: 0.488966\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313110; batch adversarial loss: 0.563936\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350871; batch adversarial loss: 0.554626\n",
      "epoch 196; iter: 0; batch classifier loss: 0.324738; batch adversarial loss: 0.571885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383836; batch adversarial loss: 0.590939\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335777; batch adversarial loss: 0.578667\n",
      "epoch 199; iter: 0; batch classifier loss: 0.376715; batch adversarial loss: 0.544310\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683557; batch adversarial loss: 0.598809\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626263; batch adversarial loss: 0.617150\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617317; batch adversarial loss: 0.706567\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585465; batch adversarial loss: 0.657214\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496857; batch adversarial loss: 0.706673\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602455; batch adversarial loss: 0.699357\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565814; batch adversarial loss: 0.697412\n",
      "epoch 7; iter: 0; batch classifier loss: 0.620442; batch adversarial loss: 0.609738\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573887; batch adversarial loss: 0.590347\n",
      "epoch 9; iter: 0; batch classifier loss: 0.682650; batch adversarial loss: 0.633577\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553924; batch adversarial loss: 0.683369\n",
      "epoch 11; iter: 0; batch classifier loss: 0.626682; batch adversarial loss: 0.645293\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531966; batch adversarial loss: 0.596897\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532004; batch adversarial loss: 0.570879\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573367; batch adversarial loss: 0.594596\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521449; batch adversarial loss: 0.559523\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519346; batch adversarial loss: 0.514217\n",
      "epoch 17; iter: 0; batch classifier loss: 0.446107; batch adversarial loss: 0.540050\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484206; batch adversarial loss: 0.559476\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497473; batch adversarial loss: 0.512318\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440856; batch adversarial loss: 0.573178\n",
      "epoch 21; iter: 0; batch classifier loss: 0.441231; batch adversarial loss: 0.523872\n",
      "epoch 22; iter: 0; batch classifier loss: 0.421252; batch adversarial loss: 0.579217\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465892; batch adversarial loss: 0.529737\n",
      "epoch 24; iter: 0; batch classifier loss: 0.418049; batch adversarial loss: 0.521057\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493749; batch adversarial loss: 0.604391\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502142; batch adversarial loss: 0.579078\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537781; batch adversarial loss: 0.596757\n",
      "epoch 28; iter: 0; batch classifier loss: 0.444383; batch adversarial loss: 0.537112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.480911; batch adversarial loss: 0.535783\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495320; batch adversarial loss: 0.596983\n",
      "epoch 31; iter: 0; batch classifier loss: 0.394197; batch adversarial loss: 0.634943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.557399; batch adversarial loss: 0.591168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467571; batch adversarial loss: 0.589432\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446603; batch adversarial loss: 0.570862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433390; batch adversarial loss: 0.544816\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447375; batch adversarial loss: 0.543879\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436780; batch adversarial loss: 0.527621\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458279; batch adversarial loss: 0.589289\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474648; batch adversarial loss: 0.561707\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472364; batch adversarial loss: 0.516219\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407504; batch adversarial loss: 0.633247\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393317; batch adversarial loss: 0.581720\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412923; batch adversarial loss: 0.544628\n",
      "epoch 44; iter: 0; batch classifier loss: 0.471888; batch adversarial loss: 0.562729\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433967; batch adversarial loss: 0.652463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422833; batch adversarial loss: 0.526354\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461018; batch adversarial loss: 0.562831\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402392; batch adversarial loss: 0.536017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400344; batch adversarial loss: 0.578738\n",
      "epoch 50; iter: 0; batch classifier loss: 0.398229; batch adversarial loss: 0.481610\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406305; batch adversarial loss: 0.552702\n",
      "epoch 52; iter: 0; batch classifier loss: 0.369437; batch adversarial loss: 0.535712\n",
      "epoch 53; iter: 0; batch classifier loss: 0.387713; batch adversarial loss: 0.571948\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411458; batch adversarial loss: 0.535112\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408711; batch adversarial loss: 0.554349\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416531; batch adversarial loss: 0.598550\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459147; batch adversarial loss: 0.517024\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388197; batch adversarial loss: 0.533836\n",
      "epoch 59; iter: 0; batch classifier loss: 0.517323; batch adversarial loss: 0.535948\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439361; batch adversarial loss: 0.526283\n",
      "epoch 61; iter: 0; batch classifier loss: 0.448341; batch adversarial loss: 0.644601\n",
      "epoch 62; iter: 0; batch classifier loss: 0.343665; batch adversarial loss: 0.527036\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426024; batch adversarial loss: 0.446476\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395999; batch adversarial loss: 0.581850\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381518; batch adversarial loss: 0.625538\n",
      "epoch 66; iter: 0; batch classifier loss: 0.325278; batch adversarial loss: 0.510308\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408400; batch adversarial loss: 0.524612\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412892; batch adversarial loss: 0.508469\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425409; batch adversarial loss: 0.597412\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403114; batch adversarial loss: 0.553005\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370225; batch adversarial loss: 0.464230\n",
      "epoch 72; iter: 0; batch classifier loss: 0.346692; batch adversarial loss: 0.580782\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445456; batch adversarial loss: 0.588209\n",
      "epoch 74; iter: 0; batch classifier loss: 0.360529; batch adversarial loss: 0.483817\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353561; batch adversarial loss: 0.574454\n",
      "epoch 76; iter: 0; batch classifier loss: 0.353939; batch adversarial loss: 0.614629\n",
      "epoch 77; iter: 0; batch classifier loss: 0.367329; batch adversarial loss: 0.604672\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390293; batch adversarial loss: 0.596984\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421691; batch adversarial loss: 0.527798\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408839; batch adversarial loss: 0.481044\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408914; batch adversarial loss: 0.555119\n",
      "epoch 82; iter: 0; batch classifier loss: 0.302681; batch adversarial loss: 0.616505\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401544; batch adversarial loss: 0.479238\n",
      "epoch 84; iter: 0; batch classifier loss: 0.423907; batch adversarial loss: 0.534425\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397722; batch adversarial loss: 0.553420\n",
      "epoch 86; iter: 0; batch classifier loss: 0.457250; batch adversarial loss: 0.551965\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403051; batch adversarial loss: 0.524920\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384072; batch adversarial loss: 0.543002\n",
      "epoch 89; iter: 0; batch classifier loss: 0.423547; batch adversarial loss: 0.650881\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404538; batch adversarial loss: 0.580883\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372548; batch adversarial loss: 0.571936\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376350; batch adversarial loss: 0.536356\n",
      "epoch 93; iter: 0; batch classifier loss: 0.415533; batch adversarial loss: 0.571572\n",
      "epoch 94; iter: 0; batch classifier loss: 0.315362; batch adversarial loss: 0.560616\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417698; batch adversarial loss: 0.545224\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399337; batch adversarial loss: 0.543752\n",
      "epoch 97; iter: 0; batch classifier loss: 0.341868; batch adversarial loss: 0.560188\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378555; batch adversarial loss: 0.529853\n",
      "epoch 99; iter: 0; batch classifier loss: 0.309095; batch adversarial loss: 0.509044\n",
      "epoch 100; iter: 0; batch classifier loss: 0.296549; batch adversarial loss: 0.561550\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376897; batch adversarial loss: 0.573388\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435177; batch adversarial loss: 0.487241\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426053; batch adversarial loss: 0.535959\n",
      "epoch 104; iter: 0; batch classifier loss: 0.430097; batch adversarial loss: 0.481991\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384196; batch adversarial loss: 0.452693\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421685; batch adversarial loss: 0.543107\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421565; batch adversarial loss: 0.580076\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351142; batch adversarial loss: 0.601859\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364185; batch adversarial loss: 0.544219\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386837; batch adversarial loss: 0.570045\n",
      "epoch 111; iter: 0; batch classifier loss: 0.404541; batch adversarial loss: 0.543314\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381834; batch adversarial loss: 0.594028\n",
      "epoch 113; iter: 0; batch classifier loss: 0.433548; batch adversarial loss: 0.608183\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410440; batch adversarial loss: 0.472315\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326587; batch adversarial loss: 0.517052\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370836; batch adversarial loss: 0.479984\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326844; batch adversarial loss: 0.562364\n",
      "epoch 118; iter: 0; batch classifier loss: 0.434899; batch adversarial loss: 0.515241\n",
      "epoch 119; iter: 0; batch classifier loss: 0.435155; batch adversarial loss: 0.536297\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381804; batch adversarial loss: 0.574758\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400813; batch adversarial loss: 0.619617\n",
      "epoch 122; iter: 0; batch classifier loss: 0.417467; batch adversarial loss: 0.550481\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372468; batch adversarial loss: 0.546911\n",
      "epoch 124; iter: 0; batch classifier loss: 0.448554; batch adversarial loss: 0.536682\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346082; batch adversarial loss: 0.596758\n",
      "epoch 126; iter: 0; batch classifier loss: 0.397471; batch adversarial loss: 0.606757\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391763; batch adversarial loss: 0.552055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.442158; batch adversarial loss: 0.550521\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369694; batch adversarial loss: 0.585690\n",
      "epoch 130; iter: 0; batch classifier loss: 0.337424; batch adversarial loss: 0.579520\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351176; batch adversarial loss: 0.551400\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323096; batch adversarial loss: 0.599445\n",
      "epoch 133; iter: 0; batch classifier loss: 0.319327; batch adversarial loss: 0.599158\n",
      "epoch 134; iter: 0; batch classifier loss: 0.280568; batch adversarial loss: 0.615306\n",
      "epoch 135; iter: 0; batch classifier loss: 0.451015; batch adversarial loss: 0.546169\n",
      "epoch 136; iter: 0; batch classifier loss: 0.318549; batch adversarial loss: 0.622173\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388182; batch adversarial loss: 0.516629\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341013; batch adversarial loss: 0.517286\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377580; batch adversarial loss: 0.592559\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409663; batch adversarial loss: 0.553208\n",
      "epoch 141; iter: 0; batch classifier loss: 0.314712; batch adversarial loss: 0.546227\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376017; batch adversarial loss: 0.544673\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374034; batch adversarial loss: 0.446662\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390145; batch adversarial loss: 0.554447\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356731; batch adversarial loss: 0.620134\n",
      "epoch 146; iter: 0; batch classifier loss: 0.421363; batch adversarial loss: 0.498367\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302518; batch adversarial loss: 0.472984\n",
      "epoch 148; iter: 0; batch classifier loss: 0.422132; batch adversarial loss: 0.599788\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396752; batch adversarial loss: 0.573284\n",
      "epoch 150; iter: 0; batch classifier loss: 0.452216; batch adversarial loss: 0.541444\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345266; batch adversarial loss: 0.555772\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383437; batch adversarial loss: 0.500601\n",
      "epoch 153; iter: 0; batch classifier loss: 0.398333; batch adversarial loss: 0.525154\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356593; batch adversarial loss: 0.583552\n",
      "epoch 155; iter: 0; batch classifier loss: 0.422555; batch adversarial loss: 0.542066\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328874; batch adversarial loss: 0.586462\n",
      "epoch 157; iter: 0; batch classifier loss: 0.453496; batch adversarial loss: 0.498400\n",
      "epoch 158; iter: 0; batch classifier loss: 0.288647; batch adversarial loss: 0.508691\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393629; batch adversarial loss: 0.570598\n",
      "epoch 160; iter: 0; batch classifier loss: 0.288530; batch adversarial loss: 0.563520\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378956; batch adversarial loss: 0.543542\n",
      "epoch 162; iter: 0; batch classifier loss: 0.302155; batch adversarial loss: 0.523317\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362665; batch adversarial loss: 0.590379\n",
      "epoch 164; iter: 0; batch classifier loss: 0.278640; batch adversarial loss: 0.484809\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373943; batch adversarial loss: 0.577786\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376263; batch adversarial loss: 0.481335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.310264; batch adversarial loss: 0.567226\n",
      "epoch 168; iter: 0; batch classifier loss: 0.287366; batch adversarial loss: 0.508897\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324349; batch adversarial loss: 0.563802\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344666; batch adversarial loss: 0.582205\n",
      "epoch 171; iter: 0; batch classifier loss: 0.421443; batch adversarial loss: 0.563738\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343237; batch adversarial loss: 0.628333\n",
      "epoch 173; iter: 0; batch classifier loss: 0.395306; batch adversarial loss: 0.544456\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393930; batch adversarial loss: 0.553151\n",
      "epoch 175; iter: 0; batch classifier loss: 0.426091; batch adversarial loss: 0.596746\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343738; batch adversarial loss: 0.544367\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343912; batch adversarial loss: 0.619104\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339207; batch adversarial loss: 0.473140\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377681; batch adversarial loss: 0.568852\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343576; batch adversarial loss: 0.628316\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423955; batch adversarial loss: 0.546885\n",
      "epoch 182; iter: 0; batch classifier loss: 0.295047; batch adversarial loss: 0.542975\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321835; batch adversarial loss: 0.525621\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376097; batch adversarial loss: 0.562599\n",
      "epoch 185; iter: 0; batch classifier loss: 0.359028; batch adversarial loss: 0.658227\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373915; batch adversarial loss: 0.543872\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375341; batch adversarial loss: 0.563418\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352547; batch adversarial loss: 0.552662\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347441; batch adversarial loss: 0.612644\n",
      "epoch 190; iter: 0; batch classifier loss: 0.433156; batch adversarial loss: 0.558906\n",
      "epoch 191; iter: 0; batch classifier loss: 0.440848; batch adversarial loss: 0.617320\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315104; batch adversarial loss: 0.540872\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398361; batch adversarial loss: 0.539690\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330999; batch adversarial loss: 0.510643\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290930; batch adversarial loss: 0.475699\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369991; batch adversarial loss: 0.591489\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324746; batch adversarial loss: 0.543422\n",
      "epoch 198; iter: 0; batch classifier loss: 0.510785; batch adversarial loss: 0.508890\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365898; batch adversarial loss: 0.527085\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693109; batch adversarial loss: 0.755834\n",
      "epoch 1; iter: 0; batch classifier loss: 0.710696; batch adversarial loss: 0.787622\n",
      "epoch 2; iter: 0; batch classifier loss: 0.747283; batch adversarial loss: 0.754514\n",
      "epoch 3; iter: 0; batch classifier loss: 0.737281; batch adversarial loss: 0.730457\n",
      "epoch 4; iter: 0; batch classifier loss: 0.652968; batch adversarial loss: 0.681307\n",
      "epoch 5; iter: 0; batch classifier loss: 0.610749; batch adversarial loss: 0.618338\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520886; batch adversarial loss: 0.659259\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561304; batch adversarial loss: 0.617791\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517611; batch adversarial loss: 0.605816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503882; batch adversarial loss: 0.618333\n",
      "epoch 10; iter: 0; batch classifier loss: 0.596421; batch adversarial loss: 0.606104\n",
      "epoch 11; iter: 0; batch classifier loss: 0.482729; batch adversarial loss: 0.571517\n",
      "epoch 12; iter: 0; batch classifier loss: 0.403045; batch adversarial loss: 0.633915\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599537; batch adversarial loss: 0.633423\n",
      "epoch 14; iter: 0; batch classifier loss: 0.627351; batch adversarial loss: 0.616414\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546392; batch adversarial loss: 0.573319\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525063; batch adversarial loss: 0.572547\n",
      "epoch 17; iter: 0; batch classifier loss: 0.571067; batch adversarial loss: 0.580398\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547841; batch adversarial loss: 0.595240\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489301; batch adversarial loss: 0.575947\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499157; batch adversarial loss: 0.557775\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527922; batch adversarial loss: 0.580491\n",
      "epoch 22; iter: 0; batch classifier loss: 0.561959; batch adversarial loss: 0.582290\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517207; batch adversarial loss: 0.565048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.439439; batch adversarial loss: 0.542751\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495160; batch adversarial loss: 0.581123\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436982; batch adversarial loss: 0.521360\n",
      "epoch 27; iter: 0; batch classifier loss: 0.438682; batch adversarial loss: 0.576991\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492173; batch adversarial loss: 0.497606\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460186; batch adversarial loss: 0.589669\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425614; batch adversarial loss: 0.628412\n",
      "epoch 31; iter: 0; batch classifier loss: 0.537333; batch adversarial loss: 0.587478\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425310; batch adversarial loss: 0.566685\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459524; batch adversarial loss: 0.467824\n",
      "epoch 34; iter: 0; batch classifier loss: 0.493403; batch adversarial loss: 0.499494\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458135; batch adversarial loss: 0.539653\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512570; batch adversarial loss: 0.578386\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466530; batch adversarial loss: 0.500777\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400776; batch adversarial loss: 0.558884\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461379; batch adversarial loss: 0.597742\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396135; batch adversarial loss: 0.545024\n",
      "epoch 41; iter: 0; batch classifier loss: 0.475110; batch adversarial loss: 0.535356\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443354; batch adversarial loss: 0.545672\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458144; batch adversarial loss: 0.543945\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439814; batch adversarial loss: 0.504062\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448671; batch adversarial loss: 0.614519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381735; batch adversarial loss: 0.572611\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477678; batch adversarial loss: 0.529401\n",
      "epoch 48; iter: 0; batch classifier loss: 0.512960; batch adversarial loss: 0.657304\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458029; batch adversarial loss: 0.605356\n",
      "epoch 50; iter: 0; batch classifier loss: 0.467287; batch adversarial loss: 0.578645\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447802; batch adversarial loss: 0.570381\n",
      "epoch 52; iter: 0; batch classifier loss: 0.489693; batch adversarial loss: 0.537540\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425197; batch adversarial loss: 0.509712\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400213; batch adversarial loss: 0.527925\n",
      "epoch 55; iter: 0; batch classifier loss: 0.365104; batch adversarial loss: 0.518559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421246; batch adversarial loss: 0.571403\n",
      "epoch 57; iter: 0; batch classifier loss: 0.480145; batch adversarial loss: 0.615725\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393324; batch adversarial loss: 0.526517\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466923; batch adversarial loss: 0.500297\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413349; batch adversarial loss: 0.562646\n",
      "epoch 61; iter: 0; batch classifier loss: 0.356839; batch adversarial loss: 0.571598\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378862; batch adversarial loss: 0.606078\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387998; batch adversarial loss: 0.596787\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460703; batch adversarial loss: 0.535810\n",
      "epoch 65; iter: 0; batch classifier loss: 0.334913; batch adversarial loss: 0.544604\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426218; batch adversarial loss: 0.491828\n",
      "epoch 67; iter: 0; batch classifier loss: 0.459693; batch adversarial loss: 0.535671\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445537; batch adversarial loss: 0.508936\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377016; batch adversarial loss: 0.493549\n",
      "epoch 70; iter: 0; batch classifier loss: 0.365488; batch adversarial loss: 0.570785\n",
      "epoch 71; iter: 0; batch classifier loss: 0.499552; batch adversarial loss: 0.497641\n",
      "epoch 72; iter: 0; batch classifier loss: 0.346859; batch adversarial loss: 0.466225\n",
      "epoch 73; iter: 0; batch classifier loss: 0.482918; batch adversarial loss: 0.588467\n",
      "epoch 74; iter: 0; batch classifier loss: 0.400806; batch adversarial loss: 0.595944\n",
      "epoch 75; iter: 0; batch classifier loss: 0.340608; batch adversarial loss: 0.644728\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412773; batch adversarial loss: 0.545134\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389842; batch adversarial loss: 0.526396\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429899; batch adversarial loss: 0.649324\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375184; batch adversarial loss: 0.492326\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398593; batch adversarial loss: 0.583308\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427868; batch adversarial loss: 0.560663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395917; batch adversarial loss: 0.499580\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378751; batch adversarial loss: 0.580419\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405080; batch adversarial loss: 0.606529\n",
      "epoch 85; iter: 0; batch classifier loss: 0.337882; batch adversarial loss: 0.545388\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377606; batch adversarial loss: 0.526408\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421723; batch adversarial loss: 0.563325\n",
      "epoch 88; iter: 0; batch classifier loss: 0.514003; batch adversarial loss: 0.580278\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431040; batch adversarial loss: 0.588433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.471225; batch adversarial loss: 0.554095\n",
      "epoch 91; iter: 0; batch classifier loss: 0.463337; batch adversarial loss: 0.589748\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450064; batch adversarial loss: 0.623220\n",
      "epoch 93; iter: 0; batch classifier loss: 0.321957; batch adversarial loss: 0.609100\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354785; batch adversarial loss: 0.503838\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391778; batch adversarial loss: 0.650660\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382653; batch adversarial loss: 0.601691\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430165; batch adversarial loss: 0.538197\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362311; batch adversarial loss: 0.517773\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413207; batch adversarial loss: 0.533589\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396189; batch adversarial loss: 0.562109\n",
      "epoch 101; iter: 0; batch classifier loss: 0.348125; batch adversarial loss: 0.453090\n",
      "epoch 102; iter: 0; batch classifier loss: 0.456246; batch adversarial loss: 0.490178\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369723; batch adversarial loss: 0.554727\n",
      "epoch 104; iter: 0; batch classifier loss: 0.289960; batch adversarial loss: 0.529854\n",
      "epoch 105; iter: 0; batch classifier loss: 0.283124; batch adversarial loss: 0.472020\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408248; batch adversarial loss: 0.500046\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358218; batch adversarial loss: 0.642029\n",
      "epoch 108; iter: 0; batch classifier loss: 0.442691; batch adversarial loss: 0.517167\n",
      "epoch 109; iter: 0; batch classifier loss: 0.440247; batch adversarial loss: 0.561891\n",
      "epoch 110; iter: 0; batch classifier loss: 0.441890; batch adversarial loss: 0.606563\n",
      "epoch 111; iter: 0; batch classifier loss: 0.536481; batch adversarial loss: 0.593288\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415832; batch adversarial loss: 0.551340\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351232; batch adversarial loss: 0.527340\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345590; batch adversarial loss: 0.513403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328331; batch adversarial loss: 0.510885\n",
      "epoch 116; iter: 0; batch classifier loss: 0.340427; batch adversarial loss: 0.499668\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371092; batch adversarial loss: 0.562792\n",
      "epoch 118; iter: 0; batch classifier loss: 0.455429; batch adversarial loss: 0.577361\n",
      "epoch 119; iter: 0; batch classifier loss: 0.464673; batch adversarial loss: 0.560774\n",
      "epoch 120; iter: 0; batch classifier loss: 0.461610; batch adversarial loss: 0.520453\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398633; batch adversarial loss: 0.523034\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424123; batch adversarial loss: 0.502592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.386225; batch adversarial loss: 0.546116\n",
      "epoch 124; iter: 0; batch classifier loss: 0.319072; batch adversarial loss: 0.610587\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403461; batch adversarial loss: 0.524136\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399617; batch adversarial loss: 0.550697\n",
      "epoch 127; iter: 0; batch classifier loss: 0.478557; batch adversarial loss: 0.586507\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351485; batch adversarial loss: 0.492870\n",
      "epoch 129; iter: 0; batch classifier loss: 0.420389; batch adversarial loss: 0.688815\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398301; batch adversarial loss: 0.536837\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337082; batch adversarial loss: 0.530757\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334442; batch adversarial loss: 0.553380\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302663; batch adversarial loss: 0.573568\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402945; batch adversarial loss: 0.587155\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382850; batch adversarial loss: 0.581327\n",
      "epoch 136; iter: 0; batch classifier loss: 0.438760; batch adversarial loss: 0.514218\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362068; batch adversarial loss: 0.579075\n",
      "epoch 138; iter: 0; batch classifier loss: 0.429448; batch adversarial loss: 0.586336\n",
      "epoch 139; iter: 0; batch classifier loss: 0.449927; batch adversarial loss: 0.597395\n",
      "epoch 140; iter: 0; batch classifier loss: 0.462677; batch adversarial loss: 0.543932\n",
      "epoch 141; iter: 0; batch classifier loss: 0.321546; batch adversarial loss: 0.551966\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391427; batch adversarial loss: 0.560305\n",
      "epoch 143; iter: 0; batch classifier loss: 0.409940; batch adversarial loss: 0.625351\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374871; batch adversarial loss: 0.541973\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335239; batch adversarial loss: 0.525770\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416093; batch adversarial loss: 0.509094\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373985; batch adversarial loss: 0.475139\n",
      "epoch 148; iter: 0; batch classifier loss: 0.427444; batch adversarial loss: 0.487565\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405929; batch adversarial loss: 0.524959\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396125; batch adversarial loss: 0.520908\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372659; batch adversarial loss: 0.601177\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341221; batch adversarial loss: 0.527148\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384383; batch adversarial loss: 0.595582\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394141; batch adversarial loss: 0.564003\n",
      "epoch 155; iter: 0; batch classifier loss: 0.322326; batch adversarial loss: 0.604249\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372522; batch adversarial loss: 0.500320\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369908; batch adversarial loss: 0.546839\n",
      "epoch 158; iter: 0; batch classifier loss: 0.304544; batch adversarial loss: 0.536263\n",
      "epoch 159; iter: 0; batch classifier loss: 0.305106; batch adversarial loss: 0.618724\n",
      "epoch 160; iter: 0; batch classifier loss: 0.315857; batch adversarial loss: 0.592260\n",
      "epoch 161; iter: 0; batch classifier loss: 0.396991; batch adversarial loss: 0.564721\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352738; batch adversarial loss: 0.534314\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392534; batch adversarial loss: 0.557497\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342620; batch adversarial loss: 0.507867\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327766; batch adversarial loss: 0.605896\n",
      "epoch 166; iter: 0; batch classifier loss: 0.393468; batch adversarial loss: 0.587298\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401704; batch adversarial loss: 0.535741\n",
      "epoch 168; iter: 0; batch classifier loss: 0.381183; batch adversarial loss: 0.587264\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381685; batch adversarial loss: 0.562764\n",
      "epoch 170; iter: 0; batch classifier loss: 0.331661; batch adversarial loss: 0.622554\n",
      "epoch 171; iter: 0; batch classifier loss: 0.416465; batch adversarial loss: 0.543449\n",
      "epoch 172; iter: 0; batch classifier loss: 0.343069; batch adversarial loss: 0.571010\n",
      "epoch 173; iter: 0; batch classifier loss: 0.308450; batch adversarial loss: 0.564107\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384042; batch adversarial loss: 0.529667\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400474; batch adversarial loss: 0.549440\n",
      "epoch 176; iter: 0; batch classifier loss: 0.342273; batch adversarial loss: 0.507063\n",
      "epoch 177; iter: 0; batch classifier loss: 0.410377; batch adversarial loss: 0.533871\n",
      "epoch 178; iter: 0; batch classifier loss: 0.443652; batch adversarial loss: 0.534900\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399434; batch adversarial loss: 0.621984\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379867; batch adversarial loss: 0.608567\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337530; batch adversarial loss: 0.595169\n",
      "epoch 182; iter: 0; batch classifier loss: 0.323940; batch adversarial loss: 0.576475\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397044; batch adversarial loss: 0.550578\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375931; batch adversarial loss: 0.539049\n",
      "epoch 185; iter: 0; batch classifier loss: 0.416808; batch adversarial loss: 0.578889\n",
      "epoch 186; iter: 0; batch classifier loss: 0.431560; batch adversarial loss: 0.447072\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358596; batch adversarial loss: 0.555290\n",
      "epoch 188; iter: 0; batch classifier loss: 0.415454; batch adversarial loss: 0.563557\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354800; batch adversarial loss: 0.535092\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351154; batch adversarial loss: 0.584242\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347971; batch adversarial loss: 0.565025\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345898; batch adversarial loss: 0.598906\n",
      "epoch 193; iter: 0; batch classifier loss: 0.371613; batch adversarial loss: 0.507820\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348111; batch adversarial loss: 0.527915\n",
      "epoch 195; iter: 0; batch classifier loss: 0.401151; batch adversarial loss: 0.552198\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378325; batch adversarial loss: 0.599051\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361383; batch adversarial loss: 0.519326\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387542; batch adversarial loss: 0.587169\n",
      "epoch 199; iter: 0; batch classifier loss: 0.442993; batch adversarial loss: 0.574227\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729575; batch adversarial loss: 0.752620\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642400; batch adversarial loss: 0.713963\n",
      "epoch 2; iter: 0; batch classifier loss: 0.500914; batch adversarial loss: 0.676287\n",
      "epoch 3; iter: 0; batch classifier loss: 0.514464; batch adversarial loss: 0.648732\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531479; batch adversarial loss: 0.651431\n",
      "epoch 5; iter: 0; batch classifier loss: 0.493421; batch adversarial loss: 0.635302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565252; batch adversarial loss: 0.588410\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499157; batch adversarial loss: 0.589418\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552013; batch adversarial loss: 0.587784\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577868; batch adversarial loss: 0.521657\n",
      "epoch 10; iter: 0; batch classifier loss: 0.457712; batch adversarial loss: 0.550299\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517728; batch adversarial loss: 0.630930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.592414; batch adversarial loss: 0.597957\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540828; batch adversarial loss: 0.557987\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481526; batch adversarial loss: 0.589681\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535370; batch adversarial loss: 0.620487\n",
      "epoch 16; iter: 0; batch classifier loss: 0.474769; batch adversarial loss: 0.565171\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513820; batch adversarial loss: 0.560076\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556875; batch adversarial loss: 0.583379\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518630; batch adversarial loss: 0.574536\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456719; batch adversarial loss: 0.556547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.512453; batch adversarial loss: 0.544083\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515674; batch adversarial loss: 0.560328\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539292; batch adversarial loss: 0.558889\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470548; batch adversarial loss: 0.531826\n",
      "epoch 25; iter: 0; batch classifier loss: 0.422590; batch adversarial loss: 0.604380\n",
      "epoch 26; iter: 0; batch classifier loss: 0.373344; batch adversarial loss: 0.616279\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461506; batch adversarial loss: 0.566190\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481858; batch adversarial loss: 0.586203\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490220; batch adversarial loss: 0.529863\n",
      "epoch 30; iter: 0; batch classifier loss: 0.405058; batch adversarial loss: 0.603440\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446818; batch adversarial loss: 0.619601\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450138; batch adversarial loss: 0.564623\n",
      "epoch 33; iter: 0; batch classifier loss: 0.528936; batch adversarial loss: 0.547242\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459964; batch adversarial loss: 0.543425\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403133; batch adversarial loss: 0.570949\n",
      "epoch 36; iter: 0; batch classifier loss: 0.392915; batch adversarial loss: 0.546848\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400379; batch adversarial loss: 0.506075\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412603; batch adversarial loss: 0.538158\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442995; batch adversarial loss: 0.562686\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436677; batch adversarial loss: 0.533819\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421766; batch adversarial loss: 0.580883\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490262; batch adversarial loss: 0.481116\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480623; batch adversarial loss: 0.579690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444709; batch adversarial loss: 0.551226\n",
      "epoch 45; iter: 0; batch classifier loss: 0.396458; batch adversarial loss: 0.543054\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440447; batch adversarial loss: 0.610734\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386194; batch adversarial loss: 0.537140\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444258; batch adversarial loss: 0.528766\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412783; batch adversarial loss: 0.571235\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390821; batch adversarial loss: 0.659783\n",
      "epoch 51; iter: 0; batch classifier loss: 0.403998; batch adversarial loss: 0.553957\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428241; batch adversarial loss: 0.606353\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431920; batch adversarial loss: 0.589827\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455288; batch adversarial loss: 0.571009\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389395; batch adversarial loss: 0.550851\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424783; batch adversarial loss: 0.617242\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463278; batch adversarial loss: 0.527609\n",
      "epoch 58; iter: 0; batch classifier loss: 0.376831; batch adversarial loss: 0.537871\n",
      "epoch 59; iter: 0; batch classifier loss: 0.451640; batch adversarial loss: 0.595438\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456519; batch adversarial loss: 0.471085\n",
      "epoch 61; iter: 0; batch classifier loss: 0.528037; batch adversarial loss: 0.553145\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409384; batch adversarial loss: 0.562642\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444319; batch adversarial loss: 0.600727\n",
      "epoch 64; iter: 0; batch classifier loss: 0.342044; batch adversarial loss: 0.577388\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390642; batch adversarial loss: 0.544176\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395759; batch adversarial loss: 0.570896\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414631; batch adversarial loss: 0.525127\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392777; batch adversarial loss: 0.503760\n",
      "epoch 69; iter: 0; batch classifier loss: 0.464351; batch adversarial loss: 0.538348\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380340; batch adversarial loss: 0.499455\n",
      "epoch 71; iter: 0; batch classifier loss: 0.379688; batch adversarial loss: 0.593647\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434235; batch adversarial loss: 0.552245\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445812; batch adversarial loss: 0.664864\n",
      "epoch 74; iter: 0; batch classifier loss: 0.450819; batch adversarial loss: 0.583073\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452640; batch adversarial loss: 0.472261\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384163; batch adversarial loss: 0.586191\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345374; batch adversarial loss: 0.535755\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341531; batch adversarial loss: 0.570067\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380993; batch adversarial loss: 0.501391\n",
      "epoch 80; iter: 0; batch classifier loss: 0.487149; batch adversarial loss: 0.534847\n",
      "epoch 81; iter: 0; batch classifier loss: 0.362807; batch adversarial loss: 0.591931\n",
      "epoch 82; iter: 0; batch classifier loss: 0.329431; batch adversarial loss: 0.508767\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421446; batch adversarial loss: 0.536859\n",
      "epoch 84; iter: 0; batch classifier loss: 0.326557; batch adversarial loss: 0.588902\n",
      "epoch 85; iter: 0; batch classifier loss: 0.371436; batch adversarial loss: 0.552919\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365665; batch adversarial loss: 0.537337\n",
      "epoch 87; iter: 0; batch classifier loss: 0.323967; batch adversarial loss: 0.562761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370162; batch adversarial loss: 0.436731\n",
      "epoch 89; iter: 0; batch classifier loss: 0.372135; batch adversarial loss: 0.545384\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463973; batch adversarial loss: 0.572972\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397116; batch adversarial loss: 0.643858\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412975; batch adversarial loss: 0.563030\n",
      "epoch 93; iter: 0; batch classifier loss: 0.443473; batch adversarial loss: 0.527227\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406397; batch adversarial loss: 0.543611\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425472; batch adversarial loss: 0.543947\n",
      "epoch 96; iter: 0; batch classifier loss: 0.327491; batch adversarial loss: 0.481272\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400910; batch adversarial loss: 0.510514\n",
      "epoch 98; iter: 0; batch classifier loss: 0.374865; batch adversarial loss: 0.507357\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433516; batch adversarial loss: 0.607033\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392220; batch adversarial loss: 0.490674\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363518; batch adversarial loss: 0.536260\n",
      "epoch 102; iter: 0; batch classifier loss: 0.338974; batch adversarial loss: 0.570738\n",
      "epoch 103; iter: 0; batch classifier loss: 0.326498; batch adversarial loss: 0.561756\n",
      "epoch 104; iter: 0; batch classifier loss: 0.353348; batch adversarial loss: 0.527376\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415912; batch adversarial loss: 0.606190\n",
      "epoch 106; iter: 0; batch classifier loss: 0.361638; batch adversarial loss: 0.627376\n",
      "epoch 107; iter: 0; batch classifier loss: 0.466875; batch adversarial loss: 0.509555\n",
      "epoch 108; iter: 0; batch classifier loss: 0.333885; batch adversarial loss: 0.545177\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376198; batch adversarial loss: 0.536284\n",
      "epoch 110; iter: 0; batch classifier loss: 0.318743; batch adversarial loss: 0.580470\n",
      "epoch 111; iter: 0; batch classifier loss: 0.470052; batch adversarial loss: 0.543731\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398712; batch adversarial loss: 0.554082\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419217; batch adversarial loss: 0.562154\n",
      "epoch 114; iter: 0; batch classifier loss: 0.419978; batch adversarial loss: 0.545033\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397360; batch adversarial loss: 0.589630\n",
      "epoch 116; iter: 0; batch classifier loss: 0.459821; batch adversarial loss: 0.616749\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390121; batch adversarial loss: 0.598538\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345248; batch adversarial loss: 0.661405\n",
      "epoch 119; iter: 0; batch classifier loss: 0.312866; batch adversarial loss: 0.526710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.359294; batch adversarial loss: 0.579997\n",
      "epoch 121; iter: 0; batch classifier loss: 0.313274; batch adversarial loss: 0.588834\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367718; batch adversarial loss: 0.535111\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415343; batch adversarial loss: 0.571225\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341758; batch adversarial loss: 0.507558\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375575; batch adversarial loss: 0.581323\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399907; batch adversarial loss: 0.526210\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360896; batch adversarial loss: 0.564073\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356706; batch adversarial loss: 0.517983\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348800; batch adversarial loss: 0.535253\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433406; batch adversarial loss: 0.498796\n",
      "epoch 131; iter: 0; batch classifier loss: 0.444831; batch adversarial loss: 0.580412\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377991; batch adversarial loss: 0.517011\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385062; batch adversarial loss: 0.608264\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329233; batch adversarial loss: 0.517953\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353867; batch adversarial loss: 0.644692\n",
      "epoch 136; iter: 0; batch classifier loss: 0.310214; batch adversarial loss: 0.508582\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399485; batch adversarial loss: 0.535716\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368277; batch adversarial loss: 0.535514\n",
      "epoch 139; iter: 0; batch classifier loss: 0.437961; batch adversarial loss: 0.634381\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344637; batch adversarial loss: 0.562845\n",
      "epoch 141; iter: 0; batch classifier loss: 0.417034; batch adversarial loss: 0.507896\n",
      "epoch 142; iter: 0; batch classifier loss: 0.474927; batch adversarial loss: 0.598905\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369208; batch adversarial loss: 0.580949\n",
      "epoch 144; iter: 0; batch classifier loss: 0.271674; batch adversarial loss: 0.553397\n",
      "epoch 145; iter: 0; batch classifier loss: 0.343936; batch adversarial loss: 0.535984\n",
      "epoch 146; iter: 0; batch classifier loss: 0.408824; batch adversarial loss: 0.581953\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319995; batch adversarial loss: 0.609186\n",
      "epoch 148; iter: 0; batch classifier loss: 0.393292; batch adversarial loss: 0.618391\n",
      "epoch 149; iter: 0; batch classifier loss: 0.306099; batch adversarial loss: 0.517539\n",
      "epoch 150; iter: 0; batch classifier loss: 0.402684; batch adversarial loss: 0.460223\n",
      "epoch 151; iter: 0; batch classifier loss: 0.346127; batch adversarial loss: 0.600004\n",
      "epoch 152; iter: 0; batch classifier loss: 0.345133; batch adversarial loss: 0.607735\n",
      "epoch 153; iter: 0; batch classifier loss: 0.423129; batch adversarial loss: 0.445413\n",
      "epoch 154; iter: 0; batch classifier loss: 0.328180; batch adversarial loss: 0.527225\n",
      "epoch 155; iter: 0; batch classifier loss: 0.264440; batch adversarial loss: 0.570661\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402038; batch adversarial loss: 0.525216\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340261; batch adversarial loss: 0.551507\n",
      "epoch 158; iter: 0; batch classifier loss: 0.464668; batch adversarial loss: 0.614128\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346171; batch adversarial loss: 0.563534\n",
      "epoch 160; iter: 0; batch classifier loss: 0.338154; batch adversarial loss: 0.590509\n",
      "epoch 161; iter: 0; batch classifier loss: 0.298619; batch adversarial loss: 0.565366\n",
      "epoch 162; iter: 0; batch classifier loss: 0.455579; batch adversarial loss: 0.514218\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402183; batch adversarial loss: 0.482605\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397195; batch adversarial loss: 0.498870\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385247; batch adversarial loss: 0.562964\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340315; batch adversarial loss: 0.472570\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324734; batch adversarial loss: 0.572158\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387026; batch adversarial loss: 0.561613\n",
      "epoch 169; iter: 0; batch classifier loss: 0.401927; batch adversarial loss: 0.643310\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325898; batch adversarial loss: 0.553569\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320425; batch adversarial loss: 0.598804\n",
      "epoch 172; iter: 0; batch classifier loss: 0.472055; batch adversarial loss: 0.540926\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363711; batch adversarial loss: 0.536156\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380353; batch adversarial loss: 0.589967\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378906; batch adversarial loss: 0.581898\n",
      "epoch 176; iter: 0; batch classifier loss: 0.294639; batch adversarial loss: 0.463629\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348487; batch adversarial loss: 0.471270\n",
      "epoch 178; iter: 0; batch classifier loss: 0.270258; batch adversarial loss: 0.617261\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367305; batch adversarial loss: 0.587809\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391699; batch adversarial loss: 0.535832\n",
      "epoch 181; iter: 0; batch classifier loss: 0.285305; batch adversarial loss: 0.545274\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324407; batch adversarial loss: 0.589357\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392362; batch adversarial loss: 0.553196\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377965; batch adversarial loss: 0.543649\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332275; batch adversarial loss: 0.598983\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374493; batch adversarial loss: 0.562330\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368323; batch adversarial loss: 0.616089\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361320; batch adversarial loss: 0.606983\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382269; batch adversarial loss: 0.580510\n",
      "epoch 190; iter: 0; batch classifier loss: 0.388050; batch adversarial loss: 0.544878\n",
      "epoch 191; iter: 0; batch classifier loss: 0.416801; batch adversarial loss: 0.508277\n",
      "epoch 192; iter: 0; batch classifier loss: 0.380930; batch adversarial loss: 0.490330\n",
      "epoch 193; iter: 0; batch classifier loss: 0.322656; batch adversarial loss: 0.561750\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321700; batch adversarial loss: 0.598010\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321047; batch adversarial loss: 0.571236\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326867; batch adversarial loss: 0.499244\n",
      "epoch 197; iter: 0; batch classifier loss: 0.382962; batch adversarial loss: 0.544215\n",
      "epoch 198; iter: 0; batch classifier loss: 0.456164; batch adversarial loss: 0.515643\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337379; batch adversarial loss: 0.553806\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708908; batch adversarial loss: 0.654835\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583986; batch adversarial loss: 0.678485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.521505; batch adversarial loss: 0.650374\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578000; batch adversarial loss: 0.629320\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498619; batch adversarial loss: 0.613093\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567134; batch adversarial loss: 0.604502\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583411; batch adversarial loss: 0.636081\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547674; batch adversarial loss: 0.566342\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507998; batch adversarial loss: 0.616665\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504440; batch adversarial loss: 0.605271\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540600; batch adversarial loss: 0.591762\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472574; batch adversarial loss: 0.591675\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487829; batch adversarial loss: 0.592945\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462201; batch adversarial loss: 0.624050\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514134; batch adversarial loss: 0.586434\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485757; batch adversarial loss: 0.604861\n",
      "epoch 16; iter: 0; batch classifier loss: 0.566517; batch adversarial loss: 0.569406\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470688; batch adversarial loss: 0.570114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.485709; batch adversarial loss: 0.631275\n",
      "epoch 19; iter: 0; batch classifier loss: 0.589504; batch adversarial loss: 0.568343\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465067; batch adversarial loss: 0.490647\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524874; batch adversarial loss: 0.537132\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506979; batch adversarial loss: 0.618889\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465091; batch adversarial loss: 0.568552\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453136; batch adversarial loss: 0.599472\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487766; batch adversarial loss: 0.509675\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406988; batch adversarial loss: 0.528675\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455374; batch adversarial loss: 0.566833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482341; batch adversarial loss: 0.580765\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445880; batch adversarial loss: 0.583358\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540265; batch adversarial loss: 0.550671\n",
      "epoch 31; iter: 0; batch classifier loss: 0.379920; batch adversarial loss: 0.583887\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442624; batch adversarial loss: 0.562917\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483413; batch adversarial loss: 0.534700\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494694; batch adversarial loss: 0.513800\n",
      "epoch 35; iter: 0; batch classifier loss: 0.417936; batch adversarial loss: 0.574191\n",
      "epoch 36; iter: 0; batch classifier loss: 0.396939; batch adversarial loss: 0.586789\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402211; batch adversarial loss: 0.508191\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458942; batch adversarial loss: 0.572004\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463186; batch adversarial loss: 0.560527\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455090; batch adversarial loss: 0.525621\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432839; batch adversarial loss: 0.503944\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365871; batch adversarial loss: 0.616280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446037; batch adversarial loss: 0.510474\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406599; batch adversarial loss: 0.553589\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478815; batch adversarial loss: 0.528693\n",
      "epoch 46; iter: 0; batch classifier loss: 0.399935; batch adversarial loss: 0.561883\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440502; batch adversarial loss: 0.546260\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408531; batch adversarial loss: 0.613838\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458657; batch adversarial loss: 0.493559\n",
      "epoch 50; iter: 0; batch classifier loss: 0.485485; batch adversarial loss: 0.536220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479025; batch adversarial loss: 0.571429\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449875; batch adversarial loss: 0.552133\n",
      "epoch 53; iter: 0; batch classifier loss: 0.382428; batch adversarial loss: 0.518277\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460015; batch adversarial loss: 0.591148\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441713; batch adversarial loss: 0.571378\n",
      "epoch 56; iter: 0; batch classifier loss: 0.460827; batch adversarial loss: 0.579275\n",
      "epoch 57; iter: 0; batch classifier loss: 0.381905; batch adversarial loss: 0.553544\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448227; batch adversarial loss: 0.598329\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422328; batch adversarial loss: 0.588349\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450842; batch adversarial loss: 0.484730\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451211; batch adversarial loss: 0.596055\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425321; batch adversarial loss: 0.519105\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413181; batch adversarial loss: 0.587813\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404448; batch adversarial loss: 0.526050\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379726; batch adversarial loss: 0.527530\n",
      "epoch 66; iter: 0; batch classifier loss: 0.449373; batch adversarial loss: 0.604040\n",
      "epoch 67; iter: 0; batch classifier loss: 0.368961; batch adversarial loss: 0.633969\n",
      "epoch 68; iter: 0; batch classifier loss: 0.365539; batch adversarial loss: 0.602637\n",
      "epoch 69; iter: 0; batch classifier loss: 0.493560; batch adversarial loss: 0.683402\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409619; batch adversarial loss: 0.551631\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438968; batch adversarial loss: 0.574564\n",
      "epoch 72; iter: 0; batch classifier loss: 0.445945; batch adversarial loss: 0.584692\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400214; batch adversarial loss: 0.586848\n",
      "epoch 74; iter: 0; batch classifier loss: 0.431083; batch adversarial loss: 0.549077\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423756; batch adversarial loss: 0.567909\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376773; batch adversarial loss: 0.599223\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380037; batch adversarial loss: 0.621387\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415516; batch adversarial loss: 0.555099\n",
      "epoch 79; iter: 0; batch classifier loss: 0.414380; batch adversarial loss: 0.545298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398301; batch adversarial loss: 0.494580\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388009; batch adversarial loss: 0.580097\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441116; batch adversarial loss: 0.475070\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448565; batch adversarial loss: 0.572643\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353758; batch adversarial loss: 0.698374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363503; batch adversarial loss: 0.621364\n",
      "epoch 86; iter: 0; batch classifier loss: 0.457177; batch adversarial loss: 0.570831\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380055; batch adversarial loss: 0.587355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378435; batch adversarial loss: 0.536035\n",
      "epoch 89; iter: 0; batch classifier loss: 0.318744; batch adversarial loss: 0.518733\n",
      "epoch 90; iter: 0; batch classifier loss: 0.416216; batch adversarial loss: 0.484671\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376353; batch adversarial loss: 0.579841\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405818; batch adversarial loss: 0.640470\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387652; batch adversarial loss: 0.570875\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446074; batch adversarial loss: 0.596781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.444345; batch adversarial loss: 0.562331\n",
      "epoch 96; iter: 0; batch classifier loss: 0.278353; batch adversarial loss: 0.518295\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390491; batch adversarial loss: 0.614699\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402331; batch adversarial loss: 0.579613\n",
      "epoch 99; iter: 0; batch classifier loss: 0.352018; batch adversarial loss: 0.561972\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398089; batch adversarial loss: 0.613502\n",
      "epoch 101; iter: 0; batch classifier loss: 0.380041; batch adversarial loss: 0.519071\n",
      "epoch 102; iter: 0; batch classifier loss: 0.480032; batch adversarial loss: 0.449241\n",
      "epoch 103; iter: 0; batch classifier loss: 0.357993; batch adversarial loss: 0.535974\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391508; batch adversarial loss: 0.509270\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331278; batch adversarial loss: 0.485202\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394819; batch adversarial loss: 0.545178\n",
      "epoch 107; iter: 0; batch classifier loss: 0.293836; batch adversarial loss: 0.614640\n",
      "epoch 108; iter: 0; batch classifier loss: 0.316285; batch adversarial loss: 0.554289\n",
      "epoch 109; iter: 0; batch classifier loss: 0.462953; batch adversarial loss: 0.597519\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414679; batch adversarial loss: 0.500577\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382816; batch adversarial loss: 0.509659\n",
      "epoch 112; iter: 0; batch classifier loss: 0.446926; batch adversarial loss: 0.474178\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390066; batch adversarial loss: 0.589210\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380054; batch adversarial loss: 0.493498\n",
      "epoch 115; iter: 0; batch classifier loss: 0.460483; batch adversarial loss: 0.491704\n",
      "epoch 116; iter: 0; batch classifier loss: 0.414827; batch adversarial loss: 0.466775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.371543; batch adversarial loss: 0.544589\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370919; batch adversarial loss: 0.544982\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399416; batch adversarial loss: 0.545848\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416055; batch adversarial loss: 0.502617\n",
      "epoch 121; iter: 0; batch classifier loss: 0.336114; batch adversarial loss: 0.544816\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373101; batch adversarial loss: 0.554058\n",
      "epoch 123; iter: 0; batch classifier loss: 0.420011; batch adversarial loss: 0.589542\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340019; batch adversarial loss: 0.553998\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399504; batch adversarial loss: 0.554018\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391748; batch adversarial loss: 0.597693\n",
      "epoch 127; iter: 0; batch classifier loss: 0.448477; batch adversarial loss: 0.536511\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385607; batch adversarial loss: 0.571101\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325049; batch adversarial loss: 0.535953\n",
      "epoch 130; iter: 0; batch classifier loss: 0.410632; batch adversarial loss: 0.571440\n",
      "epoch 131; iter: 0; batch classifier loss: 0.442677; batch adversarial loss: 0.543922\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335248; batch adversarial loss: 0.614431\n",
      "epoch 133; iter: 0; batch classifier loss: 0.333015; batch adversarial loss: 0.613660\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339662; batch adversarial loss: 0.553804\n",
      "epoch 135; iter: 0; batch classifier loss: 0.439362; batch adversarial loss: 0.536740\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421608; batch adversarial loss: 0.527680\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399910; batch adversarial loss: 0.580438\n",
      "epoch 138; iter: 0; batch classifier loss: 0.395952; batch adversarial loss: 0.563245\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342459; batch adversarial loss: 0.580067\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371725; batch adversarial loss: 0.571286\n",
      "epoch 141; iter: 0; batch classifier loss: 0.442362; batch adversarial loss: 0.588861\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380947; batch adversarial loss: 0.554451\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431540; batch adversarial loss: 0.544513\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338363; batch adversarial loss: 0.527260\n",
      "epoch 145; iter: 0; batch classifier loss: 0.396464; batch adversarial loss: 0.562526\n",
      "epoch 146; iter: 0; batch classifier loss: 0.393713; batch adversarial loss: 0.632690\n",
      "epoch 147; iter: 0; batch classifier loss: 0.409899; batch adversarial loss: 0.544610\n",
      "epoch 148; iter: 0; batch classifier loss: 0.451265; batch adversarial loss: 0.509835\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344333; batch adversarial loss: 0.544706\n",
      "epoch 150; iter: 0; batch classifier loss: 0.327951; batch adversarial loss: 0.597752\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378468; batch adversarial loss: 0.518412\n",
      "epoch 152; iter: 0; batch classifier loss: 0.401590; batch adversarial loss: 0.571331\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344588; batch adversarial loss: 0.561494\n",
      "epoch 154; iter: 0; batch classifier loss: 0.355739; batch adversarial loss: 0.535689\n",
      "epoch 155; iter: 0; batch classifier loss: 0.424948; batch adversarial loss: 0.481925\n",
      "epoch 156; iter: 0; batch classifier loss: 0.434490; batch adversarial loss: 0.572310\n",
      "epoch 157; iter: 0; batch classifier loss: 0.423890; batch adversarial loss: 0.543074\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323043; batch adversarial loss: 0.614767\n",
      "epoch 159; iter: 0; batch classifier loss: 0.475359; batch adversarial loss: 0.546093\n",
      "epoch 160; iter: 0; batch classifier loss: 0.426397; batch adversarial loss: 0.622427\n",
      "epoch 161; iter: 0; batch classifier loss: 0.405353; batch adversarial loss: 0.579578\n",
      "epoch 162; iter: 0; batch classifier loss: 0.411902; batch adversarial loss: 0.518392\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357058; batch adversarial loss: 0.516837\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354273; batch adversarial loss: 0.588473\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318769; batch adversarial loss: 0.589090\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377485; batch adversarial loss: 0.500455\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358164; batch adversarial loss: 0.571630\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375017; batch adversarial loss: 0.474679\n",
      "epoch 169; iter: 0; batch classifier loss: 0.398625; batch adversarial loss: 0.519016\n",
      "epoch 170; iter: 0; batch classifier loss: 0.414139; batch adversarial loss: 0.552290\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340534; batch adversarial loss: 0.588009\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384885; batch adversarial loss: 0.569596\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401683; batch adversarial loss: 0.587195\n",
      "epoch 174; iter: 0; batch classifier loss: 0.520233; batch adversarial loss: 0.617306\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340566; batch adversarial loss: 0.519332\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308206; batch adversarial loss: 0.553148\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433562; batch adversarial loss: 0.520229\n",
      "epoch 178; iter: 0; batch classifier loss: 0.400099; batch adversarial loss: 0.617601\n",
      "epoch 179; iter: 0; batch classifier loss: 0.435444; batch adversarial loss: 0.552081\n",
      "epoch 180; iter: 0; batch classifier loss: 0.422098; batch adversarial loss: 0.545002\n",
      "epoch 181; iter: 0; batch classifier loss: 0.316454; batch adversarial loss: 0.528780\n",
      "epoch 182; iter: 0; batch classifier loss: 0.449729; batch adversarial loss: 0.631502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398873; batch adversarial loss: 0.597431\n",
      "epoch 184; iter: 0; batch classifier loss: 0.340136; batch adversarial loss: 0.578449\n",
      "epoch 185; iter: 0; batch classifier loss: 0.447315; batch adversarial loss: 0.555725\n",
      "epoch 186; iter: 0; batch classifier loss: 0.408155; batch adversarial loss: 0.604802\n",
      "epoch 187; iter: 0; batch classifier loss: 0.443788; batch adversarial loss: 0.518699\n",
      "epoch 188; iter: 0; batch classifier loss: 0.390926; batch adversarial loss: 0.588455\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368469; batch adversarial loss: 0.528086\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376061; batch adversarial loss: 0.545665\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370852; batch adversarial loss: 0.614107\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368073; batch adversarial loss: 0.527760\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388890; batch adversarial loss: 0.544982\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384436; batch adversarial loss: 0.623364\n",
      "epoch 195; iter: 0; batch classifier loss: 0.427381; batch adversarial loss: 0.562282\n",
      "epoch 196; iter: 0; batch classifier loss: 0.417821; batch adversarial loss: 0.519070\n",
      "epoch 197; iter: 0; batch classifier loss: 0.414666; batch adversarial loss: 0.614482\n",
      "epoch 198; iter: 0; batch classifier loss: 0.429318; batch adversarial loss: 0.588481\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353719; batch adversarial loss: 0.518739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686647; batch adversarial loss: 0.603054\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552371; batch adversarial loss: 0.664141\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572102; batch adversarial loss: 0.633011\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541908; batch adversarial loss: 0.636154\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583656; batch adversarial loss: 0.663799\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590147; batch adversarial loss: 0.608069\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529809; batch adversarial loss: 0.663614\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527486; batch adversarial loss: 0.591573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565314; batch adversarial loss: 0.623091\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549963; batch adversarial loss: 0.593347\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511777; batch adversarial loss: 0.569362\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577277; batch adversarial loss: 0.560567\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506726; batch adversarial loss: 0.592840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560008; batch adversarial loss: 0.590110\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481066; batch adversarial loss: 0.595180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.510020; batch adversarial loss: 0.611849\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490430; batch adversarial loss: 0.589861\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541011; batch adversarial loss: 0.513932\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540771; batch adversarial loss: 0.583158\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504915; batch adversarial loss: 0.575978\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435273; batch adversarial loss: 0.507897\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509076; batch adversarial loss: 0.562101\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582307; batch adversarial loss: 0.528492\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444406; batch adversarial loss: 0.532548\n",
      "epoch 24; iter: 0; batch classifier loss: 0.414417; batch adversarial loss: 0.565455\n",
      "epoch 25; iter: 0; batch classifier loss: 0.551883; batch adversarial loss: 0.590288\n",
      "epoch 26; iter: 0; batch classifier loss: 0.571332; batch adversarial loss: 0.575258\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485580; batch adversarial loss: 0.589348\n",
      "epoch 28; iter: 0; batch classifier loss: 0.591740; batch adversarial loss: 0.588805\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456577; batch adversarial loss: 0.546319\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446428; batch adversarial loss: 0.594548\n",
      "epoch 31; iter: 0; batch classifier loss: 0.546492; batch adversarial loss: 0.607323\n",
      "epoch 32; iter: 0; batch classifier loss: 0.406365; batch adversarial loss: 0.474509\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467708; batch adversarial loss: 0.570325\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451249; batch adversarial loss: 0.569452\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465225; batch adversarial loss: 0.520869\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466420; batch adversarial loss: 0.564286\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407315; batch adversarial loss: 0.597553\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505828; batch adversarial loss: 0.551642\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432886; batch adversarial loss: 0.657122\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436622; batch adversarial loss: 0.554578\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455608; batch adversarial loss: 0.588702\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476266; batch adversarial loss: 0.534535\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449943; batch adversarial loss: 0.565008\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436902; batch adversarial loss: 0.534258\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443922; batch adversarial loss: 0.563678\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444227; batch adversarial loss: 0.507338\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429730; batch adversarial loss: 0.523551\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407611; batch adversarial loss: 0.650375\n",
      "epoch 49; iter: 0; batch classifier loss: 0.512285; batch adversarial loss: 0.564191\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393743; batch adversarial loss: 0.570632\n",
      "epoch 51; iter: 0; batch classifier loss: 0.370399; batch adversarial loss: 0.617025\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409383; batch adversarial loss: 0.580229\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412195; batch adversarial loss: 0.590172\n",
      "epoch 54; iter: 0; batch classifier loss: 0.494691; batch adversarial loss: 0.570453\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401561; batch adversarial loss: 0.590914\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392224; batch adversarial loss: 0.497466\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409158; batch adversarial loss: 0.570608\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388237; batch adversarial loss: 0.513164\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457885; batch adversarial loss: 0.601693\n",
      "epoch 60; iter: 0; batch classifier loss: 0.335776; batch adversarial loss: 0.543468\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446436; batch adversarial loss: 0.544584\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444141; batch adversarial loss: 0.524301\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422521; batch adversarial loss: 0.572160\n",
      "epoch 64; iter: 0; batch classifier loss: 0.510689; batch adversarial loss: 0.571852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453502; batch adversarial loss: 0.587689\n",
      "epoch 66; iter: 0; batch classifier loss: 0.332356; batch adversarial loss: 0.509057\n",
      "epoch 67; iter: 0; batch classifier loss: 0.498716; batch adversarial loss: 0.518758\n",
      "epoch 68; iter: 0; batch classifier loss: 0.352245; batch adversarial loss: 0.524753\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451043; batch adversarial loss: 0.598230\n",
      "epoch 70; iter: 0; batch classifier loss: 0.457984; batch adversarial loss: 0.653036\n",
      "epoch 71; iter: 0; batch classifier loss: 0.467233; batch adversarial loss: 0.533307\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419021; batch adversarial loss: 0.515584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.455891; batch adversarial loss: 0.570371\n",
      "epoch 74; iter: 0; batch classifier loss: 0.338350; batch adversarial loss: 0.520918\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438132; batch adversarial loss: 0.595977\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398330; batch adversarial loss: 0.533509\n",
      "epoch 77; iter: 0; batch classifier loss: 0.451972; batch adversarial loss: 0.599629\n",
      "epoch 78; iter: 0; batch classifier loss: 0.295157; batch adversarial loss: 0.581468\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402630; batch adversarial loss: 0.516880\n",
      "epoch 80; iter: 0; batch classifier loss: 0.443777; batch adversarial loss: 0.571487\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367435; batch adversarial loss: 0.572024\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385669; batch adversarial loss: 0.507820\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446759; batch adversarial loss: 0.527454\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362542; batch adversarial loss: 0.582586\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409962; batch adversarial loss: 0.634968\n",
      "epoch 86; iter: 0; batch classifier loss: 0.346752; batch adversarial loss: 0.581296\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405654; batch adversarial loss: 0.534065\n",
      "epoch 88; iter: 0; batch classifier loss: 0.439432; batch adversarial loss: 0.507832\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355562; batch adversarial loss: 0.500936\n",
      "epoch 90; iter: 0; batch classifier loss: 0.442193; batch adversarial loss: 0.560439\n",
      "epoch 91; iter: 0; batch classifier loss: 0.415130; batch adversarial loss: 0.524325\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418682; batch adversarial loss: 0.609605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.309976; batch adversarial loss: 0.590395\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396030; batch adversarial loss: 0.544592\n",
      "epoch 95; iter: 0; batch classifier loss: 0.354556; batch adversarial loss: 0.582096\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376920; batch adversarial loss: 0.589061\n",
      "epoch 97; iter: 0; batch classifier loss: 0.447934; batch adversarial loss: 0.527280\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378470; batch adversarial loss: 0.555429\n",
      "epoch 99; iter: 0; batch classifier loss: 0.421412; batch adversarial loss: 0.518223\n",
      "epoch 100; iter: 0; batch classifier loss: 0.399030; batch adversarial loss: 0.550952\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366786; batch adversarial loss: 0.565107\n",
      "epoch 102; iter: 0; batch classifier loss: 0.470713; batch adversarial loss: 0.554394\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349249; batch adversarial loss: 0.578622\n",
      "epoch 104; iter: 0; batch classifier loss: 0.436235; batch adversarial loss: 0.588702\n",
      "epoch 105; iter: 0; batch classifier loss: 0.356839; batch adversarial loss: 0.616696\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353908; batch adversarial loss: 0.627674\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412587; batch adversarial loss: 0.563151\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388722; batch adversarial loss: 0.534637\n",
      "epoch 109; iter: 0; batch classifier loss: 0.426696; batch adversarial loss: 0.589227\n",
      "epoch 110; iter: 0; batch classifier loss: 0.433761; batch adversarial loss: 0.544347\n",
      "epoch 111; iter: 0; batch classifier loss: 0.420954; batch adversarial loss: 0.660776\n",
      "epoch 112; iter: 0; batch classifier loss: 0.404849; batch adversarial loss: 0.542788\n",
      "epoch 113; iter: 0; batch classifier loss: 0.435130; batch adversarial loss: 0.572343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.406186; batch adversarial loss: 0.616414\n",
      "epoch 115; iter: 0; batch classifier loss: 0.330272; batch adversarial loss: 0.561267\n",
      "epoch 116; iter: 0; batch classifier loss: 0.439451; batch adversarial loss: 0.590404\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401077; batch adversarial loss: 0.481136\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374562; batch adversarial loss: 0.506707\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367427; batch adversarial loss: 0.507781\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401100; batch adversarial loss: 0.534803\n",
      "epoch 121; iter: 0; batch classifier loss: 0.484601; batch adversarial loss: 0.562544\n",
      "epoch 122; iter: 0; batch classifier loss: 0.375436; batch adversarial loss: 0.623254\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336468; batch adversarial loss: 0.543821\n",
      "epoch 124; iter: 0; batch classifier loss: 0.403017; batch adversarial loss: 0.496780\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368782; batch adversarial loss: 0.544088\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398044; batch adversarial loss: 0.524577\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348573; batch adversarial loss: 0.581962\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353142; batch adversarial loss: 0.544447\n",
      "epoch 129; iter: 0; batch classifier loss: 0.449597; batch adversarial loss: 0.555755\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363141; batch adversarial loss: 0.544231\n",
      "epoch 131; iter: 0; batch classifier loss: 0.415030; batch adversarial loss: 0.535944\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367752; batch adversarial loss: 0.590863\n",
      "epoch 133; iter: 0; batch classifier loss: 0.428489; batch adversarial loss: 0.510727\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376009; batch adversarial loss: 0.552023\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361778; batch adversarial loss: 0.561392\n",
      "epoch 136; iter: 0; batch classifier loss: 0.384398; batch adversarial loss: 0.535604\n",
      "epoch 137; iter: 0; batch classifier loss: 0.276737; batch adversarial loss: 0.563066\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340280; batch adversarial loss: 0.571865\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390276; batch adversarial loss: 0.615004\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328710; batch adversarial loss: 0.562649\n",
      "epoch 141; iter: 0; batch classifier loss: 0.413256; batch adversarial loss: 0.525542\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378935; batch adversarial loss: 0.599372\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394798; batch adversarial loss: 0.497610\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292849; batch adversarial loss: 0.581233\n",
      "epoch 145; iter: 0; batch classifier loss: 0.437418; batch adversarial loss: 0.552652\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332234; batch adversarial loss: 0.551233\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387944; batch adversarial loss: 0.518092\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323677; batch adversarial loss: 0.554580\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359823; batch adversarial loss: 0.482869\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364342; batch adversarial loss: 0.515490\n",
      "epoch 151; iter: 0; batch classifier loss: 0.394094; batch adversarial loss: 0.542569\n",
      "epoch 152; iter: 0; batch classifier loss: 0.399279; batch adversarial loss: 0.579394\n",
      "epoch 153; iter: 0; batch classifier loss: 0.488633; batch adversarial loss: 0.525554\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381807; batch adversarial loss: 0.543831\n",
      "epoch 155; iter: 0; batch classifier loss: 0.454828; batch adversarial loss: 0.580842\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402965; batch adversarial loss: 0.544908\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365464; batch adversarial loss: 0.537130\n",
      "epoch 158; iter: 0; batch classifier loss: 0.444681; batch adversarial loss: 0.571129\n",
      "epoch 159; iter: 0; batch classifier loss: 0.408190; batch adversarial loss: 0.545551\n",
      "epoch 160; iter: 0; batch classifier loss: 0.389982; batch adversarial loss: 0.563695\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343537; batch adversarial loss: 0.554167\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383153; batch adversarial loss: 0.508399\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361355; batch adversarial loss: 0.489746\n",
      "epoch 164; iter: 0; batch classifier loss: 0.315723; batch adversarial loss: 0.562235\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333661; batch adversarial loss: 0.454454\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388658; batch adversarial loss: 0.616585\n",
      "epoch 167; iter: 0; batch classifier loss: 0.330079; batch adversarial loss: 0.589967\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332788; batch adversarial loss: 0.499025\n",
      "epoch 169; iter: 0; batch classifier loss: 0.378018; batch adversarial loss: 0.570845\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403640; batch adversarial loss: 0.543027\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392412; batch adversarial loss: 0.608594\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377923; batch adversarial loss: 0.545268\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380523; batch adversarial loss: 0.552475\n",
      "epoch 174; iter: 0; batch classifier loss: 0.439730; batch adversarial loss: 0.517447\n",
      "epoch 175; iter: 0; batch classifier loss: 0.523108; batch adversarial loss: 0.544983\n",
      "epoch 176; iter: 0; batch classifier loss: 0.406228; batch adversarial loss: 0.534916\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381711; batch adversarial loss: 0.526113\n",
      "epoch 178; iter: 0; batch classifier loss: 0.313750; batch adversarial loss: 0.536293\n",
      "epoch 179; iter: 0; batch classifier loss: 0.376965; batch adversarial loss: 0.588095\n",
      "epoch 180; iter: 0; batch classifier loss: 0.456121; batch adversarial loss: 0.589663\n",
      "epoch 181; iter: 0; batch classifier loss: 0.433259; batch adversarial loss: 0.518508\n",
      "epoch 182; iter: 0; batch classifier loss: 0.424179; batch adversarial loss: 0.608267\n",
      "epoch 183; iter: 0; batch classifier loss: 0.496772; batch adversarial loss: 0.607552\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353471; batch adversarial loss: 0.615089\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360807; batch adversarial loss: 0.534562\n",
      "epoch 186; iter: 0; batch classifier loss: 0.459752; batch adversarial loss: 0.526401\n",
      "epoch 187; iter: 0; batch classifier loss: 0.294079; batch adversarial loss: 0.606090\n",
      "epoch 188; iter: 0; batch classifier loss: 0.410981; batch adversarial loss: 0.553198\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347256; batch adversarial loss: 0.533729\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367209; batch adversarial loss: 0.545285\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373470; batch adversarial loss: 0.544685\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345079; batch adversarial loss: 0.535578\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359473; batch adversarial loss: 0.507725\n",
      "epoch 194; iter: 0; batch classifier loss: 0.432328; batch adversarial loss: 0.526702\n",
      "epoch 195; iter: 0; batch classifier loss: 0.433252; batch adversarial loss: 0.454443\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403636; batch adversarial loss: 0.472058\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373137; batch adversarial loss: 0.572124\n",
      "epoch 198; iter: 0; batch classifier loss: 0.276675; batch adversarial loss: 0.553393\n",
      "epoch 199; iter: 0; batch classifier loss: 0.375044; batch adversarial loss: 0.508302\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736120; batch adversarial loss: 0.960953\n",
      "epoch 1; iter: 0; batch classifier loss: 0.778739; batch adversarial loss: 1.047492\n",
      "epoch 2; iter: 0; batch classifier loss: 1.023618; batch adversarial loss: 1.014431\n",
      "epoch 3; iter: 0; batch classifier loss: 1.005744; batch adversarial loss: 0.920241\n",
      "epoch 4; iter: 0; batch classifier loss: 1.081825; batch adversarial loss: 0.864090\n",
      "epoch 5; iter: 0; batch classifier loss: 1.101197; batch adversarial loss: 0.791133\n",
      "epoch 6; iter: 0; batch classifier loss: 1.005970; batch adversarial loss: 0.725838\n",
      "epoch 7; iter: 0; batch classifier loss: 0.846561; batch adversarial loss: 0.673816\n",
      "epoch 8; iter: 0; batch classifier loss: 0.675097; batch adversarial loss: 0.659394\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604179; batch adversarial loss: 0.615068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565385; batch adversarial loss: 0.571816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.500706; batch adversarial loss: 0.575330\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504684; batch adversarial loss: 0.586093\n",
      "epoch 13; iter: 0; batch classifier loss: 0.577141; batch adversarial loss: 0.562482\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516999; batch adversarial loss: 0.572139\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463210; batch adversarial loss: 0.531998\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531896; batch adversarial loss: 0.539617\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471656; batch adversarial loss: 0.568744\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491098; batch adversarial loss: 0.579585\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491603; batch adversarial loss: 0.564372\n",
      "epoch 20; iter: 0; batch classifier loss: 0.589797; batch adversarial loss: 0.543455\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531230; batch adversarial loss: 0.566553\n",
      "epoch 22; iter: 0; batch classifier loss: 0.539091; batch adversarial loss: 0.511429\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491623; batch adversarial loss: 0.599328\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469706; batch adversarial loss: 0.540099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513331; batch adversarial loss: 0.526010\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500418; batch adversarial loss: 0.509637\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433161; batch adversarial loss: 0.522017\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482258; batch adversarial loss: 0.475231\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487050; batch adversarial loss: 0.547543\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456575; batch adversarial loss: 0.463764\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425675; batch adversarial loss: 0.579634\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430926; batch adversarial loss: 0.550466\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440150; batch adversarial loss: 0.547951\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502047; batch adversarial loss: 0.621421\n",
      "epoch 35; iter: 0; batch classifier loss: 0.563351; batch adversarial loss: 0.505116\n",
      "epoch 36; iter: 0; batch classifier loss: 0.328368; batch adversarial loss: 0.563351\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466259; batch adversarial loss: 0.527159\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439398; batch adversarial loss: 0.589365\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485237; batch adversarial loss: 0.552260\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492084; batch adversarial loss: 0.442425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.535105; batch adversarial loss: 0.539548\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411283; batch adversarial loss: 0.503610\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399297; batch adversarial loss: 0.544245\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397753; batch adversarial loss: 0.459984\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384190; batch adversarial loss: 0.530004\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408823; batch adversarial loss: 0.555004\n",
      "epoch 47; iter: 0; batch classifier loss: 0.396451; batch adversarial loss: 0.569184\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423603; batch adversarial loss: 0.579920\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417212; batch adversarial loss: 0.615055\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441236; batch adversarial loss: 0.527790\n",
      "epoch 51; iter: 0; batch classifier loss: 0.542806; batch adversarial loss: 0.572522\n",
      "epoch 52; iter: 0; batch classifier loss: 0.345895; batch adversarial loss: 0.649920\n",
      "epoch 53; iter: 0; batch classifier loss: 0.467936; batch adversarial loss: 0.565211\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481721; batch adversarial loss: 0.535183\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439922; batch adversarial loss: 0.581231\n",
      "epoch 56; iter: 0; batch classifier loss: 0.363891; batch adversarial loss: 0.511765\n",
      "epoch 57; iter: 0; batch classifier loss: 0.486069; batch adversarial loss: 0.482726\n",
      "epoch 58; iter: 0; batch classifier loss: 0.352825; batch adversarial loss: 0.570428\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441524; batch adversarial loss: 0.508625\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442073; batch adversarial loss: 0.571166\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430287; batch adversarial loss: 0.633284\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394882; batch adversarial loss: 0.595892\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463635; batch adversarial loss: 0.563026\n",
      "epoch 64; iter: 0; batch classifier loss: 0.318859; batch adversarial loss: 0.519261\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426953; batch adversarial loss: 0.580366\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385713; batch adversarial loss: 0.627586\n",
      "epoch 67; iter: 0; batch classifier loss: 0.369508; batch adversarial loss: 0.501447\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443783; batch adversarial loss: 0.666305\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411968; batch adversarial loss: 0.553361\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397287; batch adversarial loss: 0.572423\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399931; batch adversarial loss: 0.533663\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413423; batch adversarial loss: 0.588396\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439401; batch adversarial loss: 0.553257\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374909; batch adversarial loss: 0.470373\n",
      "epoch 75; iter: 0; batch classifier loss: 0.392210; batch adversarial loss: 0.573786\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375767; batch adversarial loss: 0.588453\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383602; batch adversarial loss: 0.552851\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375905; batch adversarial loss: 0.534050\n",
      "epoch 79; iter: 0; batch classifier loss: 0.467003; batch adversarial loss: 0.591033\n",
      "epoch 80; iter: 0; batch classifier loss: 0.477928; batch adversarial loss: 0.616291\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422513; batch adversarial loss: 0.552380\n",
      "epoch 82; iter: 0; batch classifier loss: 0.470582; batch adversarial loss: 0.533861\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377837; batch adversarial loss: 0.567692\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377656; batch adversarial loss: 0.503727\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433304; batch adversarial loss: 0.537279\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353906; batch adversarial loss: 0.523478\n",
      "epoch 87; iter: 0; batch classifier loss: 0.476951; batch adversarial loss: 0.527214\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385907; batch adversarial loss: 0.590994\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405124; batch adversarial loss: 0.516121\n",
      "epoch 90; iter: 0; batch classifier loss: 0.321294; batch adversarial loss: 0.519102\n",
      "epoch 91; iter: 0; batch classifier loss: 0.464713; batch adversarial loss: 0.508445\n",
      "epoch 92; iter: 0; batch classifier loss: 0.336403; batch adversarial loss: 0.653704\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341088; batch adversarial loss: 0.626698\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446676; batch adversarial loss: 0.487200\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393471; batch adversarial loss: 0.543872\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425210; batch adversarial loss: 0.588278\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376943; batch adversarial loss: 0.485763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398522; batch adversarial loss: 0.588449\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410327; batch adversarial loss: 0.603406\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382418; batch adversarial loss: 0.518944\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411279; batch adversarial loss: 0.515663\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353573; batch adversarial loss: 0.609721\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349852; batch adversarial loss: 0.564724\n",
      "epoch 104; iter: 0; batch classifier loss: 0.295232; batch adversarial loss: 0.532827\n",
      "epoch 105; iter: 0; batch classifier loss: 0.421642; batch adversarial loss: 0.490033\n",
      "epoch 106; iter: 0; batch classifier loss: 0.453754; batch adversarial loss: 0.613992\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394024; batch adversarial loss: 0.497892\n",
      "epoch 108; iter: 0; batch classifier loss: 0.319208; batch adversarial loss: 0.532813\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355870; batch adversarial loss: 0.566168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.311431; batch adversarial loss: 0.517163\n",
      "epoch 111; iter: 0; batch classifier loss: 0.485140; batch adversarial loss: 0.465895\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363028; batch adversarial loss: 0.561504\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338383; batch adversarial loss: 0.500089\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329176; batch adversarial loss: 0.622748\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364521; batch adversarial loss: 0.580783\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323497; batch adversarial loss: 0.522129\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351146; batch adversarial loss: 0.580544\n",
      "epoch 118; iter: 0; batch classifier loss: 0.312372; batch adversarial loss: 0.558469\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352906; batch adversarial loss: 0.549755\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367850; batch adversarial loss: 0.606324\n",
      "epoch 121; iter: 0; batch classifier loss: 0.399344; batch adversarial loss: 0.511281\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406139; batch adversarial loss: 0.534904\n",
      "epoch 123; iter: 0; batch classifier loss: 0.299916; batch adversarial loss: 0.597043\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366744; batch adversarial loss: 0.644822\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367046; batch adversarial loss: 0.606152\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314848; batch adversarial loss: 0.500673\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330021; batch adversarial loss: 0.629812\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410310; batch adversarial loss: 0.508973\n",
      "epoch 129; iter: 0; batch classifier loss: 0.357069; batch adversarial loss: 0.480616\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345142; batch adversarial loss: 0.563198\n",
      "epoch 131; iter: 0; batch classifier loss: 0.333571; batch adversarial loss: 0.488263\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357285; batch adversarial loss: 0.520918\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343272; batch adversarial loss: 0.544630\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374888; batch adversarial loss: 0.601534\n",
      "epoch 135; iter: 0; batch classifier loss: 0.275259; batch adversarial loss: 0.611047\n",
      "epoch 136; iter: 0; batch classifier loss: 0.280698; batch adversarial loss: 0.633296\n",
      "epoch 137; iter: 0; batch classifier loss: 0.279857; batch adversarial loss: 0.573628\n",
      "epoch 138; iter: 0; batch classifier loss: 0.287654; batch adversarial loss: 0.543825\n",
      "epoch 139; iter: 0; batch classifier loss: 0.420329; batch adversarial loss: 0.538397\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349790; batch adversarial loss: 0.583683\n",
      "epoch 141; iter: 0; batch classifier loss: 0.396984; batch adversarial loss: 0.609953\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374035; batch adversarial loss: 0.591659\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373728; batch adversarial loss: 0.524073\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370326; batch adversarial loss: 0.525053\n",
      "epoch 145; iter: 0; batch classifier loss: 0.298766; batch adversarial loss: 0.491604\n",
      "epoch 146; iter: 0; batch classifier loss: 0.360201; batch adversarial loss: 0.609989\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342556; batch adversarial loss: 0.500460\n",
      "epoch 148; iter: 0; batch classifier loss: 0.423614; batch adversarial loss: 0.511128\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415247; batch adversarial loss: 0.564836\n",
      "epoch 150; iter: 0; batch classifier loss: 0.457071; batch adversarial loss: 0.509932\n",
      "epoch 151; iter: 0; batch classifier loss: 0.274927; batch adversarial loss: 0.569411\n",
      "epoch 152; iter: 0; batch classifier loss: 0.302654; batch adversarial loss: 0.514990\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374453; batch adversarial loss: 0.545769\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349052; batch adversarial loss: 0.518345\n",
      "epoch 155; iter: 0; batch classifier loss: 0.300171; batch adversarial loss: 0.585144\n",
      "epoch 156; iter: 0; batch classifier loss: 0.311891; batch adversarial loss: 0.605208\n",
      "epoch 157; iter: 0; batch classifier loss: 0.293375; batch adversarial loss: 0.560894\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345114; batch adversarial loss: 0.657251\n",
      "epoch 159; iter: 0; batch classifier loss: 0.305372; batch adversarial loss: 0.530237\n",
      "epoch 160; iter: 0; batch classifier loss: 0.290951; batch adversarial loss: 0.562664\n",
      "epoch 161; iter: 0; batch classifier loss: 0.321560; batch adversarial loss: 0.492690\n",
      "epoch 162; iter: 0; batch classifier loss: 0.285811; batch adversarial loss: 0.630299\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354301; batch adversarial loss: 0.552787\n",
      "epoch 164; iter: 0; batch classifier loss: 0.317184; batch adversarial loss: 0.551992\n",
      "epoch 165; iter: 0; batch classifier loss: 0.391623; batch adversarial loss: 0.522514\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355614; batch adversarial loss: 0.518904\n",
      "epoch 167; iter: 0; batch classifier loss: 0.306488; batch adversarial loss: 0.580588\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309953; batch adversarial loss: 0.540015\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358620; batch adversarial loss: 0.540050\n",
      "epoch 170; iter: 0; batch classifier loss: 0.268065; batch adversarial loss: 0.584960\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344570; batch adversarial loss: 0.486432\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326518; batch adversarial loss: 0.551456\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385189; batch adversarial loss: 0.573876\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368352; batch adversarial loss: 0.612841\n",
      "epoch 175; iter: 0; batch classifier loss: 0.261463; batch adversarial loss: 0.532463\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320322; batch adversarial loss: 0.616801\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347371; batch adversarial loss: 0.569142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318802; batch adversarial loss: 0.475454\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370038; batch adversarial loss: 0.547725\n",
      "epoch 180; iter: 0; batch classifier loss: 0.415292; batch adversarial loss: 0.627598\n",
      "epoch 181; iter: 0; batch classifier loss: 0.381844; batch adversarial loss: 0.530503\n",
      "epoch 182; iter: 0; batch classifier loss: 0.328100; batch adversarial loss: 0.537949\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323856; batch adversarial loss: 0.659391\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351681; batch adversarial loss: 0.550546\n",
      "epoch 185; iter: 0; batch classifier loss: 0.278401; batch adversarial loss: 0.637107\n",
      "epoch 186; iter: 0; batch classifier loss: 0.344009; batch adversarial loss: 0.534122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.405955; batch adversarial loss: 0.528985\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337211; batch adversarial loss: 0.589408\n",
      "epoch 189; iter: 0; batch classifier loss: 0.416468; batch adversarial loss: 0.526180\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360405; batch adversarial loss: 0.549676\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382678; batch adversarial loss: 0.592709\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342893; batch adversarial loss: 0.506352\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344668; batch adversarial loss: 0.567693\n",
      "epoch 194; iter: 0; batch classifier loss: 0.310623; batch adversarial loss: 0.589873\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366688; batch adversarial loss: 0.554926\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309572; batch adversarial loss: 0.578607\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321145; batch adversarial loss: 0.544749\n",
      "epoch 198; iter: 0; batch classifier loss: 0.266936; batch adversarial loss: 0.624252\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348607; batch adversarial loss: 0.544469\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701733; batch adversarial loss: 0.577242\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583240; batch adversarial loss: 0.620294\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579233; batch adversarial loss: 0.661980\n",
      "epoch 3; iter: 0; batch classifier loss: 0.526551; batch adversarial loss: 0.705383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595246; batch adversarial loss: 0.597264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594037; batch adversarial loss: 0.629682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.561861; batch adversarial loss: 0.647487\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505524; batch adversarial loss: 0.645393\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586212; batch adversarial loss: 0.622928\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570858; batch adversarial loss: 0.582984\n",
      "epoch 10; iter: 0; batch classifier loss: 0.642752; batch adversarial loss: 0.588354\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596554; batch adversarial loss: 0.596272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.610063; batch adversarial loss: 0.589056\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546977; batch adversarial loss: 0.575067\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559663; batch adversarial loss: 0.614375\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458671; batch adversarial loss: 0.539125\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483461; batch adversarial loss: 0.547489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504307; batch adversarial loss: 0.576746\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471379; batch adversarial loss: 0.542643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495845; batch adversarial loss: 0.575870\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513998; batch adversarial loss: 0.520682\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484716; batch adversarial loss: 0.616276\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488101; batch adversarial loss: 0.555277\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527637; batch adversarial loss: 0.566214\n",
      "epoch 24; iter: 0; batch classifier loss: 0.424366; batch adversarial loss: 0.589032\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478752; batch adversarial loss: 0.555511\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433651; batch adversarial loss: 0.593992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472732; batch adversarial loss: 0.548359\n",
      "epoch 28; iter: 0; batch classifier loss: 0.403409; batch adversarial loss: 0.478056\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480029; batch adversarial loss: 0.511974\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439309; batch adversarial loss: 0.510034\n",
      "epoch 31; iter: 0; batch classifier loss: 0.403211; batch adversarial loss: 0.529008\n",
      "epoch 32; iter: 0; batch classifier loss: 0.476290; batch adversarial loss: 0.542232\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363420; batch adversarial loss: 0.593673\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515489; batch adversarial loss: 0.560755\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456937; batch adversarial loss: 0.631846\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400457; batch adversarial loss: 0.572034\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446316; batch adversarial loss: 0.526441\n",
      "epoch 38; iter: 0; batch classifier loss: 0.421434; batch adversarial loss: 0.517839\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422802; batch adversarial loss: 0.569322\n",
      "epoch 40; iter: 0; batch classifier loss: 0.548111; batch adversarial loss: 0.534980\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506543; batch adversarial loss: 0.581140\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451740; batch adversarial loss: 0.614887\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408892; batch adversarial loss: 0.517913\n",
      "epoch 44; iter: 0; batch classifier loss: 0.513929; batch adversarial loss: 0.526685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467596; batch adversarial loss: 0.499840\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455186; batch adversarial loss: 0.625232\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429221; batch adversarial loss: 0.535086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371174; batch adversarial loss: 0.517540\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433382; batch adversarial loss: 0.578828\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448517; batch adversarial loss: 0.570997\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438407; batch adversarial loss: 0.580411\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449325; batch adversarial loss: 0.498934\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403517; batch adversarial loss: 0.598404\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429944; batch adversarial loss: 0.544684\n",
      "epoch 55; iter: 0; batch classifier loss: 0.457192; batch adversarial loss: 0.509410\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434696; batch adversarial loss: 0.454914\n",
      "epoch 57; iter: 0; batch classifier loss: 0.417128; batch adversarial loss: 0.508024\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458272; batch adversarial loss: 0.526804\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423651; batch adversarial loss: 0.462872\n",
      "epoch 60; iter: 0; batch classifier loss: 0.372493; batch adversarial loss: 0.538032\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401196; batch adversarial loss: 0.542464\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377887; batch adversarial loss: 0.607747\n",
      "epoch 63; iter: 0; batch classifier loss: 0.347989; batch adversarial loss: 0.589207\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358218; batch adversarial loss: 0.599877\n",
      "epoch 65; iter: 0; batch classifier loss: 0.360990; batch adversarial loss: 0.499578\n",
      "epoch 66; iter: 0; batch classifier loss: 0.497242; batch adversarial loss: 0.534570\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402175; batch adversarial loss: 0.554093\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397070; batch adversarial loss: 0.492618\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431434; batch adversarial loss: 0.492070\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419047; batch adversarial loss: 0.509544\n",
      "epoch 71; iter: 0; batch classifier loss: 0.494620; batch adversarial loss: 0.579766\n",
      "epoch 72; iter: 0; batch classifier loss: 0.370913; batch adversarial loss: 0.599011\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415609; batch adversarial loss: 0.616530\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392638; batch adversarial loss: 0.498999\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360696; batch adversarial loss: 0.516154\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427801; batch adversarial loss: 0.552150\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387578; batch adversarial loss: 0.517037\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402737; batch adversarial loss: 0.592027\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405431; batch adversarial loss: 0.580380\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378035; batch adversarial loss: 0.644598\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413325; batch adversarial loss: 0.523194\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423726; batch adversarial loss: 0.563307\n",
      "epoch 83; iter: 0; batch classifier loss: 0.314804; batch adversarial loss: 0.614143\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401535; batch adversarial loss: 0.463369\n",
      "epoch 85; iter: 0; batch classifier loss: 0.445324; batch adversarial loss: 0.591171\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417217; batch adversarial loss: 0.472991\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452193; batch adversarial loss: 0.509277\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422689; batch adversarial loss: 0.537761\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431309; batch adversarial loss: 0.619146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.478647; batch adversarial loss: 0.516466\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434143; batch adversarial loss: 0.544358\n",
      "epoch 92; iter: 0; batch classifier loss: 0.444113; batch adversarial loss: 0.536241\n",
      "epoch 93; iter: 0; batch classifier loss: 0.382407; batch adversarial loss: 0.518066\n",
      "epoch 94; iter: 0; batch classifier loss: 0.503241; batch adversarial loss: 0.571444\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357723; batch adversarial loss: 0.544475\n",
      "epoch 96; iter: 0; batch classifier loss: 0.436799; batch adversarial loss: 0.617493\n",
      "epoch 97; iter: 0; batch classifier loss: 0.417354; batch adversarial loss: 0.586775\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393550; batch adversarial loss: 0.605758\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398082; batch adversarial loss: 0.502041\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351742; batch adversarial loss: 0.518213\n",
      "epoch 101; iter: 0; batch classifier loss: 0.442229; batch adversarial loss: 0.582394\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414914; batch adversarial loss: 0.545404\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355932; batch adversarial loss: 0.572985\n",
      "epoch 104; iter: 0; batch classifier loss: 0.330794; batch adversarial loss: 0.526008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.452011; batch adversarial loss: 0.570922\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410055; batch adversarial loss: 0.553592\n",
      "epoch 107; iter: 0; batch classifier loss: 0.435540; batch adversarial loss: 0.454669\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332521; batch adversarial loss: 0.545319\n",
      "epoch 109; iter: 0; batch classifier loss: 0.321731; batch adversarial loss: 0.526506\n",
      "epoch 110; iter: 0; batch classifier loss: 0.336213; batch adversarial loss: 0.545274\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357149; batch adversarial loss: 0.533997\n",
      "epoch 112; iter: 0; batch classifier loss: 0.431630; batch adversarial loss: 0.545057\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380194; batch adversarial loss: 0.563224\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358868; batch adversarial loss: 0.689509\n",
      "epoch 115; iter: 0; batch classifier loss: 0.384709; batch adversarial loss: 0.544660\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369539; batch adversarial loss: 0.509789\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386011; batch adversarial loss: 0.525111\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385614; batch adversarial loss: 0.613462\n",
      "epoch 119; iter: 0; batch classifier loss: 0.527380; batch adversarial loss: 0.562896\n",
      "epoch 120; iter: 0; batch classifier loss: 0.443391; batch adversarial loss: 0.482349\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414378; batch adversarial loss: 0.564524\n",
      "epoch 122; iter: 0; batch classifier loss: 0.338563; batch adversarial loss: 0.633961\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380390; batch adversarial loss: 0.590313\n",
      "epoch 124; iter: 0; batch classifier loss: 0.412166; batch adversarial loss: 0.560530\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414376; batch adversarial loss: 0.652534\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351802; batch adversarial loss: 0.551479\n",
      "epoch 127; iter: 0; batch classifier loss: 0.299245; batch adversarial loss: 0.642182\n",
      "epoch 128; iter: 0; batch classifier loss: 0.412526; batch adversarial loss: 0.539151\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359896; batch adversarial loss: 0.571180\n",
      "epoch 130; iter: 0; batch classifier loss: 0.324240; batch adversarial loss: 0.551922\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427078; batch adversarial loss: 0.542940\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365994; batch adversarial loss: 0.554090\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386553; batch adversarial loss: 0.463526\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385595; batch adversarial loss: 0.533672\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377300; batch adversarial loss: 0.562190\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366460; batch adversarial loss: 0.508624\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350479; batch adversarial loss: 0.499770\n",
      "epoch 138; iter: 0; batch classifier loss: 0.456054; batch adversarial loss: 0.551986\n",
      "epoch 139; iter: 0; batch classifier loss: 0.279716; batch adversarial loss: 0.533247\n",
      "epoch 140; iter: 0; batch classifier loss: 0.380985; batch adversarial loss: 0.626674\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350733; batch adversarial loss: 0.508514\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338303; batch adversarial loss: 0.482477\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342151; batch adversarial loss: 0.558785\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371479; batch adversarial loss: 0.499531\n",
      "epoch 145; iter: 0; batch classifier loss: 0.420398; batch adversarial loss: 0.627578\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378047; batch adversarial loss: 0.591529\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361481; batch adversarial loss: 0.578355\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389898; batch adversarial loss: 0.507399\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339031; batch adversarial loss: 0.536236\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373809; batch adversarial loss: 0.510398\n",
      "epoch 151; iter: 0; batch classifier loss: 0.317661; batch adversarial loss: 0.517149\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366828; batch adversarial loss: 0.619205\n",
      "epoch 153; iter: 0; batch classifier loss: 0.312671; batch adversarial loss: 0.527681\n",
      "epoch 154; iter: 0; batch classifier loss: 0.388177; batch adversarial loss: 0.492032\n",
      "epoch 155; iter: 0; batch classifier loss: 0.400277; batch adversarial loss: 0.543330\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336411; batch adversarial loss: 0.488663\n",
      "epoch 157; iter: 0; batch classifier loss: 0.355646; batch adversarial loss: 0.577193\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365955; batch adversarial loss: 0.574387\n",
      "epoch 159; iter: 0; batch classifier loss: 0.418099; batch adversarial loss: 0.597582\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370124; batch adversarial loss: 0.489461\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374278; batch adversarial loss: 0.590103\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323853; batch adversarial loss: 0.507296\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346873; batch adversarial loss: 0.571715\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339036; batch adversarial loss: 0.555646\n",
      "epoch 165; iter: 0; batch classifier loss: 0.438925; batch adversarial loss: 0.497923\n",
      "epoch 166; iter: 0; batch classifier loss: 0.405162; batch adversarial loss: 0.571511\n",
      "epoch 167; iter: 0; batch classifier loss: 0.269359; batch adversarial loss: 0.530061\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367737; batch adversarial loss: 0.580812\n",
      "epoch 169; iter: 0; batch classifier loss: 0.416131; batch adversarial loss: 0.570572\n",
      "epoch 170; iter: 0; batch classifier loss: 0.407468; batch adversarial loss: 0.536308\n",
      "epoch 171; iter: 0; batch classifier loss: 0.423040; batch adversarial loss: 0.597435\n",
      "epoch 172; iter: 0; batch classifier loss: 0.439378; batch adversarial loss: 0.527052\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386723; batch adversarial loss: 0.562778\n",
      "epoch 174; iter: 0; batch classifier loss: 0.411612; batch adversarial loss: 0.568449\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375909; batch adversarial loss: 0.544864\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362579; batch adversarial loss: 0.555447\n",
      "epoch 177; iter: 0; batch classifier loss: 0.440265; batch adversarial loss: 0.536309\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387532; batch adversarial loss: 0.489775\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391590; batch adversarial loss: 0.623802\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381195; batch adversarial loss: 0.544077\n",
      "epoch 181; iter: 0; batch classifier loss: 0.368784; batch adversarial loss: 0.571984\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354848; batch adversarial loss: 0.604327\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386405; batch adversarial loss: 0.563788\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363992; batch adversarial loss: 0.490637\n",
      "epoch 185; iter: 0; batch classifier loss: 0.363405; batch adversarial loss: 0.501890\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328341; batch adversarial loss: 0.626684\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393399; batch adversarial loss: 0.518959\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277145; batch adversarial loss: 0.550552\n",
      "epoch 189; iter: 0; batch classifier loss: 0.468257; batch adversarial loss: 0.545793\n",
      "epoch 190; iter: 0; batch classifier loss: 0.410334; batch adversarial loss: 0.542638\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337713; batch adversarial loss: 0.536718\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323118; batch adversarial loss: 0.618245\n",
      "epoch 193; iter: 0; batch classifier loss: 0.346381; batch adversarial loss: 0.590024\n",
      "epoch 194; iter: 0; batch classifier loss: 0.310942; batch adversarial loss: 0.527981\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341134; batch adversarial loss: 0.671243\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342604; batch adversarial loss: 0.553540\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350884; batch adversarial loss: 0.561884\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334327; batch adversarial loss: 0.492229\n",
      "epoch 199; iter: 0; batch classifier loss: 0.443446; batch adversarial loss: 0.553358\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714352; batch adversarial loss: 0.800433\n",
      "epoch 1; iter: 0; batch classifier loss: 0.859760; batch adversarial loss: 0.881380\n",
      "epoch 2; iter: 0; batch classifier loss: 0.827018; batch adversarial loss: 0.807012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.799044; batch adversarial loss: 0.736507\n",
      "epoch 4; iter: 0; batch classifier loss: 0.697081; batch adversarial loss: 0.680397\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592008; batch adversarial loss: 0.653001\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540176; batch adversarial loss: 0.636734\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528487; batch adversarial loss: 0.616736\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566512; batch adversarial loss: 0.585787\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627658; batch adversarial loss: 0.622909\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469731; batch adversarial loss: 0.573117\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501126; batch adversarial loss: 0.584624\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518661; batch adversarial loss: 0.559893\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524080; batch adversarial loss: 0.599411\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535756; batch adversarial loss: 0.607989\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506202; batch adversarial loss: 0.551995\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520085; batch adversarial loss: 0.553372\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506256; batch adversarial loss: 0.521050\n",
      "epoch 18; iter: 0; batch classifier loss: 0.554506; batch adversarial loss: 0.498536\n",
      "epoch 19; iter: 0; batch classifier loss: 0.590835; batch adversarial loss: 0.550869\n",
      "epoch 20; iter: 0; batch classifier loss: 0.555715; batch adversarial loss: 0.541982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504250; batch adversarial loss: 0.602589\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423901; batch adversarial loss: 0.613834\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516090; batch adversarial loss: 0.603119\n",
      "epoch 24; iter: 0; batch classifier loss: 0.537735; batch adversarial loss: 0.558513\n",
      "epoch 25; iter: 0; batch classifier loss: 0.469213; batch adversarial loss: 0.521667\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512245; batch adversarial loss: 0.552279\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392719; batch adversarial loss: 0.515733\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495941; batch adversarial loss: 0.569456\n",
      "epoch 29; iter: 0; batch classifier loss: 0.526047; batch adversarial loss: 0.514893\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489109; batch adversarial loss: 0.552277\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432652; batch adversarial loss: 0.511553\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483155; batch adversarial loss: 0.550580\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386889; batch adversarial loss: 0.548908\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470668; batch adversarial loss: 0.540012\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486174; batch adversarial loss: 0.653954\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454383; batch adversarial loss: 0.528375\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487852; batch adversarial loss: 0.521409\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452065; batch adversarial loss: 0.555894\n",
      "epoch 39; iter: 0; batch classifier loss: 0.357544; batch adversarial loss: 0.667866\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429183; batch adversarial loss: 0.575512\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440222; batch adversarial loss: 0.579810\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405976; batch adversarial loss: 0.575983\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456391; batch adversarial loss: 0.553088\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451358; batch adversarial loss: 0.588623\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450500; batch adversarial loss: 0.543300\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457202; batch adversarial loss: 0.421551\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440865; batch adversarial loss: 0.509272\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465833; batch adversarial loss: 0.535991\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428514; batch adversarial loss: 0.633424\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392392; batch adversarial loss: 0.605967\n",
      "epoch 51; iter: 0; batch classifier loss: 0.480765; batch adversarial loss: 0.586623\n",
      "epoch 52; iter: 0; batch classifier loss: 0.348871; batch adversarial loss: 0.553442\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480097; batch adversarial loss: 0.536539\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404672; batch adversarial loss: 0.527055\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486452; batch adversarial loss: 0.581083\n",
      "epoch 56; iter: 0; batch classifier loss: 0.351472; batch adversarial loss: 0.608794\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390220; batch adversarial loss: 0.580843\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431367; batch adversarial loss: 0.536011\n",
      "epoch 59; iter: 0; batch classifier loss: 0.377763; batch adversarial loss: 0.553862\n",
      "epoch 60; iter: 0; batch classifier loss: 0.308973; batch adversarial loss: 0.534446\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468851; batch adversarial loss: 0.580151\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382473; batch adversarial loss: 0.542196\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392397; batch adversarial loss: 0.526312\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431604; batch adversarial loss: 0.463263\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379205; batch adversarial loss: 0.482201\n",
      "epoch 66; iter: 0; batch classifier loss: 0.478462; batch adversarial loss: 0.481596\n",
      "epoch 67; iter: 0; batch classifier loss: 0.315878; batch adversarial loss: 0.560449\n",
      "epoch 68; iter: 0; batch classifier loss: 0.351093; batch adversarial loss: 0.581729\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414641; batch adversarial loss: 0.516701\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397464; batch adversarial loss: 0.545965\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429016; batch adversarial loss: 0.552285\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385186; batch adversarial loss: 0.501139\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421548; batch adversarial loss: 0.464504\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433915; batch adversarial loss: 0.560451\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382540; batch adversarial loss: 0.561437\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366329; batch adversarial loss: 0.616172\n",
      "epoch 77; iter: 0; batch classifier loss: 0.490766; batch adversarial loss: 0.554272\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399068; batch adversarial loss: 0.497752\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429098; batch adversarial loss: 0.510542\n",
      "epoch 80; iter: 0; batch classifier loss: 0.471255; batch adversarial loss: 0.553358\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391019; batch adversarial loss: 0.553874\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387420; batch adversarial loss: 0.481006\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364820; batch adversarial loss: 0.574754\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364550; batch adversarial loss: 0.615159\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402743; batch adversarial loss: 0.597587\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367847; batch adversarial loss: 0.580699\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360242; batch adversarial loss: 0.561613\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408020; batch adversarial loss: 0.597394\n",
      "epoch 89; iter: 0; batch classifier loss: 0.421341; batch adversarial loss: 0.536114\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344729; batch adversarial loss: 0.567443\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411345; batch adversarial loss: 0.572004\n",
      "epoch 92; iter: 0; batch classifier loss: 0.439322; batch adversarial loss: 0.547094\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320860; batch adversarial loss: 0.525513\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375537; batch adversarial loss: 0.596719\n",
      "epoch 95; iter: 0; batch classifier loss: 0.331710; batch adversarial loss: 0.537290\n",
      "epoch 96; iter: 0; batch classifier loss: 0.397670; batch adversarial loss: 0.548414\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395676; batch adversarial loss: 0.590688\n",
      "epoch 98; iter: 0; batch classifier loss: 0.459341; batch adversarial loss: 0.498824\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384148; batch adversarial loss: 0.612921\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346338; batch adversarial loss: 0.590583\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406469; batch adversarial loss: 0.541791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.393288; batch adversarial loss: 0.502021\n",
      "epoch 103; iter: 0; batch classifier loss: 0.338124; batch adversarial loss: 0.593224\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446932; batch adversarial loss: 0.588590\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394812; batch adversarial loss: 0.509866\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330297; batch adversarial loss: 0.604727\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392922; batch adversarial loss: 0.553738\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353170; batch adversarial loss: 0.564277\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331646; batch adversarial loss: 0.565477\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400519; batch adversarial loss: 0.580026\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355464; batch adversarial loss: 0.556671\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386451; batch adversarial loss: 0.479592\n",
      "epoch 113; iter: 0; batch classifier loss: 0.438139; batch adversarial loss: 0.586256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384821; batch adversarial loss: 0.528327\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380684; batch adversarial loss: 0.526082\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382350; batch adversarial loss: 0.581765\n",
      "epoch 117; iter: 0; batch classifier loss: 0.433729; batch adversarial loss: 0.525452\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405185; batch adversarial loss: 0.544709\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356424; batch adversarial loss: 0.552454\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413918; batch adversarial loss: 0.541263\n",
      "epoch 121; iter: 0; batch classifier loss: 0.405858; batch adversarial loss: 0.501143\n",
      "epoch 122; iter: 0; batch classifier loss: 0.319709; batch adversarial loss: 0.560969\n",
      "epoch 123; iter: 0; batch classifier loss: 0.418150; batch adversarial loss: 0.553738\n",
      "epoch 124; iter: 0; batch classifier loss: 0.413109; batch adversarial loss: 0.552631\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375289; batch adversarial loss: 0.579824\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353790; batch adversarial loss: 0.615112\n",
      "epoch 127; iter: 0; batch classifier loss: 0.399479; batch adversarial loss: 0.518321\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328309; batch adversarial loss: 0.569993\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369563; batch adversarial loss: 0.608220\n",
      "epoch 130; iter: 0; batch classifier loss: 0.403890; batch adversarial loss: 0.451443\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380035; batch adversarial loss: 0.580341\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320818; batch adversarial loss: 0.509286\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395722; batch adversarial loss: 0.562063\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366027; batch adversarial loss: 0.527196\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372474; batch adversarial loss: 0.525611\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366087; batch adversarial loss: 0.583199\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366424; batch adversarial loss: 0.527190\n",
      "epoch 138; iter: 0; batch classifier loss: 0.269419; batch adversarial loss: 0.508701\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.498963\n",
      "epoch 140; iter: 0; batch classifier loss: 0.345592; batch adversarial loss: 0.601899\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356229; batch adversarial loss: 0.535042\n",
      "epoch 142; iter: 0; batch classifier loss: 0.329191; batch adversarial loss: 0.506524\n",
      "epoch 143; iter: 0; batch classifier loss: 0.305721; batch adversarial loss: 0.601895\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365650; batch adversarial loss: 0.591751\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362618; batch adversarial loss: 0.545894\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339944; batch adversarial loss: 0.443608\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331702; batch adversarial loss: 0.534504\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332243; batch adversarial loss: 0.516334\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369356; batch adversarial loss: 0.526251\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389280; batch adversarial loss: 0.571644\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344668; batch adversarial loss: 0.571524\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390825; batch adversarial loss: 0.500518\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391059; batch adversarial loss: 0.534985\n",
      "epoch 154; iter: 0; batch classifier loss: 0.367724; batch adversarial loss: 0.436294\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362279; batch adversarial loss: 0.591447\n",
      "epoch 156; iter: 0; batch classifier loss: 0.311875; batch adversarial loss: 0.597000\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309429; batch adversarial loss: 0.524914\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318186; batch adversarial loss: 0.655751\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338608; batch adversarial loss: 0.572513\n",
      "epoch 160; iter: 0; batch classifier loss: 0.371936; batch adversarial loss: 0.524727\n",
      "epoch 161; iter: 0; batch classifier loss: 0.435995; batch adversarial loss: 0.572079\n",
      "epoch 162; iter: 0; batch classifier loss: 0.324523; batch adversarial loss: 0.498801\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385255; batch adversarial loss: 0.547510\n",
      "epoch 164; iter: 0; batch classifier loss: 0.473705; batch adversarial loss: 0.542592\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350028; batch adversarial loss: 0.544311\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347031; batch adversarial loss: 0.552269\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387720; batch adversarial loss: 0.589558\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306478; batch adversarial loss: 0.480917\n",
      "epoch 169; iter: 0; batch classifier loss: 0.259920; batch adversarial loss: 0.535872\n",
      "epoch 170; iter: 0; batch classifier loss: 0.276419; batch adversarial loss: 0.599549\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374452; batch adversarial loss: 0.581136\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345457; batch adversarial loss: 0.602262\n",
      "epoch 173; iter: 0; batch classifier loss: 0.441184; batch adversarial loss: 0.553113\n",
      "epoch 174; iter: 0; batch classifier loss: 0.414594; batch adversarial loss: 0.506847\n",
      "epoch 175; iter: 0; batch classifier loss: 0.318833; batch adversarial loss: 0.497542\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310258; batch adversarial loss: 0.468649\n",
      "epoch 177; iter: 0; batch classifier loss: 0.471004; batch adversarial loss: 0.582363\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384574; batch adversarial loss: 0.510901\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374501; batch adversarial loss: 0.533295\n",
      "epoch 180; iter: 0; batch classifier loss: 0.300528; batch adversarial loss: 0.481623\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365752; batch adversarial loss: 0.545501\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379417; batch adversarial loss: 0.617089\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329427; batch adversarial loss: 0.593533\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424009; batch adversarial loss: 0.591048\n",
      "epoch 185; iter: 0; batch classifier loss: 0.301165; batch adversarial loss: 0.563944\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383499; batch adversarial loss: 0.527963\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376078; batch adversarial loss: 0.642572\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392787; batch adversarial loss: 0.587438\n",
      "epoch 189; iter: 0; batch classifier loss: 0.318045; batch adversarial loss: 0.526988\n",
      "epoch 190; iter: 0; batch classifier loss: 0.259677; batch adversarial loss: 0.575152\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359075; batch adversarial loss: 0.572060\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396603; batch adversarial loss: 0.522834\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335798; batch adversarial loss: 0.561984\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333128; batch adversarial loss: 0.558325\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393309; batch adversarial loss: 0.488759\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387104; batch adversarial loss: 0.546957\n",
      "epoch 197; iter: 0; batch classifier loss: 0.404606; batch adversarial loss: 0.488865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.304101; batch adversarial loss: 0.601205\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373891; batch adversarial loss: 0.560142\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727096; batch adversarial loss: 0.890842\n",
      "epoch 1; iter: 0; batch classifier loss: 0.712280; batch adversarial loss: 1.037899\n",
      "epoch 2; iter: 0; batch classifier loss: 0.661640; batch adversarial loss: 0.960582\n",
      "epoch 3; iter: 0; batch classifier loss: 0.657461; batch adversarial loss: 0.845554\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603396; batch adversarial loss: 0.765677\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544483; batch adversarial loss: 0.763316\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548057; batch adversarial loss: 0.725577\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588804; batch adversarial loss: 0.662764\n",
      "epoch 8; iter: 0; batch classifier loss: 0.639022; batch adversarial loss: 0.683321\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559691; batch adversarial loss: 0.617485\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522498; batch adversarial loss: 0.616718\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564880; batch adversarial loss: 0.578808\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527076; batch adversarial loss: 0.614947\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559046; batch adversarial loss: 0.622643\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459163; batch adversarial loss: 0.601101\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495071; batch adversarial loss: 0.529916\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527183; batch adversarial loss: 0.584127\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516942; batch adversarial loss: 0.568746\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514386; batch adversarial loss: 0.565019\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484607; batch adversarial loss: 0.553793\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498424; batch adversarial loss: 0.588355\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470354; batch adversarial loss: 0.543060\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433093; batch adversarial loss: 0.513289\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506598; batch adversarial loss: 0.563132\n",
      "epoch 24; iter: 0; batch classifier loss: 0.423651; batch adversarial loss: 0.573464\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439455; batch adversarial loss: 0.569292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500970; batch adversarial loss: 0.558998\n",
      "epoch 27; iter: 0; batch classifier loss: 0.566343; batch adversarial loss: 0.554825\n",
      "epoch 28; iter: 0; batch classifier loss: 0.501855; batch adversarial loss: 0.550533\n",
      "epoch 29; iter: 0; batch classifier loss: 0.536205; batch adversarial loss: 0.524047\n",
      "epoch 30; iter: 0; batch classifier loss: 0.542879; batch adversarial loss: 0.538440\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511009; batch adversarial loss: 0.502216\n",
      "epoch 32; iter: 0; batch classifier loss: 0.539505; batch adversarial loss: 0.565380\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425547; batch adversarial loss: 0.516465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481228; batch adversarial loss: 0.485115\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459506; batch adversarial loss: 0.528480\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450366; batch adversarial loss: 0.575871\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459678; batch adversarial loss: 0.587266\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402317; batch adversarial loss: 0.539927\n",
      "epoch 39; iter: 0; batch classifier loss: 0.449641; batch adversarial loss: 0.565184\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468587; batch adversarial loss: 0.526493\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378926; batch adversarial loss: 0.558493\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426697; batch adversarial loss: 0.491225\n",
      "epoch 43; iter: 0; batch classifier loss: 0.529649; batch adversarial loss: 0.527080\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428863; batch adversarial loss: 0.471963\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385345; batch adversarial loss: 0.553618\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423772; batch adversarial loss: 0.553652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480785; batch adversarial loss: 0.509895\n",
      "epoch 48; iter: 0; batch classifier loss: 0.531598; batch adversarial loss: 0.570635\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410531; batch adversarial loss: 0.589223\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442752; batch adversarial loss: 0.501792\n",
      "epoch 51; iter: 0; batch classifier loss: 0.419610; batch adversarial loss: 0.619311\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380476; batch adversarial loss: 0.572874\n",
      "epoch 53; iter: 0; batch classifier loss: 0.467816; batch adversarial loss: 0.586287\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414519; batch adversarial loss: 0.581148\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428203; batch adversarial loss: 0.553630\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431390; batch adversarial loss: 0.526494\n",
      "epoch 57; iter: 0; batch classifier loss: 0.476378; batch adversarial loss: 0.462205\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417768; batch adversarial loss: 0.610519\n",
      "epoch 59; iter: 0; batch classifier loss: 0.333916; batch adversarial loss: 0.562512\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455545; batch adversarial loss: 0.497699\n",
      "epoch 61; iter: 0; batch classifier loss: 0.393840; batch adversarial loss: 0.497455\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375525; batch adversarial loss: 0.555122\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468017; batch adversarial loss: 0.582745\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414081; batch adversarial loss: 0.552086\n",
      "epoch 65; iter: 0; batch classifier loss: 0.346586; batch adversarial loss: 0.488511\n",
      "epoch 66; iter: 0; batch classifier loss: 0.456595; batch adversarial loss: 0.573533\n",
      "epoch 67; iter: 0; batch classifier loss: 0.462118; batch adversarial loss: 0.552358\n",
      "epoch 68; iter: 0; batch classifier loss: 0.371405; batch adversarial loss: 0.572269\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444167; batch adversarial loss: 0.552741\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397485; batch adversarial loss: 0.545046\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414075; batch adversarial loss: 0.526101\n",
      "epoch 72; iter: 0; batch classifier loss: 0.350037; batch adversarial loss: 0.563316\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408669; batch adversarial loss: 0.553147\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418532; batch adversarial loss: 0.573502\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426096; batch adversarial loss: 0.545628\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410921; batch adversarial loss: 0.489327\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409839; batch adversarial loss: 0.535272\n",
      "epoch 78; iter: 0; batch classifier loss: 0.443586; batch adversarial loss: 0.526887\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389140; batch adversarial loss: 0.570993\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383112; batch adversarial loss: 0.591213\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365441; batch adversarial loss: 0.536241\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438697; batch adversarial loss: 0.572339\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391895; batch adversarial loss: 0.480327\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411538; batch adversarial loss: 0.544953\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390882; batch adversarial loss: 0.635268\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373468; batch adversarial loss: 0.461350\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375261; batch adversarial loss: 0.572182\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385700; batch adversarial loss: 0.526336\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364881; batch adversarial loss: 0.507774\n",
      "epoch 90; iter: 0; batch classifier loss: 0.356643; batch adversarial loss: 0.488580\n",
      "epoch 91; iter: 0; batch classifier loss: 0.368155; batch adversarial loss: 0.525756\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436843; batch adversarial loss: 0.554018\n",
      "epoch 93; iter: 0; batch classifier loss: 0.500902; batch adversarial loss: 0.627337\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430612; batch adversarial loss: 0.544016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.372914; batch adversarial loss: 0.516875\n",
      "epoch 96; iter: 0; batch classifier loss: 0.316035; batch adversarial loss: 0.526222\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405123; batch adversarial loss: 0.534601\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412341; batch adversarial loss: 0.553167\n",
      "epoch 99; iter: 0; batch classifier loss: 0.512138; batch adversarial loss: 0.607682\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379172; batch adversarial loss: 0.597748\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406631; batch adversarial loss: 0.572467\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414060; batch adversarial loss: 0.554277\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361344; batch adversarial loss: 0.588076\n",
      "epoch 104; iter: 0; batch classifier loss: 0.501285; batch adversarial loss: 0.610593\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358437; batch adversarial loss: 0.506792\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339525; batch adversarial loss: 0.527598\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350644; batch adversarial loss: 0.461329\n",
      "epoch 108; iter: 0; batch classifier loss: 0.309226; batch adversarial loss: 0.525621\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399966; batch adversarial loss: 0.535567\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388113; batch adversarial loss: 0.470937\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379188; batch adversarial loss: 0.545472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324053; batch adversarial loss: 0.563981\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379276; batch adversarial loss: 0.553922\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381770; batch adversarial loss: 0.563475\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374746; batch adversarial loss: 0.581080\n",
      "epoch 116; iter: 0; batch classifier loss: 0.331073; batch adversarial loss: 0.553926\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314759; batch adversarial loss: 0.591416\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342421; batch adversarial loss: 0.444832\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423799; batch adversarial loss: 0.636030\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375499; batch adversarial loss: 0.563360\n",
      "epoch 121; iter: 0; batch classifier loss: 0.399390; batch adversarial loss: 0.508550\n",
      "epoch 122; iter: 0; batch classifier loss: 0.381456; batch adversarial loss: 0.507810\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403307; batch adversarial loss: 0.524355\n",
      "epoch 124; iter: 0; batch classifier loss: 0.328903; batch adversarial loss: 0.497139\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362691; batch adversarial loss: 0.572689\n",
      "epoch 126; iter: 0; batch classifier loss: 0.331021; batch adversarial loss: 0.544254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415965; batch adversarial loss: 0.526638\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397585; batch adversarial loss: 0.535138\n",
      "epoch 129; iter: 0; batch classifier loss: 0.439455; batch adversarial loss: 0.552423\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421653; batch adversarial loss: 0.498480\n",
      "epoch 131; iter: 0; batch classifier loss: 0.327019; batch adversarial loss: 0.535051\n",
      "epoch 132; iter: 0; batch classifier loss: 0.366033; batch adversarial loss: 0.543361\n",
      "epoch 133; iter: 0; batch classifier loss: 0.479587; batch adversarial loss: 0.488437\n",
      "epoch 134; iter: 0; batch classifier loss: 0.423655; batch adversarial loss: 0.561386\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314908; batch adversarial loss: 0.478550\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372057; batch adversarial loss: 0.533473\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323754; batch adversarial loss: 0.581731\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357184; batch adversarial loss: 0.497745\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373500; batch adversarial loss: 0.571047\n",
      "epoch 140; iter: 0; batch classifier loss: 0.266050; batch adversarial loss: 0.544690\n",
      "epoch 141; iter: 0; batch classifier loss: 0.475939; batch adversarial loss: 0.569929\n",
      "epoch 142; iter: 0; batch classifier loss: 0.301271; batch adversarial loss: 0.489692\n",
      "epoch 143; iter: 0; batch classifier loss: 0.411724; batch adversarial loss: 0.498238\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405608; batch adversarial loss: 0.571211\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348228; batch adversarial loss: 0.610904\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375231; batch adversarial loss: 0.583621\n",
      "epoch 147; iter: 0; batch classifier loss: 0.378159; batch adversarial loss: 0.480171\n",
      "epoch 148; iter: 0; batch classifier loss: 0.325008; batch adversarial loss: 0.582172\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354877; batch adversarial loss: 0.591393\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351439; batch adversarial loss: 0.488931\n",
      "epoch 151; iter: 0; batch classifier loss: 0.345188; batch adversarial loss: 0.655516\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388699; batch adversarial loss: 0.545455\n",
      "epoch 153; iter: 0; batch classifier loss: 0.319901; batch adversarial loss: 0.506640\n",
      "epoch 154; iter: 0; batch classifier loss: 0.431081; batch adversarial loss: 0.544147\n",
      "epoch 155; iter: 0; batch classifier loss: 0.335732; batch adversarial loss: 0.582869\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361628; batch adversarial loss: 0.571239\n",
      "epoch 157; iter: 0; batch classifier loss: 0.332811; batch adversarial loss: 0.572689\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369327; batch adversarial loss: 0.527433\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351874; batch adversarial loss: 0.543314\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364718; batch adversarial loss: 0.471568\n",
      "epoch 161; iter: 0; batch classifier loss: 0.303153; batch adversarial loss: 0.563602\n",
      "epoch 162; iter: 0; batch classifier loss: 0.431645; batch adversarial loss: 0.636935\n",
      "epoch 163; iter: 0; batch classifier loss: 0.308490; batch adversarial loss: 0.507878\n",
      "epoch 164; iter: 0; batch classifier loss: 0.407119; batch adversarial loss: 0.516761\n",
      "epoch 165; iter: 0; batch classifier loss: 0.403624; batch adversarial loss: 0.536166\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384322; batch adversarial loss: 0.544619\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340236; batch adversarial loss: 0.590986\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349069; batch adversarial loss: 0.563747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.328391; batch adversarial loss: 0.617275\n",
      "epoch 170; iter: 0; batch classifier loss: 0.311679; batch adversarial loss: 0.571863\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394589; batch adversarial loss: 0.565156\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375448; batch adversarial loss: 0.442981\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354019; batch adversarial loss: 0.554058\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365510; batch adversarial loss: 0.565516\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357341; batch adversarial loss: 0.568662\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338454; batch adversarial loss: 0.471361\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329022; batch adversarial loss: 0.489273\n",
      "epoch 178; iter: 0; batch classifier loss: 0.454096; batch adversarial loss: 0.571698\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369212; batch adversarial loss: 0.571819\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322852; batch adversarial loss: 0.573324\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354429; batch adversarial loss: 0.535282\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338002; batch adversarial loss: 0.515589\n",
      "epoch 183; iter: 0; batch classifier loss: 0.360617; batch adversarial loss: 0.560906\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332171; batch adversarial loss: 0.590837\n",
      "epoch 185; iter: 0; batch classifier loss: 0.259111; batch adversarial loss: 0.589957\n",
      "epoch 186; iter: 0; batch classifier loss: 0.376179; batch adversarial loss: 0.554670\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355841; batch adversarial loss: 0.581549\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397041; batch adversarial loss: 0.619968\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368011; batch adversarial loss: 0.617139\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407749; batch adversarial loss: 0.552457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.360173; batch adversarial loss: 0.515655\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368245; batch adversarial loss: 0.563843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333687; batch adversarial loss: 0.600893\n",
      "epoch 194; iter: 0; batch classifier loss: 0.383310; batch adversarial loss: 0.525274\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375944; batch adversarial loss: 0.552953\n",
      "epoch 196; iter: 0; batch classifier loss: 0.387909; batch adversarial loss: 0.579973\n",
      "epoch 197; iter: 0; batch classifier loss: 0.296258; batch adversarial loss: 0.635650\n",
      "epoch 198; iter: 0; batch classifier loss: 0.255069; batch adversarial loss: 0.499400\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350092; batch adversarial loss: 0.507498\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691784; batch adversarial loss: 0.774389\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668290; batch adversarial loss: 0.876890\n",
      "epoch 2; iter: 0; batch classifier loss: 0.661428; batch adversarial loss: 0.792222\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575072; batch adversarial loss: 0.721337\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598033; batch adversarial loss: 0.671578\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596711; batch adversarial loss: 0.673405\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526045; batch adversarial loss: 0.636101\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591002; batch adversarial loss: 0.621058\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561096; batch adversarial loss: 0.617949\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616639; batch adversarial loss: 0.582273\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514750; batch adversarial loss: 0.638876\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571115; batch adversarial loss: 0.598761\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542285; batch adversarial loss: 0.585097\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580012; batch adversarial loss: 0.584253\n",
      "epoch 14; iter: 0; batch classifier loss: 0.561459; batch adversarial loss: 0.589688\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462471; batch adversarial loss: 0.571979\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529999; batch adversarial loss: 0.557803\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515911; batch adversarial loss: 0.576815\n",
      "epoch 18; iter: 0; batch classifier loss: 0.538698; batch adversarial loss: 0.578473\n",
      "epoch 19; iter: 0; batch classifier loss: 0.588882; batch adversarial loss: 0.591337\n",
      "epoch 20; iter: 0; batch classifier loss: 0.541104; batch adversarial loss: 0.586119\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429389; batch adversarial loss: 0.554857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.565192; batch adversarial loss: 0.555742\n",
      "epoch 23; iter: 0; batch classifier loss: 0.425924; batch adversarial loss: 0.537526\n",
      "epoch 24; iter: 0; batch classifier loss: 0.432087; batch adversarial loss: 0.561881\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452863; batch adversarial loss: 0.548136\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496393; batch adversarial loss: 0.534476\n",
      "epoch 27; iter: 0; batch classifier loss: 0.508138; batch adversarial loss: 0.549835\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473798; batch adversarial loss: 0.493125\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457539; batch adversarial loss: 0.566430\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513529; batch adversarial loss: 0.542006\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490532; batch adversarial loss: 0.506788\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407225; batch adversarial loss: 0.554235\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468895; batch adversarial loss: 0.545673\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434946; batch adversarial loss: 0.539070\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489132; batch adversarial loss: 0.590188\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390601; batch adversarial loss: 0.511524\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451846; batch adversarial loss: 0.459706\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473915; batch adversarial loss: 0.560747\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477880; batch adversarial loss: 0.546880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430885; batch adversarial loss: 0.568629\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470474; batch adversarial loss: 0.578737\n",
      "epoch 42; iter: 0; batch classifier loss: 0.468439; batch adversarial loss: 0.569418\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461540; batch adversarial loss: 0.532876\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477251; batch adversarial loss: 0.624725\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463244; batch adversarial loss: 0.519984\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432842; batch adversarial loss: 0.536773\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433589; batch adversarial loss: 0.570668\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424966; batch adversarial loss: 0.599462\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424003; batch adversarial loss: 0.588487\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410637; batch adversarial loss: 0.590232\n",
      "epoch 51; iter: 0; batch classifier loss: 0.325542; batch adversarial loss: 0.527155\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407710; batch adversarial loss: 0.535493\n",
      "epoch 53; iter: 0; batch classifier loss: 0.440005; batch adversarial loss: 0.490308\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413756; batch adversarial loss: 0.589931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446013; batch adversarial loss: 0.463497\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409564; batch adversarial loss: 0.545196\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406869; batch adversarial loss: 0.579860\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389450; batch adversarial loss: 0.499196\n",
      "epoch 59; iter: 0; batch classifier loss: 0.450393; batch adversarial loss: 0.599258\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481067; batch adversarial loss: 0.536288\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422795; batch adversarial loss: 0.607555\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406601; batch adversarial loss: 0.535722\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420067; batch adversarial loss: 0.606731\n",
      "epoch 64; iter: 0; batch classifier loss: 0.474670; batch adversarial loss: 0.517535\n",
      "epoch 65; iter: 0; batch classifier loss: 0.452423; batch adversarial loss: 0.651853\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436054; batch adversarial loss: 0.473327\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379222; batch adversarial loss: 0.526939\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383605; batch adversarial loss: 0.561719\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390460; batch adversarial loss: 0.500770\n",
      "epoch 70; iter: 0; batch classifier loss: 0.373753; batch adversarial loss: 0.615055\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425639; batch adversarial loss: 0.572615\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478398; batch adversarial loss: 0.544239\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419084; batch adversarial loss: 0.508527\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389387; batch adversarial loss: 0.543488\n",
      "epoch 75; iter: 0; batch classifier loss: 0.460993; batch adversarial loss: 0.589161\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411825; batch adversarial loss: 0.562714\n",
      "epoch 77; iter: 0; batch classifier loss: 0.366444; batch adversarial loss: 0.553699\n",
      "epoch 78; iter: 0; batch classifier loss: 0.463775; batch adversarial loss: 0.689036\n",
      "epoch 79; iter: 0; batch classifier loss: 0.332738; batch adversarial loss: 0.608501\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421615; batch adversarial loss: 0.508271\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417644; batch adversarial loss: 0.578448\n",
      "epoch 82; iter: 0; batch classifier loss: 0.474518; batch adversarial loss: 0.579617\n",
      "epoch 83; iter: 0; batch classifier loss: 0.352824; batch adversarial loss: 0.562616\n",
      "epoch 84; iter: 0; batch classifier loss: 0.457521; batch adversarial loss: 0.545990\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368420; batch adversarial loss: 0.544769\n",
      "epoch 86; iter: 0; batch classifier loss: 0.463041; batch adversarial loss: 0.534545\n",
      "epoch 87; iter: 0; batch classifier loss: 0.444803; batch adversarial loss: 0.544119\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435056; batch adversarial loss: 0.590023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.428645; batch adversarial loss: 0.533832\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351550; batch adversarial loss: 0.535155\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387860; batch adversarial loss: 0.561651\n",
      "epoch 92; iter: 0; batch classifier loss: 0.416270; batch adversarial loss: 0.545265\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417167; batch adversarial loss: 0.554935\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452414; batch adversarial loss: 0.606991\n",
      "epoch 95; iter: 0; batch classifier loss: 0.467784; batch adversarial loss: 0.607650\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398059; batch adversarial loss: 0.581681\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422755; batch adversarial loss: 0.481391\n",
      "epoch 98; iter: 0; batch classifier loss: 0.473447; batch adversarial loss: 0.591437\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381819; batch adversarial loss: 0.626030\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400868; batch adversarial loss: 0.526504\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374811; batch adversarial loss: 0.562270\n",
      "epoch 102; iter: 0; batch classifier loss: 0.428411; batch adversarial loss: 0.526029\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408092; batch adversarial loss: 0.480520\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416491; batch adversarial loss: 0.608766\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340216; batch adversarial loss: 0.518754\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388747; batch adversarial loss: 0.544851\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397339; batch adversarial loss: 0.535739\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382802; batch adversarial loss: 0.589970\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368098; batch adversarial loss: 0.545225\n",
      "epoch 110; iter: 0; batch classifier loss: 0.456302; batch adversarial loss: 0.545269\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394093; batch adversarial loss: 0.527492\n",
      "epoch 112; iter: 0; batch classifier loss: 0.421950; batch adversarial loss: 0.660584\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381543; batch adversarial loss: 0.590255\n",
      "epoch 114; iter: 0; batch classifier loss: 0.436655; batch adversarial loss: 0.606512\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420322; batch adversarial loss: 0.472013\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395858; batch adversarial loss: 0.644039\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376732; batch adversarial loss: 0.507511\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408489; batch adversarial loss: 0.633804\n",
      "epoch 119; iter: 0; batch classifier loss: 0.321854; batch adversarial loss: 0.499272\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363276; batch adversarial loss: 0.517614\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387539; batch adversarial loss: 0.544842\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424640; batch adversarial loss: 0.518849\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396009; batch adversarial loss: 0.527383\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370816; batch adversarial loss: 0.499901\n",
      "epoch 125; iter: 0; batch classifier loss: 0.385504; batch adversarial loss: 0.572150\n",
      "epoch 126; iter: 0; batch classifier loss: 0.452925; batch adversarial loss: 0.616053\n",
      "epoch 127; iter: 0; batch classifier loss: 0.325226; batch adversarial loss: 0.562549\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343133; batch adversarial loss: 0.524610\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338370; batch adversarial loss: 0.660263\n",
      "epoch 130; iter: 0; batch classifier loss: 0.330640; batch adversarial loss: 0.490292\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353561; batch adversarial loss: 0.571356\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388025; batch adversarial loss: 0.545004\n",
      "epoch 133; iter: 0; batch classifier loss: 0.406056; batch adversarial loss: 0.571483\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387076; batch adversarial loss: 0.489780\n",
      "epoch 135; iter: 0; batch classifier loss: 0.333407; batch adversarial loss: 0.509952\n",
      "epoch 136; iter: 0; batch classifier loss: 0.367263; batch adversarial loss: 0.518601\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379375; batch adversarial loss: 0.464140\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388879; batch adversarial loss: 0.570661\n",
      "epoch 139; iter: 0; batch classifier loss: 0.418005; batch adversarial loss: 0.536635\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352700; batch adversarial loss: 0.544349\n",
      "epoch 141; iter: 0; batch classifier loss: 0.432754; batch adversarial loss: 0.590519\n",
      "epoch 142; iter: 0; batch classifier loss: 0.411602; batch adversarial loss: 0.510890\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401996; batch adversarial loss: 0.490867\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371878; batch adversarial loss: 0.545910\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359052; batch adversarial loss: 0.535559\n",
      "epoch 146; iter: 0; batch classifier loss: 0.451098; batch adversarial loss: 0.601316\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390015; batch adversarial loss: 0.570486\n",
      "epoch 148; iter: 0; batch classifier loss: 0.308794; batch adversarial loss: 0.544085\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344578; batch adversarial loss: 0.562347\n",
      "epoch 150; iter: 0; batch classifier loss: 0.419569; batch adversarial loss: 0.518788\n",
      "epoch 151; iter: 0; batch classifier loss: 0.261212; batch adversarial loss: 0.526021\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391531; batch adversarial loss: 0.561733\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333571; batch adversarial loss: 0.518239\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340386; batch adversarial loss: 0.473323\n",
      "epoch 155; iter: 0; batch classifier loss: 0.414479; batch adversarial loss: 0.534672\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368855; batch adversarial loss: 0.589419\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323718; batch adversarial loss: 0.562175\n",
      "epoch 158; iter: 0; batch classifier loss: 0.491269; batch adversarial loss: 0.623242\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398579; batch adversarial loss: 0.526892\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357028; batch adversarial loss: 0.542895\n",
      "epoch 161; iter: 0; batch classifier loss: 0.423374; batch adversarial loss: 0.643123\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376618; batch adversarial loss: 0.551265\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356844; batch adversarial loss: 0.542955\n",
      "epoch 164; iter: 0; batch classifier loss: 0.316811; batch adversarial loss: 0.591422\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369383; batch adversarial loss: 0.545361\n",
      "epoch 166; iter: 0; batch classifier loss: 0.383959; batch adversarial loss: 0.517670\n",
      "epoch 167; iter: 0; batch classifier loss: 0.413648; batch adversarial loss: 0.651247\n",
      "epoch 168; iter: 0; batch classifier loss: 0.395098; batch adversarial loss: 0.526547\n",
      "epoch 169; iter: 0; batch classifier loss: 0.293424; batch adversarial loss: 0.552038\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339969; batch adversarial loss: 0.590132\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420546; batch adversarial loss: 0.535946\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344423; batch adversarial loss: 0.517463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.387717; batch adversarial loss: 0.581802\n",
      "epoch 174; iter: 0; batch classifier loss: 0.447685; batch adversarial loss: 0.517960\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384523; batch adversarial loss: 0.588772\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380124; batch adversarial loss: 0.616910\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391992; batch adversarial loss: 0.561363\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369070; batch adversarial loss: 0.579800\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345384; batch adversarial loss: 0.517671\n",
      "epoch 180; iter: 0; batch classifier loss: 0.348341; batch adversarial loss: 0.527097\n",
      "epoch 181; iter: 0; batch classifier loss: 0.327918; batch adversarial loss: 0.553156\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375739; batch adversarial loss: 0.445266\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429644; batch adversarial loss: 0.590630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363477; batch adversarial loss: 0.570856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.322531; batch adversarial loss: 0.608696\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328437; batch adversarial loss: 0.526613\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370393; batch adversarial loss: 0.631570\n",
      "epoch 188; iter: 0; batch classifier loss: 0.292855; batch adversarial loss: 0.517530\n",
      "epoch 189; iter: 0; batch classifier loss: 0.333917; batch adversarial loss: 0.516560\n",
      "epoch 190; iter: 0; batch classifier loss: 0.442132; batch adversarial loss: 0.500980\n",
      "epoch 191; iter: 0; batch classifier loss: 0.285130; batch adversarial loss: 0.607839\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369725; batch adversarial loss: 0.587897\n",
      "epoch 193; iter: 0; batch classifier loss: 0.334214; batch adversarial loss: 0.618451\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403923; batch adversarial loss: 0.596820\n",
      "epoch 195; iter: 0; batch classifier loss: 0.396062; batch adversarial loss: 0.572348\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334426; batch adversarial loss: 0.660213\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372199; batch adversarial loss: 0.545934\n",
      "epoch 198; iter: 0; batch classifier loss: 0.411091; batch adversarial loss: 0.535139\n",
      "epoch 199; iter: 0; batch classifier loss: 0.398825; batch adversarial loss: 0.500076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.809510; batch adversarial loss: 0.833752\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582175; batch adversarial loss: 0.773334\n",
      "epoch 2; iter: 0; batch classifier loss: 0.534577; batch adversarial loss: 0.768851\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615724; batch adversarial loss: 0.700639\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498862; batch adversarial loss: 0.672346\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527488; batch adversarial loss: 0.639488\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563348; batch adversarial loss: 0.656647\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533459; batch adversarial loss: 0.594551\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552753; batch adversarial loss: 0.596586\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533540; batch adversarial loss: 0.643997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566929; batch adversarial loss: 0.620856\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550614; batch adversarial loss: 0.603054\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491899; batch adversarial loss: 0.618488\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599107; batch adversarial loss: 0.537393\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517918; batch adversarial loss: 0.550332\n",
      "epoch 15; iter: 0; batch classifier loss: 0.441253; batch adversarial loss: 0.613386\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523030; batch adversarial loss: 0.598886\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477833; batch adversarial loss: 0.604498\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473336; batch adversarial loss: 0.558554\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512865; batch adversarial loss: 0.570972\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447466; batch adversarial loss: 0.529960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462686; batch adversarial loss: 0.575386\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470190; batch adversarial loss: 0.549869\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482199; batch adversarial loss: 0.502470\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435299; batch adversarial loss: 0.532312\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470478; batch adversarial loss: 0.552000\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560931; batch adversarial loss: 0.540939\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462150; batch adversarial loss: 0.513006\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464421; batch adversarial loss: 0.577643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484474; batch adversarial loss: 0.608167\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437346; batch adversarial loss: 0.611127\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485614; batch adversarial loss: 0.498057\n",
      "epoch 32; iter: 0; batch classifier loss: 0.543841; batch adversarial loss: 0.566578\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481761; batch adversarial loss: 0.575555\n",
      "epoch 34; iter: 0; batch classifier loss: 0.538097; batch adversarial loss: 0.539066\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456725; batch adversarial loss: 0.540084\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495106; batch adversarial loss: 0.570474\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450518; batch adversarial loss: 0.529349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468894; batch adversarial loss: 0.597433\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490296; batch adversarial loss: 0.537866\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507210; batch adversarial loss: 0.528660\n",
      "epoch 41; iter: 0; batch classifier loss: 0.386914; batch adversarial loss: 0.519701\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451162; batch adversarial loss: 0.545862\n",
      "epoch 43; iter: 0; batch classifier loss: 0.519490; batch adversarial loss: 0.468065\n",
      "epoch 44; iter: 0; batch classifier loss: 0.487266; batch adversarial loss: 0.659413\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451496; batch adversarial loss: 0.580502\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398761; batch adversarial loss: 0.562798\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399538; batch adversarial loss: 0.637736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.537789; batch adversarial loss: 0.536672\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427355; batch adversarial loss: 0.622142\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498641; batch adversarial loss: 0.527018\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433581; batch adversarial loss: 0.501674\n",
      "epoch 52; iter: 0; batch classifier loss: 0.525681; batch adversarial loss: 0.571101\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395766; batch adversarial loss: 0.578744\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437584; batch adversarial loss: 0.546163\n",
      "epoch 55; iter: 0; batch classifier loss: 0.438811; batch adversarial loss: 0.501175\n",
      "epoch 56; iter: 0; batch classifier loss: 0.610180; batch adversarial loss: 0.588413\n",
      "epoch 57; iter: 0; batch classifier loss: 0.455429; batch adversarial loss: 0.534663\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436403; batch adversarial loss: 0.493392\n",
      "epoch 59; iter: 0; batch classifier loss: 0.390668; batch adversarial loss: 0.597863\n",
      "epoch 60; iter: 0; batch classifier loss: 0.375483; batch adversarial loss: 0.555159\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467809; batch adversarial loss: 0.553161\n",
      "epoch 62; iter: 0; batch classifier loss: 0.475695; batch adversarial loss: 0.586945\n",
      "epoch 63; iter: 0; batch classifier loss: 0.480453; batch adversarial loss: 0.440206\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402610; batch adversarial loss: 0.605630\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410816; batch adversarial loss: 0.518504\n",
      "epoch 66; iter: 0; batch classifier loss: 0.351437; batch adversarial loss: 0.552970\n",
      "epoch 67; iter: 0; batch classifier loss: 0.484244; batch adversarial loss: 0.607424\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364730; batch adversarial loss: 0.546956\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447666; batch adversarial loss: 0.536202\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369909; batch adversarial loss: 0.535326\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471718; batch adversarial loss: 0.564167\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444263; batch adversarial loss: 0.528211\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428024; batch adversarial loss: 0.551812\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437407; batch adversarial loss: 0.596303\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420961; batch adversarial loss: 0.624312\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385904; batch adversarial loss: 0.588743\n",
      "epoch 77; iter: 0; batch classifier loss: 0.373162; batch adversarial loss: 0.580816\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419536; batch adversarial loss: 0.464281\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376756; batch adversarial loss: 0.572021\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476136; batch adversarial loss: 0.499588\n",
      "epoch 81; iter: 0; batch classifier loss: 0.362369; batch adversarial loss: 0.554569\n",
      "epoch 82; iter: 0; batch classifier loss: 0.301155; batch adversarial loss: 0.571679\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423825; batch adversarial loss: 0.474507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.462041; batch adversarial loss: 0.535810\n",
      "epoch 85; iter: 0; batch classifier loss: 0.322054; batch adversarial loss: 0.606596\n",
      "epoch 86; iter: 0; batch classifier loss: 0.455378; batch adversarial loss: 0.546477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.381360; batch adversarial loss: 0.606382\n",
      "epoch 88; iter: 0; batch classifier loss: 0.325538; batch adversarial loss: 0.554805\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433308; batch adversarial loss: 0.482713\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353684; batch adversarial loss: 0.571951\n",
      "epoch 91; iter: 0; batch classifier loss: 0.442950; batch adversarial loss: 0.591042\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398693; batch adversarial loss: 0.534547\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375329; batch adversarial loss: 0.588600\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422021; batch adversarial loss: 0.579790\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431960; batch adversarial loss: 0.544672\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422084; batch adversarial loss: 0.607965\n",
      "epoch 97; iter: 0; batch classifier loss: 0.403201; batch adversarial loss: 0.526322\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390643; batch adversarial loss: 0.649928\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375508; batch adversarial loss: 0.536721\n",
      "epoch 100; iter: 0; batch classifier loss: 0.321446; batch adversarial loss: 0.438830\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434996; batch adversarial loss: 0.553667\n",
      "epoch 102; iter: 0; batch classifier loss: 0.419478; batch adversarial loss: 0.640504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367311; batch adversarial loss: 0.572198\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398651; batch adversarial loss: 0.552808\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442051; batch adversarial loss: 0.456888\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378737; batch adversarial loss: 0.543145\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372198; batch adversarial loss: 0.517311\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385972; batch adversarial loss: 0.639605\n",
      "epoch 109; iter: 0; batch classifier loss: 0.339606; batch adversarial loss: 0.614476\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338265; batch adversarial loss: 0.534806\n",
      "epoch 111; iter: 0; batch classifier loss: 0.301766; batch adversarial loss: 0.553918\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387525; batch adversarial loss: 0.482935\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338775; batch adversarial loss: 0.587122\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428355; batch adversarial loss: 0.586286\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374910; batch adversarial loss: 0.580102\n",
      "epoch 116; iter: 0; batch classifier loss: 0.419870; batch adversarial loss: 0.562764\n",
      "epoch 117; iter: 0; batch classifier loss: 0.307472; batch adversarial loss: 0.560749\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367351; batch adversarial loss: 0.581205\n",
      "epoch 119; iter: 0; batch classifier loss: 0.318013; batch adversarial loss: 0.553848\n",
      "epoch 120; iter: 0; batch classifier loss: 0.335584; batch adversarial loss: 0.525629\n",
      "epoch 121; iter: 0; batch classifier loss: 0.424567; batch adversarial loss: 0.535365\n",
      "epoch 122; iter: 0; batch classifier loss: 0.461874; batch adversarial loss: 0.536815\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330218; batch adversarial loss: 0.563227\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336618; batch adversarial loss: 0.519160\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.589670\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358650; batch adversarial loss: 0.604519\n",
      "epoch 127; iter: 0; batch classifier loss: 0.306890; batch adversarial loss: 0.526326\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422389; batch adversarial loss: 0.543351\n",
      "epoch 129; iter: 0; batch classifier loss: 0.421253; batch adversarial loss: 0.621158\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359234; batch adversarial loss: 0.561309\n",
      "epoch 131; iter: 0; batch classifier loss: 0.369621; batch adversarial loss: 0.630708\n",
      "epoch 132; iter: 0; batch classifier loss: 0.241941; batch adversarial loss: 0.503163\n",
      "epoch 133; iter: 0; batch classifier loss: 0.368881; batch adversarial loss: 0.534298\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405705; batch adversarial loss: 0.508749\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364400; batch adversarial loss: 0.519952\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340461; batch adversarial loss: 0.544466\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359371; batch adversarial loss: 0.647307\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342130; batch adversarial loss: 0.569341\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334012; batch adversarial loss: 0.535559\n",
      "epoch 140; iter: 0; batch classifier loss: 0.372895; batch adversarial loss: 0.554662\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375420; batch adversarial loss: 0.525583\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418973; batch adversarial loss: 0.553869\n",
      "epoch 143; iter: 0; batch classifier loss: 0.422704; batch adversarial loss: 0.553406\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370752; batch adversarial loss: 0.578980\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407869; batch adversarial loss: 0.516102\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383426; batch adversarial loss: 0.544487\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382270; batch adversarial loss: 0.614647\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368485; batch adversarial loss: 0.499245\n",
      "epoch 149; iter: 0; batch classifier loss: 0.431129; batch adversarial loss: 0.615484\n",
      "epoch 150; iter: 0; batch classifier loss: 0.416138; batch adversarial loss: 0.538392\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347650; batch adversarial loss: 0.511986\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388513; batch adversarial loss: 0.537210\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334650; batch adversarial loss: 0.597434\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329555; batch adversarial loss: 0.552628\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370303; batch adversarial loss: 0.589114\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359699; batch adversarial loss: 0.535695\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361884; batch adversarial loss: 0.587987\n",
      "epoch 158; iter: 0; batch classifier loss: 0.399227; batch adversarial loss: 0.503701\n",
      "epoch 159; iter: 0; batch classifier loss: 0.421381; batch adversarial loss: 0.563619\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348856; batch adversarial loss: 0.553756\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358952; batch adversarial loss: 0.617440\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369222; batch adversarial loss: 0.551747\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380988; batch adversarial loss: 0.587464\n",
      "epoch 164; iter: 0; batch classifier loss: 0.370382; batch adversarial loss: 0.571164\n",
      "epoch 165; iter: 0; batch classifier loss: 0.429568; batch adversarial loss: 0.537912\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346324; batch adversarial loss: 0.587099\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344439; batch adversarial loss: 0.623765\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376062; batch adversarial loss: 0.561868\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405895; batch adversarial loss: 0.616549\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368434; batch adversarial loss: 0.563355\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383036; batch adversarial loss: 0.554489\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355619; batch adversarial loss: 0.608208\n",
      "epoch 173; iter: 0; batch classifier loss: 0.353145; batch adversarial loss: 0.571695\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366721; batch adversarial loss: 0.553246\n",
      "epoch 175; iter: 0; batch classifier loss: 0.370035; batch adversarial loss: 0.510150\n",
      "epoch 176; iter: 0; batch classifier loss: 0.386289; batch adversarial loss: 0.579357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321549; batch adversarial loss: 0.519732\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337612; batch adversarial loss: 0.613475\n",
      "epoch 179; iter: 0; batch classifier loss: 0.287633; batch adversarial loss: 0.545837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.341325; batch adversarial loss: 0.552651\n",
      "epoch 181; iter: 0; batch classifier loss: 0.438002; batch adversarial loss: 0.580460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393383; batch adversarial loss: 0.588698\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332439; batch adversarial loss: 0.525568\n",
      "epoch 184; iter: 0; batch classifier loss: 0.359965; batch adversarial loss: 0.568365\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366932; batch adversarial loss: 0.597575\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366061; batch adversarial loss: 0.613850\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388680; batch adversarial loss: 0.570454\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386652; batch adversarial loss: 0.537532\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361296; batch adversarial loss: 0.475808\n",
      "epoch 190; iter: 0; batch classifier loss: 0.247153; batch adversarial loss: 0.491395\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390642; batch adversarial loss: 0.577621\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362332; batch adversarial loss: 0.598662\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342641; batch adversarial loss: 0.570775\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342288; batch adversarial loss: 0.500392\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343497; batch adversarial loss: 0.535608\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374180; batch adversarial loss: 0.563147\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377695; batch adversarial loss: 0.467046\n",
      "epoch 198; iter: 0; batch classifier loss: 0.311810; batch adversarial loss: 0.709447\n",
      "epoch 199; iter: 0; batch classifier loss: 0.303919; batch adversarial loss: 0.527093\n",
      "epoch 0; iter: 0; batch classifier loss: 0.762877; batch adversarial loss: 0.940110\n",
      "epoch 1; iter: 0; batch classifier loss: 0.778509; batch adversarial loss: 0.999958\n",
      "epoch 2; iter: 0; batch classifier loss: 1.088377; batch adversarial loss: 1.050258\n",
      "epoch 3; iter: 0; batch classifier loss: 1.051852; batch adversarial loss: 0.943972\n",
      "epoch 4; iter: 0; batch classifier loss: 1.000017; batch adversarial loss: 0.847480\n",
      "epoch 5; iter: 0; batch classifier loss: 1.030476; batch adversarial loss: 0.783962\n",
      "epoch 6; iter: 0; batch classifier loss: 1.034485; batch adversarial loss: 0.742903\n",
      "epoch 7; iter: 0; batch classifier loss: 0.754684; batch adversarial loss: 0.663217\n",
      "epoch 8; iter: 0; batch classifier loss: 0.747698; batch adversarial loss: 0.620072\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545081; batch adversarial loss: 0.652071\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559465; batch adversarial loss: 0.623514\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564936; batch adversarial loss: 0.609229\n",
      "epoch 12; iter: 0; batch classifier loss: 0.479476; batch adversarial loss: 0.577658\n",
      "epoch 13; iter: 0; batch classifier loss: 0.592718; batch adversarial loss: 0.578630\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500301; batch adversarial loss: 0.580995\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562357; batch adversarial loss: 0.575970\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516851; batch adversarial loss: 0.564998\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512546; batch adversarial loss: 0.543550\n",
      "epoch 18; iter: 0; batch classifier loss: 0.538651; batch adversarial loss: 0.565996\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522282; batch adversarial loss: 0.583001\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454410; batch adversarial loss: 0.551722\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500618; batch adversarial loss: 0.576732\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456155; batch adversarial loss: 0.553660\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501287; batch adversarial loss: 0.577868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.447545; batch adversarial loss: 0.607876\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465551; batch adversarial loss: 0.572993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470738; batch adversarial loss: 0.576823\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506168; batch adversarial loss: 0.593227\n",
      "epoch 28; iter: 0; batch classifier loss: 0.426954; batch adversarial loss: 0.568791\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458889; batch adversarial loss: 0.572610\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513838; batch adversarial loss: 0.553829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498148; batch adversarial loss: 0.581449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.518694; batch adversarial loss: 0.602151\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522034; batch adversarial loss: 0.485029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466319; batch adversarial loss: 0.527637\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393159; batch adversarial loss: 0.563962\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442591; batch adversarial loss: 0.643617\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480813; batch adversarial loss: 0.533223\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432754; batch adversarial loss: 0.486731\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500327; batch adversarial loss: 0.495663\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505955; batch adversarial loss: 0.502321\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470199; batch adversarial loss: 0.521550\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414877; batch adversarial loss: 0.640577\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392177; batch adversarial loss: 0.526428\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410864; batch adversarial loss: 0.557231\n",
      "epoch 45; iter: 0; batch classifier loss: 0.493471; batch adversarial loss: 0.598601\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412123; batch adversarial loss: 0.542633\n",
      "epoch 47; iter: 0; batch classifier loss: 0.469360; batch adversarial loss: 0.520814\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450736; batch adversarial loss: 0.448418\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522154; batch adversarial loss: 0.519791\n",
      "epoch 50; iter: 0; batch classifier loss: 0.533778; batch adversarial loss: 0.545179\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405456; batch adversarial loss: 0.580385\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476506; batch adversarial loss: 0.590119\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480144; batch adversarial loss: 0.554213\n",
      "epoch 54; iter: 0; batch classifier loss: 0.478828; batch adversarial loss: 0.553688\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440905; batch adversarial loss: 0.536405\n",
      "epoch 56; iter: 0; batch classifier loss: 0.379343; batch adversarial loss: 0.456894\n",
      "epoch 57; iter: 0; batch classifier loss: 0.478902; batch adversarial loss: 0.562483\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388178; batch adversarial loss: 0.571393\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444038; batch adversarial loss: 0.589390\n",
      "epoch 60; iter: 0; batch classifier loss: 0.502275; batch adversarial loss: 0.499821\n",
      "epoch 61; iter: 0; batch classifier loss: 0.486530; batch adversarial loss: 0.562256\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444758; batch adversarial loss: 0.615964\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384244; batch adversarial loss: 0.597797\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407440; batch adversarial loss: 0.454539\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367313; batch adversarial loss: 0.553251\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426093; batch adversarial loss: 0.553912\n",
      "epoch 67; iter: 0; batch classifier loss: 0.383027; batch adversarial loss: 0.561851\n",
      "epoch 68; iter: 0; batch classifier loss: 0.331803; batch adversarial loss: 0.498709\n",
      "epoch 69; iter: 0; batch classifier loss: 0.335945; batch adversarial loss: 0.579410\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424565; batch adversarial loss: 0.543847\n",
      "epoch 71; iter: 0; batch classifier loss: 0.283520; batch adversarial loss: 0.527728\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396182; batch adversarial loss: 0.525914\n",
      "epoch 73; iter: 0; batch classifier loss: 0.350002; batch adversarial loss: 0.580634\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417577; batch adversarial loss: 0.652757\n",
      "epoch 75; iter: 0; batch classifier loss: 0.326572; batch adversarial loss: 0.516997\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370590; batch adversarial loss: 0.563899\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379764; batch adversarial loss: 0.571384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.406887; batch adversarial loss: 0.578066\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424378; batch adversarial loss: 0.544445\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431790; batch adversarial loss: 0.590333\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384533; batch adversarial loss: 0.464421\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356046; batch adversarial loss: 0.623614\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360604; batch adversarial loss: 0.570873\n",
      "epoch 84; iter: 0; batch classifier loss: 0.342594; batch adversarial loss: 0.562294\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405110; batch adversarial loss: 0.562144\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390054; batch adversarial loss: 0.536005\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405348; batch adversarial loss: 0.536085\n",
      "epoch 88; iter: 0; batch classifier loss: 0.314985; batch adversarial loss: 0.554258\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387739; batch adversarial loss: 0.552392\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397432; batch adversarial loss: 0.583246\n",
      "epoch 91; iter: 0; batch classifier loss: 0.461472; batch adversarial loss: 0.567281\n",
      "epoch 92; iter: 0; batch classifier loss: 0.302519; batch adversarial loss: 0.542531\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438620; batch adversarial loss: 0.564815\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381617; batch adversarial loss: 0.497734\n",
      "epoch 95; iter: 0; batch classifier loss: 0.336674; batch adversarial loss: 0.591687\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400665; batch adversarial loss: 0.563786\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394023; batch adversarial loss: 0.463786\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395389; batch adversarial loss: 0.596950\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339462; batch adversarial loss: 0.492055\n",
      "epoch 100; iter: 0; batch classifier loss: 0.428290; batch adversarial loss: 0.584571\n",
      "epoch 101; iter: 0; batch classifier loss: 0.339116; batch adversarial loss: 0.571684\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339995; batch adversarial loss: 0.554576\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407588; batch adversarial loss: 0.527793\n",
      "epoch 104; iter: 0; batch classifier loss: 0.379876; batch adversarial loss: 0.578279\n",
      "epoch 105; iter: 0; batch classifier loss: 0.376544; batch adversarial loss: 0.469227\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354312; batch adversarial loss: 0.516979\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413959; batch adversarial loss: 0.482698\n",
      "epoch 108; iter: 0; batch classifier loss: 0.319977; batch adversarial loss: 0.522590\n",
      "epoch 109; iter: 0; batch classifier loss: 0.276675; batch adversarial loss: 0.582488\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382405; batch adversarial loss: 0.474316\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388476; batch adversarial loss: 0.595575\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394282; batch adversarial loss: 0.555086\n",
      "epoch 113; iter: 0; batch classifier loss: 0.305187; batch adversarial loss: 0.537368\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372891; batch adversarial loss: 0.524358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366020; batch adversarial loss: 0.554260\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399074; batch adversarial loss: 0.559311\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345244; batch adversarial loss: 0.479592\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387350; batch adversarial loss: 0.527400\n",
      "epoch 119; iter: 0; batch classifier loss: 0.365860; batch adversarial loss: 0.552970\n",
      "epoch 120; iter: 0; batch classifier loss: 0.308009; batch adversarial loss: 0.597607\n",
      "epoch 121; iter: 0; batch classifier loss: 0.310154; batch adversarial loss: 0.517216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388362; batch adversarial loss: 0.553202\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355956; batch adversarial loss: 0.594613\n",
      "epoch 124; iter: 0; batch classifier loss: 0.292638; batch adversarial loss: 0.471915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375988; batch adversarial loss: 0.570240\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402319; batch adversarial loss: 0.528260\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348031; batch adversarial loss: 0.555358\n",
      "epoch 128; iter: 0; batch classifier loss: 0.341118; batch adversarial loss: 0.535429\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350155; batch adversarial loss: 0.609966\n",
      "epoch 130; iter: 0; batch classifier loss: 0.409765; batch adversarial loss: 0.565015\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383932; batch adversarial loss: 0.484855\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327243; batch adversarial loss: 0.552524\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399397; batch adversarial loss: 0.569570\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355048; batch adversarial loss: 0.489028\n",
      "epoch 135; iter: 0; batch classifier loss: 0.319937; batch adversarial loss: 0.559185\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399819; batch adversarial loss: 0.492027\n",
      "epoch 137; iter: 0; batch classifier loss: 0.301672; batch adversarial loss: 0.552479\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415908; batch adversarial loss: 0.492344\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363589; batch adversarial loss: 0.482034\n",
      "epoch 140; iter: 0; batch classifier loss: 0.388927; batch adversarial loss: 0.447403\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377027; batch adversarial loss: 0.472022\n",
      "epoch 142; iter: 0; batch classifier loss: 0.344466; batch adversarial loss: 0.566047\n",
      "epoch 143; iter: 0; batch classifier loss: 0.304711; batch adversarial loss: 0.591517\n",
      "epoch 144; iter: 0; batch classifier loss: 0.421673; batch adversarial loss: 0.492710\n",
      "epoch 145; iter: 0; batch classifier loss: 0.310617; batch adversarial loss: 0.575264\n",
      "epoch 146; iter: 0; batch classifier loss: 0.326810; batch adversarial loss: 0.524745\n",
      "epoch 147; iter: 0; batch classifier loss: 0.264009; batch adversarial loss: 0.597640\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392865; batch adversarial loss: 0.572617\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355727; batch adversarial loss: 0.542110\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353800; batch adversarial loss: 0.481133\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352719; batch adversarial loss: 0.587366\n",
      "epoch 152; iter: 0; batch classifier loss: 0.303868; batch adversarial loss: 0.562792\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339639; batch adversarial loss: 0.588927\n",
      "epoch 154; iter: 0; batch classifier loss: 0.445824; batch adversarial loss: 0.545957\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412777; batch adversarial loss: 0.590351\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355814; batch adversarial loss: 0.582236\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405941; batch adversarial loss: 0.545594\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370240; batch adversarial loss: 0.560856\n",
      "epoch 159; iter: 0; batch classifier loss: 0.409389; batch adversarial loss: 0.561674\n",
      "epoch 160; iter: 0; batch classifier loss: 0.257886; batch adversarial loss: 0.509062\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393921; batch adversarial loss: 0.589034\n",
      "epoch 162; iter: 0; batch classifier loss: 0.296650; batch adversarial loss: 0.500153\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375929; batch adversarial loss: 0.544852\n",
      "epoch 164; iter: 0; batch classifier loss: 0.419518; batch adversarial loss: 0.583558\n",
      "epoch 165; iter: 0; batch classifier loss: 0.391887; batch adversarial loss: 0.583267\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382924; batch adversarial loss: 0.505564\n",
      "epoch 167; iter: 0; batch classifier loss: 0.293546; batch adversarial loss: 0.582133\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315097; batch adversarial loss: 0.588409\n",
      "epoch 169; iter: 0; batch classifier loss: 0.280253; batch adversarial loss: 0.549410\n",
      "epoch 170; iter: 0; batch classifier loss: 0.277302; batch adversarial loss: 0.586291\n",
      "epoch 171; iter: 0; batch classifier loss: 0.308083; batch adversarial loss: 0.587296\n",
      "epoch 172; iter: 0; batch classifier loss: 0.396349; batch adversarial loss: 0.542647\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372468; batch adversarial loss: 0.512636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.337274; batch adversarial loss: 0.609270\n",
      "epoch 175; iter: 0; batch classifier loss: 0.284287; batch adversarial loss: 0.579396\n",
      "epoch 176; iter: 0; batch classifier loss: 0.302432; batch adversarial loss: 0.534555\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316365; batch adversarial loss: 0.601177\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307938; batch adversarial loss: 0.553885\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394315; batch adversarial loss: 0.536884\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395421; batch adversarial loss: 0.506811\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336622; batch adversarial loss: 0.564127\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379185; batch adversarial loss: 0.526544\n",
      "epoch 183; iter: 0; batch classifier loss: 0.303642; batch adversarial loss: 0.529324\n",
      "epoch 184; iter: 0; batch classifier loss: 0.421121; batch adversarial loss: 0.594454\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362355; batch adversarial loss: 0.499991\n",
      "epoch 186; iter: 0; batch classifier loss: 0.246009; batch adversarial loss: 0.562326\n",
      "epoch 187; iter: 0; batch classifier loss: 0.309232; batch adversarial loss: 0.608323\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386694; batch adversarial loss: 0.464586\n",
      "epoch 189; iter: 0; batch classifier loss: 0.306887; batch adversarial loss: 0.562410\n",
      "epoch 190; iter: 0; batch classifier loss: 0.397395; batch adversarial loss: 0.647712\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365212; batch adversarial loss: 0.626146\n",
      "epoch 192; iter: 0; batch classifier loss: 0.307377; batch adversarial loss: 0.509821\n",
      "epoch 193; iter: 0; batch classifier loss: 0.229407; batch adversarial loss: 0.562711\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279073; batch adversarial loss: 0.452065\n",
      "epoch 195; iter: 0; batch classifier loss: 0.391341; batch adversarial loss: 0.590134\n",
      "epoch 196; iter: 0; batch classifier loss: 0.384926; batch adversarial loss: 0.549859\n",
      "epoch 197; iter: 0; batch classifier loss: 0.295541; batch adversarial loss: 0.551950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.260046; batch adversarial loss: 0.649398\n",
      "epoch 199; iter: 0; batch classifier loss: 0.263303; batch adversarial loss: 0.546324\n",
      "epoch 0; iter: 0; batch classifier loss: 0.646748; batch adversarial loss: 0.655724\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571747; batch adversarial loss: 0.623809\n",
      "epoch 2; iter: 0; batch classifier loss: 0.518415; batch adversarial loss: 0.631519\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629889; batch adversarial loss: 0.564181\n",
      "epoch 4; iter: 0; batch classifier loss: 0.478360; batch adversarial loss: 0.589780\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551743; batch adversarial loss: 0.564540\n",
      "epoch 6; iter: 0; batch classifier loss: 0.642954; batch adversarial loss: 0.587636\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583837; batch adversarial loss: 0.567698\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513674; batch adversarial loss: 0.595947\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575126; batch adversarial loss: 0.632992\n",
      "epoch 10; iter: 0; batch classifier loss: 0.625936; batch adversarial loss: 0.606131\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570171; batch adversarial loss: 0.591281\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575104; batch adversarial loss: 0.621080\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563673; batch adversarial loss: 0.588408\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528183; batch adversarial loss: 0.507371\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543965; batch adversarial loss: 0.552257\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479920; batch adversarial loss: 0.570125\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511317; batch adversarial loss: 0.603134\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484862; batch adversarial loss: 0.595814\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443084; batch adversarial loss: 0.521655\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528040; batch adversarial loss: 0.527597\n",
      "epoch 21; iter: 0; batch classifier loss: 0.624648; batch adversarial loss: 0.486064\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507734; batch adversarial loss: 0.537288\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490031; batch adversarial loss: 0.564984\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547128; batch adversarial loss: 0.674111\n",
      "epoch 25; iter: 0; batch classifier loss: 0.414488; batch adversarial loss: 0.534719\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512051; batch adversarial loss: 0.508286\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517478; batch adversarial loss: 0.543161\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439194; batch adversarial loss: 0.545572\n",
      "epoch 29; iter: 0; batch classifier loss: 0.542637; batch adversarial loss: 0.480619\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509084; batch adversarial loss: 0.541043\n",
      "epoch 31; iter: 0; batch classifier loss: 0.518091; batch adversarial loss: 0.558632\n",
      "epoch 32; iter: 0; batch classifier loss: 0.480022; batch adversarial loss: 0.562285\n",
      "epoch 33; iter: 0; batch classifier loss: 0.371427; batch adversarial loss: 0.535535\n",
      "epoch 34; iter: 0; batch classifier loss: 0.517404; batch adversarial loss: 0.512805\n",
      "epoch 35; iter: 0; batch classifier loss: 0.505666; batch adversarial loss: 0.493895\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415471; batch adversarial loss: 0.589058\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472179; batch adversarial loss: 0.575845\n",
      "epoch 38; iter: 0; batch classifier loss: 0.513823; batch adversarial loss: 0.636794\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481011; batch adversarial loss: 0.629834\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431050; batch adversarial loss: 0.524456\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444964; batch adversarial loss: 0.599867\n",
      "epoch 42; iter: 0; batch classifier loss: 0.384547; batch adversarial loss: 0.601793\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413295; batch adversarial loss: 0.589848\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501682; batch adversarial loss: 0.499371\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374324; batch adversarial loss: 0.573408\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505761; batch adversarial loss: 0.581677\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429627; batch adversarial loss: 0.489882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473540; batch adversarial loss: 0.526207\n",
      "epoch 49; iter: 0; batch classifier loss: 0.498576; batch adversarial loss: 0.703089\n",
      "epoch 50; iter: 0; batch classifier loss: 0.381013; batch adversarial loss: 0.497417\n",
      "epoch 51; iter: 0; batch classifier loss: 0.412155; batch adversarial loss: 0.488161\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451493; batch adversarial loss: 0.554108\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432652; batch adversarial loss: 0.600554\n",
      "epoch 54; iter: 0; batch classifier loss: 0.544678; batch adversarial loss: 0.620201\n",
      "epoch 55; iter: 0; batch classifier loss: 0.356932; batch adversarial loss: 0.572268\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394155; batch adversarial loss: 0.544324\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441133; batch adversarial loss: 0.526144\n",
      "epoch 58; iter: 0; batch classifier loss: 0.383399; batch adversarial loss: 0.555206\n",
      "epoch 59; iter: 0; batch classifier loss: 0.456152; batch adversarial loss: 0.554144\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394504; batch adversarial loss: 0.564513\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386719; batch adversarial loss: 0.536331\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449412; batch adversarial loss: 0.488053\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396862; batch adversarial loss: 0.469923\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427490; batch adversarial loss: 0.440840\n",
      "epoch 65; iter: 0; batch classifier loss: 0.472170; batch adversarial loss: 0.524325\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443901; batch adversarial loss: 0.581872\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447344; batch adversarial loss: 0.573156\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402141; batch adversarial loss: 0.534537\n",
      "epoch 69; iter: 0; batch classifier loss: 0.485247; batch adversarial loss: 0.519192\n",
      "epoch 70; iter: 0; batch classifier loss: 0.469755; batch adversarial loss: 0.619931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.414405; batch adversarial loss: 0.526532\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369497; batch adversarial loss: 0.516568\n",
      "epoch 73; iter: 0; batch classifier loss: 0.455517; batch adversarial loss: 0.545098\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446149; batch adversarial loss: 0.516960\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408518; batch adversarial loss: 0.628939\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376072; batch adversarial loss: 0.590506\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396338; batch adversarial loss: 0.497950\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404980; batch adversarial loss: 0.637739\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393789; batch adversarial loss: 0.535753\n",
      "epoch 80; iter: 0; batch classifier loss: 0.453560; batch adversarial loss: 0.545653\n",
      "epoch 81; iter: 0; batch classifier loss: 0.412850; batch adversarial loss: 0.553689\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376059; batch adversarial loss: 0.431990\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392028; batch adversarial loss: 0.479260\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408598; batch adversarial loss: 0.515879\n",
      "epoch 85; iter: 0; batch classifier loss: 0.447981; batch adversarial loss: 0.535871\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378686; batch adversarial loss: 0.553465\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429311; batch adversarial loss: 0.545218\n",
      "epoch 88; iter: 0; batch classifier loss: 0.343474; batch adversarial loss: 0.525837\n",
      "epoch 89; iter: 0; batch classifier loss: 0.437477; batch adversarial loss: 0.546224\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386445; batch adversarial loss: 0.571696\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354316; batch adversarial loss: 0.582600\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428430; batch adversarial loss: 0.545738\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384235; batch adversarial loss: 0.553805\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397647; batch adversarial loss: 0.526782\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407966; batch adversarial loss: 0.582927\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381354; batch adversarial loss: 0.601597\n",
      "epoch 97; iter: 0; batch classifier loss: 0.380856; batch adversarial loss: 0.497979\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393631; batch adversarial loss: 0.524981\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403049; batch adversarial loss: 0.508383\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397593; batch adversarial loss: 0.582513\n",
      "epoch 101; iter: 0; batch classifier loss: 0.451331; batch adversarial loss: 0.563753\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404281; batch adversarial loss: 0.505813\n",
      "epoch 103; iter: 0; batch classifier loss: 0.428485; batch adversarial loss: 0.571817\n",
      "epoch 104; iter: 0; batch classifier loss: 0.450291; batch adversarial loss: 0.544909\n",
      "epoch 105; iter: 0; batch classifier loss: 0.456427; batch adversarial loss: 0.506652\n",
      "epoch 106; iter: 0; batch classifier loss: 0.324089; batch adversarial loss: 0.488756\n",
      "epoch 107; iter: 0; batch classifier loss: 0.446431; batch adversarial loss: 0.535574\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317371; batch adversarial loss: 0.638110\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370496; batch adversarial loss: 0.545935\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347273; batch adversarial loss: 0.517376\n",
      "epoch 111; iter: 0; batch classifier loss: 0.446202; batch adversarial loss: 0.497490\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359526; batch adversarial loss: 0.497069\n",
      "epoch 113; iter: 0; batch classifier loss: 0.478977; batch adversarial loss: 0.497212\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403056; batch adversarial loss: 0.534863\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328980; batch adversarial loss: 0.551710\n",
      "epoch 116; iter: 0; batch classifier loss: 0.434603; batch adversarial loss: 0.488419\n",
      "epoch 117; iter: 0; batch classifier loss: 0.359062; batch adversarial loss: 0.525515\n",
      "epoch 118; iter: 0; batch classifier loss: 0.454368; batch adversarial loss: 0.647178\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392463; batch adversarial loss: 0.506417\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400748; batch adversarial loss: 0.486820\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356280; batch adversarial loss: 0.422929\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363601; batch adversarial loss: 0.515828\n",
      "epoch 123; iter: 0; batch classifier loss: 0.446867; batch adversarial loss: 0.543579\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342702; batch adversarial loss: 0.555230\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395090; batch adversarial loss: 0.581781\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317792; batch adversarial loss: 0.526455\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390154; batch adversarial loss: 0.553166\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360447; batch adversarial loss: 0.632082\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374851; batch adversarial loss: 0.524327\n",
      "epoch 130; iter: 0; batch classifier loss: 0.434583; batch adversarial loss: 0.582643\n",
      "epoch 131; iter: 0; batch classifier loss: 0.455786; batch adversarial loss: 0.535418\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369985; batch adversarial loss: 0.470797\n",
      "epoch 133; iter: 0; batch classifier loss: 0.429093; batch adversarial loss: 0.459740\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362302; batch adversarial loss: 0.562336\n",
      "epoch 135; iter: 0; batch classifier loss: 0.393776; batch adversarial loss: 0.422860\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322713; batch adversarial loss: 0.545282\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386971; batch adversarial loss: 0.535417\n",
      "epoch 138; iter: 0; batch classifier loss: 0.496764; batch adversarial loss: 0.553286\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415100; batch adversarial loss: 0.488739\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358328; batch adversarial loss: 0.544957\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339940; batch adversarial loss: 0.479174\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403057; batch adversarial loss: 0.496700\n",
      "epoch 143; iter: 0; batch classifier loss: 0.464437; batch adversarial loss: 0.573222\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350552; batch adversarial loss: 0.534568\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359946; batch adversarial loss: 0.534559\n",
      "epoch 146; iter: 0; batch classifier loss: 0.431042; batch adversarial loss: 0.620959\n",
      "epoch 147; iter: 0; batch classifier loss: 0.419064; batch adversarial loss: 0.507599\n",
      "epoch 148; iter: 0; batch classifier loss: 0.431286; batch adversarial loss: 0.534221\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415948; batch adversarial loss: 0.440736\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358088; batch adversarial loss: 0.561809\n",
      "epoch 151; iter: 0; batch classifier loss: 0.404336; batch adversarial loss: 0.518721\n",
      "epoch 152; iter: 0; batch classifier loss: 0.423938; batch adversarial loss: 0.459207\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355358; batch adversarial loss: 0.488522\n",
      "epoch 154; iter: 0; batch classifier loss: 0.318805; batch adversarial loss: 0.503074\n",
      "epoch 155; iter: 0; batch classifier loss: 0.310822; batch adversarial loss: 0.581821\n",
      "epoch 156; iter: 0; batch classifier loss: 0.434194; batch adversarial loss: 0.563790\n",
      "epoch 157; iter: 0; batch classifier loss: 0.438104; batch adversarial loss: 0.507386\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348938; batch adversarial loss: 0.590377\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334904; batch adversarial loss: 0.564747\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374818; batch adversarial loss: 0.507816\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366631; batch adversarial loss: 0.570482\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323991; batch adversarial loss: 0.563188\n",
      "epoch 163; iter: 0; batch classifier loss: 0.387430; batch adversarial loss: 0.533171\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386160; batch adversarial loss: 0.503468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387889; batch adversarial loss: 0.468867\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344418; batch adversarial loss: 0.575237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.339006; batch adversarial loss: 0.486558\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340129; batch adversarial loss: 0.523491\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385451; batch adversarial loss: 0.553489\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333072; batch adversarial loss: 0.422111\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320003; batch adversarial loss: 0.534241\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392819; batch adversarial loss: 0.515387\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316532; batch adversarial loss: 0.525388\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395652; batch adversarial loss: 0.451620\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382846; batch adversarial loss: 0.554017\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367170; batch adversarial loss: 0.457448\n",
      "epoch 177; iter: 0; batch classifier loss: 0.448498; batch adversarial loss: 0.496507\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314054; batch adversarial loss: 0.506355\n",
      "epoch 179; iter: 0; batch classifier loss: 0.396110; batch adversarial loss: 0.590107\n",
      "epoch 180; iter: 0; batch classifier loss: 0.412530; batch adversarial loss: 0.535302\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410990; batch adversarial loss: 0.544190\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337989; batch adversarial loss: 0.508235\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356254; batch adversarial loss: 0.543801\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356790; batch adversarial loss: 0.486970\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371036; batch adversarial loss: 0.471421\n",
      "epoch 186; iter: 0; batch classifier loss: 0.425401; batch adversarial loss: 0.449613\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305204; batch adversarial loss: 0.496884\n",
      "epoch 188; iter: 0; batch classifier loss: 0.326640; batch adversarial loss: 0.543473\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344852; batch adversarial loss: 0.552785\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351624; batch adversarial loss: 0.581293\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330738; batch adversarial loss: 0.554238\n",
      "epoch 192; iter: 0; batch classifier loss: 0.434852; batch adversarial loss: 0.449267\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351749; batch adversarial loss: 0.508265\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331983; batch adversarial loss: 0.535175\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354219; batch adversarial loss: 0.542690\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378760; batch adversarial loss: 0.514224\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319932; batch adversarial loss: 0.523963\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361294; batch adversarial loss: 0.544298\n",
      "epoch 199; iter: 0; batch classifier loss: 0.299198; batch adversarial loss: 0.535712\n",
      "epoch 0; iter: 0; batch classifier loss: 0.742985; batch adversarial loss: 0.834633\n",
      "epoch 1; iter: 0; batch classifier loss: 0.650398; batch adversarial loss: 0.744289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581999; batch adversarial loss: 0.686543\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566486; batch adversarial loss: 0.677221\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552116; batch adversarial loss: 0.653696\n",
      "epoch 5; iter: 0; batch classifier loss: 0.677184; batch adversarial loss: 0.635637\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571241; batch adversarial loss: 0.664350\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566664; batch adversarial loss: 0.620321\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557124; batch adversarial loss: 0.616680\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502993; batch adversarial loss: 0.591533\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499587; batch adversarial loss: 0.584809\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531504; batch adversarial loss: 0.621712\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505276; batch adversarial loss: 0.553642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519233; batch adversarial loss: 0.584233\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473311; batch adversarial loss: 0.653969\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589644; batch adversarial loss: 0.639619\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525665; batch adversarial loss: 0.554035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541127; batch adversarial loss: 0.487206\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490317; batch adversarial loss: 0.547257\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518004; batch adversarial loss: 0.588451\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465337; batch adversarial loss: 0.541483\n",
      "epoch 21; iter: 0; batch classifier loss: 0.557645; batch adversarial loss: 0.589484\n",
      "epoch 22; iter: 0; batch classifier loss: 0.551921; batch adversarial loss: 0.534785\n",
      "epoch 23; iter: 0; batch classifier loss: 0.556558; batch adversarial loss: 0.478307\n",
      "epoch 24; iter: 0; batch classifier loss: 0.560063; batch adversarial loss: 0.585612\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487749; batch adversarial loss: 0.525411\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519991; batch adversarial loss: 0.567684\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495709; batch adversarial loss: 0.570093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414525; batch adversarial loss: 0.513628\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436178; batch adversarial loss: 0.558634\n",
      "epoch 30; iter: 0; batch classifier loss: 0.413046; batch adversarial loss: 0.560630\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486998; batch adversarial loss: 0.608398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484887; batch adversarial loss: 0.622968\n",
      "epoch 33; iter: 0; batch classifier loss: 0.398466; batch adversarial loss: 0.473784\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445172; batch adversarial loss: 0.537248\n",
      "epoch 35; iter: 0; batch classifier loss: 0.531305; batch adversarial loss: 0.523412\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447890; batch adversarial loss: 0.587676\n",
      "epoch 37; iter: 0; batch classifier loss: 0.543409; batch adversarial loss: 0.587205\n",
      "epoch 38; iter: 0; batch classifier loss: 0.538524; batch adversarial loss: 0.614884\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470636; batch adversarial loss: 0.468156\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466891; batch adversarial loss: 0.544003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446595; batch adversarial loss: 0.575425\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471821; batch adversarial loss: 0.561264\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413511; batch adversarial loss: 0.498579\n",
      "epoch 44; iter: 0; batch classifier loss: 0.384253; batch adversarial loss: 0.608426\n",
      "epoch 45; iter: 0; batch classifier loss: 0.406739; batch adversarial loss: 0.568195\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483255; batch adversarial loss: 0.516999\n",
      "epoch 47; iter: 0; batch classifier loss: 0.518184; batch adversarial loss: 0.578038\n",
      "epoch 48; iter: 0; batch classifier loss: 0.519962; batch adversarial loss: 0.678512\n",
      "epoch 49; iter: 0; batch classifier loss: 0.360907; batch adversarial loss: 0.500760\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442162; batch adversarial loss: 0.542585\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411912; batch adversarial loss: 0.556896\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386097; batch adversarial loss: 0.587849\n",
      "epoch 53; iter: 0; batch classifier loss: 0.520835; batch adversarial loss: 0.527745\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433156; batch adversarial loss: 0.498424\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430463; batch adversarial loss: 0.550039\n",
      "epoch 56; iter: 0; batch classifier loss: 0.472612; batch adversarial loss: 0.525478\n",
      "epoch 57; iter: 0; batch classifier loss: 0.362925; batch adversarial loss: 0.626941\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409863; batch adversarial loss: 0.560505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418341; batch adversarial loss: 0.502302\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456484; batch adversarial loss: 0.551723\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371481; batch adversarial loss: 0.563334\n",
      "epoch 62; iter: 0; batch classifier loss: 0.461292; batch adversarial loss: 0.588611\n",
      "epoch 63; iter: 0; batch classifier loss: 0.475052; batch adversarial loss: 0.482863\n",
      "epoch 64; iter: 0; batch classifier loss: 0.357192; batch adversarial loss: 0.562462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.377739; batch adversarial loss: 0.565004\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378723; batch adversarial loss: 0.532072\n",
      "epoch 67; iter: 0; batch classifier loss: 0.492593; batch adversarial loss: 0.537072\n",
      "epoch 68; iter: 0; batch classifier loss: 0.467864; batch adversarial loss: 0.534342\n",
      "epoch 69; iter: 0; batch classifier loss: 0.348288; batch adversarial loss: 0.619246\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403959; batch adversarial loss: 0.507564\n",
      "epoch 71; iter: 0; batch classifier loss: 0.459423; batch adversarial loss: 0.533333\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413452; batch adversarial loss: 0.579122\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394321; batch adversarial loss: 0.639140\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437613; batch adversarial loss: 0.591145\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353839; batch adversarial loss: 0.543663\n",
      "epoch 76; iter: 0; batch classifier loss: 0.350400; batch adversarial loss: 0.516380\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360699; batch adversarial loss: 0.485842\n",
      "epoch 78; iter: 0; batch classifier loss: 0.316118; batch adversarial loss: 0.563299\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379540; batch adversarial loss: 0.595999\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421412; batch adversarial loss: 0.492604\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360317; batch adversarial loss: 0.489755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374137; batch adversarial loss: 0.588105\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409407; batch adversarial loss: 0.604703\n",
      "epoch 84; iter: 0; batch classifier loss: 0.465466; batch adversarial loss: 0.453223\n",
      "epoch 85; iter: 0; batch classifier loss: 0.476179; batch adversarial loss: 0.632357\n",
      "epoch 86; iter: 0; batch classifier loss: 0.450860; batch adversarial loss: 0.545733\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440288; batch adversarial loss: 0.526355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354136; batch adversarial loss: 0.526717\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415740; batch adversarial loss: 0.491043\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393275; batch adversarial loss: 0.516081\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361271; batch adversarial loss: 0.506505\n",
      "epoch 92; iter: 0; batch classifier loss: 0.464342; batch adversarial loss: 0.517258\n",
      "epoch 93; iter: 0; batch classifier loss: 0.318606; batch adversarial loss: 0.554497\n",
      "epoch 94; iter: 0; batch classifier loss: 0.340878; batch adversarial loss: 0.498575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.480027; batch adversarial loss: 0.531552\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412060; batch adversarial loss: 0.527016\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420271; batch adversarial loss: 0.562594\n",
      "epoch 98; iter: 0; batch classifier loss: 0.311379; batch adversarial loss: 0.565075\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354679; batch adversarial loss: 0.622969\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397498; batch adversarial loss: 0.547875\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374883; batch adversarial loss: 0.472574\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366738; batch adversarial loss: 0.505854\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402687; batch adversarial loss: 0.647225\n",
      "epoch 104; iter: 0; batch classifier loss: 0.382255; batch adversarial loss: 0.560643\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385059; batch adversarial loss: 0.502875\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387391; batch adversarial loss: 0.564591\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400804; batch adversarial loss: 0.569965\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413499; batch adversarial loss: 0.569460\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430727; batch adversarial loss: 0.576980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.432190; batch adversarial loss: 0.493506\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428187; batch adversarial loss: 0.488214\n",
      "epoch 112; iter: 0; batch classifier loss: 0.421242; batch adversarial loss: 0.538182\n",
      "epoch 113; iter: 0; batch classifier loss: 0.434848; batch adversarial loss: 0.595922\n",
      "epoch 114; iter: 0; batch classifier loss: 0.445830; batch adversarial loss: 0.530387\n",
      "epoch 115; iter: 0; batch classifier loss: 0.312365; batch adversarial loss: 0.574079\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390366; batch adversarial loss: 0.513781\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390163; batch adversarial loss: 0.587260\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392979; batch adversarial loss: 0.460608\n",
      "epoch 119; iter: 0; batch classifier loss: 0.343975; batch adversarial loss: 0.589235\n",
      "epoch 120; iter: 0; batch classifier loss: 0.438801; batch adversarial loss: 0.593631\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364460; batch adversarial loss: 0.490389\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369871; batch adversarial loss: 0.505365\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413465; batch adversarial loss: 0.582655\n",
      "epoch 124; iter: 0; batch classifier loss: 0.300936; batch adversarial loss: 0.587195\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402503; batch adversarial loss: 0.555514\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369455; batch adversarial loss: 0.510858\n",
      "epoch 127; iter: 0; batch classifier loss: 0.409163; batch adversarial loss: 0.590956\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399681; batch adversarial loss: 0.486326\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412750; batch adversarial loss: 0.556575\n",
      "epoch 130; iter: 0; batch classifier loss: 0.434852; batch adversarial loss: 0.498813\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351477; batch adversarial loss: 0.541122\n",
      "epoch 132; iter: 0; batch classifier loss: 0.292388; batch adversarial loss: 0.614748\n",
      "epoch 133; iter: 0; batch classifier loss: 0.313506; batch adversarial loss: 0.517557\n",
      "epoch 134; iter: 0; batch classifier loss: 0.429333; batch adversarial loss: 0.528610\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347329; batch adversarial loss: 0.544963\n",
      "epoch 136; iter: 0; batch classifier loss: 0.454306; batch adversarial loss: 0.595802\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340291; batch adversarial loss: 0.553399\n",
      "epoch 138; iter: 0; batch classifier loss: 0.416406; batch adversarial loss: 0.535740\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335100; batch adversarial loss: 0.504420\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373298; batch adversarial loss: 0.468433\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367006; batch adversarial loss: 0.490149\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340464; batch adversarial loss: 0.544712\n",
      "epoch 143; iter: 0; batch classifier loss: 0.316948; batch adversarial loss: 0.483237\n",
      "epoch 144; iter: 0; batch classifier loss: 0.319510; batch adversarial loss: 0.580857\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387543; batch adversarial loss: 0.555326\n",
      "epoch 146; iter: 0; batch classifier loss: 0.478099; batch adversarial loss: 0.569432\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353442; batch adversarial loss: 0.595122\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327605; batch adversarial loss: 0.535815\n",
      "epoch 149; iter: 0; batch classifier loss: 0.451768; batch adversarial loss: 0.496683\n",
      "epoch 150; iter: 0; batch classifier loss: 0.402318; batch adversarial loss: 0.583916\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362510; batch adversarial loss: 0.544896\n",
      "epoch 152; iter: 0; batch classifier loss: 0.328915; batch adversarial loss: 0.549930\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367448; batch adversarial loss: 0.525440\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336297; batch adversarial loss: 0.533468\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408160; batch adversarial loss: 0.554819\n",
      "epoch 156; iter: 0; batch classifier loss: 0.406392; batch adversarial loss: 0.524213\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418329; batch adversarial loss: 0.542472\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333736; batch adversarial loss: 0.573586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290467; batch adversarial loss: 0.590163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.587696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.371711; batch adversarial loss: 0.516395\n",
      "epoch 162; iter: 0; batch classifier loss: 0.396348; batch adversarial loss: 0.555947\n",
      "epoch 163; iter: 0; batch classifier loss: 0.472550; batch adversarial loss: 0.593547\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312782; batch adversarial loss: 0.428517\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348573; batch adversarial loss: 0.476727\n",
      "epoch 166; iter: 0; batch classifier loss: 0.289210; batch adversarial loss: 0.469438\n",
      "epoch 167; iter: 0; batch classifier loss: 0.310953; batch adversarial loss: 0.517867\n",
      "epoch 168; iter: 0; batch classifier loss: 0.346030; batch adversarial loss: 0.653742\n",
      "epoch 169; iter: 0; batch classifier loss: 0.419694; batch adversarial loss: 0.589563\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364716; batch adversarial loss: 0.568819\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374481; batch adversarial loss: 0.493299\n",
      "epoch 172; iter: 0; batch classifier loss: 0.319756; batch adversarial loss: 0.596645\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338396; batch adversarial loss: 0.553293\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336914; batch adversarial loss: 0.565266\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400419; batch adversarial loss: 0.429106\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328215; batch adversarial loss: 0.513718\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406555; batch adversarial loss: 0.552953\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341060; batch adversarial loss: 0.507398\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369699; batch adversarial loss: 0.552853\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356396; batch adversarial loss: 0.592083\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345110; batch adversarial loss: 0.481212\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341418; batch adversarial loss: 0.571168\n",
      "epoch 183; iter: 0; batch classifier loss: 0.328798; batch adversarial loss: 0.558697\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319858; batch adversarial loss: 0.561801\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383761; batch adversarial loss: 0.526870\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410718; batch adversarial loss: 0.475409\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319272; batch adversarial loss: 0.618308\n",
      "epoch 188; iter: 0; batch classifier loss: 0.417966; batch adversarial loss: 0.618940\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368611; batch adversarial loss: 0.556720\n",
      "epoch 190; iter: 0; batch classifier loss: 0.295278; batch adversarial loss: 0.581806\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382378; batch adversarial loss: 0.526154\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344174; batch adversarial loss: 0.580886\n",
      "epoch 193; iter: 0; batch classifier loss: 0.384559; batch adversarial loss: 0.543716\n",
      "epoch 194; iter: 0; batch classifier loss: 0.364583; batch adversarial loss: 0.603862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.288353; batch adversarial loss: 0.589875\n",
      "epoch 196; iter: 0; batch classifier loss: 0.437630; batch adversarial loss: 0.480863\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349873; batch adversarial loss: 0.417530\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328308; batch adversarial loss: 0.488926\n",
      "epoch 199; iter: 0; batch classifier loss: 0.422541; batch adversarial loss: 0.614608\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691731; batch adversarial loss: 0.648981\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546080; batch adversarial loss: 0.704907\n",
      "epoch 2; iter: 0; batch classifier loss: 0.584711; batch adversarial loss: 0.637286\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558419; batch adversarial loss: 0.628922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551834; batch adversarial loss: 0.691562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548240; batch adversarial loss: 0.578029\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563062; batch adversarial loss: 0.647919\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542682; batch adversarial loss: 0.666721\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536154; batch adversarial loss: 0.618265\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586417; batch adversarial loss: 0.587621\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484433; batch adversarial loss: 0.610789\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553974; batch adversarial loss: 0.607784\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476218; batch adversarial loss: 0.561116\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544370; batch adversarial loss: 0.555764\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483540; batch adversarial loss: 0.550209\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560076; batch adversarial loss: 0.574003\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491018; batch adversarial loss: 0.618790\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501354; batch adversarial loss: 0.612716\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544799; batch adversarial loss: 0.501874\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455837; batch adversarial loss: 0.555898\n",
      "epoch 20; iter: 0; batch classifier loss: 0.442170; batch adversarial loss: 0.584015\n",
      "epoch 21; iter: 0; batch classifier loss: 0.440642; batch adversarial loss: 0.574112\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478411; batch adversarial loss: 0.576822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496993; batch adversarial loss: 0.584395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465457; batch adversarial loss: 0.582489\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503749; batch adversarial loss: 0.503331\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502959; batch adversarial loss: 0.541126\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483044; batch adversarial loss: 0.592233\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425141; batch adversarial loss: 0.611562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464820; batch adversarial loss: 0.633552\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515497; batch adversarial loss: 0.562377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443288; batch adversarial loss: 0.568670\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465997; batch adversarial loss: 0.492855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467921; batch adversarial loss: 0.563785\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419280; batch adversarial loss: 0.562470\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458726; batch adversarial loss: 0.606269\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400138; batch adversarial loss: 0.516506\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421334; batch adversarial loss: 0.572044\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466917; batch adversarial loss: 0.586535\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408901; batch adversarial loss: 0.524777\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467836; batch adversarial loss: 0.508297\n",
      "epoch 41; iter: 0; batch classifier loss: 0.508986; batch adversarial loss: 0.578930\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449201; batch adversarial loss: 0.590874\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408815; batch adversarial loss: 0.556262\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427696; batch adversarial loss: 0.563334\n",
      "epoch 45; iter: 0; batch classifier loss: 0.388479; batch adversarial loss: 0.613524\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416997; batch adversarial loss: 0.554749\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425907; batch adversarial loss: 0.596609\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422267; batch adversarial loss: 0.637557\n",
      "epoch 49; iter: 0; batch classifier loss: 0.364741; batch adversarial loss: 0.512021\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423534; batch adversarial loss: 0.545588\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423397; batch adversarial loss: 0.657633\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390575; batch adversarial loss: 0.588120\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390866; batch adversarial loss: 0.596550\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418705; batch adversarial loss: 0.536061\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485904; batch adversarial loss: 0.561856\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348552; batch adversarial loss: 0.578774\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428237; batch adversarial loss: 0.596472\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410957; batch adversarial loss: 0.631512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.397676; batch adversarial loss: 0.588716\n",
      "epoch 60; iter: 0; batch classifier loss: 0.375980; batch adversarial loss: 0.571785\n",
      "epoch 61; iter: 0; batch classifier loss: 0.480089; batch adversarial loss: 0.554110\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435029; batch adversarial loss: 0.623236\n",
      "epoch 63; iter: 0; batch classifier loss: 0.445643; batch adversarial loss: 0.519359\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450793; batch adversarial loss: 0.639018\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406738; batch adversarial loss: 0.493267\n",
      "epoch 66; iter: 0; batch classifier loss: 0.392653; batch adversarial loss: 0.560700\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360722; batch adversarial loss: 0.656050\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399096; batch adversarial loss: 0.554053\n",
      "epoch 69; iter: 0; batch classifier loss: 0.446284; batch adversarial loss: 0.519253\n",
      "epoch 70; iter: 0; batch classifier loss: 0.477085; batch adversarial loss: 0.579205\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389297; batch adversarial loss: 0.562130\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440209; batch adversarial loss: 0.536139\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419052; batch adversarial loss: 0.605470\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408878; batch adversarial loss: 0.599425\n",
      "epoch 75; iter: 0; batch classifier loss: 0.501927; batch adversarial loss: 0.537821\n",
      "epoch 76; iter: 0; batch classifier loss: 0.356879; batch adversarial loss: 0.570594\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380922; batch adversarial loss: 0.554328\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421193; batch adversarial loss: 0.528430\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437581; batch adversarial loss: 0.587551\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380142; batch adversarial loss: 0.632321\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388777; batch adversarial loss: 0.613341\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347565; batch adversarial loss: 0.536549\n",
      "epoch 83; iter: 0; batch classifier loss: 0.336277; batch adversarial loss: 0.527764\n",
      "epoch 84; iter: 0; batch classifier loss: 0.305809; batch adversarial loss: 0.528564\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366787; batch adversarial loss: 0.528244\n",
      "epoch 86; iter: 0; batch classifier loss: 0.489959; batch adversarial loss: 0.552577\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399002; batch adversarial loss: 0.572374\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385964; batch adversarial loss: 0.544664\n",
      "epoch 89; iter: 0; batch classifier loss: 0.466685; batch adversarial loss: 0.588316\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353838; batch adversarial loss: 0.580035\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362205; batch adversarial loss: 0.527684\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405779; batch adversarial loss: 0.546113\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424839; batch adversarial loss: 0.562276\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435993; batch adversarial loss: 0.597920\n",
      "epoch 95; iter: 0; batch classifier loss: 0.320026; batch adversarial loss: 0.493370\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392162; batch adversarial loss: 0.510147\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440326; batch adversarial loss: 0.579253\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365801; batch adversarial loss: 0.528039\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367286; batch adversarial loss: 0.511243\n",
      "epoch 100; iter: 0; batch classifier loss: 0.472808; batch adversarial loss: 0.580391\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365324; batch adversarial loss: 0.596910\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351064; batch adversarial loss: 0.510131\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417737; batch adversarial loss: 0.561919\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416824; batch adversarial loss: 0.588824\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342397; batch adversarial loss: 0.614682\n",
      "epoch 106; iter: 0; batch classifier loss: 0.415551; batch adversarial loss: 0.527902\n",
      "epoch 107; iter: 0; batch classifier loss: 0.416319; batch adversarial loss: 0.501593\n",
      "epoch 108; iter: 0; batch classifier loss: 0.465314; batch adversarial loss: 0.509350\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381187; batch adversarial loss: 0.631555\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430235; batch adversarial loss: 0.560144\n",
      "epoch 111; iter: 0; batch classifier loss: 0.491531; batch adversarial loss: 0.588053\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388653; batch adversarial loss: 0.519661\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417624; batch adversarial loss: 0.597851\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410538; batch adversarial loss: 0.536422\n",
      "epoch 115; iter: 0; batch classifier loss: 0.304769; batch adversarial loss: 0.528270\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366490; batch adversarial loss: 0.545008\n",
      "epoch 117; iter: 0; batch classifier loss: 0.335415; batch adversarial loss: 0.595573\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398470; batch adversarial loss: 0.509923\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417603; batch adversarial loss: 0.527112\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375812; batch adversarial loss: 0.554326\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369276; batch adversarial loss: 0.596540\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368322; batch adversarial loss: 0.493462\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373650; batch adversarial loss: 0.518294\n",
      "epoch 124; iter: 0; batch classifier loss: 0.427691; batch adversarial loss: 0.543252\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342741; batch adversarial loss: 0.571274\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375227; batch adversarial loss: 0.570627\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367329; batch adversarial loss: 0.536857\n",
      "epoch 128; iter: 0; batch classifier loss: 0.496924; batch adversarial loss: 0.598660\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373130; batch adversarial loss: 0.545830\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361738; batch adversarial loss: 0.624076\n",
      "epoch 131; iter: 0; batch classifier loss: 0.430029; batch adversarial loss: 0.511018\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.527654\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347616; batch adversarial loss: 0.545254\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372674; batch adversarial loss: 0.484113\n",
      "epoch 135; iter: 0; batch classifier loss: 0.420784; batch adversarial loss: 0.537105\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366291; batch adversarial loss: 0.580361\n",
      "epoch 137; iter: 0; batch classifier loss: 0.424559; batch adversarial loss: 0.580247\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351783; batch adversarial loss: 0.527555\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336625; batch adversarial loss: 0.570871\n",
      "epoch 140; iter: 0; batch classifier loss: 0.392465; batch adversarial loss: 0.563253\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362971; batch adversarial loss: 0.621886\n",
      "epoch 142; iter: 0; batch classifier loss: 0.476387; batch adversarial loss: 0.553863\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419972; batch adversarial loss: 0.605862\n",
      "epoch 144; iter: 0; batch classifier loss: 0.439085; batch adversarial loss: 0.535638\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374833; batch adversarial loss: 0.571474\n",
      "epoch 146; iter: 0; batch classifier loss: 0.324711; batch adversarial loss: 0.535420\n",
      "epoch 147; iter: 0; batch classifier loss: 0.439741; batch adversarial loss: 0.550212\n",
      "epoch 148; iter: 0; batch classifier loss: 0.418449; batch adversarial loss: 0.596285\n",
      "epoch 149; iter: 0; batch classifier loss: 0.290604; batch adversarial loss: 0.580624\n",
      "epoch 150; iter: 0; batch classifier loss: 0.331261; batch adversarial loss: 0.500322\n",
      "epoch 151; iter: 0; batch classifier loss: 0.342618; batch adversarial loss: 0.570980\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352789; batch adversarial loss: 0.528517\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372866; batch adversarial loss: 0.526489\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366987; batch adversarial loss: 0.639989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.454852; batch adversarial loss: 0.527445\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356848; batch adversarial loss: 0.555339\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369365; batch adversarial loss: 0.580702\n",
      "epoch 158; iter: 0; batch classifier loss: 0.247617; batch adversarial loss: 0.612758\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369627; batch adversarial loss: 0.561236\n",
      "epoch 160; iter: 0; batch classifier loss: 0.342837; batch adversarial loss: 0.528943\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401805; batch adversarial loss: 0.596965\n",
      "epoch 162; iter: 0; batch classifier loss: 0.330387; batch adversarial loss: 0.553308\n",
      "epoch 163; iter: 0; batch classifier loss: 0.412789; batch adversarial loss: 0.554720\n",
      "epoch 164; iter: 0; batch classifier loss: 0.431410; batch adversarial loss: 0.553110\n",
      "epoch 165; iter: 0; batch classifier loss: 0.438402; batch adversarial loss: 0.580124\n",
      "epoch 166; iter: 0; batch classifier loss: 0.345515; batch adversarial loss: 0.518924\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371125; batch adversarial loss: 0.544863\n",
      "epoch 168; iter: 0; batch classifier loss: 0.297398; batch adversarial loss: 0.536973\n",
      "epoch 169; iter: 0; batch classifier loss: 0.293218; batch adversarial loss: 0.605732\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398665; batch adversarial loss: 0.535754\n",
      "epoch 171; iter: 0; batch classifier loss: 0.422256; batch adversarial loss: 0.536336\n",
      "epoch 172; iter: 0; batch classifier loss: 0.393510; batch adversarial loss: 0.517888\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414337; batch adversarial loss: 0.519059\n",
      "epoch 174; iter: 0; batch classifier loss: 0.383771; batch adversarial loss: 0.577400\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345990; batch adversarial loss: 0.578795\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334631; batch adversarial loss: 0.521338\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351728; batch adversarial loss: 0.518984\n",
      "epoch 178; iter: 0; batch classifier loss: 0.327311; batch adversarial loss: 0.578694\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344962; batch adversarial loss: 0.615454\n",
      "epoch 180; iter: 0; batch classifier loss: 0.419932; batch adversarial loss: 0.528483\n",
      "epoch 181; iter: 0; batch classifier loss: 0.425403; batch adversarial loss: 0.528270\n",
      "epoch 182; iter: 0; batch classifier loss: 0.298862; batch adversarial loss: 0.571458\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395866; batch adversarial loss: 0.484643\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380940; batch adversarial loss: 0.517641\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372479; batch adversarial loss: 0.502317\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382599; batch adversarial loss: 0.615316\n",
      "epoch 187; iter: 0; batch classifier loss: 0.391556; batch adversarial loss: 0.595432\n",
      "epoch 188; iter: 0; batch classifier loss: 0.309303; batch adversarial loss: 0.519578\n",
      "epoch 189; iter: 0; batch classifier loss: 0.396248; batch adversarial loss: 0.518591\n",
      "epoch 190; iter: 0; batch classifier loss: 0.370891; batch adversarial loss: 0.589849\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316166; batch adversarial loss: 0.570751\n",
      "epoch 192; iter: 0; batch classifier loss: 0.414412; batch adversarial loss: 0.561095\n",
      "epoch 193; iter: 0; batch classifier loss: 0.424093; batch adversarial loss: 0.511203\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393398; batch adversarial loss: 0.571631\n",
      "epoch 195; iter: 0; batch classifier loss: 0.394001; batch adversarial loss: 0.517643\n",
      "epoch 196; iter: 0; batch classifier loss: 0.433482; batch adversarial loss: 0.579665\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336324; batch adversarial loss: 0.544465\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326451; batch adversarial loss: 0.571322\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385193; batch adversarial loss: 0.571926\n",
      "epoch 0; iter: 0; batch classifier loss: 0.773407; batch adversarial loss: 0.695284\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691267; batch adversarial loss: 0.660838\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621025; batch adversarial loss: 0.658735\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563657; batch adversarial loss: 0.625095\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531671; batch adversarial loss: 0.615839\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541380; batch adversarial loss: 0.605959\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588636; batch adversarial loss: 0.615899\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575487; batch adversarial loss: 0.616150\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499927; batch adversarial loss: 0.595932\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508757; batch adversarial loss: 0.623763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522538; batch adversarial loss: 0.598606\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533258; batch adversarial loss: 0.566191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513741; batch adversarial loss: 0.588122\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527524; batch adversarial loss: 0.582438\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512444; batch adversarial loss: 0.580432\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535205; batch adversarial loss: 0.534185\n",
      "epoch 16; iter: 0; batch classifier loss: 0.616754; batch adversarial loss: 0.569822\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528726; batch adversarial loss: 0.542507\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486670; batch adversarial loss: 0.558354\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472116; batch adversarial loss: 0.525870\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499601; batch adversarial loss: 0.537687\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492356; batch adversarial loss: 0.527018\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499886; batch adversarial loss: 0.576574\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475437; batch adversarial loss: 0.483251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515795; batch adversarial loss: 0.634396\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535590; batch adversarial loss: 0.525366\n",
      "epoch 26; iter: 0; batch classifier loss: 0.518960; batch adversarial loss: 0.630101\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483557; batch adversarial loss: 0.515184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529303; batch adversarial loss: 0.581760\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511755; batch adversarial loss: 0.513075\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439087; batch adversarial loss: 0.586617\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481174; batch adversarial loss: 0.511776\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456954; batch adversarial loss: 0.571211\n",
      "epoch 33; iter: 0; batch classifier loss: 0.500016; batch adversarial loss: 0.553859\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494432; batch adversarial loss: 0.545468\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480592; batch adversarial loss: 0.561858\n",
      "epoch 36; iter: 0; batch classifier loss: 0.493127; batch adversarial loss: 0.519517\n",
      "epoch 37; iter: 0; batch classifier loss: 0.437714; batch adversarial loss: 0.553677\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431005; batch adversarial loss: 0.588610\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476298; batch adversarial loss: 0.553180\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500541; batch adversarial loss: 0.553673\n",
      "epoch 41; iter: 0; batch classifier loss: 0.565338; batch adversarial loss: 0.483241\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417935; batch adversarial loss: 0.562269\n",
      "epoch 43; iter: 0; batch classifier loss: 0.411879; batch adversarial loss: 0.508574\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441318; batch adversarial loss: 0.526750\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397701; batch adversarial loss: 0.544386\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455068; batch adversarial loss: 0.500753\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443296; batch adversarial loss: 0.554683\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485010; batch adversarial loss: 0.517258\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440825; batch adversarial loss: 0.552743\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420861; batch adversarial loss: 0.561781\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497129; batch adversarial loss: 0.563689\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429531; batch adversarial loss: 0.606871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.467183; batch adversarial loss: 0.606060\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474637; batch adversarial loss: 0.631401\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483309; batch adversarial loss: 0.511876\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454669; batch adversarial loss: 0.515867\n",
      "epoch 57; iter: 0; batch classifier loss: 0.552269; batch adversarial loss: 0.504326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411441; batch adversarial loss: 0.540691\n",
      "epoch 59; iter: 0; batch classifier loss: 0.475378; batch adversarial loss: 0.481842\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384969; batch adversarial loss: 0.572506\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439836; batch adversarial loss: 0.519946\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453057; batch adversarial loss: 0.588299\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465524; batch adversarial loss: 0.646371\n",
      "epoch 64; iter: 0; batch classifier loss: 0.331029; batch adversarial loss: 0.507582\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402246; batch adversarial loss: 0.508384\n",
      "epoch 66; iter: 0; batch classifier loss: 0.479487; batch adversarial loss: 0.535642\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431035; batch adversarial loss: 0.626808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381845; batch adversarial loss: 0.562472\n",
      "epoch 69; iter: 0; batch classifier loss: 0.354600; batch adversarial loss: 0.599479\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436097; batch adversarial loss: 0.588906\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449997; batch adversarial loss: 0.596491\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396859; batch adversarial loss: 0.543751\n",
      "epoch 73; iter: 0; batch classifier loss: 0.524382; batch adversarial loss: 0.624176\n",
      "epoch 74; iter: 0; batch classifier loss: 0.470753; batch adversarial loss: 0.569823\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377836; batch adversarial loss: 0.590717\n",
      "epoch 76; iter: 0; batch classifier loss: 0.469036; batch adversarial loss: 0.500338\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401880; batch adversarial loss: 0.555039\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402078; batch adversarial loss: 0.534504\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392909; batch adversarial loss: 0.653379\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411438; batch adversarial loss: 0.490835\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407155; batch adversarial loss: 0.543401\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390090; batch adversarial loss: 0.571139\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389977; batch adversarial loss: 0.625083\n",
      "epoch 84; iter: 0; batch classifier loss: 0.394981; batch adversarial loss: 0.588277\n",
      "epoch 85; iter: 0; batch classifier loss: 0.459253; batch adversarial loss: 0.604721\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394467; batch adversarial loss: 0.526680\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440140; batch adversarial loss: 0.553658\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402144; batch adversarial loss: 0.589883\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329028; batch adversarial loss: 0.571021\n",
      "epoch 90; iter: 0; batch classifier loss: 0.458993; batch adversarial loss: 0.580414\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404594; batch adversarial loss: 0.608795\n",
      "epoch 92; iter: 0; batch classifier loss: 0.444061; batch adversarial loss: 0.525907\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371952; batch adversarial loss: 0.580666\n",
      "epoch 94; iter: 0; batch classifier loss: 0.439102; batch adversarial loss: 0.508122\n",
      "epoch 95; iter: 0; batch classifier loss: 0.454139; batch adversarial loss: 0.544529\n",
      "epoch 96; iter: 0; batch classifier loss: 0.448748; batch adversarial loss: 0.596283\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425913; batch adversarial loss: 0.612150\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398068; batch adversarial loss: 0.579607\n",
      "epoch 99; iter: 0; batch classifier loss: 0.349072; batch adversarial loss: 0.481135\n",
      "epoch 100; iter: 0; batch classifier loss: 0.479047; batch adversarial loss: 0.517397\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355873; batch adversarial loss: 0.545539\n",
      "epoch 102; iter: 0; batch classifier loss: 0.424767; batch adversarial loss: 0.590367\n",
      "epoch 103; iter: 0; batch classifier loss: 0.387989; batch adversarial loss: 0.562764\n",
      "epoch 104; iter: 0; batch classifier loss: 0.313666; batch adversarial loss: 0.572293\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382216; batch adversarial loss: 0.610017\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398928; batch adversarial loss: 0.492667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.389191; batch adversarial loss: 0.652875\n",
      "epoch 108; iter: 0; batch classifier loss: 0.456495; batch adversarial loss: 0.533292\n",
      "epoch 109; iter: 0; batch classifier loss: 0.362184; batch adversarial loss: 0.536583\n",
      "epoch 110; iter: 0; batch classifier loss: 0.361694; batch adversarial loss: 0.545567\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378674; batch adversarial loss: 0.527173\n",
      "epoch 112; iter: 0; batch classifier loss: 0.443189; batch adversarial loss: 0.635114\n",
      "epoch 113; iter: 0; batch classifier loss: 0.430607; batch adversarial loss: 0.544344\n",
      "epoch 114; iter: 0; batch classifier loss: 0.421558; batch adversarial loss: 0.480859\n",
      "epoch 115; iter: 0; batch classifier loss: 0.272899; batch adversarial loss: 0.546804\n",
      "epoch 116; iter: 0; batch classifier loss: 0.411123; batch adversarial loss: 0.544731\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393297; batch adversarial loss: 0.498483\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394189; batch adversarial loss: 0.534084\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383944; batch adversarial loss: 0.642032\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340448; batch adversarial loss: 0.606521\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381238; batch adversarial loss: 0.534960\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383603; batch adversarial loss: 0.554856\n",
      "epoch 123; iter: 0; batch classifier loss: 0.303439; batch adversarial loss: 0.482465\n",
      "epoch 124; iter: 0; batch classifier loss: 0.394122; batch adversarial loss: 0.508905\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374001; batch adversarial loss: 0.551825\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395588; batch adversarial loss: 0.563142\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443948; batch adversarial loss: 0.552897\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415513; batch adversarial loss: 0.606375\n",
      "epoch 129; iter: 0; batch classifier loss: 0.366324; batch adversarial loss: 0.470803\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394286; batch adversarial loss: 0.565746\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389032; batch adversarial loss: 0.535297\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347981; batch adversarial loss: 0.508555\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331295; batch adversarial loss: 0.579299\n",
      "epoch 134; iter: 0; batch classifier loss: 0.302889; batch adversarial loss: 0.580697\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400158; batch adversarial loss: 0.591940\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348531; batch adversarial loss: 0.607732\n",
      "epoch 137; iter: 0; batch classifier loss: 0.484487; batch adversarial loss: 0.501829\n",
      "epoch 138; iter: 0; batch classifier loss: 0.352941; batch adversarial loss: 0.553372\n",
      "epoch 139; iter: 0; batch classifier loss: 0.451714; batch adversarial loss: 0.552117\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354696; batch adversarial loss: 0.500019\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351985; batch adversarial loss: 0.510818\n",
      "epoch 142; iter: 0; batch classifier loss: 0.450547; batch adversarial loss: 0.544274\n",
      "epoch 143; iter: 0; batch classifier loss: 0.486151; batch adversarial loss: 0.492146\n",
      "epoch 144; iter: 0; batch classifier loss: 0.314882; batch adversarial loss: 0.508575\n",
      "epoch 145; iter: 0; batch classifier loss: 0.493248; batch adversarial loss: 0.492253\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388470; batch adversarial loss: 0.535316\n",
      "epoch 147; iter: 0; batch classifier loss: 0.398623; batch adversarial loss: 0.571168\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336190; batch adversarial loss: 0.578157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.360260; batch adversarial loss: 0.519083\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363787; batch adversarial loss: 0.527106\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376730; batch adversarial loss: 0.644564\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378164; batch adversarial loss: 0.552729\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345150; batch adversarial loss: 0.546039\n",
      "epoch 154; iter: 0; batch classifier loss: 0.458923; batch adversarial loss: 0.518936\n",
      "epoch 155; iter: 0; batch classifier loss: 0.376341; batch adversarial loss: 0.544943\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368989; batch adversarial loss: 0.542849\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335377; batch adversarial loss: 0.552724\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341593; batch adversarial loss: 0.623966\n",
      "epoch 159; iter: 0; batch classifier loss: 0.355957; batch adversarial loss: 0.597376\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348995; batch adversarial loss: 0.553893\n",
      "epoch 161; iter: 0; batch classifier loss: 0.262113; batch adversarial loss: 0.569366\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387298; batch adversarial loss: 0.555604\n",
      "epoch 163; iter: 0; batch classifier loss: 0.379646; batch adversarial loss: 0.569743\n",
      "epoch 164; iter: 0; batch classifier loss: 0.438158; batch adversarial loss: 0.519010\n",
      "epoch 165; iter: 0; batch classifier loss: 0.423080; batch adversarial loss: 0.595697\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328246; batch adversarial loss: 0.596771\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288318; batch adversarial loss: 0.597587\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387650; batch adversarial loss: 0.623277\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407799; batch adversarial loss: 0.535893\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380398; batch adversarial loss: 0.554241\n",
      "epoch 171; iter: 0; batch classifier loss: 0.400998; batch adversarial loss: 0.560658\n",
      "epoch 172; iter: 0; batch classifier loss: 0.438869; batch adversarial loss: 0.553871\n",
      "epoch 173; iter: 0; batch classifier loss: 0.391931; batch adversarial loss: 0.553051\n",
      "epoch 174; iter: 0; batch classifier loss: 0.417648; batch adversarial loss: 0.498685\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352190; batch adversarial loss: 0.534076\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346728; batch adversarial loss: 0.525319\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339126; batch adversarial loss: 0.511368\n",
      "epoch 178; iter: 0; batch classifier loss: 0.397149; batch adversarial loss: 0.517512\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350547; batch adversarial loss: 0.498395\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345155; batch adversarial loss: 0.561789\n",
      "epoch 181; iter: 0; batch classifier loss: 0.351910; batch adversarial loss: 0.544998\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322255; batch adversarial loss: 0.509406\n",
      "epoch 183; iter: 0; batch classifier loss: 0.411153; batch adversarial loss: 0.564017\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342245; batch adversarial loss: 0.607971\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326103; batch adversarial loss: 0.640847\n",
      "epoch 186; iter: 0; batch classifier loss: 0.429836; batch adversarial loss: 0.543033\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388648; batch adversarial loss: 0.571691\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332598; batch adversarial loss: 0.632304\n",
      "epoch 189; iter: 0; batch classifier loss: 0.374427; batch adversarial loss: 0.516037\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354052; batch adversarial loss: 0.562149\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360398; batch adversarial loss: 0.535657\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335787; batch adversarial loss: 0.598338\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335561; batch adversarial loss: 0.610112\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316068; batch adversarial loss: 0.652600\n",
      "epoch 195; iter: 0; batch classifier loss: 0.372781; batch adversarial loss: 0.535390\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310122; batch adversarial loss: 0.561991\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396469; batch adversarial loss: 0.569758\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354544; batch adversarial loss: 0.625483\n",
      "epoch 199; iter: 0; batch classifier loss: 0.369428; batch adversarial loss: 0.524201\n",
      "epoch 0; iter: 0; batch classifier loss: 0.745055; batch adversarial loss: 0.615584\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610674; batch adversarial loss: 0.655615\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595545; batch adversarial loss: 0.640693\n",
      "epoch 3; iter: 0; batch classifier loss: 0.722478; batch adversarial loss: 0.670104\n",
      "epoch 4; iter: 0; batch classifier loss: 0.657349; batch adversarial loss: 0.641662\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614859; batch adversarial loss: 0.626871\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599208; batch adversarial loss: 0.582377\n",
      "epoch 7; iter: 0; batch classifier loss: 0.476992; batch adversarial loss: 0.579757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568032; batch adversarial loss: 0.557656\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563824; batch adversarial loss: 0.517127\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541762; batch adversarial loss: 0.589224\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537622; batch adversarial loss: 0.616095\n",
      "epoch 12; iter: 0; batch classifier loss: 0.466469; batch adversarial loss: 0.617207\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525383; batch adversarial loss: 0.564111\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476983; batch adversarial loss: 0.576521\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528188; batch adversarial loss: 0.563634\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469579; batch adversarial loss: 0.610780\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494298; batch adversarial loss: 0.560405\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464448; batch adversarial loss: 0.560645\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495445; batch adversarial loss: 0.541449\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473792; batch adversarial loss: 0.513186\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495357; batch adversarial loss: 0.540433\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450735; batch adversarial loss: 0.599197\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473624; batch adversarial loss: 0.638469\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480867; batch adversarial loss: 0.585234\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451937; batch adversarial loss: 0.537226\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520420; batch adversarial loss: 0.564341\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440455; batch adversarial loss: 0.543624\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468388; batch adversarial loss: 0.462931\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474690; batch adversarial loss: 0.549001\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406735; batch adversarial loss: 0.566025\n",
      "epoch 31; iter: 0; batch classifier loss: 0.553434; batch adversarial loss: 0.573278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417858; batch adversarial loss: 0.523654\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455227; batch adversarial loss: 0.594694\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491514; batch adversarial loss: 0.526106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.518313; batch adversarial loss: 0.552330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488666; batch adversarial loss: 0.551927\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449164; batch adversarial loss: 0.582253\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481509; batch adversarial loss: 0.655590\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405224; batch adversarial loss: 0.539518\n",
      "epoch 40; iter: 0; batch classifier loss: 0.525584; batch adversarial loss: 0.541648\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425216; batch adversarial loss: 0.515812\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456324; batch adversarial loss: 0.618635\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478836; batch adversarial loss: 0.583455\n",
      "epoch 44; iter: 0; batch classifier loss: 0.544252; batch adversarial loss: 0.564669\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435859; batch adversarial loss: 0.538237\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430424; batch adversarial loss: 0.564212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.438435; batch adversarial loss: 0.638069\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429620; batch adversarial loss: 0.512618\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402572; batch adversarial loss: 0.451390\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422101; batch adversarial loss: 0.502196\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418264; batch adversarial loss: 0.580180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464892; batch adversarial loss: 0.528078\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430923; batch adversarial loss: 0.488342\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411266; batch adversarial loss: 0.535087\n",
      "epoch 55; iter: 0; batch classifier loss: 0.456916; batch adversarial loss: 0.571175\n",
      "epoch 56; iter: 0; batch classifier loss: 0.358162; batch adversarial loss: 0.518822\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472699; batch adversarial loss: 0.638372\n",
      "epoch 58; iter: 0; batch classifier loss: 0.363795; batch adversarial loss: 0.527067\n",
      "epoch 59; iter: 0; batch classifier loss: 0.472320; batch adversarial loss: 0.534543\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379714; batch adversarial loss: 0.533358\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436005; batch adversarial loss: 0.579532\n",
      "epoch 62; iter: 0; batch classifier loss: 0.354079; batch adversarial loss: 0.533574\n",
      "epoch 63; iter: 0; batch classifier loss: 0.350032; batch adversarial loss: 0.561904\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358795; batch adversarial loss: 0.509977\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369161; batch adversarial loss: 0.487625\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398325; batch adversarial loss: 0.562231\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407884; batch adversarial loss: 0.584393\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383355; batch adversarial loss: 0.544437\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409215; batch adversarial loss: 0.476967\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427112; batch adversarial loss: 0.579821\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443937; batch adversarial loss: 0.536095\n",
      "epoch 72; iter: 0; batch classifier loss: 0.464246; batch adversarial loss: 0.525661\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394581; batch adversarial loss: 0.591816\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404143; batch adversarial loss: 0.498839\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375560; batch adversarial loss: 0.571045\n",
      "epoch 76; iter: 0; batch classifier loss: 0.433807; batch adversarial loss: 0.535843\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363352; batch adversarial loss: 0.562235\n",
      "epoch 78; iter: 0; batch classifier loss: 0.423117; batch adversarial loss: 0.507940\n",
      "epoch 79; iter: 0; batch classifier loss: 0.361396; batch adversarial loss: 0.649081\n",
      "epoch 80; iter: 0; batch classifier loss: 0.361998; batch adversarial loss: 0.580571\n",
      "epoch 81; iter: 0; batch classifier loss: 0.452614; batch adversarial loss: 0.601348\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386009; batch adversarial loss: 0.562779\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414852; batch adversarial loss: 0.554278\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411090; batch adversarial loss: 0.523895\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425876; batch adversarial loss: 0.544959\n",
      "epoch 86; iter: 0; batch classifier loss: 0.494137; batch adversarial loss: 0.589487\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394044; batch adversarial loss: 0.570878\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402785; batch adversarial loss: 0.573301\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375188; batch adversarial loss: 0.570996\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411208; batch adversarial loss: 0.574748\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376428; batch adversarial loss: 0.498425\n",
      "epoch 92; iter: 0; batch classifier loss: 0.352773; batch adversarial loss: 0.543928\n",
      "epoch 93; iter: 0; batch classifier loss: 0.296975; batch adversarial loss: 0.442915\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377528; batch adversarial loss: 0.534604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408126; batch adversarial loss: 0.552395\n",
      "epoch 96; iter: 0; batch classifier loss: 0.344848; batch adversarial loss: 0.518431\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350255; batch adversarial loss: 0.563384\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370241; batch adversarial loss: 0.533597\n",
      "epoch 99; iter: 0; batch classifier loss: 0.445115; batch adversarial loss: 0.472134\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355880; batch adversarial loss: 0.633946\n",
      "epoch 101; iter: 0; batch classifier loss: 0.438558; batch adversarial loss: 0.580499\n",
      "epoch 102; iter: 0; batch classifier loss: 0.334222; batch adversarial loss: 0.573709\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406534; batch adversarial loss: 0.523893\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370090; batch adversarial loss: 0.480033\n",
      "epoch 105; iter: 0; batch classifier loss: 0.458690; batch adversarial loss: 0.526847\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377370; batch adversarial loss: 0.507241\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339950; batch adversarial loss: 0.592754\n",
      "epoch 108; iter: 0; batch classifier loss: 0.420285; batch adversarial loss: 0.536443\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401830; batch adversarial loss: 0.496654\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392798; batch adversarial loss: 0.476015\n",
      "epoch 111; iter: 0; batch classifier loss: 0.422371; batch adversarial loss: 0.562696\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394314; batch adversarial loss: 0.535411\n",
      "epoch 113; iter: 0; batch classifier loss: 0.487673; batch adversarial loss: 0.581919\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392602; batch adversarial loss: 0.453746\n",
      "epoch 115; iter: 0; batch classifier loss: 0.376887; batch adversarial loss: 0.570491\n",
      "epoch 116; iter: 0; batch classifier loss: 0.416635; batch adversarial loss: 0.524742\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409709; batch adversarial loss: 0.475866\n",
      "epoch 118; iter: 0; batch classifier loss: 0.407203; batch adversarial loss: 0.513478\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379475; batch adversarial loss: 0.535155\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379064; batch adversarial loss: 0.609594\n",
      "epoch 121; iter: 0; batch classifier loss: 0.357189; batch adversarial loss: 0.525730\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389161; batch adversarial loss: 0.463318\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394924; batch adversarial loss: 0.535211\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376074; batch adversarial loss: 0.562227\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394356; batch adversarial loss: 0.545018\n",
      "epoch 126; iter: 0; batch classifier loss: 0.437359; batch adversarial loss: 0.526700\n",
      "epoch 127; iter: 0; batch classifier loss: 0.373531; batch adversarial loss: 0.571058\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376937; batch adversarial loss: 0.570757\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339934; batch adversarial loss: 0.469119\n",
      "epoch 130; iter: 0; batch classifier loss: 0.320450; batch adversarial loss: 0.553948\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372142; batch adversarial loss: 0.505096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312934; batch adversarial loss: 0.542598\n",
      "epoch 133; iter: 0; batch classifier loss: 0.317661; batch adversarial loss: 0.518758\n",
      "epoch 134; iter: 0; batch classifier loss: 0.459791; batch adversarial loss: 0.495858\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375864; batch adversarial loss: 0.450165\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373516; batch adversarial loss: 0.627473\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386770; batch adversarial loss: 0.552070\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415720; batch adversarial loss: 0.581444\n",
      "epoch 139; iter: 0; batch classifier loss: 0.300113; batch adversarial loss: 0.615233\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358740; batch adversarial loss: 0.471172\n",
      "epoch 141; iter: 0; batch classifier loss: 0.396700; batch adversarial loss: 0.489564\n",
      "epoch 142; iter: 0; batch classifier loss: 0.493545; batch adversarial loss: 0.565824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.372694; batch adversarial loss: 0.658365\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331586; batch adversarial loss: 0.573960\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399956; batch adversarial loss: 0.496734\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380133; batch adversarial loss: 0.552687\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346826; batch adversarial loss: 0.590786\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410650; batch adversarial loss: 0.572160\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378572; batch adversarial loss: 0.600448\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359885; batch adversarial loss: 0.477483\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395517; batch adversarial loss: 0.599246\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366625; batch adversarial loss: 0.582307\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365599; batch adversarial loss: 0.632028\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389012; batch adversarial loss: 0.563132\n",
      "epoch 155; iter: 0; batch classifier loss: 0.333325; batch adversarial loss: 0.581550\n",
      "epoch 156; iter: 0; batch classifier loss: 0.406947; batch adversarial loss: 0.581121\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381659; batch adversarial loss: 0.537202\n",
      "epoch 158; iter: 0; batch classifier loss: 0.262317; batch adversarial loss: 0.553400\n",
      "epoch 159; iter: 0; batch classifier loss: 0.402817; batch adversarial loss: 0.571920\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375256; batch adversarial loss: 0.581146\n",
      "epoch 161; iter: 0; batch classifier loss: 0.427476; batch adversarial loss: 0.496972\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349539; batch adversarial loss: 0.470535\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364893; batch adversarial loss: 0.516981\n",
      "epoch 164; iter: 0; batch classifier loss: 0.296031; batch adversarial loss: 0.471402\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352062; batch adversarial loss: 0.444049\n",
      "epoch 166; iter: 0; batch classifier loss: 0.386037; batch adversarial loss: 0.591118\n",
      "epoch 167; iter: 0; batch classifier loss: 0.326475; batch adversarial loss: 0.590004\n",
      "epoch 168; iter: 0; batch classifier loss: 0.391380; batch adversarial loss: 0.553486\n",
      "epoch 169; iter: 0; batch classifier loss: 0.464795; batch adversarial loss: 0.517882\n",
      "epoch 170; iter: 0; batch classifier loss: 0.392896; batch adversarial loss: 0.600711\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334515; batch adversarial loss: 0.581679\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362857; batch adversarial loss: 0.562748\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364265; batch adversarial loss: 0.561677\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357909; batch adversarial loss: 0.578557\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372699; batch adversarial loss: 0.589645\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362748; batch adversarial loss: 0.527625\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362291; batch adversarial loss: 0.625444\n",
      "epoch 178; iter: 0; batch classifier loss: 0.282037; batch adversarial loss: 0.492968\n",
      "epoch 179; iter: 0; batch classifier loss: 0.302675; batch adversarial loss: 0.566921\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334373; batch adversarial loss: 0.527298\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344488; batch adversarial loss: 0.637280\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336095; batch adversarial loss: 0.610326\n",
      "epoch 183; iter: 0; batch classifier loss: 0.438806; batch adversarial loss: 0.562366\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334890; batch adversarial loss: 0.602891\n",
      "epoch 185; iter: 0; batch classifier loss: 0.425101; batch adversarial loss: 0.599158\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299628; batch adversarial loss: 0.634803\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364041; batch adversarial loss: 0.599579\n",
      "epoch 188; iter: 0; batch classifier loss: 0.266348; batch adversarial loss: 0.526163\n",
      "epoch 189; iter: 0; batch classifier loss: 0.396375; batch adversarial loss: 0.581674\n",
      "epoch 190; iter: 0; batch classifier loss: 0.295065; batch adversarial loss: 0.524990\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351286; batch adversarial loss: 0.509039\n",
      "epoch 192; iter: 0; batch classifier loss: 0.331212; batch adversarial loss: 0.553490\n",
      "epoch 193; iter: 0; batch classifier loss: 0.377070; batch adversarial loss: 0.535616\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395531; batch adversarial loss: 0.536885\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329716; batch adversarial loss: 0.526449\n",
      "epoch 196; iter: 0; batch classifier loss: 0.412043; batch adversarial loss: 0.544726\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358543; batch adversarial loss: 0.554042\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390572; batch adversarial loss: 0.470280\n",
      "epoch 199; iter: 0; batch classifier loss: 0.431504; batch adversarial loss: 0.600317\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706502; batch adversarial loss: 0.527943\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639942; batch adversarial loss: 0.674500\n",
      "epoch 2; iter: 0; batch classifier loss: 0.546833; batch adversarial loss: 0.630194\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602382; batch adversarial loss: 0.621838\n",
      "epoch 4; iter: 0; batch classifier loss: 0.622624; batch adversarial loss: 0.715731\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572716; batch adversarial loss: 0.641868\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581585; batch adversarial loss: 0.642173\n",
      "epoch 7; iter: 0; batch classifier loss: 0.638422; batch adversarial loss: 0.636969\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547856; batch adversarial loss: 0.649733\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566472; batch adversarial loss: 0.597594\n",
      "epoch 10; iter: 0; batch classifier loss: 0.606138; batch adversarial loss: 0.654504\n",
      "epoch 11; iter: 0; batch classifier loss: 0.598382; batch adversarial loss: 0.583519\n",
      "epoch 12; iter: 0; batch classifier loss: 0.589793; batch adversarial loss: 0.563716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498767; batch adversarial loss: 0.559382\n",
      "epoch 14; iter: 0; batch classifier loss: 0.561985; batch adversarial loss: 0.556841\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486509; batch adversarial loss: 0.538082\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471040; batch adversarial loss: 0.494280\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498054; batch adversarial loss: 0.511672\n",
      "epoch 18; iter: 0; batch classifier loss: 0.638250; batch adversarial loss: 0.529837\n",
      "epoch 19; iter: 0; batch classifier loss: 0.452831; batch adversarial loss: 0.505488\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493910; batch adversarial loss: 0.580781\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453690; batch adversarial loss: 0.531520\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493089; batch adversarial loss: 0.555414\n",
      "epoch 23; iter: 0; batch classifier loss: 0.406661; batch adversarial loss: 0.540582\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526436; batch adversarial loss: 0.505194\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437815; batch adversarial loss: 0.545646\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502306; batch adversarial loss: 0.570637\n",
      "epoch 27; iter: 0; batch classifier loss: 0.412337; batch adversarial loss: 0.496597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434729; batch adversarial loss: 0.563071\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456418; batch adversarial loss: 0.554019\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502820; batch adversarial loss: 0.519517\n",
      "epoch 31; iter: 0; batch classifier loss: 0.521033; batch adversarial loss: 0.520011\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454569; batch adversarial loss: 0.528402\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438022; batch adversarial loss: 0.632577\n",
      "epoch 34; iter: 0; batch classifier loss: 0.388054; batch adversarial loss: 0.527040\n",
      "epoch 35; iter: 0; batch classifier loss: 0.418775; batch adversarial loss: 0.570480\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504206; batch adversarial loss: 0.589721\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415850; batch adversarial loss: 0.562075\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483884; batch adversarial loss: 0.537379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.435182; batch adversarial loss: 0.534740\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462082; batch adversarial loss: 0.536371\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436097; batch adversarial loss: 0.650944\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434775; batch adversarial loss: 0.465256\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385377; batch adversarial loss: 0.589575\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451800; batch adversarial loss: 0.615977\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479183; batch adversarial loss: 0.518931\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424256; batch adversarial loss: 0.571573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485689; batch adversarial loss: 0.569327\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364742; batch adversarial loss: 0.571390\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351391; batch adversarial loss: 0.597515\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438963; batch adversarial loss: 0.543519\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454932; batch adversarial loss: 0.569763\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414612; batch adversarial loss: 0.553002\n",
      "epoch 53; iter: 0; batch classifier loss: 0.526616; batch adversarial loss: 0.589117\n",
      "epoch 54; iter: 0; batch classifier loss: 0.323007; batch adversarial loss: 0.587182\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462255; batch adversarial loss: 0.577387\n",
      "epoch 56; iter: 0; batch classifier loss: 0.509234; batch adversarial loss: 0.523141\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424469; batch adversarial loss: 0.525406\n",
      "epoch 58; iter: 0; batch classifier loss: 0.352651; batch adversarial loss: 0.599169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446432; batch adversarial loss: 0.492952\n",
      "epoch 60; iter: 0; batch classifier loss: 0.498002; batch adversarial loss: 0.601041\n",
      "epoch 61; iter: 0; batch classifier loss: 0.482578; batch adversarial loss: 0.579476\n",
      "epoch 62; iter: 0; batch classifier loss: 0.468303; batch adversarial loss: 0.492294\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390773; batch adversarial loss: 0.544569\n",
      "epoch 64; iter: 0; batch classifier loss: 0.430929; batch adversarial loss: 0.535266\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431383; batch adversarial loss: 0.614948\n",
      "epoch 66; iter: 0; batch classifier loss: 0.500638; batch adversarial loss: 0.560938\n",
      "epoch 67; iter: 0; batch classifier loss: 0.449051; batch adversarial loss: 0.537878\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383095; batch adversarial loss: 0.545965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417843; batch adversarial loss: 0.502675\n",
      "epoch 70; iter: 0; batch classifier loss: 0.441136; batch adversarial loss: 0.544892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386710; batch adversarial loss: 0.570441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373867; batch adversarial loss: 0.562617\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404034; batch adversarial loss: 0.466159\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478672; batch adversarial loss: 0.475145\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390143; batch adversarial loss: 0.527278\n",
      "epoch 76; iter: 0; batch classifier loss: 0.486581; batch adversarial loss: 0.536394\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418186; batch adversarial loss: 0.571226\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404957; batch adversarial loss: 0.606287\n",
      "epoch 79; iter: 0; batch classifier loss: 0.451543; batch adversarial loss: 0.510239\n",
      "epoch 80; iter: 0; batch classifier loss: 0.415180; batch adversarial loss: 0.562400\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423288; batch adversarial loss: 0.553374\n",
      "epoch 82; iter: 0; batch classifier loss: 0.328771; batch adversarial loss: 0.580012\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409497; batch adversarial loss: 0.597546\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363684; batch adversarial loss: 0.500900\n",
      "epoch 85; iter: 0; batch classifier loss: 0.330453; batch adversarial loss: 0.535930\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408728; batch adversarial loss: 0.483243\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423631; batch adversarial loss: 0.509603\n",
      "epoch 88; iter: 0; batch classifier loss: 0.391194; batch adversarial loss: 0.518303\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415393; batch adversarial loss: 0.527258\n",
      "epoch 90; iter: 0; batch classifier loss: 0.339382; batch adversarial loss: 0.535898\n",
      "epoch 91; iter: 0; batch classifier loss: 0.533828; batch adversarial loss: 0.580231\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379822; batch adversarial loss: 0.518382\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384707; batch adversarial loss: 0.526971\n",
      "epoch 94; iter: 0; batch classifier loss: 0.323779; batch adversarial loss: 0.518273\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347508; batch adversarial loss: 0.527152\n",
      "epoch 96; iter: 0; batch classifier loss: 0.295055; batch adversarial loss: 0.641201\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410677; batch adversarial loss: 0.571525\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354570; batch adversarial loss: 0.518261\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441307; batch adversarial loss: 0.632639\n",
      "epoch 100; iter: 0; batch classifier loss: 0.299151; batch adversarial loss: 0.456957\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421868; batch adversarial loss: 0.580193\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397124; batch adversarial loss: 0.650045\n",
      "epoch 103; iter: 0; batch classifier loss: 0.428417; batch adversarial loss: 0.562443\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399068; batch adversarial loss: 0.571009\n",
      "epoch 105; iter: 0; batch classifier loss: 0.452749; batch adversarial loss: 0.588709\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410794; batch adversarial loss: 0.527316\n",
      "epoch 107; iter: 0; batch classifier loss: 0.437441; batch adversarial loss: 0.571417\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354483; batch adversarial loss: 0.527105\n",
      "epoch 109; iter: 0; batch classifier loss: 0.273080; batch adversarial loss: 0.553662\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421379; batch adversarial loss: 0.562508\n",
      "epoch 111; iter: 0; batch classifier loss: 0.373652; batch adversarial loss: 0.536038\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396107; batch adversarial loss: 0.483216\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375153; batch adversarial loss: 0.570837\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394065; batch adversarial loss: 0.544862\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393791; batch adversarial loss: 0.527500\n",
      "epoch 116; iter: 0; batch classifier loss: 0.424815; batch adversarial loss: 0.553814\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382438; batch adversarial loss: 0.509259\n",
      "epoch 118; iter: 0; batch classifier loss: 0.305400; batch adversarial loss: 0.562432\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372238; batch adversarial loss: 0.606097\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351268; batch adversarial loss: 0.588466\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387609; batch adversarial loss: 0.465876\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377768; batch adversarial loss: 0.501020\n",
      "epoch 123; iter: 0; batch classifier loss: 0.435436; batch adversarial loss: 0.588948\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402880; batch adversarial loss: 0.597312\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342053; batch adversarial loss: 0.553381\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395928; batch adversarial loss: 0.544737\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417301; batch adversarial loss: 0.589217\n",
      "epoch 128; iter: 0; batch classifier loss: 0.412921; batch adversarial loss: 0.563014\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380038; batch adversarial loss: 0.527366\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377580; batch adversarial loss: 0.500281\n",
      "epoch 131; iter: 0; batch classifier loss: 0.313693; batch adversarial loss: 0.544182\n",
      "epoch 132; iter: 0; batch classifier loss: 0.484274; batch adversarial loss: 0.579762\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412688; batch adversarial loss: 0.554213\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361108; batch adversarial loss: 0.526648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.332704; batch adversarial loss: 0.527399\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397088; batch adversarial loss: 0.571392\n",
      "epoch 137; iter: 0; batch classifier loss: 0.307290; batch adversarial loss: 0.481845\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375150; batch adversarial loss: 0.518561\n",
      "epoch 139; iter: 0; batch classifier loss: 0.410680; batch adversarial loss: 0.659437\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404090; batch adversarial loss: 0.483269\n",
      "epoch 141; iter: 0; batch classifier loss: 0.371780; batch adversarial loss: 0.536370\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348216; batch adversarial loss: 0.571016\n",
      "epoch 143; iter: 0; batch classifier loss: 0.436402; batch adversarial loss: 0.597292\n",
      "epoch 144; iter: 0; batch classifier loss: 0.335827; batch adversarial loss: 0.518264\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375852; batch adversarial loss: 0.606355\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331696; batch adversarial loss: 0.570806\n",
      "epoch 147; iter: 0; batch classifier loss: 0.469142; batch adversarial loss: 0.553972\n",
      "epoch 148; iter: 0; batch classifier loss: 0.340088; batch adversarial loss: 0.562153\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402922; batch adversarial loss: 0.562431\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381004; batch adversarial loss: 0.588855\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376868; batch adversarial loss: 0.580402\n",
      "epoch 152; iter: 0; batch classifier loss: 0.328914; batch adversarial loss: 0.589041\n",
      "epoch 153; iter: 0; batch classifier loss: 0.449134; batch adversarial loss: 0.650529\n",
      "epoch 154; iter: 0; batch classifier loss: 0.290853; batch adversarial loss: 0.536129\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354279; batch adversarial loss: 0.580018\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413973; batch adversarial loss: 0.633351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367252; batch adversarial loss: 0.606389\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325757; batch adversarial loss: 0.527259\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329335; batch adversarial loss: 0.570952\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339120; batch adversarial loss: 0.518261\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375158; batch adversarial loss: 0.588871\n",
      "epoch 162; iter: 0; batch classifier loss: 0.418145; batch adversarial loss: 0.553961\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365276; batch adversarial loss: 0.526966\n",
      "epoch 164; iter: 0; batch classifier loss: 0.401635; batch adversarial loss: 0.615265\n",
      "epoch 165; iter: 0; batch classifier loss: 0.432499; batch adversarial loss: 0.544765\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364202; batch adversarial loss: 0.615543\n",
      "epoch 167; iter: 0; batch classifier loss: 0.297966; batch adversarial loss: 0.553278\n",
      "epoch 168; iter: 0; batch classifier loss: 0.424036; batch adversarial loss: 0.650339\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380822; batch adversarial loss: 0.570755\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355720; batch adversarial loss: 0.518846\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340444; batch adversarial loss: 0.588699\n",
      "epoch 172; iter: 0; batch classifier loss: 0.442641; batch adversarial loss: 0.615422\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335981; batch adversarial loss: 0.448293\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321484; batch adversarial loss: 0.518029\n",
      "epoch 175; iter: 0; batch classifier loss: 0.399917; batch adversarial loss: 0.614836\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396686; batch adversarial loss: 0.465931\n",
      "epoch 177; iter: 0; batch classifier loss: 0.440187; batch adversarial loss: 0.570832\n",
      "epoch 178; iter: 0; batch classifier loss: 0.392871; batch adversarial loss: 0.562570\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355704; batch adversarial loss: 0.527340\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386218; batch adversarial loss: 0.588831\n",
      "epoch 181; iter: 0; batch classifier loss: 0.375663; batch adversarial loss: 0.492247\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377001; batch adversarial loss: 0.536212\n",
      "epoch 183; iter: 0; batch classifier loss: 0.380649; batch adversarial loss: 0.483282\n",
      "epoch 184; iter: 0; batch classifier loss: 0.435952; batch adversarial loss: 0.562432\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305623; batch adversarial loss: 0.562279\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366940; batch adversarial loss: 0.535584\n",
      "epoch 187; iter: 0; batch classifier loss: 0.415662; batch adversarial loss: 0.597793\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378150; batch adversarial loss: 0.561922\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341520; batch adversarial loss: 0.518238\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327844; batch adversarial loss: 0.562030\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372253; batch adversarial loss: 0.597221\n",
      "epoch 192; iter: 0; batch classifier loss: 0.472593; batch adversarial loss: 0.606521\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370509; batch adversarial loss: 0.579906\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360223; batch adversarial loss: 0.527840\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339642; batch adversarial loss: 0.500982\n",
      "epoch 196; iter: 0; batch classifier loss: 0.391943; batch adversarial loss: 0.535858\n",
      "epoch 197; iter: 0; batch classifier loss: 0.382622; batch adversarial loss: 0.518456\n",
      "epoch 198; iter: 0; batch classifier loss: 0.399134; batch adversarial loss: 0.492044\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404783; batch adversarial loss: 0.544884\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701710; batch adversarial loss: 0.585264\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595081; batch adversarial loss: 0.655705\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616569; batch adversarial loss: 0.633456\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556172; batch adversarial loss: 0.617787\n",
      "epoch 4; iter: 0; batch classifier loss: 0.599942; batch adversarial loss: 0.691364\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588567; batch adversarial loss: 0.601004\n",
      "epoch 6; iter: 0; batch classifier loss: 0.637437; batch adversarial loss: 0.550188\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532825; batch adversarial loss: 0.603580\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520937; batch adversarial loss: 0.612297\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495830; batch adversarial loss: 0.593534\n",
      "epoch 10; iter: 0; batch classifier loss: 0.459517; batch adversarial loss: 0.568110\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490727; batch adversarial loss: 0.562425\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491543; batch adversarial loss: 0.536050\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515914; batch adversarial loss: 0.559951\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504110; batch adversarial loss: 0.584798\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409561; batch adversarial loss: 0.614752\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495498; batch adversarial loss: 0.612083\n",
      "epoch 17; iter: 0; batch classifier loss: 0.475927; batch adversarial loss: 0.558570\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498304; batch adversarial loss: 0.508240\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522949; batch adversarial loss: 0.599299\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472867; batch adversarial loss: 0.537143\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537703; batch adversarial loss: 0.512968\n",
      "epoch 22; iter: 0; batch classifier loss: 0.444786; batch adversarial loss: 0.588675\n",
      "epoch 23; iter: 0; batch classifier loss: 0.428462; batch adversarial loss: 0.580623\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509225; batch adversarial loss: 0.560786\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535369; batch adversarial loss: 0.582611\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483749; batch adversarial loss: 0.579574\n",
      "epoch 27; iter: 0; batch classifier loss: 0.498725; batch adversarial loss: 0.579425\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446928; batch adversarial loss: 0.547480\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492453; batch adversarial loss: 0.530188\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492786; batch adversarial loss: 0.517470\n",
      "epoch 31; iter: 0; batch classifier loss: 0.583668; batch adversarial loss: 0.491822\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506249; batch adversarial loss: 0.577763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.482949; batch adversarial loss: 0.544824\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448891; batch adversarial loss: 0.502917\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478134; batch adversarial loss: 0.565720\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508446; batch adversarial loss: 0.640842\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427837; batch adversarial loss: 0.532326\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480748; batch adversarial loss: 0.603830\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468974; batch adversarial loss: 0.546274\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493167; batch adversarial loss: 0.564743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459812; batch adversarial loss: 0.581791\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463848; batch adversarial loss: 0.563222\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433228; batch adversarial loss: 0.512394\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369868; batch adversarial loss: 0.562280\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382605; batch adversarial loss: 0.503254\n",
      "epoch 46; iter: 0; batch classifier loss: 0.384735; batch adversarial loss: 0.638660\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403898; batch adversarial loss: 0.570725\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460013; batch adversarial loss: 0.596186\n",
      "epoch 49; iter: 0; batch classifier loss: 0.479666; batch adversarial loss: 0.552128\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430559; batch adversarial loss: 0.581657\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423887; batch adversarial loss: 0.526753\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386916; batch adversarial loss: 0.536891\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438766; batch adversarial loss: 0.595954\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405930; batch adversarial loss: 0.536015\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436220; batch adversarial loss: 0.482940\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434972; batch adversarial loss: 0.482609\n",
      "epoch 57; iter: 0; batch classifier loss: 0.505761; batch adversarial loss: 0.606335\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422319; batch adversarial loss: 0.518060\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411148; batch adversarial loss: 0.562428\n",
      "epoch 60; iter: 0; batch classifier loss: 0.479677; batch adversarial loss: 0.500908\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410279; batch adversarial loss: 0.580181\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453901; batch adversarial loss: 0.572094\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399339; batch adversarial loss: 0.500470\n",
      "epoch 64; iter: 0; batch classifier loss: 0.468390; batch adversarial loss: 0.535915\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447575; batch adversarial loss: 0.641598\n",
      "epoch 66; iter: 0; batch classifier loss: 0.480941; batch adversarial loss: 0.553469\n",
      "epoch 67; iter: 0; batch classifier loss: 0.397152; batch adversarial loss: 0.562545\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375575; batch adversarial loss: 0.500755\n",
      "epoch 69; iter: 0; batch classifier loss: 0.468268; batch adversarial loss: 0.509876\n",
      "epoch 70; iter: 0; batch classifier loss: 0.449746; batch adversarial loss: 0.562523\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394736; batch adversarial loss: 0.562894\n",
      "epoch 72; iter: 0; batch classifier loss: 0.465724; batch adversarial loss: 0.518839\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441900; batch adversarial loss: 0.562260\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415836; batch adversarial loss: 0.596345\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418850; batch adversarial loss: 0.544911\n",
      "epoch 76; iter: 0; batch classifier loss: 0.342644; batch adversarial loss: 0.535946\n",
      "epoch 77; iter: 0; batch classifier loss: 0.359787; batch adversarial loss: 0.588446\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386954; batch adversarial loss: 0.544744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.459763; batch adversarial loss: 0.536096\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392072; batch adversarial loss: 0.623651\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375925; batch adversarial loss: 0.589569\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368719; batch adversarial loss: 0.614996\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381293; batch adversarial loss: 0.553749\n",
      "epoch 84; iter: 0; batch classifier loss: 0.357014; batch adversarial loss: 0.535870\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365855; batch adversarial loss: 0.492660\n",
      "epoch 86; iter: 0; batch classifier loss: 0.459023; batch adversarial loss: 0.553854\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427723; batch adversarial loss: 0.527300\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427969; batch adversarial loss: 0.580120\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396392; batch adversarial loss: 0.553405\n",
      "epoch 90; iter: 0; batch classifier loss: 0.441196; batch adversarial loss: 0.553703\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373539; batch adversarial loss: 0.527223\n",
      "epoch 92; iter: 0; batch classifier loss: 0.471726; batch adversarial loss: 0.579591\n",
      "epoch 93; iter: 0; batch classifier loss: 0.494099; batch adversarial loss: 0.562189\n",
      "epoch 94; iter: 0; batch classifier loss: 0.393378; batch adversarial loss: 0.614404\n",
      "epoch 95; iter: 0; batch classifier loss: 0.403272; batch adversarial loss: 0.606408\n",
      "epoch 96; iter: 0; batch classifier loss: 0.453204; batch adversarial loss: 0.518229\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391107; batch adversarial loss: 0.588371\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438102; batch adversarial loss: 0.562240\n",
      "epoch 99; iter: 0; batch classifier loss: 0.336361; batch adversarial loss: 0.545038\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412944; batch adversarial loss: 0.623661\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403811; batch adversarial loss: 0.526981\n",
      "epoch 102; iter: 0; batch classifier loss: 0.411626; batch adversarial loss: 0.492095\n",
      "epoch 103; iter: 0; batch classifier loss: 0.302303; batch adversarial loss: 0.527442\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389107; batch adversarial loss: 0.614881\n",
      "epoch 105; iter: 0; batch classifier loss: 0.303784; batch adversarial loss: 0.606054\n",
      "epoch 106; iter: 0; batch classifier loss: 0.457990; batch adversarial loss: 0.615249\n",
      "epoch 107; iter: 0; batch classifier loss: 0.432112; batch adversarial loss: 0.465894\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385199; batch adversarial loss: 0.527686\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423268; batch adversarial loss: 0.622796\n",
      "epoch 110; iter: 0; batch classifier loss: 0.444464; batch adversarial loss: 0.571720\n",
      "epoch 111; iter: 0; batch classifier loss: 0.452296; batch adversarial loss: 0.527059\n",
      "epoch 112; iter: 0; batch classifier loss: 0.439878; batch adversarial loss: 0.544403\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397634; batch adversarial loss: 0.614939\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394448; batch adversarial loss: 0.562050\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332338; batch adversarial loss: 0.597062\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384487; batch adversarial loss: 0.501136\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375190; batch adversarial loss: 0.571170\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427130; batch adversarial loss: 0.562122\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385980; batch adversarial loss: 0.614846\n",
      "epoch 120; iter: 0; batch classifier loss: 0.355733; batch adversarial loss: 0.614941\n",
      "epoch 121; iter: 0; batch classifier loss: 0.300307; batch adversarial loss: 0.571297\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373717; batch adversarial loss: 0.545088\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334127; batch adversarial loss: 0.570903\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392174; batch adversarial loss: 0.518227\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384928; batch adversarial loss: 0.545246\n",
      "epoch 126; iter: 0; batch classifier loss: 0.415015; batch adversarial loss: 0.588432\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402619; batch adversarial loss: 0.615376\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395835; batch adversarial loss: 0.527094\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431316; batch adversarial loss: 0.527134\n",
      "epoch 130; iter: 0; batch classifier loss: 0.456319; batch adversarial loss: 0.500762\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381213; batch adversarial loss: 0.544093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.312331; batch adversarial loss: 0.536632\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349930; batch adversarial loss: 0.562612\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383490; batch adversarial loss: 0.545271\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388504; batch adversarial loss: 0.570744\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392127; batch adversarial loss: 0.579889\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380321; batch adversarial loss: 0.535399\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405552; batch adversarial loss: 0.527904\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368403; batch adversarial loss: 0.561704\n",
      "epoch 140; iter: 0; batch classifier loss: 0.425062; batch adversarial loss: 0.457283\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399312; batch adversarial loss: 0.466012\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367153; batch adversarial loss: 0.587744\n",
      "epoch 143; iter: 0; batch classifier loss: 0.362094; batch adversarial loss: 0.562955\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358665; batch adversarial loss: 0.536951\n",
      "epoch 145; iter: 0; batch classifier loss: 0.432424; batch adversarial loss: 0.561720\n",
      "epoch 146; iter: 0; batch classifier loss: 0.484816; batch adversarial loss: 0.624123\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342645; batch adversarial loss: 0.606971\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358306; batch adversarial loss: 0.622694\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392057; batch adversarial loss: 0.526812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.310209; batch adversarial loss: 0.553743\n",
      "epoch 151; iter: 0; batch classifier loss: 0.346096; batch adversarial loss: 0.492182\n",
      "epoch 152; iter: 0; batch classifier loss: 0.271157; batch adversarial loss: 0.545245\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368640; batch adversarial loss: 0.474068\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364280; batch adversarial loss: 0.535750\n",
      "epoch 155; iter: 0; batch classifier loss: 0.449459; batch adversarial loss: 0.606296\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404451; batch adversarial loss: 0.572013\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393305; batch adversarial loss: 0.553504\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362194; batch adversarial loss: 0.502336\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377170; batch adversarial loss: 0.545108\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341495; batch adversarial loss: 0.633273\n",
      "epoch 161; iter: 0; batch classifier loss: 0.349810; batch adversarial loss: 0.562270\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387718; batch adversarial loss: 0.554395\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331677; batch adversarial loss: 0.588783\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333716; batch adversarial loss: 0.580265\n",
      "epoch 165; iter: 0; batch classifier loss: 0.294804; batch adversarial loss: 0.545291\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357921; batch adversarial loss: 0.649113\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345475; batch adversarial loss: 0.677131\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347419; batch adversarial loss: 0.553365\n",
      "epoch 169; iter: 0; batch classifier loss: 0.414997; batch adversarial loss: 0.597929\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378514; batch adversarial loss: 0.684510\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317926; batch adversarial loss: 0.536378\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379786; batch adversarial loss: 0.588681\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323132; batch adversarial loss: 0.596785\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359795; batch adversarial loss: 0.483385\n",
      "epoch 175; iter: 0; batch classifier loss: 0.405346; batch adversarial loss: 0.526893\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384630; batch adversarial loss: 0.633380\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355504; batch adversarial loss: 0.500842\n",
      "epoch 178; iter: 0; batch classifier loss: 0.440039; batch adversarial loss: 0.500302\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384772; batch adversarial loss: 0.580297\n",
      "epoch 180; iter: 0; batch classifier loss: 0.438073; batch adversarial loss: 0.589227\n",
      "epoch 181; iter: 0; batch classifier loss: 0.298393; batch adversarial loss: 0.526824\n",
      "epoch 182; iter: 0; batch classifier loss: 0.448767; batch adversarial loss: 0.579629\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348783; batch adversarial loss: 0.562067\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344756; batch adversarial loss: 0.595943\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307146; batch adversarial loss: 0.579502\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312714; batch adversarial loss: 0.563062\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340070; batch adversarial loss: 0.535698\n",
      "epoch 188; iter: 0; batch classifier loss: 0.364900; batch adversarial loss: 0.607800\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366098; batch adversarial loss: 0.579898\n",
      "epoch 190; iter: 0; batch classifier loss: 0.394312; batch adversarial loss: 0.543339\n",
      "epoch 191; iter: 0; batch classifier loss: 0.405316; batch adversarial loss: 0.535986\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319169; batch adversarial loss: 0.562431\n",
      "epoch 193; iter: 0; batch classifier loss: 0.468489; batch adversarial loss: 0.607113\n",
      "epoch 194; iter: 0; batch classifier loss: 0.383706; batch adversarial loss: 0.614818\n",
      "epoch 195; iter: 0; batch classifier loss: 0.313360; batch adversarial loss: 0.510358\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342149; batch adversarial loss: 0.536545\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353666; batch adversarial loss: 0.580663\n",
      "epoch 198; iter: 0; batch classifier loss: 0.438099; batch adversarial loss: 0.622683\n",
      "epoch 199; iter: 0; batch classifier loss: 0.450067; batch adversarial loss: 0.535847\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698721; batch adversarial loss: 0.732166\n",
      "epoch 1; iter: 0; batch classifier loss: 0.713238; batch adversarial loss: 0.749210\n",
      "epoch 2; iter: 0; batch classifier loss: 0.741611; batch adversarial loss: 0.708560\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573861; batch adversarial loss: 0.662836\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535700; batch adversarial loss: 0.631211\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557597; batch adversarial loss: 0.618742\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560950; batch adversarial loss: 0.626247\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553476; batch adversarial loss: 0.610555\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572250; batch adversarial loss: 0.602569\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533053; batch adversarial loss: 0.607934\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491241; batch adversarial loss: 0.544995\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563155; batch adversarial loss: 0.623305\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548879; batch adversarial loss: 0.601094\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583070; batch adversarial loss: 0.568458\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554945; batch adversarial loss: 0.581306\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489921; batch adversarial loss: 0.503122\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512085; batch adversarial loss: 0.553229\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494565; batch adversarial loss: 0.531054\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454593; batch adversarial loss: 0.546953\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522138; batch adversarial loss: 0.577537\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507214; batch adversarial loss: 0.527704\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532319; batch adversarial loss: 0.562396\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451086; batch adversarial loss: 0.521158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.407456; batch adversarial loss: 0.521237\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440309; batch adversarial loss: 0.542841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505814; batch adversarial loss: 0.565969\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489669; batch adversarial loss: 0.581536\n",
      "epoch 27; iter: 0; batch classifier loss: 0.528786; batch adversarial loss: 0.502517\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452024; batch adversarial loss: 0.558636\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512786; batch adversarial loss: 0.589244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.480687; batch adversarial loss: 0.593906\n",
      "epoch 31; iter: 0; batch classifier loss: 0.377213; batch adversarial loss: 0.559027\n",
      "epoch 32; iter: 0; batch classifier loss: 0.538137; batch adversarial loss: 0.616104\n",
      "epoch 33; iter: 0; batch classifier loss: 0.418836; batch adversarial loss: 0.644985\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421315; batch adversarial loss: 0.621106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.383217; batch adversarial loss: 0.588861\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499062; batch adversarial loss: 0.567727\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486021; batch adversarial loss: 0.573030\n",
      "epoch 38; iter: 0; batch classifier loss: 0.356182; batch adversarial loss: 0.551885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401670; batch adversarial loss: 0.557398\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411141; batch adversarial loss: 0.579548\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389171; batch adversarial loss: 0.558887\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464783; batch adversarial loss: 0.626042\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420871; batch adversarial loss: 0.507111\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427737; batch adversarial loss: 0.572353\n",
      "epoch 45; iter: 0; batch classifier loss: 0.351762; batch adversarial loss: 0.556216\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452763; batch adversarial loss: 0.539090\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477716; batch adversarial loss: 0.525669\n",
      "epoch 48; iter: 0; batch classifier loss: 0.394330; batch adversarial loss: 0.530449\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458385; batch adversarial loss: 0.517695\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411940; batch adversarial loss: 0.590265\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450418; batch adversarial loss: 0.527978\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372442; batch adversarial loss: 0.546355\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412297; batch adversarial loss: 0.604716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415928; batch adversarial loss: 0.571495\n",
      "epoch 55; iter: 0; batch classifier loss: 0.359004; batch adversarial loss: 0.580924\n",
      "epoch 56; iter: 0; batch classifier loss: 0.387977; batch adversarial loss: 0.535943\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395933; batch adversarial loss: 0.554313\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409690; batch adversarial loss: 0.588571\n",
      "epoch 59; iter: 0; batch classifier loss: 0.544659; batch adversarial loss: 0.596523\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466667; batch adversarial loss: 0.537223\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435881; batch adversarial loss: 0.519256\n",
      "epoch 62; iter: 0; batch classifier loss: 0.411987; batch adversarial loss: 0.604881\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392113; batch adversarial loss: 0.553954\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450345; batch adversarial loss: 0.605453\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423368; batch adversarial loss: 0.527459\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398613; batch adversarial loss: 0.613394\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380032; batch adversarial loss: 0.536314\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364406; batch adversarial loss: 0.578936\n",
      "epoch 69; iter: 0; batch classifier loss: 0.446348; batch adversarial loss: 0.562106\n",
      "epoch 70; iter: 0; batch classifier loss: 0.442698; batch adversarial loss: 0.605855\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450533; batch adversarial loss: 0.614607\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432141; batch adversarial loss: 0.544936\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418787; batch adversarial loss: 0.562323\n",
      "epoch 74; iter: 0; batch classifier loss: 0.450049; batch adversarial loss: 0.553291\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384142; batch adversarial loss: 0.519182\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422225; batch adversarial loss: 0.623494\n",
      "epoch 77; iter: 0; batch classifier loss: 0.316502; batch adversarial loss: 0.501759\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355675; batch adversarial loss: 0.587850\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413810; batch adversarial loss: 0.554283\n",
      "epoch 80; iter: 0; batch classifier loss: 0.446740; batch adversarial loss: 0.544691\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428240; batch adversarial loss: 0.537012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365248; batch adversarial loss: 0.640612\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345344; batch adversarial loss: 0.571121\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365353; batch adversarial loss: 0.595754\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361902; batch adversarial loss: 0.572955\n",
      "epoch 86; iter: 0; batch classifier loss: 0.313866; batch adversarial loss: 0.560451\n",
      "epoch 87; iter: 0; batch classifier loss: 0.354012; batch adversarial loss: 0.535481\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414604; batch adversarial loss: 0.586473\n",
      "epoch 89; iter: 0; batch classifier loss: 0.323001; batch adversarial loss: 0.537252\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413859; batch adversarial loss: 0.596134\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391627; batch adversarial loss: 0.537820\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410502; batch adversarial loss: 0.495065\n",
      "epoch 93; iter: 0; batch classifier loss: 0.428130; batch adversarial loss: 0.545498\n",
      "epoch 94; iter: 0; batch classifier loss: 0.314061; batch adversarial loss: 0.502899\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393644; batch adversarial loss: 0.596059\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324525; batch adversarial loss: 0.621288\n",
      "epoch 97; iter: 0; batch classifier loss: 0.462806; batch adversarial loss: 0.535963\n",
      "epoch 98; iter: 0; batch classifier loss: 0.485238; batch adversarial loss: 0.634658\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401504; batch adversarial loss: 0.542649\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364756; batch adversarial loss: 0.635802\n",
      "epoch 101; iter: 0; batch classifier loss: 0.303310; batch adversarial loss: 0.616756\n",
      "epoch 102; iter: 0; batch classifier loss: 0.336795; batch adversarial loss: 0.557084\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390578; batch adversarial loss: 0.549284\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350812; batch adversarial loss: 0.528618\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427144; batch adversarial loss: 0.530298\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360755; batch adversarial loss: 0.579980\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364882; batch adversarial loss: 0.591353\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351701; batch adversarial loss: 0.482977\n",
      "epoch 109; iter: 0; batch classifier loss: 0.339759; batch adversarial loss: 0.534777\n",
      "epoch 110; iter: 0; batch classifier loss: 0.406323; batch adversarial loss: 0.570738\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388331; batch adversarial loss: 0.546933\n",
      "epoch 112; iter: 0; batch classifier loss: 0.279867; batch adversarial loss: 0.633027\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335556; batch adversarial loss: 0.536447\n",
      "epoch 114; iter: 0; batch classifier loss: 0.470177; batch adversarial loss: 0.554121\n",
      "epoch 115; iter: 0; batch classifier loss: 0.452426; batch adversarial loss: 0.476047\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438826; batch adversarial loss: 0.545505\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415894; batch adversarial loss: 0.561722\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361387; batch adversarial loss: 0.587415\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372337; batch adversarial loss: 0.578897\n",
      "epoch 120; iter: 0; batch classifier loss: 0.321841; batch adversarial loss: 0.544575\n",
      "epoch 121; iter: 0; batch classifier loss: 0.479826; batch adversarial loss: 0.440389\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410070; batch adversarial loss: 0.579872\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355693; batch adversarial loss: 0.544912\n",
      "epoch 124; iter: 0; batch classifier loss: 0.439469; batch adversarial loss: 0.554263\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389141; batch adversarial loss: 0.588677\n",
      "epoch 126; iter: 0; batch classifier loss: 0.393101; batch adversarial loss: 0.553901\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386605; batch adversarial loss: 0.544861\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352587; batch adversarial loss: 0.528474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.380921; batch adversarial loss: 0.518762\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384027; batch adversarial loss: 0.475834\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400683; batch adversarial loss: 0.588016\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330446; batch adversarial loss: 0.483884\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378212; batch adversarial loss: 0.562125\n",
      "epoch 134; iter: 0; batch classifier loss: 0.441489; batch adversarial loss: 0.509892\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388813; batch adversarial loss: 0.544636\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373640; batch adversarial loss: 0.553433\n",
      "epoch 137; iter: 0; batch classifier loss: 0.287685; batch adversarial loss: 0.578498\n",
      "epoch 138; iter: 0; batch classifier loss: 0.284723; batch adversarial loss: 0.552378\n",
      "epoch 139; iter: 0; batch classifier loss: 0.406306; batch adversarial loss: 0.543935\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342534; batch adversarial loss: 0.649228\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357303; batch adversarial loss: 0.606301\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347283; batch adversarial loss: 0.552783\n",
      "epoch 143; iter: 0; batch classifier loss: 0.314767; batch adversarial loss: 0.571687\n",
      "epoch 144; iter: 0; batch classifier loss: 0.475874; batch adversarial loss: 0.596717\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350138; batch adversarial loss: 0.589256\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369356; batch adversarial loss: 0.536294\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322791; batch adversarial loss: 0.612603\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412631; batch adversarial loss: 0.571583\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374126; batch adversarial loss: 0.519191\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311028; batch adversarial loss: 0.649954\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422498; batch adversarial loss: 0.561989\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341681; batch adversarial loss: 0.606012\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362285; batch adversarial loss: 0.615018\n",
      "epoch 154; iter: 0; batch classifier loss: 0.315700; batch adversarial loss: 0.527677\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356408; batch adversarial loss: 0.667870\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398899; batch adversarial loss: 0.544690\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328253; batch adversarial loss: 0.554138\n",
      "epoch 158; iter: 0; batch classifier loss: 0.385683; batch adversarial loss: 0.510306\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372620; batch adversarial loss: 0.554001\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336427; batch adversarial loss: 0.467270\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333819; batch adversarial loss: 0.588252\n",
      "epoch 162; iter: 0; batch classifier loss: 0.299897; batch adversarial loss: 0.587784\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369941; batch adversarial loss: 0.545144\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360450; batch adversarial loss: 0.571627\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326959; batch adversarial loss: 0.553375\n",
      "epoch 166; iter: 0; batch classifier loss: 0.398613; batch adversarial loss: 0.570955\n",
      "epoch 167; iter: 0; batch classifier loss: 0.385846; batch adversarial loss: 0.536622\n",
      "epoch 168; iter: 0; batch classifier loss: 0.294446; batch adversarial loss: 0.623465\n",
      "epoch 169; iter: 0; batch classifier loss: 0.309140; batch adversarial loss: 0.509321\n",
      "epoch 170; iter: 0; batch classifier loss: 0.390206; batch adversarial loss: 0.518706\n",
      "epoch 171; iter: 0; batch classifier loss: 0.337033; batch adversarial loss: 0.553579\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360546; batch adversarial loss: 0.614664\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383337; batch adversarial loss: 0.545509\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404820; batch adversarial loss: 0.615232\n",
      "epoch 175; iter: 0; batch classifier loss: 0.407983; batch adversarial loss: 0.501215\n",
      "epoch 176; iter: 0; batch classifier loss: 0.375612; batch adversarial loss: 0.475645\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378556; batch adversarial loss: 0.510222\n",
      "epoch 178; iter: 0; batch classifier loss: 0.409983; batch adversarial loss: 0.518575\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330945; batch adversarial loss: 0.631054\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396568; batch adversarial loss: 0.605241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331789; batch adversarial loss: 0.570658\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356947; batch adversarial loss: 0.501896\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378084; batch adversarial loss: 0.500774\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376854; batch adversarial loss: 0.597589\n",
      "epoch 185; iter: 0; batch classifier loss: 0.301046; batch adversarial loss: 0.622998\n",
      "epoch 186; iter: 0; batch classifier loss: 0.409539; batch adversarial loss: 0.579080\n",
      "epoch 187; iter: 0; batch classifier loss: 0.312311; batch adversarial loss: 0.519360\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359585; batch adversarial loss: 0.554167\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345098; batch adversarial loss: 0.614916\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365944; batch adversarial loss: 0.570184\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316581; batch adversarial loss: 0.500743\n",
      "epoch 192; iter: 0; batch classifier loss: 0.233664; batch adversarial loss: 0.544111\n",
      "epoch 193; iter: 0; batch classifier loss: 0.416412; batch adversarial loss: 0.553196\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336461; batch adversarial loss: 0.613931\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362762; batch adversarial loss: 0.544210\n",
      "epoch 196; iter: 0; batch classifier loss: 0.294012; batch adversarial loss: 0.528161\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392736; batch adversarial loss: 0.596220\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340274; batch adversarial loss: 0.579986\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331595; batch adversarial loss: 0.589298\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736441; batch adversarial loss: 0.833314\n",
      "epoch 1; iter: 0; batch classifier loss: 0.804636; batch adversarial loss: 0.888917\n",
      "epoch 2; iter: 0; batch classifier loss: 0.819977; batch adversarial loss: 0.823343\n",
      "epoch 3; iter: 0; batch classifier loss: 0.774098; batch adversarial loss: 0.739802\n",
      "epoch 4; iter: 0; batch classifier loss: 0.755988; batch adversarial loss: 0.736750\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593386; batch adversarial loss: 0.669129\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580111; batch adversarial loss: 0.626801\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480758; batch adversarial loss: 0.655196\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545516; batch adversarial loss: 0.586779\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538680; batch adversarial loss: 0.618863\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565684; batch adversarial loss: 0.567313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517357; batch adversarial loss: 0.579916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468732; batch adversarial loss: 0.624446\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572304; batch adversarial loss: 0.558821\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521426; batch adversarial loss: 0.579746\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486828; batch adversarial loss: 0.578918\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521071; batch adversarial loss: 0.517024\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467013; batch adversarial loss: 0.538539\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524027; batch adversarial loss: 0.536571\n",
      "epoch 19; iter: 0; batch classifier loss: 0.558981; batch adversarial loss: 0.600078\n",
      "epoch 20; iter: 0; batch classifier loss: 0.550837; batch adversarial loss: 0.522282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.389623; batch adversarial loss: 0.599610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.390383; batch adversarial loss: 0.539358\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477363; batch adversarial loss: 0.534103\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480097; batch adversarial loss: 0.575492\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496690; batch adversarial loss: 0.506270\n",
      "epoch 26; iter: 0; batch classifier loss: 0.423718; batch adversarial loss: 0.638698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.483549; batch adversarial loss: 0.520732\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484480; batch adversarial loss: 0.535036\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462638; batch adversarial loss: 0.574103\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524081; batch adversarial loss: 0.527316\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435009; batch adversarial loss: 0.575433\n",
      "epoch 32; iter: 0; batch classifier loss: 0.368396; batch adversarial loss: 0.627044\n",
      "epoch 33; iter: 0; batch classifier loss: 0.493570; batch adversarial loss: 0.488313\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451213; batch adversarial loss: 0.503789\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455049; batch adversarial loss: 0.511509\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406535; batch adversarial loss: 0.585219\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399650; batch adversarial loss: 0.553295\n",
      "epoch 38; iter: 0; batch classifier loss: 0.520150; batch adversarial loss: 0.451445\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459584; batch adversarial loss: 0.579488\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477860; batch adversarial loss: 0.504468\n",
      "epoch 41; iter: 0; batch classifier loss: 0.491582; batch adversarial loss: 0.506300\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421169; batch adversarial loss: 0.505670\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464911; batch adversarial loss: 0.517074\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385346; batch adversarial loss: 0.553078\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461789; batch adversarial loss: 0.476901\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466748; batch adversarial loss: 0.571645\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424602; batch adversarial loss: 0.534513\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403353; batch adversarial loss: 0.538667\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473243; batch adversarial loss: 0.585726\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407903; batch adversarial loss: 0.471833\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444429; batch adversarial loss: 0.510407\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452326; batch adversarial loss: 0.585121\n",
      "epoch 53; iter: 0; batch classifier loss: 0.435069; batch adversarial loss: 0.541075\n",
      "epoch 54; iter: 0; batch classifier loss: 0.380949; batch adversarial loss: 0.633319\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430868; batch adversarial loss: 0.512371\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454629; batch adversarial loss: 0.583303\n",
      "epoch 57; iter: 0; batch classifier loss: 0.476133; batch adversarial loss: 0.526576\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380645; batch adversarial loss: 0.576776\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386324; batch adversarial loss: 0.538315\n",
      "epoch 60; iter: 0; batch classifier loss: 0.482946; batch adversarial loss: 0.597313\n",
      "epoch 61; iter: 0; batch classifier loss: 0.370881; batch adversarial loss: 0.569998\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424766; batch adversarial loss: 0.544182\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385631; batch adversarial loss: 0.536945\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462100; batch adversarial loss: 0.680198\n",
      "epoch 65; iter: 0; batch classifier loss: 0.332976; batch adversarial loss: 0.517614\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437970; batch adversarial loss: 0.517822\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425984; batch adversarial loss: 0.526992\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394558; batch adversarial loss: 0.580269\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376007; batch adversarial loss: 0.554911\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393246; batch adversarial loss: 0.490030\n",
      "epoch 71; iter: 0; batch classifier loss: 0.320375; batch adversarial loss: 0.526157\n",
      "epoch 72; iter: 0; batch classifier loss: 0.509197; batch adversarial loss: 0.553195\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396042; batch adversarial loss: 0.562775\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385094; batch adversarial loss: 0.517395\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367380; batch adversarial loss: 0.562806\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377141; batch adversarial loss: 0.544412\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412206; batch adversarial loss: 0.590498\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419196; batch adversarial loss: 0.535606\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416626; batch adversarial loss: 0.562782\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360163; batch adversarial loss: 0.461817\n",
      "epoch 81; iter: 0; batch classifier loss: 0.457475; batch adversarial loss: 0.570469\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421865; batch adversarial loss: 0.536275\n",
      "epoch 83; iter: 0; batch classifier loss: 0.337149; batch adversarial loss: 0.571700\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413534; batch adversarial loss: 0.526576\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369232; batch adversarial loss: 0.526568\n",
      "epoch 86; iter: 0; batch classifier loss: 0.362886; batch adversarial loss: 0.580992\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360609; batch adversarial loss: 0.571439\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345458; batch adversarial loss: 0.610631\n",
      "epoch 89; iter: 0; batch classifier loss: 0.450734; batch adversarial loss: 0.553904\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391537; batch adversarial loss: 0.608900\n",
      "epoch 91; iter: 0; batch classifier loss: 0.401079; batch adversarial loss: 0.582531\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381018; batch adversarial loss: 0.563123\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344305; batch adversarial loss: 0.570386\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374396; batch adversarial loss: 0.524950\n",
      "epoch 95; iter: 0; batch classifier loss: 0.421522; batch adversarial loss: 0.642539\n",
      "epoch 96; iter: 0; batch classifier loss: 0.348203; batch adversarial loss: 0.550835\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344426; batch adversarial loss: 0.516276\n",
      "epoch 98; iter: 0; batch classifier loss: 0.355052; batch adversarial loss: 0.552319\n",
      "epoch 99; iter: 0; batch classifier loss: 0.450957; batch adversarial loss: 0.493048\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355710; batch adversarial loss: 0.462429\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370677; batch adversarial loss: 0.563535\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393182; batch adversarial loss: 0.534922\n",
      "epoch 103; iter: 0; batch classifier loss: 0.331643; batch adversarial loss: 0.572464\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372185; batch adversarial loss: 0.617238\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390091; batch adversarial loss: 0.517190\n",
      "epoch 106; iter: 0; batch classifier loss: 0.267055; batch adversarial loss: 0.571561\n",
      "epoch 107; iter: 0; batch classifier loss: 0.289781; batch adversarial loss: 0.499350\n",
      "epoch 108; iter: 0; batch classifier loss: 0.274744; batch adversarial loss: 0.562243\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383779; batch adversarial loss: 0.473295\n",
      "epoch 110; iter: 0; batch classifier loss: 0.311175; batch adversarial loss: 0.607002\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384248; batch adversarial loss: 0.579516\n",
      "epoch 112; iter: 0; batch classifier loss: 0.457228; batch adversarial loss: 0.517063\n",
      "epoch 113; iter: 0; batch classifier loss: 0.334309; batch adversarial loss: 0.544525\n",
      "epoch 114; iter: 0; batch classifier loss: 0.304549; batch adversarial loss: 0.572013\n",
      "epoch 115; iter: 0; batch classifier loss: 0.432772; batch adversarial loss: 0.572114\n",
      "epoch 116; iter: 0; batch classifier loss: 0.386303; batch adversarial loss: 0.599322\n",
      "epoch 117; iter: 0; batch classifier loss: 0.307530; batch adversarial loss: 0.617554\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338665; batch adversarial loss: 0.617309\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417382; batch adversarial loss: 0.490238\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409782; batch adversarial loss: 0.499078\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371562; batch adversarial loss: 0.507869\n",
      "epoch 122; iter: 0; batch classifier loss: 0.318931; batch adversarial loss: 0.571926\n",
      "epoch 123; iter: 0; batch classifier loss: 0.295485; batch adversarial loss: 0.553586\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360563; batch adversarial loss: 0.635982\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399348; batch adversarial loss: 0.581027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.439349; batch adversarial loss: 0.517186\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394004; batch adversarial loss: 0.535346\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342129; batch adversarial loss: 0.489090\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373130; batch adversarial loss: 0.461151\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394051; batch adversarial loss: 0.487996\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340495; batch adversarial loss: 0.607758\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402872; batch adversarial loss: 0.580181\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356286; batch adversarial loss: 0.599942\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364251; batch adversarial loss: 0.560658\n",
      "epoch 135; iter: 0; batch classifier loss: 0.458614; batch adversarial loss: 0.544166\n",
      "epoch 136; iter: 0; batch classifier loss: 0.429592; batch adversarial loss: 0.610074\n",
      "epoch 137; iter: 0; batch classifier loss: 0.418748; batch adversarial loss: 0.527622\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344152; batch adversarial loss: 0.545703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.464757; batch adversarial loss: 0.562515\n",
      "epoch 140; iter: 0; batch classifier loss: 0.319037; batch adversarial loss: 0.526912\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361030; batch adversarial loss: 0.545247\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383701; batch adversarial loss: 0.517029\n",
      "epoch 143; iter: 0; batch classifier loss: 0.341898; batch adversarial loss: 0.554612\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401734; batch adversarial loss: 0.562856\n",
      "epoch 145; iter: 0; batch classifier loss: 0.483771; batch adversarial loss: 0.554038\n",
      "epoch 146; iter: 0; batch classifier loss: 0.415699; batch adversarial loss: 0.499489\n",
      "epoch 147; iter: 0; batch classifier loss: 0.431840; batch adversarial loss: 0.544442\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358166; batch adversarial loss: 0.535787\n",
      "epoch 149; iter: 0; batch classifier loss: 0.406542; batch adversarial loss: 0.508028\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372554; batch adversarial loss: 0.626375\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392766; batch adversarial loss: 0.526647\n",
      "epoch 152; iter: 0; batch classifier loss: 0.435704; batch adversarial loss: 0.544825\n",
      "epoch 153; iter: 0; batch classifier loss: 0.273888; batch adversarial loss: 0.544570\n",
      "epoch 154; iter: 0; batch classifier loss: 0.284340; batch adversarial loss: 0.562254\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327996; batch adversarial loss: 0.572430\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351573; batch adversarial loss: 0.608546\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394745; batch adversarial loss: 0.508384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.437701; batch adversarial loss: 0.562967\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354181; batch adversarial loss: 0.526259\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368982; batch adversarial loss: 0.571789\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337711; batch adversarial loss: 0.544472\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412995; batch adversarial loss: 0.535279\n",
      "epoch 163; iter: 0; batch classifier loss: 0.305128; batch adversarial loss: 0.635296\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378034; batch adversarial loss: 0.590018\n",
      "epoch 165; iter: 0; batch classifier loss: 0.396102; batch adversarial loss: 0.481322\n",
      "epoch 166; iter: 0; batch classifier loss: 0.345870; batch adversarial loss: 0.653474\n",
      "epoch 167; iter: 0; batch classifier loss: 0.426128; batch adversarial loss: 0.589768\n",
      "epoch 168; iter: 0; batch classifier loss: 0.297334; batch adversarial loss: 0.516903\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322083; batch adversarial loss: 0.544547\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355922; batch adversarial loss: 0.553687\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409065; batch adversarial loss: 0.562481\n",
      "epoch 172; iter: 0; batch classifier loss: 0.390907; batch adversarial loss: 0.562649\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410206; batch adversarial loss: 0.589983\n",
      "epoch 174; iter: 0; batch classifier loss: 0.406259; batch adversarial loss: 0.535416\n",
      "epoch 175; iter: 0; batch classifier loss: 0.304865; batch adversarial loss: 0.535504\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344139; batch adversarial loss: 0.571830\n",
      "epoch 177; iter: 0; batch classifier loss: 0.313906; batch adversarial loss: 0.553729\n",
      "epoch 178; iter: 0; batch classifier loss: 0.303122; batch adversarial loss: 0.589871\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366516; batch adversarial loss: 0.571997\n",
      "epoch 180; iter: 0; batch classifier loss: 0.341549; batch adversarial loss: 0.535278\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410241; batch adversarial loss: 0.508201\n",
      "epoch 182; iter: 0; batch classifier loss: 0.437042; batch adversarial loss: 0.562822\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323710; batch adversarial loss: 0.553308\n",
      "epoch 184; iter: 0; batch classifier loss: 0.314847; batch adversarial loss: 0.508241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.260079; batch adversarial loss: 0.598977\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334772; batch adversarial loss: 0.553885\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360333; batch adversarial loss: 0.544649\n",
      "epoch 188; iter: 0; batch classifier loss: 0.354813; batch adversarial loss: 0.526224\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381229; batch adversarial loss: 0.535486\n",
      "epoch 190; iter: 0; batch classifier loss: 0.396254; batch adversarial loss: 0.599217\n",
      "epoch 191; iter: 0; batch classifier loss: 0.285169; batch adversarial loss: 0.489874\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399059; batch adversarial loss: 0.563047\n",
      "epoch 193; iter: 0; batch classifier loss: 0.280397; batch adversarial loss: 0.471725\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344283; batch adversarial loss: 0.535442\n",
      "epoch 195; iter: 0; batch classifier loss: 0.418409; batch adversarial loss: 0.526239\n",
      "epoch 196; iter: 0; batch classifier loss: 0.366588; batch adversarial loss: 0.663174\n",
      "epoch 197; iter: 0; batch classifier loss: 0.310619; batch adversarial loss: 0.580984\n",
      "epoch 198; iter: 0; batch classifier loss: 0.438227; batch adversarial loss: 0.544528\n",
      "epoch 199; iter: 0; batch classifier loss: 0.321879; batch adversarial loss: 0.517251\n",
      "epoch 0; iter: 0; batch classifier loss: 0.792705; batch adversarial loss: 0.750561\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624446; batch adversarial loss: 0.700651\n",
      "epoch 2; iter: 0; batch classifier loss: 0.653399; batch adversarial loss: 0.659867\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550263; batch adversarial loss: 0.649166\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564368; batch adversarial loss: 0.616080\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580850; batch adversarial loss: 0.602615\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557847; batch adversarial loss: 0.613252\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544108; batch adversarial loss: 0.612937\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516953; batch adversarial loss: 0.582188\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536443; batch adversarial loss: 0.572842\n",
      "epoch 10; iter: 0; batch classifier loss: 0.483455; batch adversarial loss: 0.607543\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585105; batch adversarial loss: 0.609951\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566247; batch adversarial loss: 0.609345\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599548; batch adversarial loss: 0.595522\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576459; batch adversarial loss: 0.592545\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563598; batch adversarial loss: 0.590991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512623; batch adversarial loss: 0.564716\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507401; batch adversarial loss: 0.552744\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475070; batch adversarial loss: 0.560472\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528775; batch adversarial loss: 0.538759\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548403; batch adversarial loss: 0.560868\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542030; batch adversarial loss: 0.598387\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423360; batch adversarial loss: 0.490378\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460599; batch adversarial loss: 0.594978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.563710; batch adversarial loss: 0.511109\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463223; batch adversarial loss: 0.574050\n",
      "epoch 26; iter: 0; batch classifier loss: 0.394062; batch adversarial loss: 0.580382\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475226; batch adversarial loss: 0.569590\n",
      "epoch 28; iter: 0; batch classifier loss: 0.378698; batch adversarial loss: 0.572213\n",
      "epoch 29; iter: 0; batch classifier loss: 0.589421; batch adversarial loss: 0.571253\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459767; batch adversarial loss: 0.588930\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493908; batch adversarial loss: 0.538430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405867; batch adversarial loss: 0.552931\n",
      "epoch 33; iter: 0; batch classifier loss: 0.524951; batch adversarial loss: 0.605111\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474608; batch adversarial loss: 0.545673\n",
      "epoch 35; iter: 0; batch classifier loss: 0.518320; batch adversarial loss: 0.606688\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425717; batch adversarial loss: 0.562759\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460064; batch adversarial loss: 0.528748\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470567; batch adversarial loss: 0.552061\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429313; batch adversarial loss: 0.536530\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501482; batch adversarial loss: 0.526195\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459001; batch adversarial loss: 0.519216\n",
      "epoch 42; iter: 0; batch classifier loss: 0.567145; batch adversarial loss: 0.615786\n",
      "epoch 43; iter: 0; batch classifier loss: 0.388574; batch adversarial loss: 0.491540\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406319; batch adversarial loss: 0.589108\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477270; batch adversarial loss: 0.483318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448892; batch adversarial loss: 0.579546\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438703; batch adversarial loss: 0.552428\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395612; batch adversarial loss: 0.604857\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421078; batch adversarial loss: 0.563724\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457631; batch adversarial loss: 0.630985\n",
      "epoch 51; iter: 0; batch classifier loss: 0.359842; batch adversarial loss: 0.554676\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430533; batch adversarial loss: 0.501942\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381092; batch adversarial loss: 0.543768\n",
      "epoch 54; iter: 0; batch classifier loss: 0.370849; batch adversarial loss: 0.529843\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449955; batch adversarial loss: 0.548589\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436643; batch adversarial loss: 0.543814\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424666; batch adversarial loss: 0.503289\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391327; batch adversarial loss: 0.587113\n",
      "epoch 59; iter: 0; batch classifier loss: 0.507236; batch adversarial loss: 0.631783\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404867; batch adversarial loss: 0.502246\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423830; batch adversarial loss: 0.500718\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414782; batch adversarial loss: 0.550988\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379817; batch adversarial loss: 0.529081\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435267; batch adversarial loss: 0.515257\n",
      "epoch 65; iter: 0; batch classifier loss: 0.464743; batch adversarial loss: 0.599113\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414800; batch adversarial loss: 0.581437\n",
      "epoch 67; iter: 0; batch classifier loss: 0.497729; batch adversarial loss: 0.546536\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373831; batch adversarial loss: 0.554168\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418273; batch adversarial loss: 0.613965\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359124; batch adversarial loss: 0.519651\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377021; batch adversarial loss: 0.526860\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382098; batch adversarial loss: 0.545709\n",
      "epoch 73; iter: 0; batch classifier loss: 0.466939; batch adversarial loss: 0.583590\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447799; batch adversarial loss: 0.557030\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426402; batch adversarial loss: 0.537553\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425350; batch adversarial loss: 0.544819\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394049; batch adversarial loss: 0.518183\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365768; batch adversarial loss: 0.562002\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408584; batch adversarial loss: 0.500497\n",
      "epoch 80; iter: 0; batch classifier loss: 0.345013; batch adversarial loss: 0.587852\n",
      "epoch 81; iter: 0; batch classifier loss: 0.446323; batch adversarial loss: 0.559157\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393327; batch adversarial loss: 0.600672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410687; batch adversarial loss: 0.499878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372849; batch adversarial loss: 0.510234\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390848; batch adversarial loss: 0.580116\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382473; batch adversarial loss: 0.559200\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387212; batch adversarial loss: 0.509464\n",
      "epoch 88; iter: 0; batch classifier loss: 0.434921; batch adversarial loss: 0.590030\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380084; batch adversarial loss: 0.534761\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384888; batch adversarial loss: 0.563494\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409615; batch adversarial loss: 0.537477\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432736; batch adversarial loss: 0.667317\n",
      "epoch 93; iter: 0; batch classifier loss: 0.287769; batch adversarial loss: 0.499968\n",
      "epoch 94; iter: 0; batch classifier loss: 0.326151; batch adversarial loss: 0.466808\n",
      "epoch 95; iter: 0; batch classifier loss: 0.297592; batch adversarial loss: 0.539189\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386274; batch adversarial loss: 0.563161\n",
      "epoch 97; iter: 0; batch classifier loss: 0.307443; batch adversarial loss: 0.560197\n",
      "epoch 98; iter: 0; batch classifier loss: 0.496584; batch adversarial loss: 0.580508\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354428; batch adversarial loss: 0.543154\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364369; batch adversarial loss: 0.561256\n",
      "epoch 101; iter: 0; batch classifier loss: 0.356455; batch adversarial loss: 0.551907\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370609; batch adversarial loss: 0.542416\n",
      "epoch 103; iter: 0; batch classifier loss: 0.455256; batch adversarial loss: 0.606521\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413483; batch adversarial loss: 0.560396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.441702; batch adversarial loss: 0.580123\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388306; batch adversarial loss: 0.465691\n",
      "epoch 107; iter: 0; batch classifier loss: 0.344174; batch adversarial loss: 0.590679\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415905; batch adversarial loss: 0.509628\n",
      "epoch 109; iter: 0; batch classifier loss: 0.390527; batch adversarial loss: 0.549744\n",
      "epoch 110; iter: 0; batch classifier loss: 0.423818; batch adversarial loss: 0.520933\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374297; batch adversarial loss: 0.528189\n",
      "epoch 112; iter: 0; batch classifier loss: 0.314837; batch adversarial loss: 0.621724\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354913; batch adversarial loss: 0.586287\n",
      "epoch 114; iter: 0; batch classifier loss: 0.461726; batch adversarial loss: 0.536974\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341772; batch adversarial loss: 0.553308\n",
      "epoch 116; iter: 0; batch classifier loss: 0.448178; batch adversarial loss: 0.551562\n",
      "epoch 117; iter: 0; batch classifier loss: 0.427228; batch adversarial loss: 0.605341\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378169; batch adversarial loss: 0.548623\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431991; batch adversarial loss: 0.615919\n",
      "epoch 120; iter: 0; batch classifier loss: 0.384959; batch adversarial loss: 0.601338\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383094; batch adversarial loss: 0.498692\n",
      "epoch 122; iter: 0; batch classifier loss: 0.423190; batch adversarial loss: 0.555827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.310952; batch adversarial loss: 0.585676\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380892; batch adversarial loss: 0.538364\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353828; batch adversarial loss: 0.606808\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375095; batch adversarial loss: 0.515915\n",
      "epoch 127; iter: 0; batch classifier loss: 0.429119; batch adversarial loss: 0.572364\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360316; batch adversarial loss: 0.577520\n",
      "epoch 129; iter: 0; batch classifier loss: 0.297894; batch adversarial loss: 0.538493\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365492; batch adversarial loss: 0.587998\n",
      "epoch 131; iter: 0; batch classifier loss: 0.440337; batch adversarial loss: 0.616521\n",
      "epoch 132; iter: 0; batch classifier loss: 0.304489; batch adversarial loss: 0.659303\n",
      "epoch 133; iter: 0; batch classifier loss: 0.419434; batch adversarial loss: 0.502057\n",
      "epoch 134; iter: 0; batch classifier loss: 0.437697; batch adversarial loss: 0.578533\n",
      "epoch 135; iter: 0; batch classifier loss: 0.432378; batch adversarial loss: 0.564853\n",
      "epoch 136; iter: 0; batch classifier loss: 0.424362; batch adversarial loss: 0.570487\n",
      "epoch 137; iter: 0; batch classifier loss: 0.338221; batch adversarial loss: 0.577262\n",
      "epoch 138; iter: 0; batch classifier loss: 0.436754; batch adversarial loss: 0.497358\n",
      "epoch 139; iter: 0; batch classifier loss: 0.430099; batch adversarial loss: 0.622991\n",
      "epoch 140; iter: 0; batch classifier loss: 0.380586; batch adversarial loss: 0.502638\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348997; batch adversarial loss: 0.544867\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387387; batch adversarial loss: 0.675422\n",
      "epoch 143; iter: 0; batch classifier loss: 0.461360; batch adversarial loss: 0.502316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.428820; batch adversarial loss: 0.589600\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334676; batch adversarial loss: 0.545436\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418023; batch adversarial loss: 0.534323\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307791; batch adversarial loss: 0.631993\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417263; batch adversarial loss: 0.517860\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331802; batch adversarial loss: 0.529456\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396530; batch adversarial loss: 0.562095\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386369; batch adversarial loss: 0.535399\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366956; batch adversarial loss: 0.577930\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342765; batch adversarial loss: 0.554142\n",
      "epoch 154; iter: 0; batch classifier loss: 0.289365; batch adversarial loss: 0.570750\n",
      "epoch 155; iter: 0; batch classifier loss: 0.303970; batch adversarial loss: 0.573486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381552; batch adversarial loss: 0.542115\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374952; batch adversarial loss: 0.501544\n",
      "epoch 158; iter: 0; batch classifier loss: 0.480682; batch adversarial loss: 0.563393\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277925; batch adversarial loss: 0.521549\n",
      "epoch 160; iter: 0; batch classifier loss: 0.355003; batch adversarial loss: 0.611503\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370568; batch adversarial loss: 0.573041\n",
      "epoch 162; iter: 0; batch classifier loss: 0.285390; batch adversarial loss: 0.516397\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417582; batch adversarial loss: 0.497425\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351028; batch adversarial loss: 0.547041\n",
      "epoch 165; iter: 0; batch classifier loss: 0.403798; batch adversarial loss: 0.552339\n",
      "epoch 166; iter: 0; batch classifier loss: 0.468322; batch adversarial loss: 0.547162\n",
      "epoch 167; iter: 0; batch classifier loss: 0.431231; batch adversarial loss: 0.550350\n",
      "epoch 168; iter: 0; batch classifier loss: 0.477964; batch adversarial loss: 0.543330\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350449; batch adversarial loss: 0.581814\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386327; batch adversarial loss: 0.527210\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336928; batch adversarial loss: 0.568775\n",
      "epoch 172; iter: 0; batch classifier loss: 0.400478; batch adversarial loss: 0.516665\n",
      "epoch 173; iter: 0; batch classifier loss: 0.437980; batch adversarial loss: 0.574083\n",
      "epoch 174; iter: 0; batch classifier loss: 0.354851; batch adversarial loss: 0.554846\n",
      "epoch 175; iter: 0; batch classifier loss: 0.406482; batch adversarial loss: 0.501279\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388086; batch adversarial loss: 0.532014\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384411; batch adversarial loss: 0.538079\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332937; batch adversarial loss: 0.582682\n",
      "epoch 179; iter: 0; batch classifier loss: 0.325070; batch adversarial loss: 0.599541\n",
      "epoch 180; iter: 0; batch classifier loss: 0.571082; batch adversarial loss: 0.563330\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332922; batch adversarial loss: 0.608935\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358578; batch adversarial loss: 0.564260\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346444; batch adversarial loss: 0.527948\n",
      "epoch 184; iter: 0; batch classifier loss: 0.412983; batch adversarial loss: 0.601284\n",
      "epoch 185; iter: 0; batch classifier loss: 0.374276; batch adversarial loss: 0.534620\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383670; batch adversarial loss: 0.598807\n",
      "epoch 187; iter: 0; batch classifier loss: 0.402338; batch adversarial loss: 0.542813\n",
      "epoch 188; iter: 0; batch classifier loss: 0.351380; batch adversarial loss: 0.552786\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335731; batch adversarial loss: 0.538306\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323748; batch adversarial loss: 0.511847\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362309; batch adversarial loss: 0.489531\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358165; batch adversarial loss: 0.490377\n",
      "epoch 193; iter: 0; batch classifier loss: 0.397082; batch adversarial loss: 0.531061\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393135; batch adversarial loss: 0.581393\n",
      "epoch 195; iter: 0; batch classifier loss: 0.450318; batch adversarial loss: 0.510149\n",
      "epoch 196; iter: 0; batch classifier loss: 0.434242; batch adversarial loss: 0.517560\n",
      "epoch 197; iter: 0; batch classifier loss: 0.463058; batch adversarial loss: 0.614942\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358704; batch adversarial loss: 0.559373\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404001; batch adversarial loss: 0.544857\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770825; batch adversarial loss: 1.073677\n",
      "epoch 1; iter: 0; batch classifier loss: 0.893537; batch adversarial loss: 1.202411\n",
      "epoch 2; iter: 0; batch classifier loss: 1.022683; batch adversarial loss: 1.125052\n",
      "epoch 3; iter: 0; batch classifier loss: 1.118660; batch adversarial loss: 1.024891\n",
      "epoch 4; iter: 0; batch classifier loss: 0.930895; batch adversarial loss: 0.955291\n",
      "epoch 5; iter: 0; batch classifier loss: 0.928123; batch adversarial loss: 0.869163\n",
      "epoch 6; iter: 0; batch classifier loss: 1.080241; batch adversarial loss: 0.785715\n",
      "epoch 7; iter: 0; batch classifier loss: 0.901591; batch adversarial loss: 0.731493\n",
      "epoch 8; iter: 0; batch classifier loss: 0.746580; batch adversarial loss: 0.694383\n",
      "epoch 9; iter: 0; batch classifier loss: 0.608585; batch adversarial loss: 0.653563\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579614; batch adversarial loss: 0.572564\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526999; batch adversarial loss: 0.606843\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553719; batch adversarial loss: 0.594304\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508060; batch adversarial loss: 0.616803\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535022; batch adversarial loss: 0.568580\n",
      "epoch 15; iter: 0; batch classifier loss: 0.439069; batch adversarial loss: 0.560507\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513695; batch adversarial loss: 0.551900\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496689; batch adversarial loss: 0.526129\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515624; batch adversarial loss: 0.530658\n",
      "epoch 19; iter: 0; batch classifier loss: 0.433797; batch adversarial loss: 0.620346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.456427; batch adversarial loss: 0.556888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490907; batch adversarial loss: 0.593901\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453172; batch adversarial loss: 0.556066\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510675; batch adversarial loss: 0.533292\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402733; batch adversarial loss: 0.595172\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470228; batch adversarial loss: 0.574295\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493624; batch adversarial loss: 0.537040\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450418; batch adversarial loss: 0.610252\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470740; batch adversarial loss: 0.601009\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502254; batch adversarial loss: 0.618093\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550780; batch adversarial loss: 0.633544\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495880; batch adversarial loss: 0.585457\n",
      "epoch 32; iter: 0; batch classifier loss: 0.440392; batch adversarial loss: 0.545572\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451128; batch adversarial loss: 0.560487\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440284; batch adversarial loss: 0.511757\n",
      "epoch 35; iter: 0; batch classifier loss: 0.516021; batch adversarial loss: 0.528135\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503675; batch adversarial loss: 0.562206\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472634; batch adversarial loss: 0.536867\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409703; batch adversarial loss: 0.553342\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430488; batch adversarial loss: 0.544967\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454169; batch adversarial loss: 0.598644\n",
      "epoch 41; iter: 0; batch classifier loss: 0.491045; batch adversarial loss: 0.536741\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443091; batch adversarial loss: 0.560029\n",
      "epoch 43; iter: 0; batch classifier loss: 0.352850; batch adversarial loss: 0.562901\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433807; batch adversarial loss: 0.581324\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453025; batch adversarial loss: 0.623450\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391345; batch adversarial loss: 0.596034\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467633; batch adversarial loss: 0.572258\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486507; batch adversarial loss: 0.642856\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464021; batch adversarial loss: 0.570098\n",
      "epoch 50; iter: 0; batch classifier loss: 0.464024; batch adversarial loss: 0.585996\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384706; batch adversarial loss: 0.491755\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476575; batch adversarial loss: 0.528588\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406446; batch adversarial loss: 0.571714\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446887; batch adversarial loss: 0.517303\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459131; batch adversarial loss: 0.600820\n",
      "epoch 56; iter: 0; batch classifier loss: 0.407210; batch adversarial loss: 0.483761\n",
      "epoch 57; iter: 0; batch classifier loss: 0.417742; batch adversarial loss: 0.572106\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407702; batch adversarial loss: 0.615839\n",
      "epoch 59; iter: 0; batch classifier loss: 0.403798; batch adversarial loss: 0.555126\n",
      "epoch 60; iter: 0; batch classifier loss: 0.458599; batch adversarial loss: 0.536390\n",
      "epoch 61; iter: 0; batch classifier loss: 0.372307; batch adversarial loss: 0.568652\n",
      "epoch 62; iter: 0; batch classifier loss: 0.349990; batch adversarial loss: 0.505594\n",
      "epoch 63; iter: 0; batch classifier loss: 0.477454; batch adversarial loss: 0.492244\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398554; batch adversarial loss: 0.510071\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377307; batch adversarial loss: 0.536413\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405712; batch adversarial loss: 0.472722\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410073; batch adversarial loss: 0.485952\n",
      "epoch 68; iter: 0; batch classifier loss: 0.476828; batch adversarial loss: 0.650139\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423403; batch adversarial loss: 0.609782\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428757; batch adversarial loss: 0.553763\n",
      "epoch 71; iter: 0; batch classifier loss: 0.475557; batch adversarial loss: 0.579099\n",
      "epoch 72; iter: 0; batch classifier loss: 0.344024; batch adversarial loss: 0.491507\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400593; batch adversarial loss: 0.571032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.420616; batch adversarial loss: 0.615711\n",
      "epoch 75; iter: 0; batch classifier loss: 0.427591; batch adversarial loss: 0.545608\n",
      "epoch 76; iter: 0; batch classifier loss: 0.315738; batch adversarial loss: 0.554055\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374035; batch adversarial loss: 0.580624\n",
      "epoch 78; iter: 0; batch classifier loss: 0.418813; batch adversarial loss: 0.588197\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404082; batch adversarial loss: 0.570521\n",
      "epoch 80; iter: 0; batch classifier loss: 0.404543; batch adversarial loss: 0.579948\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429018; batch adversarial loss: 0.536058\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417886; batch adversarial loss: 0.546083\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451103; batch adversarial loss: 0.579872\n",
      "epoch 84; iter: 0; batch classifier loss: 0.473280; batch adversarial loss: 0.571287\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364632; batch adversarial loss: 0.615924\n",
      "epoch 86; iter: 0; batch classifier loss: 0.333195; batch adversarial loss: 0.527091\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391695; batch adversarial loss: 0.517995\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422202; batch adversarial loss: 0.508704\n",
      "epoch 89; iter: 0; batch classifier loss: 0.364479; batch adversarial loss: 0.490185\n",
      "epoch 90; iter: 0; batch classifier loss: 0.356916; batch adversarial loss: 0.581159\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399951; batch adversarial loss: 0.499243\n",
      "epoch 92; iter: 0; batch classifier loss: 0.328977; batch adversarial loss: 0.517969\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385738; batch adversarial loss: 0.589025\n",
      "epoch 94; iter: 0; batch classifier loss: 0.427206; batch adversarial loss: 0.597981\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373479; batch adversarial loss: 0.588945\n",
      "epoch 96; iter: 0; batch classifier loss: 0.330787; batch adversarial loss: 0.562111\n",
      "epoch 97; iter: 0; batch classifier loss: 0.329789; batch adversarial loss: 0.554241\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393655; batch adversarial loss: 0.544508\n",
      "epoch 99; iter: 0; batch classifier loss: 0.328806; batch adversarial loss: 0.543613\n",
      "epoch 100; iter: 0; batch classifier loss: 0.453507; batch adversarial loss: 0.560226\n",
      "epoch 101; iter: 0; batch classifier loss: 0.341734; batch adversarial loss: 0.487534\n",
      "epoch 102; iter: 0; batch classifier loss: 0.341763; batch adversarial loss: 0.515957\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379089; batch adversarial loss: 0.514569\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399491; batch adversarial loss: 0.551673\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394250; batch adversarial loss: 0.434081\n",
      "epoch 106; iter: 0; batch classifier loss: 0.438702; batch adversarial loss: 0.481814\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406060; batch adversarial loss: 0.506974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421332; batch adversarial loss: 0.564648\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410110; batch adversarial loss: 0.582100\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427089; batch adversarial loss: 0.500905\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433544; batch adversarial loss: 0.509533\n",
      "epoch 112; iter: 0; batch classifier loss: 0.282023; batch adversarial loss: 0.500159\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333204; batch adversarial loss: 0.518386\n",
      "epoch 114; iter: 0; batch classifier loss: 0.330970; batch adversarial loss: 0.456452\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397515; batch adversarial loss: 0.447199\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351016; batch adversarial loss: 0.544664\n",
      "epoch 117; iter: 0; batch classifier loss: 0.380736; batch adversarial loss: 0.491051\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377171; batch adversarial loss: 0.517809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.355607; batch adversarial loss: 0.508712\n",
      "epoch 120; iter: 0; batch classifier loss: 0.429306; batch adversarial loss: 0.642799\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364115; batch adversarial loss: 0.580064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387227; batch adversarial loss: 0.517982\n",
      "epoch 123; iter: 0; batch classifier loss: 0.405710; batch adversarial loss: 0.571840\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351006; batch adversarial loss: 0.597616\n",
      "epoch 125; iter: 0; batch classifier loss: 0.306821; batch adversarial loss: 0.571328\n",
      "epoch 126; iter: 0; batch classifier loss: 0.306305; batch adversarial loss: 0.534268\n",
      "epoch 127; iter: 0; batch classifier loss: 0.289163; batch adversarial loss: 0.545242\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351056; batch adversarial loss: 0.509958\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349256; batch adversarial loss: 0.500806\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332882; batch adversarial loss: 0.486717\n",
      "epoch 131; iter: 0; batch classifier loss: 0.390291; batch adversarial loss: 0.598096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.425964; batch adversarial loss: 0.629154\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337242; batch adversarial loss: 0.516758\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344673; batch adversarial loss: 0.570961\n",
      "epoch 135; iter: 0; batch classifier loss: 0.316298; batch adversarial loss: 0.616217\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333837; batch adversarial loss: 0.607612\n",
      "epoch 137; iter: 0; batch classifier loss: 0.427288; batch adversarial loss: 0.641681\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365376; batch adversarial loss: 0.623327\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350618; batch adversarial loss: 0.598096\n",
      "epoch 140; iter: 0; batch classifier loss: 0.504889; batch adversarial loss: 0.572120\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353724; batch adversarial loss: 0.562621\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324138; batch adversarial loss: 0.545290\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391753; batch adversarial loss: 0.606416\n",
      "epoch 144; iter: 0; batch classifier loss: 0.333945; batch adversarial loss: 0.490775\n",
      "epoch 145; iter: 0; batch classifier loss: 0.324351; batch adversarial loss: 0.598012\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327804; batch adversarial loss: 0.536218\n",
      "epoch 147; iter: 0; batch classifier loss: 0.411463; batch adversarial loss: 0.517705\n",
      "epoch 148; iter: 0; batch classifier loss: 0.325263; batch adversarial loss: 0.598296\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317613; batch adversarial loss: 0.544327\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339165; batch adversarial loss: 0.571043\n",
      "epoch 151; iter: 0; batch classifier loss: 0.285984; batch adversarial loss: 0.553697\n",
      "epoch 152; iter: 0; batch classifier loss: 0.329050; batch adversarial loss: 0.408408\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350929; batch adversarial loss: 0.587908\n",
      "epoch 154; iter: 0; batch classifier loss: 0.431608; batch adversarial loss: 0.553334\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340309; batch adversarial loss: 0.571027\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351856; batch adversarial loss: 0.563149\n",
      "epoch 157; iter: 0; batch classifier loss: 0.231670; batch adversarial loss: 0.660154\n",
      "epoch 158; iter: 0; batch classifier loss: 0.360097; batch adversarial loss: 0.527496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.404376; batch adversarial loss: 0.554108\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340758; batch adversarial loss: 0.571516\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314081; batch adversarial loss: 0.464539\n",
      "epoch 162; iter: 0; batch classifier loss: 0.307051; batch adversarial loss: 0.624138\n",
      "epoch 163; iter: 0; batch classifier loss: 0.296930; batch adversarial loss: 0.536009\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366520; batch adversarial loss: 0.509342\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334944; batch adversarial loss: 0.634180\n",
      "epoch 166; iter: 0; batch classifier loss: 0.305495; batch adversarial loss: 0.554121\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381021; batch adversarial loss: 0.499408\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327845; batch adversarial loss: 0.580457\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367568; batch adversarial loss: 0.527303\n",
      "epoch 170; iter: 0; batch classifier loss: 0.272849; batch adversarial loss: 0.553044\n",
      "epoch 171; iter: 0; batch classifier loss: 0.431853; batch adversarial loss: 0.607592\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297028; batch adversarial loss: 0.598035\n",
      "epoch 173; iter: 0; batch classifier loss: 0.306030; batch adversarial loss: 0.517623\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359698; batch adversarial loss: 0.598212\n",
      "epoch 175; iter: 0; batch classifier loss: 0.312029; batch adversarial loss: 0.525257\n",
      "epoch 176; iter: 0; batch classifier loss: 0.433444; batch adversarial loss: 0.508267\n",
      "epoch 177; iter: 0; batch classifier loss: 0.298803; batch adversarial loss: 0.562645\n",
      "epoch 178; iter: 0; batch classifier loss: 0.448562; batch adversarial loss: 0.552711\n",
      "epoch 179; iter: 0; batch classifier loss: 0.316944; batch adversarial loss: 0.672218\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388596; batch adversarial loss: 0.570561\n",
      "epoch 181; iter: 0; batch classifier loss: 0.306181; batch adversarial loss: 0.544845\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361353; batch adversarial loss: 0.579132\n",
      "epoch 183; iter: 0; batch classifier loss: 0.414981; batch adversarial loss: 0.617058\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383264; batch adversarial loss: 0.562547\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397651; batch adversarial loss: 0.617368\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393439; batch adversarial loss: 0.517588\n",
      "epoch 187; iter: 0; batch classifier loss: 0.379831; batch adversarial loss: 0.564353\n",
      "epoch 188; iter: 0; batch classifier loss: 0.355208; batch adversarial loss: 0.490972\n",
      "epoch 189; iter: 0; batch classifier loss: 0.295210; batch adversarial loss: 0.491293\n",
      "epoch 190; iter: 0; batch classifier loss: 0.256628; batch adversarial loss: 0.473884\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380191; batch adversarial loss: 0.597763\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332318; batch adversarial loss: 0.491249\n",
      "epoch 193; iter: 0; batch classifier loss: 0.405476; batch adversarial loss: 0.542860\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396170; batch adversarial loss: 0.535975\n",
      "epoch 195; iter: 0; batch classifier loss: 0.294088; batch adversarial loss: 0.625852\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351815; batch adversarial loss: 0.535863\n",
      "epoch 197; iter: 0; batch classifier loss: 0.359994; batch adversarial loss: 0.473389\n",
      "epoch 198; iter: 0; batch classifier loss: 0.354583; batch adversarial loss: 0.544298\n",
      "epoch 199; iter: 0; batch classifier loss: 0.291102; batch adversarial loss: 0.607415\n",
      "epoch 0; iter: 0; batch classifier loss: 0.659000; batch adversarial loss: 0.617256\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599805; batch adversarial loss: 0.633958\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582709; batch adversarial loss: 0.643492\n",
      "epoch 3; iter: 0; batch classifier loss: 0.600818; batch adversarial loss: 0.592475\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572638; batch adversarial loss: 0.659953\n",
      "epoch 5; iter: 0; batch classifier loss: 0.645201; batch adversarial loss: 0.608923\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522490; batch adversarial loss: 0.598801\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543721; batch adversarial loss: 0.606048\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537522; batch adversarial loss: 0.607884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573111; batch adversarial loss: 0.598233\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526037; batch adversarial loss: 0.580541\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569663; batch adversarial loss: 0.570631\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495800; batch adversarial loss: 0.501682\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487756; batch adversarial loss: 0.566821\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510044; batch adversarial loss: 0.593504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525237; batch adversarial loss: 0.539834\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540115; batch adversarial loss: 0.536137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.536734; batch adversarial loss: 0.589348\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455874; batch adversarial loss: 0.578098\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490572; batch adversarial loss: 0.585407\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517330; batch adversarial loss: 0.587835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492803; batch adversarial loss: 0.503206\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479047; batch adversarial loss: 0.546680\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450201; batch adversarial loss: 0.545266\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426090; batch adversarial loss: 0.495682\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488799; batch adversarial loss: 0.570144\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483074; batch adversarial loss: 0.590980\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443322; batch adversarial loss: 0.555418\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429206; batch adversarial loss: 0.589494\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451941; batch adversarial loss: 0.589102\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524576; batch adversarial loss: 0.573044\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441035; batch adversarial loss: 0.501520\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454473; batch adversarial loss: 0.526351\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523124; batch adversarial loss: 0.612194\n",
      "epoch 34; iter: 0; batch classifier loss: 0.424650; batch adversarial loss: 0.538727\n",
      "epoch 35; iter: 0; batch classifier loss: 0.532313; batch adversarial loss: 0.552648\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400292; batch adversarial loss: 0.547154\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389952; batch adversarial loss: 0.552758\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492363; batch adversarial loss: 0.507542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.406846; batch adversarial loss: 0.542173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470264; batch adversarial loss: 0.501896\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441499; batch adversarial loss: 0.601696\n",
      "epoch 42; iter: 0; batch classifier loss: 0.442961; batch adversarial loss: 0.456761\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481269; batch adversarial loss: 0.507903\n",
      "epoch 44; iter: 0; batch classifier loss: 0.432290; batch adversarial loss: 0.579215\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438697; batch adversarial loss: 0.538514\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425235; batch adversarial loss: 0.578956\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391138; batch adversarial loss: 0.535433\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473290; batch adversarial loss: 0.482901\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451129; batch adversarial loss: 0.527490\n",
      "epoch 50; iter: 0; batch classifier loss: 0.405194; batch adversarial loss: 0.579060\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463055; batch adversarial loss: 0.590180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456148; batch adversarial loss: 0.616736\n",
      "epoch 53; iter: 0; batch classifier loss: 0.517259; batch adversarial loss: 0.543299\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435517; batch adversarial loss: 0.588208\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421819; batch adversarial loss: 0.543405\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424618; batch adversarial loss: 0.562295\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430963; batch adversarial loss: 0.616088\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469636; batch adversarial loss: 0.537245\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462272; batch adversarial loss: 0.464462\n",
      "epoch 60; iter: 0; batch classifier loss: 0.364402; batch adversarial loss: 0.563588\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409996; batch adversarial loss: 0.579424\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387243; batch adversarial loss: 0.473100\n",
      "epoch 63; iter: 0; batch classifier loss: 0.456607; batch adversarial loss: 0.517788\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375805; batch adversarial loss: 0.536393\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370484; batch adversarial loss: 0.581856\n",
      "epoch 66; iter: 0; batch classifier loss: 0.472102; batch adversarial loss: 0.544103\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421070; batch adversarial loss: 0.635663\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415160; batch adversarial loss: 0.580841\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457919; batch adversarial loss: 0.531910\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425443; batch adversarial loss: 0.540945\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398843; batch adversarial loss: 0.646765\n",
      "epoch 72; iter: 0; batch classifier loss: 0.490043; batch adversarial loss: 0.529570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.457053; batch adversarial loss: 0.532475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424928; batch adversarial loss: 0.522330\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398638; batch adversarial loss: 0.538590\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439798; batch adversarial loss: 0.527391\n",
      "epoch 77; iter: 0; batch classifier loss: 0.358851; batch adversarial loss: 0.571524\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378567; batch adversarial loss: 0.568096\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382573; batch adversarial loss: 0.629024\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435219; batch adversarial loss: 0.547027\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378456; batch adversarial loss: 0.599935\n",
      "epoch 82; iter: 0; batch classifier loss: 0.433968; batch adversarial loss: 0.515304\n",
      "epoch 83; iter: 0; batch classifier loss: 0.363915; batch adversarial loss: 0.509259\n",
      "epoch 84; iter: 0; batch classifier loss: 0.423088; batch adversarial loss: 0.658955\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398422; batch adversarial loss: 0.571061\n",
      "epoch 86; iter: 0; batch classifier loss: 0.483630; batch adversarial loss: 0.518494\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387554; batch adversarial loss: 0.517355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441686; batch adversarial loss: 0.536904\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378884; batch adversarial loss: 0.586787\n",
      "epoch 90; iter: 0; batch classifier loss: 0.352381; batch adversarial loss: 0.545389\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428427; batch adversarial loss: 0.544983\n",
      "epoch 92; iter: 0; batch classifier loss: 0.346053; batch adversarial loss: 0.553548\n",
      "epoch 93; iter: 0; batch classifier loss: 0.372667; batch adversarial loss: 0.597338\n",
      "epoch 94; iter: 0; batch classifier loss: 0.459469; batch adversarial loss: 0.588778\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418730; batch adversarial loss: 0.650840\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392926; batch adversarial loss: 0.553378\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362309; batch adversarial loss: 0.536044\n",
      "epoch 98; iter: 0; batch classifier loss: 0.363500; batch adversarial loss: 0.599451\n",
      "epoch 99; iter: 0; batch classifier loss: 0.328676; batch adversarial loss: 0.598603\n",
      "epoch 100; iter: 0; batch classifier loss: 0.446670; batch adversarial loss: 0.580096\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336797; batch adversarial loss: 0.552714\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382594; batch adversarial loss: 0.581074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363606; batch adversarial loss: 0.571684\n",
      "epoch 104; iter: 0; batch classifier loss: 0.347029; batch adversarial loss: 0.616859\n",
      "epoch 105; iter: 0; batch classifier loss: 0.307729; batch adversarial loss: 0.626812\n",
      "epoch 106; iter: 0; batch classifier loss: 0.414916; batch adversarial loss: 0.536127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382604; batch adversarial loss: 0.583746\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369747; batch adversarial loss: 0.569139\n",
      "epoch 109; iter: 0; batch classifier loss: 0.521569; batch adversarial loss: 0.605013\n",
      "epoch 110; iter: 0; batch classifier loss: 0.412605; batch adversarial loss: 0.542757\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365102; batch adversarial loss: 0.608772\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374707; batch adversarial loss: 0.577891\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413306; batch adversarial loss: 0.542403\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349394; batch adversarial loss: 0.581300\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374090; batch adversarial loss: 0.551605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.414186; batch adversarial loss: 0.514728\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333912; batch adversarial loss: 0.608307\n",
      "epoch 118; iter: 0; batch classifier loss: 0.422585; batch adversarial loss: 0.473054\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367489; batch adversarial loss: 0.510141\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421596; batch adversarial loss: 0.487452\n",
      "epoch 121; iter: 0; batch classifier loss: 0.367797; batch adversarial loss: 0.553943\n",
      "epoch 122; iter: 0; batch classifier loss: 0.412751; batch adversarial loss: 0.578236\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355246; batch adversarial loss: 0.535509\n",
      "epoch 124; iter: 0; batch classifier loss: 0.414619; batch adversarial loss: 0.578702\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360835; batch adversarial loss: 0.616277\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376808; batch adversarial loss: 0.614405\n",
      "epoch 127; iter: 0; batch classifier loss: 0.363808; batch adversarial loss: 0.580160\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377850; batch adversarial loss: 0.518451\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347980; batch adversarial loss: 0.606138\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386938; batch adversarial loss: 0.527876\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359982; batch adversarial loss: 0.544904\n",
      "epoch 132; iter: 0; batch classifier loss: 0.356025; batch adversarial loss: 0.606489\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346833; batch adversarial loss: 0.570979\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333952; batch adversarial loss: 0.588854\n",
      "epoch 135; iter: 0; batch classifier loss: 0.355569; batch adversarial loss: 0.527799\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395751; batch adversarial loss: 0.473258\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407136; batch adversarial loss: 0.563282\n",
      "epoch 138; iter: 0; batch classifier loss: 0.299961; batch adversarial loss: 0.644319\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334007; batch adversarial loss: 0.614877\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364512; batch adversarial loss: 0.553864\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411659; batch adversarial loss: 0.508196\n",
      "epoch 142; iter: 0; batch classifier loss: 0.312021; batch adversarial loss: 0.500357\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396228; batch adversarial loss: 0.588691\n",
      "epoch 144; iter: 0; batch classifier loss: 0.355324; batch adversarial loss: 0.607631\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372313; batch adversarial loss: 0.572257\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404206; batch adversarial loss: 0.544312\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383306; batch adversarial loss: 0.516879\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336587; batch adversarial loss: 0.607000\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417972; batch adversarial loss: 0.561767\n",
      "epoch 150; iter: 0; batch classifier loss: 0.428885; batch adversarial loss: 0.580030\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417663; batch adversarial loss: 0.526204\n",
      "epoch 152; iter: 0; batch classifier loss: 0.393402; batch adversarial loss: 0.509293\n",
      "epoch 153; iter: 0; batch classifier loss: 0.418958; batch adversarial loss: 0.562518\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385824; batch adversarial loss: 0.562900\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398670; batch adversarial loss: 0.526732\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349854; batch adversarial loss: 0.571476\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346080; batch adversarial loss: 0.544738\n",
      "epoch 158; iter: 0; batch classifier loss: 0.385618; batch adversarial loss: 0.598625\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396311; batch adversarial loss: 0.617661\n",
      "epoch 160; iter: 0; batch classifier loss: 0.437332; batch adversarial loss: 0.536316\n",
      "epoch 161; iter: 0; batch classifier loss: 0.389682; batch adversarial loss: 0.526675\n",
      "epoch 162; iter: 0; batch classifier loss: 0.459680; batch adversarial loss: 0.588823\n",
      "epoch 163; iter: 0; batch classifier loss: 0.460580; batch adversarial loss: 0.535656\n",
      "epoch 164; iter: 0; batch classifier loss: 0.420422; batch adversarial loss: 0.507802\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369384; batch adversarial loss: 0.553240\n",
      "epoch 166; iter: 0; batch classifier loss: 0.420086; batch adversarial loss: 0.553458\n",
      "epoch 167; iter: 0; batch classifier loss: 0.396454; batch adversarial loss: 0.517372\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331687; batch adversarial loss: 0.479673\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302271; batch adversarial loss: 0.622860\n",
      "epoch 170; iter: 0; batch classifier loss: 0.434037; batch adversarial loss: 0.634648\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401052; batch adversarial loss: 0.515081\n",
      "epoch 172; iter: 0; batch classifier loss: 0.390399; batch adversarial loss: 0.527734\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329012; batch adversarial loss: 0.554142\n",
      "epoch 174; iter: 0; batch classifier loss: 0.297855; batch adversarial loss: 0.553987\n",
      "epoch 175; iter: 0; batch classifier loss: 0.398335; batch adversarial loss: 0.578198\n",
      "epoch 176; iter: 0; batch classifier loss: 0.404599; batch adversarial loss: 0.597562\n",
      "epoch 177; iter: 0; batch classifier loss: 0.419959; batch adversarial loss: 0.591341\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362419; batch adversarial loss: 0.579972\n",
      "epoch 179; iter: 0; batch classifier loss: 0.447239; batch adversarial loss: 0.571298\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358689; batch adversarial loss: 0.582187\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331945; batch adversarial loss: 0.493141\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340084; batch adversarial loss: 0.544974\n",
      "epoch 183; iter: 0; batch classifier loss: 0.391978; batch adversarial loss: 0.562566\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334329; batch adversarial loss: 0.579449\n",
      "epoch 185; iter: 0; batch classifier loss: 0.344839; batch adversarial loss: 0.500632\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328121; batch adversarial loss: 0.536679\n",
      "epoch 187; iter: 0; batch classifier loss: 0.426269; batch adversarial loss: 0.607162\n",
      "epoch 188; iter: 0; batch classifier loss: 0.295270; batch adversarial loss: 0.563745\n",
      "epoch 189; iter: 0; batch classifier loss: 0.360355; batch adversarial loss: 0.616270\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327401; batch adversarial loss: 0.545419\n",
      "epoch 191; iter: 0; batch classifier loss: 0.409969; batch adversarial loss: 0.499735\n",
      "epoch 192; iter: 0; batch classifier loss: 0.418340; batch adversarial loss: 0.634831\n",
      "epoch 193; iter: 0; batch classifier loss: 0.401874; batch adversarial loss: 0.490443\n",
      "epoch 194; iter: 0; batch classifier loss: 0.381026; batch adversarial loss: 0.561527\n",
      "epoch 195; iter: 0; batch classifier loss: 0.400384; batch adversarial loss: 0.543267\n",
      "epoch 196; iter: 0; batch classifier loss: 0.388739; batch adversarial loss: 0.562189\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385007; batch adversarial loss: 0.527745\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328689; batch adversarial loss: 0.580874\n",
      "epoch 199; iter: 0; batch classifier loss: 0.421704; batch adversarial loss: 0.590296\n",
      "epoch 0; iter: 0; batch classifier loss: 0.874217; batch adversarial loss: 1.264567\n",
      "epoch 1; iter: 0; batch classifier loss: 0.909190; batch adversarial loss: 1.260244\n",
      "epoch 2; iter: 0; batch classifier loss: 1.162967; batch adversarial loss: 1.223943\n",
      "epoch 3; iter: 0; batch classifier loss: 1.168487; batch adversarial loss: 1.113584\n",
      "epoch 4; iter: 0; batch classifier loss: 1.160312; batch adversarial loss: 1.020420\n",
      "epoch 5; iter: 0; batch classifier loss: 1.160683; batch adversarial loss: 0.948486\n",
      "epoch 6; iter: 0; batch classifier loss: 1.154619; batch adversarial loss: 0.892098\n",
      "epoch 7; iter: 0; batch classifier loss: 1.068198; batch adversarial loss: 0.806977\n",
      "epoch 8; iter: 0; batch classifier loss: 0.941072; batch adversarial loss: 0.775308\n",
      "epoch 9; iter: 0; batch classifier loss: 0.857034; batch adversarial loss: 0.717969\n",
      "epoch 10; iter: 0; batch classifier loss: 0.744366; batch adversarial loss: 0.689491\n",
      "epoch 11; iter: 0; batch classifier loss: 0.656206; batch adversarial loss: 0.588364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.551047; batch adversarial loss: 0.573272\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543831; batch adversarial loss: 0.581553\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501973; batch adversarial loss: 0.615838\n",
      "epoch 15; iter: 0; batch classifier loss: 0.517289; batch adversarial loss: 0.566561\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539335; batch adversarial loss: 0.585552\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560081; batch adversarial loss: 0.598797\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493232; batch adversarial loss: 0.610774\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521062; batch adversarial loss: 0.683068\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543275; batch adversarial loss: 0.531633\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502710; batch adversarial loss: 0.615839\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489370; batch adversarial loss: 0.609115\n",
      "epoch 23; iter: 0; batch classifier loss: 0.535787; batch adversarial loss: 0.527406\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482551; batch adversarial loss: 0.522105\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471267; batch adversarial loss: 0.551541\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466466; batch adversarial loss: 0.548820\n",
      "epoch 27; iter: 0; batch classifier loss: 0.597886; batch adversarial loss: 0.536754\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482860; batch adversarial loss: 0.544403\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434646; batch adversarial loss: 0.558455\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517305; batch adversarial loss: 0.503553\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495510; batch adversarial loss: 0.533072\n",
      "epoch 32; iter: 0; batch classifier loss: 0.508754; batch adversarial loss: 0.530983\n",
      "epoch 33; iter: 0; batch classifier loss: 0.526676; batch adversarial loss: 0.468707\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450919; batch adversarial loss: 0.546172\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499747; batch adversarial loss: 0.576534\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485827; batch adversarial loss: 0.539428\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462468; batch adversarial loss: 0.563560\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453610; batch adversarial loss: 0.535922\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453369; batch adversarial loss: 0.523255\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459711; batch adversarial loss: 0.512324\n",
      "epoch 41; iter: 0; batch classifier loss: 0.409816; batch adversarial loss: 0.507947\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489009; batch adversarial loss: 0.556729\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460705; batch adversarial loss: 0.548038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423863; batch adversarial loss: 0.541936\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415283; batch adversarial loss: 0.596927\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426962; batch adversarial loss: 0.633274\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444556; batch adversarial loss: 0.549760\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450557; batch adversarial loss: 0.520666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.492652; batch adversarial loss: 0.580872\n",
      "epoch 50; iter: 0; batch classifier loss: 0.375023; batch adversarial loss: 0.557938\n",
      "epoch 51; iter: 0; batch classifier loss: 0.407846; batch adversarial loss: 0.561566\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432262; batch adversarial loss: 0.502378\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404871; batch adversarial loss: 0.615583\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400686; batch adversarial loss: 0.570519\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428958; batch adversarial loss: 0.581947\n",
      "epoch 56; iter: 0; batch classifier loss: 0.316094; batch adversarial loss: 0.607498\n",
      "epoch 57; iter: 0; batch classifier loss: 0.366693; batch adversarial loss: 0.536610\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393965; batch adversarial loss: 0.502041\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446699; batch adversarial loss: 0.563741\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443921; batch adversarial loss: 0.544775\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397715; batch adversarial loss: 0.571784\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409910; batch adversarial loss: 0.599270\n",
      "epoch 63; iter: 0; batch classifier loss: 0.471489; batch adversarial loss: 0.544463\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463076; batch adversarial loss: 0.589460\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410938; batch adversarial loss: 0.534867\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381023; batch adversarial loss: 0.598257\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391367; batch adversarial loss: 0.508625\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413387; batch adversarial loss: 0.568286\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395633; batch adversarial loss: 0.669523\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406534; batch adversarial loss: 0.432513\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389086; batch adversarial loss: 0.649116\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386602; batch adversarial loss: 0.554026\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412642; batch adversarial loss: 0.504464\n",
      "epoch 74; iter: 0; batch classifier loss: 0.434189; batch adversarial loss: 0.526401\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375337; batch adversarial loss: 0.623220\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388400; batch adversarial loss: 0.561175\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425726; batch adversarial loss: 0.557402\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399228; batch adversarial loss: 0.527573\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418176; batch adversarial loss: 0.558746\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384355; batch adversarial loss: 0.543990\n",
      "epoch 81; iter: 0; batch classifier loss: 0.377995; batch adversarial loss: 0.561020\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381096; batch adversarial loss: 0.530324\n",
      "epoch 83; iter: 0; batch classifier loss: 0.346872; batch adversarial loss: 0.497960\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395881; batch adversarial loss: 0.577646\n",
      "epoch 85; iter: 0; batch classifier loss: 0.506818; batch adversarial loss: 0.580657\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.586580\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416216; batch adversarial loss: 0.565089\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375307; batch adversarial loss: 0.496040\n",
      "epoch 89; iter: 0; batch classifier loss: 0.507402; batch adversarial loss: 0.530937\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362608; batch adversarial loss: 0.576473\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413786; batch adversarial loss: 0.541416\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450881; batch adversarial loss: 0.621391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398479; batch adversarial loss: 0.568392\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437862; batch adversarial loss: 0.541552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430889; batch adversarial loss: 0.531640\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410167; batch adversarial loss: 0.602638\n",
      "epoch 97; iter: 0; batch classifier loss: 0.442174; batch adversarial loss: 0.569743\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410141; batch adversarial loss: 0.568469\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456356; batch adversarial loss: 0.507478\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404907; batch adversarial loss: 0.544259\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410586; batch adversarial loss: 0.556156\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407105; batch adversarial loss: 0.552131\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399147; batch adversarial loss: 0.539139\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367678; batch adversarial loss: 0.525156\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380277; batch adversarial loss: 0.537865\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367758; batch adversarial loss: 0.483330\n",
      "epoch 107; iter: 0; batch classifier loss: 0.418903; batch adversarial loss: 0.621289\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388388; batch adversarial loss: 0.527112\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384830; batch adversarial loss: 0.575504\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334428; batch adversarial loss: 0.513632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.392984; batch adversarial loss: 0.554409\n",
      "epoch 112; iter: 0; batch classifier loss: 0.346444; batch adversarial loss: 0.597948\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375783; batch adversarial loss: 0.613635\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359018; batch adversarial loss: 0.539545\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343052; batch adversarial loss: 0.496039\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382993; batch adversarial loss: 0.549059\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383907; batch adversarial loss: 0.647953\n",
      "epoch 118; iter: 0; batch classifier loss: 0.323455; batch adversarial loss: 0.553317\n",
      "epoch 119; iter: 0; batch classifier loss: 0.289385; batch adversarial loss: 0.487874\n",
      "epoch 120; iter: 0; batch classifier loss: 0.295354; batch adversarial loss: 0.538931\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398795; batch adversarial loss: 0.579216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376613; batch adversarial loss: 0.524859\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356927; batch adversarial loss: 0.522404\n",
      "epoch 124; iter: 0; batch classifier loss: 0.419677; batch adversarial loss: 0.513977\n",
      "epoch 125; iter: 0; batch classifier loss: 0.342253; batch adversarial loss: 0.582567\n",
      "epoch 126; iter: 0; batch classifier loss: 0.309833; batch adversarial loss: 0.537389\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369171; batch adversarial loss: 0.641361\n",
      "epoch 128; iter: 0; batch classifier loss: 0.401951; batch adversarial loss: 0.486939\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375909; batch adversarial loss: 0.583453\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352446; batch adversarial loss: 0.481135\n",
      "epoch 131; iter: 0; batch classifier loss: 0.280308; batch adversarial loss: 0.573768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.308283; batch adversarial loss: 0.693356\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380416; batch adversarial loss: 0.563855\n",
      "epoch 134; iter: 0; batch classifier loss: 0.313111; batch adversarial loss: 0.518452\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358745; batch adversarial loss: 0.557169\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328339; batch adversarial loss: 0.564221\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362646; batch adversarial loss: 0.590075\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362658; batch adversarial loss: 0.522132\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355292; batch adversarial loss: 0.518200\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366501; batch adversarial loss: 0.574358\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356181; batch adversarial loss: 0.511289\n",
      "epoch 142; iter: 0; batch classifier loss: 0.441438; batch adversarial loss: 0.604457\n",
      "epoch 143; iter: 0; batch classifier loss: 0.327233; batch adversarial loss: 0.570284\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369832; batch adversarial loss: 0.581174\n",
      "epoch 145; iter: 0; batch classifier loss: 0.344421; batch adversarial loss: 0.597565\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331689; batch adversarial loss: 0.590861\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379213; batch adversarial loss: 0.552951\n",
      "epoch 148; iter: 0; batch classifier loss: 0.437794; batch adversarial loss: 0.524053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.358227; batch adversarial loss: 0.533216\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359167; batch adversarial loss: 0.507960\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378670; batch adversarial loss: 0.495015\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335065; batch adversarial loss: 0.493472\n",
      "epoch 153; iter: 0; batch classifier loss: 0.282037; batch adversarial loss: 0.561608\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362903; batch adversarial loss: 0.549596\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325717; batch adversarial loss: 0.516047\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347062; batch adversarial loss: 0.537956\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377304; batch adversarial loss: 0.508701\n",
      "epoch 158; iter: 0; batch classifier loss: 0.429575; batch adversarial loss: 0.601424\n",
      "epoch 159; iter: 0; batch classifier loss: 0.450912; batch adversarial loss: 0.578432\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381024; batch adversarial loss: 0.543571\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345832; batch adversarial loss: 0.583545\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313452; batch adversarial loss: 0.548766\n",
      "epoch 163; iter: 0; batch classifier loss: 0.393444; batch adversarial loss: 0.573663\n",
      "epoch 164; iter: 0; batch classifier loss: 0.357415; batch adversarial loss: 0.492376\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374956; batch adversarial loss: 0.528017\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351700; batch adversarial loss: 0.581670\n",
      "epoch 167; iter: 0; batch classifier loss: 0.314583; batch adversarial loss: 0.622580\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327210; batch adversarial loss: 0.569116\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344520; batch adversarial loss: 0.626384\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326223; batch adversarial loss: 0.516871\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358921; batch adversarial loss: 0.541343\n",
      "epoch 172; iter: 0; batch classifier loss: 0.269048; batch adversarial loss: 0.558346\n",
      "epoch 173; iter: 0; batch classifier loss: 0.320751; batch adversarial loss: 0.514967\n",
      "epoch 174; iter: 0; batch classifier loss: 0.412486; batch adversarial loss: 0.529914\n",
      "epoch 175; iter: 0; batch classifier loss: 0.305964; batch adversarial loss: 0.550885\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319192; batch adversarial loss: 0.533265\n",
      "epoch 177; iter: 0; batch classifier loss: 0.302262; batch adversarial loss: 0.563496\n",
      "epoch 178; iter: 0; batch classifier loss: 0.321271; batch adversarial loss: 0.587436\n",
      "epoch 179; iter: 0; batch classifier loss: 0.320058; batch adversarial loss: 0.515424\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345637; batch adversarial loss: 0.538377\n",
      "epoch 181; iter: 0; batch classifier loss: 0.310202; batch adversarial loss: 0.547936\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361237; batch adversarial loss: 0.513102\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356394; batch adversarial loss: 0.615321\n",
      "epoch 184; iter: 0; batch classifier loss: 0.293387; batch adversarial loss: 0.492244\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338223; batch adversarial loss: 0.553706\n",
      "epoch 186; iter: 0; batch classifier loss: 0.291107; batch adversarial loss: 0.517683\n",
      "epoch 187; iter: 0; batch classifier loss: 0.316974; batch adversarial loss: 0.525802\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371314; batch adversarial loss: 0.536454\n",
      "epoch 189; iter: 0; batch classifier loss: 0.324130; batch adversarial loss: 0.457949\n",
      "epoch 190; iter: 0; batch classifier loss: 0.319409; batch adversarial loss: 0.528785\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339453; batch adversarial loss: 0.496409\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320874; batch adversarial loss: 0.557071\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335139; batch adversarial loss: 0.549970\n",
      "epoch 194; iter: 0; batch classifier loss: 0.313444; batch adversarial loss: 0.510769\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322489; batch adversarial loss: 0.572700\n",
      "epoch 196; iter: 0; batch classifier loss: 0.289202; batch adversarial loss: 0.573459\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367631; batch adversarial loss: 0.589627\n",
      "epoch 198; iter: 0; batch classifier loss: 0.447530; batch adversarial loss: 0.556950\n",
      "epoch 199; iter: 0; batch classifier loss: 0.289490; batch adversarial loss: 0.583573\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736493; batch adversarial loss: 0.578002\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602616; batch adversarial loss: 0.670926\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542719; batch adversarial loss: 0.650014\n",
      "epoch 3; iter: 0; batch classifier loss: 0.648271; batch adversarial loss: 0.661463\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517941; batch adversarial loss: 0.668256\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563639; batch adversarial loss: 0.690980\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534989; batch adversarial loss: 0.614283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632091; batch adversarial loss: 0.604578\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560757; batch adversarial loss: 0.657076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.636593; batch adversarial loss: 0.594408\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602708; batch adversarial loss: 0.602282\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537228; batch adversarial loss: 0.570123\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489048; batch adversarial loss: 0.596942\n",
      "epoch 13; iter: 0; batch classifier loss: 0.442023; batch adversarial loss: 0.568399\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548984; batch adversarial loss: 0.626277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.461532; batch adversarial loss: 0.580182\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477156; batch adversarial loss: 0.587617\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459727; batch adversarial loss: 0.567774\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487411; batch adversarial loss: 0.538242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517252; batch adversarial loss: 0.522874\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493754; batch adversarial loss: 0.663466\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454978; batch adversarial loss: 0.504215\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507929; batch adversarial loss: 0.621203\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523137; batch adversarial loss: 0.534064\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484904; batch adversarial loss: 0.610819\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519946; batch adversarial loss: 0.538776\n",
      "epoch 26; iter: 0; batch classifier loss: 0.509450; batch adversarial loss: 0.563191\n",
      "epoch 27; iter: 0; batch classifier loss: 0.568234; batch adversarial loss: 0.546196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441666; batch adversarial loss: 0.512259\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464081; batch adversarial loss: 0.553455\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414747; batch adversarial loss: 0.587920\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507409; batch adversarial loss: 0.596337\n",
      "epoch 32; iter: 0; batch classifier loss: 0.411125; batch adversarial loss: 0.562265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488551; batch adversarial loss: 0.587861\n",
      "epoch 34; iter: 0; batch classifier loss: 0.465199; batch adversarial loss: 0.554030\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491366; batch adversarial loss: 0.648899\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488151; batch adversarial loss: 0.493085\n",
      "epoch 37; iter: 0; batch classifier loss: 0.368958; batch adversarial loss: 0.527907\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431776; batch adversarial loss: 0.605172\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436110; batch adversarial loss: 0.501691\n",
      "epoch 40; iter: 0; batch classifier loss: 0.548231; batch adversarial loss: 0.545032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460093; batch adversarial loss: 0.571119\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403633; batch adversarial loss: 0.536209\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482830; batch adversarial loss: 0.553521\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456115; batch adversarial loss: 0.632459\n",
      "epoch 45; iter: 0; batch classifier loss: 0.546419; batch adversarial loss: 0.466224\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416591; batch adversarial loss: 0.571202\n",
      "epoch 47; iter: 0; batch classifier loss: 0.448562; batch adversarial loss: 0.501176\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420890; batch adversarial loss: 0.545015\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402524; batch adversarial loss: 0.595451\n",
      "epoch 50; iter: 0; batch classifier loss: 0.376755; batch adversarial loss: 0.587871\n",
      "epoch 51; iter: 0; batch classifier loss: 0.452691; batch adversarial loss: 0.501926\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460653; batch adversarial loss: 0.534994\n",
      "epoch 53; iter: 0; batch classifier loss: 0.489006; batch adversarial loss: 0.545463\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409716; batch adversarial loss: 0.586284\n",
      "epoch 55; iter: 0; batch classifier loss: 0.534296; batch adversarial loss: 0.637222\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413438; batch adversarial loss: 0.562742\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498227; batch adversarial loss: 0.552268\n",
      "epoch 58; iter: 0; batch classifier loss: 0.459097; batch adversarial loss: 0.500718\n",
      "epoch 59; iter: 0; batch classifier loss: 0.517953; batch adversarial loss: 0.599068\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409558; batch adversarial loss: 0.598972\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440207; batch adversarial loss: 0.570861\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462369; batch adversarial loss: 0.491704\n",
      "epoch 63; iter: 0; batch classifier loss: 0.391548; batch adversarial loss: 0.465598\n",
      "epoch 64; iter: 0; batch classifier loss: 0.391683; batch adversarial loss: 0.570080\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425083; batch adversarial loss: 0.517554\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436410; batch adversarial loss: 0.535812\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423555; batch adversarial loss: 0.509838\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425814; batch adversarial loss: 0.492728\n",
      "epoch 69; iter: 0; batch classifier loss: 0.379568; batch adversarial loss: 0.544585\n",
      "epoch 70; iter: 0; batch classifier loss: 0.374211; batch adversarial loss: 0.563506\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415001; batch adversarial loss: 0.596037\n",
      "epoch 72; iter: 0; batch classifier loss: 0.356029; batch adversarial loss: 0.544908\n",
      "epoch 73; iter: 0; batch classifier loss: 0.454302; batch adversarial loss: 0.637608\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447202; batch adversarial loss: 0.561067\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385440; batch adversarial loss: 0.575708\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454757; batch adversarial loss: 0.625346\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343169; batch adversarial loss: 0.517359\n",
      "epoch 78; iter: 0; batch classifier loss: 0.332588; batch adversarial loss: 0.526378\n",
      "epoch 79; iter: 0; batch classifier loss: 0.423927; batch adversarial loss: 0.580909\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356821; batch adversarial loss: 0.563978\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382908; batch adversarial loss: 0.545342\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368991; batch adversarial loss: 0.545524\n",
      "epoch 83; iter: 0; batch classifier loss: 0.340509; batch adversarial loss: 0.561842\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431152; batch adversarial loss: 0.612615\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402996; batch adversarial loss: 0.552309\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419318; batch adversarial loss: 0.596295\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362377; batch adversarial loss: 0.527682\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375834; batch adversarial loss: 0.500809\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438420; batch adversarial loss: 0.543200\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398151; batch adversarial loss: 0.545570\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382955; batch adversarial loss: 0.587496\n",
      "epoch 92; iter: 0; batch classifier loss: 0.473799; batch adversarial loss: 0.535391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352810; batch adversarial loss: 0.554535\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372955; batch adversarial loss: 0.589583\n",
      "epoch 95; iter: 0; batch classifier loss: 0.361131; batch adversarial loss: 0.544061\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403332; batch adversarial loss: 0.562007\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386634; batch adversarial loss: 0.560024\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406370; batch adversarial loss: 0.562516\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417211; batch adversarial loss: 0.553083\n",
      "epoch 100; iter: 0; batch classifier loss: 0.380439; batch adversarial loss: 0.526606\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387451; batch adversarial loss: 0.580105\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417276; batch adversarial loss: 0.570140\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395645; batch adversarial loss: 0.589849\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344570; batch adversarial loss: 0.546051\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343773; batch adversarial loss: 0.579789\n",
      "epoch 106; iter: 0; batch classifier loss: 0.375804; batch adversarial loss: 0.560777\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406058; batch adversarial loss: 0.642752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.405243; batch adversarial loss: 0.552875\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331077; batch adversarial loss: 0.473041\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386731; batch adversarial loss: 0.564346\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388713; batch adversarial loss: 0.501020\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363290; batch adversarial loss: 0.529139\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353956; batch adversarial loss: 0.545991\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383939; batch adversarial loss: 0.509284\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389368; batch adversarial loss: 0.510209\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369352; batch adversarial loss: 0.568897\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350310; batch adversarial loss: 0.579618\n",
      "epoch 118; iter: 0; batch classifier loss: 0.418515; batch adversarial loss: 0.519359\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390083; batch adversarial loss: 0.595547\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362808; batch adversarial loss: 0.544705\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393658; batch adversarial loss: 0.527641\n",
      "epoch 122; iter: 0; batch classifier loss: 0.341633; batch adversarial loss: 0.623118\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359024; batch adversarial loss: 0.569152\n",
      "epoch 124; iter: 0; batch classifier loss: 0.450166; batch adversarial loss: 0.547434\n",
      "epoch 125; iter: 0; batch classifier loss: 0.421062; batch adversarial loss: 0.554859\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383960; batch adversarial loss: 0.574568\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397281; batch adversarial loss: 0.553412\n",
      "epoch 128; iter: 0; batch classifier loss: 0.440678; batch adversarial loss: 0.613820\n",
      "epoch 129; iter: 0; batch classifier loss: 0.351717; batch adversarial loss: 0.544503\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357499; batch adversarial loss: 0.588624\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407912; batch adversarial loss: 0.562454\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413548; batch adversarial loss: 0.625845\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388640; batch adversarial loss: 0.546267\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326587; batch adversarial loss: 0.527359\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362493; batch adversarial loss: 0.608455\n",
      "epoch 136; iter: 0; batch classifier loss: 0.284266; batch adversarial loss: 0.427332\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402315; batch adversarial loss: 0.589774\n",
      "epoch 138; iter: 0; batch classifier loss: 0.361715; batch adversarial loss: 0.615296\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383620; batch adversarial loss: 0.623308\n",
      "epoch 140; iter: 0; batch classifier loss: 0.394373; batch adversarial loss: 0.509750\n",
      "epoch 141; iter: 0; batch classifier loss: 0.417487; batch adversarial loss: 0.545977\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360219; batch adversarial loss: 0.580298\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414417; batch adversarial loss: 0.632511\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354375; batch adversarial loss: 0.581559\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387338; batch adversarial loss: 0.502262\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359741; batch adversarial loss: 0.579195\n",
      "epoch 147; iter: 0; batch classifier loss: 0.447816; batch adversarial loss: 0.586249\n",
      "epoch 148; iter: 0; batch classifier loss: 0.324324; batch adversarial loss: 0.543591\n",
      "epoch 149; iter: 0; batch classifier loss: 0.437432; batch adversarial loss: 0.501444\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389718; batch adversarial loss: 0.525048\n",
      "epoch 151; iter: 0; batch classifier loss: 0.436390; batch adversarial loss: 0.614640\n",
      "epoch 152; iter: 0; batch classifier loss: 0.407049; batch adversarial loss: 0.544476\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358923; batch adversarial loss: 0.448050\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340578; batch adversarial loss: 0.572239\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397361; batch adversarial loss: 0.533990\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384008; batch adversarial loss: 0.500587\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432789; batch adversarial loss: 0.411192\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395351; batch adversarial loss: 0.574921\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373861; batch adversarial loss: 0.565546\n",
      "epoch 160; iter: 0; batch classifier loss: 0.402289; batch adversarial loss: 0.569757\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341065; batch adversarial loss: 0.523526\n",
      "epoch 162; iter: 0; batch classifier loss: 0.434042; batch adversarial loss: 0.566914\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361532; batch adversarial loss: 0.577838\n",
      "epoch 164; iter: 0; batch classifier loss: 0.420507; batch adversarial loss: 0.503437\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329078; batch adversarial loss: 0.589541\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353318; batch adversarial loss: 0.593972\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366263; batch adversarial loss: 0.545755\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317375; batch adversarial loss: 0.580721\n",
      "epoch 169; iter: 0; batch classifier loss: 0.290547; batch adversarial loss: 0.584311\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386785; batch adversarial loss: 0.511872\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336337; batch adversarial loss: 0.618599\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349011; batch adversarial loss: 0.592301\n",
      "epoch 173; iter: 0; batch classifier loss: 0.319846; batch adversarial loss: 0.596861\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353700; batch adversarial loss: 0.555751\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409455; batch adversarial loss: 0.560546\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328362; batch adversarial loss: 0.659019\n",
      "epoch 177; iter: 0; batch classifier loss: 0.402633; batch adversarial loss: 0.508902\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347600; batch adversarial loss: 0.598577\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380437; batch adversarial loss: 0.455168\n",
      "epoch 180; iter: 0; batch classifier loss: 0.413015; batch adversarial loss: 0.491627\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311609; batch adversarial loss: 0.570476\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363379; batch adversarial loss: 0.596619\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363080; batch adversarial loss: 0.598018\n",
      "epoch 184; iter: 0; batch classifier loss: 0.405384; batch adversarial loss: 0.534783\n",
      "epoch 185; iter: 0; batch classifier loss: 0.310083; batch adversarial loss: 0.474719\n",
      "epoch 186; iter: 0; batch classifier loss: 0.437122; batch adversarial loss: 0.579122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389662; batch adversarial loss: 0.510951\n",
      "epoch 188; iter: 0; batch classifier loss: 0.333802; batch adversarial loss: 0.556357\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305461; batch adversarial loss: 0.517143\n",
      "epoch 190; iter: 0; batch classifier loss: 0.389529; batch adversarial loss: 0.535861\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331190; batch adversarial loss: 0.608998\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394380; batch adversarial loss: 0.589927\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353610; batch adversarial loss: 0.525800\n",
      "epoch 194; iter: 0; batch classifier loss: 0.413239; batch adversarial loss: 0.493342\n",
      "epoch 195; iter: 0; batch classifier loss: 0.378002; batch adversarial loss: 0.553172\n",
      "epoch 196; iter: 0; batch classifier loss: 0.404686; batch adversarial loss: 0.525188\n",
      "epoch 197; iter: 0; batch classifier loss: 0.418618; batch adversarial loss: 0.516618\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352064; batch adversarial loss: 0.588258\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366684; batch adversarial loss: 0.572049\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718256; batch adversarial loss: 0.662281\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603292; batch adversarial loss: 0.641783\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563348; batch adversarial loss: 0.641245\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530703; batch adversarial loss: 0.608385\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519714; batch adversarial loss: 0.583550\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599128; batch adversarial loss: 0.639030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.696271; batch adversarial loss: 0.627331\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539110; batch adversarial loss: 0.559610\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516476; batch adversarial loss: 0.574172\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501117; batch adversarial loss: 0.576566\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588461; batch adversarial loss: 0.596791\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574758; batch adversarial loss: 0.569105\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553163; batch adversarial loss: 0.604811\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569330; batch adversarial loss: 0.621057\n",
      "epoch 14; iter: 0; batch classifier loss: 0.585951; batch adversarial loss: 0.584261\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488653; batch adversarial loss: 0.598973\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468466; batch adversarial loss: 0.542900\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481689; batch adversarial loss: 0.598045\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506754; batch adversarial loss: 0.524361\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497773; batch adversarial loss: 0.658294\n",
      "epoch 20; iter: 0; batch classifier loss: 0.540466; batch adversarial loss: 0.602136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503640; batch adversarial loss: 0.527055\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515326; batch adversarial loss: 0.553096\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483952; batch adversarial loss: 0.545467\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514756; batch adversarial loss: 0.481335\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508449; batch adversarial loss: 0.579848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433970; batch adversarial loss: 0.492599\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488042; batch adversarial loss: 0.506646\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468323; batch adversarial loss: 0.562880\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463155; batch adversarial loss: 0.523377\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422920; batch adversarial loss: 0.554302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474593; batch adversarial loss: 0.511598\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434820; batch adversarial loss: 0.569304\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507242; batch adversarial loss: 0.578426\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448209; batch adversarial loss: 0.605956\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420800; batch adversarial loss: 0.577439\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469054; batch adversarial loss: 0.534417\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481049; batch adversarial loss: 0.519465\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451507; batch adversarial loss: 0.509567\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427234; batch adversarial loss: 0.531331\n",
      "epoch 40; iter: 0; batch classifier loss: 0.491218; batch adversarial loss: 0.563574\n",
      "epoch 41; iter: 0; batch classifier loss: 0.555152; batch adversarial loss: 0.535300\n",
      "epoch 42; iter: 0; batch classifier loss: 0.523860; batch adversarial loss: 0.607335\n",
      "epoch 43; iter: 0; batch classifier loss: 0.417895; batch adversarial loss: 0.526063\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429903; batch adversarial loss: 0.461203\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481325; batch adversarial loss: 0.477720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496034; batch adversarial loss: 0.541050\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436805; batch adversarial loss: 0.544093\n",
      "epoch 48; iter: 0; batch classifier loss: 0.510026; batch adversarial loss: 0.588255\n",
      "epoch 49; iter: 0; batch classifier loss: 0.469555; batch adversarial loss: 0.480244\n",
      "epoch 50; iter: 0; batch classifier loss: 0.425403; batch adversarial loss: 0.531982\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470235; batch adversarial loss: 0.536246\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414831; batch adversarial loss: 0.515605\n",
      "epoch 53; iter: 0; batch classifier loss: 0.453970; batch adversarial loss: 0.579493\n",
      "epoch 54; iter: 0; batch classifier loss: 0.371129; batch adversarial loss: 0.576437\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444732; batch adversarial loss: 0.518225\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442924; batch adversarial loss: 0.524468\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420398; batch adversarial loss: 0.571959\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431425; batch adversarial loss: 0.505734\n",
      "epoch 59; iter: 0; batch classifier loss: 0.463946; batch adversarial loss: 0.651732\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383383; batch adversarial loss: 0.585230\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383923; batch adversarial loss: 0.553758\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424398; batch adversarial loss: 0.643237\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411891; batch adversarial loss: 0.560965\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348064; batch adversarial loss: 0.470568\n",
      "epoch 65; iter: 0; batch classifier loss: 0.475091; batch adversarial loss: 0.514341\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411502; batch adversarial loss: 0.560972\n",
      "epoch 67; iter: 0; batch classifier loss: 0.467980; batch adversarial loss: 0.538629\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405394; batch adversarial loss: 0.548672\n",
      "epoch 69; iter: 0; batch classifier loss: 0.391336; batch adversarial loss: 0.504025\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462280; batch adversarial loss: 0.541769\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479286; batch adversarial loss: 0.519119\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368856; batch adversarial loss: 0.487638\n",
      "epoch 73; iter: 0; batch classifier loss: 0.361996; batch adversarial loss: 0.605046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.362158; batch adversarial loss: 0.567328\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426171; batch adversarial loss: 0.522192\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396709; batch adversarial loss: 0.570964\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404976; batch adversarial loss: 0.551055\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399483; batch adversarial loss: 0.579199\n",
      "epoch 79; iter: 0; batch classifier loss: 0.342505; batch adversarial loss: 0.546359\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399530; batch adversarial loss: 0.548000\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389881; batch adversarial loss: 0.512491\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418485; batch adversarial loss: 0.558952\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424030; batch adversarial loss: 0.515360\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383286; batch adversarial loss: 0.526333\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382432; batch adversarial loss: 0.518651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356757; batch adversarial loss: 0.601291\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370771; batch adversarial loss: 0.546947\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336446; batch adversarial loss: 0.611053\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334770; batch adversarial loss: 0.536379\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370375; batch adversarial loss: 0.626917\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405315; batch adversarial loss: 0.552556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412746; batch adversarial loss: 0.528968\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383772; batch adversarial loss: 0.545130\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422150; batch adversarial loss: 0.534396\n",
      "epoch 95; iter: 0; batch classifier loss: 0.457187; batch adversarial loss: 0.560615\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372886; batch adversarial loss: 0.541669\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390953; batch adversarial loss: 0.582829\n",
      "epoch 98; iter: 0; batch classifier loss: 0.464966; batch adversarial loss: 0.569520\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393989; batch adversarial loss: 0.544726\n",
      "epoch 100; iter: 0; batch classifier loss: 0.369409; batch adversarial loss: 0.577326\n",
      "epoch 101; iter: 0; batch classifier loss: 0.346533; batch adversarial loss: 0.517730\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377988; batch adversarial loss: 0.479257\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362691; batch adversarial loss: 0.543292\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397784; batch adversarial loss: 0.581642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.455484; batch adversarial loss: 0.573286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352527; batch adversarial loss: 0.582557\n",
      "epoch 107; iter: 0; batch classifier loss: 0.541728; batch adversarial loss: 0.614784\n",
      "epoch 108; iter: 0; batch classifier loss: 0.438121; batch adversarial loss: 0.619669\n",
      "epoch 109; iter: 0; batch classifier loss: 0.361554; batch adversarial loss: 0.471280\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414049; batch adversarial loss: 0.571873\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387472; batch adversarial loss: 0.575342\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366303; batch adversarial loss: 0.591628\n",
      "epoch 113; iter: 0; batch classifier loss: 0.468407; batch adversarial loss: 0.535514\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383733; batch adversarial loss: 0.533603\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362130; batch adversarial loss: 0.594306\n",
      "epoch 116; iter: 0; batch classifier loss: 0.383313; batch adversarial loss: 0.490961\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328868; batch adversarial loss: 0.481670\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368785; batch adversarial loss: 0.508829\n",
      "epoch 119; iter: 0; batch classifier loss: 0.313665; batch adversarial loss: 0.508666\n",
      "epoch 120; iter: 0; batch classifier loss: 0.336146; batch adversarial loss: 0.583890\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362330; batch adversarial loss: 0.553385\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335070; batch adversarial loss: 0.536872\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354422; batch adversarial loss: 0.536674\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342340; batch adversarial loss: 0.537109\n",
      "epoch 125; iter: 0; batch classifier loss: 0.458435; batch adversarial loss: 0.574218\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329681; batch adversarial loss: 0.558307\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396717; batch adversarial loss: 0.491260\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419526; batch adversarial loss: 0.474697\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350380; batch adversarial loss: 0.554144\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377035; batch adversarial loss: 0.629119\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349736; batch adversarial loss: 0.517462\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384999; batch adversarial loss: 0.452989\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374928; batch adversarial loss: 0.524079\n",
      "epoch 134; iter: 0; batch classifier loss: 0.294938; batch adversarial loss: 0.504992\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308505; batch adversarial loss: 0.561604\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345655; batch adversarial loss: 0.553688\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377026; batch adversarial loss: 0.578742\n",
      "epoch 138; iter: 0; batch classifier loss: 0.295019; batch adversarial loss: 0.519944\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383425; batch adversarial loss: 0.516435\n",
      "epoch 140; iter: 0; batch classifier loss: 0.362987; batch adversarial loss: 0.601755\n",
      "epoch 141; iter: 0; batch classifier loss: 0.324903; batch adversarial loss: 0.489856\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346331; batch adversarial loss: 0.518380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431985; batch adversarial loss: 0.530101\n",
      "epoch 144; iter: 0; batch classifier loss: 0.314192; batch adversarial loss: 0.518664\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412215; batch adversarial loss: 0.534943\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345848; batch adversarial loss: 0.520228\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351884; batch adversarial loss: 0.489584\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323229; batch adversarial loss: 0.536857\n",
      "epoch 149; iter: 0; batch classifier loss: 0.303512; batch adversarial loss: 0.579823\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340211; batch adversarial loss: 0.589874\n",
      "epoch 151; iter: 0; batch classifier loss: 0.314483; batch adversarial loss: 0.561021\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339349; batch adversarial loss: 0.553130\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372996; batch adversarial loss: 0.553846\n",
      "epoch 154; iter: 0; batch classifier loss: 0.326360; batch adversarial loss: 0.524319\n",
      "epoch 155; iter: 0; batch classifier loss: 0.351192; batch adversarial loss: 0.580192\n",
      "epoch 156; iter: 0; batch classifier loss: 0.426966; batch adversarial loss: 0.581446\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392307; batch adversarial loss: 0.571033\n",
      "epoch 158; iter: 0; batch classifier loss: 0.406443; batch adversarial loss: 0.552859\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353237; batch adversarial loss: 0.543447\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362721; batch adversarial loss: 0.591456\n",
      "epoch 161; iter: 0; batch classifier loss: 0.381368; batch adversarial loss: 0.592362\n",
      "epoch 162; iter: 0; batch classifier loss: 0.282496; batch adversarial loss: 0.527795\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366758; batch adversarial loss: 0.555963\n",
      "epoch 164; iter: 0; batch classifier loss: 0.316769; batch adversarial loss: 0.552577\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344204; batch adversarial loss: 0.542233\n",
      "epoch 166; iter: 0; batch classifier loss: 0.479309; batch adversarial loss: 0.534878\n",
      "epoch 167; iter: 0; batch classifier loss: 0.430234; batch adversarial loss: 0.571104\n",
      "epoch 168; iter: 0; batch classifier loss: 0.311410; batch adversarial loss: 0.544494\n",
      "epoch 169; iter: 0; batch classifier loss: 0.340969; batch adversarial loss: 0.635384\n",
      "epoch 170; iter: 0; batch classifier loss: 0.509767; batch adversarial loss: 0.553564\n",
      "epoch 171; iter: 0; batch classifier loss: 0.339263; batch adversarial loss: 0.614943\n",
      "epoch 172; iter: 0; batch classifier loss: 0.309441; batch adversarial loss: 0.570053\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360889; batch adversarial loss: 0.578186\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340319; batch adversarial loss: 0.538404\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332488; batch adversarial loss: 0.580063\n",
      "epoch 176; iter: 0; batch classifier loss: 0.390298; batch adversarial loss: 0.545160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.370638; batch adversarial loss: 0.554356\n",
      "epoch 178; iter: 0; batch classifier loss: 0.413357; batch adversarial loss: 0.507096\n",
      "epoch 179; iter: 0; batch classifier loss: 0.393894; batch adversarial loss: 0.564195\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328239; batch adversarial loss: 0.453162\n",
      "epoch 181; iter: 0; batch classifier loss: 0.380978; batch adversarial loss: 0.564671\n",
      "epoch 182; iter: 0; batch classifier loss: 0.386124; batch adversarial loss: 0.480661\n",
      "epoch 183; iter: 0; batch classifier loss: 0.298384; batch adversarial loss: 0.526312\n",
      "epoch 184; iter: 0; batch classifier loss: 0.419046; batch adversarial loss: 0.582483\n",
      "epoch 185; iter: 0; batch classifier loss: 0.302955; batch adversarial loss: 0.571533\n",
      "epoch 186; iter: 0; batch classifier loss: 0.362841; batch adversarial loss: 0.589779\n",
      "epoch 187; iter: 0; batch classifier loss: 0.275922; batch adversarial loss: 0.560762\n",
      "epoch 188; iter: 0; batch classifier loss: 0.293201; batch adversarial loss: 0.545268\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354432; batch adversarial loss: 0.473682\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351258; batch adversarial loss: 0.554356\n",
      "epoch 191; iter: 0; batch classifier loss: 0.284243; batch adversarial loss: 0.561385\n",
      "epoch 192; iter: 0; batch classifier loss: 0.414031; batch adversarial loss: 0.581190\n",
      "epoch 193; iter: 0; batch classifier loss: 0.385762; batch adversarial loss: 0.546719\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392827; batch adversarial loss: 0.562700\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369174; batch adversarial loss: 0.535265\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347970; batch adversarial loss: 0.553431\n",
      "epoch 197; iter: 0; batch classifier loss: 0.418474; batch adversarial loss: 0.514001\n",
      "epoch 198; iter: 0; batch classifier loss: 0.266370; batch adversarial loss: 0.524464\n",
      "epoch 199; iter: 0; batch classifier loss: 0.390722; batch adversarial loss: 0.445604\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734102; batch adversarial loss: 0.729919\n",
      "epoch 1; iter: 0; batch classifier loss: 0.661129; batch adversarial loss: 0.686629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.641791; batch adversarial loss: 0.665467\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544557; batch adversarial loss: 0.646727\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640111; batch adversarial loss: 0.620566\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537986; batch adversarial loss: 0.597597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545657; batch adversarial loss: 0.624602\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511352; batch adversarial loss: 0.616213\n",
      "epoch 8; iter: 0; batch classifier loss: 0.493750; batch adversarial loss: 0.610014\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602284; batch adversarial loss: 0.623643\n",
      "epoch 10; iter: 0; batch classifier loss: 0.527032; batch adversarial loss: 0.562312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536079; batch adversarial loss: 0.587522\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538669; batch adversarial loss: 0.604296\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500962; batch adversarial loss: 0.581472\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552344; batch adversarial loss: 0.497849\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492547; batch adversarial loss: 0.609663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442613; batch adversarial loss: 0.577785\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461225; batch adversarial loss: 0.614478\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489166; batch adversarial loss: 0.588748\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557899; batch adversarial loss: 0.619267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.503044; batch adversarial loss: 0.605058\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531950; batch adversarial loss: 0.585495\n",
      "epoch 22; iter: 0; batch classifier loss: 0.589215; batch adversarial loss: 0.567955\n",
      "epoch 23; iter: 0; batch classifier loss: 0.433123; batch adversarial loss: 0.463569\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446194; batch adversarial loss: 0.612482\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510356; batch adversarial loss: 0.551324\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419815; batch adversarial loss: 0.557345\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511788; batch adversarial loss: 0.594618\n",
      "epoch 28; iter: 0; batch classifier loss: 0.476818; batch adversarial loss: 0.524240\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467934; batch adversarial loss: 0.538655\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469880; batch adversarial loss: 0.506720\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451178; batch adversarial loss: 0.547687\n",
      "epoch 32; iter: 0; batch classifier loss: 0.413310; batch adversarial loss: 0.574207\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441804; batch adversarial loss: 0.536945\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467906; batch adversarial loss: 0.542013\n",
      "epoch 35; iter: 0; batch classifier loss: 0.520730; batch adversarial loss: 0.556195\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486635; batch adversarial loss: 0.529959\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400260; batch adversarial loss: 0.484310\n",
      "epoch 38; iter: 0; batch classifier loss: 0.546873; batch adversarial loss: 0.537593\n",
      "epoch 39; iter: 0; batch classifier loss: 0.393135; batch adversarial loss: 0.572086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459828; batch adversarial loss: 0.589941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426604; batch adversarial loss: 0.519359\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482336; batch adversarial loss: 0.548180\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415283; batch adversarial loss: 0.616008\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406681; batch adversarial loss: 0.607490\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449164; batch adversarial loss: 0.520144\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443315; batch adversarial loss: 0.553794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.378633; batch adversarial loss: 0.589918\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459562; batch adversarial loss: 0.519193\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411376; batch adversarial loss: 0.518461\n",
      "epoch 50; iter: 0; batch classifier loss: 0.510628; batch adversarial loss: 0.554741\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483938; batch adversarial loss: 0.544634\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461694; batch adversarial loss: 0.519301\n",
      "epoch 53; iter: 0; batch classifier loss: 0.479071; batch adversarial loss: 0.544273\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425312; batch adversarial loss: 0.572298\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441904; batch adversarial loss: 0.519615\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423441; batch adversarial loss: 0.519098\n",
      "epoch 57; iter: 0; batch classifier loss: 0.476101; batch adversarial loss: 0.589524\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418192; batch adversarial loss: 0.614948\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449354; batch adversarial loss: 0.608285\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443343; batch adversarial loss: 0.570271\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413807; batch adversarial loss: 0.507864\n",
      "epoch 62; iter: 0; batch classifier loss: 0.505453; batch adversarial loss: 0.617447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.433090; batch adversarial loss: 0.526341\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401509; batch adversarial loss: 0.515990\n",
      "epoch 65; iter: 0; batch classifier loss: 0.486134; batch adversarial loss: 0.545290\n",
      "epoch 66; iter: 0; batch classifier loss: 0.310760; batch adversarial loss: 0.526085\n",
      "epoch 67; iter: 0; batch classifier loss: 0.456532; batch adversarial loss: 0.526848\n",
      "epoch 68; iter: 0; batch classifier loss: 0.444731; batch adversarial loss: 0.545501\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378713; batch adversarial loss: 0.552579\n",
      "epoch 70; iter: 0; batch classifier loss: 0.452386; batch adversarial loss: 0.552782\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378816; batch adversarial loss: 0.659346\n",
      "epoch 72; iter: 0; batch classifier loss: 0.496886; batch adversarial loss: 0.516096\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406190; batch adversarial loss: 0.624275\n",
      "epoch 74; iter: 0; batch classifier loss: 0.474251; batch adversarial loss: 0.535736\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438377; batch adversarial loss: 0.598349\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410643; batch adversarial loss: 0.526592\n",
      "epoch 77; iter: 0; batch classifier loss: 0.354043; batch adversarial loss: 0.562828\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431957; batch adversarial loss: 0.535906\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409135; batch adversarial loss: 0.579986\n",
      "epoch 80; iter: 0; batch classifier loss: 0.317912; batch adversarial loss: 0.553786\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428903; batch adversarial loss: 0.500122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426038; batch adversarial loss: 0.552859\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452646; batch adversarial loss: 0.527452\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435705; batch adversarial loss: 0.507644\n",
      "epoch 85; iter: 0; batch classifier loss: 0.371977; batch adversarial loss: 0.562734\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411506; batch adversarial loss: 0.615750\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410009; batch adversarial loss: 0.580033\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388444; batch adversarial loss: 0.517603\n",
      "epoch 89; iter: 0; batch classifier loss: 0.298645; batch adversarial loss: 0.569722\n",
      "epoch 90; iter: 0; batch classifier loss: 0.318064; batch adversarial loss: 0.500394\n",
      "epoch 91; iter: 0; batch classifier loss: 0.350952; batch adversarial loss: 0.588606\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366232; batch adversarial loss: 0.472463\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422871; batch adversarial loss: 0.598219\n",
      "epoch 94; iter: 0; batch classifier loss: 0.304806; batch adversarial loss: 0.579406\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348605; batch adversarial loss: 0.472519\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335172; batch adversarial loss: 0.506511\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389615; batch adversarial loss: 0.573947\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361821; batch adversarial loss: 0.589266\n",
      "epoch 99; iter: 0; batch classifier loss: 0.420561; batch adversarial loss: 0.608396\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374719; batch adversarial loss: 0.585379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.400518; batch adversarial loss: 0.652445\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414050; batch adversarial loss: 0.555680\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438821; batch adversarial loss: 0.614762\n",
      "epoch 104; iter: 0; batch classifier loss: 0.328065; batch adversarial loss: 0.606172\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380070; batch adversarial loss: 0.622585\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398308; batch adversarial loss: 0.527576\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402721; batch adversarial loss: 0.483932\n",
      "epoch 108; iter: 0; batch classifier loss: 0.428244; batch adversarial loss: 0.563469\n",
      "epoch 109; iter: 0; batch classifier loss: 0.436846; batch adversarial loss: 0.580538\n",
      "epoch 110; iter: 0; batch classifier loss: 0.445736; batch adversarial loss: 0.500469\n",
      "epoch 111; iter: 0; batch classifier loss: 0.324776; batch adversarial loss: 0.561548\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390043; batch adversarial loss: 0.579928\n",
      "epoch 113; iter: 0; batch classifier loss: 0.371958; batch adversarial loss: 0.572306\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370233; batch adversarial loss: 0.562642\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394462; batch adversarial loss: 0.518579\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410248; batch adversarial loss: 0.536096\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388580; batch adversarial loss: 0.544132\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401440; batch adversarial loss: 0.535663\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394973; batch adversarial loss: 0.518723\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362040; batch adversarial loss: 0.509195\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358923; batch adversarial loss: 0.526659\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386727; batch adversarial loss: 0.481323\n",
      "epoch 123; iter: 0; batch classifier loss: 0.465190; batch adversarial loss: 0.465449\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378272; batch adversarial loss: 0.574320\n",
      "epoch 125; iter: 0; batch classifier loss: 0.431632; batch adversarial loss: 0.607233\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401292; batch adversarial loss: 0.535300\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385902; batch adversarial loss: 0.526922\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332233; batch adversarial loss: 0.590206\n",
      "epoch 129; iter: 0; batch classifier loss: 0.438659; batch adversarial loss: 0.597244\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349632; batch adversarial loss: 0.554180\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365958; batch adversarial loss: 0.544301\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375690; batch adversarial loss: 0.608327\n",
      "epoch 133; iter: 0; batch classifier loss: 0.428217; batch adversarial loss: 0.536489\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415014; batch adversarial loss: 0.633278\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400510; batch adversarial loss: 0.597010\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361851; batch adversarial loss: 0.473804\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382225; batch adversarial loss: 0.527355\n",
      "epoch 138; iter: 0; batch classifier loss: 0.397644; batch adversarial loss: 0.553132\n",
      "epoch 139; iter: 0; batch classifier loss: 0.447795; batch adversarial loss: 0.580062\n",
      "epoch 140; iter: 0; batch classifier loss: 0.450202; batch adversarial loss: 0.571228\n",
      "epoch 141; iter: 0; batch classifier loss: 0.290279; batch adversarial loss: 0.562241\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336689; batch adversarial loss: 0.544719\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385091; batch adversarial loss: 0.588356\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292301; batch adversarial loss: 0.579699\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404629; batch adversarial loss: 0.589455\n",
      "epoch 146; iter: 0; batch classifier loss: 0.322189; batch adversarial loss: 0.562182\n",
      "epoch 147; iter: 0; batch classifier loss: 0.366534; batch adversarial loss: 0.563620\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365417; batch adversarial loss: 0.527826\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396313; batch adversarial loss: 0.553431\n",
      "epoch 150; iter: 0; batch classifier loss: 0.421246; batch adversarial loss: 0.562731\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355677; batch adversarial loss: 0.552330\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354484; batch adversarial loss: 0.589018\n",
      "epoch 153; iter: 0; batch classifier loss: 0.315370; batch adversarial loss: 0.517465\n",
      "epoch 154; iter: 0; batch classifier loss: 0.406029; batch adversarial loss: 0.614966\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377644; batch adversarial loss: 0.483050\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300206; batch adversarial loss: 0.517041\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324606; batch adversarial loss: 0.572056\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342615; batch adversarial loss: 0.535855\n",
      "epoch 159; iter: 0; batch classifier loss: 0.405886; batch adversarial loss: 0.561689\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386490; batch adversarial loss: 0.534542\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325908; batch adversarial loss: 0.544112\n",
      "epoch 162; iter: 0; batch classifier loss: 0.310857; batch adversarial loss: 0.563594\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365914; batch adversarial loss: 0.652376\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335317; batch adversarial loss: 0.535846\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344402; batch adversarial loss: 0.526298\n",
      "epoch 166; iter: 0; batch classifier loss: 0.348215; batch adversarial loss: 0.571072\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397802; batch adversarial loss: 0.590234\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380555; batch adversarial loss: 0.589326\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376295; batch adversarial loss: 0.482794\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398592; batch adversarial loss: 0.553939\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385112; batch adversarial loss: 0.516993\n",
      "epoch 172; iter: 0; batch classifier loss: 0.448058; batch adversarial loss: 0.536261\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323171; batch adversarial loss: 0.580983\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384341; batch adversarial loss: 0.581414\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359139; batch adversarial loss: 0.588194\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372395; batch adversarial loss: 0.545891\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351882; batch adversarial loss: 0.544900\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287518; batch adversarial loss: 0.544648\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337700; batch adversarial loss: 0.597518\n",
      "epoch 180; iter: 0; batch classifier loss: 0.405130; batch adversarial loss: 0.580201\n",
      "epoch 181; iter: 0; batch classifier loss: 0.443505; batch adversarial loss: 0.581891\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359243; batch adversarial loss: 0.527684\n",
      "epoch 183; iter: 0; batch classifier loss: 0.301057; batch adversarial loss: 0.535758\n",
      "epoch 184; iter: 0; batch classifier loss: 0.428559; batch adversarial loss: 0.518506\n",
      "epoch 185; iter: 0; batch classifier loss: 0.432245; batch adversarial loss: 0.605398\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383460; batch adversarial loss: 0.517636\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355272; batch adversarial loss: 0.500602\n",
      "epoch 188; iter: 0; batch classifier loss: 0.358646; batch adversarial loss: 0.527188\n",
      "epoch 189; iter: 0; batch classifier loss: 0.284849; batch adversarial loss: 0.562125\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344149; batch adversarial loss: 0.615815\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391452; batch adversarial loss: 0.518326\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374379; batch adversarial loss: 0.615403\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338929; batch adversarial loss: 0.545370\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356031; batch adversarial loss: 0.571985\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317892; batch adversarial loss: 0.553348\n",
      "epoch 196; iter: 0; batch classifier loss: 0.282541; batch adversarial loss: 0.544435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.316895; batch adversarial loss: 0.562669\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328389; batch adversarial loss: 0.598370\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323407; batch adversarial loss: 0.562709\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678346; batch adversarial loss: 0.805359\n",
      "epoch 1; iter: 0; batch classifier loss: 0.832322; batch adversarial loss: 0.997925\n",
      "epoch 2; iter: 0; batch classifier loss: 0.973609; batch adversarial loss: 0.975459\n",
      "epoch 3; iter: 0; batch classifier loss: 1.043949; batch adversarial loss: 0.926687\n",
      "epoch 4; iter: 0; batch classifier loss: 0.934553; batch adversarial loss: 0.830709\n",
      "epoch 5; iter: 0; batch classifier loss: 0.811871; batch adversarial loss: 0.728973\n",
      "epoch 6; iter: 0; batch classifier loss: 0.699639; batch adversarial loss: 0.672506\n",
      "epoch 7; iter: 0; batch classifier loss: 0.648419; batch adversarial loss: 0.668203\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574518; batch adversarial loss: 0.612824\n",
      "epoch 9; iter: 0; batch classifier loss: 0.606696; batch adversarial loss: 0.588718\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549892; batch adversarial loss: 0.578290\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585094; batch adversarial loss: 0.596871\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537394; batch adversarial loss: 0.551044\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542861; batch adversarial loss: 0.601949\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557672; batch adversarial loss: 0.629888\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569247; batch adversarial loss: 0.552579\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538513; batch adversarial loss: 0.556112\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525993; batch adversarial loss: 0.598783\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532083; batch adversarial loss: 0.628972\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516721; batch adversarial loss: 0.563924\n",
      "epoch 20; iter: 0; batch classifier loss: 0.467803; batch adversarial loss: 0.611800\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517189; batch adversarial loss: 0.512866\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470864; batch adversarial loss: 0.626102\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473442; batch adversarial loss: 0.580786\n",
      "epoch 24; iter: 0; batch classifier loss: 0.545838; batch adversarial loss: 0.558032\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498951; batch adversarial loss: 0.566683\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465223; batch adversarial loss: 0.537236\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476240; batch adversarial loss: 0.532309\n",
      "epoch 28; iter: 0; batch classifier loss: 0.536935; batch adversarial loss: 0.534449\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431186; batch adversarial loss: 0.501649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427847; batch adversarial loss: 0.558955\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506478; batch adversarial loss: 0.573008\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491233; batch adversarial loss: 0.565916\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425214; batch adversarial loss: 0.553322\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536371; batch adversarial loss: 0.548019\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473775; batch adversarial loss: 0.576577\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430658; batch adversarial loss: 0.615873\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491411; batch adversarial loss: 0.561217\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434413; batch adversarial loss: 0.577097\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478523; batch adversarial loss: 0.626453\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471122; batch adversarial loss: 0.546109\n",
      "epoch 41; iter: 0; batch classifier loss: 0.490210; batch adversarial loss: 0.536994\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464988; batch adversarial loss: 0.629806\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480821; batch adversarial loss: 0.592310\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516739; batch adversarial loss: 0.594176\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516646; batch adversarial loss: 0.522181\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464273; batch adversarial loss: 0.564801\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468724; batch adversarial loss: 0.535483\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395008; batch adversarial loss: 0.553435\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438624; batch adversarial loss: 0.543965\n",
      "epoch 50; iter: 0; batch classifier loss: 0.481966; batch adversarial loss: 0.512096\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457770; batch adversarial loss: 0.528353\n",
      "epoch 52; iter: 0; batch classifier loss: 0.396760; batch adversarial loss: 0.569065\n",
      "epoch 53; iter: 0; batch classifier loss: 0.457115; batch adversarial loss: 0.553631\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440576; batch adversarial loss: 0.631891\n",
      "epoch 55; iter: 0; batch classifier loss: 0.369033; batch adversarial loss: 0.589826\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492515; batch adversarial loss: 0.463017\n",
      "epoch 57; iter: 0; batch classifier loss: 0.462645; batch adversarial loss: 0.606862\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403059; batch adversarial loss: 0.474698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412133; batch adversarial loss: 0.591362\n",
      "epoch 60; iter: 0; batch classifier loss: 0.375390; batch adversarial loss: 0.598144\n",
      "epoch 61; iter: 0; batch classifier loss: 0.339564; batch adversarial loss: 0.607509\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434364; batch adversarial loss: 0.553571\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417198; batch adversarial loss: 0.536048\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411016; batch adversarial loss: 0.579831\n",
      "epoch 65; iter: 0; batch classifier loss: 0.339522; batch adversarial loss: 0.561641\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459156; batch adversarial loss: 0.563162\n",
      "epoch 67; iter: 0; batch classifier loss: 0.343877; batch adversarial loss: 0.471963\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364210; batch adversarial loss: 0.581118\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426199; batch adversarial loss: 0.517282\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401624; batch adversarial loss: 0.499318\n",
      "epoch 71; iter: 0; batch classifier loss: 0.466665; batch adversarial loss: 0.626123\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427405; batch adversarial loss: 0.553059\n",
      "epoch 73; iter: 0; batch classifier loss: 0.537766; batch adversarial loss: 0.589412\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367106; batch adversarial loss: 0.570713\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358878; batch adversarial loss: 0.543371\n",
      "epoch 76; iter: 0; batch classifier loss: 0.524716; batch adversarial loss: 0.650174\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408845; batch adversarial loss: 0.526926\n",
      "epoch 78; iter: 0; batch classifier loss: 0.444033; batch adversarial loss: 0.554875\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357396; batch adversarial loss: 0.642309\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447569; batch adversarial loss: 0.581445\n",
      "epoch 81; iter: 0; batch classifier loss: 0.324940; batch adversarial loss: 0.606663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406331; batch adversarial loss: 0.588791\n",
      "epoch 83; iter: 0; batch classifier loss: 0.362129; batch adversarial loss: 0.635057\n",
      "epoch 84; iter: 0; batch classifier loss: 0.480216; batch adversarial loss: 0.535157\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376617; batch adversarial loss: 0.545626\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370303; batch adversarial loss: 0.535980\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340069; batch adversarial loss: 0.533161\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376030; batch adversarial loss: 0.515812\n",
      "epoch 89; iter: 0; batch classifier loss: 0.447218; batch adversarial loss: 0.527706\n",
      "epoch 90; iter: 0; batch classifier loss: 0.470411; batch adversarial loss: 0.624396\n",
      "epoch 91; iter: 0; batch classifier loss: 0.450910; batch adversarial loss: 0.527880\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404875; batch adversarial loss: 0.473218\n",
      "epoch 93; iter: 0; batch classifier loss: 0.382848; batch adversarial loss: 0.515959\n",
      "epoch 94; iter: 0; batch classifier loss: 0.297389; batch adversarial loss: 0.553621\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423220; batch adversarial loss: 0.546401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.359257; batch adversarial loss: 0.596513\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375208; batch adversarial loss: 0.616884\n",
      "epoch 98; iter: 0; batch classifier loss: 0.413745; batch adversarial loss: 0.571386\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415889; batch adversarial loss: 0.597802\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351098; batch adversarial loss: 0.511044\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374267; batch adversarial loss: 0.660073\n",
      "epoch 102; iter: 0; batch classifier loss: 0.407881; batch adversarial loss: 0.569988\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413189; batch adversarial loss: 0.481159\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421550; batch adversarial loss: 0.608003\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359043; batch adversarial loss: 0.534861\n",
      "epoch 106; iter: 0; batch classifier loss: 0.322429; batch adversarial loss: 0.543536\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335719; batch adversarial loss: 0.479769\n",
      "epoch 108; iter: 0; batch classifier loss: 0.350177; batch adversarial loss: 0.482988\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402050; batch adversarial loss: 0.575811\n",
      "epoch 110; iter: 0; batch classifier loss: 0.332106; batch adversarial loss: 0.534941\n",
      "epoch 111; iter: 0; batch classifier loss: 0.308252; batch adversarial loss: 0.547244\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383350; batch adversarial loss: 0.569130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.359980; batch adversarial loss: 0.544038\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369240; batch adversarial loss: 0.481024\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328175; batch adversarial loss: 0.536820\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441188; batch adversarial loss: 0.506863\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370586; batch adversarial loss: 0.543982\n",
      "epoch 118; iter: 0; batch classifier loss: 0.475704; batch adversarial loss: 0.554649\n",
      "epoch 119; iter: 0; batch classifier loss: 0.411418; batch adversarial loss: 0.527063\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369041; batch adversarial loss: 0.507957\n",
      "epoch 121; iter: 0; batch classifier loss: 0.354435; batch adversarial loss: 0.515451\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372399; batch adversarial loss: 0.661640\n",
      "epoch 123; iter: 0; batch classifier loss: 0.410836; batch adversarial loss: 0.538398\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346314; batch adversarial loss: 0.563189\n",
      "epoch 125; iter: 0; batch classifier loss: 0.324130; batch adversarial loss: 0.643780\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369418; batch adversarial loss: 0.623684\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352981; batch adversarial loss: 0.537958\n",
      "epoch 128; iter: 0; batch classifier loss: 0.425049; batch adversarial loss: 0.499682\n",
      "epoch 129; iter: 0; batch classifier loss: 0.335697; batch adversarial loss: 0.536943\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355726; batch adversarial loss: 0.617497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348834; batch adversarial loss: 0.560728\n",
      "epoch 132; iter: 0; batch classifier loss: 0.311621; batch adversarial loss: 0.643002\n",
      "epoch 133; iter: 0; batch classifier loss: 0.363573; batch adversarial loss: 0.462311\n",
      "epoch 134; iter: 0; batch classifier loss: 0.461156; batch adversarial loss: 0.544854\n",
      "epoch 135; iter: 0; batch classifier loss: 0.327595; batch adversarial loss: 0.562100\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361231; batch adversarial loss: 0.534146\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352842; batch adversarial loss: 0.617151\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318245; batch adversarial loss: 0.612215\n",
      "epoch 139; iter: 0; batch classifier loss: 0.317052; batch adversarial loss: 0.570984\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329863; batch adversarial loss: 0.544085\n",
      "epoch 141; iter: 0; batch classifier loss: 0.384581; batch adversarial loss: 0.525055\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311873; batch adversarial loss: 0.543559\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361411; batch adversarial loss: 0.489668\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346396; batch adversarial loss: 0.601020\n",
      "epoch 145; iter: 0; batch classifier loss: 0.388970; batch adversarial loss: 0.526471\n",
      "epoch 146; iter: 0; batch classifier loss: 0.444703; batch adversarial loss: 0.509816\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383865; batch adversarial loss: 0.516079\n",
      "epoch 148; iter: 0; batch classifier loss: 0.298299; batch adversarial loss: 0.572393\n",
      "epoch 149; iter: 0; batch classifier loss: 0.360779; batch adversarial loss: 0.562540\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360109; batch adversarial loss: 0.502342\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372527; batch adversarial loss: 0.561518\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374982; batch adversarial loss: 0.547728\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355989; batch adversarial loss: 0.507025\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332710; batch adversarial loss: 0.489320\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353315; batch adversarial loss: 0.561848\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336917; batch adversarial loss: 0.508411\n",
      "epoch 157; iter: 0; batch classifier loss: 0.281232; batch adversarial loss: 0.442874\n",
      "epoch 158; iter: 0; batch classifier loss: 0.296247; batch adversarial loss: 0.536200\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349185; batch adversarial loss: 0.535619\n",
      "epoch 160; iter: 0; batch classifier loss: 0.410649; batch adversarial loss: 0.547297\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325082; batch adversarial loss: 0.560881\n",
      "epoch 162; iter: 0; batch classifier loss: 0.314345; batch adversarial loss: 0.658868\n",
      "epoch 163; iter: 0; batch classifier loss: 0.313682; batch adversarial loss: 0.492377\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368280; batch adversarial loss: 0.617381\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362712; batch adversarial loss: 0.562126\n",
      "epoch 166; iter: 0; batch classifier loss: 0.363541; batch adversarial loss: 0.610533\n",
      "epoch 167; iter: 0; batch classifier loss: 0.300157; batch adversarial loss: 0.573387\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396202; batch adversarial loss: 0.563152\n",
      "epoch 169; iter: 0; batch classifier loss: 0.388618; batch adversarial loss: 0.555212\n",
      "epoch 170; iter: 0; batch classifier loss: 0.298496; batch adversarial loss: 0.518069\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335483; batch adversarial loss: 0.435965\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326183; batch adversarial loss: 0.552594\n",
      "epoch 173; iter: 0; batch classifier loss: 0.418787; batch adversarial loss: 0.554780\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363766; batch adversarial loss: 0.598992\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330574; batch adversarial loss: 0.506621\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370037; batch adversarial loss: 0.624236\n",
      "epoch 177; iter: 0; batch classifier loss: 0.456786; batch adversarial loss: 0.547064\n",
      "epoch 178; iter: 0; batch classifier loss: 0.476294; batch adversarial loss: 0.542243\n",
      "epoch 179; iter: 0; batch classifier loss: 0.292567; batch adversarial loss: 0.524232\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312985; batch adversarial loss: 0.560021\n",
      "epoch 181; iter: 0; batch classifier loss: 0.380305; batch adversarial loss: 0.551645\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329190; batch adversarial loss: 0.583584\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346221; batch adversarial loss: 0.516480\n",
      "epoch 184; iter: 0; batch classifier loss: 0.412339; batch adversarial loss: 0.555798\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346169; batch adversarial loss: 0.543459\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400015; batch adversarial loss: 0.489109\n",
      "epoch 187; iter: 0; batch classifier loss: 0.281709; batch adversarial loss: 0.534398\n",
      "epoch 188; iter: 0; batch classifier loss: 0.323480; batch adversarial loss: 0.506816\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385262; batch adversarial loss: 0.616571\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367296; batch adversarial loss: 0.587611\n",
      "epoch 191; iter: 0; batch classifier loss: 0.257235; batch adversarial loss: 0.604972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.340853; batch adversarial loss: 0.552335\n",
      "epoch 193; iter: 0; batch classifier loss: 0.371582; batch adversarial loss: 0.514925\n",
      "epoch 194; iter: 0; batch classifier loss: 0.388718; batch adversarial loss: 0.491989\n",
      "epoch 195; iter: 0; batch classifier loss: 0.285165; batch adversarial loss: 0.508280\n",
      "epoch 196; iter: 0; batch classifier loss: 0.393455; batch adversarial loss: 0.580273\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341830; batch adversarial loss: 0.528119\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352693; batch adversarial loss: 0.569887\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349057; batch adversarial loss: 0.579868\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687256; batch adversarial loss: 0.711443\n",
      "epoch 1; iter: 0; batch classifier loss: 0.540372; batch adversarial loss: 0.679594\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580160; batch adversarial loss: 0.667064\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558282; batch adversarial loss: 0.665891\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600663; batch adversarial loss: 0.607206\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538851; batch adversarial loss: 0.608876\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492374; batch adversarial loss: 0.626166\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481481; batch adversarial loss: 0.564068\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543923; batch adversarial loss: 0.566327\n",
      "epoch 9; iter: 0; batch classifier loss: 0.497440; batch adversarial loss: 0.571030\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468534; batch adversarial loss: 0.587835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493715; batch adversarial loss: 0.554183\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467470; batch adversarial loss: 0.598493\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563811; batch adversarial loss: 0.622545\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519560; batch adversarial loss: 0.606586\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544027; batch adversarial loss: 0.612120\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523746; batch adversarial loss: 0.597162\n",
      "epoch 17; iter: 0; batch classifier loss: 0.418440; batch adversarial loss: 0.516263\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493155; batch adversarial loss: 0.564081\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524137; batch adversarial loss: 0.594494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426640; batch adversarial loss: 0.561102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.419260; batch adversarial loss: 0.554127\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517130; batch adversarial loss: 0.547274\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501440; batch adversarial loss: 0.578900\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528338; batch adversarial loss: 0.568720\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497707; batch adversarial loss: 0.552346\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484451; batch adversarial loss: 0.524393\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453961; batch adversarial loss: 0.538598\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465273; batch adversarial loss: 0.535215\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455549; batch adversarial loss: 0.508711\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472066; batch adversarial loss: 0.515442\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473954; batch adversarial loss: 0.571033\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438827; batch adversarial loss: 0.555123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.389872; batch adversarial loss: 0.581094\n",
      "epoch 34; iter: 0; batch classifier loss: 0.513246; batch adversarial loss: 0.556334\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402209; batch adversarial loss: 0.621043\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403722; batch adversarial loss: 0.570279\n",
      "epoch 37; iter: 0; batch classifier loss: 0.382538; batch adversarial loss: 0.562150\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437891; batch adversarial loss: 0.502424\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424420; batch adversarial loss: 0.493497\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448737; batch adversarial loss: 0.605485\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462898; batch adversarial loss: 0.518921\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465306; batch adversarial loss: 0.562145\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436337; batch adversarial loss: 0.580219\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421996; batch adversarial loss: 0.527573\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465937; batch adversarial loss: 0.562608\n",
      "epoch 46; iter: 0; batch classifier loss: 0.404382; batch adversarial loss: 0.527374\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472334; batch adversarial loss: 0.570575\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411657; batch adversarial loss: 0.562438\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401300; batch adversarial loss: 0.553052\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461680; batch adversarial loss: 0.579630\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406784; batch adversarial loss: 0.579858\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372222; batch adversarial loss: 0.500703\n",
      "epoch 53; iter: 0; batch classifier loss: 0.325609; batch adversarial loss: 0.553629\n",
      "epoch 54; iter: 0; batch classifier loss: 0.389628; batch adversarial loss: 0.517846\n",
      "epoch 55; iter: 0; batch classifier loss: 0.340040; batch adversarial loss: 0.544510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378538; batch adversarial loss: 0.616050\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432409; batch adversarial loss: 0.571271\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402867; batch adversarial loss: 0.588627\n",
      "epoch 59; iter: 0; batch classifier loss: 0.380402; batch adversarial loss: 0.553591\n",
      "epoch 60; iter: 0; batch classifier loss: 0.360026; batch adversarial loss: 0.562495\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410409; batch adversarial loss: 0.500936\n",
      "epoch 62; iter: 0; batch classifier loss: 0.361541; batch adversarial loss: 0.633637\n",
      "epoch 63; iter: 0; batch classifier loss: 0.398895; batch adversarial loss: 0.544816\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368485; batch adversarial loss: 0.571280\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410324; batch adversarial loss: 0.588913\n",
      "epoch 66; iter: 0; batch classifier loss: 0.466818; batch adversarial loss: 0.509222\n",
      "epoch 67; iter: 0; batch classifier loss: 0.348398; batch adversarial loss: 0.535694\n",
      "epoch 68; iter: 0; batch classifier loss: 0.387654; batch adversarial loss: 0.535717\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402133; batch adversarial loss: 0.580306\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402222; batch adversarial loss: 0.518236\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365536; batch adversarial loss: 0.473465\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347453; batch adversarial loss: 0.678216\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387557; batch adversarial loss: 0.517912\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422478; batch adversarial loss: 0.552694\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379089; batch adversarial loss: 0.501904\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416560; batch adversarial loss: 0.560533\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361189; batch adversarial loss: 0.519539\n",
      "epoch 78; iter: 0; batch classifier loss: 0.463247; batch adversarial loss: 0.535432\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433261; batch adversarial loss: 0.525905\n",
      "epoch 80; iter: 0; batch classifier loss: 0.323357; batch adversarial loss: 0.653191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398650; batch adversarial loss: 0.563435\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411429; batch adversarial loss: 0.480581\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400048; batch adversarial loss: 0.455389\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372998; batch adversarial loss: 0.526401\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365130; batch adversarial loss: 0.571722\n",
      "epoch 86; iter: 0; batch classifier loss: 0.375410; batch adversarial loss: 0.490549\n",
      "epoch 87; iter: 0; batch classifier loss: 0.354264; batch adversarial loss: 0.580535\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416331; batch adversarial loss: 0.562120\n",
      "epoch 89; iter: 0; batch classifier loss: 0.352494; batch adversarial loss: 0.544896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.395503; batch adversarial loss: 0.526536\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402256; batch adversarial loss: 0.587530\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424917; batch adversarial loss: 0.624539\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375112; batch adversarial loss: 0.500737\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401516; batch adversarial loss: 0.519639\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371140; batch adversarial loss: 0.501681\n",
      "epoch 96; iter: 0; batch classifier loss: 0.508764; batch adversarial loss: 0.518183\n",
      "epoch 97; iter: 0; batch classifier loss: 0.288205; batch adversarial loss: 0.597846\n",
      "epoch 98; iter: 0; batch classifier loss: 0.292528; batch adversarial loss: 0.545218\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355163; batch adversarial loss: 0.536570\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429486; batch adversarial loss: 0.624225\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379103; batch adversarial loss: 0.598379\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323599; batch adversarial loss: 0.571270\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361726; batch adversarial loss: 0.527740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.437201; batch adversarial loss: 0.544415\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413193; batch adversarial loss: 0.641951\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443241; batch adversarial loss: 0.527159\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397232; batch adversarial loss: 0.571613\n",
      "epoch 108; iter: 0; batch classifier loss: 0.329337; batch adversarial loss: 0.597349\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342604; batch adversarial loss: 0.598192\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377858; batch adversarial loss: 0.588927\n",
      "epoch 111; iter: 0; batch classifier loss: 0.321469; batch adversarial loss: 0.562480\n",
      "epoch 112; iter: 0; batch classifier loss: 0.305078; batch adversarial loss: 0.527408\n",
      "epoch 113; iter: 0; batch classifier loss: 0.344317; batch adversarial loss: 0.509585\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329147; batch adversarial loss: 0.562554\n",
      "epoch 115; iter: 0; batch classifier loss: 0.308425; batch adversarial loss: 0.455979\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359577; batch adversarial loss: 0.500517\n",
      "epoch 117; iter: 0; batch classifier loss: 0.398814; batch adversarial loss: 0.580119\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393661; batch adversarial loss: 0.536141\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387975; batch adversarial loss: 0.580015\n",
      "epoch 120; iter: 0; batch classifier loss: 0.274405; batch adversarial loss: 0.615188\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319791; batch adversarial loss: 0.527212\n",
      "epoch 122; iter: 0; batch classifier loss: 0.448896; batch adversarial loss: 0.589377\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368614; batch adversarial loss: 0.588959\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371243; batch adversarial loss: 0.571301\n",
      "epoch 125; iter: 0; batch classifier loss: 0.399980; batch adversarial loss: 0.527033\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326566; batch adversarial loss: 0.518048\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376501; batch adversarial loss: 0.562522\n",
      "epoch 128; iter: 0; batch classifier loss: 0.384924; batch adversarial loss: 0.518270\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298806; batch adversarial loss: 0.607053\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348196; batch adversarial loss: 0.518402\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406781; batch adversarial loss: 0.597860\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325977; batch adversarial loss: 0.562826\n",
      "epoch 133; iter: 0; batch classifier loss: 0.403795; batch adversarial loss: 0.535789\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386650; batch adversarial loss: 0.535943\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363293; batch adversarial loss: 0.518415\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380169; batch adversarial loss: 0.526901\n",
      "epoch 137; iter: 0; batch classifier loss: 0.365503; batch adversarial loss: 0.615992\n",
      "epoch 138; iter: 0; batch classifier loss: 0.347593; batch adversarial loss: 0.473678\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316589; batch adversarial loss: 0.500261\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359480; batch adversarial loss: 0.553350\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345195; batch adversarial loss: 0.581019\n",
      "epoch 142; iter: 0; batch classifier loss: 0.400885; batch adversarial loss: 0.589028\n",
      "epoch 143; iter: 0; batch classifier loss: 0.312899; batch adversarial loss: 0.482495\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360563; batch adversarial loss: 0.517971\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351806; batch adversarial loss: 0.509134\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337663; batch adversarial loss: 0.527285\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317240; batch adversarial loss: 0.544313\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311978; batch adversarial loss: 0.633631\n",
      "epoch 149; iter: 0; batch classifier loss: 0.407065; batch adversarial loss: 0.544786\n",
      "epoch 150; iter: 0; batch classifier loss: 0.429057; batch adversarial loss: 0.580444\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336095; batch adversarial loss: 0.517828\n",
      "epoch 152; iter: 0; batch classifier loss: 0.311963; batch adversarial loss: 0.562282\n",
      "epoch 153; iter: 0; batch classifier loss: 0.277832; batch adversarial loss: 0.589009\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319127; batch adversarial loss: 0.509170\n",
      "epoch 155; iter: 0; batch classifier loss: 0.432531; batch adversarial loss: 0.580184\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351722; batch adversarial loss: 0.527498\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361537; batch adversarial loss: 0.641916\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318138; batch adversarial loss: 0.562529\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334911; batch adversarial loss: 0.590063\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320629; batch adversarial loss: 0.588517\n",
      "epoch 161; iter: 0; batch classifier loss: 0.327649; batch adversarial loss: 0.464948\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347252; batch adversarial loss: 0.553604\n",
      "epoch 163; iter: 0; batch classifier loss: 0.270169; batch adversarial loss: 0.571019\n",
      "epoch 164; iter: 0; batch classifier loss: 0.428138; batch adversarial loss: 0.491587\n",
      "epoch 165; iter: 0; batch classifier loss: 0.359438; batch adversarial loss: 0.624261\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334775; batch adversarial loss: 0.526723\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319916; batch adversarial loss: 0.536003\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392804; batch adversarial loss: 0.660312\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351834; batch adversarial loss: 0.500129\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339847; batch adversarial loss: 0.580161\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317527; batch adversarial loss: 0.615844\n",
      "epoch 172; iter: 0; batch classifier loss: 0.450308; batch adversarial loss: 0.615458\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321554; batch adversarial loss: 0.562611\n",
      "epoch 174; iter: 0; batch classifier loss: 0.338528; batch adversarial loss: 0.518291\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395153; batch adversarial loss: 0.562706\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320826; batch adversarial loss: 0.589474\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321263; batch adversarial loss: 0.580149\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387019; batch adversarial loss: 0.589302\n",
      "epoch 179; iter: 0; batch classifier loss: 0.441059; batch adversarial loss: 0.526771\n",
      "epoch 180; iter: 0; batch classifier loss: 0.256857; batch adversarial loss: 0.554254\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382852; batch adversarial loss: 0.571534\n",
      "epoch 182; iter: 0; batch classifier loss: 0.321568; batch adversarial loss: 0.553585\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315261; batch adversarial loss: 0.598154\n",
      "epoch 184; iter: 0; batch classifier loss: 0.263974; batch adversarial loss: 0.553279\n",
      "epoch 185; iter: 0; batch classifier loss: 0.294047; batch adversarial loss: 0.571574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.413022; batch adversarial loss: 0.526959\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314412; batch adversarial loss: 0.571297\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361052; batch adversarial loss: 0.562651\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332932; batch adversarial loss: 0.509624\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358152; batch adversarial loss: 0.544724\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351489; batch adversarial loss: 0.517798\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298267; batch adversarial loss: 0.562500\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341819; batch adversarial loss: 0.500634\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335791; batch adversarial loss: 0.588988\n",
      "epoch 195; iter: 0; batch classifier loss: 0.292203; batch adversarial loss: 0.571352\n",
      "epoch 196; iter: 0; batch classifier loss: 0.288866; batch adversarial loss: 0.526593\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375830; batch adversarial loss: 0.571124\n",
      "epoch 198; iter: 0; batch classifier loss: 0.308057; batch adversarial loss: 0.527051\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328111; batch adversarial loss: 0.500320\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673473; batch adversarial loss: 0.845687\n",
      "epoch 1; iter: 0; batch classifier loss: 0.706367; batch adversarial loss: 0.987764\n",
      "epoch 2; iter: 0; batch classifier loss: 0.740743; batch adversarial loss: 0.948562\n",
      "epoch 3; iter: 0; batch classifier loss: 0.791782; batch adversarial loss: 0.885860\n",
      "epoch 4; iter: 0; batch classifier loss: 0.680757; batch adversarial loss: 0.767129\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612453; batch adversarial loss: 0.753549\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590054; batch adversarial loss: 0.689134\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624843; batch adversarial loss: 0.677793\n",
      "epoch 8; iter: 0; batch classifier loss: 0.597759; batch adversarial loss: 0.615660\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493548; batch adversarial loss: 0.619403\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515795; batch adversarial loss: 0.629159\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543214; batch adversarial loss: 0.586216\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539727; batch adversarial loss: 0.602404\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543832; batch adversarial loss: 0.639160\n",
      "epoch 14; iter: 0; batch classifier loss: 0.599612; batch adversarial loss: 0.631895\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477192; batch adversarial loss: 0.633215\n",
      "epoch 16; iter: 0; batch classifier loss: 0.586894; batch adversarial loss: 0.570425\n",
      "epoch 17; iter: 0; batch classifier loss: 0.450253; batch adversarial loss: 0.591830\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515714; batch adversarial loss: 0.546226\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542701; batch adversarial loss: 0.573904\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492317; batch adversarial loss: 0.612292\n",
      "epoch 21; iter: 0; batch classifier loss: 0.433869; batch adversarial loss: 0.531088\n",
      "epoch 22; iter: 0; batch classifier loss: 0.418180; batch adversarial loss: 0.580616\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518223; batch adversarial loss: 0.569506\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454818; batch adversarial loss: 0.514220\n",
      "epoch 25; iter: 0; batch classifier loss: 0.404268; batch adversarial loss: 0.538472\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472606; batch adversarial loss: 0.590885\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446703; batch adversarial loss: 0.536522\n",
      "epoch 28; iter: 0; batch classifier loss: 0.546152; batch adversarial loss: 0.515480\n",
      "epoch 29; iter: 0; batch classifier loss: 0.401374; batch adversarial loss: 0.662325\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457517; batch adversarial loss: 0.539934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471849; batch adversarial loss: 0.578705\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456484; batch adversarial loss: 0.542304\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494673; batch adversarial loss: 0.552468\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472350; batch adversarial loss: 0.540273\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407455; batch adversarial loss: 0.556309\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438913; batch adversarial loss: 0.576507\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480948; batch adversarial loss: 0.501811\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483181; batch adversarial loss: 0.599288\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433753; batch adversarial loss: 0.547135\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445236; batch adversarial loss: 0.501636\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464573; batch adversarial loss: 0.546732\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451119; batch adversarial loss: 0.526320\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412368; batch adversarial loss: 0.528742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461497; batch adversarial loss: 0.560936\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405024; batch adversarial loss: 0.561886\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457002; batch adversarial loss: 0.552878\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398755; batch adversarial loss: 0.596019\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423718; batch adversarial loss: 0.495090\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471856; batch adversarial loss: 0.564124\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465551; batch adversarial loss: 0.623693\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466566; batch adversarial loss: 0.651782\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416825; batch adversarial loss: 0.520238\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439280; batch adversarial loss: 0.572923\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464124; batch adversarial loss: 0.509810\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393447; batch adversarial loss: 0.563880\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403731; batch adversarial loss: 0.508010\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403111; batch adversarial loss: 0.546573\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471627; batch adversarial loss: 0.525733\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404694; batch adversarial loss: 0.534842\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377295; batch adversarial loss: 0.500508\n",
      "epoch 61; iter: 0; batch classifier loss: 0.452003; batch adversarial loss: 0.535438\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462651; batch adversarial loss: 0.560863\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410464; batch adversarial loss: 0.572070\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441989; batch adversarial loss: 0.501825\n",
      "epoch 65; iter: 0; batch classifier loss: 0.351344; batch adversarial loss: 0.510922\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432878; batch adversarial loss: 0.587528\n",
      "epoch 67; iter: 0; batch classifier loss: 0.348506; batch adversarial loss: 0.518934\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389056; batch adversarial loss: 0.570808\n",
      "epoch 69; iter: 0; batch classifier loss: 0.337064; batch adversarial loss: 0.554427\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352862; batch adversarial loss: 0.510523\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412408; batch adversarial loss: 0.579782\n",
      "epoch 72; iter: 0; batch classifier loss: 0.330388; batch adversarial loss: 0.605318\n",
      "epoch 73; iter: 0; batch classifier loss: 0.341937; batch adversarial loss: 0.563378\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436396; batch adversarial loss: 0.614368\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424952; batch adversarial loss: 0.503198\n",
      "epoch 76; iter: 0; batch classifier loss: 0.334803; batch adversarial loss: 0.519129\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376780; batch adversarial loss: 0.510156\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437396; batch adversarial loss: 0.527033\n",
      "epoch 79; iter: 0; batch classifier loss: 0.352427; batch adversarial loss: 0.562562\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380143; batch adversarial loss: 0.553236\n",
      "epoch 81; iter: 0; batch classifier loss: 0.456673; batch adversarial loss: 0.612599\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359210; batch adversarial loss: 0.579122\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417416; batch adversarial loss: 0.571775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.427556; batch adversarial loss: 0.553565\n",
      "epoch 85; iter: 0; batch classifier loss: 0.412540; batch adversarial loss: 0.493188\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331414; batch adversarial loss: 0.588867\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421394; batch adversarial loss: 0.553844\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378911; batch adversarial loss: 0.587622\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384404; batch adversarial loss: 0.572189\n",
      "epoch 90; iter: 0; batch classifier loss: 0.421648; batch adversarial loss: 0.561942\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376747; batch adversarial loss: 0.579528\n",
      "epoch 92; iter: 0; batch classifier loss: 0.440158; batch adversarial loss: 0.537317\n",
      "epoch 93; iter: 0; batch classifier loss: 0.370885; batch adversarial loss: 0.605801\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391635; batch adversarial loss: 0.571211\n",
      "epoch 95; iter: 0; batch classifier loss: 0.351402; batch adversarial loss: 0.588998\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375649; batch adversarial loss: 0.535608\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440340; batch adversarial loss: 0.510597\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349440; batch adversarial loss: 0.450252\n",
      "epoch 99; iter: 0; batch classifier loss: 0.338159; batch adversarial loss: 0.571036\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374532; batch adversarial loss: 0.596286\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376085; batch adversarial loss: 0.631675\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394230; batch adversarial loss: 0.553144\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369172; batch adversarial loss: 0.587535\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399085; batch adversarial loss: 0.579148\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385470; batch adversarial loss: 0.563404\n",
      "epoch 106; iter: 0; batch classifier loss: 0.316815; batch adversarial loss: 0.493311\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402406; batch adversarial loss: 0.510108\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361374; batch adversarial loss: 0.562113\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372174; batch adversarial loss: 0.571043\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403062; batch adversarial loss: 0.604708\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361537; batch adversarial loss: 0.630629\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371947; batch adversarial loss: 0.553251\n",
      "epoch 113; iter: 0; batch classifier loss: 0.306019; batch adversarial loss: 0.561844\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383981; batch adversarial loss: 0.578937\n",
      "epoch 115; iter: 0; batch classifier loss: 0.376453; batch adversarial loss: 0.528331\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392021; batch adversarial loss: 0.632085\n",
      "epoch 117; iter: 0; batch classifier loss: 0.306965; batch adversarial loss: 0.580099\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399781; batch adversarial loss: 0.579883\n",
      "epoch 119; iter: 0; batch classifier loss: 0.416963; batch adversarial loss: 0.527854\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358661; batch adversarial loss: 0.563470\n",
      "epoch 121; iter: 0; batch classifier loss: 0.286826; batch adversarial loss: 0.493802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.327184; batch adversarial loss: 0.615693\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368573; batch adversarial loss: 0.528229\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401026; batch adversarial loss: 0.564214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375250; batch adversarial loss: 0.588049\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363156; batch adversarial loss: 0.518156\n",
      "epoch 127; iter: 0; batch classifier loss: 0.331548; batch adversarial loss: 0.632279\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373231; batch adversarial loss: 0.537133\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380173; batch adversarial loss: 0.569970\n",
      "epoch 130; iter: 0; batch classifier loss: 0.298207; batch adversarial loss: 0.544818\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360495; batch adversarial loss: 0.546005\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342322; batch adversarial loss: 0.475169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.373778; batch adversarial loss: 0.606025\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371229; batch adversarial loss: 0.511274\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369336; batch adversarial loss: 0.561052\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425311; batch adversarial loss: 0.570305\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385246; batch adversarial loss: 0.502068\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386470; batch adversarial loss: 0.560968\n",
      "epoch 139; iter: 0; batch classifier loss: 0.406651; batch adversarial loss: 0.475358\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376723; batch adversarial loss: 0.588142\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326006; batch adversarial loss: 0.528162\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347057; batch adversarial loss: 0.570490\n",
      "epoch 143; iter: 0; batch classifier loss: 0.336334; batch adversarial loss: 0.536270\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339900; batch adversarial loss: 0.595972\n",
      "epoch 145; iter: 0; batch classifier loss: 0.294681; batch adversarial loss: 0.605254\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336619; batch adversarial loss: 0.544149\n",
      "epoch 147; iter: 0; batch classifier loss: 0.295605; batch adversarial loss: 0.579403\n",
      "epoch 148; iter: 0; batch classifier loss: 0.402536; batch adversarial loss: 0.571166\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382740; batch adversarial loss: 0.606380\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391369; batch adversarial loss: 0.605959\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356636; batch adversarial loss: 0.502557\n",
      "epoch 152; iter: 0; batch classifier loss: 0.412291; batch adversarial loss: 0.604544\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342846; batch adversarial loss: 0.568742\n",
      "epoch 154; iter: 0; batch classifier loss: 0.367630; batch adversarial loss: 0.536558\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330414; batch adversarial loss: 0.502380\n",
      "epoch 156; iter: 0; batch classifier loss: 0.259516; batch adversarial loss: 0.588694\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350132; batch adversarial loss: 0.527849\n",
      "epoch 158; iter: 0; batch classifier loss: 0.405272; batch adversarial loss: 0.623989\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348486; batch adversarial loss: 0.632698\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373510; batch adversarial loss: 0.545134\n",
      "epoch 161; iter: 0; batch classifier loss: 0.442510; batch adversarial loss: 0.544065\n",
      "epoch 162; iter: 0; batch classifier loss: 0.324273; batch adversarial loss: 0.545513\n",
      "epoch 163; iter: 0; batch classifier loss: 0.372398; batch adversarial loss: 0.597943\n",
      "epoch 164; iter: 0; batch classifier loss: 0.382018; batch adversarial loss: 0.526990\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326520; batch adversarial loss: 0.598538\n",
      "epoch 166; iter: 0; batch classifier loss: 0.421196; batch adversarial loss: 0.622419\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353283; batch adversarial loss: 0.604884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340253; batch adversarial loss: 0.561673\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381234; batch adversarial loss: 0.545696\n",
      "epoch 170; iter: 0; batch classifier loss: 0.328892; batch adversarial loss: 0.546064\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362993; batch adversarial loss: 0.622819\n",
      "epoch 172; iter: 0; batch classifier loss: 0.229292; batch adversarial loss: 0.562734\n",
      "epoch 173; iter: 0; batch classifier loss: 0.454325; batch adversarial loss: 0.605197\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389260; batch adversarial loss: 0.605778\n",
      "epoch 175; iter: 0; batch classifier loss: 0.450967; batch adversarial loss: 0.578714\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395057; batch adversarial loss: 0.561292\n",
      "epoch 177; iter: 0; batch classifier loss: 0.381280; batch adversarial loss: 0.552660\n",
      "epoch 178; iter: 0; batch classifier loss: 0.377496; batch adversarial loss: 0.571232\n",
      "epoch 179; iter: 0; batch classifier loss: 0.444542; batch adversarial loss: 0.595644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.334878; batch adversarial loss: 0.552414\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374874; batch adversarial loss: 0.553573\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304548; batch adversarial loss: 0.578525\n",
      "epoch 183; iter: 0; batch classifier loss: 0.319541; batch adversarial loss: 0.587927\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382701; batch adversarial loss: 0.585035\n",
      "epoch 185; iter: 0; batch classifier loss: 0.368853; batch adversarial loss: 0.502889\n",
      "epoch 186; iter: 0; batch classifier loss: 0.295990; batch adversarial loss: 0.499462\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352939; batch adversarial loss: 0.545079\n",
      "epoch 188; iter: 0; batch classifier loss: 0.279625; batch adversarial loss: 0.576885\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266374; batch adversarial loss: 0.546639\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407989; batch adversarial loss: 0.500577\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367642; batch adversarial loss: 0.641314\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317855; batch adversarial loss: 0.465143\n",
      "epoch 193; iter: 0; batch classifier loss: 0.295814; batch adversarial loss: 0.491100\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377588; batch adversarial loss: 0.667752\n",
      "epoch 195; iter: 0; batch classifier loss: 0.403496; batch adversarial loss: 0.580304\n",
      "epoch 196; iter: 0; batch classifier loss: 0.262015; batch adversarial loss: 0.596187\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340321; batch adversarial loss: 0.569236\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370245; batch adversarial loss: 0.553675\n",
      "epoch 199; iter: 0; batch classifier loss: 0.344149; batch adversarial loss: 0.537438\n",
      "epoch 0; iter: 0; batch classifier loss: 0.835755; batch adversarial loss: 0.819608\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572670; batch adversarial loss: 0.715182\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595863; batch adversarial loss: 0.664757\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637243; batch adversarial loss: 0.662512\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559440; batch adversarial loss: 0.625420\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578770; batch adversarial loss: 0.646134\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523219; batch adversarial loss: 0.617460\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538497; batch adversarial loss: 0.625520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484450; batch adversarial loss: 0.592666\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548374; batch adversarial loss: 0.569811\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512661; batch adversarial loss: 0.529070\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507146; batch adversarial loss: 0.530475\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448526; batch adversarial loss: 0.557422\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496966; batch adversarial loss: 0.603173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573248; batch adversarial loss: 0.623470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452772; batch adversarial loss: 0.605361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539008; batch adversarial loss: 0.551650\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492727; batch adversarial loss: 0.564258\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508924; batch adversarial loss: 0.580491\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564939; batch adversarial loss: 0.589969\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491913; batch adversarial loss: 0.596936\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490112; batch adversarial loss: 0.505075\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501595; batch adversarial loss: 0.576061\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481955; batch adversarial loss: 0.581684\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527968; batch adversarial loss: 0.537769\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432463; batch adversarial loss: 0.576600\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499859; batch adversarial loss: 0.598405\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428101; batch adversarial loss: 0.550172\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507082; batch adversarial loss: 0.580582\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501234; batch adversarial loss: 0.454795\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485486; batch adversarial loss: 0.587590\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480859; batch adversarial loss: 0.554773\n",
      "epoch 32; iter: 0; batch classifier loss: 0.480598; batch adversarial loss: 0.587372\n",
      "epoch 33; iter: 0; batch classifier loss: 0.516289; batch adversarial loss: 0.570354\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350120; batch adversarial loss: 0.444305\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411896; batch adversarial loss: 0.546389\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441273; batch adversarial loss: 0.537487\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439049; batch adversarial loss: 0.553142\n",
      "epoch 38; iter: 0; batch classifier loss: 0.494587; batch adversarial loss: 0.518642\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433245; batch adversarial loss: 0.562078\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524879; batch adversarial loss: 0.570643\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401020; batch adversarial loss: 0.553469\n",
      "epoch 42; iter: 0; batch classifier loss: 0.519333; batch adversarial loss: 0.580464\n",
      "epoch 43; iter: 0; batch classifier loss: 0.379132; batch adversarial loss: 0.571002\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461871; batch adversarial loss: 0.570571\n",
      "epoch 45; iter: 0; batch classifier loss: 0.391174; batch adversarial loss: 0.544070\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422531; batch adversarial loss: 0.515994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472597; batch adversarial loss: 0.580210\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412557; batch adversarial loss: 0.543385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371484; batch adversarial loss: 0.544892\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400311; batch adversarial loss: 0.581661\n",
      "epoch 51; iter: 0; batch classifier loss: 0.536137; batch adversarial loss: 0.632734\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390961; batch adversarial loss: 0.579789\n",
      "epoch 53; iter: 0; batch classifier loss: 0.493367; batch adversarial loss: 0.552707\n",
      "epoch 54; iter: 0; batch classifier loss: 0.301012; batch adversarial loss: 0.657220\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421746; batch adversarial loss: 0.543680\n",
      "epoch 56; iter: 0; batch classifier loss: 0.353365; batch adversarial loss: 0.527437\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402321; batch adversarial loss: 0.491447\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398238; batch adversarial loss: 0.605370\n",
      "epoch 59; iter: 0; batch classifier loss: 0.367530; batch adversarial loss: 0.553801\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452521; batch adversarial loss: 0.605396\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404110; batch adversarial loss: 0.561864\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436220; batch adversarial loss: 0.561252\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379729; batch adversarial loss: 0.568137\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359668; batch adversarial loss: 0.552239\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437734; batch adversarial loss: 0.563048\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447858; batch adversarial loss: 0.579374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388338; batch adversarial loss: 0.598383\n",
      "epoch 68; iter: 0; batch classifier loss: 0.316459; batch adversarial loss: 0.634288\n",
      "epoch 69; iter: 0; batch classifier loss: 0.469153; batch adversarial loss: 0.598310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.344783; batch adversarial loss: 0.545531\n",
      "epoch 71; iter: 0; batch classifier loss: 0.442961; batch adversarial loss: 0.562971\n",
      "epoch 72; iter: 0; batch classifier loss: 0.491574; batch adversarial loss: 0.553499\n",
      "epoch 73; iter: 0; batch classifier loss: 0.416420; batch adversarial loss: 0.562821\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439517; batch adversarial loss: 0.499344\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391646; batch adversarial loss: 0.607915\n",
      "epoch 76; iter: 0; batch classifier loss: 0.537859; batch adversarial loss: 0.598730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.418230; batch adversarial loss: 0.589661\n",
      "epoch 78; iter: 0; batch classifier loss: 0.432635; batch adversarial loss: 0.535589\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404819; batch adversarial loss: 0.553568\n",
      "epoch 80; iter: 0; batch classifier loss: 0.433337; batch adversarial loss: 0.500123\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392558; batch adversarial loss: 0.598679\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397852; batch adversarial loss: 0.589496\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345479; batch adversarial loss: 0.606532\n",
      "epoch 84; iter: 0; batch classifier loss: 0.474326; batch adversarial loss: 0.607270\n",
      "epoch 85; iter: 0; batch classifier loss: 0.473985; batch adversarial loss: 0.544151\n",
      "epoch 86; iter: 0; batch classifier loss: 0.464760; batch adversarial loss: 0.526550\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380420; batch adversarial loss: 0.536243\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431441; batch adversarial loss: 0.526391\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389149; batch adversarial loss: 0.526965\n",
      "epoch 90; iter: 0; batch classifier loss: 0.459096; batch adversarial loss: 0.544944\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399411; batch adversarial loss: 0.580323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372764; batch adversarial loss: 0.535913\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438821; batch adversarial loss: 0.553975\n",
      "epoch 94; iter: 0; batch classifier loss: 0.389594; batch adversarial loss: 0.606698\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416350; batch adversarial loss: 0.500303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419297; batch adversarial loss: 0.572281\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344604; batch adversarial loss: 0.615893\n",
      "epoch 98; iter: 0; batch classifier loss: 0.456837; batch adversarial loss: 0.588943\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375803; batch adversarial loss: 0.509215\n",
      "epoch 100; iter: 0; batch classifier loss: 0.317768; batch adversarial loss: 0.589972\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399855; batch adversarial loss: 0.552876\n",
      "epoch 102; iter: 0; batch classifier loss: 0.408934; batch adversarial loss: 0.499572\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440440; batch adversarial loss: 0.554058\n",
      "epoch 104; iter: 0; batch classifier loss: 0.394113; batch adversarial loss: 0.508725\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.562670\n",
      "epoch 106; iter: 0; batch classifier loss: 0.439290; batch adversarial loss: 0.500095\n",
      "epoch 107; iter: 0; batch classifier loss: 0.376505; batch adversarial loss: 0.571903\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375717; batch adversarial loss: 0.527211\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371788; batch adversarial loss: 0.456312\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383792; batch adversarial loss: 0.607311\n",
      "epoch 111; iter: 0; batch classifier loss: 0.311009; batch adversarial loss: 0.543950\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378728; batch adversarial loss: 0.554355\n",
      "epoch 113; iter: 0; batch classifier loss: 0.367677; batch adversarial loss: 0.544955\n",
      "epoch 114; iter: 0; batch classifier loss: 0.442627; batch adversarial loss: 0.526716\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377337; batch adversarial loss: 0.552824\n",
      "epoch 116; iter: 0; batch classifier loss: 0.395695; batch adversarial loss: 0.501027\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379977; batch adversarial loss: 0.482157\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378522; batch adversarial loss: 0.544727\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339719; batch adversarial loss: 0.545438\n",
      "epoch 120; iter: 0; batch classifier loss: 0.296021; batch adversarial loss: 0.608075\n",
      "epoch 121; iter: 0; batch classifier loss: 0.372475; batch adversarial loss: 0.545282\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346515; batch adversarial loss: 0.544882\n",
      "epoch 123; iter: 0; batch classifier loss: 0.452326; batch adversarial loss: 0.572323\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386184; batch adversarial loss: 0.678018\n",
      "epoch 125; iter: 0; batch classifier loss: 0.454554; batch adversarial loss: 0.615218\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367677; batch adversarial loss: 0.508810\n",
      "epoch 127; iter: 0; batch classifier loss: 0.324985; batch adversarial loss: 0.580960\n",
      "epoch 128; iter: 0; batch classifier loss: 0.429313; batch adversarial loss: 0.500214\n",
      "epoch 129; iter: 0; batch classifier loss: 0.301527; batch adversarial loss: 0.536003\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339724; batch adversarial loss: 0.545346\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366574; batch adversarial loss: 0.526521\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346500; batch adversarial loss: 0.517190\n",
      "epoch 133; iter: 0; batch classifier loss: 0.305188; batch adversarial loss: 0.562627\n",
      "epoch 134; iter: 0; batch classifier loss: 0.297384; batch adversarial loss: 0.552948\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372522; batch adversarial loss: 0.562185\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341110; batch adversarial loss: 0.544173\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385858; batch adversarial loss: 0.588942\n",
      "epoch 138; iter: 0; batch classifier loss: 0.452799; batch adversarial loss: 0.490257\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401281; batch adversarial loss: 0.534811\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377205; batch adversarial loss: 0.651071\n",
      "epoch 141; iter: 0; batch classifier loss: 0.413314; batch adversarial loss: 0.518399\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324641; batch adversarial loss: 0.518359\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371918; batch adversarial loss: 0.553494\n",
      "epoch 144; iter: 0; batch classifier loss: 0.364526; batch adversarial loss: 0.580447\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409165; batch adversarial loss: 0.597901\n",
      "epoch 146; iter: 0; batch classifier loss: 0.419236; batch adversarial loss: 0.536296\n",
      "epoch 147; iter: 0; batch classifier loss: 0.306887; batch adversarial loss: 0.526676\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338679; batch adversarial loss: 0.527299\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333508; batch adversarial loss: 0.580072\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339375; batch adversarial loss: 0.535931\n",
      "epoch 151; iter: 0; batch classifier loss: 0.280209; batch adversarial loss: 0.545295\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333540; batch adversarial loss: 0.535570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.421308; batch adversarial loss: 0.580655\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337422; batch adversarial loss: 0.508540\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344363; batch adversarial loss: 0.553174\n",
      "epoch 156; iter: 0; batch classifier loss: 0.365181; batch adversarial loss: 0.552548\n",
      "epoch 157; iter: 0; batch classifier loss: 0.421898; batch adversarial loss: 0.642408\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338457; batch adversarial loss: 0.624667\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333648; batch adversarial loss: 0.536053\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345456; batch adversarial loss: 0.571161\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376753; batch adversarial loss: 0.607660\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370294; batch adversarial loss: 0.606794\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345122; batch adversarial loss: 0.588834\n",
      "epoch 164; iter: 0; batch classifier loss: 0.359814; batch adversarial loss: 0.535799\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330098; batch adversarial loss: 0.598005\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361399; batch adversarial loss: 0.580006\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363456; batch adversarial loss: 0.588644\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341170; batch adversarial loss: 0.500066\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362381; batch adversarial loss: 0.508926\n",
      "epoch 170; iter: 0; batch classifier loss: 0.350550; batch adversarial loss: 0.508980\n",
      "epoch 171; iter: 0; batch classifier loss: 0.393864; batch adversarial loss: 0.507551\n",
      "epoch 172; iter: 0; batch classifier loss: 0.339041; batch adversarial loss: 0.598025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.329257; batch adversarial loss: 0.526305\n",
      "epoch 174; iter: 0; batch classifier loss: 0.320698; batch adversarial loss: 0.536770\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332723; batch adversarial loss: 0.536232\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366235; batch adversarial loss: 0.563047\n",
      "epoch 177; iter: 0; batch classifier loss: 0.341065; batch adversarial loss: 0.554268\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364426; batch adversarial loss: 0.499451\n",
      "epoch 179; iter: 0; batch classifier loss: 0.264204; batch adversarial loss: 0.642497\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395219; batch adversarial loss: 0.562690\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362021; batch adversarial loss: 0.544489\n",
      "epoch 182; iter: 0; batch classifier loss: 0.288685; batch adversarial loss: 0.518283\n",
      "epoch 183; iter: 0; batch classifier loss: 0.474867; batch adversarial loss: 0.571940\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366029; batch adversarial loss: 0.598729\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390212; batch adversarial loss: 0.562327\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308645; batch adversarial loss: 0.545122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.283782; batch adversarial loss: 0.554092\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423877; batch adversarial loss: 0.500947\n",
      "epoch 189; iter: 0; batch classifier loss: 0.293183; batch adversarial loss: 0.561802\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327642; batch adversarial loss: 0.518115\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335183; batch adversarial loss: 0.517657\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347239; batch adversarial loss: 0.616470\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350521; batch adversarial loss: 0.507857\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308347; batch adversarial loss: 0.607524\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357337; batch adversarial loss: 0.499979\n",
      "epoch 196; iter: 0; batch classifier loss: 0.264779; batch adversarial loss: 0.562735\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353405; batch adversarial loss: 0.562172\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375790; batch adversarial loss: 0.464904\n",
      "epoch 199; iter: 0; batch classifier loss: 0.468432; batch adversarial loss: 0.616195\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689798; batch adversarial loss: 0.702232\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602968; batch adversarial loss: 0.669322\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583125; batch adversarial loss: 0.644885\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586941; batch adversarial loss: 0.634933\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544876; batch adversarial loss: 0.598454\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570608; batch adversarial loss: 0.612017\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494518; batch adversarial loss: 0.602000\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531989; batch adversarial loss: 0.634153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547164; batch adversarial loss: 0.596556\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511036; batch adversarial loss: 0.592763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529208; batch adversarial loss: 0.526706\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540655; batch adversarial loss: 0.546687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.471789; batch adversarial loss: 0.611561\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540942; batch adversarial loss: 0.670847\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479326; batch adversarial loss: 0.553064\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485109; batch adversarial loss: 0.502710\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532381; batch adversarial loss: 0.556259\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525575; batch adversarial loss: 0.608682\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478178; batch adversarial loss: 0.566493\n",
      "epoch 19; iter: 0; batch classifier loss: 0.453868; batch adversarial loss: 0.586299\n",
      "epoch 20; iter: 0; batch classifier loss: 0.439188; batch adversarial loss: 0.562461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527373; batch adversarial loss: 0.586795\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496422; batch adversarial loss: 0.558374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483090; batch adversarial loss: 0.572630\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433939; batch adversarial loss: 0.528445\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496063; batch adversarial loss: 0.566405\n",
      "epoch 26; iter: 0; batch classifier loss: 0.541505; batch adversarial loss: 0.568960\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495474; batch adversarial loss: 0.617652\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404687; batch adversarial loss: 0.579358\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474136; batch adversarial loss: 0.523696\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488609; batch adversarial loss: 0.539898\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461659; batch adversarial loss: 0.613026\n",
      "epoch 32; iter: 0; batch classifier loss: 0.514659; batch adversarial loss: 0.587628\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476613; batch adversarial loss: 0.541768\n",
      "epoch 34; iter: 0; batch classifier loss: 0.521317; batch adversarial loss: 0.595637\n",
      "epoch 35; iter: 0; batch classifier loss: 0.359208; batch adversarial loss: 0.529083\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465834; batch adversarial loss: 0.519214\n",
      "epoch 37; iter: 0; batch classifier loss: 0.528340; batch adversarial loss: 0.535418\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443966; batch adversarial loss: 0.624725\n",
      "epoch 39; iter: 0; batch classifier loss: 0.556610; batch adversarial loss: 0.566438\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424292; batch adversarial loss: 0.565065\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453013; batch adversarial loss: 0.478287\n",
      "epoch 42; iter: 0; batch classifier loss: 0.514516; batch adversarial loss: 0.503125\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438458; batch adversarial loss: 0.539909\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501770; batch adversarial loss: 0.538058\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463239; batch adversarial loss: 0.501926\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433981; batch adversarial loss: 0.597039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453945; batch adversarial loss: 0.508932\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416557; batch adversarial loss: 0.562658\n",
      "epoch 49; iter: 0; batch classifier loss: 0.493907; batch adversarial loss: 0.516706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408323; batch adversarial loss: 0.472810\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423246; batch adversarial loss: 0.617790\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410822; batch adversarial loss: 0.552270\n",
      "epoch 53; iter: 0; batch classifier loss: 0.457312; batch adversarial loss: 0.438380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434503; batch adversarial loss: 0.489805\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429315; batch adversarial loss: 0.686585\n",
      "epoch 56; iter: 0; batch classifier loss: 0.498411; batch adversarial loss: 0.600781\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426036; batch adversarial loss: 0.553630\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437861; batch adversarial loss: 0.547891\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464208; batch adversarial loss: 0.537525\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382936; batch adversarial loss: 0.547664\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407365; batch adversarial loss: 0.562661\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405666; batch adversarial loss: 0.555276\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395025; batch adversarial loss: 0.553144\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400630; batch adversarial loss: 0.557824\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426703; batch adversarial loss: 0.630656\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429356; batch adversarial loss: 0.527309\n",
      "epoch 67; iter: 0; batch classifier loss: 0.462594; batch adversarial loss: 0.544479\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406200; batch adversarial loss: 0.586448\n",
      "epoch 69; iter: 0; batch classifier loss: 0.385637; batch adversarial loss: 0.567541\n",
      "epoch 70; iter: 0; batch classifier loss: 0.531127; batch adversarial loss: 0.524460\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451974; batch adversarial loss: 0.581862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.464457; batch adversarial loss: 0.537645\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390442; batch adversarial loss: 0.571126\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452370; batch adversarial loss: 0.539700\n",
      "epoch 75; iter: 0; batch classifier loss: 0.446334; batch adversarial loss: 0.597408\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388478; batch adversarial loss: 0.561154\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385158; batch adversarial loss: 0.454004\n",
      "epoch 78; iter: 0; batch classifier loss: 0.329332; batch adversarial loss: 0.547363\n",
      "epoch 79; iter: 0; batch classifier loss: 0.483419; batch adversarial loss: 0.581789\n",
      "epoch 80; iter: 0; batch classifier loss: 0.543050; batch adversarial loss: 0.547317\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403309; batch adversarial loss: 0.486968\n",
      "epoch 82; iter: 0; batch classifier loss: 0.360944; batch adversarial loss: 0.543615\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416921; batch adversarial loss: 0.636853\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371725; batch adversarial loss: 0.561787\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390626; batch adversarial loss: 0.514043\n",
      "epoch 86; iter: 0; batch classifier loss: 0.471629; batch adversarial loss: 0.535608\n",
      "epoch 87; iter: 0; batch classifier loss: 0.354643; batch adversarial loss: 0.509052\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423390; batch adversarial loss: 0.560022\n",
      "epoch 89; iter: 0; batch classifier loss: 0.446455; batch adversarial loss: 0.549752\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434781; batch adversarial loss: 0.525936\n",
      "epoch 91; iter: 0; batch classifier loss: 0.430463; batch adversarial loss: 0.580584\n",
      "epoch 92; iter: 0; batch classifier loss: 0.343267; batch adversarial loss: 0.534377\n",
      "epoch 93; iter: 0; batch classifier loss: 0.434114; batch adversarial loss: 0.606250\n",
      "epoch 94; iter: 0; batch classifier loss: 0.451687; batch adversarial loss: 0.506147\n",
      "epoch 95; iter: 0; batch classifier loss: 0.447489; batch adversarial loss: 0.533341\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364991; batch adversarial loss: 0.483831\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388734; batch adversarial loss: 0.461316\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403342; batch adversarial loss: 0.535044\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410952; batch adversarial loss: 0.552479\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418654; batch adversarial loss: 0.491896\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421951; batch adversarial loss: 0.563238\n",
      "epoch 102; iter: 0; batch classifier loss: 0.429809; batch adversarial loss: 0.498362\n",
      "epoch 103; iter: 0; batch classifier loss: 0.430122; batch adversarial loss: 0.570362\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421534; batch adversarial loss: 0.541093\n",
      "epoch 105; iter: 0; batch classifier loss: 0.485953; batch adversarial loss: 0.587709\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.567377\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361493; batch adversarial loss: 0.623735\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405320; batch adversarial loss: 0.551943\n",
      "epoch 109; iter: 0; batch classifier loss: 0.460901; batch adversarial loss: 0.626877\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370225; batch adversarial loss: 0.536947\n",
      "epoch 111; iter: 0; batch classifier loss: 0.306775; batch adversarial loss: 0.607108\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347606; batch adversarial loss: 0.526659\n",
      "epoch 113; iter: 0; batch classifier loss: 0.455635; batch adversarial loss: 0.488487\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377144; batch adversarial loss: 0.543653\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372276; batch adversarial loss: 0.467445\n",
      "epoch 116; iter: 0; batch classifier loss: 0.444257; batch adversarial loss: 0.615927\n",
      "epoch 117; iter: 0; batch classifier loss: 0.312818; batch adversarial loss: 0.595447\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393179; batch adversarial loss: 0.643157\n",
      "epoch 119; iter: 0; batch classifier loss: 0.419373; batch adversarial loss: 0.528656\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399663; batch adversarial loss: 0.532293\n",
      "epoch 121; iter: 0; batch classifier loss: 0.399842; batch adversarial loss: 0.598162\n",
      "epoch 122; iter: 0; batch classifier loss: 0.442193; batch adversarial loss: 0.570682\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394082; batch adversarial loss: 0.549362\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390250; batch adversarial loss: 0.528151\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343544; batch adversarial loss: 0.535691\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360894; batch adversarial loss: 0.588084\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386964; batch adversarial loss: 0.508430\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387881; batch adversarial loss: 0.468205\n",
      "epoch 129; iter: 0; batch classifier loss: 0.422867; batch adversarial loss: 0.489612\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395555; batch adversarial loss: 0.547112\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373993; batch adversarial loss: 0.609045\n",
      "epoch 132; iter: 0; batch classifier loss: 0.302675; batch adversarial loss: 0.515995\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393934; batch adversarial loss: 0.595632\n",
      "epoch 134; iter: 0; batch classifier loss: 0.366513; batch adversarial loss: 0.568442\n",
      "epoch 135; iter: 0; batch classifier loss: 0.355001; batch adversarial loss: 0.632513\n",
      "epoch 136; iter: 0; batch classifier loss: 0.447538; batch adversarial loss: 0.581543\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358434; batch adversarial loss: 0.596336\n",
      "epoch 138; iter: 0; batch classifier loss: 0.400278; batch adversarial loss: 0.546104\n",
      "epoch 139; iter: 0; batch classifier loss: 0.413969; batch adversarial loss: 0.479856\n",
      "epoch 140; iter: 0; batch classifier loss: 0.468261; batch adversarial loss: 0.538222\n",
      "epoch 141; iter: 0; batch classifier loss: 0.467952; batch adversarial loss: 0.534036\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397619; batch adversarial loss: 0.538653\n",
      "epoch 143; iter: 0; batch classifier loss: 0.287802; batch adversarial loss: 0.529649\n",
      "epoch 144; iter: 0; batch classifier loss: 0.403304; batch adversarial loss: 0.626029\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356541; batch adversarial loss: 0.515260\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389746; batch adversarial loss: 0.483056\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410013; batch adversarial loss: 0.502353\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389639; batch adversarial loss: 0.509607\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331322; batch adversarial loss: 0.567815\n",
      "epoch 150; iter: 0; batch classifier loss: 0.398676; batch adversarial loss: 0.562708\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367074; batch adversarial loss: 0.518685\n",
      "epoch 152; iter: 0; batch classifier loss: 0.434902; batch adversarial loss: 0.538393\n",
      "epoch 153; iter: 0; batch classifier loss: 0.441530; batch adversarial loss: 0.583894\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395932; batch adversarial loss: 0.554809\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370496; batch adversarial loss: 0.483847\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380969; batch adversarial loss: 0.551979\n",
      "epoch 157; iter: 0; batch classifier loss: 0.388050; batch adversarial loss: 0.618688\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344065; batch adversarial loss: 0.625552\n",
      "epoch 159; iter: 0; batch classifier loss: 0.401690; batch adversarial loss: 0.550380\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398125; batch adversarial loss: 0.582163\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387481; batch adversarial loss: 0.525037\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409280; batch adversarial loss: 0.577136\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343955; batch adversarial loss: 0.573935\n",
      "epoch 164; iter: 0; batch classifier loss: 0.329213; batch adversarial loss: 0.525488\n",
      "epoch 165; iter: 0; batch classifier loss: 0.404317; batch adversarial loss: 0.526641\n",
      "epoch 166; iter: 0; batch classifier loss: 0.392153; batch adversarial loss: 0.555538\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353624; batch adversarial loss: 0.617233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.387101; batch adversarial loss: 0.629830\n",
      "epoch 169; iter: 0; batch classifier loss: 0.463219; batch adversarial loss: 0.550874\n",
      "epoch 170; iter: 0; batch classifier loss: 0.489908; batch adversarial loss: 0.527667\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394611; batch adversarial loss: 0.583916\n",
      "epoch 172; iter: 0; batch classifier loss: 0.473139; batch adversarial loss: 0.614893\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329448; batch adversarial loss: 0.528523\n",
      "epoch 174; iter: 0; batch classifier loss: 0.474395; batch adversarial loss: 0.501799\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308243; batch adversarial loss: 0.542312\n",
      "epoch 176; iter: 0; batch classifier loss: 0.311981; batch adversarial loss: 0.536471\n",
      "epoch 177; iter: 0; batch classifier loss: 0.400922; batch adversarial loss: 0.553377\n",
      "epoch 178; iter: 0; batch classifier loss: 0.439441; batch adversarial loss: 0.541757\n",
      "epoch 179; iter: 0; batch classifier loss: 0.418258; batch adversarial loss: 0.535822\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366771; batch adversarial loss: 0.587807\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344794; batch adversarial loss: 0.562072\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375815; batch adversarial loss: 0.447407\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385657; batch adversarial loss: 0.579327\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356174; batch adversarial loss: 0.490260\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355256; batch adversarial loss: 0.560578\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390003; batch adversarial loss: 0.537518\n",
      "epoch 187; iter: 0; batch classifier loss: 0.261822; batch adversarial loss: 0.506616\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368270; batch adversarial loss: 0.607868\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348949; batch adversarial loss: 0.445776\n",
      "epoch 190; iter: 0; batch classifier loss: 0.370605; batch adversarial loss: 0.510613\n",
      "epoch 191; iter: 0; batch classifier loss: 0.311586; batch adversarial loss: 0.518974\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373980; batch adversarial loss: 0.556830\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389066; batch adversarial loss: 0.526715\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315384; batch adversarial loss: 0.564259\n",
      "epoch 195; iter: 0; batch classifier loss: 0.355253; batch adversarial loss: 0.579919\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355699; batch adversarial loss: 0.547438\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354251; batch adversarial loss: 0.525779\n",
      "epoch 198; iter: 0; batch classifier loss: 0.425825; batch adversarial loss: 0.577629\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340754; batch adversarial loss: 0.530911\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695766; batch adversarial loss: 0.966386\n",
      "epoch 1; iter: 0; batch classifier loss: 0.900206; batch adversarial loss: 1.164014\n",
      "epoch 2; iter: 0; batch classifier loss: 1.018195; batch adversarial loss: 1.170766\n",
      "epoch 3; iter: 0; batch classifier loss: 1.185643; batch adversarial loss: 1.070694\n",
      "epoch 4; iter: 0; batch classifier loss: 1.125498; batch adversarial loss: 1.001623\n",
      "epoch 5; iter: 0; batch classifier loss: 1.167783; batch adversarial loss: 0.915274\n",
      "epoch 6; iter: 0; batch classifier loss: 1.260492; batch adversarial loss: 0.851250\n",
      "epoch 7; iter: 0; batch classifier loss: 1.292556; batch adversarial loss: 0.794388\n",
      "epoch 8; iter: 0; batch classifier loss: 1.170942; batch adversarial loss: 0.725794\n",
      "epoch 9; iter: 0; batch classifier loss: 0.977718; batch adversarial loss: 0.689362\n",
      "epoch 10; iter: 0; batch classifier loss: 0.959447; batch adversarial loss: 0.650320\n",
      "epoch 11; iter: 0; batch classifier loss: 0.943734; batch adversarial loss: 0.626646\n",
      "epoch 12; iter: 0; batch classifier loss: 0.968219; batch adversarial loss: 0.638512\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567094; batch adversarial loss: 0.597352\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530129; batch adversarial loss: 0.595795\n",
      "epoch 15; iter: 0; batch classifier loss: 0.557760; batch adversarial loss: 0.548638\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472504; batch adversarial loss: 0.552538\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507086; batch adversarial loss: 0.592149\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522404; batch adversarial loss: 0.572345\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531191; batch adversarial loss: 0.588256\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461395; batch adversarial loss: 0.547612\n",
      "epoch 21; iter: 0; batch classifier loss: 0.506099; batch adversarial loss: 0.578153\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525918; batch adversarial loss: 0.614011\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523151; batch adversarial loss: 0.531052\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436279; batch adversarial loss: 0.540666\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420081; batch adversarial loss: 0.561990\n",
      "epoch 26; iter: 0; batch classifier loss: 0.525636; batch adversarial loss: 0.519814\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520804; batch adversarial loss: 0.553660\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478529; batch adversarial loss: 0.530194\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492985; batch adversarial loss: 0.548926\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418596; batch adversarial loss: 0.482955\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499145; batch adversarial loss: 0.540973\n",
      "epoch 32; iter: 0; batch classifier loss: 0.590996; batch adversarial loss: 0.592019\n",
      "epoch 33; iter: 0; batch classifier loss: 0.552506; batch adversarial loss: 0.530714\n",
      "epoch 34; iter: 0; batch classifier loss: 0.555841; batch adversarial loss: 0.507178\n",
      "epoch 35; iter: 0; batch classifier loss: 0.525028; batch adversarial loss: 0.581377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519998; batch adversarial loss: 0.552382\n",
      "epoch 37; iter: 0; batch classifier loss: 0.525879; batch adversarial loss: 0.491661\n",
      "epoch 38; iter: 0; batch classifier loss: 0.525425; batch adversarial loss: 0.542434\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485141; batch adversarial loss: 0.559665\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403512; batch adversarial loss: 0.458988\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384696; batch adversarial loss: 0.541853\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414220; batch adversarial loss: 0.479603\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431232; batch adversarial loss: 0.572880\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463686; batch adversarial loss: 0.611899\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458264; batch adversarial loss: 0.605650\n",
      "epoch 46; iter: 0; batch classifier loss: 0.435402; batch adversarial loss: 0.572181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.508661; batch adversarial loss: 0.476781\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495289; batch adversarial loss: 0.607788\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460448; batch adversarial loss: 0.470757\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431852; batch adversarial loss: 0.612742\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446588; batch adversarial loss: 0.518627\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448871; batch adversarial loss: 0.525802\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379103; batch adversarial loss: 0.546322\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433442; batch adversarial loss: 0.502638\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409675; batch adversarial loss: 0.482675\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449476; batch adversarial loss: 0.610610\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407498; batch adversarial loss: 0.520454\n",
      "epoch 58; iter: 0; batch classifier loss: 0.381750; batch adversarial loss: 0.558678\n",
      "epoch 59; iter: 0; batch classifier loss: 0.508687; batch adversarial loss: 0.529093\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420830; batch adversarial loss: 0.503978\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466204; batch adversarial loss: 0.584920\n",
      "epoch 62; iter: 0; batch classifier loss: 0.485923; batch adversarial loss: 0.607578\n",
      "epoch 63; iter: 0; batch classifier loss: 0.445779; batch adversarial loss: 0.613738\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423133; batch adversarial loss: 0.527137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.431375; batch adversarial loss: 0.623320\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384598; batch adversarial loss: 0.559136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.489486; batch adversarial loss: 0.553242\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342015; batch adversarial loss: 0.587657\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366984; batch adversarial loss: 0.515154\n",
      "epoch 70; iter: 0; batch classifier loss: 0.320055; batch adversarial loss: 0.524443\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388277; batch adversarial loss: 0.586427\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383407; batch adversarial loss: 0.504477\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440350; batch adversarial loss: 0.555353\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424349; batch adversarial loss: 0.546474\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388181; batch adversarial loss: 0.510822\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375695; batch adversarial loss: 0.618744\n",
      "epoch 77; iter: 0; batch classifier loss: 0.357939; batch adversarial loss: 0.564842\n",
      "epoch 78; iter: 0; batch classifier loss: 0.422355; batch adversarial loss: 0.566924\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356517; batch adversarial loss: 0.535555\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400976; batch adversarial loss: 0.562208\n",
      "epoch 81; iter: 0; batch classifier loss: 0.455531; batch adversarial loss: 0.579806\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365730; batch adversarial loss: 0.560750\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425699; batch adversarial loss: 0.560929\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393860; batch adversarial loss: 0.455815\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377125; batch adversarial loss: 0.592355\n",
      "epoch 86; iter: 0; batch classifier loss: 0.302232; batch adversarial loss: 0.553064\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375203; batch adversarial loss: 0.497807\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386122; batch adversarial loss: 0.543950\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378530; batch adversarial loss: 0.569597\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428123; batch adversarial loss: 0.599336\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354583; batch adversarial loss: 0.554123\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405572; batch adversarial loss: 0.529350\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399476; batch adversarial loss: 0.518823\n",
      "epoch 94; iter: 0; batch classifier loss: 0.340622; batch adversarial loss: 0.616486\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359396; batch adversarial loss: 0.578644\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370181; batch adversarial loss: 0.463647\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389997; batch adversarial loss: 0.552145\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356717; batch adversarial loss: 0.500995\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434645; batch adversarial loss: 0.527249\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360810; batch adversarial loss: 0.535024\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367217; batch adversarial loss: 0.533367\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426498; batch adversarial loss: 0.565443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.298926; batch adversarial loss: 0.580145\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415505; batch adversarial loss: 0.600505\n",
      "epoch 105; iter: 0; batch classifier loss: 0.315268; batch adversarial loss: 0.544059\n",
      "epoch 106; iter: 0; batch classifier loss: 0.321135; batch adversarial loss: 0.534793\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355384; batch adversarial loss: 0.488786\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413644; batch adversarial loss: 0.600302\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342741; batch adversarial loss: 0.606944\n",
      "epoch 110; iter: 0; batch classifier loss: 0.432019; batch adversarial loss: 0.499938\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398428; batch adversarial loss: 0.535306\n",
      "epoch 112; iter: 0; batch classifier loss: 0.310356; batch adversarial loss: 0.481587\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387809; batch adversarial loss: 0.572853\n",
      "epoch 114; iter: 0; batch classifier loss: 0.295605; batch adversarial loss: 0.600362\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339171; batch adversarial loss: 0.534743\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379673; batch adversarial loss: 0.563718\n",
      "epoch 117; iter: 0; batch classifier loss: 0.331126; batch adversarial loss: 0.609904\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381800; batch adversarial loss: 0.591233\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356404; batch adversarial loss: 0.463128\n",
      "epoch 120; iter: 0; batch classifier loss: 0.310077; batch adversarial loss: 0.618241\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307059; batch adversarial loss: 0.491922\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350225; batch adversarial loss: 0.587866\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334433; batch adversarial loss: 0.537228\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352682; batch adversarial loss: 0.561572\n",
      "epoch 125; iter: 0; batch classifier loss: 0.321388; batch adversarial loss: 0.546609\n",
      "epoch 126; iter: 0; batch classifier loss: 0.318297; batch adversarial loss: 0.552340\n",
      "epoch 127; iter: 0; batch classifier loss: 0.405507; batch adversarial loss: 0.479218\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356586; batch adversarial loss: 0.572860\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344776; batch adversarial loss: 0.607948\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356828; batch adversarial loss: 0.652458\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361594; batch adversarial loss: 0.543870\n",
      "epoch 132; iter: 0; batch classifier loss: 0.408906; batch adversarial loss: 0.500307\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371260; batch adversarial loss: 0.597730\n",
      "epoch 134; iter: 0; batch classifier loss: 0.312310; batch adversarial loss: 0.611374\n",
      "epoch 135; iter: 0; batch classifier loss: 0.342555; batch adversarial loss: 0.574042\n",
      "epoch 136; iter: 0; batch classifier loss: 0.286466; batch adversarial loss: 0.544808\n",
      "epoch 137; iter: 0; batch classifier loss: 0.393042; batch adversarial loss: 0.444100\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322876; batch adversarial loss: 0.517900\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393237; batch adversarial loss: 0.563937\n",
      "epoch 140; iter: 0; batch classifier loss: 0.321179; batch adversarial loss: 0.480751\n",
      "epoch 141; iter: 0; batch classifier loss: 0.360918; batch adversarial loss: 0.597910\n",
      "epoch 142; iter: 0; batch classifier loss: 0.279743; batch adversarial loss: 0.553432\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377970; batch adversarial loss: 0.518526\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401325; batch adversarial loss: 0.552879\n",
      "epoch 145; iter: 0; batch classifier loss: 0.343757; batch adversarial loss: 0.545338\n",
      "epoch 146; iter: 0; batch classifier loss: 0.291945; batch adversarial loss: 0.489981\n",
      "epoch 147; iter: 0; batch classifier loss: 0.314946; batch adversarial loss: 0.481068\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336771; batch adversarial loss: 0.507973\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320879; batch adversarial loss: 0.627604\n",
      "epoch 150; iter: 0; batch classifier loss: 0.232014; batch adversarial loss: 0.536790\n",
      "epoch 151; iter: 0; batch classifier loss: 0.306642; batch adversarial loss: 0.526442\n",
      "epoch 152; iter: 0; batch classifier loss: 0.294350; batch adversarial loss: 0.509736\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369065; batch adversarial loss: 0.518317\n",
      "epoch 154; iter: 0; batch classifier loss: 0.308263; batch adversarial loss: 0.597927\n",
      "epoch 155; iter: 0; batch classifier loss: 0.322428; batch adversarial loss: 0.498454\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329493; batch adversarial loss: 0.589841\n",
      "epoch 157; iter: 0; batch classifier loss: 0.402245; batch adversarial loss: 0.426263\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334311; batch adversarial loss: 0.490236\n",
      "epoch 159; iter: 0; batch classifier loss: 0.307451; batch adversarial loss: 0.506547\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372045; batch adversarial loss: 0.498434\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342880; batch adversarial loss: 0.544583\n",
      "epoch 162; iter: 0; batch classifier loss: 0.332407; batch adversarial loss: 0.570740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 163; iter: 0; batch classifier loss: 0.345325; batch adversarial loss: 0.607339\n",
      "epoch 164; iter: 0; batch classifier loss: 0.315304; batch adversarial loss: 0.572467\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315385; batch adversarial loss: 0.542904\n",
      "epoch 166; iter: 0; batch classifier loss: 0.304692; batch adversarial loss: 0.500339\n",
      "epoch 167; iter: 0; batch classifier loss: 0.327664; batch adversarial loss: 0.517581\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338726; batch adversarial loss: 0.497744\n",
      "epoch 169; iter: 0; batch classifier loss: 0.225192; batch adversarial loss: 0.507198\n",
      "epoch 170; iter: 0; batch classifier loss: 0.283819; batch adversarial loss: 0.616698\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378640; batch adversarial loss: 0.563973\n",
      "epoch 172; iter: 0; batch classifier loss: 0.271472; batch adversarial loss: 0.553888\n",
      "epoch 173; iter: 0; batch classifier loss: 0.376696; batch adversarial loss: 0.636697\n",
      "epoch 174; iter: 0; batch classifier loss: 0.312149; batch adversarial loss: 0.507812\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330989; batch adversarial loss: 0.552871\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319341; batch adversarial loss: 0.572001\n",
      "epoch 177; iter: 0; batch classifier loss: 0.331479; batch adversarial loss: 0.508175\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387145; batch adversarial loss: 0.533677\n",
      "epoch 179; iter: 0; batch classifier loss: 0.286499; batch adversarial loss: 0.563203\n",
      "epoch 180; iter: 0; batch classifier loss: 0.283450; batch adversarial loss: 0.526116\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343156; batch adversarial loss: 0.671739\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349047; batch adversarial loss: 0.570907\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382364; batch adversarial loss: 0.534695\n",
      "epoch 184; iter: 0; batch classifier loss: 0.310069; batch adversarial loss: 0.471078\n",
      "epoch 185; iter: 0; batch classifier loss: 0.340507; batch adversarial loss: 0.536192\n",
      "epoch 186; iter: 0; batch classifier loss: 0.408927; batch adversarial loss: 0.570947\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310302; batch adversarial loss: 0.545696\n",
      "epoch 188; iter: 0; batch classifier loss: 0.295911; batch adversarial loss: 0.488096\n",
      "epoch 189; iter: 0; batch classifier loss: 0.276127; batch adversarial loss: 0.534542\n",
      "epoch 190; iter: 0; batch classifier loss: 0.301039; batch adversarial loss: 0.570766\n",
      "epoch 191; iter: 0; batch classifier loss: 0.309245; batch adversarial loss: 0.599934\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392289; batch adversarial loss: 0.528911\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348396; batch adversarial loss: 0.516888\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342672; batch adversarial loss: 0.555272\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390893; batch adversarial loss: 0.618909\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368402; batch adversarial loss: 0.561666\n",
      "epoch 197; iter: 0; batch classifier loss: 0.271102; batch adversarial loss: 0.527642\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306546; batch adversarial loss: 0.479102\n",
      "epoch 199; iter: 0; batch classifier loss: 0.282247; batch adversarial loss: 0.579932\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658431; batch adversarial loss: 0.848739\n",
      "epoch 1; iter: 0; batch classifier loss: 0.830318; batch adversarial loss: 1.336700\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900272; batch adversarial loss: 1.436206\n",
      "epoch 3; iter: 0; batch classifier loss: 1.124860; batch adversarial loss: 1.348866\n",
      "epoch 4; iter: 0; batch classifier loss: 1.198362; batch adversarial loss: 1.194118\n",
      "epoch 5; iter: 0; batch classifier loss: 1.052202; batch adversarial loss: 1.119205\n",
      "epoch 6; iter: 0; batch classifier loss: 1.085780; batch adversarial loss: 1.048504\n",
      "epoch 7; iter: 0; batch classifier loss: 0.941591; batch adversarial loss: 0.954997\n",
      "epoch 8; iter: 0; batch classifier loss: 0.981324; batch adversarial loss: 0.888196\n",
      "epoch 9; iter: 0; batch classifier loss: 0.935445; batch adversarial loss: 0.850335\n",
      "epoch 10; iter: 0; batch classifier loss: 0.890812; batch adversarial loss: 0.794856\n",
      "epoch 11; iter: 0; batch classifier loss: 0.871086; batch adversarial loss: 0.681510\n",
      "epoch 12; iter: 0; batch classifier loss: 0.639763; batch adversarial loss: 0.692776\n",
      "epoch 13; iter: 0; batch classifier loss: 0.625984; batch adversarial loss: 0.625858\n",
      "epoch 14; iter: 0; batch classifier loss: 0.603122; batch adversarial loss: 0.591948\n",
      "epoch 15; iter: 0; batch classifier loss: 0.571609; batch adversarial loss: 0.627076\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527767; batch adversarial loss: 0.567060\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500470; batch adversarial loss: 0.557159\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508936; batch adversarial loss: 0.600998\n",
      "epoch 19; iter: 0; batch classifier loss: 0.493942; batch adversarial loss: 0.541501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499294; batch adversarial loss: 0.626745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536548; batch adversarial loss: 0.523784\n",
      "epoch 22; iter: 0; batch classifier loss: 0.614901; batch adversarial loss: 0.555086\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500230; batch adversarial loss: 0.552931\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474528; batch adversarial loss: 0.613421\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462571; batch adversarial loss: 0.576656\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457079; batch adversarial loss: 0.558546\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436996; batch adversarial loss: 0.636368\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529908; batch adversarial loss: 0.599112\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455511; batch adversarial loss: 0.567045\n",
      "epoch 30; iter: 0; batch classifier loss: 0.447831; batch adversarial loss: 0.560891\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494240; batch adversarial loss: 0.549610\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487251; batch adversarial loss: 0.551922\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485802; batch adversarial loss: 0.519005\n",
      "epoch 34; iter: 0; batch classifier loss: 0.410627; batch adversarial loss: 0.595860\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462663; batch adversarial loss: 0.528471\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427411; batch adversarial loss: 0.601569\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461256; batch adversarial loss: 0.547061\n",
      "epoch 38; iter: 0; batch classifier loss: 0.385607; batch adversarial loss: 0.607104\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447231; batch adversarial loss: 0.538552\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455216; batch adversarial loss: 0.602394\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438822; batch adversarial loss: 0.575832\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451114; batch adversarial loss: 0.491366\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458710; batch adversarial loss: 0.589617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372319; batch adversarial loss: 0.610233\n",
      "epoch 45; iter: 0; batch classifier loss: 0.372830; batch adversarial loss: 0.524288\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487916; batch adversarial loss: 0.581671\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433350; batch adversarial loss: 0.554443\n",
      "epoch 48; iter: 0; batch classifier loss: 0.363211; batch adversarial loss: 0.552552\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442712; batch adversarial loss: 0.544329\n",
      "epoch 50; iter: 0; batch classifier loss: 0.481614; batch adversarial loss: 0.589787\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481858; batch adversarial loss: 0.525730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398995; batch adversarial loss: 0.595904\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376426; batch adversarial loss: 0.560902\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431893; batch adversarial loss: 0.524643\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489695; batch adversarial loss: 0.551311\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433080; batch adversarial loss: 0.560196\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410199; batch adversarial loss: 0.513915\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455994; batch adversarial loss: 0.617884\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398036; batch adversarial loss: 0.571236\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389149; batch adversarial loss: 0.600617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419102; batch adversarial loss: 0.554176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.393233; batch adversarial loss: 0.418482\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431524; batch adversarial loss: 0.633496\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376482; batch adversarial loss: 0.546033\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397163; batch adversarial loss: 0.586996\n",
      "epoch 66; iter: 0; batch classifier loss: 0.484008; batch adversarial loss: 0.461967\n",
      "epoch 67; iter: 0; batch classifier loss: 0.464309; batch adversarial loss: 0.582676\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445631; batch adversarial loss: 0.570113\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358215; batch adversarial loss: 0.628476\n",
      "epoch 70; iter: 0; batch classifier loss: 0.441222; batch adversarial loss: 0.515938\n",
      "epoch 71; iter: 0; batch classifier loss: 0.327913; batch adversarial loss: 0.553578\n",
      "epoch 72; iter: 0; batch classifier loss: 0.441649; batch adversarial loss: 0.545305\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372798; batch adversarial loss: 0.498137\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416863; batch adversarial loss: 0.575841\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395586; batch adversarial loss: 0.571796\n",
      "epoch 76; iter: 0; batch classifier loss: 0.360562; batch adversarial loss: 0.523285\n",
      "epoch 77; iter: 0; batch classifier loss: 0.332395; batch adversarial loss: 0.681900\n",
      "epoch 78; iter: 0; batch classifier loss: 0.334429; batch adversarial loss: 0.615640\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409876; batch adversarial loss: 0.624487\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442049; batch adversarial loss: 0.561733\n",
      "epoch 81; iter: 0; batch classifier loss: 0.333300; batch adversarial loss: 0.624339\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423891; batch adversarial loss: 0.616678\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389216; batch adversarial loss: 0.607036\n",
      "epoch 84; iter: 0; batch classifier loss: 0.461109; batch adversarial loss: 0.529585\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366540; batch adversarial loss: 0.542444\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403154; batch adversarial loss: 0.576877\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410456; batch adversarial loss: 0.573220\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382051; batch adversarial loss: 0.576332\n",
      "epoch 89; iter: 0; batch classifier loss: 0.420956; batch adversarial loss: 0.609213\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402626; batch adversarial loss: 0.554606\n",
      "epoch 91; iter: 0; batch classifier loss: 0.283548; batch adversarial loss: 0.554455\n",
      "epoch 92; iter: 0; batch classifier loss: 0.422212; batch adversarial loss: 0.525409\n",
      "epoch 93; iter: 0; batch classifier loss: 0.286676; batch adversarial loss: 0.561010\n",
      "epoch 94; iter: 0; batch classifier loss: 0.332864; batch adversarial loss: 0.614170\n",
      "epoch 95; iter: 0; batch classifier loss: 0.383456; batch adversarial loss: 0.622919\n",
      "epoch 96; iter: 0; batch classifier loss: 0.455040; batch adversarial loss: 0.527289\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363214; batch adversarial loss: 0.587162\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392008; batch adversarial loss: 0.537543\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381380; batch adversarial loss: 0.560352\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439988; batch adversarial loss: 0.551724\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377080; batch adversarial loss: 0.623277\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349837; batch adversarial loss: 0.545253\n",
      "epoch 103; iter: 0; batch classifier loss: 0.459328; batch adversarial loss: 0.518046\n",
      "epoch 104; iter: 0; batch classifier loss: 0.335371; batch adversarial loss: 0.623089\n",
      "epoch 105; iter: 0; batch classifier loss: 0.315521; batch adversarial loss: 0.511881\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394666; batch adversarial loss: 0.473174\n",
      "epoch 107; iter: 0; batch classifier loss: 0.500759; batch adversarial loss: 0.560934\n",
      "epoch 108; iter: 0; batch classifier loss: 0.328184; batch adversarial loss: 0.508359\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403385; batch adversarial loss: 0.625513\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370058; batch adversarial loss: 0.527922\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398747; batch adversarial loss: 0.590972\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355731; batch adversarial loss: 0.586010\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370289; batch adversarial loss: 0.465258\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359215; batch adversarial loss: 0.554494\n",
      "epoch 115; iter: 0; batch classifier loss: 0.348825; batch adversarial loss: 0.463472\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347308; batch adversarial loss: 0.555425\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346848; batch adversarial loss: 0.508522\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378781; batch adversarial loss: 0.583360\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404839; batch adversarial loss: 0.483976\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378414; batch adversarial loss: 0.516613\n",
      "epoch 121; iter: 0; batch classifier loss: 0.292860; batch adversarial loss: 0.598910\n",
      "epoch 122; iter: 0; batch classifier loss: 0.301930; batch adversarial loss: 0.589252\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354180; batch adversarial loss: 0.545861\n",
      "epoch 124; iter: 0; batch classifier loss: 0.445081; batch adversarial loss: 0.571012\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400031; batch adversarial loss: 0.587120\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362677; batch adversarial loss: 0.543500\n",
      "epoch 127; iter: 0; batch classifier loss: 0.294182; batch adversarial loss: 0.543478\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415477; batch adversarial loss: 0.499891\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337110; batch adversarial loss: 0.633882\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387392; batch adversarial loss: 0.588457\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383051; batch adversarial loss: 0.523287\n",
      "epoch 132; iter: 0; batch classifier loss: 0.434456; batch adversarial loss: 0.453484\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336495; batch adversarial loss: 0.588656\n",
      "epoch 134; iter: 0; batch classifier loss: 0.370756; batch adversarial loss: 0.490309\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376556; batch adversarial loss: 0.549358\n",
      "epoch 136; iter: 0; batch classifier loss: 0.412820; batch adversarial loss: 0.590118\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327971; batch adversarial loss: 0.544663\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384264; batch adversarial loss: 0.454682\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316528; batch adversarial loss: 0.545767\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332568; batch adversarial loss: 0.502091\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328441; batch adversarial loss: 0.587601\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341615; batch adversarial loss: 0.523091\n",
      "epoch 143; iter: 0; batch classifier loss: 0.416657; batch adversarial loss: 0.608407\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346617; batch adversarial loss: 0.510545\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424726; batch adversarial loss: 0.621072\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334027; batch adversarial loss: 0.576508\n",
      "epoch 147; iter: 0; batch classifier loss: 0.385750; batch adversarial loss: 0.562786\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332630; batch adversarial loss: 0.525215\n",
      "epoch 149; iter: 0; batch classifier loss: 0.442217; batch adversarial loss: 0.581907\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349336; batch adversarial loss: 0.578795\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326454; batch adversarial loss: 0.551780\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375367; batch adversarial loss: 0.569760\n",
      "epoch 153; iter: 0; batch classifier loss: 0.249726; batch adversarial loss: 0.589913\n",
      "epoch 154; iter: 0; batch classifier loss: 0.368766; batch adversarial loss: 0.572482\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360377; batch adversarial loss: 0.511156\n",
      "epoch 156; iter: 0; batch classifier loss: 0.310243; batch adversarial loss: 0.605401\n",
      "epoch 157; iter: 0; batch classifier loss: 0.290831; batch adversarial loss: 0.526639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.346430; batch adversarial loss: 0.516318\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393171; batch adversarial loss: 0.590179\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380909; batch adversarial loss: 0.585103\n",
      "epoch 161; iter: 0; batch classifier loss: 0.296084; batch adversarial loss: 0.525014\n",
      "epoch 162; iter: 0; batch classifier loss: 0.414021; batch adversarial loss: 0.533574\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342005; batch adversarial loss: 0.624809\n",
      "epoch 164; iter: 0; batch classifier loss: 0.391716; batch adversarial loss: 0.447726\n",
      "epoch 165; iter: 0; batch classifier loss: 0.284537; batch adversarial loss: 0.493641\n",
      "epoch 166; iter: 0; batch classifier loss: 0.364297; batch adversarial loss: 0.600967\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345661; batch adversarial loss: 0.514920\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376082; batch adversarial loss: 0.516675\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374919; batch adversarial loss: 0.652043\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388257; batch adversarial loss: 0.522937\n",
      "epoch 171; iter: 0; batch classifier loss: 0.297759; batch adversarial loss: 0.560115\n",
      "epoch 172; iter: 0; batch classifier loss: 0.320342; batch adversarial loss: 0.527262\n",
      "epoch 173; iter: 0; batch classifier loss: 0.309943; batch adversarial loss: 0.605174\n",
      "epoch 174; iter: 0; batch classifier loss: 0.313736; batch adversarial loss: 0.541996\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336089; batch adversarial loss: 0.608420\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310784; batch adversarial loss: 0.544687\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337034; batch adversarial loss: 0.552746\n",
      "epoch 178; iter: 0; batch classifier loss: 0.278053; batch adversarial loss: 0.580233\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354476; batch adversarial loss: 0.592523\n",
      "epoch 180; iter: 0; batch classifier loss: 0.310395; batch adversarial loss: 0.542515\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354117; batch adversarial loss: 0.561739\n",
      "epoch 182; iter: 0; batch classifier loss: 0.375479; batch adversarial loss: 0.572126\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323867; batch adversarial loss: 0.490973\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370217; batch adversarial loss: 0.561197\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387817; batch adversarial loss: 0.523693\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351425; batch adversarial loss: 0.559819\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329864; batch adversarial loss: 0.519416\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365488; batch adversarial loss: 0.569957\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357190; batch adversarial loss: 0.582910\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326335; batch adversarial loss: 0.609427\n",
      "epoch 191; iter: 0; batch classifier loss: 0.390393; batch adversarial loss: 0.510857\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336860; batch adversarial loss: 0.561069\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378671; batch adversarial loss: 0.518514\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382925; batch adversarial loss: 0.542585\n",
      "epoch 195; iter: 0; batch classifier loss: 0.357479; batch adversarial loss: 0.524005\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364461; batch adversarial loss: 0.439182\n",
      "epoch 197; iter: 0; batch classifier loss: 0.473437; batch adversarial loss: 0.557105\n",
      "epoch 198; iter: 0; batch classifier loss: 0.293810; batch adversarial loss: 0.553351\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323754; batch adversarial loss: 0.564802\n",
      "epoch 0; iter: 0; batch classifier loss: 0.775496; batch adversarial loss: 0.831127\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629392; batch adversarial loss: 0.777386\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623838; batch adversarial loss: 0.718149\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576707; batch adversarial loss: 0.712676\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531101; batch adversarial loss: 0.647616\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582142; batch adversarial loss: 0.647423\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562600; batch adversarial loss: 0.620477\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584894; batch adversarial loss: 0.619020\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475731; batch adversarial loss: 0.591504\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561868; batch adversarial loss: 0.641289\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528915; batch adversarial loss: 0.644975\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522626; batch adversarial loss: 0.593093\n",
      "epoch 12; iter: 0; batch classifier loss: 0.580980; batch adversarial loss: 0.558120\n",
      "epoch 13; iter: 0; batch classifier loss: 0.562288; batch adversarial loss: 0.587490\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504252; batch adversarial loss: 0.600145\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494985; batch adversarial loss: 0.581592\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534129; batch adversarial loss: 0.487981\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592620; batch adversarial loss: 0.568587\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517626; batch adversarial loss: 0.645043\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465331; batch adversarial loss: 0.497570\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473223; batch adversarial loss: 0.613954\n",
      "epoch 21; iter: 0; batch classifier loss: 0.448367; batch adversarial loss: 0.583328\n",
      "epoch 22; iter: 0; batch classifier loss: 0.577717; batch adversarial loss: 0.558835\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461764; batch adversarial loss: 0.595461\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523528; batch adversarial loss: 0.637071\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484019; batch adversarial loss: 0.574272\n",
      "epoch 26; iter: 0; batch classifier loss: 0.537865; batch adversarial loss: 0.527545\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509527; batch adversarial loss: 0.525782\n",
      "epoch 28; iter: 0; batch classifier loss: 0.521245; batch adversarial loss: 0.538677\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522322; batch adversarial loss: 0.553482\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470172; batch adversarial loss: 0.577207\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414716; batch adversarial loss: 0.522540\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466910; batch adversarial loss: 0.498383\n",
      "epoch 33; iter: 0; batch classifier loss: 0.516937; batch adversarial loss: 0.488230\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470644; batch adversarial loss: 0.599674\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463790; batch adversarial loss: 0.527851\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494623; batch adversarial loss: 0.504228\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408433; batch adversarial loss: 0.547152\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482093; batch adversarial loss: 0.553514\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446924; batch adversarial loss: 0.530294\n",
      "epoch 40; iter: 0; batch classifier loss: 0.478423; batch adversarial loss: 0.598459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.496581; batch adversarial loss: 0.562642\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436115; batch adversarial loss: 0.545584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.502271; batch adversarial loss: 0.535474\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418063; batch adversarial loss: 0.563827\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464483; batch adversarial loss: 0.570898\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508980; batch adversarial loss: 0.492747\n",
      "epoch 47; iter: 0; batch classifier loss: 0.495804; batch adversarial loss: 0.571737\n",
      "epoch 48; iter: 0; batch classifier loss: 0.527725; batch adversarial loss: 0.517403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432366; batch adversarial loss: 0.527285\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479582; batch adversarial loss: 0.589351\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471274; batch adversarial loss: 0.545149\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446686; batch adversarial loss: 0.525459\n",
      "epoch 53; iter: 0; batch classifier loss: 0.341162; batch adversarial loss: 0.517162\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397230; batch adversarial loss: 0.525921\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440312; batch adversarial loss: 0.598768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.462125; batch adversarial loss: 0.543788\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402824; batch adversarial loss: 0.608037\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439564; batch adversarial loss: 0.543323\n",
      "epoch 59; iter: 0; batch classifier loss: 0.403439; batch adversarial loss: 0.645329\n",
      "epoch 60; iter: 0; batch classifier loss: 0.475985; batch adversarial loss: 0.553064\n",
      "epoch 61; iter: 0; batch classifier loss: 0.506065; batch adversarial loss: 0.544504\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429322; batch adversarial loss: 0.544528\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420187; batch adversarial loss: 0.509533\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438540; batch adversarial loss: 0.518335\n",
      "epoch 65; iter: 0; batch classifier loss: 0.456900; batch adversarial loss: 0.589307\n",
      "epoch 66; iter: 0; batch classifier loss: 0.480843; batch adversarial loss: 0.482760\n",
      "epoch 67; iter: 0; batch classifier loss: 0.457061; batch adversarial loss: 0.517927\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415329; batch adversarial loss: 0.535720\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432313; batch adversarial loss: 0.535692\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422926; batch adversarial loss: 0.535635\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427332; batch adversarial loss: 0.580624\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442409; batch adversarial loss: 0.508659\n",
      "epoch 73; iter: 0; batch classifier loss: 0.397946; batch adversarial loss: 0.544512\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437194; batch adversarial loss: 0.544673\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369469; batch adversarial loss: 0.571775\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427550; batch adversarial loss: 0.580867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.506921; batch adversarial loss: 0.553606\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381300; batch adversarial loss: 0.615723\n",
      "epoch 79; iter: 0; batch classifier loss: 0.503036; batch adversarial loss: 0.598792\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417259; batch adversarial loss: 0.616335\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365651; batch adversarial loss: 0.561434\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397572; batch adversarial loss: 0.517380\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358684; batch adversarial loss: 0.597176\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349716; batch adversarial loss: 0.580161\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428549; batch adversarial loss: 0.517682\n",
      "epoch 86; iter: 0; batch classifier loss: 0.457770; batch adversarial loss: 0.472754\n",
      "epoch 87; iter: 0; batch classifier loss: 0.437851; batch adversarial loss: 0.545016\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367916; batch adversarial loss: 0.599511\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436605; batch adversarial loss: 0.599451\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407696; batch adversarial loss: 0.562514\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399671; batch adversarial loss: 0.544611\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379468; batch adversarial loss: 0.535201\n",
      "epoch 93; iter: 0; batch classifier loss: 0.416384; batch adversarial loss: 0.500507\n",
      "epoch 94; iter: 0; batch classifier loss: 0.418060; batch adversarial loss: 0.587780\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397022; batch adversarial loss: 0.579665\n",
      "epoch 96; iter: 0; batch classifier loss: 0.465164; batch adversarial loss: 0.580149\n",
      "epoch 97; iter: 0; batch classifier loss: 0.321751; batch adversarial loss: 0.586293\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395937; batch adversarial loss: 0.500423\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385758; batch adversarial loss: 0.559165\n",
      "epoch 100; iter: 0; batch classifier loss: 0.327981; batch adversarial loss: 0.526332\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393259; batch adversarial loss: 0.592937\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391980; batch adversarial loss: 0.514049\n",
      "epoch 103; iter: 0; batch classifier loss: 0.446751; batch adversarial loss: 0.560075\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348290; batch adversarial loss: 0.528934\n",
      "epoch 105; iter: 0; batch classifier loss: 0.393419; batch adversarial loss: 0.493299\n",
      "epoch 106; iter: 0; batch classifier loss: 0.348679; batch adversarial loss: 0.621114\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397339; batch adversarial loss: 0.634571\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386447; batch adversarial loss: 0.597358\n",
      "epoch 109; iter: 0; batch classifier loss: 0.456517; batch adversarial loss: 0.515369\n",
      "epoch 110; iter: 0; batch classifier loss: 0.464765; batch adversarial loss: 0.527356\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381779; batch adversarial loss: 0.644416\n",
      "epoch 112; iter: 0; batch classifier loss: 0.417979; batch adversarial loss: 0.470746\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419439; batch adversarial loss: 0.516719\n",
      "epoch 114; iter: 0; batch classifier loss: 0.356001; batch adversarial loss: 0.490032\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332466; batch adversarial loss: 0.563089\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420946; batch adversarial loss: 0.544362\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407675; batch adversarial loss: 0.453088\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395053; batch adversarial loss: 0.554039\n",
      "epoch 119; iter: 0; batch classifier loss: 0.418920; batch adversarial loss: 0.544413\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406217; batch adversarial loss: 0.444464\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351990; batch adversarial loss: 0.525680\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364221; batch adversarial loss: 0.535888\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336414; batch adversarial loss: 0.498857\n",
      "epoch 124; iter: 0; batch classifier loss: 0.412661; batch adversarial loss: 0.544438\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351764; batch adversarial loss: 0.607590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377864; batch adversarial loss: 0.562268\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379329; batch adversarial loss: 0.571759\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385154; batch adversarial loss: 0.533777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416829; batch adversarial loss: 0.536420\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375471; batch adversarial loss: 0.544678\n",
      "epoch 131; iter: 0; batch classifier loss: 0.532141; batch adversarial loss: 0.544782\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346312; batch adversarial loss: 0.544548\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370940; batch adversarial loss: 0.635642\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376447; batch adversarial loss: 0.517340\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380554; batch adversarial loss: 0.571970\n",
      "epoch 136; iter: 0; batch classifier loss: 0.432612; batch adversarial loss: 0.553960\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376654; batch adversarial loss: 0.535035\n",
      "epoch 138; iter: 0; batch classifier loss: 0.512007; batch adversarial loss: 0.590726\n",
      "epoch 139; iter: 0; batch classifier loss: 0.447935; batch adversarial loss: 0.517881\n",
      "epoch 140; iter: 0; batch classifier loss: 0.477562; batch adversarial loss: 0.525185\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342668; batch adversarial loss: 0.561507\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356123; batch adversarial loss: 0.598857\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413533; batch adversarial loss: 0.562222\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394949; batch adversarial loss: 0.553603\n",
      "epoch 145; iter: 0; batch classifier loss: 0.460661; batch adversarial loss: 0.571169\n",
      "epoch 146; iter: 0; batch classifier loss: 0.390701; batch adversarial loss: 0.616365\n",
      "epoch 147; iter: 0; batch classifier loss: 0.375860; batch adversarial loss: 0.499898\n",
      "epoch 148; iter: 0; batch classifier loss: 0.418294; batch adversarial loss: 0.527301\n",
      "epoch 149; iter: 0; batch classifier loss: 0.428530; batch adversarial loss: 0.490306\n",
      "epoch 150; iter: 0; batch classifier loss: 0.332719; batch adversarial loss: 0.534651\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371726; batch adversarial loss: 0.616706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.366454; batch adversarial loss: 0.499530\n",
      "epoch 153; iter: 0; batch classifier loss: 0.442598; batch adversarial loss: 0.590219\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384991; batch adversarial loss: 0.544914\n",
      "epoch 155; iter: 0; batch classifier loss: 0.414329; batch adversarial loss: 0.517734\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418028; batch adversarial loss: 0.562412\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375818; batch adversarial loss: 0.545124\n",
      "epoch 158; iter: 0; batch classifier loss: 0.479591; batch adversarial loss: 0.489366\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374616; batch adversarial loss: 0.625491\n",
      "epoch 160; iter: 0; batch classifier loss: 0.426730; batch adversarial loss: 0.571011\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359228; batch adversarial loss: 0.499898\n",
      "epoch 162; iter: 0; batch classifier loss: 0.430211; batch adversarial loss: 0.616445\n",
      "epoch 163; iter: 0; batch classifier loss: 0.460342; batch adversarial loss: 0.553416\n",
      "epoch 164; iter: 0; batch classifier loss: 0.321918; batch adversarial loss: 0.671543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379833; batch adversarial loss: 0.544708\n",
      "epoch 166; iter: 0; batch classifier loss: 0.419916; batch adversarial loss: 0.582037\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387697; batch adversarial loss: 0.536228\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364815; batch adversarial loss: 0.446207\n",
      "epoch 169; iter: 0; batch classifier loss: 0.329657; batch adversarial loss: 0.571148\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365708; batch adversarial loss: 0.553095\n",
      "epoch 171; iter: 0; batch classifier loss: 0.309628; batch adversarial loss: 0.517372\n",
      "epoch 172; iter: 0; batch classifier loss: 0.433568; batch adversarial loss: 0.527175\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378067; batch adversarial loss: 0.580796\n",
      "epoch 174; iter: 0; batch classifier loss: 0.503613; batch adversarial loss: 0.571812\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395465; batch adversarial loss: 0.535342\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378963; batch adversarial loss: 0.517451\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342344; batch adversarial loss: 0.598469\n",
      "epoch 178; iter: 0; batch classifier loss: 0.430288; batch adversarial loss: 0.553367\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375490; batch adversarial loss: 0.598208\n",
      "epoch 180; iter: 0; batch classifier loss: 0.332820; batch adversarial loss: 0.463428\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384467; batch adversarial loss: 0.571791\n",
      "epoch 182; iter: 0; batch classifier loss: 0.423059; batch adversarial loss: 0.544529\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358956; batch adversarial loss: 0.589749\n",
      "epoch 184; iter: 0; batch classifier loss: 0.399443; batch adversarial loss: 0.607686\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342325; batch adversarial loss: 0.535589\n",
      "epoch 186; iter: 0; batch classifier loss: 0.423514; batch adversarial loss: 0.535255\n",
      "epoch 187; iter: 0; batch classifier loss: 0.408217; batch adversarial loss: 0.589525\n",
      "epoch 188; iter: 0; batch classifier loss: 0.288616; batch adversarial loss: 0.535909\n",
      "epoch 189; iter: 0; batch classifier loss: 0.308681; batch adversarial loss: 0.499641\n",
      "epoch 190; iter: 0; batch classifier loss: 0.422915; batch adversarial loss: 0.499119\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362129; batch adversarial loss: 0.562634\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368181; batch adversarial loss: 0.544949\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361601; batch adversarial loss: 0.490005\n",
      "epoch 194; iter: 0; batch classifier loss: 0.463282; batch adversarial loss: 0.481143\n",
      "epoch 195; iter: 0; batch classifier loss: 0.355752; batch adversarial loss: 0.580791\n",
      "epoch 196; iter: 0; batch classifier loss: 0.395927; batch adversarial loss: 0.526424\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388037; batch adversarial loss: 0.553342\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377487; batch adversarial loss: 0.508482\n",
      "epoch 199; iter: 0; batch classifier loss: 0.390375; batch adversarial loss: 0.499942\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695225; batch adversarial loss: 0.631500\n",
      "epoch 1; iter: 0; batch classifier loss: 0.644986; batch adversarial loss: 0.619767\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587571; batch adversarial loss: 0.643149\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559858; batch adversarial loss: 0.606915\n",
      "epoch 4; iter: 0; batch classifier loss: 0.499979; batch adversarial loss: 0.637823\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558261; batch adversarial loss: 0.636468\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597298; batch adversarial loss: 0.613489\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532804; batch adversarial loss: 0.571611\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527445; batch adversarial loss: 0.637428\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558522; batch adversarial loss: 0.536024\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532645; batch adversarial loss: 0.657149\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556338; batch adversarial loss: 0.578398\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538264; batch adversarial loss: 0.591341\n",
      "epoch 13; iter: 0; batch classifier loss: 0.470476; batch adversarial loss: 0.535810\n",
      "epoch 14; iter: 0; batch classifier loss: 0.593859; batch adversarial loss: 0.573182\n",
      "epoch 15; iter: 0; batch classifier loss: 0.565900; batch adversarial loss: 0.529998\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510004; batch adversarial loss: 0.546681\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520633; batch adversarial loss: 0.588145\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559695; batch adversarial loss: 0.504927\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543561; batch adversarial loss: 0.518553\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523553; batch adversarial loss: 0.527202\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501527; batch adversarial loss: 0.532612\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459553; batch adversarial loss: 0.517453\n",
      "epoch 23; iter: 0; batch classifier loss: 0.581819; batch adversarial loss: 0.551372\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471580; batch adversarial loss: 0.545178\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434322; batch adversarial loss: 0.613741\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432110; batch adversarial loss: 0.594650\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500985; batch adversarial loss: 0.549781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.546611; batch adversarial loss: 0.558145\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487608; batch adversarial loss: 0.531977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551560; batch adversarial loss: 0.490290\n",
      "epoch 31; iter: 0; batch classifier loss: 0.427357; batch adversarial loss: 0.535350\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438923; batch adversarial loss: 0.548617\n",
      "epoch 33; iter: 0; batch classifier loss: 0.540879; batch adversarial loss: 0.565328\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419933; batch adversarial loss: 0.516387\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435235; batch adversarial loss: 0.506535\n",
      "epoch 36; iter: 0; batch classifier loss: 0.523918; batch adversarial loss: 0.561834\n",
      "epoch 37; iter: 0; batch classifier loss: 0.515772; batch adversarial loss: 0.635726\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422995; batch adversarial loss: 0.544083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465858; batch adversarial loss: 0.584029\n",
      "epoch 40; iter: 0; batch classifier loss: 0.368967; batch adversarial loss: 0.538860\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460843; batch adversarial loss: 0.573283\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422532; batch adversarial loss: 0.517184\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459828; batch adversarial loss: 0.593957\n",
      "epoch 44; iter: 0; batch classifier loss: 0.503028; batch adversarial loss: 0.496081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489542; batch adversarial loss: 0.617391\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436837; batch adversarial loss: 0.555177\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475067; batch adversarial loss: 0.611045\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469019; batch adversarial loss: 0.449212\n",
      "epoch 49; iter: 0; batch classifier loss: 0.577587; batch adversarial loss: 0.542512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.446271; batch adversarial loss: 0.484822\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466413; batch adversarial loss: 0.597766\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435772; batch adversarial loss: 0.514419\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410985; batch adversarial loss: 0.536447\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433987; batch adversarial loss: 0.648553\n",
      "epoch 55; iter: 0; batch classifier loss: 0.474901; batch adversarial loss: 0.465723\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393129; batch adversarial loss: 0.560428\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498792; batch adversarial loss: 0.576482\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462645; batch adversarial loss: 0.632498\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452244; batch adversarial loss: 0.483592\n",
      "epoch 60; iter: 0; batch classifier loss: 0.371448; batch adversarial loss: 0.554712\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398942; batch adversarial loss: 0.644392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443999; batch adversarial loss: 0.591880\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402905; batch adversarial loss: 0.537306\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403907; batch adversarial loss: 0.513641\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391495; batch adversarial loss: 0.587981\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447800; batch adversarial loss: 0.610793\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388258; batch adversarial loss: 0.570829\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356029; batch adversarial loss: 0.570989\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424840; batch adversarial loss: 0.466341\n",
      "epoch 70; iter: 0; batch classifier loss: 0.487492; batch adversarial loss: 0.579830\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390245; batch adversarial loss: 0.562110\n",
      "epoch 72; iter: 0; batch classifier loss: 0.426767; batch adversarial loss: 0.499103\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447025; batch adversarial loss: 0.561094\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391741; batch adversarial loss: 0.544675\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441029; batch adversarial loss: 0.524565\n",
      "epoch 76; iter: 0; batch classifier loss: 0.524428; batch adversarial loss: 0.551671\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379390; batch adversarial loss: 0.501974\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409654; batch adversarial loss: 0.633926\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355472; batch adversarial loss: 0.549029\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476181; batch adversarial loss: 0.579358\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394614; batch adversarial loss: 0.500056\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372908; batch adversarial loss: 0.507556\n",
      "epoch 83; iter: 0; batch classifier loss: 0.479331; batch adversarial loss: 0.591016\n",
      "epoch 84; iter: 0; batch classifier loss: 0.455453; batch adversarial loss: 0.568919\n",
      "epoch 85; iter: 0; batch classifier loss: 0.454307; batch adversarial loss: 0.568691\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394791; batch adversarial loss: 0.534706\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403404; batch adversarial loss: 0.676345\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401532; batch adversarial loss: 0.537781\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427401; batch adversarial loss: 0.559757\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372269; batch adversarial loss: 0.482513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399158; batch adversarial loss: 0.423055\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369635; batch adversarial loss: 0.603100\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361217; batch adversarial loss: 0.561782\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377549; batch adversarial loss: 0.526509\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398261; batch adversarial loss: 0.484097\n",
      "epoch 96; iter: 0; batch classifier loss: 0.323887; batch adversarial loss: 0.545048\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383841; batch adversarial loss: 0.534006\n",
      "epoch 98; iter: 0; batch classifier loss: 0.437814; batch adversarial loss: 0.542502\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424656; batch adversarial loss: 0.510319\n",
      "epoch 100; iter: 0; batch classifier loss: 0.532730; batch adversarial loss: 0.580929\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379949; batch adversarial loss: 0.546792\n",
      "epoch 102; iter: 0; batch classifier loss: 0.493508; batch adversarial loss: 0.577380\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388281; batch adversarial loss: 0.563529\n",
      "epoch 104; iter: 0; batch classifier loss: 0.407657; batch adversarial loss: 0.598583\n",
      "epoch 105; iter: 0; batch classifier loss: 0.422077; batch adversarial loss: 0.607616\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353442; batch adversarial loss: 0.490217\n",
      "epoch 107; iter: 0; batch classifier loss: 0.422848; batch adversarial loss: 0.594092\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338571; batch adversarial loss: 0.579006\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351011; batch adversarial loss: 0.612961\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405870; batch adversarial loss: 0.636070\n",
      "epoch 111; iter: 0; batch classifier loss: 0.443305; batch adversarial loss: 0.528684\n",
      "epoch 112; iter: 0; batch classifier loss: 0.432836; batch adversarial loss: 0.577063\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389233; batch adversarial loss: 0.582020\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400910; batch adversarial loss: 0.508233\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420825; batch adversarial loss: 0.553250\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376862; batch adversarial loss: 0.592005\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393657; batch adversarial loss: 0.492110\n",
      "epoch 118; iter: 0; batch classifier loss: 0.303978; batch adversarial loss: 0.596378\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375696; batch adversarial loss: 0.543503\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422464; batch adversarial loss: 0.609317\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382784; batch adversarial loss: 0.542392\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359593; batch adversarial loss: 0.503885\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399704; batch adversarial loss: 0.577217\n",
      "epoch 124; iter: 0; batch classifier loss: 0.427543; batch adversarial loss: 0.564289\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376128; batch adversarial loss: 0.621044\n",
      "epoch 126; iter: 0; batch classifier loss: 0.342111; batch adversarial loss: 0.642394\n",
      "epoch 127; iter: 0; batch classifier loss: 0.335765; batch adversarial loss: 0.520207\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395579; batch adversarial loss: 0.571378\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388225; batch adversarial loss: 0.596525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.418213; batch adversarial loss: 0.516524\n",
      "epoch 131; iter: 0; batch classifier loss: 0.411086; batch adversarial loss: 0.546128\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367298; batch adversarial loss: 0.595401\n",
      "epoch 133; iter: 0; batch classifier loss: 0.316476; batch adversarial loss: 0.509622\n",
      "epoch 134; iter: 0; batch classifier loss: 0.322443; batch adversarial loss: 0.633635\n",
      "epoch 135; iter: 0; batch classifier loss: 0.289706; batch adversarial loss: 0.574021\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397529; batch adversarial loss: 0.544796\n",
      "epoch 137; iter: 0; batch classifier loss: 0.409881; batch adversarial loss: 0.588238\n",
      "epoch 138; iter: 0; batch classifier loss: 0.297863; batch adversarial loss: 0.481157\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352159; batch adversarial loss: 0.521395\n",
      "epoch 140; iter: 0; batch classifier loss: 0.469221; batch adversarial loss: 0.581578\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368193; batch adversarial loss: 0.561439\n",
      "epoch 142; iter: 0; batch classifier loss: 0.325313; batch adversarial loss: 0.517571\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379372; batch adversarial loss: 0.512239\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350823; batch adversarial loss: 0.604788\n",
      "epoch 145; iter: 0; batch classifier loss: 0.279619; batch adversarial loss: 0.558045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.359097; batch adversarial loss: 0.536392\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372263; batch adversarial loss: 0.534702\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365978; batch adversarial loss: 0.527969\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413794; batch adversarial loss: 0.570301\n",
      "epoch 150; iter: 0; batch classifier loss: 0.464164; batch adversarial loss: 0.509499\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432913; batch adversarial loss: 0.590397\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377294; batch adversarial loss: 0.554942\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322867; batch adversarial loss: 0.572999\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373091; batch adversarial loss: 0.543788\n",
      "epoch 155; iter: 0; batch classifier loss: 0.319678; batch adversarial loss: 0.580264\n",
      "epoch 156; iter: 0; batch classifier loss: 0.320362; batch adversarial loss: 0.562134\n",
      "epoch 157; iter: 0; batch classifier loss: 0.426514; batch adversarial loss: 0.472964\n",
      "epoch 158; iter: 0; batch classifier loss: 0.409654; batch adversarial loss: 0.634724\n",
      "epoch 159; iter: 0; batch classifier loss: 0.425251; batch adversarial loss: 0.613222\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319066; batch adversarial loss: 0.593964\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314505; batch adversarial loss: 0.567507\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347992; batch adversarial loss: 0.562221\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365131; batch adversarial loss: 0.523501\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392958; batch adversarial loss: 0.560714\n",
      "epoch 165; iter: 0; batch classifier loss: 0.298980; batch adversarial loss: 0.605027\n",
      "epoch 166; iter: 0; batch classifier loss: 0.429981; batch adversarial loss: 0.571956\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384145; batch adversarial loss: 0.567206\n",
      "epoch 168; iter: 0; batch classifier loss: 0.257393; batch adversarial loss: 0.509016\n",
      "epoch 169; iter: 0; batch classifier loss: 0.441510; batch adversarial loss: 0.540988\n",
      "epoch 170; iter: 0; batch classifier loss: 0.291097; batch adversarial loss: 0.616661\n",
      "epoch 171; iter: 0; batch classifier loss: 0.377701; batch adversarial loss: 0.589498\n",
      "epoch 172; iter: 0; batch classifier loss: 0.464135; batch adversarial loss: 0.528696\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355764; batch adversarial loss: 0.570472\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362317; batch adversarial loss: 0.648815\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409312; batch adversarial loss: 0.617450\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346276; batch adversarial loss: 0.519276\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377198; batch adversarial loss: 0.579568\n",
      "epoch 178; iter: 0; batch classifier loss: 0.394999; batch adversarial loss: 0.655791\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355946; batch adversarial loss: 0.578121\n",
      "epoch 180; iter: 0; batch classifier loss: 0.380402; batch adversarial loss: 0.588590\n",
      "epoch 181; iter: 0; batch classifier loss: 0.430505; batch adversarial loss: 0.615544\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390261; batch adversarial loss: 0.589925\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352004; batch adversarial loss: 0.553087\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385649; batch adversarial loss: 0.500069\n",
      "epoch 185; iter: 0; batch classifier loss: 0.340452; batch adversarial loss: 0.562362\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315518; batch adversarial loss: 0.546512\n",
      "epoch 187; iter: 0; batch classifier loss: 0.409233; batch adversarial loss: 0.561234\n",
      "epoch 188; iter: 0; batch classifier loss: 0.296806; batch adversarial loss: 0.521260\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364154; batch adversarial loss: 0.616449\n",
      "epoch 190; iter: 0; batch classifier loss: 0.402879; batch adversarial loss: 0.535491\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380706; batch adversarial loss: 0.604918\n",
      "epoch 192; iter: 0; batch classifier loss: 0.448576; batch adversarial loss: 0.615404\n",
      "epoch 193; iter: 0; batch classifier loss: 0.399732; batch adversarial loss: 0.544323\n",
      "epoch 194; iter: 0; batch classifier loss: 0.394540; batch adversarial loss: 0.551095\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320644; batch adversarial loss: 0.535513\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398069; batch adversarial loss: 0.554175\n",
      "epoch 197; iter: 0; batch classifier loss: 0.404708; batch adversarial loss: 0.561312\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321431; batch adversarial loss: 0.572092\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331864; batch adversarial loss: 0.597150\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679518; batch adversarial loss: 0.669805\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601482; batch adversarial loss: 0.651373\n",
      "epoch 2; iter: 0; batch classifier loss: 0.559212; batch adversarial loss: 0.628016\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548286; batch adversarial loss: 0.631833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.536897; batch adversarial loss: 0.591794\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516537; batch adversarial loss: 0.544928\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504350; batch adversarial loss: 0.578623\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505383; batch adversarial loss: 0.603968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534710; batch adversarial loss: 0.608390\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506163; batch adversarial loss: 0.592431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540544; batch adversarial loss: 0.596670\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552880; batch adversarial loss: 0.597968\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531619; batch adversarial loss: 0.687155\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569068; batch adversarial loss: 0.617898\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564987; batch adversarial loss: 0.568565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.557127; batch adversarial loss: 0.549581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514874; batch adversarial loss: 0.664891\n",
      "epoch 17; iter: 0; batch classifier loss: 0.579979; batch adversarial loss: 0.553988\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513709; batch adversarial loss: 0.559493\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510497; batch adversarial loss: 0.560634\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556255; batch adversarial loss: 0.573888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460216; batch adversarial loss: 0.647341\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495096; batch adversarial loss: 0.640976\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528774; batch adversarial loss: 0.527770\n",
      "epoch 24; iter: 0; batch classifier loss: 0.543619; batch adversarial loss: 0.598074\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451029; batch adversarial loss: 0.575688\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513881; batch adversarial loss: 0.511650\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529472; batch adversarial loss: 0.580496\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462711; batch adversarial loss: 0.626925\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457146; batch adversarial loss: 0.531292\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523101; batch adversarial loss: 0.515247\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515994; batch adversarial loss: 0.530647\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458499; batch adversarial loss: 0.556034\n",
      "epoch 33; iter: 0; batch classifier loss: 0.389491; batch adversarial loss: 0.563179\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453826; batch adversarial loss: 0.553315\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457631; batch adversarial loss: 0.502850\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442532; batch adversarial loss: 0.545951\n",
      "epoch 37; iter: 0; batch classifier loss: 0.433954; batch adversarial loss: 0.527943\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483198; batch adversarial loss: 0.588084\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457912; batch adversarial loss: 0.562474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.345069; batch adversarial loss: 0.553657\n",
      "epoch 41; iter: 0; batch classifier loss: 0.491033; batch adversarial loss: 0.597007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447327; batch adversarial loss: 0.509913\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432403; batch adversarial loss: 0.642952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.439786; batch adversarial loss: 0.581794\n",
      "epoch 45; iter: 0; batch classifier loss: 0.487078; batch adversarial loss: 0.500544\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471170; batch adversarial loss: 0.534571\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424923; batch adversarial loss: 0.597053\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418432; batch adversarial loss: 0.570040\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433639; batch adversarial loss: 0.588887\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414452; batch adversarial loss: 0.487684\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411143; batch adversarial loss: 0.572683\n",
      "epoch 52; iter: 0; batch classifier loss: 0.492936; batch adversarial loss: 0.577975\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406492; batch adversarial loss: 0.569993\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408915; batch adversarial loss: 0.520866\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441837; batch adversarial loss: 0.562896\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454313; batch adversarial loss: 0.498228\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426359; batch adversarial loss: 0.578240\n",
      "epoch 58; iter: 0; batch classifier loss: 0.485247; batch adversarial loss: 0.524527\n",
      "epoch 59; iter: 0; batch classifier loss: 0.453487; batch adversarial loss: 0.597931\n",
      "epoch 60; iter: 0; batch classifier loss: 0.471619; batch adversarial loss: 0.562581\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439333; batch adversarial loss: 0.588211\n",
      "epoch 62; iter: 0; batch classifier loss: 0.467842; batch adversarial loss: 0.554081\n",
      "epoch 63; iter: 0; batch classifier loss: 0.494995; batch adversarial loss: 0.561415\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395075; batch adversarial loss: 0.578245\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437402; batch adversarial loss: 0.527177\n",
      "epoch 66; iter: 0; batch classifier loss: 0.462641; batch adversarial loss: 0.509186\n",
      "epoch 67; iter: 0; batch classifier loss: 0.342767; batch adversarial loss: 0.623019\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380701; batch adversarial loss: 0.579290\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447329; batch adversarial loss: 0.574198\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424210; batch adversarial loss: 0.520322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419566; batch adversarial loss: 0.521784\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448887; batch adversarial loss: 0.588934\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358651; batch adversarial loss: 0.481930\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413214; batch adversarial loss: 0.528266\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366669; batch adversarial loss: 0.420093\n",
      "epoch 76; iter: 0; batch classifier loss: 0.442634; batch adversarial loss: 0.588701\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374754; batch adversarial loss: 0.544672\n",
      "epoch 78; iter: 0; batch classifier loss: 0.430911; batch adversarial loss: 0.554120\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426584; batch adversarial loss: 0.571966\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378273; batch adversarial loss: 0.555655\n",
      "epoch 81; iter: 0; batch classifier loss: 0.469969; batch adversarial loss: 0.599672\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396891; batch adversarial loss: 0.507029\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398924; batch adversarial loss: 0.543140\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396136; batch adversarial loss: 0.560890\n",
      "epoch 85; iter: 0; batch classifier loss: 0.515480; batch adversarial loss: 0.533852\n",
      "epoch 86; iter: 0; batch classifier loss: 0.438468; batch adversarial loss: 0.641481\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429179; batch adversarial loss: 0.537944\n",
      "epoch 88; iter: 0; batch classifier loss: 0.473007; batch adversarial loss: 0.564946\n",
      "epoch 89; iter: 0; batch classifier loss: 0.409149; batch adversarial loss: 0.499481\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398000; batch adversarial loss: 0.743119\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452450; batch adversarial loss: 0.579838\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389018; batch adversarial loss: 0.538148\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404019; batch adversarial loss: 0.573290\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392915; batch adversarial loss: 0.552604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395091; batch adversarial loss: 0.526669\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431253; batch adversarial loss: 0.594512\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399904; batch adversarial loss: 0.607866\n",
      "epoch 98; iter: 0; batch classifier loss: 0.346564; batch adversarial loss: 0.512477\n",
      "epoch 99; iter: 0; batch classifier loss: 0.331921; batch adversarial loss: 0.520225\n",
      "epoch 100; iter: 0; batch classifier loss: 0.307353; batch adversarial loss: 0.481654\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357831; batch adversarial loss: 0.545457\n",
      "epoch 102; iter: 0; batch classifier loss: 0.307038; batch adversarial loss: 0.507686\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413229; batch adversarial loss: 0.560678\n",
      "epoch 104; iter: 0; batch classifier loss: 0.454349; batch adversarial loss: 0.514548\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406264; batch adversarial loss: 0.597523\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398768; batch adversarial loss: 0.439019\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436197; batch adversarial loss: 0.553632\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377540; batch adversarial loss: 0.526599\n",
      "epoch 109; iter: 0; batch classifier loss: 0.429315; batch adversarial loss: 0.524966\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382587; batch adversarial loss: 0.600255\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427083; batch adversarial loss: 0.518966\n",
      "epoch 112; iter: 0; batch classifier loss: 0.439345; batch adversarial loss: 0.572671\n",
      "epoch 113; iter: 0; batch classifier loss: 0.376979; batch adversarial loss: 0.572471\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389509; batch adversarial loss: 0.490903\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355900; batch adversarial loss: 0.510523\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413911; batch adversarial loss: 0.534149\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348484; batch adversarial loss: 0.492587\n",
      "epoch 118; iter: 0; batch classifier loss: 0.329309; batch adversarial loss: 0.623787\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397533; batch adversarial loss: 0.526024\n",
      "epoch 120; iter: 0; batch classifier loss: 0.462243; batch adversarial loss: 0.586854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351774; batch adversarial loss: 0.561106\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404588; batch adversarial loss: 0.475756\n",
      "epoch 123; iter: 0; batch classifier loss: 0.434145; batch adversarial loss: 0.546655\n",
      "epoch 124; iter: 0; batch classifier loss: 0.344277; batch adversarial loss: 0.536542\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391174; batch adversarial loss: 0.533970\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405738; batch adversarial loss: 0.555826\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.543189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.406474; batch adversarial loss: 0.624174\n",
      "epoch 129; iter: 0; batch classifier loss: 0.433746; batch adversarial loss: 0.528064\n",
      "epoch 130; iter: 0; batch classifier loss: 0.409304; batch adversarial loss: 0.499348\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364145; batch adversarial loss: 0.544272\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351702; batch adversarial loss: 0.492061\n",
      "epoch 133; iter: 0; batch classifier loss: 0.401881; batch adversarial loss: 0.553649\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361320; batch adversarial loss: 0.596874\n",
      "epoch 135; iter: 0; batch classifier loss: 0.303936; batch adversarial loss: 0.579367\n",
      "epoch 136; iter: 0; batch classifier loss: 0.452094; batch adversarial loss: 0.570637\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386165; batch adversarial loss: 0.528115\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356245; batch adversarial loss: 0.543778\n",
      "epoch 139; iter: 0; batch classifier loss: 0.454681; batch adversarial loss: 0.554233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.445768; batch adversarial loss: 0.588806\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356955; batch adversarial loss: 0.648921\n",
      "epoch 142; iter: 0; batch classifier loss: 0.379643; batch adversarial loss: 0.572614\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408375; batch adversarial loss: 0.590543\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377339; batch adversarial loss: 0.597038\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332984; batch adversarial loss: 0.560845\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376129; batch adversarial loss: 0.559790\n",
      "epoch 147; iter: 0; batch classifier loss: 0.438918; batch adversarial loss: 0.577331\n",
      "epoch 148; iter: 0; batch classifier loss: 0.503534; batch adversarial loss: 0.551899\n",
      "epoch 149; iter: 0; batch classifier loss: 0.394597; batch adversarial loss: 0.585750\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353863; batch adversarial loss: 0.509498\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355414; batch adversarial loss: 0.528316\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350950; batch adversarial loss: 0.535531\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379583; batch adversarial loss: 0.605808\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360436; batch adversarial loss: 0.553499\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355514; batch adversarial loss: 0.573640\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368142; batch adversarial loss: 0.581413\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360658; batch adversarial loss: 0.563016\n",
      "epoch 158; iter: 0; batch classifier loss: 0.422633; batch adversarial loss: 0.578086\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347033; batch adversarial loss: 0.600336\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361043; batch adversarial loss: 0.544173\n",
      "epoch 161; iter: 0; batch classifier loss: 0.437786; batch adversarial loss: 0.509667\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334523; batch adversarial loss: 0.652332\n",
      "epoch 163; iter: 0; batch classifier loss: 0.428134; batch adversarial loss: 0.542518\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378089; batch adversarial loss: 0.455917\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388808; batch adversarial loss: 0.597926\n",
      "epoch 166; iter: 0; batch classifier loss: 0.481387; batch adversarial loss: 0.564821\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406016; batch adversarial loss: 0.537058\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342828; batch adversarial loss: 0.525157\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339217; batch adversarial loss: 0.574596\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366796; batch adversarial loss: 0.542706\n",
      "epoch 171; iter: 0; batch classifier loss: 0.309246; batch adversarial loss: 0.564239\n",
      "epoch 172; iter: 0; batch classifier loss: 0.413040; batch adversarial loss: 0.550231\n",
      "epoch 173; iter: 0; batch classifier loss: 0.517607; batch adversarial loss: 0.493857\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359215; batch adversarial loss: 0.554768\n",
      "epoch 175; iter: 0; batch classifier loss: 0.484824; batch adversarial loss: 0.543561\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381923; batch adversarial loss: 0.670892\n",
      "epoch 177; iter: 0; batch classifier loss: 0.439766; batch adversarial loss: 0.560943\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368098; batch adversarial loss: 0.632988\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359581; batch adversarial loss: 0.500357\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414563; batch adversarial loss: 0.507070\n",
      "epoch 181; iter: 0; batch classifier loss: 0.392496; batch adversarial loss: 0.572398\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361936; batch adversarial loss: 0.555238\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356209; batch adversarial loss: 0.571145\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343208; batch adversarial loss: 0.534070\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383366; batch adversarial loss: 0.608493\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359886; batch adversarial loss: 0.509915\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388011; batch adversarial loss: 0.555644\n",
      "epoch 188; iter: 0; batch classifier loss: 0.454814; batch adversarial loss: 0.508252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379581; batch adversarial loss: 0.501035\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333123; batch adversarial loss: 0.579987\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340586; batch adversarial loss: 0.580966\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317897; batch adversarial loss: 0.580139\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364105; batch adversarial loss: 0.537662\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356062; batch adversarial loss: 0.511475\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398522; batch adversarial loss: 0.508074\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356008; batch adversarial loss: 0.500541\n",
      "epoch 197; iter: 0; batch classifier loss: 0.503636; batch adversarial loss: 0.652436\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336057; batch adversarial loss: 0.572454\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353987; batch adversarial loss: 0.545216\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712472; batch adversarial loss: 0.710500\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518936; batch adversarial loss: 0.698418\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623904; batch adversarial loss: 0.669378\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542959; batch adversarial loss: 0.635791\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601312; batch adversarial loss: 0.593234\n",
      "epoch 5; iter: 0; batch classifier loss: 0.653244; batch adversarial loss: 0.609235\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513017; batch adversarial loss: 0.587911\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578982; batch adversarial loss: 0.595666\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566455; batch adversarial loss: 0.601480\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551567; batch adversarial loss: 0.586017\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528699; batch adversarial loss: 0.526472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568694; batch adversarial loss: 0.582433\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461708; batch adversarial loss: 0.580187\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504043; batch adversarial loss: 0.549536\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513409; batch adversarial loss: 0.576055\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525369; batch adversarial loss: 0.556080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.466427; batch adversarial loss: 0.559661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542042; batch adversarial loss: 0.543672\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521021; batch adversarial loss: 0.568067\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438773; batch adversarial loss: 0.543074\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518661; batch adversarial loss: 0.544975\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452889; batch adversarial loss: 0.521639\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490723; batch adversarial loss: 0.539990\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493063; batch adversarial loss: 0.571366\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427081; batch adversarial loss: 0.618921\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493455; batch adversarial loss: 0.589247\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487285; batch adversarial loss: 0.587281\n",
      "epoch 27; iter: 0; batch classifier loss: 0.384249; batch adversarial loss: 0.558755\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468168; batch adversarial loss: 0.640172\n",
      "epoch 29; iter: 0; batch classifier loss: 0.407892; batch adversarial loss: 0.541060\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453605; batch adversarial loss: 0.638561\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455516; batch adversarial loss: 0.555665\n",
      "epoch 32; iter: 0; batch classifier loss: 0.501314; batch adversarial loss: 0.545891\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435024; batch adversarial loss: 0.631446\n",
      "epoch 34; iter: 0; batch classifier loss: 0.555640; batch adversarial loss: 0.597057\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371641; batch adversarial loss: 0.527499\n",
      "epoch 36; iter: 0; batch classifier loss: 0.413065; batch adversarial loss: 0.553826\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500714; batch adversarial loss: 0.535286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.433648; batch adversarial loss: 0.516366\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425729; batch adversarial loss: 0.534186\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490127; batch adversarial loss: 0.542896\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418682; batch adversarial loss: 0.486464\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461340; batch adversarial loss: 0.608885\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491840; batch adversarial loss: 0.553339\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389276; batch adversarial loss: 0.475461\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401318; batch adversarial loss: 0.440715\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374579; batch adversarial loss: 0.507592\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403246; batch adversarial loss: 0.535628\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489312; batch adversarial loss: 0.535197\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389233; batch adversarial loss: 0.536535\n",
      "epoch 50; iter: 0; batch classifier loss: 0.367065; batch adversarial loss: 0.514224\n",
      "epoch 51; iter: 0; batch classifier loss: 0.356805; batch adversarial loss: 0.471074\n",
      "epoch 52; iter: 0; batch classifier loss: 0.317477; batch adversarial loss: 0.490321\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402453; batch adversarial loss: 0.527197\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447152; batch adversarial loss: 0.508652\n",
      "epoch 55; iter: 0; batch classifier loss: 0.346123; batch adversarial loss: 0.445373\n",
      "epoch 56; iter: 0; batch classifier loss: 0.365760; batch adversarial loss: 0.598207\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403193; batch adversarial loss: 0.561352\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398832; batch adversarial loss: 0.535615\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410210; batch adversarial loss: 0.543054\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440825; batch adversarial loss: 0.588281\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439200; batch adversarial loss: 0.533309\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429644; batch adversarial loss: 0.580592\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449721; batch adversarial loss: 0.460617\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440389; batch adversarial loss: 0.450241\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443355; batch adversarial loss: 0.536952\n",
      "epoch 66; iter: 0; batch classifier loss: 0.340321; batch adversarial loss: 0.571865\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361732; batch adversarial loss: 0.645265\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423338; batch adversarial loss: 0.561785\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400467; batch adversarial loss: 0.567617\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380078; batch adversarial loss: 0.529536\n",
      "epoch 71; iter: 0; batch classifier loss: 0.416054; batch adversarial loss: 0.518490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.359730; batch adversarial loss: 0.558742\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440551; batch adversarial loss: 0.544296\n",
      "epoch 74; iter: 0; batch classifier loss: 0.496028; batch adversarial loss: 0.516459\n",
      "epoch 75; iter: 0; batch classifier loss: 0.320045; batch adversarial loss: 0.537757\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393305; batch adversarial loss: 0.506917\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381876; batch adversarial loss: 0.570732\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411184; batch adversarial loss: 0.517071\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374992; batch adversarial loss: 0.581871\n",
      "epoch 80; iter: 0; batch classifier loss: 0.372112; batch adversarial loss: 0.593067\n",
      "epoch 81; iter: 0; batch classifier loss: 0.467188; batch adversarial loss: 0.620069\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399543; batch adversarial loss: 0.620186\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422830; batch adversarial loss: 0.554465\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382983; batch adversarial loss: 0.599588\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381742; batch adversarial loss: 0.517048\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358049; batch adversarial loss: 0.554270\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427316; batch adversarial loss: 0.544063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422449; batch adversarial loss: 0.571140\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436779; batch adversarial loss: 0.479106\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348031; batch adversarial loss: 0.507069\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382687; batch adversarial loss: 0.562813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377543; batch adversarial loss: 0.543657\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356955; batch adversarial loss: 0.554249\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419183; batch adversarial loss: 0.572722\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357799; batch adversarial loss: 0.497704\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.516914\n",
      "epoch 97; iter: 0; batch classifier loss: 0.333110; batch adversarial loss: 0.508377\n",
      "epoch 98; iter: 0; batch classifier loss: 0.412264; batch adversarial loss: 0.542167\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332139; batch adversarial loss: 0.564762\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386733; batch adversarial loss: 0.497994\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365299; batch adversarial loss: 0.602020\n",
      "epoch 102; iter: 0; batch classifier loss: 0.275510; batch adversarial loss: 0.526203\n",
      "epoch 103; iter: 0; batch classifier loss: 0.324190; batch adversarial loss: 0.564033\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361811; batch adversarial loss: 0.667455\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416771; batch adversarial loss: 0.534784\n",
      "epoch 106; iter: 0; batch classifier loss: 0.476639; batch adversarial loss: 0.601063\n",
      "epoch 107; iter: 0; batch classifier loss: 0.344163; batch adversarial loss: 0.554282\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379805; batch adversarial loss: 0.488364\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355416; batch adversarial loss: 0.553809\n",
      "epoch 110; iter: 0; batch classifier loss: 0.308882; batch adversarial loss: 0.600883\n",
      "epoch 111; iter: 0; batch classifier loss: 0.517961; batch adversarial loss: 0.591065\n",
      "epoch 112; iter: 0; batch classifier loss: 0.308493; batch adversarial loss: 0.488158\n",
      "epoch 113; iter: 0; batch classifier loss: 0.451974; batch adversarial loss: 0.506745\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354304; batch adversarial loss: 0.460153\n",
      "epoch 115; iter: 0; batch classifier loss: 0.300001; batch adversarial loss: 0.525767\n",
      "epoch 116; iter: 0; batch classifier loss: 0.435001; batch adversarial loss: 0.488317\n",
      "epoch 117; iter: 0; batch classifier loss: 0.305174; batch adversarial loss: 0.507300\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385813; batch adversarial loss: 0.572294\n",
      "epoch 119; iter: 0; batch classifier loss: 0.432356; batch adversarial loss: 0.590799\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360231; batch adversarial loss: 0.610044\n",
      "epoch 121; iter: 0; batch classifier loss: 0.323564; batch adversarial loss: 0.628764\n",
      "epoch 122; iter: 0; batch classifier loss: 0.317381; batch adversarial loss: 0.450971\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346114; batch adversarial loss: 0.619471\n",
      "epoch 124; iter: 0; batch classifier loss: 0.400978; batch adversarial loss: 0.535079\n",
      "epoch 125; iter: 0; batch classifier loss: 0.304350; batch adversarial loss: 0.572454\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396390; batch adversarial loss: 0.506444\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371796; batch adversarial loss: 0.517182\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410913; batch adversarial loss: 0.498829\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416642; batch adversarial loss: 0.516578\n",
      "epoch 130; iter: 0; batch classifier loss: 0.312787; batch adversarial loss: 0.518140\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362204; batch adversarial loss: 0.552968\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355374; batch adversarial loss: 0.546019\n",
      "epoch 133; iter: 0; batch classifier loss: 0.417123; batch adversarial loss: 0.602558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.348098; batch adversarial loss: 0.554465\n",
      "epoch 135; iter: 0; batch classifier loss: 0.302480; batch adversarial loss: 0.545660\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403239; batch adversarial loss: 0.571070\n",
      "epoch 137; iter: 0; batch classifier loss: 0.286614; batch adversarial loss: 0.506945\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402669; batch adversarial loss: 0.610027\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356733; batch adversarial loss: 0.488286\n",
      "epoch 140; iter: 0; batch classifier loss: 0.310253; batch adversarial loss: 0.497801\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424785; batch adversarial loss: 0.544562\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355621; batch adversarial loss: 0.601218\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348787; batch adversarial loss: 0.507097\n",
      "epoch 144; iter: 0; batch classifier loss: 0.316848; batch adversarial loss: 0.544361\n",
      "epoch 145; iter: 0; batch classifier loss: 0.274693; batch adversarial loss: 0.563070\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347623; batch adversarial loss: 0.553521\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347599; batch adversarial loss: 0.526220\n",
      "epoch 148; iter: 0; batch classifier loss: 0.404583; batch adversarial loss: 0.572722\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346398; batch adversarial loss: 0.544060\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399153; batch adversarial loss: 0.526313\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417257; batch adversarial loss: 0.488688\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340340; batch adversarial loss: 0.572466\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327168; batch adversarial loss: 0.600086\n",
      "epoch 154; iter: 0; batch classifier loss: 0.367956; batch adversarial loss: 0.533350\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394455; batch adversarial loss: 0.517263\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348331; batch adversarial loss: 0.625861\n",
      "epoch 157; iter: 0; batch classifier loss: 0.345420; batch adversarial loss: 0.554358\n",
      "epoch 158; iter: 0; batch classifier loss: 0.371600; batch adversarial loss: 0.509734\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338236; batch adversarial loss: 0.563522\n",
      "epoch 160; iter: 0; batch classifier loss: 0.391585; batch adversarial loss: 0.544724\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393477; batch adversarial loss: 0.507313\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326643; batch adversarial loss: 0.591605\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353364; batch adversarial loss: 0.478708\n",
      "epoch 164; iter: 0; batch classifier loss: 0.528890; batch adversarial loss: 0.517065\n",
      "epoch 165; iter: 0; batch classifier loss: 0.390729; batch adversarial loss: 0.544264\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324805; batch adversarial loss: 0.506840\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345873; batch adversarial loss: 0.638789\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337992; batch adversarial loss: 0.554887\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358206; batch adversarial loss: 0.545053\n",
      "epoch 170; iter: 0; batch classifier loss: 0.375835; batch adversarial loss: 0.582512\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351382; batch adversarial loss: 0.553978\n",
      "epoch 172; iter: 0; batch classifier loss: 0.386985; batch adversarial loss: 0.497323\n",
      "epoch 173; iter: 0; batch classifier loss: 0.290364; batch adversarial loss: 0.582282\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380747; batch adversarial loss: 0.507251\n",
      "epoch 175; iter: 0; batch classifier loss: 0.396610; batch adversarial loss: 0.516443\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334430; batch adversarial loss: 0.460213\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391596; batch adversarial loss: 0.581867\n",
      "epoch 178; iter: 0; batch classifier loss: 0.276828; batch adversarial loss: 0.563275\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402046; batch adversarial loss: 0.525795\n",
      "epoch 180; iter: 0; batch classifier loss: 0.266676; batch adversarial loss: 0.600303\n",
      "epoch 181; iter: 0; batch classifier loss: 0.324658; batch adversarial loss: 0.526149\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351915; batch adversarial loss: 0.562925\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311848; batch adversarial loss: 0.572738\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377845; batch adversarial loss: 0.599982\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342957; batch adversarial loss: 0.507379\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375418; batch adversarial loss: 0.637046\n",
      "epoch 187; iter: 0; batch classifier loss: 0.394357; batch adversarial loss: 0.469883\n",
      "epoch 188; iter: 0; batch classifier loss: 0.322503; batch adversarial loss: 0.507511\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366933; batch adversarial loss: 0.581532\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326456; batch adversarial loss: 0.525779\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359699; batch adversarial loss: 0.554660\n",
      "epoch 192; iter: 0; batch classifier loss: 0.322059; batch adversarial loss: 0.535765\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370649; batch adversarial loss: 0.581672\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333706; batch adversarial loss: 0.582530\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335159; batch adversarial loss: 0.535671\n",
      "epoch 196; iter: 0; batch classifier loss: 0.291969; batch adversarial loss: 0.563744\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347975; batch adversarial loss: 0.525012\n",
      "epoch 198; iter: 0; batch classifier loss: 0.286403; batch adversarial loss: 0.461225\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372294; batch adversarial loss: 0.637814\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692062; batch adversarial loss: 0.943728\n",
      "epoch 1; iter: 0; batch classifier loss: 0.760510; batch adversarial loss: 1.251236\n",
      "epoch 2; iter: 0; batch classifier loss: 0.874182; batch adversarial loss: 1.190860\n",
      "epoch 3; iter: 0; batch classifier loss: 1.023808; batch adversarial loss: 1.088721\n",
      "epoch 4; iter: 0; batch classifier loss: 0.954264; batch adversarial loss: 1.010811\n",
      "epoch 5; iter: 0; batch classifier loss: 0.995770; batch adversarial loss: 0.918260\n",
      "epoch 6; iter: 0; batch classifier loss: 0.665483; batch adversarial loss: 0.867268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.690849; batch adversarial loss: 0.783667\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590487; batch adversarial loss: 0.727273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.515419; batch adversarial loss: 0.638829\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547616; batch adversarial loss: 0.623568\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533021; batch adversarial loss: 0.616252\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540159; batch adversarial loss: 0.593186\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521566; batch adversarial loss: 0.580772\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576048; batch adversarial loss: 0.533282\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462568; batch adversarial loss: 0.648012\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459213; batch adversarial loss: 0.592391\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544603; batch adversarial loss: 0.587127\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527051; batch adversarial loss: 0.563981\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463777; batch adversarial loss: 0.629198\n",
      "epoch 20; iter: 0; batch classifier loss: 0.563937; batch adversarial loss: 0.580109\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493416; batch adversarial loss: 0.566932\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485967; batch adversarial loss: 0.550697\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481672; batch adversarial loss: 0.564421\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498022; batch adversarial loss: 0.517524\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535522; batch adversarial loss: 0.591744\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501570; batch adversarial loss: 0.519267\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439880; batch adversarial loss: 0.581260\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538995; batch adversarial loss: 0.591979\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521567; batch adversarial loss: 0.641090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.426420; batch adversarial loss: 0.566191\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480731; batch adversarial loss: 0.522548\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429303; batch adversarial loss: 0.507404\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531138; batch adversarial loss: 0.523415\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438673; batch adversarial loss: 0.566215\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470814; batch adversarial loss: 0.595418\n",
      "epoch 36; iter: 0; batch classifier loss: 0.367745; batch adversarial loss: 0.620283\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472014; batch adversarial loss: 0.542496\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440675; batch adversarial loss: 0.563646\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392391; batch adversarial loss: 0.534250\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472489; batch adversarial loss: 0.555862\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461377; batch adversarial loss: 0.609703\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470600; batch adversarial loss: 0.542319\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491734; batch adversarial loss: 0.564695\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484964; batch adversarial loss: 0.543105\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445250; batch adversarial loss: 0.597235\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410468; batch adversarial loss: 0.550354\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461693; batch adversarial loss: 0.572853\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485002; batch adversarial loss: 0.597481\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522765; batch adversarial loss: 0.561874\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493234; batch adversarial loss: 0.546895\n",
      "epoch 51; iter: 0; batch classifier loss: 0.498041; batch adversarial loss: 0.491684\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447295; batch adversarial loss: 0.493968\n",
      "epoch 53; iter: 0; batch classifier loss: 0.361537; batch adversarial loss: 0.544516\n",
      "epoch 54; iter: 0; batch classifier loss: 0.393236; batch adversarial loss: 0.535730\n",
      "epoch 55; iter: 0; batch classifier loss: 0.490498; batch adversarial loss: 0.589241\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400649; batch adversarial loss: 0.510149\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429277; batch adversarial loss: 0.545418\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422576; batch adversarial loss: 0.579505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.478331; batch adversarial loss: 0.588548\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397951; batch adversarial loss: 0.561187\n",
      "epoch 61; iter: 0; batch classifier loss: 0.450706; batch adversarial loss: 0.580590\n",
      "epoch 62; iter: 0; batch classifier loss: 0.497858; batch adversarial loss: 0.659122\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429252; batch adversarial loss: 0.597295\n",
      "epoch 64; iter: 0; batch classifier loss: 0.520075; batch adversarial loss: 0.599059\n",
      "epoch 65; iter: 0; batch classifier loss: 0.486428; batch adversarial loss: 0.562561\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396868; batch adversarial loss: 0.581779\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391246; batch adversarial loss: 0.560785\n",
      "epoch 68; iter: 0; batch classifier loss: 0.353918; batch adversarial loss: 0.544999\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383175; batch adversarial loss: 0.563130\n",
      "epoch 70; iter: 0; batch classifier loss: 0.472683; batch adversarial loss: 0.536969\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448730; batch adversarial loss: 0.600187\n",
      "epoch 72; iter: 0; batch classifier loss: 0.378413; batch adversarial loss: 0.544548\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402654; batch adversarial loss: 0.516145\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363429; batch adversarial loss: 0.526113\n",
      "epoch 75; iter: 0; batch classifier loss: 0.428653; batch adversarial loss: 0.528374\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407407; batch adversarial loss: 0.627011\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408204; batch adversarial loss: 0.457766\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382946; batch adversarial loss: 0.553565\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425640; batch adversarial loss: 0.544953\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418817; batch adversarial loss: 0.572426\n",
      "epoch 81; iter: 0; batch classifier loss: 0.439086; batch adversarial loss: 0.518603\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415173; batch adversarial loss: 0.598347\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367760; batch adversarial loss: 0.509436\n",
      "epoch 84; iter: 0; batch classifier loss: 0.394868; batch adversarial loss: 0.553937\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365786; batch adversarial loss: 0.588806\n",
      "epoch 86; iter: 0; batch classifier loss: 0.361177; batch adversarial loss: 0.518438\n",
      "epoch 87; iter: 0; batch classifier loss: 0.333567; batch adversarial loss: 0.598116\n",
      "epoch 88; iter: 0; batch classifier loss: 0.364860; batch adversarial loss: 0.536335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.337396; batch adversarial loss: 0.544781\n",
      "epoch 90; iter: 0; batch classifier loss: 0.308192; batch adversarial loss: 0.491196\n",
      "epoch 91; iter: 0; batch classifier loss: 0.316507; batch adversarial loss: 0.536126\n",
      "epoch 92; iter: 0; batch classifier loss: 0.295118; batch adversarial loss: 0.616495\n",
      "epoch 93; iter: 0; batch classifier loss: 0.358446; batch adversarial loss: 0.516505\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336048; batch adversarial loss: 0.536758\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416546; batch adversarial loss: 0.517759\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391219; batch adversarial loss: 0.507940\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365128; batch adversarial loss: 0.585506\n",
      "epoch 98; iter: 0; batch classifier loss: 0.467300; batch adversarial loss: 0.492361\n",
      "epoch 99; iter: 0; batch classifier loss: 0.334185; batch adversarial loss: 0.525810\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352480; batch adversarial loss: 0.603771\n",
      "epoch 101; iter: 0; batch classifier loss: 0.332768; batch adversarial loss: 0.538924\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331072; batch adversarial loss: 0.601165\n",
      "epoch 103; iter: 0; batch classifier loss: 0.420210; batch adversarial loss: 0.526940\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419558; batch adversarial loss: 0.597744\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405328; batch adversarial loss: 0.599174\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383877; batch adversarial loss: 0.564810\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355357; batch adversarial loss: 0.519239\n",
      "epoch 108; iter: 0; batch classifier loss: 0.376101; batch adversarial loss: 0.509666\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386128; batch adversarial loss: 0.527932\n",
      "epoch 110; iter: 0; batch classifier loss: 0.297223; batch adversarial loss: 0.651408\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362071; batch adversarial loss: 0.545644\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352254; batch adversarial loss: 0.546417\n",
      "epoch 113; iter: 0; batch classifier loss: 0.349197; batch adversarial loss: 0.491441\n",
      "epoch 114; iter: 0; batch classifier loss: 0.292120; batch adversarial loss: 0.542564\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387096; batch adversarial loss: 0.494866\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379420; batch adversarial loss: 0.508995\n",
      "epoch 117; iter: 0; batch classifier loss: 0.364699; batch adversarial loss: 0.538086\n",
      "epoch 118; iter: 0; batch classifier loss: 0.476573; batch adversarial loss: 0.568103\n",
      "epoch 119; iter: 0; batch classifier loss: 0.324880; batch adversarial loss: 0.607615\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343046; batch adversarial loss: 0.644781\n",
      "epoch 121; iter: 0; batch classifier loss: 0.417576; batch adversarial loss: 0.510880\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404301; batch adversarial loss: 0.549065\n",
      "epoch 123; iter: 0; batch classifier loss: 0.371065; batch adversarial loss: 0.548549\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334926; batch adversarial loss: 0.506369\n",
      "epoch 125; iter: 0; batch classifier loss: 0.424133; batch adversarial loss: 0.581409\n",
      "epoch 126; iter: 0; batch classifier loss: 0.297337; batch adversarial loss: 0.556084\n",
      "epoch 127; iter: 0; batch classifier loss: 0.331546; batch adversarial loss: 0.555569\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343908; batch adversarial loss: 0.622100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.314344; batch adversarial loss: 0.606069\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374845; batch adversarial loss: 0.537165\n",
      "epoch 131; iter: 0; batch classifier loss: 0.429547; batch adversarial loss: 0.519458\n",
      "epoch 132; iter: 0; batch classifier loss: 0.408735; batch adversarial loss: 0.519646\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355411; batch adversarial loss: 0.474854\n",
      "epoch 134; iter: 0; batch classifier loss: 0.281458; batch adversarial loss: 0.580650\n",
      "epoch 135; iter: 0; batch classifier loss: 0.476111; batch adversarial loss: 0.560146\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346527; batch adversarial loss: 0.598061\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321901; batch adversarial loss: 0.535149\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377398; batch adversarial loss: 0.508484\n",
      "epoch 139; iter: 0; batch classifier loss: 0.325012; batch adversarial loss: 0.507734\n",
      "epoch 140; iter: 0; batch classifier loss: 0.420087; batch adversarial loss: 0.610980\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420956; batch adversarial loss: 0.674474\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334883; batch adversarial loss: 0.538459\n",
      "epoch 143; iter: 0; batch classifier loss: 0.392827; batch adversarial loss: 0.511331\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302007; batch adversarial loss: 0.561997\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327775; batch adversarial loss: 0.553965\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337912; batch adversarial loss: 0.537507\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345996; batch adversarial loss: 0.589203\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403745; batch adversarial loss: 0.605474\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355207; batch adversarial loss: 0.484143\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372993; batch adversarial loss: 0.561975\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354273; batch adversarial loss: 0.536054\n",
      "epoch 152; iter: 0; batch classifier loss: 0.416941; batch adversarial loss: 0.544770\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367442; batch adversarial loss: 0.474875\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390075; batch adversarial loss: 0.579676\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396950; batch adversarial loss: 0.535636\n",
      "epoch 156; iter: 0; batch classifier loss: 0.335294; batch adversarial loss: 0.517972\n",
      "epoch 157; iter: 0; batch classifier loss: 0.461366; batch adversarial loss: 0.598280\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332091; batch adversarial loss: 0.544212\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350802; batch adversarial loss: 0.499891\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334429; batch adversarial loss: 0.509041\n",
      "epoch 161; iter: 0; batch classifier loss: 0.470119; batch adversarial loss: 0.535829\n",
      "epoch 162; iter: 0; batch classifier loss: 0.346137; batch adversarial loss: 0.570977\n",
      "epoch 163; iter: 0; batch classifier loss: 0.407609; batch adversarial loss: 0.509960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341654; batch adversarial loss: 0.544066\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321795; batch adversarial loss: 0.588409\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377049; batch adversarial loss: 0.552197\n",
      "epoch 167; iter: 0; batch classifier loss: 0.425685; batch adversarial loss: 0.534329\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333993; batch adversarial loss: 0.622814\n",
      "epoch 169; iter: 0; batch classifier loss: 0.280683; batch adversarial loss: 0.497718\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371357; batch adversarial loss: 0.527886\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401861; batch adversarial loss: 0.618903\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330883; batch adversarial loss: 0.525915\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335999; batch adversarial loss: 0.579704\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350825; batch adversarial loss: 0.545087\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359188; batch adversarial loss: 0.545799\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338286; batch adversarial loss: 0.586338\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386770; batch adversarial loss: 0.579931\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340618; batch adversarial loss: 0.589021\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395837; batch adversarial loss: 0.570017\n",
      "epoch 180; iter: 0; batch classifier loss: 0.427055; batch adversarial loss: 0.571744\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328701; batch adversarial loss: 0.561921\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304352; batch adversarial loss: 0.606563\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365350; batch adversarial loss: 0.623212\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342036; batch adversarial loss: 0.508664\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339138; batch adversarial loss: 0.527900\n",
      "epoch 186; iter: 0; batch classifier loss: 0.410475; batch adversarial loss: 0.545051\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317333; batch adversarial loss: 0.579617\n",
      "epoch 188; iter: 0; batch classifier loss: 0.300801; batch adversarial loss: 0.562459\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354035; batch adversarial loss: 0.579804\n",
      "epoch 190; iter: 0; batch classifier loss: 0.411421; batch adversarial loss: 0.517909\n",
      "epoch 191; iter: 0; batch classifier loss: 0.311465; batch adversarial loss: 0.579865\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330058; batch adversarial loss: 0.571833\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378271; batch adversarial loss: 0.589283\n",
      "epoch 194; iter: 0; batch classifier loss: 0.270300; batch adversarial loss: 0.500389\n",
      "epoch 195; iter: 0; batch classifier loss: 0.279271; batch adversarial loss: 0.527247\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341877; batch adversarial loss: 0.570526\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362788; batch adversarial loss: 0.571215\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372358; batch adversarial loss: 0.598113\n",
      "epoch 199; iter: 0; batch classifier loss: 0.288442; batch adversarial loss: 0.598388\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719188; batch adversarial loss: 0.858301\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598124; batch adversarial loss: 0.897955\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627428; batch adversarial loss: 0.797132\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548960; batch adversarial loss: 0.747631\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568127; batch adversarial loss: 0.697648\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466825; batch adversarial loss: 0.670980\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547496; batch adversarial loss: 0.648698\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601737; batch adversarial loss: 0.646819\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535840; batch adversarial loss: 0.601602\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522765; batch adversarial loss: 0.634644\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501675; batch adversarial loss: 0.599648\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456302; batch adversarial loss: 0.545749\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527609; batch adversarial loss: 0.566112\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495409; batch adversarial loss: 0.580893\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591425; batch adversarial loss: 0.580775\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457120; batch adversarial loss: 0.586489\n",
      "epoch 16; iter: 0; batch classifier loss: 0.558685; batch adversarial loss: 0.525398\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513000; batch adversarial loss: 0.520854\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524811; batch adversarial loss: 0.524148\n",
      "epoch 19; iter: 0; batch classifier loss: 0.466721; batch adversarial loss: 0.568209\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485281; batch adversarial loss: 0.528897\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526744; batch adversarial loss: 0.472767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.439318; batch adversarial loss: 0.591597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476649; batch adversarial loss: 0.524935\n",
      "epoch 24; iter: 0; batch classifier loss: 0.566658; batch adversarial loss: 0.545173\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483134; batch adversarial loss: 0.587458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.461426; batch adversarial loss: 0.595125\n",
      "epoch 27; iter: 0; batch classifier loss: 0.544540; batch adversarial loss: 0.627203\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479327; batch adversarial loss: 0.592628\n",
      "epoch 29; iter: 0; batch classifier loss: 0.417673; batch adversarial loss: 0.505743\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396684; batch adversarial loss: 0.544962\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508202; batch adversarial loss: 0.570509\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496847; batch adversarial loss: 0.513320\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469826; batch adversarial loss: 0.595302\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509585; batch adversarial loss: 0.545412\n",
      "epoch 35; iter: 0; batch classifier loss: 0.540604; batch adversarial loss: 0.535873\n",
      "epoch 36; iter: 0; batch classifier loss: 0.528618; batch adversarial loss: 0.533825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406913; batch adversarial loss: 0.575342\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454667; batch adversarial loss: 0.483117\n",
      "epoch 39; iter: 0; batch classifier loss: 0.496497; batch adversarial loss: 0.562768\n",
      "epoch 40; iter: 0; batch classifier loss: 0.589677; batch adversarial loss: 0.528391\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427699; batch adversarial loss: 0.601073\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454705; batch adversarial loss: 0.563737\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377245; batch adversarial loss: 0.508810\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404962; batch adversarial loss: 0.544580\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413054; batch adversarial loss: 0.451012\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400339; batch adversarial loss: 0.563775\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427732; batch adversarial loss: 0.470352\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440630; batch adversarial loss: 0.544376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.508855; batch adversarial loss: 0.572897\n",
      "epoch 50; iter: 0; batch classifier loss: 0.487896; batch adversarial loss: 0.526245\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421829; batch adversarial loss: 0.478418\n",
      "epoch 52; iter: 0; batch classifier loss: 0.364000; batch adversarial loss: 0.545484\n",
      "epoch 53; iter: 0; batch classifier loss: 0.473911; batch adversarial loss: 0.515603\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429881; batch adversarial loss: 0.506894\n",
      "epoch 55; iter: 0; batch classifier loss: 0.371109; batch adversarial loss: 0.581899\n",
      "epoch 56; iter: 0; batch classifier loss: 0.462562; batch adversarial loss: 0.591994\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370765; batch adversarial loss: 0.516396\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402221; batch adversarial loss: 0.525636\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438858; batch adversarial loss: 0.506524\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446184; batch adversarial loss: 0.516091\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439696; batch adversarial loss: 0.544791\n",
      "epoch 62; iter: 0; batch classifier loss: 0.471285; batch adversarial loss: 0.553964\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408148; batch adversarial loss: 0.544085\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418277; batch adversarial loss: 0.554008\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412005; batch adversarial loss: 0.457888\n",
      "epoch 66; iter: 0; batch classifier loss: 0.490291; batch adversarial loss: 0.601407\n",
      "epoch 67; iter: 0; batch classifier loss: 0.517169; batch adversarial loss: 0.592639\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439361; batch adversarial loss: 0.573180\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432011; batch adversarial loss: 0.496971\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427117; batch adversarial loss: 0.410415\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403069; batch adversarial loss: 0.525987\n",
      "epoch 72; iter: 0; batch classifier loss: 0.361619; batch adversarial loss: 0.506249\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437234; batch adversarial loss: 0.506286\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428626; batch adversarial loss: 0.487339\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381154; batch adversarial loss: 0.487351\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369209; batch adversarial loss: 0.505341\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434093; batch adversarial loss: 0.544641\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356018; batch adversarial loss: 0.535720\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349596; batch adversarial loss: 0.438523\n",
      "epoch 80; iter: 0; batch classifier loss: 0.309476; batch adversarial loss: 0.447739\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417730; batch adversarial loss: 0.553793\n",
      "epoch 82; iter: 0; batch classifier loss: 0.380325; batch adversarial loss: 0.516711\n",
      "epoch 83; iter: 0; batch classifier loss: 0.506283; batch adversarial loss: 0.583120\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435986; batch adversarial loss: 0.554205\n",
      "epoch 85; iter: 0; batch classifier loss: 0.315395; batch adversarial loss: 0.495951\n",
      "epoch 86; iter: 0; batch classifier loss: 0.290529; batch adversarial loss: 0.611521\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368911; batch adversarial loss: 0.545168\n",
      "epoch 88; iter: 0; batch classifier loss: 0.480015; batch adversarial loss: 0.516110\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432383; batch adversarial loss: 0.447411\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367000; batch adversarial loss: 0.525241\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362577; batch adversarial loss: 0.526730\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376929; batch adversarial loss: 0.496192\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377371; batch adversarial loss: 0.506317\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381661; batch adversarial loss: 0.467889\n",
      "epoch 95; iter: 0; batch classifier loss: 0.444908; batch adversarial loss: 0.534650\n",
      "epoch 96; iter: 0; batch classifier loss: 0.393552; batch adversarial loss: 0.457158\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436519; batch adversarial loss: 0.515414\n",
      "epoch 98; iter: 0; batch classifier loss: 0.500779; batch adversarial loss: 0.506042\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398317; batch adversarial loss: 0.506641\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376980; batch adversarial loss: 0.611489\n",
      "epoch 101; iter: 0; batch classifier loss: 0.437212; batch adversarial loss: 0.486527\n",
      "epoch 102; iter: 0; batch classifier loss: 0.480208; batch adversarial loss: 0.544761\n",
      "epoch 103; iter: 0; batch classifier loss: 0.343285; batch adversarial loss: 0.631202\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371769; batch adversarial loss: 0.621778\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401190; batch adversarial loss: 0.505075\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377269; batch adversarial loss: 0.564349\n",
      "epoch 107; iter: 0; batch classifier loss: 0.444358; batch adversarial loss: 0.654287\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399804; batch adversarial loss: 0.516786\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352128; batch adversarial loss: 0.535092\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439829; batch adversarial loss: 0.555700\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378072; batch adversarial loss: 0.511148\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414739; batch adversarial loss: 0.560771\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375118; batch adversarial loss: 0.572588\n",
      "epoch 114; iter: 0; batch classifier loss: 0.440107; batch adversarial loss: 0.544854\n",
      "epoch 115; iter: 0; batch classifier loss: 0.415788; batch adversarial loss: 0.528195\n",
      "epoch 116; iter: 0; batch classifier loss: 0.416764; batch adversarial loss: 0.673557\n",
      "epoch 117; iter: 0; batch classifier loss: 0.364177; batch adversarial loss: 0.527529\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393358; batch adversarial loss: 0.506350\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387156; batch adversarial loss: 0.517005\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358353; batch adversarial loss: 0.526960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.292583; batch adversarial loss: 0.592941\n",
      "epoch 122; iter: 0; batch classifier loss: 0.443172; batch adversarial loss: 0.506481\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346604; batch adversarial loss: 0.477342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.318225; batch adversarial loss: 0.536442\n",
      "epoch 125; iter: 0; batch classifier loss: 0.322129; batch adversarial loss: 0.497756\n",
      "epoch 126; iter: 0; batch classifier loss: 0.423290; batch adversarial loss: 0.544944\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358131; batch adversarial loss: 0.639460\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396968; batch adversarial loss: 0.496910\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379788; batch adversarial loss: 0.534803\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355445; batch adversarial loss: 0.525520\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385032; batch adversarial loss: 0.535151\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318121; batch adversarial loss: 0.602108\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362609; batch adversarial loss: 0.525123\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374891; batch adversarial loss: 0.516101\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413402; batch adversarial loss: 0.602324\n",
      "epoch 136; iter: 0; batch classifier loss: 0.423191; batch adversarial loss: 0.534666\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340111; batch adversarial loss: 0.525550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.406071; batch adversarial loss: 0.506993\n",
      "epoch 139; iter: 0; batch classifier loss: 0.437480; batch adversarial loss: 0.554563\n",
      "epoch 140; iter: 0; batch classifier loss: 0.367309; batch adversarial loss: 0.533664\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334263; batch adversarial loss: 0.563222\n",
      "epoch 142; iter: 0; batch classifier loss: 0.404808; batch adversarial loss: 0.515727\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360214; batch adversarial loss: 0.485375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347423; batch adversarial loss: 0.543467\n",
      "epoch 145; iter: 0; batch classifier loss: 0.414404; batch adversarial loss: 0.555242\n",
      "epoch 146; iter: 0; batch classifier loss: 0.424861; batch adversarial loss: 0.523854\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373293; batch adversarial loss: 0.584278\n",
      "epoch 148; iter: 0; batch classifier loss: 0.304919; batch adversarial loss: 0.546170\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336175; batch adversarial loss: 0.507573\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339950; batch adversarial loss: 0.506672\n",
      "epoch 151; iter: 0; batch classifier loss: 0.411051; batch adversarial loss: 0.440312\n",
      "epoch 152; iter: 0; batch classifier loss: 0.282774; batch adversarial loss: 0.515703\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405319; batch adversarial loss: 0.563567\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349815; batch adversarial loss: 0.546645\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323776; batch adversarial loss: 0.513968\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371898; batch adversarial loss: 0.511649\n",
      "epoch 157; iter: 0; batch classifier loss: 0.281171; batch adversarial loss: 0.561808\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365821; batch adversarial loss: 0.564902\n",
      "epoch 159; iter: 0; batch classifier loss: 0.330994; batch adversarial loss: 0.501994\n",
      "epoch 160; iter: 0; batch classifier loss: 0.310944; batch adversarial loss: 0.480905\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391967; batch adversarial loss: 0.602879\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349920; batch adversarial loss: 0.450632\n",
      "epoch 163; iter: 0; batch classifier loss: 0.409879; batch adversarial loss: 0.435085\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385928; batch adversarial loss: 0.527108\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374558; batch adversarial loss: 0.524767\n",
      "epoch 166; iter: 0; batch classifier loss: 0.286969; batch adversarial loss: 0.556791\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342836; batch adversarial loss: 0.531895\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363476; batch adversarial loss: 0.516191\n",
      "epoch 169; iter: 0; batch classifier loss: 0.278624; batch adversarial loss: 0.507911\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319486; batch adversarial loss: 0.468639\n",
      "epoch 171; iter: 0; batch classifier loss: 0.356168; batch adversarial loss: 0.473635\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389798; batch adversarial loss: 0.585341\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354268; batch adversarial loss: 0.515771\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392286; batch adversarial loss: 0.634708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316381; batch adversarial loss: 0.487377\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308015; batch adversarial loss: 0.525445\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375709; batch adversarial loss: 0.603847\n",
      "epoch 178; iter: 0; batch classifier loss: 0.406408; batch adversarial loss: 0.515743\n",
      "epoch 179; iter: 0; batch classifier loss: 0.401004; batch adversarial loss: 0.595213\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367336; batch adversarial loss: 0.576285\n",
      "epoch 181; iter: 0; batch classifier loss: 0.236734; batch adversarial loss: 0.564905\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344096; batch adversarial loss: 0.545605\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369717; batch adversarial loss: 0.562601\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367925; batch adversarial loss: 0.524431\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333809; batch adversarial loss: 0.495718\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308595; batch adversarial loss: 0.553941\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370339; batch adversarial loss: 0.563224\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379956; batch adversarial loss: 0.554350\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351407; batch adversarial loss: 0.506048\n",
      "epoch 190; iter: 0; batch classifier loss: 0.451520; batch adversarial loss: 0.580349\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389287; batch adversarial loss: 0.467675\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375866; batch adversarial loss: 0.525246\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333466; batch adversarial loss: 0.459010\n",
      "epoch 194; iter: 0; batch classifier loss: 0.413612; batch adversarial loss: 0.552793\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336247; batch adversarial loss: 0.545110\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327078; batch adversarial loss: 0.602296\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364310; batch adversarial loss: 0.524961\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317915; batch adversarial loss: 0.515761\n",
      "epoch 199; iter: 0; batch classifier loss: 0.284417; batch adversarial loss: 0.600040\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698141; batch adversarial loss: 0.712053\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593868; batch adversarial loss: 0.685741\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567824; batch adversarial loss: 0.652219\n",
      "epoch 3; iter: 0; batch classifier loss: 0.571671; batch adversarial loss: 0.641730\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646260; batch adversarial loss: 0.634077\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616994; batch adversarial loss: 0.630914\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588871; batch adversarial loss: 0.617800\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499411; batch adversarial loss: 0.596160\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490684; batch adversarial loss: 0.604290\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461415; batch adversarial loss: 0.614425\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536884; batch adversarial loss: 0.654341\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564267; batch adversarial loss: 0.566779\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498228; batch adversarial loss: 0.590037\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549792; batch adversarial loss: 0.581464\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524710; batch adversarial loss: 0.594750\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485578; batch adversarial loss: 0.595255\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547308; batch adversarial loss: 0.558157\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515936; batch adversarial loss: 0.565031\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513783; batch adversarial loss: 0.552904\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500303; batch adversarial loss: 0.555798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.484029; batch adversarial loss: 0.574618\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436694; batch adversarial loss: 0.549916\n",
      "epoch 22; iter: 0; batch classifier loss: 0.539760; batch adversarial loss: 0.580869\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464491; batch adversarial loss: 0.572844\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445749; batch adversarial loss: 0.559337\n",
      "epoch 25; iter: 0; batch classifier loss: 0.422464; batch adversarial loss: 0.663430\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498467; batch adversarial loss: 0.549386\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462547; batch adversarial loss: 0.565180\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510721; batch adversarial loss: 0.564196\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463437; batch adversarial loss: 0.513425\n",
      "epoch 30; iter: 0; batch classifier loss: 0.532559; batch adversarial loss: 0.579580\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398656; batch adversarial loss: 0.562818\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458041; batch adversarial loss: 0.579932\n",
      "epoch 33; iter: 0; batch classifier loss: 0.539335; batch adversarial loss: 0.595493\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422555; batch adversarial loss: 0.527333\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472854; batch adversarial loss: 0.579498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422027; batch adversarial loss: 0.638953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450272; batch adversarial loss: 0.569242\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455875; batch adversarial loss: 0.562068\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439704; batch adversarial loss: 0.604263\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444193; batch adversarial loss: 0.544256\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445756; batch adversarial loss: 0.561643\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445278; batch adversarial loss: 0.439482\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436013; batch adversarial loss: 0.607442\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435505; batch adversarial loss: 0.561906\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498663; batch adversarial loss: 0.518919\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446563; batch adversarial loss: 0.641473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430305; batch adversarial loss: 0.607769\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418670; batch adversarial loss: 0.562601\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399429; batch adversarial loss: 0.474200\n",
      "epoch 50; iter: 0; batch classifier loss: 0.500782; batch adversarial loss: 0.623124\n",
      "epoch 51; iter: 0; batch classifier loss: 0.495019; batch adversarial loss: 0.616829\n",
      "epoch 52; iter: 0; batch classifier loss: 0.359197; batch adversarial loss: 0.501278\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470237; batch adversarial loss: 0.640510\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431341; batch adversarial loss: 0.572293\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423428; batch adversarial loss: 0.579361\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410491; batch adversarial loss: 0.536240\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456726; batch adversarial loss: 0.594554\n",
      "epoch 58; iter: 0; batch classifier loss: 0.364554; batch adversarial loss: 0.484637\n",
      "epoch 59; iter: 0; batch classifier loss: 0.389842; batch adversarial loss: 0.560894\n",
      "epoch 60; iter: 0; batch classifier loss: 0.551152; batch adversarial loss: 0.447859\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380461; batch adversarial loss: 0.535136\n",
      "epoch 62; iter: 0; batch classifier loss: 0.414762; batch adversarial loss: 0.527169\n",
      "epoch 63; iter: 0; batch classifier loss: 0.405294; batch adversarial loss: 0.580892\n",
      "epoch 64; iter: 0; batch classifier loss: 0.483366; batch adversarial loss: 0.543430\n",
      "epoch 65; iter: 0; batch classifier loss: 0.372423; batch adversarial loss: 0.544574\n",
      "epoch 66; iter: 0; batch classifier loss: 0.450665; batch adversarial loss: 0.552765\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401590; batch adversarial loss: 0.570013\n",
      "epoch 68; iter: 0; batch classifier loss: 0.351471; batch adversarial loss: 0.541044\n",
      "epoch 69; iter: 0; batch classifier loss: 0.511086; batch adversarial loss: 0.469860\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459322; batch adversarial loss: 0.517961\n",
      "epoch 71; iter: 0; batch classifier loss: 0.441371; batch adversarial loss: 0.603537\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412222; batch adversarial loss: 0.572449\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378060; batch adversarial loss: 0.616669\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393234; batch adversarial loss: 0.549926\n",
      "epoch 75; iter: 0; batch classifier loss: 0.469221; batch adversarial loss: 0.588853\n",
      "epoch 76; iter: 0; batch classifier loss: 0.435984; batch adversarial loss: 0.546667\n",
      "epoch 77; iter: 0; batch classifier loss: 0.312265; batch adversarial loss: 0.528253\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441157; batch adversarial loss: 0.596282\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355047; batch adversarial loss: 0.593354\n",
      "epoch 80; iter: 0; batch classifier loss: 0.341576; batch adversarial loss: 0.549227\n",
      "epoch 81; iter: 0; batch classifier loss: 0.352091; batch adversarial loss: 0.534693\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421505; batch adversarial loss: 0.588104\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382961; batch adversarial loss: 0.590261\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435274; batch adversarial loss: 0.449120\n",
      "epoch 85; iter: 0; batch classifier loss: 0.495246; batch adversarial loss: 0.563572\n",
      "epoch 86; iter: 0; batch classifier loss: 0.422672; batch adversarial loss: 0.631945\n",
      "epoch 87; iter: 0; batch classifier loss: 0.510750; batch adversarial loss: 0.498634\n",
      "epoch 88; iter: 0; batch classifier loss: 0.432020; batch adversarial loss: 0.546782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365154; batch adversarial loss: 0.554124\n",
      "epoch 90; iter: 0; batch classifier loss: 0.490763; batch adversarial loss: 0.537446\n",
      "epoch 91; iter: 0; batch classifier loss: 0.341643; batch adversarial loss: 0.568927\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412864; batch adversarial loss: 0.435986\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455199; batch adversarial loss: 0.565329\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357556; batch adversarial loss: 0.537116\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358525; batch adversarial loss: 0.541040\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374778; batch adversarial loss: 0.535063\n",
      "epoch 97; iter: 0; batch classifier loss: 0.345021; batch adversarial loss: 0.613310\n",
      "epoch 98; iter: 0; batch classifier loss: 0.336975; batch adversarial loss: 0.542125\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364210; batch adversarial loss: 0.562634\n",
      "epoch 100; iter: 0; batch classifier loss: 0.465295; batch adversarial loss: 0.588786\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411658; batch adversarial loss: 0.577880\n",
      "epoch 102; iter: 0; batch classifier loss: 0.442076; batch adversarial loss: 0.571100\n",
      "epoch 103; iter: 0; batch classifier loss: 0.338993; batch adversarial loss: 0.539134\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423768; batch adversarial loss: 0.546603\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410850; batch adversarial loss: 0.541533\n",
      "epoch 106; iter: 0; batch classifier loss: 0.329650; batch adversarial loss: 0.630651\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.643595\n",
      "epoch 108; iter: 0; batch classifier loss: 0.468226; batch adversarial loss: 0.565751\n",
      "epoch 109; iter: 0; batch classifier loss: 0.441045; batch adversarial loss: 0.469982\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426795; batch adversarial loss: 0.584616\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407577; batch adversarial loss: 0.541194\n",
      "epoch 112; iter: 0; batch classifier loss: 0.380031; batch adversarial loss: 0.560929\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405999; batch adversarial loss: 0.567236\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426700; batch adversarial loss: 0.518378\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372622; batch adversarial loss: 0.524239\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361150; batch adversarial loss: 0.551777\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384108; batch adversarial loss: 0.510415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.408981; batch adversarial loss: 0.651633\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356452; batch adversarial loss: 0.526312\n",
      "epoch 120; iter: 0; batch classifier loss: 0.347297; batch adversarial loss: 0.642011\n",
      "epoch 121; iter: 0; batch classifier loss: 0.498616; batch adversarial loss: 0.561714\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366491; batch adversarial loss: 0.582236\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329911; batch adversarial loss: 0.570171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.516100; batch adversarial loss: 0.605774\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397138; batch adversarial loss: 0.521256\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394282; batch adversarial loss: 0.557760\n",
      "epoch 127; iter: 0; batch classifier loss: 0.454759; batch adversarial loss: 0.556992\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397081; batch adversarial loss: 0.507857\n",
      "epoch 129; iter: 0; batch classifier loss: 0.440919; batch adversarial loss: 0.534924\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371249; batch adversarial loss: 0.594043\n",
      "epoch 131; iter: 0; batch classifier loss: 0.460611; batch adversarial loss: 0.537520\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357780; batch adversarial loss: 0.568954\n",
      "epoch 133; iter: 0; batch classifier loss: 0.449022; batch adversarial loss: 0.606508\n",
      "epoch 134; iter: 0; batch classifier loss: 0.313262; batch adversarial loss: 0.585134\n",
      "epoch 135; iter: 0; batch classifier loss: 0.305317; batch adversarial loss: 0.486946\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395703; batch adversarial loss: 0.499493\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388606; batch adversarial loss: 0.584861\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314045; batch adversarial loss: 0.508723\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416363; batch adversarial loss: 0.523846\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334168; batch adversarial loss: 0.528062\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367843; batch adversarial loss: 0.544187\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326575; batch adversarial loss: 0.569678\n",
      "epoch 143; iter: 0; batch classifier loss: 0.398266; batch adversarial loss: 0.553181\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356193; batch adversarial loss: 0.573028\n",
      "epoch 145; iter: 0; batch classifier loss: 0.394301; batch adversarial loss: 0.492132\n",
      "epoch 146; iter: 0; batch classifier loss: 0.356092; batch adversarial loss: 0.491708\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387417; batch adversarial loss: 0.493079\n",
      "epoch 148; iter: 0; batch classifier loss: 0.307606; batch adversarial loss: 0.557436\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388643; batch adversarial loss: 0.507635\n",
      "epoch 150; iter: 0; batch classifier loss: 0.335861; batch adversarial loss: 0.533977\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415793; batch adversarial loss: 0.520796\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349377; batch adversarial loss: 0.602126\n",
      "epoch 153; iter: 0; batch classifier loss: 0.347014; batch adversarial loss: 0.549102\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342002; batch adversarial loss: 0.562494\n",
      "epoch 155; iter: 0; batch classifier loss: 0.393067; batch adversarial loss: 0.549128\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340920; batch adversarial loss: 0.544330\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346484; batch adversarial loss: 0.563410\n",
      "epoch 158; iter: 0; batch classifier loss: 0.418150; batch adversarial loss: 0.593341\n",
      "epoch 159; iter: 0; batch classifier loss: 0.315171; batch adversarial loss: 0.494181\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357235; batch adversarial loss: 0.508732\n",
      "epoch 161; iter: 0; batch classifier loss: 0.464226; batch adversarial loss: 0.594142\n",
      "epoch 162; iter: 0; batch classifier loss: 0.433818; batch adversarial loss: 0.550433\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339978; batch adversarial loss: 0.553752\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345100; batch adversarial loss: 0.563765\n",
      "epoch 165; iter: 0; batch classifier loss: 0.354191; batch adversarial loss: 0.564541\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362177; batch adversarial loss: 0.571880\n",
      "epoch 167; iter: 0; batch classifier loss: 0.409449; batch adversarial loss: 0.556680\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332722; batch adversarial loss: 0.544151\n",
      "epoch 169; iter: 0; batch classifier loss: 0.418273; batch adversarial loss: 0.597650\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395997; batch adversarial loss: 0.612152\n",
      "epoch 171; iter: 0; batch classifier loss: 0.272840; batch adversarial loss: 0.496106\n",
      "epoch 172; iter: 0; batch classifier loss: 0.406781; batch adversarial loss: 0.546006\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315736; batch adversarial loss: 0.661778\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325564; batch adversarial loss: 0.608327\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380856; batch adversarial loss: 0.509179\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384419; batch adversarial loss: 0.547012\n",
      "epoch 177; iter: 0; batch classifier loss: 0.405544; batch adversarial loss: 0.551744\n",
      "epoch 178; iter: 0; batch classifier loss: 0.290290; batch adversarial loss: 0.656289\n",
      "epoch 179; iter: 0; batch classifier loss: 0.422901; batch adversarial loss: 0.523572\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367961; batch adversarial loss: 0.488789\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342555; batch adversarial loss: 0.515114\n",
      "epoch 182; iter: 0; batch classifier loss: 0.386707; batch adversarial loss: 0.600741\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330550; batch adversarial loss: 0.590202\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350898; batch adversarial loss: 0.515233\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369685; batch adversarial loss: 0.479698\n",
      "epoch 186; iter: 0; batch classifier loss: 0.345034; batch adversarial loss: 0.607229\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385009; batch adversarial loss: 0.563227\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314004; batch adversarial loss: 0.559793\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352590; batch adversarial loss: 0.644449\n",
      "epoch 190; iter: 0; batch classifier loss: 0.416862; batch adversarial loss: 0.535307\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330667; batch adversarial loss: 0.521845\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399531; batch adversarial loss: 0.600745\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341230; batch adversarial loss: 0.616285\n",
      "epoch 194; iter: 0; batch classifier loss: 0.300363; batch adversarial loss: 0.530042\n",
      "epoch 195; iter: 0; batch classifier loss: 0.385866; batch adversarial loss: 0.552394\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381275; batch adversarial loss: 0.548974\n",
      "epoch 197; iter: 0; batch classifier loss: 0.442023; batch adversarial loss: 0.542001\n",
      "epoch 198; iter: 0; batch classifier loss: 0.394789; batch adversarial loss: 0.548439\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359252; batch adversarial loss: 0.491641\n",
      "epoch 0; iter: 0; batch classifier loss: 0.766676; batch adversarial loss: 0.922625\n",
      "epoch 1; iter: 0; batch classifier loss: 0.791784; batch adversarial loss: 0.937587\n",
      "epoch 2; iter: 0; batch classifier loss: 0.833082; batch adversarial loss: 0.900026\n",
      "epoch 3; iter: 0; batch classifier loss: 0.935283; batch adversarial loss: 0.824477\n",
      "epoch 4; iter: 0; batch classifier loss: 1.103522; batch adversarial loss: 0.761780\n",
      "epoch 5; iter: 0; batch classifier loss: 0.884066; batch adversarial loss: 0.699291\n",
      "epoch 6; iter: 0; batch classifier loss: 0.870888; batch adversarial loss: 0.665210\n",
      "epoch 7; iter: 0; batch classifier loss: 0.697168; batch adversarial loss: 0.623511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.593042; batch adversarial loss: 0.594823\n",
      "epoch 9; iter: 0; batch classifier loss: 0.652668; batch adversarial loss: 0.590389\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519543; batch adversarial loss: 0.550728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588041; batch adversarial loss: 0.581267\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582617; batch adversarial loss: 0.583599\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520317; batch adversarial loss: 0.589619\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544882; batch adversarial loss: 0.605144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.525141; batch adversarial loss: 0.533912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537001; batch adversarial loss: 0.607007\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517579; batch adversarial loss: 0.581621\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532145; batch adversarial loss: 0.598393\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501675; batch adversarial loss: 0.546168\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480892; batch adversarial loss: 0.559862\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523461; batch adversarial loss: 0.602153\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478701; batch adversarial loss: 0.567977\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472473; batch adversarial loss: 0.513686\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528764; batch adversarial loss: 0.554126\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527146; batch adversarial loss: 0.641680\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476218; batch adversarial loss: 0.606623\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537481; batch adversarial loss: 0.444800\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459946; batch adversarial loss: 0.481860\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497075; batch adversarial loss: 0.523344\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434755; batch adversarial loss: 0.552774\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483289; batch adversarial loss: 0.546865\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457139; batch adversarial loss: 0.521164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471146; batch adversarial loss: 0.566876\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441881; batch adversarial loss: 0.646552\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455616; batch adversarial loss: 0.519526\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462008; batch adversarial loss: 0.619689\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464697; batch adversarial loss: 0.548155\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507931; batch adversarial loss: 0.521672\n",
      "epoch 39; iter: 0; batch classifier loss: 0.516403; batch adversarial loss: 0.517219\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466208; batch adversarial loss: 0.537420\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468511; batch adversarial loss: 0.534596\n",
      "epoch 42; iter: 0; batch classifier loss: 0.442910; batch adversarial loss: 0.546080\n",
      "epoch 43; iter: 0; batch classifier loss: 0.417015; batch adversarial loss: 0.519970\n",
      "epoch 44; iter: 0; batch classifier loss: 0.534260; batch adversarial loss: 0.528704\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408568; batch adversarial loss: 0.510548\n",
      "epoch 46; iter: 0; batch classifier loss: 0.484376; batch adversarial loss: 0.580176\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467125; batch adversarial loss: 0.509891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420963; batch adversarial loss: 0.535834\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419341; batch adversarial loss: 0.544857\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493647; batch adversarial loss: 0.544587\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383621; batch adversarial loss: 0.562497\n",
      "epoch 52; iter: 0; batch classifier loss: 0.501214; batch adversarial loss: 0.589366\n",
      "epoch 53; iter: 0; batch classifier loss: 0.370288; batch adversarial loss: 0.598434\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409329; batch adversarial loss: 0.625487\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430740; batch adversarial loss: 0.589058\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411476; batch adversarial loss: 0.580652\n",
      "epoch 57; iter: 0; batch classifier loss: 0.466385; batch adversarial loss: 0.490660\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451959; batch adversarial loss: 0.517507\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385165; batch adversarial loss: 0.615648\n",
      "epoch 60; iter: 0; batch classifier loss: 0.496203; batch adversarial loss: 0.563564\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447379; batch adversarial loss: 0.615605\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407012; batch adversarial loss: 0.471881\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416021; batch adversarial loss: 0.562165\n",
      "epoch 64; iter: 0; batch classifier loss: 0.461953; batch adversarial loss: 0.607319\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356497; batch adversarial loss: 0.554309\n",
      "epoch 66; iter: 0; batch classifier loss: 0.370051; batch adversarial loss: 0.554015\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401893; batch adversarial loss: 0.592023\n",
      "epoch 68; iter: 0; batch classifier loss: 0.463344; batch adversarial loss: 0.500410\n",
      "epoch 69; iter: 0; batch classifier loss: 0.339529; batch adversarial loss: 0.553116\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420651; batch adversarial loss: 0.500095\n",
      "epoch 71; iter: 0; batch classifier loss: 0.454768; batch adversarial loss: 0.554942\n",
      "epoch 72; iter: 0; batch classifier loss: 0.352610; batch adversarial loss: 0.553810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394615; batch adversarial loss: 0.607550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398482; batch adversarial loss: 0.525770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377609; batch adversarial loss: 0.515079\n",
      "epoch 76; iter: 0; batch classifier loss: 0.401386; batch adversarial loss: 0.597214\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400246; batch adversarial loss: 0.509098\n",
      "epoch 78; iter: 0; batch classifier loss: 0.308221; batch adversarial loss: 0.518312\n",
      "epoch 79; iter: 0; batch classifier loss: 0.352853; batch adversarial loss: 0.562008\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393464; batch adversarial loss: 0.604419\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413018; batch adversarial loss: 0.535226\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395425; batch adversarial loss: 0.617203\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420797; batch adversarial loss: 0.543900\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371253; batch adversarial loss: 0.533862\n",
      "epoch 85; iter: 0; batch classifier loss: 0.329955; batch adversarial loss: 0.462768\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382393; batch adversarial loss: 0.542887\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420565; batch adversarial loss: 0.507850\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414246; batch adversarial loss: 0.524380\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404647; batch adversarial loss: 0.525194\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400364; batch adversarial loss: 0.462088\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370716; batch adversarial loss: 0.523937\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376941; batch adversarial loss: 0.552807\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380229; batch adversarial loss: 0.573328\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406656; batch adversarial loss: 0.579499\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395019; batch adversarial loss: 0.618061\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369557; batch adversarial loss: 0.490609\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391969; batch adversarial loss: 0.589938\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365772; batch adversarial loss: 0.561846\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357661; batch adversarial loss: 0.472274\n",
      "epoch 100; iter: 0; batch classifier loss: 0.332766; batch adversarial loss: 0.461711\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395050; batch adversarial loss: 0.535317\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351705; batch adversarial loss: 0.506169\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390148; batch adversarial loss: 0.462698\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391648; batch adversarial loss: 0.573281\n",
      "epoch 105; iter: 0; batch classifier loss: 0.356045; batch adversarial loss: 0.606338\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352973; batch adversarial loss: 0.590455\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339695; batch adversarial loss: 0.580408\n",
      "epoch 108; iter: 0; batch classifier loss: 0.319735; batch adversarial loss: 0.530671\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413826; batch adversarial loss: 0.592327\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333475; batch adversarial loss: 0.582281\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359269; batch adversarial loss: 0.538010\n",
      "epoch 112; iter: 0; batch classifier loss: 0.463912; batch adversarial loss: 0.543735\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343165; batch adversarial loss: 0.472297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.379409; batch adversarial loss: 0.544249\n",
      "epoch 115; iter: 0; batch classifier loss: 0.424530; batch adversarial loss: 0.550922\n",
      "epoch 116; iter: 0; batch classifier loss: 0.306271; batch adversarial loss: 0.584258\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363374; batch adversarial loss: 0.581336\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412022; batch adversarial loss: 0.491433\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348342; batch adversarial loss: 0.567671\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421893; batch adversarial loss: 0.604823\n",
      "epoch 121; iter: 0; batch classifier loss: 0.301335; batch adversarial loss: 0.501016\n",
      "epoch 122; iter: 0; batch classifier loss: 0.321900; batch adversarial loss: 0.516915\n",
      "epoch 123; iter: 0; batch classifier loss: 0.345939; batch adversarial loss: 0.537513\n",
      "epoch 124; iter: 0; batch classifier loss: 0.352807; batch adversarial loss: 0.598586\n",
      "epoch 125; iter: 0; batch classifier loss: 0.337700; batch adversarial loss: 0.537122\n",
      "epoch 126; iter: 0; batch classifier loss: 0.437261; batch adversarial loss: 0.570808\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364034; batch adversarial loss: 0.533790\n",
      "epoch 128; iter: 0; batch classifier loss: 0.413453; batch adversarial loss: 0.591482\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344904; batch adversarial loss: 0.625200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357122; batch adversarial loss: 0.566329\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372186; batch adversarial loss: 0.582370\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400525; batch adversarial loss: 0.521292\n",
      "epoch 133; iter: 0; batch classifier loss: 0.300643; batch adversarial loss: 0.626949\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381364; batch adversarial loss: 0.502605\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341181; batch adversarial loss: 0.596316\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383060; batch adversarial loss: 0.560116\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414674; batch adversarial loss: 0.589472\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402119; batch adversarial loss: 0.579745\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356376; batch adversarial loss: 0.553880\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371782; batch adversarial loss: 0.535570\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356744; batch adversarial loss: 0.545943\n",
      "epoch 142; iter: 0; batch classifier loss: 0.278226; batch adversarial loss: 0.552530\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389300; batch adversarial loss: 0.526119\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331779; batch adversarial loss: 0.579294\n",
      "epoch 145; iter: 0; batch classifier loss: 0.354231; batch adversarial loss: 0.565854\n",
      "epoch 146; iter: 0; batch classifier loss: 0.306642; batch adversarial loss: 0.507314\n",
      "epoch 147; iter: 0; batch classifier loss: 0.304247; batch adversarial loss: 0.534964\n",
      "epoch 148; iter: 0; batch classifier loss: 0.369555; batch adversarial loss: 0.563306\n",
      "epoch 149; iter: 0; batch classifier loss: 0.416628; batch adversarial loss: 0.499557\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356323; batch adversarial loss: 0.535651\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326336; batch adversarial loss: 0.603125\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338869; batch adversarial loss: 0.572425\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372746; batch adversarial loss: 0.551778\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358315; batch adversarial loss: 0.453852\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381939; batch adversarial loss: 0.451343\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383618; batch adversarial loss: 0.595573\n",
      "epoch 157; iter: 0; batch classifier loss: 0.303466; batch adversarial loss: 0.486042\n",
      "epoch 158; iter: 0; batch classifier loss: 0.462446; batch adversarial loss: 0.572496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.335036; batch adversarial loss: 0.517067\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404581; batch adversarial loss: 0.569525\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335298; batch adversarial loss: 0.452664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344684; batch adversarial loss: 0.486489\n",
      "epoch 163; iter: 0; batch classifier loss: 0.314477; batch adversarial loss: 0.502411\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392524; batch adversarial loss: 0.542297\n",
      "epoch 165; iter: 0; batch classifier loss: 0.311974; batch adversarial loss: 0.643104\n",
      "epoch 166; iter: 0; batch classifier loss: 0.338777; batch adversarial loss: 0.580661\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337598; batch adversarial loss: 0.514208\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331732; batch adversarial loss: 0.573079\n",
      "epoch 169; iter: 0; batch classifier loss: 0.286011; batch adversarial loss: 0.495347\n",
      "epoch 170; iter: 0; batch classifier loss: 0.311515; batch adversarial loss: 0.566171\n",
      "epoch 171; iter: 0; batch classifier loss: 0.418920; batch adversarial loss: 0.559517\n",
      "epoch 172; iter: 0; batch classifier loss: 0.293885; batch adversarial loss: 0.624922\n",
      "epoch 173; iter: 0; batch classifier loss: 0.257278; batch adversarial loss: 0.418133\n",
      "epoch 174; iter: 0; batch classifier loss: 0.285614; batch adversarial loss: 0.525699\n",
      "epoch 175; iter: 0; batch classifier loss: 0.285278; batch adversarial loss: 0.472468\n",
      "epoch 176; iter: 0; batch classifier loss: 0.251977; batch adversarial loss: 0.533274\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318428; batch adversarial loss: 0.512709\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370294; batch adversarial loss: 0.553437\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341370; batch adversarial loss: 0.620302\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327571; batch adversarial loss: 0.523111\n",
      "epoch 181; iter: 0; batch classifier loss: 0.404538; batch adversarial loss: 0.566449\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357524; batch adversarial loss: 0.537723\n",
      "epoch 183; iter: 0; batch classifier loss: 0.270966; batch adversarial loss: 0.573660\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404427; batch adversarial loss: 0.552999\n",
      "epoch 185; iter: 0; batch classifier loss: 0.312999; batch adversarial loss: 0.589369\n",
      "epoch 186; iter: 0; batch classifier loss: 0.337267; batch adversarial loss: 0.526574\n",
      "epoch 187; iter: 0; batch classifier loss: 0.292500; batch adversarial loss: 0.580031\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395897; batch adversarial loss: 0.549768\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311551; batch adversarial loss: 0.568347\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385546; batch adversarial loss: 0.497481\n",
      "epoch 191; iter: 0; batch classifier loss: 0.327874; batch adversarial loss: 0.589983\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340849; batch adversarial loss: 0.488410\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337910; batch adversarial loss: 0.531243\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324025; batch adversarial loss: 0.555215\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330926; batch adversarial loss: 0.588803\n",
      "epoch 196; iter: 0; batch classifier loss: 0.282120; batch adversarial loss: 0.522492\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318947; batch adversarial loss: 0.571851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328597; batch adversarial loss: 0.542554\n",
      "epoch 199; iter: 0; batch classifier loss: 0.297971; batch adversarial loss: 0.468030\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710478; batch adversarial loss: 0.820570\n",
      "epoch 1; iter: 0; batch classifier loss: 0.875070; batch adversarial loss: 1.137352\n",
      "epoch 2; iter: 0; batch classifier loss: 1.002057; batch adversarial loss: 1.085996\n",
      "epoch 3; iter: 0; batch classifier loss: 1.097361; batch adversarial loss: 1.013243\n",
      "epoch 4; iter: 0; batch classifier loss: 1.004575; batch adversarial loss: 0.923524\n",
      "epoch 5; iter: 0; batch classifier loss: 0.959323; batch adversarial loss: 0.846182\n",
      "epoch 6; iter: 0; batch classifier loss: 1.031554; batch adversarial loss: 0.821940\n",
      "epoch 7; iter: 0; batch classifier loss: 0.825759; batch adversarial loss: 0.764032\n",
      "epoch 8; iter: 0; batch classifier loss: 0.763181; batch adversarial loss: 0.740412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.622091; batch adversarial loss: 0.675793\n",
      "epoch 10; iter: 0; batch classifier loss: 0.637500; batch adversarial loss: 0.606738\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514367; batch adversarial loss: 0.576989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.490842; batch adversarial loss: 0.563251\n",
      "epoch 13; iter: 0; batch classifier loss: 0.604137; batch adversarial loss: 0.583023\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469640; batch adversarial loss: 0.576231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471475; batch adversarial loss: 0.621266\n",
      "epoch 16; iter: 0; batch classifier loss: 0.586901; batch adversarial loss: 0.572486\n",
      "epoch 17; iter: 0; batch classifier loss: 0.448253; batch adversarial loss: 0.578761\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481644; batch adversarial loss: 0.602989\n",
      "epoch 19; iter: 0; batch classifier loss: 0.604805; batch adversarial loss: 0.532016\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491014; batch adversarial loss: 0.589682\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475002; batch adversarial loss: 0.589777\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507484; batch adversarial loss: 0.559510\n",
      "epoch 23; iter: 0; batch classifier loss: 0.413098; batch adversarial loss: 0.591121\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485621; batch adversarial loss: 0.521420\n",
      "epoch 25; iter: 0; batch classifier loss: 0.447355; batch adversarial loss: 0.528115\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438797; batch adversarial loss: 0.539881\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507332; batch adversarial loss: 0.588595\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494219; batch adversarial loss: 0.611329\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442978; batch adversarial loss: 0.493846\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487938; batch adversarial loss: 0.608625\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456980; batch adversarial loss: 0.573194\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434775; batch adversarial loss: 0.518396\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443426; batch adversarial loss: 0.591837\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451207; batch adversarial loss: 0.535928\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459495; batch adversarial loss: 0.502889\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496948; batch adversarial loss: 0.549833\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494439; batch adversarial loss: 0.519228\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459413; batch adversarial loss: 0.555589\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465184; batch adversarial loss: 0.606484\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445625; batch adversarial loss: 0.569973\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462438; batch adversarial loss: 0.558755\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415035; batch adversarial loss: 0.518863\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434826; batch adversarial loss: 0.582487\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409652; batch adversarial loss: 0.538612\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479066; batch adversarial loss: 0.539996\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408369; batch adversarial loss: 0.596684\n",
      "epoch 47; iter: 0; batch classifier loss: 0.369704; batch adversarial loss: 0.529640\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487123; batch adversarial loss: 0.544188\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404604; batch adversarial loss: 0.532627\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378696; batch adversarial loss: 0.590356\n",
      "epoch 51; iter: 0; batch classifier loss: 0.365965; batch adversarial loss: 0.549606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419811; batch adversarial loss: 0.579406\n",
      "epoch 53; iter: 0; batch classifier loss: 0.484061; batch adversarial loss: 0.600746\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406328; batch adversarial loss: 0.591693\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428034; batch adversarial loss: 0.651247\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442104; batch adversarial loss: 0.522504\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442647; batch adversarial loss: 0.588016\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399170; batch adversarial loss: 0.546212\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402442; batch adversarial loss: 0.586360\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446033; batch adversarial loss: 0.519117\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400341; batch adversarial loss: 0.596987\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395192; batch adversarial loss: 0.573072\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413865; batch adversarial loss: 0.605426\n",
      "epoch 64; iter: 0; batch classifier loss: 0.370029; batch adversarial loss: 0.581180\n",
      "epoch 65; iter: 0; batch classifier loss: 0.325878; batch adversarial loss: 0.570434\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400981; batch adversarial loss: 0.554383\n",
      "epoch 67; iter: 0; batch classifier loss: 0.449453; batch adversarial loss: 0.587978\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376936; batch adversarial loss: 0.545460\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382533; batch adversarial loss: 0.553595\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396586; batch adversarial loss: 0.639640\n",
      "epoch 71; iter: 0; batch classifier loss: 0.302517; batch adversarial loss: 0.553075\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360925; batch adversarial loss: 0.554262\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396415; batch adversarial loss: 0.648471\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409040; batch adversarial loss: 0.588826\n",
      "epoch 75; iter: 0; batch classifier loss: 0.390046; batch adversarial loss: 0.579644\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430208; batch adversarial loss: 0.536801\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395514; batch adversarial loss: 0.622270\n",
      "epoch 78; iter: 0; batch classifier loss: 0.391125; batch adversarial loss: 0.562927\n",
      "epoch 79; iter: 0; batch classifier loss: 0.313588; batch adversarial loss: 0.572263\n",
      "epoch 80; iter: 0; batch classifier loss: 0.466709; batch adversarial loss: 0.536289\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398732; batch adversarial loss: 0.562898\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403067; batch adversarial loss: 0.562393\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406976; batch adversarial loss: 0.578959\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389325; batch adversarial loss: 0.535981\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370722; batch adversarial loss: 0.647917\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407721; batch adversarial loss: 0.569895\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352225; batch adversarial loss: 0.597196\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363646; batch adversarial loss: 0.518671\n",
      "epoch 89; iter: 0; batch classifier loss: 0.372383; batch adversarial loss: 0.555352\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381320; batch adversarial loss: 0.560417\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400359; batch adversarial loss: 0.512743\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412086; batch adversarial loss: 0.551937\n",
      "epoch 93; iter: 0; batch classifier loss: 0.388571; batch adversarial loss: 0.501477\n",
      "epoch 94; iter: 0; batch classifier loss: 0.352259; batch adversarial loss: 0.544018\n",
      "epoch 95; iter: 0; batch classifier loss: 0.404793; batch adversarial loss: 0.587292\n",
      "epoch 96; iter: 0; batch classifier loss: 0.300327; batch adversarial loss: 0.586213\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386868; batch adversarial loss: 0.551187\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395699; batch adversarial loss: 0.546567\n",
      "epoch 99; iter: 0; batch classifier loss: 0.427200; batch adversarial loss: 0.535448\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373448; batch adversarial loss: 0.493762\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402524; batch adversarial loss: 0.537146\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348845; batch adversarial loss: 0.569537\n",
      "epoch 103; iter: 0; batch classifier loss: 0.320818; batch adversarial loss: 0.518338\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415279; batch adversarial loss: 0.580401\n",
      "epoch 105; iter: 0; batch classifier loss: 0.453589; batch adversarial loss: 0.505242\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331213; batch adversarial loss: 0.562076\n",
      "epoch 107; iter: 0; batch classifier loss: 0.422887; batch adversarial loss: 0.508881\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336242; batch adversarial loss: 0.608293\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352406; batch adversarial loss: 0.502031\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385845; batch adversarial loss: 0.501588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.411297; batch adversarial loss: 0.555320\n",
      "epoch 112; iter: 0; batch classifier loss: 0.286807; batch adversarial loss: 0.529593\n",
      "epoch 113; iter: 0; batch classifier loss: 0.436941; batch adversarial loss: 0.579098\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394006; batch adversarial loss: 0.586929\n",
      "epoch 115; iter: 0; batch classifier loss: 0.433509; batch adversarial loss: 0.526566\n",
      "epoch 116; iter: 0; batch classifier loss: 0.430378; batch adversarial loss: 0.538818\n",
      "epoch 117; iter: 0; batch classifier loss: 0.442551; batch adversarial loss: 0.492043\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387154; batch adversarial loss: 0.558508\n",
      "epoch 119; iter: 0; batch classifier loss: 0.426474; batch adversarial loss: 0.610707\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358625; batch adversarial loss: 0.525123\n",
      "epoch 121; iter: 0; batch classifier loss: 0.401001; batch adversarial loss: 0.590180\n",
      "epoch 122; iter: 0; batch classifier loss: 0.419586; batch adversarial loss: 0.589143\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367198; batch adversarial loss: 0.476366\n",
      "epoch 124; iter: 0; batch classifier loss: 0.450651; batch adversarial loss: 0.592951\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409303; batch adversarial loss: 0.519475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358435; batch adversarial loss: 0.533827\n",
      "epoch 127; iter: 0; batch classifier loss: 0.447453; batch adversarial loss: 0.591246\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409358; batch adversarial loss: 0.588386\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368761; batch adversarial loss: 0.568226\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397555; batch adversarial loss: 0.570442\n",
      "epoch 131; iter: 0; batch classifier loss: 0.293136; batch adversarial loss: 0.585441\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339479; batch adversarial loss: 0.578016\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408734; batch adversarial loss: 0.614543\n",
      "epoch 134; iter: 0; batch classifier loss: 0.330735; batch adversarial loss: 0.611456\n",
      "epoch 135; iter: 0; batch classifier loss: 0.386746; batch adversarial loss: 0.508804\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374675; batch adversarial loss: 0.580435\n",
      "epoch 137; iter: 0; batch classifier loss: 0.304016; batch adversarial loss: 0.538423\n",
      "epoch 138; iter: 0; batch classifier loss: 0.302903; batch adversarial loss: 0.628080\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386629; batch adversarial loss: 0.613881\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361963; batch adversarial loss: 0.495907\n",
      "epoch 141; iter: 0; batch classifier loss: 0.320448; batch adversarial loss: 0.626000\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376512; batch adversarial loss: 0.648666\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355870; batch adversarial loss: 0.588242\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331166; batch adversarial loss: 0.552904\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374287; batch adversarial loss: 0.613480\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313160; batch adversarial loss: 0.581918\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360115; batch adversarial loss: 0.545078\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342983; batch adversarial loss: 0.588963\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375508; batch adversarial loss: 0.474140\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350645; batch adversarial loss: 0.515400\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384201; batch adversarial loss: 0.485242\n",
      "epoch 152; iter: 0; batch classifier loss: 0.399055; batch adversarial loss: 0.493135\n",
      "epoch 153; iter: 0; batch classifier loss: 0.398595; batch adversarial loss: 0.578082\n",
      "epoch 154; iter: 0; batch classifier loss: 0.399083; batch adversarial loss: 0.539926\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374383; batch adversarial loss: 0.550504\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341022; batch adversarial loss: 0.613976\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356820; batch adversarial loss: 0.569172\n",
      "epoch 158; iter: 0; batch classifier loss: 0.429689; batch adversarial loss: 0.518804\n",
      "epoch 159; iter: 0; batch classifier loss: 0.435755; batch adversarial loss: 0.587300\n",
      "epoch 160; iter: 0; batch classifier loss: 0.289234; batch adversarial loss: 0.628850\n",
      "epoch 161; iter: 0; batch classifier loss: 0.323142; batch adversarial loss: 0.575665\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356941; batch adversarial loss: 0.523744\n",
      "epoch 163; iter: 0; batch classifier loss: 0.274220; batch adversarial loss: 0.562918\n",
      "epoch 164; iter: 0; batch classifier loss: 0.277956; batch adversarial loss: 0.544185\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329151; batch adversarial loss: 0.588920\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342476; batch adversarial loss: 0.560913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.357994; batch adversarial loss: 0.546105\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335164; batch adversarial loss: 0.503650\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372311; batch adversarial loss: 0.587359\n",
      "epoch 170; iter: 0; batch classifier loss: 0.393776; batch adversarial loss: 0.671865\n",
      "epoch 171; iter: 0; batch classifier loss: 0.449953; batch adversarial loss: 0.512488\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355590; batch adversarial loss: 0.510177\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351941; batch adversarial loss: 0.511980\n",
      "epoch 174; iter: 0; batch classifier loss: 0.327452; batch adversarial loss: 0.585149\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363399; batch adversarial loss: 0.503013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.304857; batch adversarial loss: 0.583974\n",
      "epoch 177; iter: 0; batch classifier loss: 0.368447; batch adversarial loss: 0.534309\n",
      "epoch 178; iter: 0; batch classifier loss: 0.381699; batch adversarial loss: 0.578881\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340490; batch adversarial loss: 0.554833\n",
      "epoch 180; iter: 0; batch classifier loss: 0.332735; batch adversarial loss: 0.623854\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388539; batch adversarial loss: 0.612117\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352194; batch adversarial loss: 0.563140\n",
      "epoch 183; iter: 0; batch classifier loss: 0.291277; batch adversarial loss: 0.516177\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383066; batch adversarial loss: 0.577353\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330635; batch adversarial loss: 0.520293\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328453; batch adversarial loss: 0.628695\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387863; batch adversarial loss: 0.544266\n",
      "epoch 188; iter: 0; batch classifier loss: 0.413130; batch adversarial loss: 0.561125\n",
      "epoch 189; iter: 0; batch classifier loss: 0.368383; batch adversarial loss: 0.592552\n",
      "epoch 190; iter: 0; batch classifier loss: 0.354823; batch adversarial loss: 0.572309\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336319; batch adversarial loss: 0.639636\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319503; batch adversarial loss: 0.584903\n",
      "epoch 193; iter: 0; batch classifier loss: 0.377047; batch adversarial loss: 0.610657\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377728; batch adversarial loss: 0.561466\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296298; batch adversarial loss: 0.481035\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333927; batch adversarial loss: 0.588087\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368047; batch adversarial loss: 0.605122\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383890; batch adversarial loss: 0.460687\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335852; batch adversarial loss: 0.541487\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758469; batch adversarial loss: 0.685552\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567869; batch adversarial loss: 0.680406\n",
      "epoch 2; iter: 0; batch classifier loss: 0.639856; batch adversarial loss: 0.634372\n",
      "epoch 3; iter: 0; batch classifier loss: 0.506485; batch adversarial loss: 0.630978\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559796; batch adversarial loss: 0.620398\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541025; batch adversarial loss: 0.596096\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501844; batch adversarial loss: 0.610535\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567204; batch adversarial loss: 0.582155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.540258; batch adversarial loss: 0.592639\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541632; batch adversarial loss: 0.609816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543891; batch adversarial loss: 0.654739\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500891; batch adversarial loss: 0.618490\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549595; batch adversarial loss: 0.619292\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572215; batch adversarial loss: 0.629539\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556655; batch adversarial loss: 0.625835\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589940; batch adversarial loss: 0.616265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498667; batch adversarial loss: 0.618187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.571093; batch adversarial loss: 0.588853\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491818; batch adversarial loss: 0.555320\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470362; batch adversarial loss: 0.575107\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491732; batch adversarial loss: 0.546579\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523468; batch adversarial loss: 0.546443\n",
      "epoch 22; iter: 0; batch classifier loss: 0.572275; batch adversarial loss: 0.572293\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531666; batch adversarial loss: 0.566526\n",
      "epoch 24; iter: 0; batch classifier loss: 0.600897; batch adversarial loss: 0.523601\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483298; batch adversarial loss: 0.582815\n",
      "epoch 26; iter: 0; batch classifier loss: 0.535745; batch adversarial loss: 0.579128\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476951; batch adversarial loss: 0.451229\n",
      "epoch 28; iter: 0; batch classifier loss: 0.511409; batch adversarial loss: 0.519811\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508484; batch adversarial loss: 0.477765\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458921; batch adversarial loss: 0.545392\n",
      "epoch 31; iter: 0; batch classifier loss: 0.504827; batch adversarial loss: 0.594523\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418194; batch adversarial loss: 0.632368\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466513; batch adversarial loss: 0.533070\n",
      "epoch 34; iter: 0; batch classifier loss: 0.387885; batch adversarial loss: 0.562638\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507707; batch adversarial loss: 0.580913\n",
      "epoch 36; iter: 0; batch classifier loss: 0.507324; batch adversarial loss: 0.571061\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444610; batch adversarial loss: 0.570726\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470534; batch adversarial loss: 0.467814\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435387; batch adversarial loss: 0.527569\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467319; batch adversarial loss: 0.590745\n",
      "epoch 41; iter: 0; batch classifier loss: 0.523751; batch adversarial loss: 0.564861\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389666; batch adversarial loss: 0.536134\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443383; batch adversarial loss: 0.544421\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440468; batch adversarial loss: 0.474373\n",
      "epoch 45; iter: 0; batch classifier loss: 0.483570; batch adversarial loss: 0.518891\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436444; batch adversarial loss: 0.545119\n",
      "epoch 47; iter: 0; batch classifier loss: 0.529853; batch adversarial loss: 0.518961\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465157; batch adversarial loss: 0.580085\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445238; batch adversarial loss: 0.501032\n",
      "epoch 50; iter: 0; batch classifier loss: 0.516279; batch adversarial loss: 0.491093\n",
      "epoch 51; iter: 0; batch classifier loss: 0.402408; batch adversarial loss: 0.473295\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429122; batch adversarial loss: 0.544074\n",
      "epoch 53; iter: 0; batch classifier loss: 0.509894; batch adversarial loss: 0.580866\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398982; batch adversarial loss: 0.473135\n",
      "epoch 55; iter: 0; batch classifier loss: 0.495326; batch adversarial loss: 0.535810\n",
      "epoch 56; iter: 0; batch classifier loss: 0.530869; batch adversarial loss: 0.518071\n",
      "epoch 57; iter: 0; batch classifier loss: 0.516551; batch adversarial loss: 0.616657\n",
      "epoch 58; iter: 0; batch classifier loss: 0.449795; batch adversarial loss: 0.544796\n",
      "epoch 59; iter: 0; batch classifier loss: 0.509419; batch adversarial loss: 0.580066\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400391; batch adversarial loss: 0.491366\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417980; batch adversarial loss: 0.579777\n",
      "epoch 62; iter: 0; batch classifier loss: 0.419203; batch adversarial loss: 0.544937\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394335; batch adversarial loss: 0.562146\n",
      "epoch 64; iter: 0; batch classifier loss: 0.446684; batch adversarial loss: 0.536095\n",
      "epoch 65; iter: 0; batch classifier loss: 0.516731; batch adversarial loss: 0.597684\n",
      "epoch 66; iter: 0; batch classifier loss: 0.362233; batch adversarial loss: 0.607484\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432143; batch adversarial loss: 0.614598\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377093; batch adversarial loss: 0.536224\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366139; batch adversarial loss: 0.525568\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412317; batch adversarial loss: 0.534183\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372990; batch adversarial loss: 0.607163\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448014; batch adversarial loss: 0.568815\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422545; batch adversarial loss: 0.545343\n",
      "epoch 74; iter: 0; batch classifier loss: 0.420626; batch adversarial loss: 0.552530\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409454; batch adversarial loss: 0.510084\n",
      "epoch 76; iter: 0; batch classifier loss: 0.435298; batch adversarial loss: 0.545745\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418745; batch adversarial loss: 0.535113\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379389; batch adversarial loss: 0.562953\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436555; batch adversarial loss: 0.517548\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376242; batch adversarial loss: 0.518689\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381356; batch adversarial loss: 0.579760\n",
      "epoch 82; iter: 0; batch classifier loss: 0.464382; batch adversarial loss: 0.528051\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326214; batch adversarial loss: 0.543068\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392914; batch adversarial loss: 0.596564\n",
      "epoch 85; iter: 0; batch classifier loss: 0.371113; batch adversarial loss: 0.604441\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397408; batch adversarial loss: 0.595515\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389704; batch adversarial loss: 0.517669\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358016; batch adversarial loss: 0.612775\n",
      "epoch 89; iter: 0; batch classifier loss: 0.249602; batch adversarial loss: 0.651544\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353952; batch adversarial loss: 0.586137\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416318; batch adversarial loss: 0.500357\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384159; batch adversarial loss: 0.508882\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417750; batch adversarial loss: 0.595116\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430003; batch adversarial loss: 0.526426\n",
      "epoch 95; iter: 0; batch classifier loss: 0.443953; batch adversarial loss: 0.552639\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396209; batch adversarial loss: 0.553327\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374680; batch adversarial loss: 0.544949\n",
      "epoch 98; iter: 0; batch classifier loss: 0.424641; batch adversarial loss: 0.508613\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366518; batch adversarial loss: 0.499083\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420678; batch adversarial loss: 0.615022\n",
      "epoch 101; iter: 0; batch classifier loss: 0.445227; batch adversarial loss: 0.597490\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415114; batch adversarial loss: 0.571711\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427106; batch adversarial loss: 0.544679\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395708; batch adversarial loss: 0.606637\n",
      "epoch 105; iter: 0; batch classifier loss: 0.467832; batch adversarial loss: 0.535329\n",
      "epoch 106; iter: 0; batch classifier loss: 0.413123; batch adversarial loss: 0.527849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.395314; batch adversarial loss: 0.507872\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395640; batch adversarial loss: 0.534384\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433162; batch adversarial loss: 0.599991\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426101; batch adversarial loss: 0.544005\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385481; batch adversarial loss: 0.490833\n",
      "epoch 112; iter: 0; batch classifier loss: 0.496476; batch adversarial loss: 0.563641\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413801; batch adversarial loss: 0.571186\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360718; batch adversarial loss: 0.544570\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394369; batch adversarial loss: 0.555327\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410851; batch adversarial loss: 0.553549\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399455; batch adversarial loss: 0.518434\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397285; batch adversarial loss: 0.474495\n",
      "epoch 119; iter: 0; batch classifier loss: 0.442002; batch adversarial loss: 0.606550\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388434; batch adversarial loss: 0.473604\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350922; batch adversarial loss: 0.543922\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382268; batch adversarial loss: 0.545112\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399160; batch adversarial loss: 0.616118\n",
      "epoch 124; iter: 0; batch classifier loss: 0.409822; batch adversarial loss: 0.526910\n",
      "epoch 125; iter: 0; batch classifier loss: 0.406102; batch adversarial loss: 0.554374\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369780; batch adversarial loss: 0.563181\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365759; batch adversarial loss: 0.570650\n",
      "epoch 128; iter: 0; batch classifier loss: 0.310584; batch adversarial loss: 0.535927\n",
      "epoch 129; iter: 0; batch classifier loss: 0.436897; batch adversarial loss: 0.561525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384464; batch adversarial loss: 0.544722\n",
      "epoch 131; iter: 0; batch classifier loss: 0.404271; batch adversarial loss: 0.553062\n",
      "epoch 132; iter: 0; batch classifier loss: 0.281135; batch adversarial loss: 0.535459\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380922; batch adversarial loss: 0.553580\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394207; batch adversarial loss: 0.563421\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388004; batch adversarial loss: 0.605994\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414359; batch adversarial loss: 0.501352\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350111; batch adversarial loss: 0.561716\n",
      "epoch 138; iter: 0; batch classifier loss: 0.427438; batch adversarial loss: 0.553163\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373713; batch adversarial loss: 0.607883\n",
      "epoch 140; iter: 0; batch classifier loss: 0.343641; batch adversarial loss: 0.587480\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369252; batch adversarial loss: 0.571130\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420528; batch adversarial loss: 0.526546\n",
      "epoch 143; iter: 0; batch classifier loss: 0.339129; batch adversarial loss: 0.572108\n",
      "epoch 144; iter: 0; batch classifier loss: 0.445603; batch adversarial loss: 0.534806\n",
      "epoch 145; iter: 0; batch classifier loss: 0.386673; batch adversarial loss: 0.579728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317519; batch adversarial loss: 0.580326\n",
      "epoch 147; iter: 0; batch classifier loss: 0.459782; batch adversarial loss: 0.517406\n",
      "epoch 148; iter: 0; batch classifier loss: 0.322706; batch adversarial loss: 0.554432\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402171; batch adversarial loss: 0.560268\n",
      "epoch 150; iter: 0; batch classifier loss: 0.470030; batch adversarial loss: 0.579388\n",
      "epoch 151; iter: 0; batch classifier loss: 0.469767; batch adversarial loss: 0.579841\n",
      "epoch 152; iter: 0; batch classifier loss: 0.318109; batch adversarial loss: 0.625279\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350736; batch adversarial loss: 0.520351\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373470; batch adversarial loss: 0.482363\n",
      "epoch 155; iter: 0; batch classifier loss: 0.466596; batch adversarial loss: 0.721018\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371251; batch adversarial loss: 0.544630\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357876; batch adversarial loss: 0.535576\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375048; batch adversarial loss: 0.553737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329123; batch adversarial loss: 0.634819\n",
      "epoch 160; iter: 0; batch classifier loss: 0.371521; batch adversarial loss: 0.607423\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344322; batch adversarial loss: 0.615415\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323431; batch adversarial loss: 0.606457\n",
      "epoch 163; iter: 0; batch classifier loss: 0.381823; batch adversarial loss: 0.510219\n",
      "epoch 164; iter: 0; batch classifier loss: 0.299448; batch adversarial loss: 0.596915\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356203; batch adversarial loss: 0.578563\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387757; batch adversarial loss: 0.578596\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336656; batch adversarial loss: 0.561272\n",
      "epoch 168; iter: 0; batch classifier loss: 0.328730; batch adversarial loss: 0.507159\n",
      "epoch 169; iter: 0; batch classifier loss: 0.307093; batch adversarial loss: 0.599067\n",
      "epoch 170; iter: 0; batch classifier loss: 0.284673; batch adversarial loss: 0.482192\n",
      "epoch 171; iter: 0; batch classifier loss: 0.417479; batch adversarial loss: 0.552893\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407516; batch adversarial loss: 0.588171\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345876; batch adversarial loss: 0.597719\n",
      "epoch 174; iter: 0; batch classifier loss: 0.386733; batch adversarial loss: 0.598750\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343256; batch adversarial loss: 0.526643\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351563; batch adversarial loss: 0.533737\n",
      "epoch 177; iter: 0; batch classifier loss: 0.415767; batch adversarial loss: 0.552790\n",
      "epoch 178; iter: 0; batch classifier loss: 0.371812; batch adversarial loss: 0.578231\n",
      "epoch 179; iter: 0; batch classifier loss: 0.400284; batch adversarial loss: 0.528116\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328191; batch adversarial loss: 0.571147\n",
      "epoch 181; iter: 0; batch classifier loss: 0.292921; batch adversarial loss: 0.534296\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336421; batch adversarial loss: 0.510185\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376058; batch adversarial loss: 0.624146\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318349; batch adversarial loss: 0.589785\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315601; batch adversarial loss: 0.543650\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380002; batch adversarial loss: 0.598139\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375972; batch adversarial loss: 0.489964\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371495; batch adversarial loss: 0.561075\n",
      "epoch 189; iter: 0; batch classifier loss: 0.422934; batch adversarial loss: 0.544919\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390956; batch adversarial loss: 0.483184\n",
      "epoch 191; iter: 0; batch classifier loss: 0.247492; batch adversarial loss: 0.508895\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328640; batch adversarial loss: 0.490701\n",
      "epoch 193; iter: 0; batch classifier loss: 0.427366; batch adversarial loss: 0.546494\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304089; batch adversarial loss: 0.661077\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363429; batch adversarial loss: 0.534261\n",
      "epoch 196; iter: 0; batch classifier loss: 0.440884; batch adversarial loss: 0.578694\n",
      "epoch 197; iter: 0; batch classifier loss: 0.454448; batch adversarial loss: 0.490742\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326848; batch adversarial loss: 0.543965\n",
      "epoch 199; iter: 0; batch classifier loss: 0.408411; batch adversarial loss: 0.590517\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690020; batch adversarial loss: 0.875662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.793048; batch adversarial loss: 1.130737\n",
      "epoch 2; iter: 0; batch classifier loss: 0.898685; batch adversarial loss: 1.088694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.970648; batch adversarial loss: 0.976146\n",
      "epoch 4; iter: 0; batch classifier loss: 0.907494; batch adversarial loss: 0.910730\n",
      "epoch 5; iter: 0; batch classifier loss: 0.757394; batch adversarial loss: 0.829065\n",
      "epoch 6; iter: 0; batch classifier loss: 0.729088; batch adversarial loss: 0.769200\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558022; batch adversarial loss: 0.682820\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507514; batch adversarial loss: 0.666105\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543848; batch adversarial loss: 0.640339\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552837; batch adversarial loss: 0.591696\n",
      "epoch 11; iter: 0; batch classifier loss: 0.444835; batch adversarial loss: 0.591758\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518886; batch adversarial loss: 0.587091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452042; batch adversarial loss: 0.603629\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484024; batch adversarial loss: 0.577208\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483444; batch adversarial loss: 0.571641\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463194; batch adversarial loss: 0.557026\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505685; batch adversarial loss: 0.590963\n",
      "epoch 18; iter: 0; batch classifier loss: 0.562952; batch adversarial loss: 0.599226\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491485; batch adversarial loss: 0.605251\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478431; batch adversarial loss: 0.581290\n",
      "epoch 21; iter: 0; batch classifier loss: 0.612218; batch adversarial loss: 0.578275\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502468; batch adversarial loss: 0.551198\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515178; batch adversarial loss: 0.553433\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461760; batch adversarial loss: 0.552655\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481763; batch adversarial loss: 0.549937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.411033; batch adversarial loss: 0.554824\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455454; batch adversarial loss: 0.564699\n",
      "epoch 28; iter: 0; batch classifier loss: 0.517186; batch adversarial loss: 0.514225\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480710; batch adversarial loss: 0.553328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502073; batch adversarial loss: 0.494635\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419597; batch adversarial loss: 0.584578\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456216; batch adversarial loss: 0.540258\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424788; batch adversarial loss: 0.504909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.508243; batch adversarial loss: 0.540626\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443618; batch adversarial loss: 0.590970\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410911; batch adversarial loss: 0.543950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.496753; batch adversarial loss: 0.559333\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484914; batch adversarial loss: 0.593631\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392849; batch adversarial loss: 0.553203\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464377; batch adversarial loss: 0.574518\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418583; batch adversarial loss: 0.585931\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465171; batch adversarial loss: 0.499167\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447084; batch adversarial loss: 0.637106\n",
      "epoch 44; iter: 0; batch classifier loss: 0.522223; batch adversarial loss: 0.580199\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417633; batch adversarial loss: 0.631395\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403338; batch adversarial loss: 0.544131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.530950; batch adversarial loss: 0.616686\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430787; batch adversarial loss: 0.508937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426951; batch adversarial loss: 0.563172\n",
      "epoch 50; iter: 0; batch classifier loss: 0.436176; batch adversarial loss: 0.524663\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490821; batch adversarial loss: 0.554825\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424933; batch adversarial loss: 0.554144\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470698; batch adversarial loss: 0.516995\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445917; batch adversarial loss: 0.526825\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446217; batch adversarial loss: 0.512873\n",
      "epoch 56; iter: 0; batch classifier loss: 0.361443; batch adversarial loss: 0.605279\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422278; batch adversarial loss: 0.640371\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472129; batch adversarial loss: 0.563160\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421041; batch adversarial loss: 0.520956\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423470; batch adversarial loss: 0.581210\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424350; batch adversarial loss: 0.588776\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417031; batch adversarial loss: 0.551155\n",
      "epoch 63; iter: 0; batch classifier loss: 0.456689; batch adversarial loss: 0.542401\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400056; batch adversarial loss: 0.543751\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457494; batch adversarial loss: 0.536034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.482066; batch adversarial loss: 0.552239\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384415; batch adversarial loss: 0.517769\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419054; batch adversarial loss: 0.517391\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376153; batch adversarial loss: 0.590697\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368220; batch adversarial loss: 0.505605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.395340; batch adversarial loss: 0.536150\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478505; batch adversarial loss: 0.533691\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391538; batch adversarial loss: 0.597468\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468195; batch adversarial loss: 0.454722\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434038; batch adversarial loss: 0.613207\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372466; batch adversarial loss: 0.552112\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398336; batch adversarial loss: 0.596816\n",
      "epoch 78; iter: 0; batch classifier loss: 0.418010; batch adversarial loss: 0.507395\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398292; batch adversarial loss: 0.581335\n",
      "epoch 80; iter: 0; batch classifier loss: 0.446623; batch adversarial loss: 0.527151\n",
      "epoch 81; iter: 0; batch classifier loss: 0.493271; batch adversarial loss: 0.499957\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348030; batch adversarial loss: 0.624319\n",
      "epoch 83; iter: 0; batch classifier loss: 0.448566; batch adversarial loss: 0.482355\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373065; batch adversarial loss: 0.491975\n",
      "epoch 85; iter: 0; batch classifier loss: 0.465405; batch adversarial loss: 0.580634\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367436; batch adversarial loss: 0.546191\n",
      "epoch 87; iter: 0; batch classifier loss: 0.359828; batch adversarial loss: 0.614109\n",
      "epoch 88; iter: 0; batch classifier loss: 0.303873; batch adversarial loss: 0.581876\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388896; batch adversarial loss: 0.543708\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405887; batch adversarial loss: 0.527796\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400948; batch adversarial loss: 0.497885\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398973; batch adversarial loss: 0.500564\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341770; batch adversarial loss: 0.548356\n",
      "epoch 94; iter: 0; batch classifier loss: 0.389584; batch adversarial loss: 0.579142\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402132; batch adversarial loss: 0.614936\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443176; batch adversarial loss: 0.551461\n",
      "epoch 97; iter: 0; batch classifier loss: 0.476447; batch adversarial loss: 0.516725\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392267; batch adversarial loss: 0.525084\n",
      "epoch 99; iter: 0; batch classifier loss: 0.295833; batch adversarial loss: 0.597881\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398843; batch adversarial loss: 0.553610\n",
      "epoch 101; iter: 0; batch classifier loss: 0.404023; batch adversarial loss: 0.589312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.380232; batch adversarial loss: 0.564352\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429632; batch adversarial loss: 0.531017\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411336; batch adversarial loss: 0.536259\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405193; batch adversarial loss: 0.516033\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372247; batch adversarial loss: 0.515737\n",
      "epoch 107; iter: 0; batch classifier loss: 0.401433; batch adversarial loss: 0.535793\n",
      "epoch 108; iter: 0; batch classifier loss: 0.309381; batch adversarial loss: 0.522587\n",
      "epoch 109; iter: 0; batch classifier loss: 0.467143; batch adversarial loss: 0.553957\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413966; batch adversarial loss: 0.556311\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389363; batch adversarial loss: 0.566778\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349346; batch adversarial loss: 0.615971\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346432; batch adversarial loss: 0.616306\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371444; batch adversarial loss: 0.514510\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407368; batch adversarial loss: 0.527685\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350064; batch adversarial loss: 0.568827\n",
      "epoch 117; iter: 0; batch classifier loss: 0.336029; batch adversarial loss: 0.535695\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404904; batch adversarial loss: 0.518374\n",
      "epoch 119; iter: 0; batch classifier loss: 0.286691; batch adversarial loss: 0.471520\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378515; batch adversarial loss: 0.588197\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391111; batch adversarial loss: 0.590698\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362287; batch adversarial loss: 0.509757\n",
      "epoch 123; iter: 0; batch classifier loss: 0.296745; batch adversarial loss: 0.526639\n",
      "epoch 124; iter: 0; batch classifier loss: 0.298276; batch adversarial loss: 0.481372\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410829; batch adversarial loss: 0.590193\n",
      "epoch 126; iter: 0; batch classifier loss: 0.408733; batch adversarial loss: 0.534372\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366489; batch adversarial loss: 0.482281\n",
      "epoch 128; iter: 0; batch classifier loss: 0.284088; batch adversarial loss: 0.492536\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339710; batch adversarial loss: 0.517702\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362899; batch adversarial loss: 0.542968\n",
      "epoch 131; iter: 0; batch classifier loss: 0.357604; batch adversarial loss: 0.543437\n",
      "epoch 132; iter: 0; batch classifier loss: 0.397047; batch adversarial loss: 0.535437\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383821; batch adversarial loss: 0.659146\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360216; batch adversarial loss: 0.545877\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356026; batch adversarial loss: 0.508720\n",
      "epoch 136; iter: 0; batch classifier loss: 0.465826; batch adversarial loss: 0.448912\n",
      "epoch 137; iter: 0; batch classifier loss: 0.293264; batch adversarial loss: 0.463501\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358574; batch adversarial loss: 0.492989\n",
      "epoch 139; iter: 0; batch classifier loss: 0.354291; batch adversarial loss: 0.541207\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375199; batch adversarial loss: 0.529102\n",
      "epoch 141; iter: 0; batch classifier loss: 0.352056; batch adversarial loss: 0.521093\n",
      "epoch 142; iter: 0; batch classifier loss: 0.451280; batch adversarial loss: 0.420251\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322418; batch adversarial loss: 0.517223\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359829; batch adversarial loss: 0.482386\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390237; batch adversarial loss: 0.536435\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355415; batch adversarial loss: 0.554697\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390474; batch adversarial loss: 0.560934\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381120; batch adversarial loss: 0.474357\n",
      "epoch 149; iter: 0; batch classifier loss: 0.404615; batch adversarial loss: 0.542956\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368295; batch adversarial loss: 0.524137\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348853; batch adversarial loss: 0.659285\n",
      "epoch 152; iter: 0; batch classifier loss: 0.270298; batch adversarial loss: 0.541506\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368038; batch adversarial loss: 0.623317\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325149; batch adversarial loss: 0.552917\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394383; batch adversarial loss: 0.585304\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385286; batch adversarial loss: 0.599778\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326874; batch adversarial loss: 0.594043\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425808; batch adversarial loss: 0.538511\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363283; batch adversarial loss: 0.535573\n",
      "epoch 160; iter: 0; batch classifier loss: 0.417453; batch adversarial loss: 0.559982\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316490; batch adversarial loss: 0.581866\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401204; batch adversarial loss: 0.609811\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403359; batch adversarial loss: 0.600687\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330498; batch adversarial loss: 0.526621\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344570; batch adversarial loss: 0.536936\n",
      "epoch 166; iter: 0; batch classifier loss: 0.386064; batch adversarial loss: 0.600453\n",
      "epoch 167; iter: 0; batch classifier loss: 0.325612; batch adversarial loss: 0.641745\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380349; batch adversarial loss: 0.603892\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312213; batch adversarial loss: 0.611699\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395557; batch adversarial loss: 0.525267\n",
      "epoch 171; iter: 0; batch classifier loss: 0.339039; batch adversarial loss: 0.536200\n",
      "epoch 172; iter: 0; batch classifier loss: 0.461234; batch adversarial loss: 0.581743\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363666; batch adversarial loss: 0.569318\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326476; batch adversarial loss: 0.578466\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392372; batch adversarial loss: 0.515189\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413670; batch adversarial loss: 0.525131\n",
      "epoch 177; iter: 0; batch classifier loss: 0.302491; batch adversarial loss: 0.578515\n",
      "epoch 178; iter: 0; batch classifier loss: 0.430057; batch adversarial loss: 0.533833\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337447; batch adversarial loss: 0.568553\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322654; batch adversarial loss: 0.514000\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384524; batch adversarial loss: 0.590744\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405327; batch adversarial loss: 0.531895\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344295; batch adversarial loss: 0.678298\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318636; batch adversarial loss: 0.580267\n",
      "epoch 185; iter: 0; batch classifier loss: 0.323992; batch adversarial loss: 0.583158\n",
      "epoch 186; iter: 0; batch classifier loss: 0.436188; batch adversarial loss: 0.601419\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398775; batch adversarial loss: 0.564193\n",
      "epoch 188; iter: 0; batch classifier loss: 0.409520; batch adversarial loss: 0.536386\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385420; batch adversarial loss: 0.542663\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385035; batch adversarial loss: 0.608956\n",
      "epoch 191; iter: 0; batch classifier loss: 0.288633; batch adversarial loss: 0.582255\n",
      "epoch 192; iter: 0; batch classifier loss: 0.310534; batch adversarial loss: 0.466314\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345477; batch adversarial loss: 0.559367\n",
      "epoch 194; iter: 0; batch classifier loss: 0.363073; batch adversarial loss: 0.549790\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382976; batch adversarial loss: 0.499891\n",
      "epoch 196; iter: 0; batch classifier loss: 0.276374; batch adversarial loss: 0.564850\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353679; batch adversarial loss: 0.534320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.361275; batch adversarial loss: 0.553911\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387467; batch adversarial loss: 0.579760\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717642; batch adversarial loss: 0.653537\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573318; batch adversarial loss: 0.649765\n",
      "epoch 2; iter: 0; batch classifier loss: 0.639449; batch adversarial loss: 0.615956\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539235; batch adversarial loss: 0.599836\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521227; batch adversarial loss: 0.618959\n",
      "epoch 5; iter: 0; batch classifier loss: 0.493973; batch adversarial loss: 0.554822\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519386; batch adversarial loss: 0.570679\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534347; batch adversarial loss: 0.609801\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522540; batch adversarial loss: 0.572660\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532073; batch adversarial loss: 0.605107\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546289; batch adversarial loss: 0.622736\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503423; batch adversarial loss: 0.612259\n",
      "epoch 12; iter: 0; batch classifier loss: 0.424119; batch adversarial loss: 0.635923\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547246; batch adversarial loss: 0.542009\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552804; batch adversarial loss: 0.536148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.581903; batch adversarial loss: 0.552132\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498610; batch adversarial loss: 0.607863\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477246; batch adversarial loss: 0.612043\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474470; batch adversarial loss: 0.622577\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507458; batch adversarial loss: 0.653795\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532053; batch adversarial loss: 0.599672\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507891; batch adversarial loss: 0.558476\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471370; batch adversarial loss: 0.537947\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490403; batch adversarial loss: 0.589591\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502587; batch adversarial loss: 0.552148\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512387; batch adversarial loss: 0.539747\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508372; batch adversarial loss: 0.524024\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432008; batch adversarial loss: 0.580100\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451496; batch adversarial loss: 0.540395\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524886; batch adversarial loss: 0.571237\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441948; batch adversarial loss: 0.571311\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481864; batch adversarial loss: 0.628710\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473424; batch adversarial loss: 0.529177\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419207; batch adversarial loss: 0.536849\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441047; batch adversarial loss: 0.528574\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430304; batch adversarial loss: 0.562455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432708; batch adversarial loss: 0.570954\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428721; batch adversarial loss: 0.613845\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441445; batch adversarial loss: 0.545126\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376449; batch adversarial loss: 0.579882\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468938; batch adversarial loss: 0.536082\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452821; batch adversarial loss: 0.606504\n",
      "epoch 42; iter: 0; batch classifier loss: 0.388523; batch adversarial loss: 0.553664\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489140; batch adversarial loss: 0.509152\n",
      "epoch 44; iter: 0; batch classifier loss: 0.368679; batch adversarial loss: 0.561064\n",
      "epoch 45; iter: 0; batch classifier loss: 0.500456; batch adversarial loss: 0.571763\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500127; batch adversarial loss: 0.544090\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389914; batch adversarial loss: 0.580030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405102; batch adversarial loss: 0.516161\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420440; batch adversarial loss: 0.500061\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426866; batch adversarial loss: 0.642405\n",
      "epoch 51; iter: 0; batch classifier loss: 0.439678; batch adversarial loss: 0.534840\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436974; batch adversarial loss: 0.466267\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389100; batch adversarial loss: 0.545572\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437451; batch adversarial loss: 0.571350\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440282; batch adversarial loss: 0.502003\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424051; batch adversarial loss: 0.492832\n",
      "epoch 57; iter: 0; batch classifier loss: 0.355387; batch adversarial loss: 0.441065\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410594; batch adversarial loss: 0.527935\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432570; batch adversarial loss: 0.632280\n",
      "epoch 60; iter: 0; batch classifier loss: 0.544333; batch adversarial loss: 0.518900\n",
      "epoch 61; iter: 0; batch classifier loss: 0.452090; batch adversarial loss: 0.535605\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376196; batch adversarial loss: 0.552640\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429443; batch adversarial loss: 0.562530\n",
      "epoch 64; iter: 0; batch classifier loss: 0.332057; batch adversarial loss: 0.579919\n",
      "epoch 65; iter: 0; batch classifier loss: 0.461068; batch adversarial loss: 0.553923\n",
      "epoch 66; iter: 0; batch classifier loss: 0.488680; batch adversarial loss: 0.518342\n",
      "epoch 67; iter: 0; batch classifier loss: 0.483154; batch adversarial loss: 0.615131\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410830; batch adversarial loss: 0.528241\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371927; batch adversarial loss: 0.544291\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388393; batch adversarial loss: 0.580148\n",
      "epoch 71; iter: 0; batch classifier loss: 0.340933; batch adversarial loss: 0.535884\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391305; batch adversarial loss: 0.482066\n",
      "epoch 73; iter: 0; batch classifier loss: 0.449602; batch adversarial loss: 0.535818\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385924; batch adversarial loss: 0.615227\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369737; batch adversarial loss: 0.553310\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402800; batch adversarial loss: 0.527157\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390704; batch adversarial loss: 0.588543\n",
      "epoch 78; iter: 0; batch classifier loss: 0.414421; batch adversarial loss: 0.526820\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388614; batch adversarial loss: 0.526800\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376833; batch adversarial loss: 0.598365\n",
      "epoch 81; iter: 0; batch classifier loss: 0.474969; batch adversarial loss: 0.535132\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401583; batch adversarial loss: 0.598120\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405697; batch adversarial loss: 0.579615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375346; batch adversarial loss: 0.606038\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390160; batch adversarial loss: 0.552960\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410437; batch adversarial loss: 0.596993\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418122; batch adversarial loss: 0.519261\n",
      "epoch 88; iter: 0; batch classifier loss: 0.364890; batch adversarial loss: 0.642758\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397791; batch adversarial loss: 0.580155\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404023; batch adversarial loss: 0.536602\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410100; batch adversarial loss: 0.606496\n",
      "epoch 92; iter: 0; batch classifier loss: 0.489361; batch adversarial loss: 0.501067\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407609; batch adversarial loss: 0.535831\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407378; batch adversarial loss: 0.597336\n",
      "epoch 95; iter: 0; batch classifier loss: 0.421876; batch adversarial loss: 0.536257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.368945; batch adversarial loss: 0.615471\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360566; batch adversarial loss: 0.606951\n",
      "epoch 98; iter: 0; batch classifier loss: 0.374541; batch adversarial loss: 0.519375\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344384; batch adversarial loss: 0.517779\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351927; batch adversarial loss: 0.536518\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386443; batch adversarial loss: 0.580700\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372554; batch adversarial loss: 0.562872\n",
      "epoch 103; iter: 0; batch classifier loss: 0.340993; batch adversarial loss: 0.518027\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398719; batch adversarial loss: 0.571831\n",
      "epoch 105; iter: 0; batch classifier loss: 0.472222; batch adversarial loss: 0.580548\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402438; batch adversarial loss: 0.544738\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372159; batch adversarial loss: 0.580314\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397342; batch adversarial loss: 0.588320\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342346; batch adversarial loss: 0.517311\n",
      "epoch 110; iter: 0; batch classifier loss: 0.340479; batch adversarial loss: 0.579882\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352656; batch adversarial loss: 0.535924\n",
      "epoch 112; iter: 0; batch classifier loss: 0.461035; batch adversarial loss: 0.508970\n",
      "epoch 113; iter: 0; batch classifier loss: 0.268200; batch adversarial loss: 0.535923\n",
      "epoch 114; iter: 0; batch classifier loss: 0.407284; batch adversarial loss: 0.597664\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350924; batch adversarial loss: 0.606303\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384714; batch adversarial loss: 0.633257\n",
      "epoch 117; iter: 0; batch classifier loss: 0.422951; batch adversarial loss: 0.517234\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387433; batch adversarial loss: 0.588353\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354705; batch adversarial loss: 0.491417\n",
      "epoch 120; iter: 0; batch classifier loss: 0.368183; batch adversarial loss: 0.561422\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360955; batch adversarial loss: 0.597878\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378449; batch adversarial loss: 0.535282\n",
      "epoch 123; iter: 0; batch classifier loss: 0.445612; batch adversarial loss: 0.501985\n",
      "epoch 124; iter: 0; batch classifier loss: 0.396547; batch adversarial loss: 0.562864\n",
      "epoch 125; iter: 0; batch classifier loss: 0.311087; batch adversarial loss: 0.562477\n",
      "epoch 126; iter: 0; batch classifier loss: 0.354096; batch adversarial loss: 0.598721\n",
      "epoch 127; iter: 0; batch classifier loss: 0.293869; batch adversarial loss: 0.642514\n",
      "epoch 128; iter: 0; batch classifier loss: 0.347174; batch adversarial loss: 0.527233\n",
      "epoch 129; iter: 0; batch classifier loss: 0.351994; batch adversarial loss: 0.562228\n",
      "epoch 130; iter: 0; batch classifier loss: 0.328648; batch adversarial loss: 0.552541\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331463; batch adversarial loss: 0.552879\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359603; batch adversarial loss: 0.553093\n",
      "epoch 133; iter: 0; batch classifier loss: 0.315553; batch adversarial loss: 0.509310\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440027; batch adversarial loss: 0.544993\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361944; batch adversarial loss: 0.501122\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364203; batch adversarial loss: 0.623522\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382438; batch adversarial loss: 0.617578\n",
      "epoch 138; iter: 0; batch classifier loss: 0.299705; batch adversarial loss: 0.596973\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321994; batch adversarial loss: 0.536665\n",
      "epoch 140; iter: 0; batch classifier loss: 0.441526; batch adversarial loss: 0.624554\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365483; batch adversarial loss: 0.526092\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338220; batch adversarial loss: 0.536144\n",
      "epoch 143; iter: 0; batch classifier loss: 0.335757; batch adversarial loss: 0.623249\n",
      "epoch 144; iter: 0; batch classifier loss: 0.364875; batch adversarial loss: 0.491353\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323963; batch adversarial loss: 0.562356\n",
      "epoch 146; iter: 0; batch classifier loss: 0.362377; batch adversarial loss: 0.589096\n",
      "epoch 147; iter: 0; batch classifier loss: 0.420286; batch adversarial loss: 0.473019\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417293; batch adversarial loss: 0.526776\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373687; batch adversarial loss: 0.561960\n",
      "epoch 150; iter: 0; batch classifier loss: 0.329755; batch adversarial loss: 0.561266\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341460; batch adversarial loss: 0.578560\n",
      "epoch 152; iter: 0; batch classifier loss: 0.281133; batch adversarial loss: 0.535590\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329433; batch adversarial loss: 0.464808\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332252; batch adversarial loss: 0.535220\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381401; batch adversarial loss: 0.537749\n",
      "epoch 156; iter: 0; batch classifier loss: 0.483606; batch adversarial loss: 0.554492\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409089; batch adversarial loss: 0.553891\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361255; batch adversarial loss: 0.543937\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311160; batch adversarial loss: 0.472927\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319438; batch adversarial loss: 0.579313\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361510; batch adversarial loss: 0.658926\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350112; batch adversarial loss: 0.553553\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349714; batch adversarial loss: 0.500269\n",
      "epoch 164; iter: 0; batch classifier loss: 0.446026; batch adversarial loss: 0.607141\n",
      "epoch 165; iter: 0; batch classifier loss: 0.417902; batch adversarial loss: 0.623478\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395974; batch adversarial loss: 0.448262\n",
      "epoch 167; iter: 0; batch classifier loss: 0.305712; batch adversarial loss: 0.561965\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372003; batch adversarial loss: 0.554184\n",
      "epoch 169; iter: 0; batch classifier loss: 0.359335; batch adversarial loss: 0.562494\n",
      "epoch 170; iter: 0; batch classifier loss: 0.340749; batch adversarial loss: 0.519828\n",
      "epoch 171; iter: 0; batch classifier loss: 0.259687; batch adversarial loss: 0.570896\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341079; batch adversarial loss: 0.544523\n",
      "epoch 173; iter: 0; batch classifier loss: 0.309619; batch adversarial loss: 0.499873\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358851; batch adversarial loss: 0.659302\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328790; batch adversarial loss: 0.589042\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356750; batch adversarial loss: 0.536488\n",
      "epoch 177; iter: 0; batch classifier loss: 0.416873; batch adversarial loss: 0.544610\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358820; batch adversarial loss: 0.580248\n",
      "epoch 179; iter: 0; batch classifier loss: 0.335809; batch adversarial loss: 0.580086\n",
      "epoch 180; iter: 0; batch classifier loss: 0.471785; batch adversarial loss: 0.537118\n",
      "epoch 181; iter: 0; batch classifier loss: 0.446998; batch adversarial loss: 0.562189\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342075; batch adversarial loss: 0.605625\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364584; batch adversarial loss: 0.536887\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343825; batch adversarial loss: 0.587828\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376169; batch adversarial loss: 0.500135\n",
      "epoch 186; iter: 0; batch classifier loss: 0.316020; batch adversarial loss: 0.597408\n",
      "epoch 187; iter: 0; batch classifier loss: 0.308288; batch adversarial loss: 0.545047\n",
      "epoch 188; iter: 0; batch classifier loss: 0.320374; batch adversarial loss: 0.607324\n",
      "epoch 189; iter: 0; batch classifier loss: 0.422150; batch adversarial loss: 0.500109\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361354; batch adversarial loss: 0.615237\n",
      "epoch 191; iter: 0; batch classifier loss: 0.442087; batch adversarial loss: 0.587440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.311872; batch adversarial loss: 0.606547\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317035; batch adversarial loss: 0.534964\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377246; batch adversarial loss: 0.519912\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398144; batch adversarial loss: 0.625858\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320606; batch adversarial loss: 0.535003\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385429; batch adversarial loss: 0.563543\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342173; batch adversarial loss: 0.475313\n",
      "epoch 199; iter: 0; batch classifier loss: 0.279352; batch adversarial loss: 0.606074\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692735; batch adversarial loss: 0.717516\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606986; batch adversarial loss: 0.682286\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606067; batch adversarial loss: 0.677172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542719; batch adversarial loss: 0.655012\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558745; batch adversarial loss: 0.621146\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534987; batch adversarial loss: 0.632647\n",
      "epoch 6; iter: 0; batch classifier loss: 0.466526; batch adversarial loss: 0.665550\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485441; batch adversarial loss: 0.652498\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541385; batch adversarial loss: 0.563599\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528669; batch adversarial loss: 0.621930\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492796; batch adversarial loss: 0.542493\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502640; batch adversarial loss: 0.599915\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504688; batch adversarial loss: 0.606596\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493011; batch adversarial loss: 0.539825\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448661; batch adversarial loss: 0.600253\n",
      "epoch 15; iter: 0; batch classifier loss: 0.438027; batch adversarial loss: 0.623804\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493882; batch adversarial loss: 0.591261\n",
      "epoch 17; iter: 0; batch classifier loss: 0.441957; batch adversarial loss: 0.544029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.564724; batch adversarial loss: 0.599625\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508623; batch adversarial loss: 0.584581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.418199; batch adversarial loss: 0.579473\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498614; batch adversarial loss: 0.550169\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489501; batch adversarial loss: 0.550894\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444978; batch adversarial loss: 0.517213\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508033; batch adversarial loss: 0.574892\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471140; batch adversarial loss: 0.556565\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483062; batch adversarial loss: 0.627846\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414593; batch adversarial loss: 0.549213\n",
      "epoch 28; iter: 0; batch classifier loss: 0.449661; batch adversarial loss: 0.611579\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490138; batch adversarial loss: 0.613852\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428906; batch adversarial loss: 0.545354\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432607; batch adversarial loss: 0.520058\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460621; batch adversarial loss: 0.586582\n",
      "epoch 33; iter: 0; batch classifier loss: 0.454776; batch adversarial loss: 0.469312\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440073; batch adversarial loss: 0.553044\n",
      "epoch 35; iter: 0; batch classifier loss: 0.512502; batch adversarial loss: 0.597359\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482862; batch adversarial loss: 0.502958\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456295; batch adversarial loss: 0.554278\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451664; batch adversarial loss: 0.511405\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443936; batch adversarial loss: 0.579172\n",
      "epoch 40; iter: 0; batch classifier loss: 0.374099; batch adversarial loss: 0.588678\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489594; batch adversarial loss: 0.604784\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434864; batch adversarial loss: 0.606121\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394505; batch adversarial loss: 0.560043\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461798; batch adversarial loss: 0.521533\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404240; batch adversarial loss: 0.578923\n",
      "epoch 46; iter: 0; batch classifier loss: 0.365386; batch adversarial loss: 0.542159\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410366; batch adversarial loss: 0.545678\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425418; batch adversarial loss: 0.567904\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429088; batch adversarial loss: 0.544561\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412275; batch adversarial loss: 0.485505\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424866; batch adversarial loss: 0.560742\n",
      "epoch 52; iter: 0; batch classifier loss: 0.495291; batch adversarial loss: 0.509731\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425431; batch adversarial loss: 0.597168\n",
      "epoch 54; iter: 0; batch classifier loss: 0.382303; batch adversarial loss: 0.580043\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480137; batch adversarial loss: 0.564342\n",
      "epoch 56; iter: 0; batch classifier loss: 0.381427; batch adversarial loss: 0.625046\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402069; batch adversarial loss: 0.656252\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452287; batch adversarial loss: 0.605447\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431611; batch adversarial loss: 0.577260\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394162; batch adversarial loss: 0.597143\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399887; batch adversarial loss: 0.607498\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424074; batch adversarial loss: 0.525003\n",
      "epoch 63; iter: 0; batch classifier loss: 0.353175; batch adversarial loss: 0.584453\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457713; batch adversarial loss: 0.544564\n",
      "epoch 65; iter: 0; batch classifier loss: 0.497054; batch adversarial loss: 0.503087\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430462; batch adversarial loss: 0.509217\n",
      "epoch 67; iter: 0; batch classifier loss: 0.419128; batch adversarial loss: 0.533370\n",
      "epoch 68; iter: 0; batch classifier loss: 0.467328; batch adversarial loss: 0.497435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420659; batch adversarial loss: 0.576630\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366009; batch adversarial loss: 0.535336\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444746; batch adversarial loss: 0.578555\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398973; batch adversarial loss: 0.544866\n",
      "epoch 73; iter: 0; batch classifier loss: 0.516788; batch adversarial loss: 0.639661\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364516; batch adversarial loss: 0.556126\n",
      "epoch 75; iter: 0; batch classifier loss: 0.456465; batch adversarial loss: 0.505949\n",
      "epoch 76; iter: 0; batch classifier loss: 0.327197; batch adversarial loss: 0.507062\n",
      "epoch 77; iter: 0; batch classifier loss: 0.489651; batch adversarial loss: 0.499503\n",
      "epoch 78; iter: 0; batch classifier loss: 0.464356; batch adversarial loss: 0.576604\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439028; batch adversarial loss: 0.500074\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381891; batch adversarial loss: 0.552791\n",
      "epoch 81; iter: 0; batch classifier loss: 0.468219; batch adversarial loss: 0.600342\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440376; batch adversarial loss: 0.495420\n",
      "epoch 83; iter: 0; batch classifier loss: 0.482287; batch adversarial loss: 0.577798\n",
      "epoch 84; iter: 0; batch classifier loss: 0.350453; batch adversarial loss: 0.519612\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382713; batch adversarial loss: 0.556208\n",
      "epoch 86; iter: 0; batch classifier loss: 0.376709; batch adversarial loss: 0.619730\n",
      "epoch 87; iter: 0; batch classifier loss: 0.449293; batch adversarial loss: 0.572768\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430636; batch adversarial loss: 0.610153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.443950; batch adversarial loss: 0.546401\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412163; batch adversarial loss: 0.539788\n",
      "epoch 91; iter: 0; batch classifier loss: 0.514283; batch adversarial loss: 0.542329\n",
      "epoch 92; iter: 0; batch classifier loss: 0.416387; batch adversarial loss: 0.524705\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392638; batch adversarial loss: 0.594334\n",
      "epoch 94; iter: 0; batch classifier loss: 0.344526; batch adversarial loss: 0.557777\n",
      "epoch 95; iter: 0; batch classifier loss: 0.421351; batch adversarial loss: 0.547575\n",
      "epoch 96; iter: 0; batch classifier loss: 0.325688; batch adversarial loss: 0.471636\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418005; batch adversarial loss: 0.546140\n",
      "epoch 98; iter: 0; batch classifier loss: 0.407092; batch adversarial loss: 0.577459\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396003; batch adversarial loss: 0.597748\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350000; batch adversarial loss: 0.577557\n",
      "epoch 101; iter: 0; batch classifier loss: 0.523412; batch adversarial loss: 0.461188\n",
      "epoch 102; iter: 0; batch classifier loss: 0.329262; batch adversarial loss: 0.596691\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383954; batch adversarial loss: 0.633557\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390413; batch adversarial loss: 0.545770\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427938; batch adversarial loss: 0.577622\n",
      "epoch 106; iter: 0; batch classifier loss: 0.444870; batch adversarial loss: 0.499834\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363371; batch adversarial loss: 0.585570\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393928; batch adversarial loss: 0.709165\n",
      "epoch 109; iter: 0; batch classifier loss: 0.314710; batch adversarial loss: 0.536432\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348564; batch adversarial loss: 0.530713\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398290; batch adversarial loss: 0.632188\n",
      "epoch 112; iter: 0; batch classifier loss: 0.449580; batch adversarial loss: 0.474284\n",
      "epoch 113; iter: 0; batch classifier loss: 0.397730; batch adversarial loss: 0.501528\n",
      "epoch 114; iter: 0; batch classifier loss: 0.335235; batch adversarial loss: 0.553841\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374750; batch adversarial loss: 0.540503\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379785; batch adversarial loss: 0.526084\n",
      "epoch 117; iter: 0; batch classifier loss: 0.366349; batch adversarial loss: 0.588501\n",
      "epoch 118; iter: 0; batch classifier loss: 0.477243; batch adversarial loss: 0.502298\n",
      "epoch 119; iter: 0; batch classifier loss: 0.275310; batch adversarial loss: 0.534866\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370828; batch adversarial loss: 0.564529\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361632; batch adversarial loss: 0.563526\n",
      "epoch 122; iter: 0; batch classifier loss: 0.426205; batch adversarial loss: 0.483274\n",
      "epoch 123; iter: 0; batch classifier loss: 0.298017; batch adversarial loss: 0.580482\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397988; batch adversarial loss: 0.500162\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389153; batch adversarial loss: 0.544761\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380936; batch adversarial loss: 0.605355\n",
      "epoch 127; iter: 0; batch classifier loss: 0.414269; batch adversarial loss: 0.606245\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362322; batch adversarial loss: 0.543228\n",
      "epoch 129; iter: 0; batch classifier loss: 0.396643; batch adversarial loss: 0.543481\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380217; batch adversarial loss: 0.551627\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338865; batch adversarial loss: 0.581845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.391054; batch adversarial loss: 0.510693\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397976; batch adversarial loss: 0.620542\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400446; batch adversarial loss: 0.625779\n",
      "epoch 135; iter: 0; batch classifier loss: 0.472785; batch adversarial loss: 0.502118\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355900; batch adversarial loss: 0.547386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.455678; batch adversarial loss: 0.611086\n",
      "epoch 138; iter: 0; batch classifier loss: 0.277762; batch adversarial loss: 0.473544\n",
      "epoch 139; iter: 0; batch classifier loss: 0.354677; batch adversarial loss: 0.541319\n",
      "epoch 140; iter: 0; batch classifier loss: 0.363289; batch adversarial loss: 0.514942\n",
      "epoch 141; iter: 0; batch classifier loss: 0.436837; batch adversarial loss: 0.484654\n",
      "epoch 142; iter: 0; batch classifier loss: 0.349890; batch adversarial loss: 0.621040\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395811; batch adversarial loss: 0.644099\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356946; batch adversarial loss: 0.613319\n",
      "epoch 145; iter: 0; batch classifier loss: 0.318829; batch adversarial loss: 0.470644\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410359; batch adversarial loss: 0.507926\n",
      "epoch 147; iter: 0; batch classifier loss: 0.356485; batch adversarial loss: 0.590962\n",
      "epoch 148; iter: 0; batch classifier loss: 0.439822; batch adversarial loss: 0.476764\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347747; batch adversarial loss: 0.556059\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430193; batch adversarial loss: 0.591982\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352656; batch adversarial loss: 0.564865\n",
      "epoch 152; iter: 0; batch classifier loss: 0.346058; batch adversarial loss: 0.606762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386703; batch adversarial loss: 0.525166\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400630; batch adversarial loss: 0.577830\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357013; batch adversarial loss: 0.580853\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396900; batch adversarial loss: 0.606021\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326503; batch adversarial loss: 0.511071\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352981; batch adversarial loss: 0.559502\n",
      "epoch 159; iter: 0; batch classifier loss: 0.409031; batch adversarial loss: 0.627551\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400167; batch adversarial loss: 0.524168\n",
      "epoch 161; iter: 0; batch classifier loss: 0.409382; batch adversarial loss: 0.581723\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365486; batch adversarial loss: 0.600081\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420177; batch adversarial loss: 0.563040\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351866; batch adversarial loss: 0.547860\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315012; batch adversarial loss: 0.606481\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358631; batch adversarial loss: 0.527980\n",
      "epoch 167; iter: 0; batch classifier loss: 0.316674; batch adversarial loss: 0.566316\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402983; batch adversarial loss: 0.553018\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317202; batch adversarial loss: 0.519242\n",
      "epoch 170; iter: 0; batch classifier loss: 0.265296; batch adversarial loss: 0.492965\n",
      "epoch 171; iter: 0; batch classifier loss: 0.306165; batch adversarial loss: 0.540550\n",
      "epoch 172; iter: 0; batch classifier loss: 0.401837; batch adversarial loss: 0.519114\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362930; batch adversarial loss: 0.527792\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358848; batch adversarial loss: 0.623260\n",
      "epoch 175; iter: 0; batch classifier loss: 0.426576; batch adversarial loss: 0.545467\n",
      "epoch 176; iter: 0; batch classifier loss: 0.401491; batch adversarial loss: 0.605671\n",
      "epoch 177; iter: 0; batch classifier loss: 0.391232; batch adversarial loss: 0.501536\n",
      "epoch 178; iter: 0; batch classifier loss: 0.375046; batch adversarial loss: 0.534281\n",
      "epoch 179; iter: 0; batch classifier loss: 0.416654; batch adversarial loss: 0.475486\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371698; batch adversarial loss: 0.585087\n",
      "epoch 181; iter: 0; batch classifier loss: 0.436910; batch adversarial loss: 0.531418\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355745; batch adversarial loss: 0.595649\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370669; batch adversarial loss: 0.530415\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413994; batch adversarial loss: 0.529627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.455465; batch adversarial loss: 0.568885\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404395; batch adversarial loss: 0.501140\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356067; batch adversarial loss: 0.454389\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318416; batch adversarial loss: 0.532099\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377921; batch adversarial loss: 0.525372\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364099; batch adversarial loss: 0.502115\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316606; batch adversarial loss: 0.538225\n",
      "epoch 192; iter: 0; batch classifier loss: 0.471584; batch adversarial loss: 0.566360\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390499; batch adversarial loss: 0.497901\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380134; batch adversarial loss: 0.559520\n",
      "epoch 195; iter: 0; batch classifier loss: 0.413959; batch adversarial loss: 0.553493\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314174; batch adversarial loss: 0.579538\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364404; batch adversarial loss: 0.531357\n",
      "epoch 198; iter: 0; batch classifier loss: 0.255489; batch adversarial loss: 0.526859\n",
      "epoch 199; iter: 0; batch classifier loss: 0.354347; batch adversarial loss: 0.592080\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740520; batch adversarial loss: 0.672547\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604942; batch adversarial loss: 0.658360\n",
      "epoch 2; iter: 0; batch classifier loss: 0.642769; batch adversarial loss: 0.632415\n",
      "epoch 3; iter: 0; batch classifier loss: 0.505112; batch adversarial loss: 0.634361\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542721; batch adversarial loss: 0.637808\n",
      "epoch 5; iter: 0; batch classifier loss: 0.485238; batch adversarial loss: 0.571502\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567606; batch adversarial loss: 0.576032\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555704; batch adversarial loss: 0.631164\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555866; batch adversarial loss: 0.587623\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562822; batch adversarial loss: 0.635372\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508359; batch adversarial loss: 0.535135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591821; batch adversarial loss: 0.624524\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497611; batch adversarial loss: 0.617448\n",
      "epoch 13; iter: 0; batch classifier loss: 0.596214; batch adversarial loss: 0.557248\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526235; batch adversarial loss: 0.599753\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563739; batch adversarial loss: 0.637021\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469772; batch adversarial loss: 0.628247\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499196; batch adversarial loss: 0.516243\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482607; batch adversarial loss: 0.573528\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437762; batch adversarial loss: 0.630286\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501152; batch adversarial loss: 0.519054\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536258; batch adversarial loss: 0.548177\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507519; batch adversarial loss: 0.584116\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426857; batch adversarial loss: 0.516669\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510238; batch adversarial loss: 0.537704\n",
      "epoch 25; iter: 0; batch classifier loss: 0.395212; batch adversarial loss: 0.497516\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473635; batch adversarial loss: 0.594612\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492702; batch adversarial loss: 0.508730\n",
      "epoch 28; iter: 0; batch classifier loss: 0.367756; batch adversarial loss: 0.595249\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466712; batch adversarial loss: 0.652169\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430819; batch adversarial loss: 0.562554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437782; batch adversarial loss: 0.520502\n",
      "epoch 32; iter: 0; batch classifier loss: 0.515466; batch adversarial loss: 0.545230\n",
      "epoch 33; iter: 0; batch classifier loss: 0.350026; batch adversarial loss: 0.527899\n",
      "epoch 34; iter: 0; batch classifier loss: 0.400401; batch adversarial loss: 0.570494\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502611; batch adversarial loss: 0.579711\n",
      "epoch 36; iter: 0; batch classifier loss: 0.501437; batch adversarial loss: 0.607061\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454501; batch adversarial loss: 0.623363\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451563; batch adversarial loss: 0.570942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.492219; batch adversarial loss: 0.580148\n",
      "epoch 40; iter: 0; batch classifier loss: 0.478677; batch adversarial loss: 0.535787\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489466; batch adversarial loss: 0.571441\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422520; batch adversarial loss: 0.464494\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440445; batch adversarial loss: 0.544872\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388313; batch adversarial loss: 0.525470\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418227; batch adversarial loss: 0.624960\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408216; batch adversarial loss: 0.545506\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402501; batch adversarial loss: 0.571460\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435498; batch adversarial loss: 0.535526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.338533; batch adversarial loss: 0.553725\n",
      "epoch 50; iter: 0; batch classifier loss: 0.589255; batch adversarial loss: 0.552732\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445163; batch adversarial loss: 0.544194\n",
      "epoch 52; iter: 0; batch classifier loss: 0.504153; batch adversarial loss: 0.490676\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436273; batch adversarial loss: 0.553380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381569; batch adversarial loss: 0.570976\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382689; batch adversarial loss: 0.553850\n",
      "epoch 56; iter: 0; batch classifier loss: 0.342330; batch adversarial loss: 0.544145\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414913; batch adversarial loss: 0.562944\n",
      "epoch 58; iter: 0; batch classifier loss: 0.501856; batch adversarial loss: 0.533869\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444341; batch adversarial loss: 0.553209\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389049; batch adversarial loss: 0.625158\n",
      "epoch 61; iter: 0; batch classifier loss: 0.344603; batch adversarial loss: 0.571803\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444420; batch adversarial loss: 0.580331\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412063; batch adversarial loss: 0.560483\n",
      "epoch 64; iter: 0; batch classifier loss: 0.337411; batch adversarial loss: 0.598728\n",
      "epoch 65; iter: 0; batch classifier loss: 0.349648; batch adversarial loss: 0.616967\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416798; batch adversarial loss: 0.535491\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400478; batch adversarial loss: 0.544456\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390845; batch adversarial loss: 0.616650\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374687; batch adversarial loss: 0.589730\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352914; batch adversarial loss: 0.554081\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426674; batch adversarial loss: 0.482490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387249; batch adversarial loss: 0.553043\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374272; batch adversarial loss: 0.707174\n",
      "epoch 74; iter: 0; batch classifier loss: 0.342072; batch adversarial loss: 0.598106\n",
      "epoch 75; iter: 0; batch classifier loss: 0.374286; batch adversarial loss: 0.544315\n",
      "epoch 76; iter: 0; batch classifier loss: 0.453689; batch adversarial loss: 0.535332\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371236; batch adversarial loss: 0.544945\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453743; batch adversarial loss: 0.535572\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415808; batch adversarial loss: 0.526823\n",
      "epoch 80; iter: 0; batch classifier loss: 0.471839; batch adversarial loss: 0.544634\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370771; batch adversarial loss: 0.580347\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410653; batch adversarial loss: 0.536514\n",
      "epoch 83; iter: 0; batch classifier loss: 0.273401; batch adversarial loss: 0.581108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.399352; batch adversarial loss: 0.508749\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364039; batch adversarial loss: 0.581229\n",
      "epoch 86; iter: 0; batch classifier loss: 0.298799; batch adversarial loss: 0.590388\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366583; batch adversarial loss: 0.562733\n",
      "epoch 88; iter: 0; batch classifier loss: 0.390138; batch adversarial loss: 0.589849\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370535; batch adversarial loss: 0.635454\n",
      "epoch 90; iter: 0; batch classifier loss: 0.379898; batch adversarial loss: 0.535499\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354891; batch adversarial loss: 0.517308\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441627; batch adversarial loss: 0.562676\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375196; batch adversarial loss: 0.553595\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363686; batch adversarial loss: 0.499715\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322640; batch adversarial loss: 0.472679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.456622; batch adversarial loss: 0.518300\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378023; batch adversarial loss: 0.553957\n",
      "epoch 98; iter: 0; batch classifier loss: 0.463301; batch adversarial loss: 0.580893\n",
      "epoch 99; iter: 0; batch classifier loss: 0.317416; batch adversarial loss: 0.616418\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394435; batch adversarial loss: 0.526463\n",
      "epoch 101; iter: 0; batch classifier loss: 0.425403; batch adversarial loss: 0.526985\n",
      "epoch 102; iter: 0; batch classifier loss: 0.303949; batch adversarial loss: 0.606591\n",
      "epoch 103; iter: 0; batch classifier loss: 0.343511; batch adversarial loss: 0.580147\n",
      "epoch 104; iter: 0; batch classifier loss: 0.473864; batch adversarial loss: 0.553821\n",
      "epoch 105; iter: 0; batch classifier loss: 0.430275; batch adversarial loss: 0.562511\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328955; batch adversarial loss: 0.571835\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430428; batch adversarial loss: 0.553675\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413077; batch adversarial loss: 0.562834\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346657; batch adversarial loss: 0.553397\n",
      "epoch 110; iter: 0; batch classifier loss: 0.417760; batch adversarial loss: 0.508469\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369910; batch adversarial loss: 0.589442\n",
      "epoch 112; iter: 0; batch classifier loss: 0.341491; batch adversarial loss: 0.517628\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343475; batch adversarial loss: 0.491049\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384287; batch adversarial loss: 0.508813\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342734; batch adversarial loss: 0.535327\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359561; batch adversarial loss: 0.517661\n",
      "epoch 117; iter: 0; batch classifier loss: 0.397945; batch adversarial loss: 0.562971\n",
      "epoch 118; iter: 0; batch classifier loss: 0.331755; batch adversarial loss: 0.562938\n",
      "epoch 119; iter: 0; batch classifier loss: 0.449637; batch adversarial loss: 0.490609\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366587; batch adversarial loss: 0.553924\n",
      "epoch 121; iter: 0; batch classifier loss: 0.371550; batch adversarial loss: 0.563415\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360646; batch adversarial loss: 0.580523\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336048; batch adversarial loss: 0.552738\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353291; batch adversarial loss: 0.526783\n",
      "epoch 125; iter: 0; batch classifier loss: 0.335364; batch adversarial loss: 0.526393\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374238; batch adversarial loss: 0.535216\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341008; batch adversarial loss: 0.526737\n",
      "epoch 128; iter: 0; batch classifier loss: 0.427717; batch adversarial loss: 0.526930\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401786; batch adversarial loss: 0.562571\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395640; batch adversarial loss: 0.544285\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384979; batch adversarial loss: 0.588869\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363546; batch adversarial loss: 0.526346\n",
      "epoch 133; iter: 0; batch classifier loss: 0.323160; batch adversarial loss: 0.535658\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355253; batch adversarial loss: 0.598686\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381755; batch adversarial loss: 0.653002\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373486; batch adversarial loss: 0.581192\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388412; batch adversarial loss: 0.526403\n",
      "epoch 138; iter: 0; batch classifier loss: 0.371633; batch adversarial loss: 0.598285\n",
      "epoch 139; iter: 0; batch classifier loss: 0.445353; batch adversarial loss: 0.463343\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361407; batch adversarial loss: 0.571442\n",
      "epoch 141; iter: 0; batch classifier loss: 0.331242; batch adversarial loss: 0.580011\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334079; batch adversarial loss: 0.526753\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391523; batch adversarial loss: 0.490103\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366776; batch adversarial loss: 0.588182\n",
      "epoch 145; iter: 0; batch classifier loss: 0.417230; batch adversarial loss: 0.571180\n",
      "epoch 146; iter: 0; batch classifier loss: 0.286634; batch adversarial loss: 0.652444\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339539; batch adversarial loss: 0.526128\n",
      "epoch 148; iter: 0; batch classifier loss: 0.295693; batch adversarial loss: 0.643381\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347654; batch adversarial loss: 0.553507\n",
      "epoch 150; iter: 0; batch classifier loss: 0.269096; batch adversarial loss: 0.544830\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392418; batch adversarial loss: 0.534649\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394064; batch adversarial loss: 0.589725\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352175; batch adversarial loss: 0.526976\n",
      "epoch 154; iter: 0; batch classifier loss: 0.305699; batch adversarial loss: 0.490962\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379884; batch adversarial loss: 0.526253\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336378; batch adversarial loss: 0.463852\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350375; batch adversarial loss: 0.517198\n",
      "epoch 158; iter: 0; batch classifier loss: 0.335619; batch adversarial loss: 0.553264\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344544; batch adversarial loss: 0.535470\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326406; batch adversarial loss: 0.589512\n",
      "epoch 161; iter: 0; batch classifier loss: 0.293054; batch adversarial loss: 0.616631\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343355; batch adversarial loss: 0.607527\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419213; batch adversarial loss: 0.526784\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335191; batch adversarial loss: 0.544463\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339461; batch adversarial loss: 0.625416\n",
      "epoch 166; iter: 0; batch classifier loss: 0.457464; batch adversarial loss: 0.482150\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390734; batch adversarial loss: 0.544605\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352920; batch adversarial loss: 0.598884\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354256; batch adversarial loss: 0.589862\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355711; batch adversarial loss: 0.509107\n",
      "epoch 171; iter: 0; batch classifier loss: 0.413481; batch adversarial loss: 0.535328\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370256; batch adversarial loss: 0.508467\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373478; batch adversarial loss: 0.625261\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370751; batch adversarial loss: 0.454377\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345912; batch adversarial loss: 0.527356\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381043; batch adversarial loss: 0.570897\n",
      "epoch 177; iter: 0; batch classifier loss: 0.282680; batch adversarial loss: 0.545164\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372087; batch adversarial loss: 0.562840\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366997; batch adversarial loss: 0.616670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.302298; batch adversarial loss: 0.598017\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386097; batch adversarial loss: 0.589904\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324813; batch adversarial loss: 0.481228\n",
      "epoch 183; iter: 0; batch classifier loss: 0.314825; batch adversarial loss: 0.535563\n",
      "epoch 184; iter: 0; batch classifier loss: 0.263939; batch adversarial loss: 0.525724\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361855; batch adversarial loss: 0.472559\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312660; batch adversarial loss: 0.536782\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336341; batch adversarial loss: 0.509138\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362471; batch adversarial loss: 0.473068\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350370; batch adversarial loss: 0.527616\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333192; batch adversarial loss: 0.544798\n",
      "epoch 191; iter: 0; batch classifier loss: 0.375198; batch adversarial loss: 0.589081\n",
      "epoch 192; iter: 0; batch classifier loss: 0.286401; batch adversarial loss: 0.580908\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368405; batch adversarial loss: 0.535960\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330686; batch adversarial loss: 0.544125\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336853; batch adversarial loss: 0.535593\n",
      "epoch 196; iter: 0; batch classifier loss: 0.297237; batch adversarial loss: 0.545423\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366412; batch adversarial loss: 0.508694\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329356; batch adversarial loss: 0.535522\n",
      "epoch 199; iter: 0; batch classifier loss: 0.269503; batch adversarial loss: 0.554010\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687886; batch adversarial loss: 0.697565\n",
      "epoch 1; iter: 0; batch classifier loss: 0.640781; batch adversarial loss: 0.644814\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594894; batch adversarial loss: 0.689420\n",
      "epoch 3; iter: 0; batch classifier loss: 0.524053; batch adversarial loss: 0.684995\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533885; batch adversarial loss: 0.658852\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521934; batch adversarial loss: 0.626680\n",
      "epoch 6; iter: 0; batch classifier loss: 0.455507; batch adversarial loss: 0.595528\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494569; batch adversarial loss: 0.546847\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528576; batch adversarial loss: 0.524460\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530622; batch adversarial loss: 0.511886\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468596; batch adversarial loss: 0.586575\n",
      "epoch 11; iter: 0; batch classifier loss: 0.466889; batch adversarial loss: 0.625448\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502978; batch adversarial loss: 0.583875\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482796; batch adversarial loss: 0.523249\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520132; batch adversarial loss: 0.572057\n",
      "epoch 15; iter: 0; batch classifier loss: 0.517928; batch adversarial loss: 0.605983\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483161; batch adversarial loss: 0.555586\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489879; batch adversarial loss: 0.517372\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462216; batch adversarial loss: 0.562912\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475775; batch adversarial loss: 0.631283\n",
      "epoch 20; iter: 0; batch classifier loss: 0.464698; batch adversarial loss: 0.616489\n",
      "epoch 21; iter: 0; batch classifier loss: 0.423047; batch adversarial loss: 0.568789\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437572; batch adversarial loss: 0.615054\n",
      "epoch 23; iter: 0; batch classifier loss: 0.608969; batch adversarial loss: 0.479582\n",
      "epoch 24; iter: 0; batch classifier loss: 0.532400; batch adversarial loss: 0.582080\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443664; batch adversarial loss: 0.526427\n",
      "epoch 26; iter: 0; batch classifier loss: 0.429098; batch adversarial loss: 0.514155\n",
      "epoch 27; iter: 0; batch classifier loss: 0.371961; batch adversarial loss: 0.600467\n",
      "epoch 28; iter: 0; batch classifier loss: 0.412566; batch adversarial loss: 0.491551\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435618; batch adversarial loss: 0.575127\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491597; batch adversarial loss: 0.534243\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483471; batch adversarial loss: 0.517047\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475270; batch adversarial loss: 0.555923\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438402; batch adversarial loss: 0.616500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427606; batch adversarial loss: 0.537389\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469545; batch adversarial loss: 0.519863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519557; batch adversarial loss: 0.563783\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414297; batch adversarial loss: 0.615186\n",
      "epoch 38; iter: 0; batch classifier loss: 0.485124; batch adversarial loss: 0.555134\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499966; batch adversarial loss: 0.536264\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495315; batch adversarial loss: 0.527887\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455024; batch adversarial loss: 0.597526\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470718; batch adversarial loss: 0.545035\n",
      "epoch 43; iter: 0; batch classifier loss: 0.389269; batch adversarial loss: 0.588735\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467424; batch adversarial loss: 0.562310\n",
      "epoch 45; iter: 0; batch classifier loss: 0.519323; batch adversarial loss: 0.457570\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397536; batch adversarial loss: 0.571414\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431258; batch adversarial loss: 0.500451\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406963; batch adversarial loss: 0.606782\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433072; batch adversarial loss: 0.544382\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441698; batch adversarial loss: 0.464654\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432169; batch adversarial loss: 0.536137\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520387; batch adversarial loss: 0.527025\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450834; batch adversarial loss: 0.571012\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447252; batch adversarial loss: 0.607888\n",
      "epoch 55; iter: 0; batch classifier loss: 0.353836; batch adversarial loss: 0.625371\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398369; batch adversarial loss: 0.535131\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428768; batch adversarial loss: 0.535933\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464085; batch adversarial loss: 0.553272\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426434; batch adversarial loss: 0.527000\n",
      "epoch 60; iter: 0; batch classifier loss: 0.538423; batch adversarial loss: 0.526791\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409177; batch adversarial loss: 0.491120\n",
      "epoch 62; iter: 0; batch classifier loss: 0.458140; batch adversarial loss: 0.580340\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402199; batch adversarial loss: 0.518204\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375998; batch adversarial loss: 0.535055\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431748; batch adversarial loss: 0.589303\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425039; batch adversarial loss: 0.580456\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399719; batch adversarial loss: 0.569986\n",
      "epoch 68; iter: 0; batch classifier loss: 0.340639; batch adversarial loss: 0.578271\n",
      "epoch 69; iter: 0; batch classifier loss: 0.370053; batch adversarial loss: 0.569339\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400646; batch adversarial loss: 0.595981\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420990; batch adversarial loss: 0.466042\n",
      "epoch 72; iter: 0; batch classifier loss: 0.351219; batch adversarial loss: 0.617145\n",
      "epoch 73; iter: 0; batch classifier loss: 0.395082; batch adversarial loss: 0.692769\n",
      "epoch 74; iter: 0; batch classifier loss: 0.504989; batch adversarial loss: 0.539647\n",
      "epoch 75; iter: 0; batch classifier loss: 0.365330; batch adversarial loss: 0.527728\n",
      "epoch 76; iter: 0; batch classifier loss: 0.438814; batch adversarial loss: 0.537087\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423364; batch adversarial loss: 0.555490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.402048; batch adversarial loss: 0.488872\n",
      "epoch 79; iter: 0; batch classifier loss: 0.427800; batch adversarial loss: 0.572850\n",
      "epoch 80; iter: 0; batch classifier loss: 0.310737; batch adversarial loss: 0.498878\n",
      "epoch 81; iter: 0; batch classifier loss: 0.474296; batch adversarial loss: 0.636781\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378907; batch adversarial loss: 0.627198\n",
      "epoch 83; iter: 0; batch classifier loss: 0.327591; batch adversarial loss: 0.544388\n",
      "epoch 84; iter: 0; batch classifier loss: 0.318253; batch adversarial loss: 0.590872\n",
      "epoch 85; iter: 0; batch classifier loss: 0.475534; batch adversarial loss: 0.526726\n",
      "epoch 86; iter: 0; batch classifier loss: 0.340849; batch adversarial loss: 0.490272\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365202; batch adversarial loss: 0.580599\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392644; batch adversarial loss: 0.571950\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374100; batch adversarial loss: 0.589124\n",
      "epoch 90; iter: 0; batch classifier loss: 0.467058; batch adversarial loss: 0.564347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402490; batch adversarial loss: 0.509503\n",
      "epoch 92; iter: 0; batch classifier loss: 0.356221; batch adversarial loss: 0.596952\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412900; batch adversarial loss: 0.580914\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384973; batch adversarial loss: 0.526535\n",
      "epoch 95; iter: 0; batch classifier loss: 0.395386; batch adversarial loss: 0.544343\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371227; batch adversarial loss: 0.499959\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404896; batch adversarial loss: 0.562582\n",
      "epoch 98; iter: 0; batch classifier loss: 0.451781; batch adversarial loss: 0.605460\n",
      "epoch 99; iter: 0; batch classifier loss: 0.490189; batch adversarial loss: 0.580389\n",
      "epoch 100; iter: 0; batch classifier loss: 0.419562; batch adversarial loss: 0.535448\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368046; batch adversarial loss: 0.562636\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354795; batch adversarial loss: 0.570624\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378905; batch adversarial loss: 0.599576\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376994; batch adversarial loss: 0.554467\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401899; batch adversarial loss: 0.517914\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385395; batch adversarial loss: 0.588971\n",
      "epoch 107; iter: 0; batch classifier loss: 0.451623; batch adversarial loss: 0.526283\n",
      "epoch 108; iter: 0; batch classifier loss: 0.347461; batch adversarial loss: 0.660749\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353334; batch adversarial loss: 0.561276\n",
      "epoch 110; iter: 0; batch classifier loss: 0.338488; batch adversarial loss: 0.534848\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395482; batch adversarial loss: 0.606000\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378900; batch adversarial loss: 0.598436\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356060; batch adversarial loss: 0.570420\n",
      "epoch 114; iter: 0; batch classifier loss: 0.462906; batch adversarial loss: 0.580933\n",
      "epoch 115; iter: 0; batch classifier loss: 0.315713; batch adversarial loss: 0.543963\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357587; batch adversarial loss: 0.490756\n",
      "epoch 117; iter: 0; batch classifier loss: 0.387142; batch adversarial loss: 0.498542\n",
      "epoch 118; iter: 0; batch classifier loss: 0.380188; batch adversarial loss: 0.571527\n",
      "epoch 119; iter: 0; batch classifier loss: 0.420096; batch adversarial loss: 0.562253\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378047; batch adversarial loss: 0.544786\n",
      "epoch 121; iter: 0; batch classifier loss: 0.432984; batch adversarial loss: 0.544400\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355565; batch adversarial loss: 0.560779\n",
      "epoch 123; iter: 0; batch classifier loss: 0.446052; batch adversarial loss: 0.473500\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322929; batch adversarial loss: 0.578704\n",
      "epoch 125; iter: 0; batch classifier loss: 0.333440; batch adversarial loss: 0.490690\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334912; batch adversarial loss: 0.535511\n",
      "epoch 127; iter: 0; batch classifier loss: 0.413323; batch adversarial loss: 0.597578\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328741; batch adversarial loss: 0.552952\n",
      "epoch 129; iter: 0; batch classifier loss: 0.400962; batch adversarial loss: 0.527227\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362503; batch adversarial loss: 0.516936\n",
      "epoch 131; iter: 0; batch classifier loss: 0.432697; batch adversarial loss: 0.580070\n",
      "epoch 132; iter: 0; batch classifier loss: 0.332072; batch adversarial loss: 0.608163\n",
      "epoch 133; iter: 0; batch classifier loss: 0.353062; batch adversarial loss: 0.571611\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440879; batch adversarial loss: 0.535544\n",
      "epoch 135; iter: 0; batch classifier loss: 0.467017; batch adversarial loss: 0.599726\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411756; batch adversarial loss: 0.598618\n",
      "epoch 137; iter: 0; batch classifier loss: 0.331443; batch adversarial loss: 0.589572\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334833; batch adversarial loss: 0.625341\n",
      "epoch 139; iter: 0; batch classifier loss: 0.381215; batch adversarial loss: 0.526650\n",
      "epoch 140; iter: 0; batch classifier loss: 0.425089; batch adversarial loss: 0.455272\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409595; batch adversarial loss: 0.517049\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311661; batch adversarial loss: 0.606621\n",
      "epoch 143; iter: 0; batch classifier loss: 0.409908; batch adversarial loss: 0.509186\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358966; batch adversarial loss: 0.509269\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372211; batch adversarial loss: 0.536930\n",
      "epoch 146; iter: 0; batch classifier loss: 0.477731; batch adversarial loss: 0.535463\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368796; batch adversarial loss: 0.588567\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338796; batch adversarial loss: 0.464012\n",
      "epoch 149; iter: 0; batch classifier loss: 0.447531; batch adversarial loss: 0.544957\n",
      "epoch 150; iter: 0; batch classifier loss: 0.445269; batch adversarial loss: 0.500601\n",
      "epoch 151; iter: 0; batch classifier loss: 0.401113; batch adversarial loss: 0.588456\n",
      "epoch 152; iter: 0; batch classifier loss: 0.423972; batch adversarial loss: 0.633879\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381651; batch adversarial loss: 0.526407\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316362; batch adversarial loss: 0.535009\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355724; batch adversarial loss: 0.589430\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377478; batch adversarial loss: 0.563814\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381888; batch adversarial loss: 0.570860\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387654; batch adversarial loss: 0.544560\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388449; batch adversarial loss: 0.544048\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400981; batch adversarial loss: 0.553874\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399346; batch adversarial loss: 0.527576\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409864; batch adversarial loss: 0.553017\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392164; batch adversarial loss: 0.544667\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336950; batch adversarial loss: 0.517261\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333833; batch adversarial loss: 0.625832\n",
      "epoch 166; iter: 0; batch classifier loss: 0.432214; batch adversarial loss: 0.525850\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344468; batch adversarial loss: 0.598815\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331592; batch adversarial loss: 0.554798\n",
      "epoch 169; iter: 0; batch classifier loss: 0.443008; batch adversarial loss: 0.481590\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398715; batch adversarial loss: 0.579613\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329501; batch adversarial loss: 0.526702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369742; batch adversarial loss: 0.596839\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373397; batch adversarial loss: 0.472355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.439881; batch adversarial loss: 0.562588\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392852; batch adversarial loss: 0.562800\n",
      "epoch 176; iter: 0; batch classifier loss: 0.303399; batch adversarial loss: 0.499470\n",
      "epoch 177; iter: 0; batch classifier loss: 0.285287; batch adversarial loss: 0.508455\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314875; batch adversarial loss: 0.598684\n",
      "epoch 179; iter: 0; batch classifier loss: 0.294469; batch adversarial loss: 0.507988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.426315; batch adversarial loss: 0.525994\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377800; batch adversarial loss: 0.581119\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374293; batch adversarial loss: 0.662173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364436; batch adversarial loss: 0.552474\n",
      "epoch 184; iter: 0; batch classifier loss: 0.288166; batch adversarial loss: 0.464078\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377962; batch adversarial loss: 0.499210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375540; batch adversarial loss: 0.508485\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369137; batch adversarial loss: 0.581116\n",
      "epoch 188; iter: 0; batch classifier loss: 0.224432; batch adversarial loss: 0.580425\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367432; batch adversarial loss: 0.498580\n",
      "epoch 190; iter: 0; batch classifier loss: 0.284910; batch adversarial loss: 0.517448\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382233; batch adversarial loss: 0.525757\n",
      "epoch 192; iter: 0; batch classifier loss: 0.307114; batch adversarial loss: 0.597441\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376288; batch adversarial loss: 0.615322\n",
      "epoch 194; iter: 0; batch classifier loss: 0.418432; batch adversarial loss: 0.490360\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309165; batch adversarial loss: 0.518433\n",
      "epoch 196; iter: 0; batch classifier loss: 0.409215; batch adversarial loss: 0.615336\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372724; batch adversarial loss: 0.544405\n",
      "epoch 198; iter: 0; batch classifier loss: 0.401102; batch adversarial loss: 0.562840\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393054; batch adversarial loss: 0.472491\n",
      "epoch 0; iter: 0; batch classifier loss: 0.838175; batch adversarial loss: 0.568912\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552575; batch adversarial loss: 0.635863\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619059; batch adversarial loss: 0.629883\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572083; batch adversarial loss: 0.666914\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544354; batch adversarial loss: 0.651600\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583916; batch adversarial loss: 0.584825\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519357; batch adversarial loss: 0.623757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513411; batch adversarial loss: 0.547005\n",
      "epoch 8; iter: 0; batch classifier loss: 0.487278; batch adversarial loss: 0.608380\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514908; batch adversarial loss: 0.652691\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541001; batch adversarial loss: 0.590313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559073; batch adversarial loss: 0.546733\n",
      "epoch 12; iter: 0; batch classifier loss: 0.603805; batch adversarial loss: 0.576000\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553976; batch adversarial loss: 0.572647\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512151; batch adversarial loss: 0.601107\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465406; batch adversarial loss: 0.563463\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538981; batch adversarial loss: 0.536868\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530253; batch adversarial loss: 0.552019\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499943; batch adversarial loss: 0.560336\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465707; batch adversarial loss: 0.524692\n",
      "epoch 20; iter: 0; batch classifier loss: 0.546244; batch adversarial loss: 0.563398\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456765; batch adversarial loss: 0.527038\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486539; batch adversarial loss: 0.560089\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420280; batch adversarial loss: 0.587696\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466009; batch adversarial loss: 0.538113\n",
      "epoch 25; iter: 0; batch classifier loss: 0.391549; batch adversarial loss: 0.618208\n",
      "epoch 26; iter: 0; batch classifier loss: 0.512706; batch adversarial loss: 0.511474\n",
      "epoch 27; iter: 0; batch classifier loss: 0.535311; batch adversarial loss: 0.545542\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505564; batch adversarial loss: 0.612201\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451685; batch adversarial loss: 0.563315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517300; batch adversarial loss: 0.587708\n",
      "epoch 31; iter: 0; batch classifier loss: 0.478247; batch adversarial loss: 0.521412\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446855; batch adversarial loss: 0.554716\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465233; batch adversarial loss: 0.555573\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471614; batch adversarial loss: 0.493502\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435937; batch adversarial loss: 0.587551\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402708; batch adversarial loss: 0.525466\n",
      "epoch 37; iter: 0; batch classifier loss: 0.357334; batch adversarial loss: 0.631734\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467725; batch adversarial loss: 0.596249\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463289; batch adversarial loss: 0.562818\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429158; batch adversarial loss: 0.511093\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417213; batch adversarial loss: 0.553708\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385027; batch adversarial loss: 0.579694\n",
      "epoch 43; iter: 0; batch classifier loss: 0.497102; batch adversarial loss: 0.519044\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465823; batch adversarial loss: 0.562216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431127; batch adversarial loss: 0.588511\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479761; batch adversarial loss: 0.597312\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401523; batch adversarial loss: 0.570969\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412958; batch adversarial loss: 0.649574\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406766; batch adversarial loss: 0.553661\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428818; batch adversarial loss: 0.597073\n",
      "epoch 51; iter: 0; batch classifier loss: 0.346816; batch adversarial loss: 0.527944\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446716; batch adversarial loss: 0.613520\n",
      "epoch 53; iter: 0; batch classifier loss: 0.353217; batch adversarial loss: 0.544737\n",
      "epoch 54; iter: 0; batch classifier loss: 0.368281; batch adversarial loss: 0.580096\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410640; batch adversarial loss: 0.588512\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423325; batch adversarial loss: 0.580503\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369000; batch adversarial loss: 0.597061\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426059; batch adversarial loss: 0.554366\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357724; batch adversarial loss: 0.536046\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397557; batch adversarial loss: 0.536298\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459728; batch adversarial loss: 0.465009\n",
      "epoch 62; iter: 0; batch classifier loss: 0.476282; batch adversarial loss: 0.630928\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395422; batch adversarial loss: 0.466193\n",
      "epoch 64; iter: 0; batch classifier loss: 0.446811; batch adversarial loss: 0.562238\n",
      "epoch 65; iter: 0; batch classifier loss: 0.407632; batch adversarial loss: 0.562687\n",
      "epoch 66; iter: 0; batch classifier loss: 0.314564; batch adversarial loss: 0.588901\n",
      "epoch 67; iter: 0; batch classifier loss: 0.481011; batch adversarial loss: 0.579729\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420499; batch adversarial loss: 0.562385\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411905; batch adversarial loss: 0.621950\n",
      "epoch 70; iter: 0; batch classifier loss: 0.449221; batch adversarial loss: 0.588646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.358315; batch adversarial loss: 0.554976\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388470; batch adversarial loss: 0.562056\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400190; batch adversarial loss: 0.606485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.543721\n",
      "epoch 75; iter: 0; batch classifier loss: 0.299236; batch adversarial loss: 0.458470\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369131; batch adversarial loss: 0.573463\n",
      "epoch 77; iter: 0; batch classifier loss: 0.370983; batch adversarial loss: 0.588067\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453850; batch adversarial loss: 0.611865\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387617; batch adversarial loss: 0.577698\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419894; batch adversarial loss: 0.591318\n",
      "epoch 81; iter: 0; batch classifier loss: 0.334500; batch adversarial loss: 0.580280\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367963; batch adversarial loss: 0.526474\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374782; batch adversarial loss: 0.582034\n",
      "epoch 84; iter: 0; batch classifier loss: 0.431016; batch adversarial loss: 0.570775\n",
      "epoch 85; iter: 0; batch classifier loss: 0.359812; batch adversarial loss: 0.579231\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372155; batch adversarial loss: 0.588584\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382807; batch adversarial loss: 0.482428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356684; batch adversarial loss: 0.483772\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383337; batch adversarial loss: 0.614242\n",
      "epoch 90; iter: 0; batch classifier loss: 0.446341; batch adversarial loss: 0.631224\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352938; batch adversarial loss: 0.501053\n",
      "epoch 92; iter: 0; batch classifier loss: 0.335795; batch adversarial loss: 0.571528\n",
      "epoch 93; iter: 0; batch classifier loss: 0.420939; batch adversarial loss: 0.535063\n",
      "epoch 94; iter: 0; batch classifier loss: 0.445160; batch adversarial loss: 0.581857\n",
      "epoch 95; iter: 0; batch classifier loss: 0.360023; batch adversarial loss: 0.562792\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401097; batch adversarial loss: 0.580736\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395454; batch adversarial loss: 0.598270\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439494; batch adversarial loss: 0.536673\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374293; batch adversarial loss: 0.588372\n",
      "epoch 100; iter: 0; batch classifier loss: 0.344180; batch adversarial loss: 0.545542\n",
      "epoch 101; iter: 0; batch classifier loss: 0.441057; batch adversarial loss: 0.553459\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350093; batch adversarial loss: 0.562649\n",
      "epoch 103; iter: 0; batch classifier loss: 0.348281; batch adversarial loss: 0.491382\n",
      "epoch 104; iter: 0; batch classifier loss: 0.359418; batch adversarial loss: 0.606134\n",
      "epoch 105; iter: 0; batch classifier loss: 0.331765; batch adversarial loss: 0.561980\n",
      "epoch 106; iter: 0; batch classifier loss: 0.423816; batch adversarial loss: 0.508909\n",
      "epoch 107; iter: 0; batch classifier loss: 0.342063; batch adversarial loss: 0.622201\n",
      "epoch 108; iter: 0; batch classifier loss: 0.301072; batch adversarial loss: 0.621652\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337877; batch adversarial loss: 0.562472\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384120; batch adversarial loss: 0.605843\n",
      "epoch 111; iter: 0; batch classifier loss: 0.330986; batch adversarial loss: 0.589090\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381603; batch adversarial loss: 0.535123\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382717; batch adversarial loss: 0.517528\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403117; batch adversarial loss: 0.527507\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404698; batch adversarial loss: 0.491416\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401791; batch adversarial loss: 0.650092\n",
      "epoch 117; iter: 0; batch classifier loss: 0.464296; batch adversarial loss: 0.607164\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376361; batch adversarial loss: 0.551894\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433912; batch adversarial loss: 0.518553\n",
      "epoch 120; iter: 0; batch classifier loss: 0.446997; batch adversarial loss: 0.561443\n",
      "epoch 121; iter: 0; batch classifier loss: 0.336641; batch adversarial loss: 0.598085\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345235; batch adversarial loss: 0.596593\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396103; batch adversarial loss: 0.563654\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387622; batch adversarial loss: 0.579179\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437746; batch adversarial loss: 0.554456\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344666; batch adversarial loss: 0.555049\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353264; batch adversarial loss: 0.536334\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325801; batch adversarial loss: 0.587854\n",
      "epoch 129; iter: 0; batch classifier loss: 0.450360; batch adversarial loss: 0.641763\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383343; batch adversarial loss: 0.526482\n",
      "epoch 131; iter: 0; batch classifier loss: 0.334849; batch adversarial loss: 0.536580\n",
      "epoch 132; iter: 0; batch classifier loss: 0.427737; batch adversarial loss: 0.554124\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334495; batch adversarial loss: 0.606753\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365911; batch adversarial loss: 0.581594\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320327; batch adversarial loss: 0.580056\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383490; batch adversarial loss: 0.595846\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388305; batch adversarial loss: 0.561822\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341155; batch adversarial loss: 0.535924\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375443; batch adversarial loss: 0.623165\n",
      "epoch 140; iter: 0; batch classifier loss: 0.363245; batch adversarial loss: 0.493148\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404508; batch adversarial loss: 0.483051\n",
      "epoch 142; iter: 0; batch classifier loss: 0.267225; batch adversarial loss: 0.579221\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351197; batch adversarial loss: 0.554530\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348351; batch adversarial loss: 0.553404\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360559; batch adversarial loss: 0.597530\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346024; batch adversarial loss: 0.552931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343116; batch adversarial loss: 0.597268\n",
      "epoch 148; iter: 0; batch classifier loss: 0.477770; batch adversarial loss: 0.499441\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326892; batch adversarial loss: 0.571366\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409579; batch adversarial loss: 0.552560\n",
      "epoch 151; iter: 0; batch classifier loss: 0.468772; batch adversarial loss: 0.490990\n",
      "epoch 152; iter: 0; batch classifier loss: 0.271102; batch adversarial loss: 0.509629\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357664; batch adversarial loss: 0.552884\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393520; batch adversarial loss: 0.560671\n",
      "epoch 155; iter: 0; batch classifier loss: 0.385155; batch adversarial loss: 0.501885\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328870; batch adversarial loss: 0.554620\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363354; batch adversarial loss: 0.595826\n",
      "epoch 158; iter: 0; batch classifier loss: 0.443447; batch adversarial loss: 0.660427\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337749; batch adversarial loss: 0.622810\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362925; batch adversarial loss: 0.577459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380756; batch adversarial loss: 0.550935\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398543; batch adversarial loss: 0.545263\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362380; batch adversarial loss: 0.560473\n",
      "epoch 164; iter: 0; batch classifier loss: 0.401451; batch adversarial loss: 0.579868\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383623; batch adversarial loss: 0.570457\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342694; batch adversarial loss: 0.544154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.362249; batch adversarial loss: 0.501297\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323343; batch adversarial loss: 0.624268\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408442; batch adversarial loss: 0.537665\n",
      "epoch 170; iter: 0; batch classifier loss: 0.507109; batch adversarial loss: 0.465933\n",
      "epoch 171; iter: 0; batch classifier loss: 0.430671; batch adversarial loss: 0.528228\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397215; batch adversarial loss: 0.650241\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334291; batch adversarial loss: 0.615981\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374136; batch adversarial loss: 0.543266\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343675; batch adversarial loss: 0.534753\n",
      "epoch 176; iter: 0; batch classifier loss: 0.440019; batch adversarial loss: 0.588551\n",
      "epoch 177; iter: 0; batch classifier loss: 0.332595; batch adversarial loss: 0.534664\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353134; batch adversarial loss: 0.561294\n",
      "epoch 179; iter: 0; batch classifier loss: 0.299295; batch adversarial loss: 0.606552\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343737; batch adversarial loss: 0.545478\n",
      "epoch 181; iter: 0; batch classifier loss: 0.285914; batch adversarial loss: 0.596073\n",
      "epoch 182; iter: 0; batch classifier loss: 0.297145; batch adversarial loss: 0.492735\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398859; batch adversarial loss: 0.580685\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343354; batch adversarial loss: 0.543469\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308638; batch adversarial loss: 0.501645\n",
      "epoch 186; iter: 0; batch classifier loss: 0.389768; batch adversarial loss: 0.552736\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395689; batch adversarial loss: 0.587602\n",
      "epoch 188; iter: 0; batch classifier loss: 0.297565; batch adversarial loss: 0.570464\n",
      "epoch 189; iter: 0; batch classifier loss: 0.303152; batch adversarial loss: 0.579320\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366066; batch adversarial loss: 0.517942\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373815; batch adversarial loss: 0.608139\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320810; batch adversarial loss: 0.544901\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368435; batch adversarial loss: 0.588076\n",
      "epoch 194; iter: 0; batch classifier loss: 0.285603; batch adversarial loss: 0.570791\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290128; batch adversarial loss: 0.623746\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380186; batch adversarial loss: 0.544092\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335196; batch adversarial loss: 0.561909\n",
      "epoch 198; iter: 0; batch classifier loss: 0.298825; batch adversarial loss: 0.551789\n",
      "epoch 199; iter: 0; batch classifier loss: 0.285240; batch adversarial loss: 0.561437\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668339; batch adversarial loss: 0.665244\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597686; batch adversarial loss: 0.653093\n",
      "epoch 2; iter: 0; batch classifier loss: 0.493866; batch adversarial loss: 0.649638\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582185; batch adversarial loss: 0.624731\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585081; batch adversarial loss: 0.617149\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543593; batch adversarial loss: 0.587492\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515234; batch adversarial loss: 0.605454\n",
      "epoch 7; iter: 0; batch classifier loss: 0.637088; batch adversarial loss: 0.595665\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575202; batch adversarial loss: 0.621717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540892; batch adversarial loss: 0.620600\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513928; batch adversarial loss: 0.590415\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549832; batch adversarial loss: 0.575088\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566995; batch adversarial loss: 0.551887\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504720; batch adversarial loss: 0.570608\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534922; batch adversarial loss: 0.602871\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462289; batch adversarial loss: 0.499331\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540290; batch adversarial loss: 0.604944\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497084; batch adversarial loss: 0.523278\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507826; batch adversarial loss: 0.565390\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545249; batch adversarial loss: 0.586867\n",
      "epoch 20; iter: 0; batch classifier loss: 0.598976; batch adversarial loss: 0.576650\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495218; batch adversarial loss: 0.567619\n",
      "epoch 22; iter: 0; batch classifier loss: 0.597127; batch adversarial loss: 0.548021\n",
      "epoch 23; iter: 0; batch classifier loss: 0.453464; batch adversarial loss: 0.552710\n",
      "epoch 24; iter: 0; batch classifier loss: 0.569772; batch adversarial loss: 0.587248\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515397; batch adversarial loss: 0.479563\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465451; batch adversarial loss: 0.521619\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513747; batch adversarial loss: 0.503165\n",
      "epoch 28; iter: 0; batch classifier loss: 0.561240; batch adversarial loss: 0.502798\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508587; batch adversarial loss: 0.556380\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453617; batch adversarial loss: 0.547199\n",
      "epoch 31; iter: 0; batch classifier loss: 0.487496; batch adversarial loss: 0.543424\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499854; batch adversarial loss: 0.605544\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486957; batch adversarial loss: 0.439086\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458902; batch adversarial loss: 0.607294\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436606; batch adversarial loss: 0.534945\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471190; batch adversarial loss: 0.571718\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445254; batch adversarial loss: 0.490518\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438189; batch adversarial loss: 0.508275\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513335; batch adversarial loss: 0.508911\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464511; batch adversarial loss: 0.614776\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421316; batch adversarial loss: 0.588844\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424173; batch adversarial loss: 0.526481\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449922; batch adversarial loss: 0.544666\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455408; batch adversarial loss: 0.526109\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441519; batch adversarial loss: 0.571857\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416423; batch adversarial loss: 0.571800\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487521; batch adversarial loss: 0.489393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464859; batch adversarial loss: 0.572214\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476272; batch adversarial loss: 0.563358\n",
      "epoch 50; iter: 0; batch classifier loss: 0.447387; batch adversarial loss: 0.488878\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466093; batch adversarial loss: 0.488875\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447438; batch adversarial loss: 0.590780\n",
      "epoch 53; iter: 0; batch classifier loss: 0.419968; batch adversarial loss: 0.525672\n",
      "epoch 54; iter: 0; batch classifier loss: 0.396596; batch adversarial loss: 0.563089\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444010; batch adversarial loss: 0.534877\n",
      "epoch 56; iter: 0; batch classifier loss: 0.500745; batch adversarial loss: 0.581805\n",
      "epoch 57; iter: 0; batch classifier loss: 0.460016; batch adversarial loss: 0.580904\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438442; batch adversarial loss: 0.507014\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423940; batch adversarial loss: 0.535768\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442072; batch adversarial loss: 0.470087\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444808; batch adversarial loss: 0.470383\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440277; batch adversarial loss: 0.489963\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390463; batch adversarial loss: 0.517159\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409762; batch adversarial loss: 0.526508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.395622; batch adversarial loss: 0.599802\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409303; batch adversarial loss: 0.618238\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385877; batch adversarial loss: 0.580375\n",
      "epoch 68; iter: 0; batch classifier loss: 0.359771; batch adversarial loss: 0.545546\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415471; batch adversarial loss: 0.608838\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423591; batch adversarial loss: 0.591091\n",
      "epoch 71; iter: 0; batch classifier loss: 0.347285; batch adversarial loss: 0.563223\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418714; batch adversarial loss: 0.497797\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407333; batch adversarial loss: 0.497894\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397377; batch adversarial loss: 0.507474\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395537; batch adversarial loss: 0.591099\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413854; batch adversarial loss: 0.581383\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375650; batch adversarial loss: 0.499581\n",
      "epoch 78; iter: 0; batch classifier loss: 0.384404; batch adversarial loss: 0.553746\n",
      "epoch 79; iter: 0; batch classifier loss: 0.459411; batch adversarial loss: 0.443087\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409817; batch adversarial loss: 0.498720\n",
      "epoch 81; iter: 0; batch classifier loss: 0.377185; batch adversarial loss: 0.534088\n",
      "epoch 82; iter: 0; batch classifier loss: 0.448621; batch adversarial loss: 0.554453\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399060; batch adversarial loss: 0.591397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354632; batch adversarial loss: 0.545299\n",
      "epoch 85; iter: 0; batch classifier loss: 0.306910; batch adversarial loss: 0.571829\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430306; batch adversarial loss: 0.479960\n",
      "epoch 87; iter: 0; batch classifier loss: 0.433129; batch adversarial loss: 0.516806\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414700; batch adversarial loss: 0.572573\n",
      "epoch 89; iter: 0; batch classifier loss: 0.457433; batch adversarial loss: 0.480656\n",
      "epoch 90; iter: 0; batch classifier loss: 0.471057; batch adversarial loss: 0.544565\n",
      "epoch 91; iter: 0; batch classifier loss: 0.425812; batch adversarial loss: 0.573336\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395143; batch adversarial loss: 0.553423\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439236; batch adversarial loss: 0.617079\n",
      "epoch 94; iter: 0; batch classifier loss: 0.300114; batch adversarial loss: 0.517053\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376049; batch adversarial loss: 0.516624\n",
      "epoch 96; iter: 0; batch classifier loss: 0.442740; batch adversarial loss: 0.526936\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415740; batch adversarial loss: 0.572905\n",
      "epoch 98; iter: 0; batch classifier loss: 0.321737; batch adversarial loss: 0.544189\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403727; batch adversarial loss: 0.553342\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400082; batch adversarial loss: 0.507523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.361458; batch adversarial loss: 0.553658\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347514; batch adversarial loss: 0.573288\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394426; batch adversarial loss: 0.618919\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371061; batch adversarial loss: 0.553478\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340051; batch adversarial loss: 0.507192\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365003; batch adversarial loss: 0.516357\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373454; batch adversarial loss: 0.554016\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435800; batch adversarial loss: 0.571376\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388394; batch adversarial loss: 0.580578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.298119; batch adversarial loss: 0.564043\n",
      "epoch 111; iter: 0; batch classifier loss: 0.300277; batch adversarial loss: 0.637420\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381942; batch adversarial loss: 0.581450\n",
      "epoch 113; iter: 0; batch classifier loss: 0.429053; batch adversarial loss: 0.535150\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368614; batch adversarial loss: 0.545025\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411730; batch adversarial loss: 0.545296\n",
      "epoch 116; iter: 0; batch classifier loss: 0.524365; batch adversarial loss: 0.535630\n",
      "epoch 117; iter: 0; batch classifier loss: 0.316203; batch adversarial loss: 0.581605\n",
      "epoch 118; iter: 0; batch classifier loss: 0.323281; batch adversarial loss: 0.599576\n",
      "epoch 119; iter: 0; batch classifier loss: 0.365758; batch adversarial loss: 0.561261\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420948; batch adversarial loss: 0.525904\n",
      "epoch 121; iter: 0; batch classifier loss: 0.407652; batch adversarial loss: 0.535253\n",
      "epoch 122; iter: 0; batch classifier loss: 0.306288; batch adversarial loss: 0.543912\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373562; batch adversarial loss: 0.610003\n",
      "epoch 124; iter: 0; batch classifier loss: 0.452357; batch adversarial loss: 0.534730\n",
      "epoch 125; iter: 0; batch classifier loss: 0.440499; batch adversarial loss: 0.545457\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412621; batch adversarial loss: 0.526919\n",
      "epoch 127; iter: 0; batch classifier loss: 0.305043; batch adversarial loss: 0.480234\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344089; batch adversarial loss: 0.535064\n",
      "epoch 129; iter: 0; batch classifier loss: 0.382620; batch adversarial loss: 0.545423\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386303; batch adversarial loss: 0.543921\n",
      "epoch 131; iter: 0; batch classifier loss: 0.433213; batch adversarial loss: 0.600399\n",
      "epoch 132; iter: 0; batch classifier loss: 0.419157; batch adversarial loss: 0.507530\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383315; batch adversarial loss: 0.498368\n",
      "epoch 134; iter: 0; batch classifier loss: 0.389835; batch adversarial loss: 0.516225\n",
      "epoch 135; iter: 0; batch classifier loss: 0.412310; batch adversarial loss: 0.582296\n",
      "epoch 136; iter: 0; batch classifier loss: 0.350159; batch adversarial loss: 0.424634\n",
      "epoch 137; iter: 0; batch classifier loss: 0.468970; batch adversarial loss: 0.536495\n",
      "epoch 138; iter: 0; batch classifier loss: 0.454895; batch adversarial loss: 0.534575\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377369; batch adversarial loss: 0.589869\n",
      "epoch 140; iter: 0; batch classifier loss: 0.448746; batch adversarial loss: 0.592010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.321051; batch adversarial loss: 0.534133\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395734; batch adversarial loss: 0.563382\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431234; batch adversarial loss: 0.507210\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380958; batch adversarial loss: 0.534665\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397258; batch adversarial loss: 0.609396\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353794; batch adversarial loss: 0.552624\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307364; batch adversarial loss: 0.516510\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361661; batch adversarial loss: 0.544710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369135; batch adversarial loss: 0.543202\n",
      "epoch 150; iter: 0; batch classifier loss: 0.415277; batch adversarial loss: 0.554829\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371702; batch adversarial loss: 0.553398\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349308; batch adversarial loss: 0.637343\n",
      "epoch 153; iter: 0; batch classifier loss: 0.409206; batch adversarial loss: 0.515841\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306720; batch adversarial loss: 0.616764\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433625; batch adversarial loss: 0.554592\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391498; batch adversarial loss: 0.523620\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319292; batch adversarial loss: 0.563597\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329992; batch adversarial loss: 0.527175\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366853; batch adversarial loss: 0.544860\n",
      "epoch 160; iter: 0; batch classifier loss: 0.468257; batch adversarial loss: 0.616112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.363348; batch adversarial loss: 0.617754\n",
      "epoch 162; iter: 0; batch classifier loss: 0.452894; batch adversarial loss: 0.498892\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363706; batch adversarial loss: 0.571529\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358479; batch adversarial loss: 0.561742\n",
      "epoch 165; iter: 0; batch classifier loss: 0.404635; batch adversarial loss: 0.546931\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318920; batch adversarial loss: 0.543841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.435907; batch adversarial loss: 0.526855\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378017; batch adversarial loss: 0.617216\n",
      "epoch 169; iter: 0; batch classifier loss: 0.381411; batch adversarial loss: 0.525801\n",
      "epoch 170; iter: 0; batch classifier loss: 0.358240; batch adversarial loss: 0.552962\n",
      "epoch 171; iter: 0; batch classifier loss: 0.305810; batch adversarial loss: 0.544375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.286199; batch adversarial loss: 0.561717\n",
      "epoch 173; iter: 0; batch classifier loss: 0.449345; batch adversarial loss: 0.610198\n",
      "epoch 174; iter: 0; batch classifier loss: 0.342035; batch adversarial loss: 0.534469\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383069; batch adversarial loss: 0.583367\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319791; batch adversarial loss: 0.563467\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336805; batch adversarial loss: 0.618992\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362236; batch adversarial loss: 0.571181\n",
      "epoch 179; iter: 0; batch classifier loss: 0.429756; batch adversarial loss: 0.498101\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326485; batch adversarial loss: 0.544787\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315100; batch adversarial loss: 0.498252\n",
      "epoch 182; iter: 0; batch classifier loss: 0.249957; batch adversarial loss: 0.552792\n",
      "epoch 183; iter: 0; batch classifier loss: 0.402525; batch adversarial loss: 0.552222\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352960; batch adversarial loss: 0.600649\n",
      "epoch 185; iter: 0; batch classifier loss: 0.322121; batch adversarial loss: 0.469814\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398589; batch adversarial loss: 0.527271\n",
      "epoch 187; iter: 0; batch classifier loss: 0.321525; batch adversarial loss: 0.563668\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330352; batch adversarial loss: 0.498470\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343827; batch adversarial loss: 0.610183\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347710; batch adversarial loss: 0.554177\n",
      "epoch 191; iter: 0; batch classifier loss: 0.431914; batch adversarial loss: 0.488997\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362346; batch adversarial loss: 0.545587\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347241; batch adversarial loss: 0.608337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.327920; batch adversarial loss: 0.525192\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365224; batch adversarial loss: 0.528257\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330813; batch adversarial loss: 0.573225\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337719; batch adversarial loss: 0.526747\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329751; batch adversarial loss: 0.525739\n",
      "epoch 199; iter: 0; batch classifier loss: 0.443259; batch adversarial loss: 0.572056\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730557; batch adversarial loss: 0.728419\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624447; batch adversarial loss: 0.692709\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572607; batch adversarial loss: 0.675766\n",
      "epoch 3; iter: 0; batch classifier loss: 0.564150; batch adversarial loss: 0.651501\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579282; batch adversarial loss: 0.631919\n",
      "epoch 5; iter: 0; batch classifier loss: 0.545250; batch adversarial loss: 0.592625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581779; batch adversarial loss: 0.579375\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583762; batch adversarial loss: 0.578524\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560932; batch adversarial loss: 0.543197\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488226; batch adversarial loss: 0.573173\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570781; batch adversarial loss: 0.572216\n",
      "epoch 11; iter: 0; batch classifier loss: 0.476901; batch adversarial loss: 0.636152\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547131; batch adversarial loss: 0.609755\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472829; batch adversarial loss: 0.568990\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601730; batch adversarial loss: 0.566985\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573504; batch adversarial loss: 0.541659\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505202; batch adversarial loss: 0.590960\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480489; batch adversarial loss: 0.582181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499267; batch adversarial loss: 0.598222\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444133; batch adversarial loss: 0.609410\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515167; batch adversarial loss: 0.543180\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490418; batch adversarial loss: 0.524836\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500268; batch adversarial loss: 0.548843\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499627; batch adversarial loss: 0.584400\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468142; batch adversarial loss: 0.515441\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456671; batch adversarial loss: 0.543455\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470283; batch adversarial loss: 0.563749\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505103; batch adversarial loss: 0.610438\n",
      "epoch 28; iter: 0; batch classifier loss: 0.403234; batch adversarial loss: 0.507864\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445229; batch adversarial loss: 0.612109\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450776; batch adversarial loss: 0.555509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410927; batch adversarial loss: 0.514001\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492378; batch adversarial loss: 0.529280\n",
      "epoch 33; iter: 0; batch classifier loss: 0.375465; batch adversarial loss: 0.519902\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485133; batch adversarial loss: 0.576952\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396839; batch adversarial loss: 0.558629\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419076; batch adversarial loss: 0.535837\n",
      "epoch 37; iter: 0; batch classifier loss: 0.371473; batch adversarial loss: 0.588415\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400898; batch adversarial loss: 0.546318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479729; batch adversarial loss: 0.545154\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461476; batch adversarial loss: 0.679334\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465431; batch adversarial loss: 0.527007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431884; batch adversarial loss: 0.508546\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419841; batch adversarial loss: 0.545587\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404533; batch adversarial loss: 0.625058\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412373; batch adversarial loss: 0.508767\n",
      "epoch 46; iter: 0; batch classifier loss: 0.393448; batch adversarial loss: 0.660129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431947; batch adversarial loss: 0.500913\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464859; batch adversarial loss: 0.580261\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418548; batch adversarial loss: 0.482073\n",
      "epoch 50; iter: 0; batch classifier loss: 0.373385; batch adversarial loss: 0.499967\n",
      "epoch 51; iter: 0; batch classifier loss: 0.377818; batch adversarial loss: 0.500486\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416268; batch adversarial loss: 0.615527\n",
      "epoch 53; iter: 0; batch classifier loss: 0.360827; batch adversarial loss: 0.589177\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427971; batch adversarial loss: 0.510238\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404023; batch adversarial loss: 0.527832\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415348; batch adversarial loss: 0.544421\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390984; batch adversarial loss: 0.597432\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417045; batch adversarial loss: 0.545158\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433922; batch adversarial loss: 0.554274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.455553; batch adversarial loss: 0.526828\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398472; batch adversarial loss: 0.526044\n",
      "epoch 62; iter: 0; batch classifier loss: 0.374082; batch adversarial loss: 0.517867\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390802; batch adversarial loss: 0.553293\n",
      "epoch 64; iter: 0; batch classifier loss: 0.344359; batch adversarial loss: 0.597155\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376457; batch adversarial loss: 0.544399\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408778; batch adversarial loss: 0.516106\n",
      "epoch 67; iter: 0; batch classifier loss: 0.349938; batch adversarial loss: 0.576711\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425773; batch adversarial loss: 0.511740\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402134; batch adversarial loss: 0.520069\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412293; batch adversarial loss: 0.563516\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449918; batch adversarial loss: 0.635130\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364004; batch adversarial loss: 0.499466\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390811; batch adversarial loss: 0.598198\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432295; batch adversarial loss: 0.599499\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382794; batch adversarial loss: 0.600041\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409440; batch adversarial loss: 0.572266\n",
      "epoch 77; iter: 0; batch classifier loss: 0.350452; batch adversarial loss: 0.508465\n",
      "epoch 78; iter: 0; batch classifier loss: 0.328205; batch adversarial loss: 0.517797\n",
      "epoch 79; iter: 0; batch classifier loss: 0.345814; batch adversarial loss: 0.571827\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400991; batch adversarial loss: 0.571548\n",
      "epoch 81; iter: 0; batch classifier loss: 0.452445; batch adversarial loss: 0.553479\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416762; batch adversarial loss: 0.499293\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419857; batch adversarial loss: 0.571913\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356700; batch adversarial loss: 0.615934\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435193; batch adversarial loss: 0.571003\n",
      "epoch 86; iter: 0; batch classifier loss: 0.334907; batch adversarial loss: 0.678712\n",
      "epoch 87; iter: 0; batch classifier loss: 0.458463; batch adversarial loss: 0.500175\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354231; batch adversarial loss: 0.500082\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405498; batch adversarial loss: 0.589396\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362189; batch adversarial loss: 0.579845\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361738; batch adversarial loss: 0.642059\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354491; batch adversarial loss: 0.482308\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417303; batch adversarial loss: 0.553526\n",
      "epoch 94; iter: 0; batch classifier loss: 0.302880; batch adversarial loss: 0.580438\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398584; batch adversarial loss: 0.508709\n",
      "epoch 96; iter: 0; batch classifier loss: 0.411788; batch adversarial loss: 0.509127\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378395; batch adversarial loss: 0.544082\n",
      "epoch 98; iter: 0; batch classifier loss: 0.492322; batch adversarial loss: 0.580143\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373524; batch adversarial loss: 0.509521\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410269; batch adversarial loss: 0.535902\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353961; batch adversarial loss: 0.598259\n",
      "epoch 102; iter: 0; batch classifier loss: 0.476672; batch adversarial loss: 0.553475\n",
      "epoch 103; iter: 0; batch classifier loss: 0.311269; batch adversarial loss: 0.526770\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446964; batch adversarial loss: 0.598188\n",
      "epoch 105; iter: 0; batch classifier loss: 0.333729; batch adversarial loss: 0.625484\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378056; batch adversarial loss: 0.607571\n",
      "epoch 107; iter: 0; batch classifier loss: 0.473328; batch adversarial loss: 0.625204\n",
      "epoch 108; iter: 0; batch classifier loss: 0.426543; batch adversarial loss: 0.536092\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404451; batch adversarial loss: 0.491314\n",
      "epoch 110; iter: 0; batch classifier loss: 0.421942; batch adversarial loss: 0.544668\n",
      "epoch 111; iter: 0; batch classifier loss: 0.334399; batch adversarial loss: 0.499834\n",
      "epoch 112; iter: 0; batch classifier loss: 0.454715; batch adversarial loss: 0.624902\n",
      "epoch 113; iter: 0; batch classifier loss: 0.410184; batch adversarial loss: 0.535979\n",
      "epoch 114; iter: 0; batch classifier loss: 0.500774; batch adversarial loss: 0.580179\n",
      "epoch 115; iter: 0; batch classifier loss: 0.415710; batch adversarial loss: 0.536005\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324827; batch adversarial loss: 0.624555\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399531; batch adversarial loss: 0.571629\n",
      "epoch 118; iter: 0; batch classifier loss: 0.414781; batch adversarial loss: 0.571597\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408894; batch adversarial loss: 0.499793\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348600; batch adversarial loss: 0.554085\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358950; batch adversarial loss: 0.527009\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397720; batch adversarial loss: 0.562518\n",
      "epoch 123; iter: 0; batch classifier loss: 0.455287; batch adversarial loss: 0.491105\n",
      "epoch 124; iter: 0; batch classifier loss: 0.388123; batch adversarial loss: 0.579643\n",
      "epoch 125; iter: 0; batch classifier loss: 0.483802; batch adversarial loss: 0.518006\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396966; batch adversarial loss: 0.482164\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354405; batch adversarial loss: 0.535830\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369290; batch adversarial loss: 0.526595\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339632; batch adversarial loss: 0.526996\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362394; batch adversarial loss: 0.508944\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374041; batch adversarial loss: 0.580319\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340991; batch adversarial loss: 0.589548\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351067; batch adversarial loss: 0.570837\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364420; batch adversarial loss: 0.553291\n",
      "epoch 135; iter: 0; batch classifier loss: 0.419312; batch adversarial loss: 0.642926\n",
      "epoch 136; iter: 0; batch classifier loss: 0.314473; batch adversarial loss: 0.553294\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332902; batch adversarial loss: 0.517489\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373074; batch adversarial loss: 0.580330\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360398; batch adversarial loss: 0.598253\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383939; batch adversarial loss: 0.571577\n",
      "epoch 141; iter: 0; batch classifier loss: 0.335614; batch adversarial loss: 0.536103\n",
      "epoch 142; iter: 0; batch classifier loss: 0.278714; batch adversarial loss: 0.597940\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412079; batch adversarial loss: 0.580185\n",
      "epoch 144; iter: 0; batch classifier loss: 0.344506; batch adversarial loss: 0.536140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.435778; batch adversarial loss: 0.598251\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349297; batch adversarial loss: 0.464152\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388501; batch adversarial loss: 0.526891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.298842; batch adversarial loss: 0.598453\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375370; batch adversarial loss: 0.527226\n",
      "epoch 150; iter: 0; batch classifier loss: 0.436036; batch adversarial loss: 0.553867\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405746; batch adversarial loss: 0.509036\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372190; batch adversarial loss: 0.553231\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348566; batch adversarial loss: 0.535957\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347559; batch adversarial loss: 0.587732\n",
      "epoch 155; iter: 0; batch classifier loss: 0.399792; batch adversarial loss: 0.624803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.433094; batch adversarial loss: 0.499735\n",
      "epoch 157; iter: 0; batch classifier loss: 0.449458; batch adversarial loss: 0.598820\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323890; batch adversarial loss: 0.509442\n",
      "epoch 159; iter: 0; batch classifier loss: 0.330148; batch adversarial loss: 0.580522\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331728; batch adversarial loss: 0.482011\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367559; batch adversarial loss: 0.596864\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343360; batch adversarial loss: 0.606579\n",
      "epoch 163; iter: 0; batch classifier loss: 0.431298; batch adversarial loss: 0.589072\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351270; batch adversarial loss: 0.525668\n",
      "epoch 165; iter: 0; batch classifier loss: 0.312163; batch adversarial loss: 0.500143\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369333; batch adversarial loss: 0.490546\n",
      "epoch 167; iter: 0; batch classifier loss: 0.442077; batch adversarial loss: 0.526945\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388927; batch adversarial loss: 0.499877\n",
      "epoch 169; iter: 0; batch classifier loss: 0.318963; batch adversarial loss: 0.562690\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382142; batch adversarial loss: 0.535895\n",
      "epoch 171; iter: 0; batch classifier loss: 0.298232; batch adversarial loss: 0.544136\n",
      "epoch 172; iter: 0; batch classifier loss: 0.427097; batch adversarial loss: 0.517435\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364254; batch adversarial loss: 0.607509\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336132; batch adversarial loss: 0.525989\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351911; batch adversarial loss: 0.571465\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377828; batch adversarial loss: 0.615955\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309748; batch adversarial loss: 0.598049\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351413; batch adversarial loss: 0.616032\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406630; batch adversarial loss: 0.633884\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334056; batch adversarial loss: 0.651734\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376813; batch adversarial loss: 0.571494\n",
      "epoch 182; iter: 0; batch classifier loss: 0.343812; batch adversarial loss: 0.625081\n",
      "epoch 183; iter: 0; batch classifier loss: 0.377485; batch adversarial loss: 0.606663\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360399; batch adversarial loss: 0.562594\n",
      "epoch 185; iter: 0; batch classifier loss: 0.292099; batch adversarial loss: 0.508982\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330684; batch adversarial loss: 0.651512\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322514; batch adversarial loss: 0.535844\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379664; batch adversarial loss: 0.544287\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320443; batch adversarial loss: 0.571303\n",
      "epoch 190; iter: 0; batch classifier loss: 0.424818; batch adversarial loss: 0.570880\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344325; batch adversarial loss: 0.544673\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381642; batch adversarial loss: 0.580551\n",
      "epoch 193; iter: 0; batch classifier loss: 0.420741; batch adversarial loss: 0.570841\n",
      "epoch 194; iter: 0; batch classifier loss: 0.432863; batch adversarial loss: 0.633812\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302826; batch adversarial loss: 0.597488\n",
      "epoch 196; iter: 0; batch classifier loss: 0.421961; batch adversarial loss: 0.545213\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372926; batch adversarial loss: 0.526217\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386423; batch adversarial loss: 0.535980\n",
      "epoch 199; iter: 0; batch classifier loss: 0.312387; batch adversarial loss: 0.579885\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739062; batch adversarial loss: 0.929450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.754100; batch adversarial loss: 0.940939\n",
      "epoch 2; iter: 0; batch classifier loss: 0.977583; batch adversarial loss: 0.925449\n",
      "epoch 3; iter: 0; batch classifier loss: 0.900707; batch adversarial loss: 0.835786\n",
      "epoch 4; iter: 0; batch classifier loss: 1.015886; batch adversarial loss: 0.811454\n",
      "epoch 5; iter: 0; batch classifier loss: 0.776334; batch adversarial loss: 0.706804\n",
      "epoch 6; iter: 0; batch classifier loss: 0.676279; batch adversarial loss: 0.671827\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626592; batch adversarial loss: 0.615157\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550815; batch adversarial loss: 0.591336\n",
      "epoch 9; iter: 0; batch classifier loss: 0.469092; batch adversarial loss: 0.630570\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524135; batch adversarial loss: 0.580756\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507102; batch adversarial loss: 0.604588\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527215; batch adversarial loss: 0.585261\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545443; batch adversarial loss: 0.568303\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477554; batch adversarial loss: 0.606193\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493492; batch adversarial loss: 0.628491\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515265; batch adversarial loss: 0.635658\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481624; batch adversarial loss: 0.570494\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504635; batch adversarial loss: 0.552493\n",
      "epoch 19; iter: 0; batch classifier loss: 0.442029; batch adversarial loss: 0.623308\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511882; batch adversarial loss: 0.526015\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537508; batch adversarial loss: 0.500385\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483684; batch adversarial loss: 0.523656\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443801; batch adversarial loss: 0.478717\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527295; batch adversarial loss: 0.609349\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478557; batch adversarial loss: 0.561538\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484141; batch adversarial loss: 0.538709\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433858; batch adversarial loss: 0.545690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469688; batch adversarial loss: 0.590416\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504735; batch adversarial loss: 0.588304\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493327; batch adversarial loss: 0.528262\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511345; batch adversarial loss: 0.564908\n",
      "epoch 32; iter: 0; batch classifier loss: 0.539142; batch adversarial loss: 0.574746\n",
      "epoch 33; iter: 0; batch classifier loss: 0.545512; batch adversarial loss: 0.566801\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483818; batch adversarial loss: 0.534372\n",
      "epoch 35; iter: 0; batch classifier loss: 0.492589; batch adversarial loss: 0.559321\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496185; batch adversarial loss: 0.495330\n",
      "epoch 37; iter: 0; batch classifier loss: 0.437772; batch adversarial loss: 0.544740\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422433; batch adversarial loss: 0.592202\n",
      "epoch 39; iter: 0; batch classifier loss: 0.378660; batch adversarial loss: 0.537728\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445756; batch adversarial loss: 0.544719\n",
      "epoch 41; iter: 0; batch classifier loss: 0.452305; batch adversarial loss: 0.461841\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446401; batch adversarial loss: 0.513920\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385699; batch adversarial loss: 0.563388\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426872; batch adversarial loss: 0.498688\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432747; batch adversarial loss: 0.527634\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424769; batch adversarial loss: 0.577045\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446859; batch adversarial loss: 0.522509\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434324; batch adversarial loss: 0.570635\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429807; batch adversarial loss: 0.563994\n",
      "epoch 50; iter: 0; batch classifier loss: 0.456749; batch adversarial loss: 0.601687\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432604; batch adversarial loss: 0.546155\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437372; batch adversarial loss: 0.563902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.462088; batch adversarial loss: 0.625024\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414714; batch adversarial loss: 0.632642\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426438; batch adversarial loss: 0.666702\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416444; batch adversarial loss: 0.551509\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442088; batch adversarial loss: 0.508964\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390694; batch adversarial loss: 0.563785\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399924; batch adversarial loss: 0.571450\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383659; batch adversarial loss: 0.614903\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425624; batch adversarial loss: 0.535898\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399327; batch adversarial loss: 0.571684\n",
      "epoch 63; iter: 0; batch classifier loss: 0.472435; batch adversarial loss: 0.582130\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414687; batch adversarial loss: 0.599308\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377244; batch adversarial loss: 0.579269\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420193; batch adversarial loss: 0.580233\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418844; batch adversarial loss: 0.491526\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430732; batch adversarial loss: 0.580336\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407675; batch adversarial loss: 0.536577\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388769; batch adversarial loss: 0.543577\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376476; batch adversarial loss: 0.598477\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358639; batch adversarial loss: 0.544058\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366840; batch adversarial loss: 0.555786\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398327; batch adversarial loss: 0.499535\n",
      "epoch 75; iter: 0; batch classifier loss: 0.439911; batch adversarial loss: 0.539556\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371497; batch adversarial loss: 0.553402\n",
      "epoch 77; iter: 0; batch classifier loss: 0.328115; batch adversarial loss: 0.480117\n",
      "epoch 78; iter: 0; batch classifier loss: 0.363908; batch adversarial loss: 0.634001\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383051; batch adversarial loss: 0.632647\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389551; batch adversarial loss: 0.544238\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432132; batch adversarial loss: 0.564656\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411099; batch adversarial loss: 0.625122\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349192; batch adversarial loss: 0.575365\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393634; batch adversarial loss: 0.590675\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390598; batch adversarial loss: 0.622386\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399982; batch adversarial loss: 0.600832\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374671; batch adversarial loss: 0.580941\n",
      "epoch 88; iter: 0; batch classifier loss: 0.366422; batch adversarial loss: 0.516927\n",
      "epoch 89; iter: 0; batch classifier loss: 0.335154; batch adversarial loss: 0.553613\n",
      "epoch 90; iter: 0; batch classifier loss: 0.337666; batch adversarial loss: 0.507188\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385912; batch adversarial loss: 0.518483\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387016; batch adversarial loss: 0.531676\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385362; batch adversarial loss: 0.551826\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408634; batch adversarial loss: 0.546433\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417302; batch adversarial loss: 0.595948\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394589; batch adversarial loss: 0.524644\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386278; batch adversarial loss: 0.500449\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344150; batch adversarial loss: 0.667938\n",
      "epoch 99; iter: 0; batch classifier loss: 0.388954; batch adversarial loss: 0.536009\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411342; batch adversarial loss: 0.569295\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342478; batch adversarial loss: 0.650900\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399658; batch adversarial loss: 0.541646\n",
      "epoch 103; iter: 0; batch classifier loss: 0.359390; batch adversarial loss: 0.565267\n",
      "epoch 104; iter: 0; batch classifier loss: 0.298830; batch adversarial loss: 0.581875\n",
      "epoch 105; iter: 0; batch classifier loss: 0.307168; batch adversarial loss: 0.557991\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360694; batch adversarial loss: 0.545928\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348092; batch adversarial loss: 0.589229\n",
      "epoch 108; iter: 0; batch classifier loss: 0.324187; batch adversarial loss: 0.641142\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338736; batch adversarial loss: 0.502285\n",
      "epoch 110; iter: 0; batch classifier loss: 0.481252; batch adversarial loss: 0.445558\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399211; batch adversarial loss: 0.496690\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386586; batch adversarial loss: 0.563948\n",
      "epoch 113; iter: 0; batch classifier loss: 0.404912; batch adversarial loss: 0.544913\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360928; batch adversarial loss: 0.545727\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344560; batch adversarial loss: 0.518680\n",
      "epoch 116; iter: 0; batch classifier loss: 0.326814; batch adversarial loss: 0.525675\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348393; batch adversarial loss: 0.506230\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343825; batch adversarial loss: 0.507703\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339019; batch adversarial loss: 0.594453\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407292; batch adversarial loss: 0.579443\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396139; batch adversarial loss: 0.626068\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372651; batch adversarial loss: 0.542662\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370281; batch adversarial loss: 0.516937\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385946; batch adversarial loss: 0.559756\n",
      "epoch 125; iter: 0; batch classifier loss: 0.308749; batch adversarial loss: 0.525179\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361805; batch adversarial loss: 0.501156\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346439; batch adversarial loss: 0.635346\n",
      "epoch 128; iter: 0; batch classifier loss: 0.357874; batch adversarial loss: 0.638871\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393169; batch adversarial loss: 0.560886\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364854; batch adversarial loss: 0.481625\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361029; batch adversarial loss: 0.546568\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417539; batch adversarial loss: 0.533040\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402656; batch adversarial loss: 0.543499\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367116; batch adversarial loss: 0.581195\n",
      "epoch 135; iter: 0; batch classifier loss: 0.297614; batch adversarial loss: 0.535560\n",
      "epoch 136; iter: 0; batch classifier loss: 0.342913; batch adversarial loss: 0.553347\n",
      "epoch 137; iter: 0; batch classifier loss: 0.409618; batch adversarial loss: 0.572711\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346585; batch adversarial loss: 0.546254\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331583; batch adversarial loss: 0.527348\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360832; batch adversarial loss: 0.531553\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387926; batch adversarial loss: 0.525880\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363601; batch adversarial loss: 0.565774\n",
      "epoch 143; iter: 0; batch classifier loss: 0.479179; batch adversarial loss: 0.589415\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337903; batch adversarial loss: 0.569990\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355794; batch adversarial loss: 0.562529\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366296; batch adversarial loss: 0.560446\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354149; batch adversarial loss: 0.527754\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350580; batch adversarial loss: 0.577926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.390597; batch adversarial loss: 0.491556\n",
      "epoch 150; iter: 0; batch classifier loss: 0.441815; batch adversarial loss: 0.563935\n",
      "epoch 151; iter: 0; batch classifier loss: 0.294385; batch adversarial loss: 0.556130\n",
      "epoch 152; iter: 0; batch classifier loss: 0.273644; batch adversarial loss: 0.499208\n",
      "epoch 153; iter: 0; batch classifier loss: 0.323883; batch adversarial loss: 0.569622\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379899; batch adversarial loss: 0.571573\n",
      "epoch 155; iter: 0; batch classifier loss: 0.405136; batch adversarial loss: 0.606476\n",
      "epoch 156; iter: 0; batch classifier loss: 0.278720; batch adversarial loss: 0.525143\n",
      "epoch 157; iter: 0; batch classifier loss: 0.389391; batch adversarial loss: 0.572930\n",
      "epoch 158; iter: 0; batch classifier loss: 0.417466; batch adversarial loss: 0.563960\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374191; batch adversarial loss: 0.537744\n",
      "epoch 160; iter: 0; batch classifier loss: 0.330569; batch adversarial loss: 0.503202\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369153; batch adversarial loss: 0.539514\n",
      "epoch 162; iter: 0; batch classifier loss: 0.490851; batch adversarial loss: 0.554052\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306847; batch adversarial loss: 0.514931\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378900; batch adversarial loss: 0.560626\n",
      "epoch 165; iter: 0; batch classifier loss: 0.310061; batch adversarial loss: 0.550817\n",
      "epoch 166; iter: 0; batch classifier loss: 0.298764; batch adversarial loss: 0.539992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.278116; batch adversarial loss: 0.543809\n",
      "epoch 168; iter: 0; batch classifier loss: 0.322456; batch adversarial loss: 0.554250\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327100; batch adversarial loss: 0.565547\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409217; batch adversarial loss: 0.623825\n",
      "epoch 171; iter: 0; batch classifier loss: 0.310355; batch adversarial loss: 0.534475\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334519; batch adversarial loss: 0.563363\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302366; batch adversarial loss: 0.542569\n",
      "epoch 174; iter: 0; batch classifier loss: 0.312270; batch adversarial loss: 0.648949\n",
      "epoch 175; iter: 0; batch classifier loss: 0.302053; batch adversarial loss: 0.601229\n",
      "epoch 176; iter: 0; batch classifier loss: 0.306853; batch adversarial loss: 0.526678\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321162; batch adversarial loss: 0.599050\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352660; batch adversarial loss: 0.507419\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306661; batch adversarial loss: 0.570685\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352462; batch adversarial loss: 0.455090\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400706; batch adversarial loss: 0.579207\n",
      "epoch 182; iter: 0; batch classifier loss: 0.321688; batch adversarial loss: 0.577534\n",
      "epoch 183; iter: 0; batch classifier loss: 0.244274; batch adversarial loss: 0.457429\n",
      "epoch 184; iter: 0; batch classifier loss: 0.326240; batch adversarial loss: 0.593327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371428; batch adversarial loss: 0.588101\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393363; batch adversarial loss: 0.580111\n",
      "epoch 187; iter: 0; batch classifier loss: 0.401631; batch adversarial loss: 0.598594\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338285; batch adversarial loss: 0.595111\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345772; batch adversarial loss: 0.551843\n",
      "epoch 190; iter: 0; batch classifier loss: 0.414020; batch adversarial loss: 0.508349\n",
      "epoch 191; iter: 0; batch classifier loss: 0.268199; batch adversarial loss: 0.671492\n",
      "epoch 192; iter: 0; batch classifier loss: 0.341048; batch adversarial loss: 0.492553\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367270; batch adversarial loss: 0.587406\n",
      "epoch 194; iter: 0; batch classifier loss: 0.303472; batch adversarial loss: 0.537790\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334409; batch adversarial loss: 0.534647\n",
      "epoch 196; iter: 0; batch classifier loss: 0.297672; batch adversarial loss: 0.604748\n",
      "epoch 197; iter: 0; batch classifier loss: 0.256603; batch adversarial loss: 0.508814\n",
      "epoch 198; iter: 0; batch classifier loss: 0.287666; batch adversarial loss: 0.541043\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330199; batch adversarial loss: 0.551232\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743341; batch adversarial loss: 0.804199\n",
      "epoch 1; iter: 0; batch classifier loss: 0.772270; batch adversarial loss: 0.780743\n",
      "epoch 2; iter: 0; batch classifier loss: 0.668911; batch adversarial loss: 0.680937\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555498; batch adversarial loss: 0.639578\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558663; batch adversarial loss: 0.657512\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577289; batch adversarial loss: 0.622580\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578153; batch adversarial loss: 0.579141\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519838; batch adversarial loss: 0.598187\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553312; batch adversarial loss: 0.604493\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518836; batch adversarial loss: 0.585613\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569236; batch adversarial loss: 0.563551\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545131; batch adversarial loss: 0.610286\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564164; batch adversarial loss: 0.619210\n",
      "epoch 13; iter: 0; batch classifier loss: 0.561489; batch adversarial loss: 0.563397\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539051; batch adversarial loss: 0.536625\n",
      "epoch 15; iter: 0; batch classifier loss: 0.547067; batch adversarial loss: 0.652024\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468159; batch adversarial loss: 0.574254\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529081; batch adversarial loss: 0.565379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535713; batch adversarial loss: 0.577702\n",
      "epoch 19; iter: 0; batch classifier loss: 0.415786; batch adversarial loss: 0.578589\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512160; batch adversarial loss: 0.615836\n",
      "epoch 21; iter: 0; batch classifier loss: 0.518714; batch adversarial loss: 0.593312\n",
      "epoch 22; iter: 0; batch classifier loss: 0.417543; batch adversarial loss: 0.544219\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523583; batch adversarial loss: 0.574028\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533733; batch adversarial loss: 0.554739\n",
      "epoch 25; iter: 0; batch classifier loss: 0.560371; batch adversarial loss: 0.548008\n",
      "epoch 26; iter: 0; batch classifier loss: 0.577676; batch adversarial loss: 0.544985\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458437; batch adversarial loss: 0.564014\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499780; batch adversarial loss: 0.651414\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451173; batch adversarial loss: 0.573475\n",
      "epoch 30; iter: 0; batch classifier loss: 0.408994; batch adversarial loss: 0.549396\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507872; batch adversarial loss: 0.580987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.376244; batch adversarial loss: 0.594769\n",
      "epoch 33; iter: 0; batch classifier loss: 0.495449; batch adversarial loss: 0.554699\n",
      "epoch 34; iter: 0; batch classifier loss: 0.503318; batch adversarial loss: 0.446742\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481201; batch adversarial loss: 0.580493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418746; batch adversarial loss: 0.570215\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445430; batch adversarial loss: 0.615436\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453472; batch adversarial loss: 0.584404\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407199; batch adversarial loss: 0.578974\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462026; batch adversarial loss: 0.549486\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431795; batch adversarial loss: 0.492436\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434954; batch adversarial loss: 0.600318\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441108; batch adversarial loss: 0.473315\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462392; batch adversarial loss: 0.621075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.461927; batch adversarial loss: 0.625401\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394009; batch adversarial loss: 0.600650\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428937; batch adversarial loss: 0.588489\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396081; batch adversarial loss: 0.543548\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396636; batch adversarial loss: 0.553355\n",
      "epoch 50; iter: 0; batch classifier loss: 0.482518; batch adversarial loss: 0.534763\n",
      "epoch 51; iter: 0; batch classifier loss: 0.403103; batch adversarial loss: 0.565149\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437129; batch adversarial loss: 0.485472\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386498; batch adversarial loss: 0.562159\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426486; batch adversarial loss: 0.575313\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412648; batch adversarial loss: 0.472294\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473884; batch adversarial loss: 0.491708\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370607; batch adversarial loss: 0.581191\n",
      "epoch 58; iter: 0; batch classifier loss: 0.341752; batch adversarial loss: 0.613273\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446532; batch adversarial loss: 0.598404\n",
      "epoch 60; iter: 0; batch classifier loss: 0.462240; batch adversarial loss: 0.509812\n",
      "epoch 61; iter: 0; batch classifier loss: 0.374385; batch adversarial loss: 0.623032\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410118; batch adversarial loss: 0.571445\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396444; batch adversarial loss: 0.579866\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437166; batch adversarial loss: 0.465993\n",
      "epoch 65; iter: 0; batch classifier loss: 0.454431; batch adversarial loss: 0.588435\n",
      "epoch 66; iter: 0; batch classifier loss: 0.469017; batch adversarial loss: 0.527131\n",
      "epoch 67; iter: 0; batch classifier loss: 0.493470; batch adversarial loss: 0.553771\n",
      "epoch 68; iter: 0; batch classifier loss: 0.459407; batch adversarial loss: 0.545063\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436006; batch adversarial loss: 0.535573\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409564; batch adversarial loss: 0.474137\n",
      "epoch 71; iter: 0; batch classifier loss: 0.476694; batch adversarial loss: 0.509926\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413151; batch adversarial loss: 0.500475\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424563; batch adversarial loss: 0.473780\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393174; batch adversarial loss: 0.562266\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455244; batch adversarial loss: 0.571106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335242; batch adversarial loss: 0.526654\n",
      "epoch 77; iter: 0; batch classifier loss: 0.457874; batch adversarial loss: 0.535881\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416303; batch adversarial loss: 0.562738\n",
      "epoch 79; iter: 0; batch classifier loss: 0.455778; batch adversarial loss: 0.562288\n",
      "epoch 80; iter: 0; batch classifier loss: 0.333044; batch adversarial loss: 0.527094\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461667; batch adversarial loss: 0.570834\n",
      "epoch 82; iter: 0; batch classifier loss: 0.431194; batch adversarial loss: 0.491095\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420011; batch adversarial loss: 0.544729\n",
      "epoch 84; iter: 0; batch classifier loss: 0.469182; batch adversarial loss: 0.553802\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347164; batch adversarial loss: 0.562666\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426909; batch adversarial loss: 0.535883\n",
      "epoch 87; iter: 0; batch classifier loss: 0.488519; batch adversarial loss: 0.571279\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408107; batch adversarial loss: 0.571543\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339636; batch adversarial loss: 0.589198\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396055; batch adversarial loss: 0.580901\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416119; batch adversarial loss: 0.561919\n",
      "epoch 92; iter: 0; batch classifier loss: 0.415925; batch adversarial loss: 0.570985\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402601; batch adversarial loss: 0.446625\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374952; batch adversarial loss: 0.589403\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425636; batch adversarial loss: 0.553715\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364350; batch adversarial loss: 0.571692\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386698; batch adversarial loss: 0.517916\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420042; batch adversarial loss: 0.509209\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395796; batch adversarial loss: 0.518505\n",
      "epoch 100; iter: 0; batch classifier loss: 0.363319; batch adversarial loss: 0.517689\n",
      "epoch 101; iter: 0; batch classifier loss: 0.316762; batch adversarial loss: 0.607508\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371603; batch adversarial loss: 0.580042\n",
      "epoch 103; iter: 0; batch classifier loss: 0.293258; batch adversarial loss: 0.500087\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372206; batch adversarial loss: 0.588911\n",
      "epoch 105; iter: 0; batch classifier loss: 0.333616; batch adversarial loss: 0.562508\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396450; batch adversarial loss: 0.606413\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404772; batch adversarial loss: 0.562456\n",
      "epoch 108; iter: 0; batch classifier loss: 0.469213; batch adversarial loss: 0.571207\n",
      "epoch 109; iter: 0; batch classifier loss: 0.408134; batch adversarial loss: 0.625539\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426666; batch adversarial loss: 0.527722\n",
      "epoch 111; iter: 0; batch classifier loss: 0.451353; batch adversarial loss: 0.572028\n",
      "epoch 112; iter: 0; batch classifier loss: 0.425167; batch adversarial loss: 0.544217\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364171; batch adversarial loss: 0.597977\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367833; batch adversarial loss: 0.535650\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321075; batch adversarial loss: 0.598678\n",
      "epoch 116; iter: 0; batch classifier loss: 0.420775; batch adversarial loss: 0.518287\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411273; batch adversarial loss: 0.553674\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401646; batch adversarial loss: 0.526688\n",
      "epoch 119; iter: 0; batch classifier loss: 0.331906; batch adversarial loss: 0.474014\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436245; batch adversarial loss: 0.562787\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381942; batch adversarial loss: 0.597805\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358038; batch adversarial loss: 0.510049\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429880; batch adversarial loss: 0.536273\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357748; batch adversarial loss: 0.589394\n",
      "epoch 125; iter: 0; batch classifier loss: 0.396251; batch adversarial loss: 0.553873\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392169; batch adversarial loss: 0.633795\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387609; batch adversarial loss: 0.589317\n",
      "epoch 128; iter: 0; batch classifier loss: 0.394273; batch adversarial loss: 0.500446\n",
      "epoch 129; iter: 0; batch classifier loss: 0.437764; batch adversarial loss: 0.500352\n",
      "epoch 130; iter: 0; batch classifier loss: 0.438380; batch adversarial loss: 0.553893\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344704; batch adversarial loss: 0.651393\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395560; batch adversarial loss: 0.553806\n",
      "epoch 133; iter: 0; batch classifier loss: 0.384367; batch adversarial loss: 0.499900\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382064; batch adversarial loss: 0.563061\n",
      "epoch 135; iter: 0; batch classifier loss: 0.276830; batch adversarial loss: 0.597845\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393337; batch adversarial loss: 0.482208\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350495; batch adversarial loss: 0.545013\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365338; batch adversarial loss: 0.562695\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367307; batch adversarial loss: 0.518233\n",
      "epoch 140; iter: 0; batch classifier loss: 0.385856; batch adversarial loss: 0.482463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.358435; batch adversarial loss: 0.597904\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320906; batch adversarial loss: 0.571226\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385010; batch adversarial loss: 0.633364\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369447; batch adversarial loss: 0.588831\n",
      "epoch 145; iter: 0; batch classifier loss: 0.340924; batch adversarial loss: 0.651627\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411634; batch adversarial loss: 0.562292\n",
      "epoch 147; iter: 0; batch classifier loss: 0.292496; batch adversarial loss: 0.473622\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350740; batch adversarial loss: 0.562518\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374948; batch adversarial loss: 0.447130\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340653; batch adversarial loss: 0.562660\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339922; batch adversarial loss: 0.509216\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395136; batch adversarial loss: 0.598492\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339156; batch adversarial loss: 0.509242\n",
      "epoch 154; iter: 0; batch classifier loss: 0.380911; batch adversarial loss: 0.544902\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359243; batch adversarial loss: 0.473768\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371081; batch adversarial loss: 0.536390\n",
      "epoch 157; iter: 0; batch classifier loss: 0.362158; batch adversarial loss: 0.526727\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373940; batch adversarial loss: 0.563209\n",
      "epoch 159; iter: 0; batch classifier loss: 0.411897; batch adversarial loss: 0.562797\n",
      "epoch 160; iter: 0; batch classifier loss: 0.453552; batch adversarial loss: 0.597544\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407329; batch adversarial loss: 0.606710\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394775; batch adversarial loss: 0.509328\n",
      "epoch 163; iter: 0; batch classifier loss: 0.360563; batch adversarial loss: 0.597811\n",
      "epoch 164; iter: 0; batch classifier loss: 0.331396; batch adversarial loss: 0.606492\n",
      "epoch 165; iter: 0; batch classifier loss: 0.384430; batch adversarial loss: 0.562698\n",
      "epoch 166; iter: 0; batch classifier loss: 0.410885; batch adversarial loss: 0.571909\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343916; batch adversarial loss: 0.570926\n",
      "epoch 168; iter: 0; batch classifier loss: 0.287956; batch adversarial loss: 0.625438\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379251; batch adversarial loss: 0.527750\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353608; batch adversarial loss: 0.490595\n",
      "epoch 171; iter: 0; batch classifier loss: 0.311291; batch adversarial loss: 0.499613\n",
      "epoch 172; iter: 0; batch classifier loss: 0.400236; batch adversarial loss: 0.535702\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333612; batch adversarial loss: 0.553841\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318661; batch adversarial loss: 0.553179\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359605; batch adversarial loss: 0.571294\n",
      "epoch 176; iter: 0; batch classifier loss: 0.380094; batch adversarial loss: 0.552600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376350; batch adversarial loss: 0.535810\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391733; batch adversarial loss: 0.535344\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352363; batch adversarial loss: 0.571923\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369717; batch adversarial loss: 0.562223\n",
      "epoch 181; iter: 0; batch classifier loss: 0.304539; batch adversarial loss: 0.562823\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333696; batch adversarial loss: 0.509150\n",
      "epoch 183; iter: 0; batch classifier loss: 0.281087; batch adversarial loss: 0.624169\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339417; batch adversarial loss: 0.509600\n",
      "epoch 185; iter: 0; batch classifier loss: 0.450455; batch adversarial loss: 0.589795\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328973; batch adversarial loss: 0.589423\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341190; batch adversarial loss: 0.544632\n",
      "epoch 188; iter: 0; batch classifier loss: 0.336555; batch adversarial loss: 0.544934\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371025; batch adversarial loss: 0.509007\n",
      "epoch 190; iter: 0; batch classifier loss: 0.378791; batch adversarial loss: 0.535780\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378083; batch adversarial loss: 0.615441\n",
      "epoch 192; iter: 0; batch classifier loss: 0.408365; batch adversarial loss: 0.571861\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318684; batch adversarial loss: 0.553744\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374024; batch adversarial loss: 0.598699\n",
      "epoch 195; iter: 0; batch classifier loss: 0.324667; batch adversarial loss: 0.482821\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321635; batch adversarial loss: 0.526628\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376298; batch adversarial loss: 0.624177\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371485; batch adversarial loss: 0.491189\n",
      "epoch 199; iter: 0; batch classifier loss: 0.293075; batch adversarial loss: 0.535710\n",
      "epoch 0; iter: 0; batch classifier loss: 0.816325; batch adversarial loss: 0.661159\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598699; batch adversarial loss: 0.672385\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600084; batch adversarial loss: 0.632437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593104; batch adversarial loss: 0.625912\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544087; batch adversarial loss: 0.623364\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600736; batch adversarial loss: 0.591013\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537345; batch adversarial loss: 0.566426\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596969; batch adversarial loss: 0.600691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.607908; batch adversarial loss: 0.559922\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547316; batch adversarial loss: 0.618984\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574312; batch adversarial loss: 0.593260\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562330; batch adversarial loss: 0.603364\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526001; batch adversarial loss: 0.598300\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516027; batch adversarial loss: 0.547792\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474083; batch adversarial loss: 0.581493\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510115; batch adversarial loss: 0.549127\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484707; batch adversarial loss: 0.574711\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532834; batch adversarial loss: 0.624721\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519148; batch adversarial loss: 0.558038\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483735; batch adversarial loss: 0.564195\n",
      "epoch 20; iter: 0; batch classifier loss: 0.459157; batch adversarial loss: 0.534476\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471878; batch adversarial loss: 0.544073\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498696; batch adversarial loss: 0.531537\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467566; batch adversarial loss: 0.556491\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519882; batch adversarial loss: 0.516093\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486491; batch adversarial loss: 0.506168\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469426; batch adversarial loss: 0.490293\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454585; batch adversarial loss: 0.561492\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461115; batch adversarial loss: 0.493406\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413959; batch adversarial loss: 0.558264\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436727; batch adversarial loss: 0.513458\n",
      "epoch 31; iter: 0; batch classifier loss: 0.527252; batch adversarial loss: 0.565709\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423858; batch adversarial loss: 0.578615\n",
      "epoch 33; iter: 0; batch classifier loss: 0.364616; batch adversarial loss: 0.568765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441453; batch adversarial loss: 0.529338\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404311; batch adversarial loss: 0.552990\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404888; batch adversarial loss: 0.646531\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409088; batch adversarial loss: 0.534457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.444131; batch adversarial loss: 0.493104\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460148; batch adversarial loss: 0.574447\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403243; batch adversarial loss: 0.520193\n",
      "epoch 41; iter: 0; batch classifier loss: 0.500451; batch adversarial loss: 0.527381\n",
      "epoch 42; iter: 0; batch classifier loss: 0.599736; batch adversarial loss: 0.525009\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474175; batch adversarial loss: 0.552463\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405697; batch adversarial loss: 0.545582\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377737; batch adversarial loss: 0.463054\n",
      "epoch 46; iter: 0; batch classifier loss: 0.507859; batch adversarial loss: 0.516854\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464369; batch adversarial loss: 0.577564\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388099; batch adversarial loss: 0.508968\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463245; batch adversarial loss: 0.605953\n",
      "epoch 50; iter: 0; batch classifier loss: 0.475360; batch adversarial loss: 0.579017\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422330; batch adversarial loss: 0.447363\n",
      "epoch 52; iter: 0; batch classifier loss: 0.411971; batch adversarial loss: 0.619040\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374861; batch adversarial loss: 0.491599\n",
      "epoch 54; iter: 0; batch classifier loss: 0.483011; batch adversarial loss: 0.582595\n",
      "epoch 55; iter: 0; batch classifier loss: 0.373324; batch adversarial loss: 0.499015\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420078; batch adversarial loss: 0.555063\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456801; batch adversarial loss: 0.560673\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389245; batch adversarial loss: 0.560595\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431279; batch adversarial loss: 0.562678\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417056; batch adversarial loss: 0.578966\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444618; batch adversarial loss: 0.626120\n",
      "epoch 62; iter: 0; batch classifier loss: 0.489252; batch adversarial loss: 0.526273\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381987; batch adversarial loss: 0.577862\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388915; batch adversarial loss: 0.608847\n",
      "epoch 65; iter: 0; batch classifier loss: 0.440715; batch adversarial loss: 0.608628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387895; batch adversarial loss: 0.560830\n",
      "epoch 67; iter: 0; batch classifier loss: 0.371213; batch adversarial loss: 0.615475\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431113; batch adversarial loss: 0.517984\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426284; batch adversarial loss: 0.555776\n",
      "epoch 70; iter: 0; batch classifier loss: 0.356015; batch adversarial loss: 0.580039\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378900; batch adversarial loss: 0.513619\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462558; batch adversarial loss: 0.551919\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400750; batch adversarial loss: 0.599517\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380182; batch adversarial loss: 0.516018\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381164; batch adversarial loss: 0.506715\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454042; batch adversarial loss: 0.554828\n",
      "epoch 77; iter: 0; batch classifier loss: 0.444041; batch adversarial loss: 0.607598\n",
      "epoch 78; iter: 0; batch classifier loss: 0.480058; batch adversarial loss: 0.508732\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410240; batch adversarial loss: 0.500555\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421671; batch adversarial loss: 0.565740\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410964; batch adversarial loss: 0.572669\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407412; batch adversarial loss: 0.563909\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416880; batch adversarial loss: 0.605715\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435475; batch adversarial loss: 0.582285\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385786; batch adversarial loss: 0.593420\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353842; batch adversarial loss: 0.598908\n",
      "epoch 87; iter: 0; batch classifier loss: 0.330120; batch adversarial loss: 0.518839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420230; batch adversarial loss: 0.518557\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362278; batch adversarial loss: 0.527455\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367736; batch adversarial loss: 0.535979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.429416; batch adversarial loss: 0.464190\n",
      "epoch 92; iter: 0; batch classifier loss: 0.442985; batch adversarial loss: 0.517149\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344790; batch adversarial loss: 0.590364\n",
      "epoch 94; iter: 0; batch classifier loss: 0.327313; batch adversarial loss: 0.572640\n",
      "epoch 95; iter: 0; batch classifier loss: 0.480769; batch adversarial loss: 0.599426\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420012; batch adversarial loss: 0.589442\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374213; batch adversarial loss: 0.545032\n",
      "epoch 98; iter: 0; batch classifier loss: 0.423109; batch adversarial loss: 0.499922\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376905; batch adversarial loss: 0.571042\n",
      "epoch 100; iter: 0; batch classifier loss: 0.333163; batch adversarial loss: 0.533984\n",
      "epoch 101; iter: 0; batch classifier loss: 0.439493; batch adversarial loss: 0.490121\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376054; batch adversarial loss: 0.496601\n",
      "epoch 103; iter: 0; batch classifier loss: 0.332070; batch adversarial loss: 0.570673\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408673; batch adversarial loss: 0.543674\n",
      "epoch 105; iter: 0; batch classifier loss: 0.587016; batch adversarial loss: 0.602311\n",
      "epoch 106; iter: 0; batch classifier loss: 0.364286; batch adversarial loss: 0.489549\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399982; batch adversarial loss: 0.590959\n",
      "epoch 108; iter: 0; batch classifier loss: 0.461864; batch adversarial loss: 0.534788\n",
      "epoch 109; iter: 0; batch classifier loss: 0.349737; batch adversarial loss: 0.578878\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401480; batch adversarial loss: 0.560896\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388587; batch adversarial loss: 0.517373\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388658; batch adversarial loss: 0.536171\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353526; batch adversarial loss: 0.561414\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408626; batch adversarial loss: 0.497771\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371160; batch adversarial loss: 0.500511\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438178; batch adversarial loss: 0.589816\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391803; batch adversarial loss: 0.581374\n",
      "epoch 118; iter: 0; batch classifier loss: 0.467323; batch adversarial loss: 0.608787\n",
      "epoch 119; iter: 0; batch classifier loss: 0.305017; batch adversarial loss: 0.616854\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408504; batch adversarial loss: 0.597814\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387938; batch adversarial loss: 0.569581\n",
      "epoch 122; iter: 0; batch classifier loss: 0.439381; batch adversarial loss: 0.560011\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327597; batch adversarial loss: 0.588990\n",
      "epoch 124; iter: 0; batch classifier loss: 0.293662; batch adversarial loss: 0.663841\n",
      "epoch 125; iter: 0; batch classifier loss: 0.364938; batch adversarial loss: 0.570029\n",
      "epoch 126; iter: 0; batch classifier loss: 0.455413; batch adversarial loss: 0.615458\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381827; batch adversarial loss: 0.561954\n",
      "epoch 128; iter: 0; batch classifier loss: 0.455290; batch adversarial loss: 0.518462\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380744; batch adversarial loss: 0.507707\n",
      "epoch 130; iter: 0; batch classifier loss: 0.424409; batch adversarial loss: 0.595757\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375972; batch adversarial loss: 0.584492\n",
      "epoch 132; iter: 0; batch classifier loss: 0.348994; batch adversarial loss: 0.569461\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355119; batch adversarial loss: 0.539845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.333978; batch adversarial loss: 0.635461\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362844; batch adversarial loss: 0.526315\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401558; batch adversarial loss: 0.527710\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384934; batch adversarial loss: 0.519144\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344464; batch adversarial loss: 0.536886\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401091; batch adversarial loss: 0.500588\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366814; batch adversarial loss: 0.581550\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343721; batch adversarial loss: 0.509961\n",
      "epoch 142; iter: 0; batch classifier loss: 0.304863; batch adversarial loss: 0.474509\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390884; batch adversarial loss: 0.500874\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358748; batch adversarial loss: 0.464625\n",
      "epoch 145; iter: 0; batch classifier loss: 0.447847; batch adversarial loss: 0.527160\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425235; batch adversarial loss: 0.490971\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346667; batch adversarial loss: 0.615924\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391396; batch adversarial loss: 0.643245\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362128; batch adversarial loss: 0.562096\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330967; batch adversarial loss: 0.534850\n",
      "epoch 151; iter: 0; batch classifier loss: 0.397301; batch adversarial loss: 0.553458\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366493; batch adversarial loss: 0.553905\n",
      "epoch 153; iter: 0; batch classifier loss: 0.383138; batch adversarial loss: 0.545162\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359481; batch adversarial loss: 0.507778\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388395; batch adversarial loss: 0.489918\n",
      "epoch 156; iter: 0; batch classifier loss: 0.403400; batch adversarial loss: 0.545102\n",
      "epoch 157; iter: 0; batch classifier loss: 0.428429; batch adversarial loss: 0.517386\n",
      "epoch 158; iter: 0; batch classifier loss: 0.482807; batch adversarial loss: 0.600347\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350676; batch adversarial loss: 0.516311\n",
      "epoch 160; iter: 0; batch classifier loss: 0.298634; batch adversarial loss: 0.534866\n",
      "epoch 161; iter: 0; batch classifier loss: 0.294250; batch adversarial loss: 0.562134\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331437; batch adversarial loss: 0.582205\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363443; batch adversarial loss: 0.499500\n",
      "epoch 164; iter: 0; batch classifier loss: 0.423367; batch adversarial loss: 0.525765\n",
      "epoch 165; iter: 0; batch classifier loss: 0.430192; batch adversarial loss: 0.562507\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318158; batch adversarial loss: 0.599107\n",
      "epoch 167; iter: 0; batch classifier loss: 0.464663; batch adversarial loss: 0.554209\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393288; batch adversarial loss: 0.589176\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374762; batch adversarial loss: 0.616360\n",
      "epoch 170; iter: 0; batch classifier loss: 0.448866; batch adversarial loss: 0.500393\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382559; batch adversarial loss: 0.607940\n",
      "epoch 172; iter: 0; batch classifier loss: 0.305344; batch adversarial loss: 0.536463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.316438; batch adversarial loss: 0.526021\n",
      "epoch 174; iter: 0; batch classifier loss: 0.439899; batch adversarial loss: 0.533926\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357982; batch adversarial loss: 0.589173\n",
      "epoch 176; iter: 0; batch classifier loss: 0.322043; batch adversarial loss: 0.580785\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417298; batch adversarial loss: 0.553496\n",
      "epoch 178; iter: 0; batch classifier loss: 0.408869; batch adversarial loss: 0.589967\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357250; batch adversarial loss: 0.572570\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324690; batch adversarial loss: 0.535918\n",
      "epoch 181; iter: 0; batch classifier loss: 0.278050; batch adversarial loss: 0.562285\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354178; batch adversarial loss: 0.571276\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324411; batch adversarial loss: 0.544965\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353274; batch adversarial loss: 0.498268\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364274; batch adversarial loss: 0.636455\n",
      "epoch 186; iter: 0; batch classifier loss: 0.425332; batch adversarial loss: 0.580674\n",
      "epoch 187; iter: 0; batch classifier loss: 0.408882; batch adversarial loss: 0.572905\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392145; batch adversarial loss: 0.535758\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344394; batch adversarial loss: 0.562478\n",
      "epoch 190; iter: 0; batch classifier loss: 0.450018; batch adversarial loss: 0.562447\n",
      "epoch 191; iter: 0; batch classifier loss: 0.383308; batch adversarial loss: 0.488585\n",
      "epoch 192; iter: 0; batch classifier loss: 0.265021; batch adversarial loss: 0.535260\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373669; batch adversarial loss: 0.544372\n",
      "epoch 194; iter: 0; batch classifier loss: 0.373750; batch adversarial loss: 0.553421\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368866; batch adversarial loss: 0.617049\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356614; batch adversarial loss: 0.462584\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356792; batch adversarial loss: 0.599091\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386947; batch adversarial loss: 0.553887\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352980; batch adversarial loss: 0.599156\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699723; batch adversarial loss: 0.725534\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588201; batch adversarial loss: 0.683428\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623312; batch adversarial loss: 0.652545\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551293; batch adversarial loss: 0.632789\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552836; batch adversarial loss: 0.624731\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612073; batch adversarial loss: 0.605681\n",
      "epoch 6; iter: 0; batch classifier loss: 0.478496; batch adversarial loss: 0.598494\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511440; batch adversarial loss: 0.622508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564902; batch adversarial loss: 0.642798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539690; batch adversarial loss: 0.589081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471567; batch adversarial loss: 0.586476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512268; batch adversarial loss: 0.677207\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500681; batch adversarial loss: 0.592563\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546850; batch adversarial loss: 0.572644\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478941; batch adversarial loss: 0.534679\n",
      "epoch 15; iter: 0; batch classifier loss: 0.517850; batch adversarial loss: 0.589890\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503368; batch adversarial loss: 0.530490\n",
      "epoch 17; iter: 0; batch classifier loss: 0.464815; batch adversarial loss: 0.646568\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484470; batch adversarial loss: 0.564940\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477536; batch adversarial loss: 0.583118\n",
      "epoch 20; iter: 0; batch classifier loss: 0.414659; batch adversarial loss: 0.531900\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509166; batch adversarial loss: 0.577194\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488721; batch adversarial loss: 0.546469\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518766; batch adversarial loss: 0.641601\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484312; batch adversarial loss: 0.585839\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442450; batch adversarial loss: 0.545282\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468517; batch adversarial loss: 0.551439\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445908; batch adversarial loss: 0.616206\n",
      "epoch 28; iter: 0; batch classifier loss: 0.497492; batch adversarial loss: 0.606528\n",
      "epoch 29; iter: 0; batch classifier loss: 0.597360; batch adversarial loss: 0.466262\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452655; batch adversarial loss: 0.549572\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486348; batch adversarial loss: 0.606487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.419030; batch adversarial loss: 0.509987\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458730; batch adversarial loss: 0.530071\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500358; batch adversarial loss: 0.577182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474628; batch adversarial loss: 0.574136\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494945; batch adversarial loss: 0.535461\n",
      "epoch 37; iter: 0; batch classifier loss: 0.507111; batch adversarial loss: 0.508649\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452758; batch adversarial loss: 0.600493\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490653; batch adversarial loss: 0.622902\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460259; batch adversarial loss: 0.578702\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422536; batch adversarial loss: 0.536272\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463010; batch adversarial loss: 0.435957\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441736; batch adversarial loss: 0.578699\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433506; batch adversarial loss: 0.553812\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477127; batch adversarial loss: 0.518186\n",
      "epoch 46; iter: 0; batch classifier loss: 0.492364; batch adversarial loss: 0.563077\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399174; batch adversarial loss: 0.605719\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412675; batch adversarial loss: 0.551896\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426288; batch adversarial loss: 0.501351\n",
      "epoch 50; iter: 0; batch classifier loss: 0.482612; batch adversarial loss: 0.580114\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468670; batch adversarial loss: 0.552949\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458606; batch adversarial loss: 0.598705\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454507; batch adversarial loss: 0.474520\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418992; batch adversarial loss: 0.631254\n",
      "epoch 55; iter: 0; batch classifier loss: 0.375861; batch adversarial loss: 0.508165\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423748; batch adversarial loss: 0.536557\n",
      "epoch 57; iter: 0; batch classifier loss: 0.353048; batch adversarial loss: 0.526966\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405401; batch adversarial loss: 0.669479\n",
      "epoch 59; iter: 0; batch classifier loss: 0.344342; batch adversarial loss: 0.446080\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393193; batch adversarial loss: 0.506163\n",
      "epoch 61; iter: 0; batch classifier loss: 0.362232; batch adversarial loss: 0.435914\n",
      "epoch 62; iter: 0; batch classifier loss: 0.481391; batch adversarial loss: 0.535109\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435429; batch adversarial loss: 0.514090\n",
      "epoch 64; iter: 0; batch classifier loss: 0.488474; batch adversarial loss: 0.534788\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431919; batch adversarial loss: 0.563825\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401006; batch adversarial loss: 0.526398\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435899; batch adversarial loss: 0.584683\n",
      "epoch 68; iter: 0; batch classifier loss: 0.456746; batch adversarial loss: 0.555481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415990; batch adversarial loss: 0.597828\n",
      "epoch 70; iter: 0; batch classifier loss: 0.356824; batch adversarial loss: 0.591004\n",
      "epoch 71; iter: 0; batch classifier loss: 0.328150; batch adversarial loss: 0.622935\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394990; batch adversarial loss: 0.517718\n",
      "epoch 73; iter: 0; batch classifier loss: 0.503955; batch adversarial loss: 0.584082\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428535; batch adversarial loss: 0.564430\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449174; batch adversarial loss: 0.519680\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424771; batch adversarial loss: 0.574530\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437870; batch adversarial loss: 0.548609\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393848; batch adversarial loss: 0.622331\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432770; batch adversarial loss: 0.587618\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460498; batch adversarial loss: 0.580672\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428897; batch adversarial loss: 0.536705\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422976; batch adversarial loss: 0.589587\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420616; batch adversarial loss: 0.520356\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405840; batch adversarial loss: 0.533125\n",
      "epoch 85; iter: 0; batch classifier loss: 0.322434; batch adversarial loss: 0.560600\n",
      "epoch 86; iter: 0; batch classifier loss: 0.329704; batch adversarial loss: 0.563001\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399788; batch adversarial loss: 0.524820\n",
      "epoch 88; iter: 0; batch classifier loss: 0.432487; batch adversarial loss: 0.517490\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384516; batch adversarial loss: 0.454545\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404270; batch adversarial loss: 0.571895\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423453; batch adversarial loss: 0.516851\n",
      "epoch 92; iter: 0; batch classifier loss: 0.453133; batch adversarial loss: 0.514274\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395730; batch adversarial loss: 0.553657\n",
      "epoch 94; iter: 0; batch classifier loss: 0.417232; batch adversarial loss: 0.543078\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362956; batch adversarial loss: 0.549341\n",
      "epoch 96; iter: 0; batch classifier loss: 0.456895; batch adversarial loss: 0.507087\n",
      "epoch 97; iter: 0; batch classifier loss: 0.449645; batch adversarial loss: 0.525916\n",
      "epoch 98; iter: 0; batch classifier loss: 0.437768; batch adversarial loss: 0.636406\n",
      "epoch 99; iter: 0; batch classifier loss: 0.334271; batch adversarial loss: 0.543704\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335837; batch adversarial loss: 0.534615\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370202; batch adversarial loss: 0.613908\n",
      "epoch 102; iter: 0; batch classifier loss: 0.458400; batch adversarial loss: 0.588127\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427715; batch adversarial loss: 0.482935\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369708; batch adversarial loss: 0.540449\n",
      "epoch 105; iter: 0; batch classifier loss: 0.289540; batch adversarial loss: 0.490484\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407415; batch adversarial loss: 0.616344\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365597; batch adversarial loss: 0.464343\n",
      "epoch 108; iter: 0; batch classifier loss: 0.345721; batch adversarial loss: 0.536143\n",
      "epoch 109; iter: 0; batch classifier loss: 0.424919; batch adversarial loss: 0.457181\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356222; batch adversarial loss: 0.505166\n",
      "epoch 111; iter: 0; batch classifier loss: 0.467176; batch adversarial loss: 0.552633\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362118; batch adversarial loss: 0.581347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370062; batch adversarial loss: 0.604190\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386085; batch adversarial loss: 0.536902\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379295; batch adversarial loss: 0.462467\n",
      "epoch 116; iter: 0; batch classifier loss: 0.404492; batch adversarial loss: 0.605556\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319049; batch adversarial loss: 0.607315\n",
      "epoch 118; iter: 0; batch classifier loss: 0.379158; batch adversarial loss: 0.519125\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410781; batch adversarial loss: 0.556555\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408679; batch adversarial loss: 0.579949\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321838; batch adversarial loss: 0.523923\n",
      "epoch 122; iter: 0; batch classifier loss: 0.405057; batch adversarial loss: 0.563047\n",
      "epoch 123; iter: 0; batch classifier loss: 0.386357; batch adversarial loss: 0.565305\n",
      "epoch 124; iter: 0; batch classifier loss: 0.304421; batch adversarial loss: 0.610844\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368689; batch adversarial loss: 0.562049\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392089; batch adversarial loss: 0.462611\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443745; batch adversarial loss: 0.554599\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366423; batch adversarial loss: 0.530451\n",
      "epoch 129; iter: 0; batch classifier loss: 0.418829; batch adversarial loss: 0.563130\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339404; batch adversarial loss: 0.571455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.416480; batch adversarial loss: 0.493215\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334772; batch adversarial loss: 0.594276\n",
      "epoch 133; iter: 0; batch classifier loss: 0.365309; batch adversarial loss: 0.548721\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338975; batch adversarial loss: 0.537109\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334337; batch adversarial loss: 0.545373\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392078; batch adversarial loss: 0.544352\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382543; batch adversarial loss: 0.581602\n",
      "epoch 138; iter: 0; batch classifier loss: 0.409567; batch adversarial loss: 0.533206\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368741; batch adversarial loss: 0.564375\n",
      "epoch 140; iter: 0; batch classifier loss: 0.470419; batch adversarial loss: 0.523377\n",
      "epoch 141; iter: 0; batch classifier loss: 0.397545; batch adversarial loss: 0.516122\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392578; batch adversarial loss: 0.518597\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348781; batch adversarial loss: 0.625404\n",
      "epoch 144; iter: 0; batch classifier loss: 0.327151; batch adversarial loss: 0.583553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.354545; batch adversarial loss: 0.535340\n",
      "epoch 146; iter: 0; batch classifier loss: 0.400470; batch adversarial loss: 0.574335\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354039; batch adversarial loss: 0.561553\n",
      "epoch 148; iter: 0; batch classifier loss: 0.340225; batch adversarial loss: 0.550162\n",
      "epoch 149; iter: 0; batch classifier loss: 0.461513; batch adversarial loss: 0.563013\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352141; batch adversarial loss: 0.604966\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422124; batch adversarial loss: 0.552030\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364707; batch adversarial loss: 0.550252\n",
      "epoch 153; iter: 0; batch classifier loss: 0.326731; batch adversarial loss: 0.600616\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389457; batch adversarial loss: 0.563276\n",
      "epoch 155; iter: 0; batch classifier loss: 0.393338; batch adversarial loss: 0.544669\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384887; batch adversarial loss: 0.574840\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352674; batch adversarial loss: 0.564197\n",
      "epoch 158; iter: 0; batch classifier loss: 0.406808; batch adversarial loss: 0.489539\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393307; batch adversarial loss: 0.534132\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401505; batch adversarial loss: 0.616857\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411616; batch adversarial loss: 0.561985\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378680; batch adversarial loss: 0.549449\n",
      "epoch 163; iter: 0; batch classifier loss: 0.455478; batch adversarial loss: 0.553032\n",
      "epoch 164; iter: 0; batch classifier loss: 0.313475; batch adversarial loss: 0.611955\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386241; batch adversarial loss: 0.526994\n",
      "epoch 166; iter: 0; batch classifier loss: 0.426963; batch adversarial loss: 0.618765\n",
      "epoch 167; iter: 0; batch classifier loss: 0.439711; batch adversarial loss: 0.633053\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343142; batch adversarial loss: 0.515362\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352474; batch adversarial loss: 0.564285\n",
      "epoch 170; iter: 0; batch classifier loss: 0.364716; batch adversarial loss: 0.589060\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363079; batch adversarial loss: 0.576967\n",
      "epoch 172; iter: 0; batch classifier loss: 0.401848; batch adversarial loss: 0.535723\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356975; batch adversarial loss: 0.543306\n",
      "epoch 174; iter: 0; batch classifier loss: 0.430942; batch adversarial loss: 0.510014\n",
      "epoch 175; iter: 0; batch classifier loss: 0.361271; batch adversarial loss: 0.566288\n",
      "epoch 176; iter: 0; batch classifier loss: 0.463298; batch adversarial loss: 0.600073\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362114; batch adversarial loss: 0.465478\n",
      "epoch 178; iter: 0; batch classifier loss: 0.448779; batch adversarial loss: 0.508756\n",
      "epoch 179; iter: 0; batch classifier loss: 0.336254; batch adversarial loss: 0.631931\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392833; batch adversarial loss: 0.542137\n",
      "epoch 181; iter: 0; batch classifier loss: 0.428424; batch adversarial loss: 0.552594\n",
      "epoch 182; iter: 0; batch classifier loss: 0.469770; batch adversarial loss: 0.553120\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355608; batch adversarial loss: 0.507920\n",
      "epoch 184; iter: 0; batch classifier loss: 0.405700; batch adversarial loss: 0.510412\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393813; batch adversarial loss: 0.573495\n",
      "epoch 186; iter: 0; batch classifier loss: 0.295727; batch adversarial loss: 0.574001\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353252; batch adversarial loss: 0.535420\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391442; batch adversarial loss: 0.609770\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375700; batch adversarial loss: 0.621747\n",
      "epoch 190; iter: 0; batch classifier loss: 0.377488; batch adversarial loss: 0.591177\n",
      "epoch 191; iter: 0; batch classifier loss: 0.442599; batch adversarial loss: 0.537003\n",
      "epoch 192; iter: 0; batch classifier loss: 0.409144; batch adversarial loss: 0.579208\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390273; batch adversarial loss: 0.553079\n",
      "epoch 194; iter: 0; batch classifier loss: 0.375687; batch adversarial loss: 0.570605\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382959; batch adversarial loss: 0.508592\n",
      "epoch 196; iter: 0; batch classifier loss: 0.285007; batch adversarial loss: 0.535693\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366938; batch adversarial loss: 0.552743\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381256; batch adversarial loss: 0.600243\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387384; batch adversarial loss: 0.586915\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743575; batch adversarial loss: 0.650266\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574786; batch adversarial loss: 0.654821\n",
      "epoch 2; iter: 0; batch classifier loss: 0.560715; batch adversarial loss: 0.641033\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548563; batch adversarial loss: 0.625008\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594366; batch adversarial loss: 0.612887\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567880; batch adversarial loss: 0.626832\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591567; batch adversarial loss: 0.599928\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495689; batch adversarial loss: 0.601986\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578020; batch adversarial loss: 0.591998\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571623; batch adversarial loss: 0.617042\n",
      "epoch 10; iter: 0; batch classifier loss: 0.482073; batch adversarial loss: 0.556657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548458; batch adversarial loss: 0.598064\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476173; batch adversarial loss: 0.571120\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567827; batch adversarial loss: 0.558670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509515; batch adversarial loss: 0.544283\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564791; batch adversarial loss: 0.551848\n",
      "epoch 16; iter: 0; batch classifier loss: 0.573782; batch adversarial loss: 0.540154\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486052; batch adversarial loss: 0.588890\n",
      "epoch 18; iter: 0; batch classifier loss: 0.428447; batch adversarial loss: 0.524209\n",
      "epoch 19; iter: 0; batch classifier loss: 0.560367; batch adversarial loss: 0.525077\n",
      "epoch 20; iter: 0; batch classifier loss: 0.558011; batch adversarial loss: 0.530064\n",
      "epoch 21; iter: 0; batch classifier loss: 0.562923; batch adversarial loss: 0.544701\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468061; batch adversarial loss: 0.572177\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474900; batch adversarial loss: 0.524654\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470336; batch adversarial loss: 0.511015\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439955; batch adversarial loss: 0.624158\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466777; batch adversarial loss: 0.530848\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466158; batch adversarial loss: 0.535487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.467793; batch adversarial loss: 0.592940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.501132; batch adversarial loss: 0.574042\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540257; batch adversarial loss: 0.510032\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463413; batch adversarial loss: 0.535800\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468845; batch adversarial loss: 0.570823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501849; batch adversarial loss: 0.593776\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427566; batch adversarial loss: 0.507352\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419833; batch adversarial loss: 0.526398\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435825; batch adversarial loss: 0.551049\n",
      "epoch 37; iter: 0; batch classifier loss: 0.519965; batch adversarial loss: 0.555680\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465606; batch adversarial loss: 0.499622\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436633; batch adversarial loss: 0.554520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421758; batch adversarial loss: 0.571970\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489207; batch adversarial loss: 0.607811\n",
      "epoch 42; iter: 0; batch classifier loss: 0.395621; batch adversarial loss: 0.489969\n",
      "epoch 43; iter: 0; batch classifier loss: 0.452589; batch adversarial loss: 0.571884\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468085; batch adversarial loss: 0.571777\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427395; batch adversarial loss: 0.535367\n",
      "epoch 46; iter: 0; batch classifier loss: 0.509545; batch adversarial loss: 0.498819\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476858; batch adversarial loss: 0.589775\n",
      "epoch 48; iter: 0; batch classifier loss: 0.516492; batch adversarial loss: 0.561969\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418728; batch adversarial loss: 0.499170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.535197; batch adversarial loss: 0.561567\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430628; batch adversarial loss: 0.569462\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430469; batch adversarial loss: 0.523943\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424000; batch adversarial loss: 0.464821\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384400; batch adversarial loss: 0.524474\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415252; batch adversarial loss: 0.588810\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454916; batch adversarial loss: 0.516050\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415310; batch adversarial loss: 0.535156\n",
      "epoch 58; iter: 0; batch classifier loss: 0.516809; batch adversarial loss: 0.526960\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445196; batch adversarial loss: 0.611017\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403601; batch adversarial loss: 0.554570\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435098; batch adversarial loss: 0.497318\n",
      "epoch 62; iter: 0; batch classifier loss: 0.422506; batch adversarial loss: 0.544594\n",
      "epoch 63; iter: 0; batch classifier loss: 0.328702; batch adversarial loss: 0.553953\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466561; batch adversarial loss: 0.488425\n",
      "epoch 65; iter: 0; batch classifier loss: 0.488462; batch adversarial loss: 0.600570\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404985; batch adversarial loss: 0.451153\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361741; batch adversarial loss: 0.525152\n",
      "epoch 68; iter: 0; batch classifier loss: 0.483753; batch adversarial loss: 0.535222\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436804; batch adversarial loss: 0.507371\n",
      "epoch 70; iter: 0; batch classifier loss: 0.409219; batch adversarial loss: 0.470339\n",
      "epoch 71; iter: 0; batch classifier loss: 0.468166; batch adversarial loss: 0.479188\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387930; batch adversarial loss: 0.553497\n",
      "epoch 73; iter: 0; batch classifier loss: 0.454044; batch adversarial loss: 0.488025\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397536; batch adversarial loss: 0.609711\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391478; batch adversarial loss: 0.524697\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396039; batch adversarial loss: 0.598639\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424218; batch adversarial loss: 0.553706\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386239; batch adversarial loss: 0.609545\n",
      "epoch 79; iter: 0; batch classifier loss: 0.501194; batch adversarial loss: 0.634785\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403189; batch adversarial loss: 0.581896\n",
      "epoch 81; iter: 0; batch classifier loss: 0.458578; batch adversarial loss: 0.497592\n",
      "epoch 82; iter: 0; batch classifier loss: 0.355316; batch adversarial loss: 0.544157\n",
      "epoch 83; iter: 0; batch classifier loss: 0.321686; batch adversarial loss: 0.486894\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363396; batch adversarial loss: 0.590197\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396604; batch adversarial loss: 0.471055\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406301; batch adversarial loss: 0.526266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405662; batch adversarial loss: 0.544805\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394670; batch adversarial loss: 0.590833\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438888; batch adversarial loss: 0.581433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.476968; batch adversarial loss: 0.589172\n",
      "epoch 91; iter: 0; batch classifier loss: 0.329709; batch adversarial loss: 0.599378\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381610; batch adversarial loss: 0.543028\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412762; batch adversarial loss: 0.498098\n",
      "epoch 94; iter: 0; batch classifier loss: 0.293495; batch adversarial loss: 0.563356\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430116; batch adversarial loss: 0.628354\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400688; batch adversarial loss: 0.527006\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366533; batch adversarial loss: 0.618704\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366255; batch adversarial loss: 0.544170\n",
      "epoch 99; iter: 0; batch classifier loss: 0.347522; batch adversarial loss: 0.582514\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383804; batch adversarial loss: 0.507674\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368470; batch adversarial loss: 0.526101\n",
      "epoch 102; iter: 0; batch classifier loss: 0.433829; batch adversarial loss: 0.572637\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384121; batch adversarial loss: 0.479239\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395810; batch adversarial loss: 0.598884\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427193; batch adversarial loss: 0.525489\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409689; batch adversarial loss: 0.479484\n",
      "epoch 107; iter: 0; batch classifier loss: 0.423291; batch adversarial loss: 0.545626\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380178; batch adversarial loss: 0.534630\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336439; batch adversarial loss: 0.610404\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353823; batch adversarial loss: 0.600034\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361892; batch adversarial loss: 0.581646\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382260; batch adversarial loss: 0.554708\n",
      "epoch 113; iter: 0; batch classifier loss: 0.491521; batch adversarial loss: 0.598916\n",
      "epoch 114; iter: 0; batch classifier loss: 0.407212; batch adversarial loss: 0.423887\n",
      "epoch 115; iter: 0; batch classifier loss: 0.413946; batch adversarial loss: 0.507588\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339424; batch adversarial loss: 0.452813\n",
      "epoch 117; iter: 0; batch classifier loss: 0.349144; batch adversarial loss: 0.564385\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354510; batch adversarial loss: 0.544717\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389844; batch adversarial loss: 0.590933\n",
      "epoch 120; iter: 0; batch classifier loss: 0.424605; batch adversarial loss: 0.572592\n",
      "epoch 121; iter: 0; batch classifier loss: 0.456877; batch adversarial loss: 0.517538\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389407; batch adversarial loss: 0.572115\n",
      "epoch 123; iter: 0; batch classifier loss: 0.383178; batch adversarial loss: 0.535926\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398938; batch adversarial loss: 0.536310\n",
      "epoch 125; iter: 0; batch classifier loss: 0.388866; batch adversarial loss: 0.620105\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374741; batch adversarial loss: 0.590557\n",
      "epoch 127; iter: 0; batch classifier loss: 0.373895; batch adversarial loss: 0.562924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.365950; batch adversarial loss: 0.479424\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376911; batch adversarial loss: 0.627824\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398812; batch adversarial loss: 0.572205\n",
      "epoch 131; iter: 0; batch classifier loss: 0.449157; batch adversarial loss: 0.545190\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320005; batch adversarial loss: 0.600205\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426067; batch adversarial loss: 0.591013\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375512; batch adversarial loss: 0.589628\n",
      "epoch 135; iter: 0; batch classifier loss: 0.482154; batch adversarial loss: 0.554330\n",
      "epoch 136; iter: 0; batch classifier loss: 0.426735; batch adversarial loss: 0.526085\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400290; batch adversarial loss: 0.507547\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362112; batch adversarial loss: 0.513686\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361536; batch adversarial loss: 0.562597\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373242; batch adversarial loss: 0.564505\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341810; batch adversarial loss: 0.636638\n",
      "epoch 142; iter: 0; batch classifier loss: 0.381695; batch adversarial loss: 0.508827\n",
      "epoch 143; iter: 0; batch classifier loss: 0.421023; batch adversarial loss: 0.507870\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365103; batch adversarial loss: 0.517472\n",
      "epoch 145; iter: 0; batch classifier loss: 0.393379; batch adversarial loss: 0.498057\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365761; batch adversarial loss: 0.648712\n",
      "epoch 147; iter: 0; batch classifier loss: 0.386122; batch adversarial loss: 0.554163\n",
      "epoch 148; iter: 0; batch classifier loss: 0.317340; batch adversarial loss: 0.610655\n",
      "epoch 149; iter: 0; batch classifier loss: 0.444172; batch adversarial loss: 0.562764\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365125; batch adversarial loss: 0.580656\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375142; batch adversarial loss: 0.562890\n",
      "epoch 152; iter: 0; batch classifier loss: 0.303270; batch adversarial loss: 0.498880\n",
      "epoch 153; iter: 0; batch classifier loss: 0.428885; batch adversarial loss: 0.497774\n",
      "epoch 154; iter: 0; batch classifier loss: 0.446995; batch adversarial loss: 0.590643\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340707; batch adversarial loss: 0.572128\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404297; batch adversarial loss: 0.573022\n",
      "epoch 157; iter: 0; batch classifier loss: 0.322039; batch adversarial loss: 0.526561\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339167; batch adversarial loss: 0.561981\n",
      "epoch 159; iter: 0; batch classifier loss: 0.254533; batch adversarial loss: 0.563307\n",
      "epoch 160; iter: 0; batch classifier loss: 0.286137; batch adversarial loss: 0.535218\n",
      "epoch 161; iter: 0; batch classifier loss: 0.454494; batch adversarial loss: 0.554389\n",
      "epoch 162; iter: 0; batch classifier loss: 0.244775; batch adversarial loss: 0.600340\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375915; batch adversarial loss: 0.554161\n",
      "epoch 164; iter: 0; batch classifier loss: 0.327314; batch adversarial loss: 0.526980\n",
      "epoch 165; iter: 0; batch classifier loss: 0.335904; batch adversarial loss: 0.507903\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344919; batch adversarial loss: 0.517114\n",
      "epoch 167; iter: 0; batch classifier loss: 0.311985; batch adversarial loss: 0.628456\n",
      "epoch 168; iter: 0; batch classifier loss: 0.303802; batch adversarial loss: 0.517376\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407295; batch adversarial loss: 0.582693\n",
      "epoch 170; iter: 0; batch classifier loss: 0.372119; batch adversarial loss: 0.582314\n",
      "epoch 171; iter: 0; batch classifier loss: 0.416336; batch adversarial loss: 0.516510\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348313; batch adversarial loss: 0.545413\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410430; batch adversarial loss: 0.526333\n",
      "epoch 174; iter: 0; batch classifier loss: 0.294441; batch adversarial loss: 0.590539\n",
      "epoch 175; iter: 0; batch classifier loss: 0.333585; batch adversarial loss: 0.588970\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340031; batch adversarial loss: 0.524678\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330681; batch adversarial loss: 0.571960\n",
      "epoch 178; iter: 0; batch classifier loss: 0.495633; batch adversarial loss: 0.598521\n",
      "epoch 179; iter: 0; batch classifier loss: 0.320815; batch adversarial loss: 0.582567\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316177; batch adversarial loss: 0.499325\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366968; batch adversarial loss: 0.496711\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380871; batch adversarial loss: 0.555523\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385516; batch adversarial loss: 0.562621\n",
      "epoch 184; iter: 0; batch classifier loss: 0.436959; batch adversarial loss: 0.507114\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326565; batch adversarial loss: 0.506964\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399530; batch adversarial loss: 0.590140\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395162; batch adversarial loss: 0.543370\n",
      "epoch 188; iter: 0; batch classifier loss: 0.268540; batch adversarial loss: 0.478320\n",
      "epoch 189; iter: 0; batch classifier loss: 0.397311; batch adversarial loss: 0.580252\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298891; batch adversarial loss: 0.543780\n",
      "epoch 191; iter: 0; batch classifier loss: 0.308037; batch adversarial loss: 0.508065\n",
      "epoch 192; iter: 0; batch classifier loss: 0.295323; batch adversarial loss: 0.535393\n",
      "epoch 193; iter: 0; batch classifier loss: 0.382672; batch adversarial loss: 0.509225\n",
      "epoch 194; iter: 0; batch classifier loss: 0.421532; batch adversarial loss: 0.480005\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311187; batch adversarial loss: 0.516760\n",
      "epoch 196; iter: 0; batch classifier loss: 0.371001; batch adversarial loss: 0.573137\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349651; batch adversarial loss: 0.507699\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371570; batch adversarial loss: 0.489037\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396742; batch adversarial loss: 0.553565\n",
      "epoch 0; iter: 0; batch classifier loss: 0.791429; batch adversarial loss: 0.544582\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599215; batch adversarial loss: 0.654087\n",
      "epoch 2; iter: 0; batch classifier loss: 0.517147; batch adversarial loss: 0.666249\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558031; batch adversarial loss: 0.665221\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542889; batch adversarial loss: 0.642453\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544286; batch adversarial loss: 0.648636\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590707; batch adversarial loss: 0.623122\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595248; batch adversarial loss: 0.661759\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602323; batch adversarial loss: 0.566459\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562293; batch adversarial loss: 0.613105\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602994; batch adversarial loss: 0.635505\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513732; batch adversarial loss: 0.487266\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578577; batch adversarial loss: 0.607560\n",
      "epoch 13; iter: 0; batch classifier loss: 0.615174; batch adversarial loss: 0.583153\n",
      "epoch 14; iter: 0; batch classifier loss: 0.537205; batch adversarial loss: 0.593900\n",
      "epoch 15; iter: 0; batch classifier loss: 0.472361; batch adversarial loss: 0.551724\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540070; batch adversarial loss: 0.587357\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466340; batch adversarial loss: 0.568327\n",
      "epoch 18; iter: 0; batch classifier loss: 0.568766; batch adversarial loss: 0.534253\n",
      "epoch 19; iter: 0; batch classifier loss: 0.553500; batch adversarial loss: 0.601195\n",
      "epoch 20; iter: 0; batch classifier loss: 0.565032; batch adversarial loss: 0.597868\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478717; batch adversarial loss: 0.504131\n",
      "epoch 22; iter: 0; batch classifier loss: 0.523335; batch adversarial loss: 0.603732\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498966; batch adversarial loss: 0.506094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.497076; batch adversarial loss: 0.563935\n",
      "epoch 25; iter: 0; batch classifier loss: 0.444514; batch adversarial loss: 0.589105\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480169; batch adversarial loss: 0.485127\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492529; batch adversarial loss: 0.527473\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529031; batch adversarial loss: 0.535294\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452596; batch adversarial loss: 0.447721\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445822; batch adversarial loss: 0.539231\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428748; batch adversarial loss: 0.544684\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445359; batch adversarial loss: 0.544254\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451352; batch adversarial loss: 0.580902\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427505; batch adversarial loss: 0.561644\n",
      "epoch 35; iter: 0; batch classifier loss: 0.361778; batch adversarial loss: 0.507480\n",
      "epoch 36; iter: 0; batch classifier loss: 0.501494; batch adversarial loss: 0.588669\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464050; batch adversarial loss: 0.518437\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440551; batch adversarial loss: 0.525535\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436574; batch adversarial loss: 0.563728\n",
      "epoch 40; iter: 0; batch classifier loss: 0.479203; batch adversarial loss: 0.571210\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402447; batch adversarial loss: 0.571947\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446903; batch adversarial loss: 0.572934\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423893; batch adversarial loss: 0.545820\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450310; batch adversarial loss: 0.509625\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399537; batch adversarial loss: 0.572739\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452130; batch adversarial loss: 0.591066\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475026; batch adversarial loss: 0.553596\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465316; batch adversarial loss: 0.533540\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357657; batch adversarial loss: 0.590134\n",
      "epoch 50; iter: 0; batch classifier loss: 0.497713; batch adversarial loss: 0.516111\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427169; batch adversarial loss: 0.536053\n",
      "epoch 52; iter: 0; batch classifier loss: 0.485284; batch adversarial loss: 0.543727\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428828; batch adversarial loss: 0.524845\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446690; batch adversarial loss: 0.588957\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414092; batch adversarial loss: 0.504256\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446844; batch adversarial loss: 0.470822\n",
      "epoch 57; iter: 0; batch classifier loss: 0.482821; batch adversarial loss: 0.536310\n",
      "epoch 58; iter: 0; batch classifier loss: 0.343985; batch adversarial loss: 0.609753\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418317; batch adversarial loss: 0.616645\n",
      "epoch 60; iter: 0; batch classifier loss: 0.501348; batch adversarial loss: 0.544700\n",
      "epoch 61; iter: 0; batch classifier loss: 0.456044; batch adversarial loss: 0.535942\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425460; batch adversarial loss: 0.481622\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400999; batch adversarial loss: 0.498983\n",
      "epoch 64; iter: 0; batch classifier loss: 0.364135; batch adversarial loss: 0.535630\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386934; batch adversarial loss: 0.589058\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414988; batch adversarial loss: 0.571889\n",
      "epoch 67; iter: 0; batch classifier loss: 0.497646; batch adversarial loss: 0.508299\n",
      "epoch 68; iter: 0; batch classifier loss: 0.449175; batch adversarial loss: 0.472419\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377939; batch adversarial loss: 0.581016\n",
      "epoch 70; iter: 0; batch classifier loss: 0.463362; batch adversarial loss: 0.544293\n",
      "epoch 71; iter: 0; batch classifier loss: 0.424322; batch adversarial loss: 0.572508\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411424; batch adversarial loss: 0.535616\n",
      "epoch 73; iter: 0; batch classifier loss: 0.485735; batch adversarial loss: 0.545015\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354427; batch adversarial loss: 0.535312\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440439; batch adversarial loss: 0.545265\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414867; batch adversarial loss: 0.562769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383380; batch adversarial loss: 0.635742\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381265; batch adversarial loss: 0.553877\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420978; batch adversarial loss: 0.536001\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399673; batch adversarial loss: 0.526271\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406147; batch adversarial loss: 0.526042\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412532; batch adversarial loss: 0.544971\n",
      "epoch 83; iter: 0; batch classifier loss: 0.408195; batch adversarial loss: 0.572084\n",
      "epoch 84; iter: 0; batch classifier loss: 0.290457; batch adversarial loss: 0.516634\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391620; batch adversarial loss: 0.535426\n",
      "epoch 86; iter: 0; batch classifier loss: 0.523886; batch adversarial loss: 0.517167\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378627; batch adversarial loss: 0.562871\n",
      "epoch 88; iter: 0; batch classifier loss: 0.403661; batch adversarial loss: 0.461856\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393199; batch adversarial loss: 0.470715\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403751; batch adversarial loss: 0.598884\n",
      "epoch 91; iter: 0; batch classifier loss: 0.483335; batch adversarial loss: 0.571410\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381413; batch adversarial loss: 0.599566\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394307; batch adversarial loss: 0.544255\n",
      "epoch 94; iter: 0; batch classifier loss: 0.409407; batch adversarial loss: 0.508100\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408421; batch adversarial loss: 0.507633\n",
      "epoch 96; iter: 0; batch classifier loss: 0.426144; batch adversarial loss: 0.553571\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413249; batch adversarial loss: 0.498438\n",
      "epoch 98; iter: 0; batch classifier loss: 0.464448; batch adversarial loss: 0.507785\n",
      "epoch 99; iter: 0; batch classifier loss: 0.430991; batch adversarial loss: 0.590558\n",
      "epoch 100; iter: 0; batch classifier loss: 0.494920; batch adversarial loss: 0.535654\n",
      "epoch 101; iter: 0; batch classifier loss: 0.331640; batch adversarial loss: 0.609814\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394749; batch adversarial loss: 0.554122\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375504; batch adversarial loss: 0.553362\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383897; batch adversarial loss: 0.496879\n",
      "epoch 105; iter: 0; batch classifier loss: 0.313045; batch adversarial loss: 0.489106\n",
      "epoch 106; iter: 0; batch classifier loss: 0.319358; batch adversarial loss: 0.523956\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381547; batch adversarial loss: 0.507049\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411407; batch adversarial loss: 0.525719\n",
      "epoch 109; iter: 0; batch classifier loss: 0.335997; batch adversarial loss: 0.486162\n",
      "epoch 110; iter: 0; batch classifier loss: 0.481344; batch adversarial loss: 0.521871\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361562; batch adversarial loss: 0.526892\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433645; batch adversarial loss: 0.461808\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417203; batch adversarial loss: 0.518884\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392969; batch adversarial loss: 0.635398\n",
      "epoch 115; iter: 0; batch classifier loss: 0.415494; batch adversarial loss: 0.481970\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394670; batch adversarial loss: 0.599862\n",
      "epoch 117; iter: 0; batch classifier loss: 0.413526; batch adversarial loss: 0.498854\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382292; batch adversarial loss: 0.599098\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382015; batch adversarial loss: 0.490256\n",
      "epoch 120; iter: 0; batch classifier loss: 0.403717; batch adversarial loss: 0.525931\n",
      "epoch 121; iter: 0; batch classifier loss: 0.308822; batch adversarial loss: 0.563164\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397393; batch adversarial loss: 0.553723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.353775; batch adversarial loss: 0.671603\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397887; batch adversarial loss: 0.617241\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398144; batch adversarial loss: 0.572854\n",
      "epoch 126; iter: 0; batch classifier loss: 0.395455; batch adversarial loss: 0.480655\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410035; batch adversarial loss: 0.545722\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396781; batch adversarial loss: 0.544749\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434937; batch adversarial loss: 0.516846\n",
      "epoch 130; iter: 0; batch classifier loss: 0.420972; batch adversarial loss: 0.554480\n",
      "epoch 131; iter: 0; batch classifier loss: 0.333790; batch adversarial loss: 0.470340\n",
      "epoch 132; iter: 0; batch classifier loss: 0.412657; batch adversarial loss: 0.590313\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350909; batch adversarial loss: 0.534601\n",
      "epoch 134; iter: 0; batch classifier loss: 0.314052; batch adversarial loss: 0.544555\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389549; batch adversarial loss: 0.489990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410872; batch adversarial loss: 0.636734\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323981; batch adversarial loss: 0.526073\n",
      "epoch 138; iter: 0; batch classifier loss: 0.447236; batch adversarial loss: 0.581928\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355174; batch adversarial loss: 0.481097\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403783; batch adversarial loss: 0.571692\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420301; batch adversarial loss: 0.535029\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390348; batch adversarial loss: 0.571779\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379856; batch adversarial loss: 0.517427\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365504; batch adversarial loss: 0.562257\n",
      "epoch 145; iter: 0; batch classifier loss: 0.410460; batch adversarial loss: 0.580943\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376541; batch adversarial loss: 0.608605\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364638; batch adversarial loss: 0.617711\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397568; batch adversarial loss: 0.526313\n",
      "epoch 149; iter: 0; batch classifier loss: 0.280710; batch adversarial loss: 0.543942\n",
      "epoch 150; iter: 0; batch classifier loss: 0.335073; batch adversarial loss: 0.635417\n",
      "epoch 151; iter: 0; batch classifier loss: 0.328526; batch adversarial loss: 0.434516\n",
      "epoch 152; iter: 0; batch classifier loss: 0.448145; batch adversarial loss: 0.534495\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368212; batch adversarial loss: 0.480710\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350189; batch adversarial loss: 0.553069\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383828; batch adversarial loss: 0.517467\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358381; batch adversarial loss: 0.535413\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328726; batch adversarial loss: 0.582066\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339354; batch adversarial loss: 0.543503\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372068; batch adversarial loss: 0.571199\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363716; batch adversarial loss: 0.488738\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336530; batch adversarial loss: 0.450818\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306498; batch adversarial loss: 0.478284\n",
      "epoch 163; iter: 0; batch classifier loss: 0.415229; batch adversarial loss: 0.535913\n",
      "epoch 164; iter: 0; batch classifier loss: 0.349295; batch adversarial loss: 0.516773\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343511; batch adversarial loss: 0.517376\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406778; batch adversarial loss: 0.534977\n",
      "epoch 167; iter: 0; batch classifier loss: 0.405294; batch adversarial loss: 0.553722\n",
      "epoch 168; iter: 0; batch classifier loss: 0.360072; batch adversarial loss: 0.608607\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304789; batch adversarial loss: 0.644327\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324862; batch adversarial loss: 0.535426\n",
      "epoch 171; iter: 0; batch classifier loss: 0.368300; batch adversarial loss: 0.571836\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358789; batch adversarial loss: 0.562876\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359183; batch adversarial loss: 0.535063\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302457; batch adversarial loss: 0.489434\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390405; batch adversarial loss: 0.443832\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297983; batch adversarial loss: 0.544347\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376819; batch adversarial loss: 0.498120\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345534; batch adversarial loss: 0.562900\n",
      "epoch 179; iter: 0; batch classifier loss: 0.401943; batch adversarial loss: 0.571971\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360167; batch adversarial loss: 0.626707\n",
      "epoch 181; iter: 0; batch classifier loss: 0.427942; batch adversarial loss: 0.526424\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314758; batch adversarial loss: 0.535804\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313496; batch adversarial loss: 0.571778\n",
      "epoch 184; iter: 0; batch classifier loss: 0.345241; batch adversarial loss: 0.572316\n",
      "epoch 185; iter: 0; batch classifier loss: 0.440486; batch adversarial loss: 0.562039\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356226; batch adversarial loss: 0.545423\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345107; batch adversarial loss: 0.507903\n",
      "epoch 188; iter: 0; batch classifier loss: 0.322180; batch adversarial loss: 0.470645\n",
      "epoch 189; iter: 0; batch classifier loss: 0.312605; batch adversarial loss: 0.489573\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312198; batch adversarial loss: 0.617429\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335221; batch adversarial loss: 0.553019\n",
      "epoch 192; iter: 0; batch classifier loss: 0.331040; batch adversarial loss: 0.536371\n",
      "epoch 193; iter: 0; batch classifier loss: 0.297668; batch adversarial loss: 0.534832\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356381; batch adversarial loss: 0.516913\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310639; batch adversarial loss: 0.580142\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386301; batch adversarial loss: 0.570854\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350983; batch adversarial loss: 0.581961\n",
      "epoch 198; iter: 0; batch classifier loss: 0.451418; batch adversarial loss: 0.554010\n",
      "epoch 199; iter: 0; batch classifier loss: 0.473413; batch adversarial loss: 0.572447\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713523; batch adversarial loss: 0.581144\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610188; batch adversarial loss: 0.689539\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562269; batch adversarial loss: 0.595962\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624583; batch adversarial loss: 0.678717\n",
      "epoch 4; iter: 0; batch classifier loss: 0.484941; batch adversarial loss: 0.651753\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573889; batch adversarial loss: 0.592325\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593314; batch adversarial loss: 0.635426\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529914; batch adversarial loss: 0.615095\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566911; batch adversarial loss: 0.613125\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540534; batch adversarial loss: 0.573722\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546380; batch adversarial loss: 0.530613\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505793; batch adversarial loss: 0.603352\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562440; batch adversarial loss: 0.562495\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537043; batch adversarial loss: 0.621656\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472310; batch adversarial loss: 0.521892\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529537; batch adversarial loss: 0.569515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552938; batch adversarial loss: 0.546377\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491027; batch adversarial loss: 0.576974\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524609; batch adversarial loss: 0.525383\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519164; batch adversarial loss: 0.582649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.463150; batch adversarial loss: 0.568042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490872; batch adversarial loss: 0.528102\n",
      "epoch 22; iter: 0; batch classifier loss: 0.543898; batch adversarial loss: 0.581332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500899; batch adversarial loss: 0.644722\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495736; batch adversarial loss: 0.585337\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520185; batch adversarial loss: 0.529603\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494423; batch adversarial loss: 0.528014\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513323; batch adversarial loss: 0.549666\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496193; batch adversarial loss: 0.526965\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489569; batch adversarial loss: 0.610196\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489096; batch adversarial loss: 0.585521\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479084; batch adversarial loss: 0.501768\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417289; batch adversarial loss: 0.552949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409259; batch adversarial loss: 0.592045\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404224; batch adversarial loss: 0.448048\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464259; batch adversarial loss: 0.562342\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460546; batch adversarial loss: 0.557095\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406213; batch adversarial loss: 0.535315\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462601; batch adversarial loss: 0.509131\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461790; batch adversarial loss: 0.590821\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416498; batch adversarial loss: 0.605217\n",
      "epoch 41; iter: 0; batch classifier loss: 0.508824; batch adversarial loss: 0.535463\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469454; batch adversarial loss: 0.501756\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445757; batch adversarial loss: 0.501854\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456590; batch adversarial loss: 0.543333\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418129; batch adversarial loss: 0.555311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.354858; batch adversarial loss: 0.553768\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404060; batch adversarial loss: 0.670745\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453039; batch adversarial loss: 0.593952\n",
      "epoch 49; iter: 0; batch classifier loss: 0.459881; batch adversarial loss: 0.693881\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414953; batch adversarial loss: 0.584371\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444168; batch adversarial loss: 0.588053\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401991; batch adversarial loss: 0.527810\n",
      "epoch 53; iter: 0; batch classifier loss: 0.419774; batch adversarial loss: 0.496737\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438195; batch adversarial loss: 0.549488\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441319; batch adversarial loss: 0.540430\n",
      "epoch 56; iter: 0; batch classifier loss: 0.471992; batch adversarial loss: 0.563831\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386101; batch adversarial loss: 0.570311\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431199; batch adversarial loss: 0.595985\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432475; batch adversarial loss: 0.579772\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426362; batch adversarial loss: 0.535748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376740; batch adversarial loss: 0.623711\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427799; batch adversarial loss: 0.501257\n",
      "epoch 63; iter: 0; batch classifier loss: 0.464384; batch adversarial loss: 0.500783\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406161; batch adversarial loss: 0.482769\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383412; batch adversarial loss: 0.606609\n",
      "epoch 66; iter: 0; batch classifier loss: 0.360641; batch adversarial loss: 0.536780\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395051; batch adversarial loss: 0.518000\n",
      "epoch 68; iter: 0; batch classifier loss: 0.473216; batch adversarial loss: 0.544914\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358066; batch adversarial loss: 0.508981\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364756; batch adversarial loss: 0.509215\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435206; batch adversarial loss: 0.544365\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448335; batch adversarial loss: 0.553226\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410382; batch adversarial loss: 0.501118\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418188; batch adversarial loss: 0.642010\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409215; batch adversarial loss: 0.562685\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399151; batch adversarial loss: 0.588320\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374253; batch adversarial loss: 0.624939\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355255; batch adversarial loss: 0.562439\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417429; batch adversarial loss: 0.563488\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455295; batch adversarial loss: 0.597651\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400263; batch adversarial loss: 0.455164\n",
      "epoch 82; iter: 0; batch classifier loss: 0.442893; batch adversarial loss: 0.473112\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443231; batch adversarial loss: 0.597150\n",
      "epoch 84; iter: 0; batch classifier loss: 0.359780; batch adversarial loss: 0.491444\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396359; batch adversarial loss: 0.597536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427951; batch adversarial loss: 0.606831\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374272; batch adversarial loss: 0.624709\n",
      "epoch 88; iter: 0; batch classifier loss: 0.450430; batch adversarial loss: 0.634068\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387085; batch adversarial loss: 0.589177\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417614; batch adversarial loss: 0.527714\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393354; batch adversarial loss: 0.464753\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404020; batch adversarial loss: 0.561480\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380932; batch adversarial loss: 0.544244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358677; batch adversarial loss: 0.615386\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344552; batch adversarial loss: 0.597720\n",
      "epoch 96; iter: 0; batch classifier loss: 0.421289; batch adversarial loss: 0.598603\n",
      "epoch 97; iter: 0; batch classifier loss: 0.321245; batch adversarial loss: 0.562253\n",
      "epoch 98; iter: 0; batch classifier loss: 0.355498; batch adversarial loss: 0.518611\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412553; batch adversarial loss: 0.507381\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402718; batch adversarial loss: 0.526940\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360592; batch adversarial loss: 0.598090\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369443; batch adversarial loss: 0.544827\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412219; batch adversarial loss: 0.544586\n",
      "epoch 104; iter: 0; batch classifier loss: 0.448994; batch adversarial loss: 0.518180\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418336; batch adversarial loss: 0.588994\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402767; batch adversarial loss: 0.615704\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447866; batch adversarial loss: 0.552928\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354831; batch adversarial loss: 0.526267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367400; batch adversarial loss: 0.518007\n",
      "epoch 110; iter: 0; batch classifier loss: 0.450738; batch adversarial loss: 0.570907\n",
      "epoch 111; iter: 0; batch classifier loss: 0.459980; batch adversarial loss: 0.544499\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354067; batch adversarial loss: 0.624851\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415218; batch adversarial loss: 0.580957\n",
      "epoch 114; iter: 0; batch classifier loss: 0.444053; batch adversarial loss: 0.643475\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445013; batch adversarial loss: 0.553446\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357804; batch adversarial loss: 0.553080\n",
      "epoch 117; iter: 0; batch classifier loss: 0.434915; batch adversarial loss: 0.518438\n",
      "epoch 118; iter: 0; batch classifier loss: 0.416719; batch adversarial loss: 0.606221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.324698; batch adversarial loss: 0.544876\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378414; batch adversarial loss: 0.598429\n",
      "epoch 121; iter: 0; batch classifier loss: 0.293198; batch adversarial loss: 0.581075\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384928; batch adversarial loss: 0.642063\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367634; batch adversarial loss: 0.615562\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348142; batch adversarial loss: 0.571530\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369543; batch adversarial loss: 0.588176\n",
      "epoch 126; iter: 0; batch classifier loss: 0.312291; batch adversarial loss: 0.580970\n",
      "epoch 127; iter: 0; batch classifier loss: 0.371162; batch adversarial loss: 0.544017\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330226; batch adversarial loss: 0.544185\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402910; batch adversarial loss: 0.536563\n",
      "epoch 130; iter: 0; batch classifier loss: 0.397683; batch adversarial loss: 0.455308\n",
      "epoch 131; iter: 0; batch classifier loss: 0.289776; batch adversarial loss: 0.482900\n",
      "epoch 132; iter: 0; batch classifier loss: 0.437564; batch adversarial loss: 0.526892\n",
      "epoch 133; iter: 0; batch classifier loss: 0.423223; batch adversarial loss: 0.508248\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343250; batch adversarial loss: 0.554043\n",
      "epoch 135; iter: 0; batch classifier loss: 0.329985; batch adversarial loss: 0.553599\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332193; batch adversarial loss: 0.536233\n",
      "epoch 137; iter: 0; batch classifier loss: 0.387630; batch adversarial loss: 0.544075\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362687; batch adversarial loss: 0.526316\n",
      "epoch 139; iter: 0; batch classifier loss: 0.322345; batch adversarial loss: 0.552852\n",
      "epoch 140; iter: 0; batch classifier loss: 0.412884; batch adversarial loss: 0.552903\n",
      "epoch 141; iter: 0; batch classifier loss: 0.407163; batch adversarial loss: 0.456174\n",
      "epoch 142; iter: 0; batch classifier loss: 0.437967; batch adversarial loss: 0.543969\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405511; batch adversarial loss: 0.588525\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389888; batch adversarial loss: 0.579783\n",
      "epoch 145; iter: 0; batch classifier loss: 0.299760; batch adversarial loss: 0.588079\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375323; batch adversarial loss: 0.544069\n",
      "epoch 147; iter: 0; batch classifier loss: 0.314555; batch adversarial loss: 0.580000\n",
      "epoch 148; iter: 0; batch classifier loss: 0.394177; batch adversarial loss: 0.588985\n",
      "epoch 149; iter: 0; batch classifier loss: 0.364255; batch adversarial loss: 0.553251\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396575; batch adversarial loss: 0.552933\n",
      "epoch 151; iter: 0; batch classifier loss: 0.416913; batch adversarial loss: 0.607131\n",
      "epoch 152; iter: 0; batch classifier loss: 0.435740; batch adversarial loss: 0.510109\n",
      "epoch 153; iter: 0; batch classifier loss: 0.387748; batch adversarial loss: 0.492772\n",
      "epoch 154; iter: 0; batch classifier loss: 0.299556; batch adversarial loss: 0.571390\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387396; batch adversarial loss: 0.571446\n",
      "epoch 156; iter: 0; batch classifier loss: 0.400255; batch adversarial loss: 0.536199\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399353; batch adversarial loss: 0.553579\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373480; batch adversarial loss: 0.499722\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391499; batch adversarial loss: 0.588544\n",
      "epoch 160; iter: 0; batch classifier loss: 0.487031; batch adversarial loss: 0.606117\n",
      "epoch 161; iter: 0; batch classifier loss: 0.300947; batch adversarial loss: 0.500520\n",
      "epoch 162; iter: 0; batch classifier loss: 0.297173; batch adversarial loss: 0.651205\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373990; batch adversarial loss: 0.625431\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410823; batch adversarial loss: 0.607764\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319674; batch adversarial loss: 0.553822\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378133; batch adversarial loss: 0.581248\n",
      "epoch 167; iter: 0; batch classifier loss: 0.442167; batch adversarial loss: 0.544727\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342034; batch adversarial loss: 0.509642\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375246; batch adversarial loss: 0.597997\n",
      "epoch 170; iter: 0; batch classifier loss: 0.311531; batch adversarial loss: 0.527171\n",
      "epoch 171; iter: 0; batch classifier loss: 0.354098; batch adversarial loss: 0.481132\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384564; batch adversarial loss: 0.491381\n",
      "epoch 173; iter: 0; batch classifier loss: 0.299745; batch adversarial loss: 0.571226\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326647; batch adversarial loss: 0.544706\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364131; batch adversarial loss: 0.562769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.409697; batch adversarial loss: 0.571392\n",
      "epoch 177; iter: 0; batch classifier loss: 0.317676; batch adversarial loss: 0.535916\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389928; batch adversarial loss: 0.562728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351018; batch adversarial loss: 0.482869\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340360; batch adversarial loss: 0.526570\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397915; batch adversarial loss: 0.527014\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355444; batch adversarial loss: 0.625010\n",
      "epoch 183; iter: 0; batch classifier loss: 0.426884; batch adversarial loss: 0.536060\n",
      "epoch 184; iter: 0; batch classifier loss: 0.333268; batch adversarial loss: 0.616043\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321971; batch adversarial loss: 0.552783\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361703; batch adversarial loss: 0.518084\n",
      "epoch 187; iter: 0; batch classifier loss: 0.366656; batch adversarial loss: 0.589032\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379044; batch adversarial loss: 0.651558\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344313; batch adversarial loss: 0.571594\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380061; batch adversarial loss: 0.501363\n",
      "epoch 191; iter: 0; batch classifier loss: 0.332729; batch adversarial loss: 0.650846\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364448; batch adversarial loss: 0.536930\n",
      "epoch 193; iter: 0; batch classifier loss: 0.385990; batch adversarial loss: 0.536065\n",
      "epoch 194; iter: 0; batch classifier loss: 0.425694; batch adversarial loss: 0.507625\n",
      "epoch 195; iter: 0; batch classifier loss: 0.378598; batch adversarial loss: 0.579175\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378894; batch adversarial loss: 0.501042\n",
      "epoch 197; iter: 0; batch classifier loss: 0.440099; batch adversarial loss: 0.561718\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347997; batch adversarial loss: 0.579887\n",
      "epoch 199; iter: 0; batch classifier loss: 0.313715; batch adversarial loss: 0.553823\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711423; batch adversarial loss: 0.966763\n",
      "epoch 1; iter: 0; batch classifier loss: 0.818799; batch adversarial loss: 0.980649\n",
      "epoch 2; iter: 0; batch classifier loss: 0.824692; batch adversarial loss: 0.914109\n",
      "epoch 3; iter: 0; batch classifier loss: 0.966904; batch adversarial loss: 0.880552\n",
      "epoch 4; iter: 0; batch classifier loss: 0.860892; batch adversarial loss: 0.804507\n",
      "epoch 5; iter: 0; batch classifier loss: 0.864807; batch adversarial loss: 0.776275\n",
      "epoch 6; iter: 0; batch classifier loss: 0.664053; batch adversarial loss: 0.670481\n",
      "epoch 7; iter: 0; batch classifier loss: 0.647460; batch adversarial loss: 0.658293\n",
      "epoch 8; iter: 0; batch classifier loss: 0.584727; batch adversarial loss: 0.626366\n",
      "epoch 9; iter: 0; batch classifier loss: 0.583986; batch adversarial loss: 0.561192\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589550; batch adversarial loss: 0.640206\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494896; batch adversarial loss: 0.576770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517588; batch adversarial loss: 0.590179\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580379; batch adversarial loss: 0.576674\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514479; batch adversarial loss: 0.611645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.524310; batch adversarial loss: 0.572734\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554967; batch adversarial loss: 0.646323\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477907; batch adversarial loss: 0.582089\n",
      "epoch 18; iter: 0; batch classifier loss: 0.564238; batch adversarial loss: 0.524913\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527678; batch adversarial loss: 0.593229\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482617; batch adversarial loss: 0.573816\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525351; batch adversarial loss: 0.632720\n",
      "epoch 22; iter: 0; batch classifier loss: 0.553544; batch adversarial loss: 0.530059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511962; batch adversarial loss: 0.630033\n",
      "epoch 24; iter: 0; batch classifier loss: 0.414410; batch adversarial loss: 0.595391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494235; batch adversarial loss: 0.570118\n",
      "epoch 26; iter: 0; batch classifier loss: 0.429265; batch adversarial loss: 0.580344\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483461; batch adversarial loss: 0.492429\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459571; batch adversarial loss: 0.646358\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485561; batch adversarial loss: 0.569762\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461637; batch adversarial loss: 0.654471\n",
      "epoch 31; iter: 0; batch classifier loss: 0.424609; batch adversarial loss: 0.579118\n",
      "epoch 32; iter: 0; batch classifier loss: 0.412465; batch adversarial loss: 0.587656\n",
      "epoch 33; iter: 0; batch classifier loss: 0.499610; batch adversarial loss: 0.571460\n",
      "epoch 34; iter: 0; batch classifier loss: 0.428308; batch adversarial loss: 0.520612\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498716; batch adversarial loss: 0.568925\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406263; batch adversarial loss: 0.526661\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475566; batch adversarial loss: 0.555503\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473356; batch adversarial loss: 0.600533\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493529; batch adversarial loss: 0.627903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462738; batch adversarial loss: 0.544842\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423488; batch adversarial loss: 0.568199\n",
      "epoch 42; iter: 0; batch classifier loss: 0.323950; batch adversarial loss: 0.535096\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397020; batch adversarial loss: 0.569765\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478407; batch adversarial loss: 0.570597\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409571; batch adversarial loss: 0.542041\n",
      "epoch 46; iter: 0; batch classifier loss: 0.358462; batch adversarial loss: 0.506734\n",
      "epoch 47; iter: 0; batch classifier loss: 0.413281; batch adversarial loss: 0.566044\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397617; batch adversarial loss: 0.521649\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466252; batch adversarial loss: 0.531315\n",
      "epoch 50; iter: 0; batch classifier loss: 0.447954; batch adversarial loss: 0.551412\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404887; batch adversarial loss: 0.530175\n",
      "epoch 52; iter: 0; batch classifier loss: 0.354209; batch adversarial loss: 0.538732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464083; batch adversarial loss: 0.528979\n",
      "epoch 54; iter: 0; batch classifier loss: 0.506385; batch adversarial loss: 0.564172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434720; batch adversarial loss: 0.552377\n",
      "epoch 56; iter: 0; batch classifier loss: 0.475371; batch adversarial loss: 0.482354\n",
      "epoch 57; iter: 0; batch classifier loss: 0.394715; batch adversarial loss: 0.511813\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436052; batch adversarial loss: 0.633484\n",
      "epoch 59; iter: 0; batch classifier loss: 0.344244; batch adversarial loss: 0.581435\n",
      "epoch 60; iter: 0; batch classifier loss: 0.415388; batch adversarial loss: 0.455767\n",
      "epoch 61; iter: 0; batch classifier loss: 0.449493; batch adversarial loss: 0.467544\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407023; batch adversarial loss: 0.578682\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370532; batch adversarial loss: 0.589863\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358550; batch adversarial loss: 0.528663\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400445; batch adversarial loss: 0.561372\n",
      "epoch 66; iter: 0; batch classifier loss: 0.461037; batch adversarial loss: 0.544358\n",
      "epoch 67; iter: 0; batch classifier loss: 0.349901; batch adversarial loss: 0.560034\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390463; batch adversarial loss: 0.569862\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430213; batch adversarial loss: 0.589739\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393870; batch adversarial loss: 0.568840\n",
      "epoch 71; iter: 0; batch classifier loss: 0.469535; batch adversarial loss: 0.643896\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399523; batch adversarial loss: 0.511392\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445155; batch adversarial loss: 0.589634\n",
      "epoch 74; iter: 0; batch classifier loss: 0.366860; batch adversarial loss: 0.538367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.307241; batch adversarial loss: 0.491691\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430751; batch adversarial loss: 0.546287\n",
      "epoch 77; iter: 0; batch classifier loss: 0.356948; batch adversarial loss: 0.580156\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378108; batch adversarial loss: 0.510198\n",
      "epoch 79; iter: 0; batch classifier loss: 0.364697; batch adversarial loss: 0.598184\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403221; batch adversarial loss: 0.570930\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419241; batch adversarial loss: 0.544995\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385952; batch adversarial loss: 0.554830\n",
      "epoch 83; iter: 0; batch classifier loss: 0.327817; batch adversarial loss: 0.588427\n",
      "epoch 84; iter: 0; batch classifier loss: 0.337634; batch adversarial loss: 0.537462\n",
      "epoch 85; iter: 0; batch classifier loss: 0.372543; batch adversarial loss: 0.605883\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365328; batch adversarial loss: 0.563391\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385360; batch adversarial loss: 0.553756\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360930; batch adversarial loss: 0.588721\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428921; batch adversarial loss: 0.554535\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400514; batch adversarial loss: 0.588305\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372258; batch adversarial loss: 0.509222\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398499; batch adversarial loss: 0.615183\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437057; batch adversarial loss: 0.634200\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377356; batch adversarial loss: 0.524305\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352146; batch adversarial loss: 0.535727\n",
      "epoch 96; iter: 0; batch classifier loss: 0.452062; batch adversarial loss: 0.535542\n",
      "epoch 97; iter: 0; batch classifier loss: 0.345656; batch adversarial loss: 0.616392\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382365; batch adversarial loss: 0.492042\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342630; batch adversarial loss: 0.578704\n",
      "epoch 100; iter: 0; batch classifier loss: 0.305619; batch adversarial loss: 0.527399\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402394; batch adversarial loss: 0.678940\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371356; batch adversarial loss: 0.643719\n",
      "epoch 103; iter: 0; batch classifier loss: 0.443735; batch adversarial loss: 0.545349\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423276; batch adversarial loss: 0.633561\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398978; batch adversarial loss: 0.553168\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390904; batch adversarial loss: 0.553343\n",
      "epoch 107; iter: 0; batch classifier loss: 0.423222; batch adversarial loss: 0.482699\n",
      "epoch 108; iter: 0; batch classifier loss: 0.308498; batch adversarial loss: 0.571537\n",
      "epoch 109; iter: 0; batch classifier loss: 0.411936; batch adversarial loss: 0.651088\n",
      "epoch 110; iter: 0; batch classifier loss: 0.329784; batch adversarial loss: 0.624419\n",
      "epoch 111; iter: 0; batch classifier loss: 0.342978; batch adversarial loss: 0.606225\n",
      "epoch 112; iter: 0; batch classifier loss: 0.348284; batch adversarial loss: 0.578736\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351768; batch adversarial loss: 0.490994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.332576; batch adversarial loss: 0.580408\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445825; batch adversarial loss: 0.518041\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323230; batch adversarial loss: 0.525026\n",
      "epoch 117; iter: 0; batch classifier loss: 0.349310; batch adversarial loss: 0.562599\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382545; batch adversarial loss: 0.490662\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377727; batch adversarial loss: 0.687354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.350001; batch adversarial loss: 0.581743\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319379; batch adversarial loss: 0.535620\n",
      "epoch 122; iter: 0; batch classifier loss: 0.324449; batch adversarial loss: 0.517498\n",
      "epoch 123; iter: 0; batch classifier loss: 0.435401; batch adversarial loss: 0.437829\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348960; batch adversarial loss: 0.571882\n",
      "epoch 125; iter: 0; batch classifier loss: 0.417268; batch adversarial loss: 0.588510\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316223; batch adversarial loss: 0.581232\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345517; batch adversarial loss: 0.508518\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329773; batch adversarial loss: 0.500258\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369718; batch adversarial loss: 0.621874\n",
      "epoch 130; iter: 0; batch classifier loss: 0.323772; batch adversarial loss: 0.607700\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438594; batch adversarial loss: 0.409884\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327446; batch adversarial loss: 0.516923\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357377; batch adversarial loss: 0.579719\n",
      "epoch 134; iter: 0; batch classifier loss: 0.276618; batch adversarial loss: 0.537134\n",
      "epoch 135; iter: 0; batch classifier loss: 0.401713; batch adversarial loss: 0.492665\n",
      "epoch 136; iter: 0; batch classifier loss: 0.362923; batch adversarial loss: 0.607795\n",
      "epoch 137; iter: 0; batch classifier loss: 0.439482; batch adversarial loss: 0.535271\n",
      "epoch 138; iter: 0; batch classifier loss: 0.378380; batch adversarial loss: 0.525548\n",
      "epoch 139; iter: 0; batch classifier loss: 0.363853; batch adversarial loss: 0.527024\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355215; batch adversarial loss: 0.483944\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376730; batch adversarial loss: 0.607135\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338990; batch adversarial loss: 0.649395\n",
      "epoch 143; iter: 0; batch classifier loss: 0.335041; batch adversarial loss: 0.499752\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389590; batch adversarial loss: 0.546578\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339100; batch adversarial loss: 0.499812\n",
      "epoch 146; iter: 0; batch classifier loss: 0.434635; batch adversarial loss: 0.580558\n",
      "epoch 147; iter: 0; batch classifier loss: 0.285553; batch adversarial loss: 0.561884\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323113; batch adversarial loss: 0.526698\n",
      "epoch 149; iter: 0; batch classifier loss: 0.330242; batch adversarial loss: 0.571452\n",
      "epoch 150; iter: 0; batch classifier loss: 0.303948; batch adversarial loss: 0.561870\n",
      "epoch 151; iter: 0; batch classifier loss: 0.333168; batch adversarial loss: 0.590250\n",
      "epoch 152; iter: 0; batch classifier loss: 0.292400; batch adversarial loss: 0.589322\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371724; batch adversarial loss: 0.543915\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356158; batch adversarial loss: 0.644488\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413214; batch adversarial loss: 0.581212\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355589; batch adversarial loss: 0.563606\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327177; batch adversarial loss: 0.500497\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388196; batch adversarial loss: 0.553788\n",
      "epoch 159; iter: 0; batch classifier loss: 0.342182; batch adversarial loss: 0.526782\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378479; batch adversarial loss: 0.517930\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368200; batch adversarial loss: 0.553431\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392264; batch adversarial loss: 0.617417\n",
      "epoch 163; iter: 0; batch classifier loss: 0.308769; batch adversarial loss: 0.607746\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352507; batch adversarial loss: 0.580952\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329159; batch adversarial loss: 0.580084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.300510; batch adversarial loss: 0.464378\n",
      "epoch 167; iter: 0; batch classifier loss: 0.282733; batch adversarial loss: 0.526673\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326129; batch adversarial loss: 0.545480\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384138; batch adversarial loss: 0.500662\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409488; batch adversarial loss: 0.562611\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333771; batch adversarial loss: 0.500361\n",
      "epoch 172; iter: 0; batch classifier loss: 0.417365; batch adversarial loss: 0.519118\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354843; batch adversarial loss: 0.589374\n",
      "epoch 174; iter: 0; batch classifier loss: 0.346031; batch adversarial loss: 0.553669\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298273; batch adversarial loss: 0.580648\n",
      "epoch 176; iter: 0; batch classifier loss: 0.357094; batch adversarial loss: 0.553070\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306139; batch adversarial loss: 0.589563\n",
      "epoch 178; iter: 0; batch classifier loss: 0.300661; batch adversarial loss: 0.484067\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355203; batch adversarial loss: 0.579632\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337353; batch adversarial loss: 0.526903\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315201; batch adversarial loss: 0.580134\n",
      "epoch 182; iter: 0; batch classifier loss: 0.360477; batch adversarial loss: 0.535539\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342405; batch adversarial loss: 0.500318\n",
      "epoch 184; iter: 0; batch classifier loss: 0.307898; batch adversarial loss: 0.589232\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313980; batch adversarial loss: 0.517749\n",
      "epoch 186; iter: 0; batch classifier loss: 0.319276; batch adversarial loss: 0.517276\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357492; batch adversarial loss: 0.492540\n",
      "epoch 188; iter: 0; batch classifier loss: 0.342887; batch adversarial loss: 0.563267\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371279; batch adversarial loss: 0.544912\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307586; batch adversarial loss: 0.580013\n",
      "epoch 191; iter: 0; batch classifier loss: 0.269134; batch adversarial loss: 0.545642\n",
      "epoch 192; iter: 0; batch classifier loss: 0.291939; batch adversarial loss: 0.527249\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376653; batch adversarial loss: 0.643246\n",
      "epoch 194; iter: 0; batch classifier loss: 0.294416; batch adversarial loss: 0.587933\n",
      "epoch 195; iter: 0; batch classifier loss: 0.299959; batch adversarial loss: 0.616801\n",
      "epoch 196; iter: 0; batch classifier loss: 0.319236; batch adversarial loss: 0.607220\n",
      "epoch 197; iter: 0; batch classifier loss: 0.447335; batch adversarial loss: 0.535109\n",
      "epoch 198; iter: 0; batch classifier loss: 0.327976; batch adversarial loss: 0.535882\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316537; batch adversarial loss: 0.562720\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681089; batch adversarial loss: 0.703332\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630267; batch adversarial loss: 0.684684\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544052; batch adversarial loss: 0.647534\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531432; batch adversarial loss: 0.635716\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559075; batch adversarial loss: 0.584741\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522518; batch adversarial loss: 0.576763\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521674; batch adversarial loss: 0.594537\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523770; batch adversarial loss: 0.585996\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479217; batch adversarial loss: 0.564333\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520120; batch adversarial loss: 0.591969\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573848; batch adversarial loss: 0.609612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.482200; batch adversarial loss: 0.595691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548225; batch adversarial loss: 0.569625\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528378; batch adversarial loss: 0.606532\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524355; batch adversarial loss: 0.575861\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469830; batch adversarial loss: 0.619230\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498565; batch adversarial loss: 0.610928\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528407; batch adversarial loss: 0.548107\n",
      "epoch 18; iter: 0; batch classifier loss: 0.566818; batch adversarial loss: 0.538285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443743; batch adversarial loss: 0.585986\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446522; batch adversarial loss: 0.546974\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545392; batch adversarial loss: 0.558117\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487255; batch adversarial loss: 0.495574\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454995; batch adversarial loss: 0.560976\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467025; batch adversarial loss: 0.508715\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523872; batch adversarial loss: 0.573172\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455271; batch adversarial loss: 0.573185\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521795; batch adversarial loss: 0.540501\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450328; batch adversarial loss: 0.555420\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445021; batch adversarial loss: 0.570729\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486261; batch adversarial loss: 0.537702\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477926; batch adversarial loss: 0.528234\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477214; batch adversarial loss: 0.534995\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480489; batch adversarial loss: 0.561115\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456406; batch adversarial loss: 0.460752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.579357; batch adversarial loss: 0.576991\n",
      "epoch 36; iter: 0; batch classifier loss: 0.530716; batch adversarial loss: 0.619933\n",
      "epoch 37; iter: 0; batch classifier loss: 0.513159; batch adversarial loss: 0.543173\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435451; batch adversarial loss: 0.490510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418158; batch adversarial loss: 0.515654\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493830; batch adversarial loss: 0.553070\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403098; batch adversarial loss: 0.472742\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466865; batch adversarial loss: 0.607967\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410837; batch adversarial loss: 0.582812\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443583; batch adversarial loss: 0.527476\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415562; batch adversarial loss: 0.508660\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462549; batch adversarial loss: 0.498031\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419616; batch adversarial loss: 0.497607\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399836; batch adversarial loss: 0.498331\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468216; batch adversarial loss: 0.636537\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403135; batch adversarial loss: 0.489733\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426640; batch adversarial loss: 0.569867\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413639; batch adversarial loss: 0.553892\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403684; batch adversarial loss: 0.578397\n",
      "epoch 54; iter: 0; batch classifier loss: 0.407931; batch adversarial loss: 0.544844\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462363; batch adversarial loss: 0.498853\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473812; batch adversarial loss: 0.590372\n",
      "epoch 57; iter: 0; batch classifier loss: 0.476552; batch adversarial loss: 0.534184\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427702; batch adversarial loss: 0.469394\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399455; batch adversarial loss: 0.521985\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374003; batch adversarial loss: 0.618714\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376131; batch adversarial loss: 0.574098\n",
      "epoch 62; iter: 0; batch classifier loss: 0.320840; batch adversarial loss: 0.507837\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430577; batch adversarial loss: 0.535593\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421762; batch adversarial loss: 0.527385\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398394; batch adversarial loss: 0.572548\n",
      "epoch 66; iter: 0; batch classifier loss: 0.500122; batch adversarial loss: 0.488968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377639; batch adversarial loss: 0.618678\n",
      "epoch 68; iter: 0; batch classifier loss: 0.361245; batch adversarial loss: 0.534770\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396509; batch adversarial loss: 0.554763\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424804; batch adversarial loss: 0.553226\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392331; batch adversarial loss: 0.508021\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442030; batch adversarial loss: 0.582016\n",
      "epoch 73; iter: 0; batch classifier loss: 0.434307; batch adversarial loss: 0.544387\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436863; batch adversarial loss: 0.425532\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421738; batch adversarial loss: 0.518176\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383422; batch adversarial loss: 0.571316\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375279; batch adversarial loss: 0.535401\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405658; batch adversarial loss: 0.516187\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413825; batch adversarial loss: 0.609744\n",
      "epoch 80; iter: 0; batch classifier loss: 0.487098; batch adversarial loss: 0.507284\n",
      "epoch 81; iter: 0; batch classifier loss: 0.315042; batch adversarial loss: 0.442739\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382422; batch adversarial loss: 0.535379\n",
      "epoch 83; iter: 0; batch classifier loss: 0.433490; batch adversarial loss: 0.535525\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362596; batch adversarial loss: 0.516678\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382231; batch adversarial loss: 0.526581\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397384; batch adversarial loss: 0.544106\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363990; batch adversarial loss: 0.572406\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425438; batch adversarial loss: 0.645444\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363137; batch adversarial loss: 0.554362\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399338; batch adversarial loss: 0.544449\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362162; batch adversarial loss: 0.516780\n",
      "epoch 92; iter: 0; batch classifier loss: 0.315202; batch adversarial loss: 0.581141\n",
      "epoch 93; iter: 0; batch classifier loss: 0.314481; batch adversarial loss: 0.535028\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366346; batch adversarial loss: 0.470376\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408428; batch adversarial loss: 0.553946\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419287; batch adversarial loss: 0.480353\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359170; batch adversarial loss: 0.498763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.352236; batch adversarial loss: 0.563625\n",
      "epoch 99; iter: 0; batch classifier loss: 0.427278; batch adversarial loss: 0.544910\n",
      "epoch 100; iter: 0; batch classifier loss: 0.426606; batch adversarial loss: 0.525981\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363569; batch adversarial loss: 0.581496\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369815; batch adversarial loss: 0.562766\n",
      "epoch 103; iter: 0; batch classifier loss: 0.430626; batch adversarial loss: 0.600059\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400676; batch adversarial loss: 0.471283\n",
      "epoch 105; iter: 0; batch classifier loss: 0.419546; batch adversarial loss: 0.599476\n",
      "epoch 106; iter: 0; batch classifier loss: 0.446374; batch adversarial loss: 0.627228\n",
      "epoch 107; iter: 0; batch classifier loss: 0.464704; batch adversarial loss: 0.590473\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366085; batch adversarial loss: 0.507830\n",
      "epoch 109; iter: 0; batch classifier loss: 0.464584; batch adversarial loss: 0.517099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.312796; batch adversarial loss: 0.618210\n",
      "epoch 111; iter: 0; batch classifier loss: 0.421905; batch adversarial loss: 0.608959\n",
      "epoch 112; iter: 0; batch classifier loss: 0.413107; batch adversarial loss: 0.571913\n",
      "epoch 113; iter: 0; batch classifier loss: 0.385447; batch adversarial loss: 0.498470\n",
      "epoch 114; iter: 0; batch classifier loss: 0.474605; batch adversarial loss: 0.599473\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331411; batch adversarial loss: 0.599640\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417473; batch adversarial loss: 0.526170\n",
      "epoch 117; iter: 0; batch classifier loss: 0.334133; batch adversarial loss: 0.562827\n",
      "epoch 118; iter: 0; batch classifier loss: 0.407362; batch adversarial loss: 0.544486\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389713; batch adversarial loss: 0.599756\n",
      "epoch 120; iter: 0; batch classifier loss: 0.405029; batch adversarial loss: 0.489301\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414508; batch adversarial loss: 0.571565\n",
      "epoch 122; iter: 0; batch classifier loss: 0.347336; batch adversarial loss: 0.553615\n",
      "epoch 123; iter: 0; batch classifier loss: 0.420560; batch adversarial loss: 0.544529\n",
      "epoch 124; iter: 0; batch classifier loss: 0.436890; batch adversarial loss: 0.590837\n",
      "epoch 125; iter: 0; batch classifier loss: 0.310996; batch adversarial loss: 0.535635\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385092; batch adversarial loss: 0.526439\n",
      "epoch 127; iter: 0; batch classifier loss: 0.486619; batch adversarial loss: 0.571941\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390909; batch adversarial loss: 0.461702\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399831; batch adversarial loss: 0.562135\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385292; batch adversarial loss: 0.498632\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367902; batch adversarial loss: 0.562181\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396028; batch adversarial loss: 0.462192\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396488; batch adversarial loss: 0.572297\n",
      "epoch 134; iter: 0; batch classifier loss: 0.398121; batch adversarial loss: 0.461592\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354474; batch adversarial loss: 0.507369\n",
      "epoch 136; iter: 0; batch classifier loss: 0.404588; batch adversarial loss: 0.617728\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375871; batch adversarial loss: 0.581247\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338932; batch adversarial loss: 0.572460\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428536; batch adversarial loss: 0.571573\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403528; batch adversarial loss: 0.536036\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377295; batch adversarial loss: 0.488922\n",
      "epoch 142; iter: 0; batch classifier loss: 0.299268; batch adversarial loss: 0.581531\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390869; batch adversarial loss: 0.590731\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388118; batch adversarial loss: 0.461873\n",
      "epoch 145; iter: 0; batch classifier loss: 0.419092; batch adversarial loss: 0.561870\n",
      "epoch 146; iter: 0; batch classifier loss: 0.414639; batch adversarial loss: 0.572358\n",
      "epoch 147; iter: 0; batch classifier loss: 0.378114; batch adversarial loss: 0.526416\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351199; batch adversarial loss: 0.462484\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368119; batch adversarial loss: 0.553559\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373252; batch adversarial loss: 0.461824\n",
      "epoch 151; iter: 0; batch classifier loss: 0.418082; batch adversarial loss: 0.525332\n",
      "epoch 152; iter: 0; batch classifier loss: 0.334274; batch adversarial loss: 0.571636\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355039; batch adversarial loss: 0.534739\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353167; batch adversarial loss: 0.589742\n",
      "epoch 155; iter: 0; batch classifier loss: 0.431555; batch adversarial loss: 0.572491\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329973; batch adversarial loss: 0.563239\n",
      "epoch 157; iter: 0; batch classifier loss: 0.316684; batch adversarial loss: 0.553139\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395870; batch adversarial loss: 0.570919\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332512; batch adversarial loss: 0.618493\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351780; batch adversarial loss: 0.646446\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325629; batch adversarial loss: 0.563460\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359781; batch adversarial loss: 0.581778\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365982; batch adversarial loss: 0.590680\n",
      "epoch 164; iter: 0; batch classifier loss: 0.292337; batch adversarial loss: 0.516660\n",
      "epoch 165; iter: 0; batch classifier loss: 0.413022; batch adversarial loss: 0.527123\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404347; batch adversarial loss: 0.608540\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367062; batch adversarial loss: 0.553886\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347258; batch adversarial loss: 0.516981\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367483; batch adversarial loss: 0.516686\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351363; batch adversarial loss: 0.598986\n",
      "epoch 171; iter: 0; batch classifier loss: 0.371846; batch adversarial loss: 0.608986\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328806; batch adversarial loss: 0.590025\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321523; batch adversarial loss: 0.507867\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390628; batch adversarial loss: 0.590117\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308215; batch adversarial loss: 0.534463\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356359; batch adversarial loss: 0.572472\n",
      "epoch 177; iter: 0; batch classifier loss: 0.408626; batch adversarial loss: 0.627247\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393799; batch adversarial loss: 0.471503\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358945; batch adversarial loss: 0.552627\n",
      "epoch 180; iter: 0; batch classifier loss: 0.321221; batch adversarial loss: 0.534491\n",
      "epoch 181; iter: 0; batch classifier loss: 0.308040; batch adversarial loss: 0.498497\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378849; batch adversarial loss: 0.572064\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348767; batch adversarial loss: 0.608973\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383119; batch adversarial loss: 0.471447\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398181; batch adversarial loss: 0.516216\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399355; batch adversarial loss: 0.461589\n",
      "epoch 187; iter: 0; batch classifier loss: 0.420407; batch adversarial loss: 0.543348\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375910; batch adversarial loss: 0.571942\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332987; batch adversarial loss: 0.517197\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347403; batch adversarial loss: 0.599422\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359626; batch adversarial loss: 0.489547\n",
      "epoch 192; iter: 0; batch classifier loss: 0.282599; batch adversarial loss: 0.544215\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372068; batch adversarial loss: 0.562688\n",
      "epoch 194; iter: 0; batch classifier loss: 0.279821; batch adversarial loss: 0.572195\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332174; batch adversarial loss: 0.498641\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359405; batch adversarial loss: 0.534974\n",
      "epoch 197; iter: 0; batch classifier loss: 0.296644; batch adversarial loss: 0.581110\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361894; batch adversarial loss: 0.581805\n",
      "epoch 199; iter: 0; batch classifier loss: 0.398066; batch adversarial loss: 0.544969\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677004; batch adversarial loss: 0.826303\n",
      "epoch 1; iter: 0; batch classifier loss: 0.789522; batch adversarial loss: 1.048127\n",
      "epoch 2; iter: 0; batch classifier loss: 0.887543; batch adversarial loss: 1.017894\n",
      "epoch 3; iter: 0; batch classifier loss: 1.009064; batch adversarial loss: 0.949623\n",
      "epoch 4; iter: 0; batch classifier loss: 1.106198; batch adversarial loss: 0.865396\n",
      "epoch 5; iter: 0; batch classifier loss: 1.009635; batch adversarial loss: 0.794843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 1.040417; batch adversarial loss: 0.734908\n",
      "epoch 7; iter: 0; batch classifier loss: 0.983641; batch adversarial loss: 0.673625\n",
      "epoch 8; iter: 0; batch classifier loss: 0.706382; batch adversarial loss: 0.652067\n",
      "epoch 9; iter: 0; batch classifier loss: 0.889198; batch adversarial loss: 0.603239\n",
      "epoch 10; iter: 0; batch classifier loss: 0.619978; batch adversarial loss: 0.607516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513818; batch adversarial loss: 0.592040\n",
      "epoch 12; iter: 0; batch classifier loss: 0.596490; batch adversarial loss: 0.570588\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478892; batch adversarial loss: 0.559531\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506903; batch adversarial loss: 0.582713\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555512; batch adversarial loss: 0.552764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528248; batch adversarial loss: 0.603386\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461132; batch adversarial loss: 0.540258\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505933; batch adversarial loss: 0.561950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501278; batch adversarial loss: 0.558150\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524771; batch adversarial loss: 0.568015\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529475; batch adversarial loss: 0.549049\n",
      "epoch 22; iter: 0; batch classifier loss: 0.449879; batch adversarial loss: 0.571325\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529237; batch adversarial loss: 0.555255\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533590; batch adversarial loss: 0.603093\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501827; batch adversarial loss: 0.552157\n",
      "epoch 26; iter: 0; batch classifier loss: 0.562544; batch adversarial loss: 0.526661\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501561; batch adversarial loss: 0.458734\n",
      "epoch 28; iter: 0; batch classifier loss: 0.382722; batch adversarial loss: 0.539094\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477502; batch adversarial loss: 0.565678\n",
      "epoch 30; iter: 0; batch classifier loss: 0.521823; batch adversarial loss: 0.513567\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456700; batch adversarial loss: 0.552327\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468738; batch adversarial loss: 0.592200\n",
      "epoch 33; iter: 0; batch classifier loss: 0.524097; batch adversarial loss: 0.607052\n",
      "epoch 34; iter: 0; batch classifier loss: 0.391750; batch adversarial loss: 0.573008\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476222; batch adversarial loss: 0.613902\n",
      "epoch 36; iter: 0; batch classifier loss: 0.567143; batch adversarial loss: 0.508253\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417605; batch adversarial loss: 0.539141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483721; batch adversarial loss: 0.500051\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439863; batch adversarial loss: 0.479417\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432507; batch adversarial loss: 0.542886\n",
      "epoch 41; iter: 0; batch classifier loss: 0.376130; batch adversarial loss: 0.593133\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457384; batch adversarial loss: 0.592252\n",
      "epoch 43; iter: 0; batch classifier loss: 0.389240; batch adversarial loss: 0.485933\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419951; batch adversarial loss: 0.540804\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408040; batch adversarial loss: 0.502428\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438264; batch adversarial loss: 0.512516\n",
      "epoch 47; iter: 0; batch classifier loss: 0.380894; batch adversarial loss: 0.623584\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420077; batch adversarial loss: 0.607854\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394478; batch adversarial loss: 0.605735\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386532; batch adversarial loss: 0.522430\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408826; batch adversarial loss: 0.545762\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409657; batch adversarial loss: 0.614836\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461275; batch adversarial loss: 0.537131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.346668; batch adversarial loss: 0.511231\n",
      "epoch 55; iter: 0; batch classifier loss: 0.360877; batch adversarial loss: 0.588809\n",
      "epoch 56; iter: 0; batch classifier loss: 0.342175; batch adversarial loss: 0.579873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387089; batch adversarial loss: 0.528414\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389091; batch adversarial loss: 0.501470\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402605; batch adversarial loss: 0.553183\n",
      "epoch 60; iter: 0; batch classifier loss: 0.369378; batch adversarial loss: 0.483930\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414055; batch adversarial loss: 0.579384\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415309; batch adversarial loss: 0.544900\n",
      "epoch 63; iter: 0; batch classifier loss: 0.363155; batch adversarial loss: 0.606174\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421970; batch adversarial loss: 0.579901\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376459; batch adversarial loss: 0.597891\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418181; batch adversarial loss: 0.544909\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398007; batch adversarial loss: 0.518051\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419857; batch adversarial loss: 0.536035\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414918; batch adversarial loss: 0.518260\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369140; batch adversarial loss: 0.588803\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392884; batch adversarial loss: 0.553441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435717; batch adversarial loss: 0.562744\n",
      "epoch 73; iter: 0; batch classifier loss: 0.343194; batch adversarial loss: 0.483138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.368427; batch adversarial loss: 0.535780\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362137; batch adversarial loss: 0.571395\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394919; batch adversarial loss: 0.597299\n",
      "epoch 77; iter: 0; batch classifier loss: 0.305296; batch adversarial loss: 0.606193\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407177; batch adversarial loss: 0.571308\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398401; batch adversarial loss: 0.589004\n",
      "epoch 80; iter: 0; batch classifier loss: 0.324320; batch adversarial loss: 0.570982\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384147; batch adversarial loss: 0.554138\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348919; batch adversarial loss: 0.588369\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371194; batch adversarial loss: 0.500868\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390826; batch adversarial loss: 0.483499\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413132; batch adversarial loss: 0.527007\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357835; batch adversarial loss: 0.561800\n",
      "epoch 87; iter: 0; batch classifier loss: 0.325944; batch adversarial loss: 0.500272\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365365; batch adversarial loss: 0.580383\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369263; batch adversarial loss: 0.509541\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388375; batch adversarial loss: 0.562305\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417496; batch adversarial loss: 0.563791\n",
      "epoch 92; iter: 0; batch classifier loss: 0.313816; batch adversarial loss: 0.606412\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351829; batch adversarial loss: 0.633129\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383502; batch adversarial loss: 0.544128\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401809; batch adversarial loss: 0.526569\n",
      "epoch 96; iter: 0; batch classifier loss: 0.353329; batch adversarial loss: 0.553425\n",
      "epoch 97; iter: 0; batch classifier loss: 0.302753; batch adversarial loss: 0.580801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354503; batch adversarial loss: 0.553798\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354118; batch adversarial loss: 0.472895\n",
      "epoch 100; iter: 0; batch classifier loss: 0.380951; batch adversarial loss: 0.490739\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365314; batch adversarial loss: 0.553603\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373926; batch adversarial loss: 0.580038\n",
      "epoch 103; iter: 0; batch classifier loss: 0.344652; batch adversarial loss: 0.580654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.357564; batch adversarial loss: 0.508706\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360548; batch adversarial loss: 0.544385\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377135; batch adversarial loss: 0.544483\n",
      "epoch 107; iter: 0; batch classifier loss: 0.383111; batch adversarial loss: 0.535396\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340473; batch adversarial loss: 0.527559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385369; batch adversarial loss: 0.589454\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348786; batch adversarial loss: 0.491963\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360983; batch adversarial loss: 0.528657\n",
      "epoch 112; iter: 0; batch classifier loss: 0.390519; batch adversarial loss: 0.579412\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366117; batch adversarial loss: 0.579553\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398888; batch adversarial loss: 0.553389\n",
      "epoch 115; iter: 0; batch classifier loss: 0.295672; batch adversarial loss: 0.634290\n",
      "epoch 116; iter: 0; batch classifier loss: 0.320904; batch adversarial loss: 0.536295\n",
      "epoch 117; iter: 0; batch classifier loss: 0.306480; batch adversarial loss: 0.598565\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356079; batch adversarial loss: 0.588363\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397348; batch adversarial loss: 0.622915\n",
      "epoch 120; iter: 0; batch classifier loss: 0.302367; batch adversarial loss: 0.536167\n",
      "epoch 121; iter: 0; batch classifier loss: 0.329537; batch adversarial loss: 0.500843\n",
      "epoch 122; iter: 0; batch classifier loss: 0.310750; batch adversarial loss: 0.581080\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353186; batch adversarial loss: 0.597702\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360704; batch adversarial loss: 0.536955\n",
      "epoch 125; iter: 0; batch classifier loss: 0.417338; batch adversarial loss: 0.545593\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351070; batch adversarial loss: 0.536091\n",
      "epoch 127; iter: 0; batch classifier loss: 0.342313; batch adversarial loss: 0.508306\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353211; batch adversarial loss: 0.597308\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325988; batch adversarial loss: 0.492359\n",
      "epoch 130; iter: 0; batch classifier loss: 0.317230; batch adversarial loss: 0.572632\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356875; batch adversarial loss: 0.570018\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335486; batch adversarial loss: 0.526301\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364858; batch adversarial loss: 0.608975\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377524; batch adversarial loss: 0.561909\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369771; batch adversarial loss: 0.624119\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382565; batch adversarial loss: 0.634828\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347556; batch adversarial loss: 0.510102\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358987; batch adversarial loss: 0.473279\n",
      "epoch 139; iter: 0; batch classifier loss: 0.348822; batch adversarial loss: 0.589389\n",
      "epoch 140; iter: 0; batch classifier loss: 0.317771; batch adversarial loss: 0.506327\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348381; batch adversarial loss: 0.554211\n",
      "epoch 142; iter: 0; batch classifier loss: 0.373551; batch adversarial loss: 0.498843\n",
      "epoch 143; iter: 0; batch classifier loss: 0.316137; batch adversarial loss: 0.526111\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384038; batch adversarial loss: 0.571823\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356009; batch adversarial loss: 0.526620\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365679; batch adversarial loss: 0.509140\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336424; batch adversarial loss: 0.537341\n",
      "epoch 148; iter: 0; batch classifier loss: 0.388119; batch adversarial loss: 0.535392\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334451; batch adversarial loss: 0.562807\n",
      "epoch 150; iter: 0; batch classifier loss: 0.380379; batch adversarial loss: 0.491410\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365049; batch adversarial loss: 0.483390\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343942; batch adversarial loss: 0.473151\n",
      "epoch 153; iter: 0; batch classifier loss: 0.341595; batch adversarial loss: 0.614294\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313918; batch adversarial loss: 0.517525\n",
      "epoch 155; iter: 0; batch classifier loss: 0.305268; batch adversarial loss: 0.552099\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376335; batch adversarial loss: 0.614680\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364902; batch adversarial loss: 0.520795\n",
      "epoch 158; iter: 0; batch classifier loss: 0.371955; batch adversarial loss: 0.597994\n",
      "epoch 159; iter: 0; batch classifier loss: 0.298345; batch adversarial loss: 0.625899\n",
      "epoch 160; iter: 0; batch classifier loss: 0.258466; batch adversarial loss: 0.552807\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367369; batch adversarial loss: 0.526287\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366863; batch adversarial loss: 0.579990\n",
      "epoch 163; iter: 0; batch classifier loss: 0.278723; batch adversarial loss: 0.561213\n",
      "epoch 164; iter: 0; batch classifier loss: 0.292643; batch adversarial loss: 0.482973\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398787; batch adversarial loss: 0.588674\n",
      "epoch 166; iter: 0; batch classifier loss: 0.298160; batch adversarial loss: 0.590142\n",
      "epoch 167; iter: 0; batch classifier loss: 0.285974; batch adversarial loss: 0.529681\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317169; batch adversarial loss: 0.596455\n",
      "epoch 169; iter: 0; batch classifier loss: 0.319991; batch adversarial loss: 0.577589\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329783; batch adversarial loss: 0.528126\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336503; batch adversarial loss: 0.546348\n",
      "epoch 172; iter: 0; batch classifier loss: 0.442204; batch adversarial loss: 0.561517\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335719; batch adversarial loss: 0.553416\n",
      "epoch 174; iter: 0; batch classifier loss: 0.261808; batch adversarial loss: 0.605671\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409720; batch adversarial loss: 0.492146\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354705; batch adversarial loss: 0.597215\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306615; batch adversarial loss: 0.467370\n",
      "epoch 178; iter: 0; batch classifier loss: 0.301100; batch adversarial loss: 0.581083\n",
      "epoch 179; iter: 0; batch classifier loss: 0.236802; batch adversarial loss: 0.632921\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363625; batch adversarial loss: 0.587911\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349758; batch adversarial loss: 0.538616\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336440; batch adversarial loss: 0.527260\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348954; batch adversarial loss: 0.536230\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337560; batch adversarial loss: 0.622851\n",
      "epoch 185; iter: 0; batch classifier loss: 0.300403; batch adversarial loss: 0.499462\n",
      "epoch 186; iter: 0; batch classifier loss: 0.360713; batch adversarial loss: 0.545608\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354554; batch adversarial loss: 0.519512\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311321; batch adversarial loss: 0.535895\n",
      "epoch 189; iter: 0; batch classifier loss: 0.372392; batch adversarial loss: 0.625039\n",
      "epoch 190; iter: 0; batch classifier loss: 0.311841; batch adversarial loss: 0.519763\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364291; batch adversarial loss: 0.577519\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335856; batch adversarial loss: 0.606926\n",
      "epoch 193; iter: 0; batch classifier loss: 0.405268; batch adversarial loss: 0.605956\n",
      "epoch 194; iter: 0; batch classifier loss: 0.294135; batch adversarial loss: 0.536533\n",
      "epoch 195; iter: 0; batch classifier loss: 0.288824; batch adversarial loss: 0.535468\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334249; batch adversarial loss: 0.525610\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364332; batch adversarial loss: 0.600309\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349148; batch adversarial loss: 0.546426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345365; batch adversarial loss: 0.545273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.776416; batch adversarial loss: 0.630334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607821; batch adversarial loss: 0.658980\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547498; batch adversarial loss: 0.641675\n",
      "epoch 3; iter: 0; batch classifier loss: 0.527796; batch adversarial loss: 0.672383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.609520; batch adversarial loss: 0.638967\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519889; batch adversarial loss: 0.632817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.634147; batch adversarial loss: 0.681458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.572036; batch adversarial loss: 0.612498\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552107; batch adversarial loss: 0.606896\n",
      "epoch 9; iter: 0; batch classifier loss: 0.618834; batch adversarial loss: 0.604185\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544331; batch adversarial loss: 0.555189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515928; batch adversarial loss: 0.661914\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474677; batch adversarial loss: 0.563873\n",
      "epoch 13; iter: 0; batch classifier loss: 0.585680; batch adversarial loss: 0.631271\n",
      "epoch 14; iter: 0; batch classifier loss: 0.482753; batch adversarial loss: 0.558439\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558805; batch adversarial loss: 0.560369\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552827; batch adversarial loss: 0.536554\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526085; batch adversarial loss: 0.561211\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542458; batch adversarial loss: 0.545463\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438061; batch adversarial loss: 0.588531\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468563; batch adversarial loss: 0.510781\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476938; batch adversarial loss: 0.555154\n",
      "epoch 22; iter: 0; batch classifier loss: 0.393640; batch adversarial loss: 0.508219\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443977; batch adversarial loss: 0.586924\n",
      "epoch 24; iter: 0; batch classifier loss: 0.619198; batch adversarial loss: 0.547843\n",
      "epoch 25; iter: 0; batch classifier loss: 0.514505; batch adversarial loss: 0.531627\n",
      "epoch 26; iter: 0; batch classifier loss: 0.422909; batch adversarial loss: 0.620947\n",
      "epoch 27; iter: 0; batch classifier loss: 0.418607; batch adversarial loss: 0.623038\n",
      "epoch 28; iter: 0; batch classifier loss: 0.543151; batch adversarial loss: 0.638220\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465581; batch adversarial loss: 0.545745\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444655; batch adversarial loss: 0.581141\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490711; batch adversarial loss: 0.535219\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461851; batch adversarial loss: 0.527974\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405155; batch adversarial loss: 0.535930\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452923; batch adversarial loss: 0.579009\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476949; batch adversarial loss: 0.518667\n",
      "epoch 36; iter: 0; batch classifier loss: 0.429879; batch adversarial loss: 0.545851\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421387; batch adversarial loss: 0.579354\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474175; batch adversarial loss: 0.500906\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450282; batch adversarial loss: 0.570503\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484958; batch adversarial loss: 0.528057\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484965; batch adversarial loss: 0.483150\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461664; batch adversarial loss: 0.544551\n",
      "epoch 43; iter: 0; batch classifier loss: 0.513029; batch adversarial loss: 0.501118\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483623; batch adversarial loss: 0.570890\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464057; batch adversarial loss: 0.527418\n",
      "epoch 46; iter: 0; batch classifier loss: 0.542596; batch adversarial loss: 0.588254\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409171; batch adversarial loss: 0.553880\n",
      "epoch 48; iter: 0; batch classifier loss: 0.496466; batch adversarial loss: 0.632963\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454779; batch adversarial loss: 0.536278\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390796; batch adversarial loss: 0.571298\n",
      "epoch 51; iter: 0; batch classifier loss: 0.400165; batch adversarial loss: 0.544890\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412320; batch adversarial loss: 0.571299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441911; batch adversarial loss: 0.553521\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431882; batch adversarial loss: 0.535926\n",
      "epoch 55; iter: 0; batch classifier loss: 0.438167; batch adversarial loss: 0.615384\n",
      "epoch 56; iter: 0; batch classifier loss: 0.487631; batch adversarial loss: 0.553281\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429254; batch adversarial loss: 0.455092\n",
      "epoch 58; iter: 0; batch classifier loss: 0.468753; batch adversarial loss: 0.599725\n",
      "epoch 59; iter: 0; batch classifier loss: 0.473606; batch adversarial loss: 0.597898\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426896; batch adversarial loss: 0.617071\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388123; batch adversarial loss: 0.608770\n",
      "epoch 62; iter: 0; batch classifier loss: 0.486612; batch adversarial loss: 0.481529\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442846; batch adversarial loss: 0.606469\n",
      "epoch 64; iter: 0; batch classifier loss: 0.437623; batch adversarial loss: 0.622547\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449650; batch adversarial loss: 0.526993\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380728; batch adversarial loss: 0.614183\n",
      "epoch 67; iter: 0; batch classifier loss: 0.444664; batch adversarial loss: 0.562649\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404922; batch adversarial loss: 0.518128\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387284; batch adversarial loss: 0.562700\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465127; batch adversarial loss: 0.580472\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380241; batch adversarial loss: 0.562260\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394217; batch adversarial loss: 0.597107\n",
      "epoch 73; iter: 0; batch classifier loss: 0.421579; batch adversarial loss: 0.579501\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346745; batch adversarial loss: 0.552915\n",
      "epoch 75; iter: 0; batch classifier loss: 0.474545; batch adversarial loss: 0.491406\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378047; batch adversarial loss: 0.589023\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433250; batch adversarial loss: 0.518729\n",
      "epoch 78; iter: 0; batch classifier loss: 0.384779; batch adversarial loss: 0.605882\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428843; batch adversarial loss: 0.571587\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363694; batch adversarial loss: 0.545004\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383508; batch adversarial loss: 0.518568\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381817; batch adversarial loss: 0.598082\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388704; batch adversarial loss: 0.501072\n",
      "epoch 84; iter: 0; batch classifier loss: 0.328702; batch adversarial loss: 0.571629\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395508; batch adversarial loss: 0.641317\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390262; batch adversarial loss: 0.580626\n",
      "epoch 87; iter: 0; batch classifier loss: 0.436448; batch adversarial loss: 0.606431\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408085; batch adversarial loss: 0.517387\n",
      "epoch 89; iter: 0; batch classifier loss: 0.443839; batch adversarial loss: 0.624530\n",
      "epoch 90; iter: 0; batch classifier loss: 0.327558; batch adversarial loss: 0.606143\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407372; batch adversarial loss: 0.535740\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412068; batch adversarial loss: 0.580588\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385184; batch adversarial loss: 0.562721\n",
      "epoch 94; iter: 0; batch classifier loss: 0.481667; batch adversarial loss: 0.587999\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431191; batch adversarial loss: 0.544988\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429076; batch adversarial loss: 0.526736\n",
      "epoch 97; iter: 0; batch classifier loss: 0.466788; batch adversarial loss: 0.553803\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416723; batch adversarial loss: 0.570889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.415004; batch adversarial loss: 0.500482\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397072; batch adversarial loss: 0.562009\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395984; batch adversarial loss: 0.553049\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390246; batch adversarial loss: 0.562449\n",
      "epoch 103; iter: 0; batch classifier loss: 0.425278; batch adversarial loss: 0.543778\n",
      "epoch 104; iter: 0; batch classifier loss: 0.447069; batch adversarial loss: 0.553006\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427727; batch adversarial loss: 0.518424\n",
      "epoch 106; iter: 0; batch classifier loss: 0.489581; batch adversarial loss: 0.562337\n",
      "epoch 107; iter: 0; batch classifier loss: 0.390088; batch adversarial loss: 0.544978\n",
      "epoch 108; iter: 0; batch classifier loss: 0.488916; batch adversarial loss: 0.580741\n",
      "epoch 109; iter: 0; batch classifier loss: 0.461494; batch adversarial loss: 0.562370\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394706; batch adversarial loss: 0.597215\n",
      "epoch 111; iter: 0; batch classifier loss: 0.442172; batch adversarial loss: 0.527876\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363046; batch adversarial loss: 0.596936\n",
      "epoch 113; iter: 0; batch classifier loss: 0.365546; batch adversarial loss: 0.624929\n",
      "epoch 114; iter: 0; batch classifier loss: 0.413873; batch adversarial loss: 0.500891\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377246; batch adversarial loss: 0.614992\n",
      "epoch 116; iter: 0; batch classifier loss: 0.406255; batch adversarial loss: 0.580281\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374598; batch adversarial loss: 0.562539\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360222; batch adversarial loss: 0.518340\n",
      "epoch 119; iter: 0; batch classifier loss: 0.341249; batch adversarial loss: 0.553466\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371994; batch adversarial loss: 0.544198\n",
      "epoch 121; iter: 0; batch classifier loss: 0.283554; batch adversarial loss: 0.588772\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351723; batch adversarial loss: 0.632668\n",
      "epoch 123; iter: 0; batch classifier loss: 0.410231; batch adversarial loss: 0.579733\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386582; batch adversarial loss: 0.579943\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340347; batch adversarial loss: 0.561861\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403174; batch adversarial loss: 0.571881\n",
      "epoch 127; iter: 0; batch classifier loss: 0.545837; batch adversarial loss: 0.528043\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367977; batch adversarial loss: 0.490647\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371631; batch adversarial loss: 0.509027\n",
      "epoch 130; iter: 0; batch classifier loss: 0.427438; batch adversarial loss: 0.570431\n",
      "epoch 131; iter: 0; batch classifier loss: 0.444246; batch adversarial loss: 0.570199\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354192; batch adversarial loss: 0.542769\n",
      "epoch 133; iter: 0; batch classifier loss: 0.446925; batch adversarial loss: 0.554468\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339539; batch adversarial loss: 0.571285\n",
      "epoch 135; iter: 0; batch classifier loss: 0.447724; batch adversarial loss: 0.598421\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359666; batch adversarial loss: 0.642885\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369099; batch adversarial loss: 0.545021\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360495; batch adversarial loss: 0.553922\n",
      "epoch 139; iter: 0; batch classifier loss: 0.391353; batch adversarial loss: 0.595870\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393649; batch adversarial loss: 0.527183\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359761; batch adversarial loss: 0.579143\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362385; batch adversarial loss: 0.563771\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365098; batch adversarial loss: 0.553452\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361826; batch adversarial loss: 0.589241\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360601; batch adversarial loss: 0.526397\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358245; batch adversarial loss: 0.545957\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343208; batch adversarial loss: 0.500398\n",
      "epoch 148; iter: 0; batch classifier loss: 0.403831; batch adversarial loss: 0.641845\n",
      "epoch 149; iter: 0; batch classifier loss: 0.318940; batch adversarial loss: 0.578477\n",
      "epoch 150; iter: 0; batch classifier loss: 0.408318; batch adversarial loss: 0.543983\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365380; batch adversarial loss: 0.589958\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394061; batch adversarial loss: 0.597568\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373214; batch adversarial loss: 0.500730\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335820; batch adversarial loss: 0.580056\n",
      "epoch 155; iter: 0; batch classifier loss: 0.454381; batch adversarial loss: 0.536462\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355856; batch adversarial loss: 0.676890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.380830; batch adversarial loss: 0.554669\n",
      "epoch 158; iter: 0; batch classifier loss: 0.309366; batch adversarial loss: 0.578483\n",
      "epoch 159; iter: 0; batch classifier loss: 0.288861; batch adversarial loss: 0.625058\n",
      "epoch 160; iter: 0; batch classifier loss: 0.366605; batch adversarial loss: 0.438926\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322646; batch adversarial loss: 0.571000\n",
      "epoch 162; iter: 0; batch classifier loss: 0.322329; batch adversarial loss: 0.509192\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353232; batch adversarial loss: 0.491240\n",
      "epoch 164; iter: 0; batch classifier loss: 0.302150; batch adversarial loss: 0.597557\n",
      "epoch 165; iter: 0; batch classifier loss: 0.341774; batch adversarial loss: 0.553781\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341131; batch adversarial loss: 0.579124\n",
      "epoch 167; iter: 0; batch classifier loss: 0.385968; batch adversarial loss: 0.662156\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324197; batch adversarial loss: 0.544064\n",
      "epoch 169; iter: 0; batch classifier loss: 0.404709; batch adversarial loss: 0.590266\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382676; batch adversarial loss: 0.536950\n",
      "epoch 171; iter: 0; batch classifier loss: 0.376260; batch adversarial loss: 0.483073\n",
      "epoch 172; iter: 0; batch classifier loss: 0.308257; batch adversarial loss: 0.595859\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342773; batch adversarial loss: 0.562028\n",
      "epoch 174; iter: 0; batch classifier loss: 0.411912; batch adversarial loss: 0.492177\n",
      "epoch 175; iter: 0; batch classifier loss: 0.377585; batch adversarial loss: 0.579279\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341075; batch adversarial loss: 0.535749\n",
      "epoch 177; iter: 0; batch classifier loss: 0.283229; batch adversarial loss: 0.500842\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384508; batch adversarial loss: 0.560995\n",
      "epoch 179; iter: 0; batch classifier loss: 0.355559; batch adversarial loss: 0.527348\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388266; batch adversarial loss: 0.552912\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325771; batch adversarial loss: 0.589169\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374466; batch adversarial loss: 0.528622\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348817; batch adversarial loss: 0.561909\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413333; batch adversarial loss: 0.641959\n",
      "epoch 185; iter: 0; batch classifier loss: 0.424185; batch adversarial loss: 0.510102\n",
      "epoch 186; iter: 0; batch classifier loss: 0.319213; batch adversarial loss: 0.542724\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332874; batch adversarial loss: 0.623430\n",
      "epoch 188; iter: 0; batch classifier loss: 0.250955; batch adversarial loss: 0.572363\n",
      "epoch 189; iter: 0; batch classifier loss: 0.319901; batch adversarial loss: 0.528918\n",
      "epoch 190; iter: 0; batch classifier loss: 0.389274; batch adversarial loss: 0.553507\n",
      "epoch 191; iter: 0; batch classifier loss: 0.415337; batch adversarial loss: 0.641756\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349293; batch adversarial loss: 0.545821\n",
      "epoch 193; iter: 0; batch classifier loss: 0.311660; batch adversarial loss: 0.492063\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335958; batch adversarial loss: 0.581596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.334528; batch adversarial loss: 0.544545\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337504; batch adversarial loss: 0.491796\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356959; batch adversarial loss: 0.544941\n",
      "epoch 198; iter: 0; batch classifier loss: 0.385212; batch adversarial loss: 0.596249\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308912; batch adversarial loss: 0.632684\n",
      "epoch 0; iter: 0; batch classifier loss: 0.633913; batch adversarial loss: 0.899465\n",
      "epoch 1; iter: 0; batch classifier loss: 0.847374; batch adversarial loss: 1.285476\n",
      "epoch 2; iter: 0; batch classifier loss: 1.042878; batch adversarial loss: 1.231258\n",
      "epoch 3; iter: 0; batch classifier loss: 1.114274; batch adversarial loss: 1.214314\n",
      "epoch 4; iter: 0; batch classifier loss: 1.276171; batch adversarial loss: 1.101538\n",
      "epoch 5; iter: 0; batch classifier loss: 1.430053; batch adversarial loss: 1.045552\n",
      "epoch 6; iter: 0; batch classifier loss: 1.361956; batch adversarial loss: 0.946638\n",
      "epoch 7; iter: 0; batch classifier loss: 1.226238; batch adversarial loss: 0.869743\n",
      "epoch 8; iter: 0; batch classifier loss: 1.312731; batch adversarial loss: 0.813159\n",
      "epoch 9; iter: 0; batch classifier loss: 1.356508; batch adversarial loss: 0.758769\n",
      "epoch 10; iter: 0; batch classifier loss: 1.108936; batch adversarial loss: 0.707504\n",
      "epoch 11; iter: 0; batch classifier loss: 1.044096; batch adversarial loss: 0.674118\n",
      "epoch 12; iter: 0; batch classifier loss: 0.796967; batch adversarial loss: 0.584475\n",
      "epoch 13; iter: 0; batch classifier loss: 0.735204; batch adversarial loss: 0.603226\n",
      "epoch 14; iter: 0; batch classifier loss: 0.671308; batch adversarial loss: 0.627744\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548343; batch adversarial loss: 0.585287\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561078; batch adversarial loss: 0.572741\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568169; batch adversarial loss: 0.549413\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505027; batch adversarial loss: 0.611050\n",
      "epoch 19; iter: 0; batch classifier loss: 0.584417; batch adversarial loss: 0.561083\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485372; batch adversarial loss: 0.581655\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511460; batch adversarial loss: 0.620026\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457117; batch adversarial loss: 0.551917\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507838; batch adversarial loss: 0.604121\n",
      "epoch 24; iter: 0; batch classifier loss: 0.540128; batch adversarial loss: 0.532941\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442487; batch adversarial loss: 0.537887\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497906; batch adversarial loss: 0.533762\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476693; batch adversarial loss: 0.524741\n",
      "epoch 28; iter: 0; batch classifier loss: 0.436181; batch adversarial loss: 0.556767\n",
      "epoch 29; iter: 0; batch classifier loss: 0.499431; batch adversarial loss: 0.564560\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488381; batch adversarial loss: 0.550842\n",
      "epoch 31; iter: 0; batch classifier loss: 0.482863; batch adversarial loss: 0.620874\n",
      "epoch 32; iter: 0; batch classifier loss: 0.523048; batch adversarial loss: 0.584752\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469853; batch adversarial loss: 0.570067\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441579; batch adversarial loss: 0.542623\n",
      "epoch 35; iter: 0; batch classifier loss: 0.501279; batch adversarial loss: 0.576787\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478761; batch adversarial loss: 0.560074\n",
      "epoch 37; iter: 0; batch classifier loss: 0.492981; batch adversarial loss: 0.615037\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446841; batch adversarial loss: 0.651448\n",
      "epoch 39; iter: 0; batch classifier loss: 0.506949; batch adversarial loss: 0.589364\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420340; batch adversarial loss: 0.586029\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449896; batch adversarial loss: 0.502625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409405; batch adversarial loss: 0.585241\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451948; batch adversarial loss: 0.534614\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412320; batch adversarial loss: 0.519559\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414093; batch adversarial loss: 0.653973\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491543; batch adversarial loss: 0.526539\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408669; batch adversarial loss: 0.512091\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439575; batch adversarial loss: 0.506955\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478010; batch adversarial loss: 0.545814\n",
      "epoch 50; iter: 0; batch classifier loss: 0.373697; batch adversarial loss: 0.585562\n",
      "epoch 51; iter: 0; batch classifier loss: 0.407442; batch adversarial loss: 0.604200\n",
      "epoch 52; iter: 0; batch classifier loss: 0.364117; batch adversarial loss: 0.576850\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450936; batch adversarial loss: 0.477926\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411373; batch adversarial loss: 0.538510\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407729; batch adversarial loss: 0.495571\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453295; batch adversarial loss: 0.554095\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396670; batch adversarial loss: 0.552780\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446756; batch adversarial loss: 0.622382\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407817; batch adversarial loss: 0.563338\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451882; batch adversarial loss: 0.544579\n",
      "epoch 61; iter: 0; batch classifier loss: 0.330340; batch adversarial loss: 0.579248\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392739; batch adversarial loss: 0.529453\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430680; batch adversarial loss: 0.545525\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429556; batch adversarial loss: 0.502747\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478601; batch adversarial loss: 0.570463\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454472; batch adversarial loss: 0.554231\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412319; batch adversarial loss: 0.580099\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407508; batch adversarial loss: 0.597012\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374820; batch adversarial loss: 0.665612\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436259; batch adversarial loss: 0.536332\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380936; batch adversarial loss: 0.528042\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433089; batch adversarial loss: 0.562380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406288; batch adversarial loss: 0.649033\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419702; batch adversarial loss: 0.631049\n",
      "epoch 75; iter: 0; batch classifier loss: 0.464612; batch adversarial loss: 0.613379\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365197; batch adversarial loss: 0.501835\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410336; batch adversarial loss: 0.536451\n",
      "epoch 78; iter: 0; batch classifier loss: 0.446751; batch adversarial loss: 0.527986\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390839; batch adversarial loss: 0.571699\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347698; batch adversarial loss: 0.572256\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375958; batch adversarial loss: 0.622988\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350036; batch adversarial loss: 0.553581\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398461; batch adversarial loss: 0.526934\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412398; batch adversarial loss: 0.527206\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407074; batch adversarial loss: 0.527487\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374776; batch adversarial loss: 0.613954\n",
      "epoch 87; iter: 0; batch classifier loss: 0.326871; batch adversarial loss: 0.587764\n",
      "epoch 88; iter: 0; batch classifier loss: 0.312158; batch adversarial loss: 0.553811\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429823; batch adversarial loss: 0.579911\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427620; batch adversarial loss: 0.569872\n",
      "epoch 91; iter: 0; batch classifier loss: 0.310079; batch adversarial loss: 0.509040\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389353; batch adversarial loss: 0.606065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.397128; batch adversarial loss: 0.569501\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372398; batch adversarial loss: 0.552493\n",
      "epoch 95; iter: 0; batch classifier loss: 0.360788; batch adversarial loss: 0.658758\n",
      "epoch 96; iter: 0; batch classifier loss: 0.393201; batch adversarial loss: 0.588299\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401481; batch adversarial loss: 0.546473\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376232; batch adversarial loss: 0.585626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.310827; batch adversarial loss: 0.604809\n",
      "epoch 100; iter: 0; batch classifier loss: 0.351661; batch adversarial loss: 0.555371\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382197; batch adversarial loss: 0.562250\n",
      "epoch 102; iter: 0; batch classifier loss: 0.324268; batch adversarial loss: 0.544910\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372191; batch adversarial loss: 0.528027\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419939; batch adversarial loss: 0.552975\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355019; batch adversarial loss: 0.585980\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369448; batch adversarial loss: 0.631973\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384679; batch adversarial loss: 0.537318\n",
      "epoch 108; iter: 0; batch classifier loss: 0.350076; batch adversarial loss: 0.554810\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402467; batch adversarial loss: 0.623369\n",
      "epoch 110; iter: 0; batch classifier loss: 0.460886; batch adversarial loss: 0.510357\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393942; batch adversarial loss: 0.579532\n",
      "epoch 112; iter: 0; batch classifier loss: 0.317436; batch adversarial loss: 0.555531\n",
      "epoch 113; iter: 0; batch classifier loss: 0.300765; batch adversarial loss: 0.552629\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410281; batch adversarial loss: 0.615162\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370791; batch adversarial loss: 0.562887\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319334; batch adversarial loss: 0.537656\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409589; batch adversarial loss: 0.552373\n",
      "epoch 118; iter: 0; batch classifier loss: 0.372160; batch adversarial loss: 0.554093\n",
      "epoch 119; iter: 0; batch classifier loss: 0.328842; batch adversarial loss: 0.589833\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372071; batch adversarial loss: 0.605135\n",
      "epoch 121; iter: 0; batch classifier loss: 0.432590; batch adversarial loss: 0.621795\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346917; batch adversarial loss: 0.569198\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404055; batch adversarial loss: 0.546178\n",
      "epoch 124; iter: 0; batch classifier loss: 0.292108; batch adversarial loss: 0.552381\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380277; batch adversarial loss: 0.644219\n",
      "epoch 126; iter: 0; batch classifier loss: 0.321416; batch adversarial loss: 0.538587\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353633; batch adversarial loss: 0.596748\n",
      "epoch 128; iter: 0; batch classifier loss: 0.335565; batch adversarial loss: 0.589011\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365745; batch adversarial loss: 0.521412\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383372; batch adversarial loss: 0.562257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.320062; batch adversarial loss: 0.568958\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319177; batch adversarial loss: 0.527708\n",
      "epoch 133; iter: 0; batch classifier loss: 0.294041; batch adversarial loss: 0.589121\n",
      "epoch 134; iter: 0; batch classifier loss: 0.328735; batch adversarial loss: 0.519125\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397403; batch adversarial loss: 0.588794\n",
      "epoch 136; iter: 0; batch classifier loss: 0.342824; batch adversarial loss: 0.545620\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327571; batch adversarial loss: 0.580752\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349748; batch adversarial loss: 0.584754\n",
      "epoch 139; iter: 0; batch classifier loss: 0.316556; batch adversarial loss: 0.576946\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397483; batch adversarial loss: 0.545878\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343416; batch adversarial loss: 0.526491\n",
      "epoch 142; iter: 0; batch classifier loss: 0.304417; batch adversarial loss: 0.498631\n",
      "epoch 143; iter: 0; batch classifier loss: 0.318503; batch adversarial loss: 0.561261\n",
      "epoch 144; iter: 0; batch classifier loss: 0.332438; batch adversarial loss: 0.561082\n",
      "epoch 145; iter: 0; batch classifier loss: 0.318035; batch adversarial loss: 0.581164\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366504; batch adversarial loss: 0.613941\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388730; batch adversarial loss: 0.552079\n",
      "epoch 148; iter: 0; batch classifier loss: 0.254019; batch adversarial loss: 0.511339\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326326; batch adversarial loss: 0.612720\n",
      "epoch 150; iter: 0; batch classifier loss: 0.410153; batch adversarial loss: 0.560724\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375385; batch adversarial loss: 0.598003\n",
      "epoch 152; iter: 0; batch classifier loss: 0.287976; batch adversarial loss: 0.530994\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385825; batch adversarial loss: 0.528283\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377404; batch adversarial loss: 0.621349\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342315; batch adversarial loss: 0.615221\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300107; batch adversarial loss: 0.586660\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405902; batch adversarial loss: 0.605329\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388230; batch adversarial loss: 0.485020\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311412; batch adversarial loss: 0.527163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326308; batch adversarial loss: 0.552815\n",
      "epoch 161; iter: 0; batch classifier loss: 0.288869; batch adversarial loss: 0.580868\n",
      "epoch 162; iter: 0; batch classifier loss: 0.373967; batch adversarial loss: 0.569179\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331566; batch adversarial loss: 0.586272\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324048; batch adversarial loss: 0.544626\n",
      "epoch 165; iter: 0; batch classifier loss: 0.247999; batch adversarial loss: 0.614710\n",
      "epoch 166; iter: 0; batch classifier loss: 0.434833; batch adversarial loss: 0.649490\n",
      "epoch 167; iter: 0; batch classifier loss: 0.338772; batch adversarial loss: 0.585712\n",
      "epoch 168; iter: 0; batch classifier loss: 0.243110; batch adversarial loss: 0.511035\n",
      "epoch 169; iter: 0; batch classifier loss: 0.287031; batch adversarial loss: 0.494426\n",
      "epoch 170; iter: 0; batch classifier loss: 0.343115; batch adversarial loss: 0.568617\n",
      "epoch 171; iter: 0; batch classifier loss: 0.327670; batch adversarial loss: 0.483312\n",
      "epoch 172; iter: 0; batch classifier loss: 0.291726; batch adversarial loss: 0.511169\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322552; batch adversarial loss: 0.558081\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362877; batch adversarial loss: 0.604207\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331075; batch adversarial loss: 0.596893\n",
      "epoch 176; iter: 0; batch classifier loss: 0.264467; batch adversarial loss: 0.587827\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316868; batch adversarial loss: 0.612648\n",
      "epoch 178; iter: 0; batch classifier loss: 0.404020; batch adversarial loss: 0.531964\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391769; batch adversarial loss: 0.655241\n",
      "epoch 180; iter: 0; batch classifier loss: 0.366276; batch adversarial loss: 0.571330\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364042; batch adversarial loss: 0.525629\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351513; batch adversarial loss: 0.561681\n",
      "epoch 183; iter: 0; batch classifier loss: 0.296267; batch adversarial loss: 0.516947\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370148; batch adversarial loss: 0.647820\n",
      "epoch 185; iter: 0; batch classifier loss: 0.400906; batch adversarial loss: 0.613924\n",
      "epoch 186; iter: 0; batch classifier loss: 0.274832; batch adversarial loss: 0.604715\n",
      "epoch 187; iter: 0; batch classifier loss: 0.407448; batch adversarial loss: 0.474068\n",
      "epoch 188; iter: 0; batch classifier loss: 0.309547; batch adversarial loss: 0.536285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.367869; batch adversarial loss: 0.501256\n",
      "epoch 190; iter: 0; batch classifier loss: 0.226804; batch adversarial loss: 0.535071\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364424; batch adversarial loss: 0.587086\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305702; batch adversarial loss: 0.598711\n",
      "epoch 193; iter: 0; batch classifier loss: 0.246830; batch adversarial loss: 0.569767\n",
      "epoch 194; iter: 0; batch classifier loss: 0.374447; batch adversarial loss: 0.526961\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362295; batch adversarial loss: 0.546338\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343054; batch adversarial loss: 0.441855\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307393; batch adversarial loss: 0.543927\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323737; batch adversarial loss: 0.525924\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334524; batch adversarial loss: 0.632313\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718751; batch adversarial loss: 0.973333\n",
      "epoch 1; iter: 0; batch classifier loss: 0.814401; batch adversarial loss: 1.038945\n",
      "epoch 2; iter: 0; batch classifier loss: 1.027939; batch adversarial loss: 1.119773\n",
      "epoch 3; iter: 0; batch classifier loss: 1.010311; batch adversarial loss: 1.038991\n",
      "epoch 4; iter: 0; batch classifier loss: 0.910663; batch adversarial loss: 0.885712\n",
      "epoch 5; iter: 0; batch classifier loss: 0.859077; batch adversarial loss: 0.862796\n",
      "epoch 6; iter: 0; batch classifier loss: 0.695126; batch adversarial loss: 0.743168\n",
      "epoch 7; iter: 0; batch classifier loss: 0.653211; batch adversarial loss: 0.701139\n",
      "epoch 8; iter: 0; batch classifier loss: 0.660645; batch adversarial loss: 0.691583\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551728; batch adversarial loss: 0.587256\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517072; batch adversarial loss: 0.631610\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580773; batch adversarial loss: 0.642987\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535770; batch adversarial loss: 0.590638\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486501; batch adversarial loss: 0.589042\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525849; batch adversarial loss: 0.641810\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483806; batch adversarial loss: 0.601319\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454156; batch adversarial loss: 0.556979\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495036; batch adversarial loss: 0.642721\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483486; batch adversarial loss: 0.566885\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488202; batch adversarial loss: 0.588717\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487212; batch adversarial loss: 0.546972\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509966; batch adversarial loss: 0.571622\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478177; batch adversarial loss: 0.594304\n",
      "epoch 23; iter: 0; batch classifier loss: 0.469014; batch adversarial loss: 0.538360\n",
      "epoch 24; iter: 0; batch classifier loss: 0.414297; batch adversarial loss: 0.548511\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478976; batch adversarial loss: 0.627399\n",
      "epoch 26; iter: 0; batch classifier loss: 0.568756; batch adversarial loss: 0.554694\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444306; batch adversarial loss: 0.571781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.571958; batch adversarial loss: 0.558007\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435789; batch adversarial loss: 0.511531\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455969; batch adversarial loss: 0.600704\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465719; batch adversarial loss: 0.545827\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493409; batch adversarial loss: 0.546060\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462558; batch adversarial loss: 0.548161\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484349; batch adversarial loss: 0.518939\n",
      "epoch 35; iter: 0; batch classifier loss: 0.379408; batch adversarial loss: 0.564077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.395117; batch adversarial loss: 0.608721\n",
      "epoch 37; iter: 0; batch classifier loss: 0.557792; batch adversarial loss: 0.562034\n",
      "epoch 38; iter: 0; batch classifier loss: 0.554923; batch adversarial loss: 0.644307\n",
      "epoch 39; iter: 0; batch classifier loss: 0.525895; batch adversarial loss: 0.574706\n",
      "epoch 40; iter: 0; batch classifier loss: 0.485582; batch adversarial loss: 0.583877\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455632; batch adversarial loss: 0.601836\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414674; batch adversarial loss: 0.567313\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434837; batch adversarial loss: 0.518478\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446620; batch adversarial loss: 0.541243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433252; batch adversarial loss: 0.578929\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423067; batch adversarial loss: 0.547645\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375096; batch adversarial loss: 0.519729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.518163; batch adversarial loss: 0.635798\n",
      "epoch 49; iter: 0; batch classifier loss: 0.528308; batch adversarial loss: 0.578165\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386017; batch adversarial loss: 0.651201\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429327; batch adversarial loss: 0.609428\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425525; batch adversarial loss: 0.625652\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401911; batch adversarial loss: 0.590172\n",
      "epoch 54; iter: 0; batch classifier loss: 0.538750; batch adversarial loss: 0.605651\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393570; batch adversarial loss: 0.545290\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419323; batch adversarial loss: 0.547537\n",
      "epoch 57; iter: 0; batch classifier loss: 0.433633; batch adversarial loss: 0.577495\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411552; batch adversarial loss: 0.550491\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407791; batch adversarial loss: 0.635792\n",
      "epoch 60; iter: 0; batch classifier loss: 0.494252; batch adversarial loss: 0.547593\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395086; batch adversarial loss: 0.634036\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387631; batch adversarial loss: 0.599614\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418136; batch adversarial loss: 0.482829\n",
      "epoch 64; iter: 0; batch classifier loss: 0.463287; batch adversarial loss: 0.511334\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402371; batch adversarial loss: 0.581173\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413549; batch adversarial loss: 0.535584\n",
      "epoch 67; iter: 0; batch classifier loss: 0.507097; batch adversarial loss: 0.502352\n",
      "epoch 68; iter: 0; batch classifier loss: 0.521979; batch adversarial loss: 0.553736\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371630; batch adversarial loss: 0.562475\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383782; batch adversarial loss: 0.536190\n",
      "epoch 71; iter: 0; batch classifier loss: 0.324969; batch adversarial loss: 0.596541\n",
      "epoch 72; iter: 0; batch classifier loss: 0.348453; batch adversarial loss: 0.560554\n",
      "epoch 73; iter: 0; batch classifier loss: 0.455869; batch adversarial loss: 0.560078\n",
      "epoch 74; iter: 0; batch classifier loss: 0.371468; batch adversarial loss: 0.522962\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362391; batch adversarial loss: 0.543109\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392601; batch adversarial loss: 0.495113\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376187; batch adversarial loss: 0.499246\n",
      "epoch 78; iter: 0; batch classifier loss: 0.403480; batch adversarial loss: 0.546783\n",
      "epoch 79; iter: 0; batch classifier loss: 0.445082; batch adversarial loss: 0.606730\n",
      "epoch 80; iter: 0; batch classifier loss: 0.450708; batch adversarial loss: 0.619941\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374923; batch adversarial loss: 0.552052\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395496; batch adversarial loss: 0.581374\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399625; batch adversarial loss: 0.543315\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371150; batch adversarial loss: 0.552229\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403068; batch adversarial loss: 0.596180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.344948; batch adversarial loss: 0.528010\n",
      "epoch 87; iter: 0; batch classifier loss: 0.543551; batch adversarial loss: 0.484059\n",
      "epoch 88; iter: 0; batch classifier loss: 0.338883; batch adversarial loss: 0.560369\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432009; batch adversarial loss: 0.476930\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370057; batch adversarial loss: 0.614175\n",
      "epoch 91; iter: 0; batch classifier loss: 0.339373; batch adversarial loss: 0.556933\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417572; batch adversarial loss: 0.611711\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379174; batch adversarial loss: 0.594886\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365317; batch adversarial loss: 0.592188\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399593; batch adversarial loss: 0.652527\n",
      "epoch 96; iter: 0; batch classifier loss: 0.288626; batch adversarial loss: 0.607158\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386752; batch adversarial loss: 0.578147\n",
      "epoch 98; iter: 0; batch classifier loss: 0.407130; batch adversarial loss: 0.618764\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358407; batch adversarial loss: 0.530393\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368540; batch adversarial loss: 0.544115\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353079; batch adversarial loss: 0.559884\n",
      "epoch 102; iter: 0; batch classifier loss: 0.405633; batch adversarial loss: 0.656724\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364426; batch adversarial loss: 0.641547\n",
      "epoch 104; iter: 0; batch classifier loss: 0.319000; batch adversarial loss: 0.519332\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368859; batch adversarial loss: 0.561408\n",
      "epoch 106; iter: 0; batch classifier loss: 0.318097; batch adversarial loss: 0.494695\n",
      "epoch 107; iter: 0; batch classifier loss: 0.264693; batch adversarial loss: 0.585770\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371685; batch adversarial loss: 0.588716\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412750; batch adversarial loss: 0.526442\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381511; batch adversarial loss: 0.623213\n",
      "epoch 111; iter: 0; batch classifier loss: 0.323011; batch adversarial loss: 0.543740\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372684; batch adversarial loss: 0.596296\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358230; batch adversarial loss: 0.509437\n",
      "epoch 114; iter: 0; batch classifier loss: 0.333063; batch adversarial loss: 0.526186\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405817; batch adversarial loss: 0.537552\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427686; batch adversarial loss: 0.495185\n",
      "epoch 117; iter: 0; batch classifier loss: 0.392176; batch adversarial loss: 0.568733\n",
      "epoch 118; iter: 0; batch classifier loss: 0.459958; batch adversarial loss: 0.519794\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408993; batch adversarial loss: 0.542110\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422167; batch adversarial loss: 0.526446\n",
      "epoch 121; iter: 0; batch classifier loss: 0.407487; batch adversarial loss: 0.576673\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380416; batch adversarial loss: 0.608108\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347526; batch adversarial loss: 0.546221\n",
      "epoch 124; iter: 0; batch classifier loss: 0.394013; batch adversarial loss: 0.507852\n",
      "epoch 125; iter: 0; batch classifier loss: 0.336606; batch adversarial loss: 0.571131\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338144; batch adversarial loss: 0.613396\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387718; batch adversarial loss: 0.545640\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366208; batch adversarial loss: 0.570555\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342732; batch adversarial loss: 0.532810\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339922; batch adversarial loss: 0.478236\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340696; batch adversarial loss: 0.559071\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406320; batch adversarial loss: 0.531446\n",
      "epoch 133; iter: 0; batch classifier loss: 0.296585; batch adversarial loss: 0.623853\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356435; batch adversarial loss: 0.552410\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402885; batch adversarial loss: 0.559421\n",
      "epoch 136; iter: 0; batch classifier loss: 0.289080; batch adversarial loss: 0.649028\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366012; batch adversarial loss: 0.554884\n",
      "epoch 138; iter: 0; batch classifier loss: 0.319833; batch adversarial loss: 0.544264\n",
      "epoch 139; iter: 0; batch classifier loss: 0.339836; batch adversarial loss: 0.561899\n",
      "epoch 140; iter: 0; batch classifier loss: 0.476422; batch adversarial loss: 0.549609\n",
      "epoch 141; iter: 0; batch classifier loss: 0.280432; batch adversarial loss: 0.486769\n",
      "epoch 142; iter: 0; batch classifier loss: 0.449282; batch adversarial loss: 0.578611\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397661; batch adversarial loss: 0.576090\n",
      "epoch 144; iter: 0; batch classifier loss: 0.446367; batch adversarial loss: 0.556450\n",
      "epoch 145; iter: 0; batch classifier loss: 0.300258; batch adversarial loss: 0.568991\n",
      "epoch 146; iter: 0; batch classifier loss: 0.443412; batch adversarial loss: 0.621661\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376216; batch adversarial loss: 0.486692\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367339; batch adversarial loss: 0.587593\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368209; batch adversarial loss: 0.458008\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339046; batch adversarial loss: 0.540023\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309491; batch adversarial loss: 0.526957\n",
      "epoch 152; iter: 0; batch classifier loss: 0.312811; batch adversarial loss: 0.551341\n",
      "epoch 153; iter: 0; batch classifier loss: 0.476285; batch adversarial loss: 0.579774\n",
      "epoch 154; iter: 0; batch classifier loss: 0.288515; batch adversarial loss: 0.502032\n",
      "epoch 155; iter: 0; batch classifier loss: 0.378754; batch adversarial loss: 0.621371\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336665; batch adversarial loss: 0.534630\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330497; batch adversarial loss: 0.511212\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425439; batch adversarial loss: 0.535217\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354847; batch adversarial loss: 0.524591\n",
      "epoch 160; iter: 0; batch classifier loss: 0.399015; batch adversarial loss: 0.570770\n",
      "epoch 161; iter: 0; batch classifier loss: 0.289997; batch adversarial loss: 0.562822\n",
      "epoch 162; iter: 0; batch classifier loss: 0.406801; batch adversarial loss: 0.687939\n",
      "epoch 163; iter: 0; batch classifier loss: 0.409855; batch adversarial loss: 0.582657\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305251; batch adversarial loss: 0.573944\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392399; batch adversarial loss: 0.537141\n",
      "epoch 166; iter: 0; batch classifier loss: 0.405786; batch adversarial loss: 0.536258\n",
      "epoch 167; iter: 0; batch classifier loss: 0.327505; batch adversarial loss: 0.563618\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308313; batch adversarial loss: 0.550905\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333081; batch adversarial loss: 0.546119\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355076; batch adversarial loss: 0.683933\n",
      "epoch 171; iter: 0; batch classifier loss: 0.414507; batch adversarial loss: 0.489917\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332369; batch adversarial loss: 0.622264\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375494; batch adversarial loss: 0.604344\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311473; batch adversarial loss: 0.622842\n",
      "epoch 175; iter: 0; batch classifier loss: 0.367348; batch adversarial loss: 0.607448\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297434; batch adversarial loss: 0.576917\n",
      "epoch 177; iter: 0; batch classifier loss: 0.368149; batch adversarial loss: 0.507517\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347342; batch adversarial loss: 0.527736\n",
      "epoch 179; iter: 0; batch classifier loss: 0.453634; batch adversarial loss: 0.615131\n",
      "epoch 180; iter: 0; batch classifier loss: 0.348231; batch adversarial loss: 0.596875\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349200; batch adversarial loss: 0.565239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.402918; batch adversarial loss: 0.586431\n",
      "epoch 183; iter: 0; batch classifier loss: 0.307892; batch adversarial loss: 0.510707\n",
      "epoch 184; iter: 0; batch classifier loss: 0.340000; batch adversarial loss: 0.501444\n",
      "epoch 185; iter: 0; batch classifier loss: 0.407992; batch adversarial loss: 0.613972\n",
      "epoch 186; iter: 0; batch classifier loss: 0.397547; batch adversarial loss: 0.620462\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395867; batch adversarial loss: 0.594549\n",
      "epoch 188; iter: 0; batch classifier loss: 0.257449; batch adversarial loss: 0.533384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404283; batch adversarial loss: 0.580411\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338663; batch adversarial loss: 0.585506\n",
      "epoch 191; iter: 0; batch classifier loss: 0.406191; batch adversarial loss: 0.535661\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323797; batch adversarial loss: 0.508894\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300100; batch adversarial loss: 0.468828\n",
      "epoch 194; iter: 0; batch classifier loss: 0.320566; batch adversarial loss: 0.568377\n",
      "epoch 195; iter: 0; batch classifier loss: 0.283793; batch adversarial loss: 0.521405\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368052; batch adversarial loss: 0.527559\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361437; batch adversarial loss: 0.586657\n",
      "epoch 198; iter: 0; batch classifier loss: 0.310524; batch adversarial loss: 0.495229\n",
      "epoch 199; iter: 0; batch classifier loss: 0.286157; batch adversarial loss: 0.492987\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676746; batch adversarial loss: 0.812307\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614766; batch adversarial loss: 0.776162\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569105; batch adversarial loss: 0.703316\n",
      "epoch 3; iter: 0; batch classifier loss: 0.517929; batch adversarial loss: 0.686989\n",
      "epoch 4; iter: 0; batch classifier loss: 0.540050; batch adversarial loss: 0.664846\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592754; batch adversarial loss: 0.640090\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564507; batch adversarial loss: 0.634300\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504476; batch adversarial loss: 0.652931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578700; batch adversarial loss: 0.601847\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576735; batch adversarial loss: 0.604893\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480563; batch adversarial loss: 0.564210\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498925; batch adversarial loss: 0.616181\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515787; batch adversarial loss: 0.567491\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461571; batch adversarial loss: 0.535680\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576149; batch adversarial loss: 0.564109\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509933; batch adversarial loss: 0.604846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452349; batch adversarial loss: 0.543305\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552056; batch adversarial loss: 0.534919\n",
      "epoch 18; iter: 0; batch classifier loss: 0.536923; batch adversarial loss: 0.579099\n",
      "epoch 19; iter: 0; batch classifier loss: 0.579331; batch adversarial loss: 0.552053\n",
      "epoch 20; iter: 0; batch classifier loss: 0.420148; batch adversarial loss: 0.482645\n",
      "epoch 21; iter: 0; batch classifier loss: 0.534674; batch adversarial loss: 0.576811\n",
      "epoch 22; iter: 0; batch classifier loss: 0.558305; batch adversarial loss: 0.552490\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486773; batch adversarial loss: 0.550073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491592; batch adversarial loss: 0.605431\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446984; batch adversarial loss: 0.548846\n",
      "epoch 26; iter: 0; batch classifier loss: 0.395186; batch adversarial loss: 0.574943\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481245; batch adversarial loss: 0.521009\n",
      "epoch 28; iter: 0; batch classifier loss: 0.540580; batch adversarial loss: 0.489353\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447310; batch adversarial loss: 0.543670\n",
      "epoch 30; iter: 0; batch classifier loss: 0.534695; batch adversarial loss: 0.516332\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481632; batch adversarial loss: 0.590837\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462027; batch adversarial loss: 0.552788\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452798; batch adversarial loss: 0.630069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459740; batch adversarial loss: 0.601034\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470948; batch adversarial loss: 0.554919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459661; batch adversarial loss: 0.528912\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451771; batch adversarial loss: 0.630141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.499141; batch adversarial loss: 0.468066\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414471; batch adversarial loss: 0.597451\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448979; batch adversarial loss: 0.578216\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441059; batch adversarial loss: 0.546787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457882; batch adversarial loss: 0.527651\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478109; batch adversarial loss: 0.580969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418771; batch adversarial loss: 0.598662\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419112; batch adversarial loss: 0.572466\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434996; batch adversarial loss: 0.465171\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398432; batch adversarial loss: 0.553018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451665; batch adversarial loss: 0.534976\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411908; batch adversarial loss: 0.569660\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449941; batch adversarial loss: 0.456852\n",
      "epoch 51; iter: 0; batch classifier loss: 0.452595; batch adversarial loss: 0.483850\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429711; batch adversarial loss: 0.598195\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424959; batch adversarial loss: 0.587213\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395560; batch adversarial loss: 0.552972\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479516; batch adversarial loss: 0.528143\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466621; batch adversarial loss: 0.578049\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405343; batch adversarial loss: 0.545384\n",
      "epoch 58; iter: 0; batch classifier loss: 0.370645; batch adversarial loss: 0.590375\n",
      "epoch 59; iter: 0; batch classifier loss: 0.472046; batch adversarial loss: 0.508736\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383906; batch adversarial loss: 0.570565\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424691; batch adversarial loss: 0.579889\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407982; batch adversarial loss: 0.518264\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419436; batch adversarial loss: 0.482315\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371159; batch adversarial loss: 0.535480\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435480; batch adversarial loss: 0.452767\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421832; batch adversarial loss: 0.528295\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426167; batch adversarial loss: 0.597303\n",
      "epoch 68; iter: 0; batch classifier loss: 0.374414; batch adversarial loss: 0.651906\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411994; batch adversarial loss: 0.518695\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417790; batch adversarial loss: 0.579289\n",
      "epoch 71; iter: 0; batch classifier loss: 0.356184; batch adversarial loss: 0.517171\n",
      "epoch 72; iter: 0; batch classifier loss: 0.431603; batch adversarial loss: 0.526310\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403932; batch adversarial loss: 0.535518\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374110; batch adversarial loss: 0.517952\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370267; batch adversarial loss: 0.508679\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386248; batch adversarial loss: 0.527038\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374328; batch adversarial loss: 0.580809\n",
      "epoch 78; iter: 0; batch classifier loss: 0.403234; batch adversarial loss: 0.471439\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356124; batch adversarial loss: 0.489966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.468572; batch adversarial loss: 0.634951\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385914; batch adversarial loss: 0.508806\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366018; batch adversarial loss: 0.526445\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397111; batch adversarial loss: 0.563039\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378541; batch adversarial loss: 0.472430\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434940; batch adversarial loss: 0.544231\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399279; batch adversarial loss: 0.535567\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362698; batch adversarial loss: 0.597585\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375463; batch adversarial loss: 0.600199\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396302; batch adversarial loss: 0.553833\n",
      "epoch 90; iter: 0; batch classifier loss: 0.442831; batch adversarial loss: 0.518365\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391370; batch adversarial loss: 0.560524\n",
      "epoch 92; iter: 0; batch classifier loss: 0.423939; batch adversarial loss: 0.553849\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437546; batch adversarial loss: 0.534255\n",
      "epoch 94; iter: 0; batch classifier loss: 0.320809; batch adversarial loss: 0.610024\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345093; batch adversarial loss: 0.581448\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418642; batch adversarial loss: 0.528082\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372518; batch adversarial loss: 0.506558\n",
      "epoch 98; iter: 0; batch classifier loss: 0.448613; batch adversarial loss: 0.588695\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422135; batch adversarial loss: 0.597610\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358723; batch adversarial loss: 0.554028\n",
      "epoch 101; iter: 0; batch classifier loss: 0.329766; batch adversarial loss: 0.500201\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371808; batch adversarial loss: 0.579524\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413811; batch adversarial loss: 0.536251\n",
      "epoch 104; iter: 0; batch classifier loss: 0.342175; batch adversarial loss: 0.617636\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348404; batch adversarial loss: 0.516603\n",
      "epoch 106; iter: 0; batch classifier loss: 0.431496; batch adversarial loss: 0.579657\n",
      "epoch 107; iter: 0; batch classifier loss: 0.313630; batch adversarial loss: 0.445775\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366339; batch adversarial loss: 0.571012\n",
      "epoch 109; iter: 0; batch classifier loss: 0.449187; batch adversarial loss: 0.527856\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357117; batch adversarial loss: 0.590784\n",
      "epoch 111; iter: 0; batch classifier loss: 0.438327; batch adversarial loss: 0.534654\n",
      "epoch 112; iter: 0; batch classifier loss: 0.440569; batch adversarial loss: 0.555517\n",
      "epoch 113; iter: 0; batch classifier loss: 0.478496; batch adversarial loss: 0.607111\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357502; batch adversarial loss: 0.570318\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363282; batch adversarial loss: 0.606217\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348351; batch adversarial loss: 0.482765\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374703; batch adversarial loss: 0.490003\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357735; batch adversarial loss: 0.633643\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394390; batch adversarial loss: 0.535157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.414311; batch adversarial loss: 0.491538\n",
      "epoch 121; iter: 0; batch classifier loss: 0.328728; batch adversarial loss: 0.490229\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396800; batch adversarial loss: 0.560400\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354137; batch adversarial loss: 0.533205\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401365; batch adversarial loss: 0.552364\n",
      "epoch 125; iter: 0; batch classifier loss: 0.418872; batch adversarial loss: 0.587584\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391734; batch adversarial loss: 0.527878\n",
      "epoch 127; iter: 0; batch classifier loss: 0.414326; batch adversarial loss: 0.678746\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343288; batch adversarial loss: 0.563743\n",
      "epoch 129; iter: 0; batch classifier loss: 0.407132; batch adversarial loss: 0.563811\n",
      "epoch 130; iter: 0; batch classifier loss: 0.344646; batch adversarial loss: 0.618073\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348211; batch adversarial loss: 0.551872\n",
      "epoch 132; iter: 0; batch classifier loss: 0.339365; batch adversarial loss: 0.661140\n",
      "epoch 133; iter: 0; batch classifier loss: 0.468136; batch adversarial loss: 0.455174\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397241; batch adversarial loss: 0.524695\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399004; batch adversarial loss: 0.558623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.447796; batch adversarial loss: 0.544494\n",
      "epoch 137; iter: 0; batch classifier loss: 0.409527; batch adversarial loss: 0.546515\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376490; batch adversarial loss: 0.573419\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338602; batch adversarial loss: 0.570378\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357517; batch adversarial loss: 0.577813\n",
      "epoch 141; iter: 0; batch classifier loss: 0.289460; batch adversarial loss: 0.581149\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364691; batch adversarial loss: 0.437066\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397625; batch adversarial loss: 0.516803\n",
      "epoch 144; iter: 0; batch classifier loss: 0.448246; batch adversarial loss: 0.551917\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353752; batch adversarial loss: 0.568789\n",
      "epoch 146; iter: 0; batch classifier loss: 0.402641; batch adversarial loss: 0.482145\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404200; batch adversarial loss: 0.580384\n",
      "epoch 148; iter: 0; batch classifier loss: 0.372681; batch adversarial loss: 0.511099\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392785; batch adversarial loss: 0.479817\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361716; batch adversarial loss: 0.516078\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340689; batch adversarial loss: 0.632896\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362792; batch adversarial loss: 0.572643\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356595; batch adversarial loss: 0.526131\n",
      "epoch 154; iter: 0; batch classifier loss: 0.311157; batch adversarial loss: 0.563658\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365328; batch adversarial loss: 0.572172\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363498; batch adversarial loss: 0.559745\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356545; batch adversarial loss: 0.480912\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398818; batch adversarial loss: 0.536166\n",
      "epoch 159; iter: 0; batch classifier loss: 0.480060; batch adversarial loss: 0.490474\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381965; batch adversarial loss: 0.618249\n",
      "epoch 161; iter: 0; batch classifier loss: 0.422441; batch adversarial loss: 0.561637\n",
      "epoch 162; iter: 0; batch classifier loss: 0.319196; batch adversarial loss: 0.489021\n",
      "epoch 163; iter: 0; batch classifier loss: 0.463362; batch adversarial loss: 0.583279\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402712; batch adversarial loss: 0.544605\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424700; batch adversarial loss: 0.553734\n",
      "epoch 166; iter: 0; batch classifier loss: 0.442132; batch adversarial loss: 0.607352\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366915; batch adversarial loss: 0.545942\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.579617\n",
      "epoch 169; iter: 0; batch classifier loss: 0.311336; batch adversarial loss: 0.563682\n",
      "epoch 170; iter: 0; batch classifier loss: 0.267980; batch adversarial loss: 0.543495\n",
      "epoch 171; iter: 0; batch classifier loss: 0.352826; batch adversarial loss: 0.536700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351456; batch adversarial loss: 0.545188\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371630; batch adversarial loss: 0.570002\n",
      "epoch 174; iter: 0; batch classifier loss: 0.446329; batch adversarial loss: 0.571800\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362385; batch adversarial loss: 0.544967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.374939; batch adversarial loss: 0.578830\n",
      "epoch 177; iter: 0; batch classifier loss: 0.421744; batch adversarial loss: 0.579088\n",
      "epoch 178; iter: 0; batch classifier loss: 0.359228; batch adversarial loss: 0.517836\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359090; batch adversarial loss: 0.499812\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390126; batch adversarial loss: 0.533076\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364142; batch adversarial loss: 0.581257\n",
      "epoch 182; iter: 0; batch classifier loss: 0.451585; batch adversarial loss: 0.587622\n",
      "epoch 183; iter: 0; batch classifier loss: 0.431988; batch adversarial loss: 0.580960\n",
      "epoch 184; iter: 0; batch classifier loss: 0.442368; batch adversarial loss: 0.510035\n",
      "epoch 185; iter: 0; batch classifier loss: 0.419020; batch adversarial loss: 0.491126\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341897; batch adversarial loss: 0.609102\n",
      "epoch 187; iter: 0; batch classifier loss: 0.420040; batch adversarial loss: 0.550153\n",
      "epoch 188; iter: 0; batch classifier loss: 0.439680; batch adversarial loss: 0.534051\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309880; batch adversarial loss: 0.482602\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400420; batch adversarial loss: 0.563367\n",
      "epoch 191; iter: 0; batch classifier loss: 0.332968; batch adversarial loss: 0.498745\n",
      "epoch 192; iter: 0; batch classifier loss: 0.402476; batch adversarial loss: 0.553702\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343287; batch adversarial loss: 0.555065\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325646; batch adversarial loss: 0.534524\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349598; batch adversarial loss: 0.533688\n",
      "epoch 196; iter: 0; batch classifier loss: 0.446040; batch adversarial loss: 0.545137\n",
      "epoch 197; iter: 0; batch classifier loss: 0.450436; batch adversarial loss: 0.544196\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382648; batch adversarial loss: 0.517212\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379199; batch adversarial loss: 0.607602\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699297; batch adversarial loss: 0.868117\n",
      "epoch 1; iter: 0; batch classifier loss: 0.783333; batch adversarial loss: 0.920019\n",
      "epoch 2; iter: 0; batch classifier loss: 1.005684; batch adversarial loss: 0.925722\n",
      "epoch 3; iter: 0; batch classifier loss: 0.999053; batch adversarial loss: 0.838718\n",
      "epoch 4; iter: 0; batch classifier loss: 0.876780; batch adversarial loss: 0.758880\n",
      "epoch 5; iter: 0; batch classifier loss: 0.787344; batch adversarial loss: 0.695714\n",
      "epoch 6; iter: 0; batch classifier loss: 0.714340; batch adversarial loss: 0.636710\n",
      "epoch 7; iter: 0; batch classifier loss: 0.621647; batch adversarial loss: 0.623808\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587638; batch adversarial loss: 0.600248\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524490; batch adversarial loss: 0.590917\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582383; batch adversarial loss: 0.609127\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521959; batch adversarial loss: 0.585797\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510714; batch adversarial loss: 0.591500\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535926; batch adversarial loss: 0.549634\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517576; batch adversarial loss: 0.604690\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468204; batch adversarial loss: 0.579879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501272; batch adversarial loss: 0.577117\n",
      "epoch 17; iter: 0; batch classifier loss: 0.564970; batch adversarial loss: 0.586125\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519399; batch adversarial loss: 0.539040\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509135; batch adversarial loss: 0.569357\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432997; batch adversarial loss: 0.532535\n",
      "epoch 21; iter: 0; batch classifier loss: 0.570954; batch adversarial loss: 0.514333\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484643; batch adversarial loss: 0.491935\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452194; batch adversarial loss: 0.492369\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506158; batch adversarial loss: 0.576067\n",
      "epoch 25; iter: 0; batch classifier loss: 0.551961; batch adversarial loss: 0.540849\n",
      "epoch 26; iter: 0; batch classifier loss: 0.521856; batch adversarial loss: 0.593699\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427759; batch adversarial loss: 0.520633\n",
      "epoch 28; iter: 0; batch classifier loss: 0.497220; batch adversarial loss: 0.503307\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468484; batch adversarial loss: 0.515655\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478078; batch adversarial loss: 0.587913\n",
      "epoch 31; iter: 0; batch classifier loss: 0.478038; batch adversarial loss: 0.512256\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472134; batch adversarial loss: 0.557497\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458588; batch adversarial loss: 0.548775\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449118; batch adversarial loss: 0.583881\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467061; batch adversarial loss: 0.505019\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400172; batch adversarial loss: 0.561487\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489880; batch adversarial loss: 0.580391\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484574; batch adversarial loss: 0.606190\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419483; batch adversarial loss: 0.548955\n",
      "epoch 40; iter: 0; batch classifier loss: 0.511315; batch adversarial loss: 0.509002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422735; batch adversarial loss: 0.560188\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471301; batch adversarial loss: 0.553342\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406682; batch adversarial loss: 0.561851\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434490; batch adversarial loss: 0.518094\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382930; batch adversarial loss: 0.664770\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409898; batch adversarial loss: 0.596390\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471441; batch adversarial loss: 0.517812\n",
      "epoch 48; iter: 0; batch classifier loss: 0.498433; batch adversarial loss: 0.556146\n",
      "epoch 49; iter: 0; batch classifier loss: 0.486358; batch adversarial loss: 0.480189\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428734; batch adversarial loss: 0.461128\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428113; batch adversarial loss: 0.672901\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462121; batch adversarial loss: 0.481307\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461318; batch adversarial loss: 0.590440\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431261; batch adversarial loss: 0.488427\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376033; batch adversarial loss: 0.588088\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425915; batch adversarial loss: 0.574380\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456620; batch adversarial loss: 0.541418\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448016; batch adversarial loss: 0.561803\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464336; batch adversarial loss: 0.564994\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456086; batch adversarial loss: 0.479522\n",
      "epoch 61; iter: 0; batch classifier loss: 0.535318; batch adversarial loss: 0.608106\n",
      "epoch 62; iter: 0; batch classifier loss: 0.360906; batch adversarial loss: 0.569319\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374624; batch adversarial loss: 0.597120\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394096; batch adversarial loss: 0.472290\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403478; batch adversarial loss: 0.582181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445637; batch adversarial loss: 0.552241\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420586; batch adversarial loss: 0.502749\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426218; batch adversarial loss: 0.578472\n",
      "epoch 69; iter: 0; batch classifier loss: 0.471571; batch adversarial loss: 0.601132\n",
      "epoch 70; iter: 0; batch classifier loss: 0.341165; batch adversarial loss: 0.559991\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392461; batch adversarial loss: 0.546047\n",
      "epoch 72; iter: 0; batch classifier loss: 0.338151; batch adversarial loss: 0.507674\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418778; batch adversarial loss: 0.501353\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433530; batch adversarial loss: 0.517293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.437814; batch adversarial loss: 0.542587\n",
      "epoch 76; iter: 0; batch classifier loss: 0.334164; batch adversarial loss: 0.514721\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400808; batch adversarial loss: 0.601002\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389334; batch adversarial loss: 0.517584\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389957; batch adversarial loss: 0.526807\n",
      "epoch 80; iter: 0; batch classifier loss: 0.475459; batch adversarial loss: 0.496008\n",
      "epoch 81; iter: 0; batch classifier loss: 0.436956; batch adversarial loss: 0.518299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.341383; batch adversarial loss: 0.573396\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396045; batch adversarial loss: 0.461257\n",
      "epoch 84; iter: 0; batch classifier loss: 0.345430; batch adversarial loss: 0.656403\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369031; batch adversarial loss: 0.470109\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403157; batch adversarial loss: 0.526702\n",
      "epoch 87; iter: 0; batch classifier loss: 0.349036; batch adversarial loss: 0.518034\n",
      "epoch 88; iter: 0; batch classifier loss: 0.327016; batch adversarial loss: 0.609366\n",
      "epoch 89; iter: 0; batch classifier loss: 0.336271; batch adversarial loss: 0.543065\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376130; batch adversarial loss: 0.570302\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460180; batch adversarial loss: 0.589064\n",
      "epoch 92; iter: 0; batch classifier loss: 0.338938; batch adversarial loss: 0.461770\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407248; batch adversarial loss: 0.604801\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436509; batch adversarial loss: 0.569106\n",
      "epoch 95; iter: 0; batch classifier loss: 0.433765; batch adversarial loss: 0.514643\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354177; batch adversarial loss: 0.551044\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388497; batch adversarial loss: 0.569348\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388673; batch adversarial loss: 0.607391\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415116; batch adversarial loss: 0.576348\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347374; batch adversarial loss: 0.611603\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398166; batch adversarial loss: 0.551732\n",
      "epoch 102; iter: 0; batch classifier loss: 0.482482; batch adversarial loss: 0.554521\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395822; batch adversarial loss: 0.480563\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419302; batch adversarial loss: 0.587202\n",
      "epoch 105; iter: 0; batch classifier loss: 0.356625; batch adversarial loss: 0.568210\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388830; batch adversarial loss: 0.498349\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358076; batch adversarial loss: 0.524676\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417931; batch adversarial loss: 0.572050\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375391; batch adversarial loss: 0.543254\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384436; batch adversarial loss: 0.460082\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347717; batch adversarial loss: 0.582244\n",
      "epoch 112; iter: 0; batch classifier loss: 0.342770; batch adversarial loss: 0.591982\n",
      "epoch 113; iter: 0; batch classifier loss: 0.349447; batch adversarial loss: 0.536739\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394859; batch adversarial loss: 0.517728\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358813; batch adversarial loss: 0.526487\n",
      "epoch 116; iter: 0; batch classifier loss: 0.389458; batch adversarial loss: 0.589246\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374393; batch adversarial loss: 0.571683\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397430; batch adversarial loss: 0.553503\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369389; batch adversarial loss: 0.553530\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371660; batch adversarial loss: 0.572236\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307207; batch adversarial loss: 0.470829\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395489; batch adversarial loss: 0.562472\n",
      "epoch 123; iter: 0; batch classifier loss: 0.402632; batch adversarial loss: 0.562965\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359992; batch adversarial loss: 0.535331\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400455; batch adversarial loss: 0.542809\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404335; batch adversarial loss: 0.580864\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397331; batch adversarial loss: 0.589324\n",
      "epoch 128; iter: 0; batch classifier loss: 0.299997; batch adversarial loss: 0.534744\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377996; batch adversarial loss: 0.628876\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322470; batch adversarial loss: 0.534366\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391607; batch adversarial loss: 0.528339\n",
      "epoch 132; iter: 0; batch classifier loss: 0.323300; batch adversarial loss: 0.488789\n",
      "epoch 133; iter: 0; batch classifier loss: 0.432079; batch adversarial loss: 0.573533\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381267; batch adversarial loss: 0.498857\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363429; batch adversarial loss: 0.507934\n",
      "epoch 136; iter: 0; batch classifier loss: 0.351757; batch adversarial loss: 0.498553\n",
      "epoch 137; iter: 0; batch classifier loss: 0.459432; batch adversarial loss: 0.472259\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343293; batch adversarial loss: 0.508356\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384227; batch adversarial loss: 0.616751\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411287; batch adversarial loss: 0.471438\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367544; batch adversarial loss: 0.608906\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331087; batch adversarial loss: 0.562543\n",
      "epoch 143; iter: 0; batch classifier loss: 0.324191; batch adversarial loss: 0.609705\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401075; batch adversarial loss: 0.571152\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409616; batch adversarial loss: 0.600211\n",
      "epoch 146; iter: 0; batch classifier loss: 0.253691; batch adversarial loss: 0.533293\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344459; batch adversarial loss: 0.561719\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344668; batch adversarial loss: 0.552740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.327144; batch adversarial loss: 0.503557\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339313; batch adversarial loss: 0.479616\n",
      "epoch 151; iter: 0; batch classifier loss: 0.329088; batch adversarial loss: 0.544635\n",
      "epoch 152; iter: 0; batch classifier loss: 0.396210; batch adversarial loss: 0.536756\n",
      "epoch 153; iter: 0; batch classifier loss: 0.425812; batch adversarial loss: 0.534571\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329510; batch adversarial loss: 0.584018\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352601; batch adversarial loss: 0.616741\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399497; batch adversarial loss: 0.601536\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326544; batch adversarial loss: 0.508367\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362523; batch adversarial loss: 0.544286\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360676; batch adversarial loss: 0.505789\n",
      "epoch 160; iter: 0; batch classifier loss: 0.298398; batch adversarial loss: 0.607610\n",
      "epoch 161; iter: 0; batch classifier loss: 0.353727; batch adversarial loss: 0.563738\n",
      "epoch 162; iter: 0; batch classifier loss: 0.439522; batch adversarial loss: 0.526266\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334045; batch adversarial loss: 0.562709\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378013; batch adversarial loss: 0.562865\n",
      "epoch 165; iter: 0; batch classifier loss: 0.404451; batch adversarial loss: 0.599397\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301989; batch adversarial loss: 0.517440\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348615; batch adversarial loss: 0.544722\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373532; batch adversarial loss: 0.563102\n",
      "epoch 169; iter: 0; batch classifier loss: 0.286054; batch adversarial loss: 0.517042\n",
      "epoch 170; iter: 0; batch classifier loss: 0.446549; batch adversarial loss: 0.608839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.291110; batch adversarial loss: 0.554077\n",
      "epoch 172; iter: 0; batch classifier loss: 0.245942; batch adversarial loss: 0.507521\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345321; batch adversarial loss: 0.498412\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393572; batch adversarial loss: 0.599586\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409038; batch adversarial loss: 0.458779\n",
      "epoch 176; iter: 0; batch classifier loss: 0.416420; batch adversarial loss: 0.524045\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335395; batch adversarial loss: 0.543898\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309476; batch adversarial loss: 0.607742\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380710; batch adversarial loss: 0.586266\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340862; batch adversarial loss: 0.503318\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333177; batch adversarial loss: 0.544333\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352573; batch adversarial loss: 0.522350\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378604; batch adversarial loss: 0.572856\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335185; batch adversarial loss: 0.441473\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311300; batch adversarial loss: 0.532860\n",
      "epoch 186; iter: 0; batch classifier loss: 0.298993; batch adversarial loss: 0.623118\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314183; batch adversarial loss: 0.528666\n",
      "epoch 188; iter: 0; batch classifier loss: 0.442503; batch adversarial loss: 0.490124\n",
      "epoch 189; iter: 0; batch classifier loss: 0.363787; batch adversarial loss: 0.589512\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326080; batch adversarial loss: 0.520159\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336777; batch adversarial loss: 0.574332\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305569; batch adversarial loss: 0.634566\n",
      "epoch 193; iter: 0; batch classifier loss: 0.417586; batch adversarial loss: 0.553895\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350628; batch adversarial loss: 0.589577\n",
      "epoch 195; iter: 0; batch classifier loss: 0.345574; batch adversarial loss: 0.598235\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380291; batch adversarial loss: 0.580724\n",
      "epoch 197; iter: 0; batch classifier loss: 0.400134; batch adversarial loss: 0.499525\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349760; batch adversarial loss: 0.662340\n",
      "epoch 199; iter: 0; batch classifier loss: 0.277501; batch adversarial loss: 0.580797\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703726; batch adversarial loss: 0.767014\n",
      "epoch 1; iter: 0; batch classifier loss: 0.680114; batch adversarial loss: 0.710315\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627800; batch adversarial loss: 0.653199\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618120; batch adversarial loss: 0.659254\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531222; batch adversarial loss: 0.608529\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602556; batch adversarial loss: 0.638999\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612598; batch adversarial loss: 0.590412\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490217; batch adversarial loss: 0.585481\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522169; batch adversarial loss: 0.604404\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466792; batch adversarial loss: 0.597010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545462; batch adversarial loss: 0.645071\n",
      "epoch 11; iter: 0; batch classifier loss: 0.466961; batch adversarial loss: 0.590810\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491762; batch adversarial loss: 0.572128\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540430; batch adversarial loss: 0.625544\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513390; batch adversarial loss: 0.644819\n",
      "epoch 15; iter: 0; batch classifier loss: 0.603692; batch adversarial loss: 0.653701\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532936; batch adversarial loss: 0.592080\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481599; batch adversarial loss: 0.616346\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508575; batch adversarial loss: 0.627979\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463803; batch adversarial loss: 0.566194\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492671; batch adversarial loss: 0.626783\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439450; batch adversarial loss: 0.568503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479905; batch adversarial loss: 0.565340\n",
      "epoch 23; iter: 0; batch classifier loss: 0.503725; batch adversarial loss: 0.613140\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491884; batch adversarial loss: 0.556520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428614; batch adversarial loss: 0.582646\n",
      "epoch 26; iter: 0; batch classifier loss: 0.430429; batch adversarial loss: 0.582080\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485501; batch adversarial loss: 0.580455\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457207; batch adversarial loss: 0.527761\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461207; batch adversarial loss: 0.535702\n",
      "epoch 30; iter: 0; batch classifier loss: 0.399734; batch adversarial loss: 0.568804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.621777; batch adversarial loss: 0.548724\n",
      "epoch 32; iter: 0; batch classifier loss: 0.538807; batch adversarial loss: 0.560067\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404990; batch adversarial loss: 0.614395\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440464; batch adversarial loss: 0.535191\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464133; batch adversarial loss: 0.511085\n",
      "epoch 36; iter: 0; batch classifier loss: 0.416552; batch adversarial loss: 0.582579\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465112; batch adversarial loss: 0.579422\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465348; batch adversarial loss: 0.553950\n",
      "epoch 39; iter: 0; batch classifier loss: 0.398340; batch adversarial loss: 0.620946\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422118; batch adversarial loss: 0.528263\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448260; batch adversarial loss: 0.545480\n",
      "epoch 42; iter: 0; batch classifier loss: 0.554319; batch adversarial loss: 0.510827\n",
      "epoch 43; iter: 0; batch classifier loss: 0.519806; batch adversarial loss: 0.536204\n",
      "epoch 44; iter: 0; batch classifier loss: 0.364276; batch adversarial loss: 0.596791\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453917; batch adversarial loss: 0.553658\n",
      "epoch 46; iter: 0; batch classifier loss: 0.512643; batch adversarial loss: 0.553841\n",
      "epoch 47; iter: 0; batch classifier loss: 0.498828; batch adversarial loss: 0.527433\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434568; batch adversarial loss: 0.605766\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466085; batch adversarial loss: 0.553910\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435289; batch adversarial loss: 0.501642\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431579; batch adversarial loss: 0.536535\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440215; batch adversarial loss: 0.465797\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410274; batch adversarial loss: 0.588767\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469142; batch adversarial loss: 0.641851\n",
      "epoch 55; iter: 0; batch classifier loss: 0.385497; batch adversarial loss: 0.562174\n",
      "epoch 56; iter: 0; batch classifier loss: 0.461599; batch adversarial loss: 0.570351\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411896; batch adversarial loss: 0.580427\n",
      "epoch 58; iter: 0; batch classifier loss: 0.325941; batch adversarial loss: 0.614870\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422673; batch adversarial loss: 0.482523\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407646; batch adversarial loss: 0.527653\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424748; batch adversarial loss: 0.560187\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390012; batch adversarial loss: 0.649178\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447367; batch adversarial loss: 0.571630\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413720; batch adversarial loss: 0.508130\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365485; batch adversarial loss: 0.574375\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408325; batch adversarial loss: 0.518175\n",
      "epoch 67; iter: 0; batch classifier loss: 0.357179; batch adversarial loss: 0.623952\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379939; batch adversarial loss: 0.660692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.464829; batch adversarial loss: 0.561700\n",
      "epoch 70; iter: 0; batch classifier loss: 0.401854; batch adversarial loss: 0.570682\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463456; batch adversarial loss: 0.547293\n",
      "epoch 72; iter: 0; batch classifier loss: 0.407294; batch adversarial loss: 0.614276\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442841; batch adversarial loss: 0.580362\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425151; batch adversarial loss: 0.508827\n",
      "epoch 75; iter: 0; batch classifier loss: 0.456679; batch adversarial loss: 0.542895\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369958; batch adversarial loss: 0.594874\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404618; batch adversarial loss: 0.476063\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409153; batch adversarial loss: 0.556600\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371587; batch adversarial loss: 0.509823\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367894; batch adversarial loss: 0.580403\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430886; batch adversarial loss: 0.580299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446660; batch adversarial loss: 0.589571\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369013; batch adversarial loss: 0.553264\n",
      "epoch 84; iter: 0; batch classifier loss: 0.448475; batch adversarial loss: 0.607044\n",
      "epoch 85; iter: 0; batch classifier loss: 0.417349; batch adversarial loss: 0.582127\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432084; batch adversarial loss: 0.642420\n",
      "epoch 87; iter: 0; batch classifier loss: 0.465848; batch adversarial loss: 0.570755\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400775; batch adversarial loss: 0.510017\n",
      "epoch 89; iter: 0; batch classifier loss: 0.470571; batch adversarial loss: 0.554286\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415415; batch adversarial loss: 0.562892\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382341; batch adversarial loss: 0.579074\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400515; batch adversarial loss: 0.613854\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427003; batch adversarial loss: 0.535208\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372534; batch adversarial loss: 0.536867\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343921; batch adversarial loss: 0.578246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382119; batch adversarial loss: 0.516491\n",
      "epoch 97; iter: 0; batch classifier loss: 0.449194; batch adversarial loss: 0.580637\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377407; batch adversarial loss: 0.611989\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402773; batch adversarial loss: 0.473300\n",
      "epoch 100; iter: 0; batch classifier loss: 0.470045; batch adversarial loss: 0.465254\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367285; batch adversarial loss: 0.616477\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357265; batch adversarial loss: 0.544553\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335307; batch adversarial loss: 0.575521\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421387; batch adversarial loss: 0.578736\n",
      "epoch 105; iter: 0; batch classifier loss: 0.328892; batch adversarial loss: 0.519446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398635; batch adversarial loss: 0.533389\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399221; batch adversarial loss: 0.496645\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408412; batch adversarial loss: 0.555794\n",
      "epoch 109; iter: 0; batch classifier loss: 0.447389; batch adversarial loss: 0.543208\n",
      "epoch 110; iter: 0; batch classifier loss: 0.350301; batch adversarial loss: 0.552980\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357615; batch adversarial loss: 0.668784\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387018; batch adversarial loss: 0.606642\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370139; batch adversarial loss: 0.518829\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.563676\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417855; batch adversarial loss: 0.516670\n",
      "epoch 116; iter: 0; batch classifier loss: 0.329040; batch adversarial loss: 0.657708\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377301; batch adversarial loss: 0.464588\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352114; batch adversarial loss: 0.623417\n",
      "epoch 119; iter: 0; batch classifier loss: 0.459128; batch adversarial loss: 0.499988\n",
      "epoch 120; iter: 0; batch classifier loss: 0.471736; batch adversarial loss: 0.554682\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390931; batch adversarial loss: 0.489786\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339647; batch adversarial loss: 0.543741\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351838; batch adversarial loss: 0.535714\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338874; batch adversarial loss: 0.471892\n",
      "epoch 125; iter: 0; batch classifier loss: 0.417100; batch adversarial loss: 0.509622\n",
      "epoch 126; iter: 0; batch classifier loss: 0.431487; batch adversarial loss: 0.559291\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366468; batch adversarial loss: 0.537617\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397811; batch adversarial loss: 0.632331\n",
      "epoch 129; iter: 0; batch classifier loss: 0.283180; batch adversarial loss: 0.498405\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398359; batch adversarial loss: 0.599314\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438323; batch adversarial loss: 0.551797\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405555; batch adversarial loss: 0.571419\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364788; batch adversarial loss: 0.553693\n",
      "epoch 134; iter: 0; batch classifier loss: 0.324869; batch adversarial loss: 0.482999\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362174; batch adversarial loss: 0.508852\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339754; batch adversarial loss: 0.543894\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378467; batch adversarial loss: 0.641622\n",
      "epoch 138; iter: 0; batch classifier loss: 0.422446; batch adversarial loss: 0.572542\n",
      "epoch 139; iter: 0; batch classifier loss: 0.429434; batch adversarial loss: 0.598455\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409709; batch adversarial loss: 0.526675\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356573; batch adversarial loss: 0.555481\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410656; batch adversarial loss: 0.553427\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365025; batch adversarial loss: 0.512404\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357542; batch adversarial loss: 0.525285\n",
      "epoch 145; iter: 0; batch classifier loss: 0.421299; batch adversarial loss: 0.519281\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334620; batch adversarial loss: 0.534321\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377932; batch adversarial loss: 0.554169\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410014; batch adversarial loss: 0.464505\n",
      "epoch 149; iter: 0; batch classifier loss: 0.314856; batch adversarial loss: 0.519487\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325318; batch adversarial loss: 0.561567\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350409; batch adversarial loss: 0.572308\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356466; batch adversarial loss: 0.552183\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348027; batch adversarial loss: 0.527110\n",
      "epoch 154; iter: 0; batch classifier loss: 0.301061; batch adversarial loss: 0.483532\n",
      "epoch 155; iter: 0; batch classifier loss: 0.412185; batch adversarial loss: 0.611188\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361186; batch adversarial loss: 0.507680\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369066; batch adversarial loss: 0.597649\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382045; batch adversarial loss: 0.562558\n",
      "epoch 159; iter: 0; batch classifier loss: 0.441212; batch adversarial loss: 0.527061\n",
      "epoch 160; iter: 0; batch classifier loss: 0.389238; batch adversarial loss: 0.538871\n",
      "epoch 161; iter: 0; batch classifier loss: 0.386386; batch adversarial loss: 0.493027\n",
      "epoch 162; iter: 0; batch classifier loss: 0.318393; batch adversarial loss: 0.466991\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420072; batch adversarial loss: 0.581943\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344698; batch adversarial loss: 0.546222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.350628; batch adversarial loss: 0.534516\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358121; batch adversarial loss: 0.570936\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393499; batch adversarial loss: 0.501635\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367513; batch adversarial loss: 0.570534\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385978; batch adversarial loss: 0.516287\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337956; batch adversarial loss: 0.579278\n",
      "epoch 171; iter: 0; batch classifier loss: 0.363776; batch adversarial loss: 0.579327\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378582; batch adversarial loss: 0.491365\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329053; batch adversarial loss: 0.533755\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387387; batch adversarial loss: 0.598249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.273226; batch adversarial loss: 0.447032\n",
      "epoch 176; iter: 0; batch classifier loss: 0.315936; batch adversarial loss: 0.544840\n",
      "epoch 177; iter: 0; batch classifier loss: 0.425249; batch adversarial loss: 0.553128\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407780; batch adversarial loss: 0.536281\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356052; batch adversarial loss: 0.625092\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381620; batch adversarial loss: 0.491614\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388742; batch adversarial loss: 0.508495\n",
      "epoch 182; iter: 0; batch classifier loss: 0.412254; batch adversarial loss: 0.561824\n",
      "epoch 183; iter: 0; batch classifier loss: 0.330820; batch adversarial loss: 0.563658\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416355; batch adversarial loss: 0.543777\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321783; batch adversarial loss: 0.474013\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363370; batch adversarial loss: 0.560038\n",
      "epoch 187; iter: 0; batch classifier loss: 0.290331; batch adversarial loss: 0.516836\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382769; batch adversarial loss: 0.527131\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346841; batch adversarial loss: 0.571578\n",
      "epoch 190; iter: 0; batch classifier loss: 0.388125; batch adversarial loss: 0.476148\n",
      "epoch 191; iter: 0; batch classifier loss: 0.250135; batch adversarial loss: 0.580361\n",
      "epoch 192; iter: 0; batch classifier loss: 0.444653; batch adversarial loss: 0.597552\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317972; batch adversarial loss: 0.553859\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407475; batch adversarial loss: 0.553270\n",
      "epoch 195; iter: 0; batch classifier loss: 0.446133; batch adversarial loss: 0.552567\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351109; batch adversarial loss: 0.622165\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350315; batch adversarial loss: 0.553983\n",
      "epoch 198; iter: 0; batch classifier loss: 0.415473; batch adversarial loss: 0.608605\n",
      "epoch 199; iter: 0; batch classifier loss: 0.418164; batch adversarial loss: 0.575543\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690647; batch adversarial loss: 0.726941\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718949; batch adversarial loss: 0.731162\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565103; batch adversarial loss: 0.653914\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530934; batch adversarial loss: 0.646479\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575772; batch adversarial loss: 0.605714\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536931; batch adversarial loss: 0.586835\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589507; batch adversarial loss: 0.602933\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510356; batch adversarial loss: 0.570745\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564546; batch adversarial loss: 0.538461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.483132; batch adversarial loss: 0.572352\n",
      "epoch 10; iter: 0; batch classifier loss: 0.463366; batch adversarial loss: 0.601938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530470; batch adversarial loss: 0.545657\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527340; batch adversarial loss: 0.594707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477998; batch adversarial loss: 0.542407\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465158; batch adversarial loss: 0.608170\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511493; batch adversarial loss: 0.517893\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545378; batch adversarial loss: 0.535601\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517418; batch adversarial loss: 0.528861\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453393; batch adversarial loss: 0.506400\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517808; batch adversarial loss: 0.619878\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491457; batch adversarial loss: 0.563811\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546757; batch adversarial loss: 0.511576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.570640; batch adversarial loss: 0.556514\n",
      "epoch 23; iter: 0; batch classifier loss: 0.575990; batch adversarial loss: 0.590863\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454842; batch adversarial loss: 0.524024\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489806; batch adversarial loss: 0.576981\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495410; batch adversarial loss: 0.591483\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484659; batch adversarial loss: 0.510864\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469937; batch adversarial loss: 0.592318\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439880; batch adversarial loss: 0.532188\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471036; batch adversarial loss: 0.552378\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490926; batch adversarial loss: 0.598579\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454973; batch adversarial loss: 0.581640\n",
      "epoch 33; iter: 0; batch classifier loss: 0.391785; batch adversarial loss: 0.525509\n",
      "epoch 34; iter: 0; batch classifier loss: 0.375591; batch adversarial loss: 0.552504\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451598; batch adversarial loss: 0.561868\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391742; batch adversarial loss: 0.561377\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471076; batch adversarial loss: 0.562120\n",
      "epoch 38; iter: 0; batch classifier loss: 0.539220; batch adversarial loss: 0.516545\n",
      "epoch 39; iter: 0; batch classifier loss: 0.530753; batch adversarial loss: 0.569133\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418959; batch adversarial loss: 0.464575\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459709; batch adversarial loss: 0.509761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403083; batch adversarial loss: 0.590601\n",
      "epoch 43; iter: 0; batch classifier loss: 0.411238; batch adversarial loss: 0.547218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434254; batch adversarial loss: 0.545867\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480986; batch adversarial loss: 0.543839\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480353; batch adversarial loss: 0.616870\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440764; batch adversarial loss: 0.612587\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406942; batch adversarial loss: 0.571495\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443844; batch adversarial loss: 0.597227\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432510; batch adversarial loss: 0.509449\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442157; batch adversarial loss: 0.474078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510127; batch adversarial loss: 0.509438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412740; batch adversarial loss: 0.509223\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433371; batch adversarial loss: 0.516961\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386723; batch adversarial loss: 0.518766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417043; batch adversarial loss: 0.581735\n",
      "epoch 57; iter: 0; batch classifier loss: 0.507499; batch adversarial loss: 0.571666\n",
      "epoch 58; iter: 0; batch classifier loss: 0.481757; batch adversarial loss: 0.525823\n",
      "epoch 59; iter: 0; batch classifier loss: 0.405755; batch adversarial loss: 0.527335\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446577; batch adversarial loss: 0.480493\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444748; batch adversarial loss: 0.517671\n",
      "epoch 62; iter: 0; batch classifier loss: 0.365987; batch adversarial loss: 0.510912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.377560; batch adversarial loss: 0.508324\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425689; batch adversarial loss: 0.525383\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420593; batch adversarial loss: 0.475212\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446448; batch adversarial loss: 0.596725\n",
      "epoch 67; iter: 0; batch classifier loss: 0.475280; batch adversarial loss: 0.489379\n",
      "epoch 68; iter: 0; batch classifier loss: 0.346246; batch adversarial loss: 0.589582\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411400; batch adversarial loss: 0.599409\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455081; batch adversarial loss: 0.607198\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391522; batch adversarial loss: 0.568739\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402753; batch adversarial loss: 0.546947\n",
      "epoch 73; iter: 0; batch classifier loss: 0.350488; batch adversarial loss: 0.533237\n",
      "epoch 74; iter: 0; batch classifier loss: 0.332825; batch adversarial loss: 0.597652\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371924; batch adversarial loss: 0.554383\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370890; batch adversarial loss: 0.526364\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435211; batch adversarial loss: 0.562357\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379407; batch adversarial loss: 0.576977\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379915; batch adversarial loss: 0.650337\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374789; batch adversarial loss: 0.528922\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414043; batch adversarial loss: 0.600105\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406967; batch adversarial loss: 0.508130\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402987; batch adversarial loss: 0.576352\n",
      "epoch 84; iter: 0; batch classifier loss: 0.340509; batch adversarial loss: 0.615267\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401995; batch adversarial loss: 0.519936\n",
      "epoch 86; iter: 0; batch classifier loss: 0.438338; batch adversarial loss: 0.472030\n",
      "epoch 87; iter: 0; batch classifier loss: 0.329330; batch adversarial loss: 0.589964\n",
      "epoch 88; iter: 0; batch classifier loss: 0.366413; batch adversarial loss: 0.462010\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367620; batch adversarial loss: 0.472012\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443029; batch adversarial loss: 0.550187\n",
      "epoch 91; iter: 0; batch classifier loss: 0.346180; batch adversarial loss: 0.573802\n",
      "epoch 92; iter: 0; batch classifier loss: 0.437075; batch adversarial loss: 0.525976\n",
      "epoch 93; iter: 0; batch classifier loss: 0.435894; batch adversarial loss: 0.562493\n",
      "epoch 94; iter: 0; batch classifier loss: 0.295041; batch adversarial loss: 0.642178\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415293; batch adversarial loss: 0.506761\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368747; batch adversarial loss: 0.581629\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391328; batch adversarial loss: 0.500102\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418027; batch adversarial loss: 0.608255\n",
      "epoch 99; iter: 0; batch classifier loss: 0.443253; batch adversarial loss: 0.573406\n",
      "epoch 100; iter: 0; batch classifier loss: 0.343883; batch adversarial loss: 0.641841\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397957; batch adversarial loss: 0.551830\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409634; batch adversarial loss: 0.560781\n",
      "epoch 103; iter: 0; batch classifier loss: 0.255895; batch adversarial loss: 0.641816\n",
      "epoch 104; iter: 0; batch classifier loss: 0.442420; batch adversarial loss: 0.481052\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347395; batch adversarial loss: 0.531457\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388169; batch adversarial loss: 0.569993\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399434; batch adversarial loss: 0.502073\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383025; batch adversarial loss: 0.581295\n",
      "epoch 109; iter: 0; batch classifier loss: 0.325962; batch adversarial loss: 0.560600\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384406; batch adversarial loss: 0.499045\n",
      "epoch 111; iter: 0; batch classifier loss: 0.450146; batch adversarial loss: 0.492623\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326627; batch adversarial loss: 0.524088\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357264; batch adversarial loss: 0.516879\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385763; batch adversarial loss: 0.568974\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428944; batch adversarial loss: 0.618657\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413910; batch adversarial loss: 0.536525\n",
      "epoch 117; iter: 0; batch classifier loss: 0.401296; batch adversarial loss: 0.543519\n",
      "epoch 118; iter: 0; batch classifier loss: 0.336816; batch adversarial loss: 0.569627\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388754; batch adversarial loss: 0.623657\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330505; batch adversarial loss: 0.569384\n",
      "epoch 121; iter: 0; batch classifier loss: 0.410387; batch adversarial loss: 0.564813\n",
      "epoch 122; iter: 0; batch classifier loss: 0.513140; batch adversarial loss: 0.524462\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375286; batch adversarial loss: 0.525578\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382095; batch adversarial loss: 0.571734\n",
      "epoch 125; iter: 0; batch classifier loss: 0.494211; batch adversarial loss: 0.587769\n",
      "epoch 126; iter: 0; batch classifier loss: 0.432723; batch adversarial loss: 0.572272\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347601; batch adversarial loss: 0.570777\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373043; batch adversarial loss: 0.513837\n",
      "epoch 129; iter: 0; batch classifier loss: 0.423659; batch adversarial loss: 0.508439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406696; batch adversarial loss: 0.525687\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337350; batch adversarial loss: 0.563903\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363371; batch adversarial loss: 0.572271\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357444; batch adversarial loss: 0.547380\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344323; batch adversarial loss: 0.553785\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381905; batch adversarial loss: 0.542607\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372670; batch adversarial loss: 0.580744\n",
      "epoch 137; iter: 0; batch classifier loss: 0.373407; batch adversarial loss: 0.591063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373392; batch adversarial loss: 0.554542\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367802; batch adversarial loss: 0.533185\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329111; batch adversarial loss: 0.514724\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346993; batch adversarial loss: 0.607051\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418248; batch adversarial loss: 0.551505\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371055; batch adversarial loss: 0.581882\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351674; batch adversarial loss: 0.535250\n",
      "epoch 145; iter: 0; batch classifier loss: 0.416380; batch adversarial loss: 0.571194\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381137; batch adversarial loss: 0.524930\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382861; batch adversarial loss: 0.568542\n",
      "epoch 148; iter: 0; batch classifier loss: 0.424007; batch adversarial loss: 0.518038\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328887; batch adversarial loss: 0.619146\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365673; batch adversarial loss: 0.534475\n",
      "epoch 151; iter: 0; batch classifier loss: 0.300615; batch adversarial loss: 0.565351\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354172; batch adversarial loss: 0.583642\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343737; batch adversarial loss: 0.542205\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353312; batch adversarial loss: 0.563450\n",
      "epoch 155; iter: 0; batch classifier loss: 0.386245; batch adversarial loss: 0.569964\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418352; batch adversarial loss: 0.581216\n",
      "epoch 157; iter: 0; batch classifier loss: 0.415017; batch adversarial loss: 0.598539\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365383; batch adversarial loss: 0.517015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.442246; batch adversarial loss: 0.534489\n",
      "epoch 160; iter: 0; batch classifier loss: 0.420774; batch adversarial loss: 0.574145\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318326; batch adversarial loss: 0.544800\n",
      "epoch 162; iter: 0; batch classifier loss: 0.317215; batch adversarial loss: 0.491649\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333251; batch adversarial loss: 0.553788\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335694; batch adversarial loss: 0.518158\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321449; batch adversarial loss: 0.605984\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301502; batch adversarial loss: 0.453883\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332147; batch adversarial loss: 0.474986\n",
      "epoch 168; iter: 0; batch classifier loss: 0.433490; batch adversarial loss: 0.545802\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385067; batch adversarial loss: 0.607768\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380429; batch adversarial loss: 0.553057\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342873; batch adversarial loss: 0.649448\n",
      "epoch 172; iter: 0; batch classifier loss: 0.284931; batch adversarial loss: 0.579453\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380719; batch adversarial loss: 0.524178\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372111; batch adversarial loss: 0.607973\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331629; batch adversarial loss: 0.623066\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323415; batch adversarial loss: 0.570792\n",
      "epoch 177; iter: 0; batch classifier loss: 0.445543; batch adversarial loss: 0.569330\n",
      "epoch 178; iter: 0; batch classifier loss: 0.478231; batch adversarial loss: 0.560745\n",
      "epoch 179; iter: 0; batch classifier loss: 0.332107; batch adversarial loss: 0.632777\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360041; batch adversarial loss: 0.508136\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420460; batch adversarial loss: 0.590515\n",
      "epoch 182; iter: 0; batch classifier loss: 0.310344; batch adversarial loss: 0.454892\n",
      "epoch 183; iter: 0; batch classifier loss: 0.319156; batch adversarial loss: 0.606730\n",
      "epoch 184; iter: 0; batch classifier loss: 0.423038; batch adversarial loss: 0.570428\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381951; batch adversarial loss: 0.479675\n",
      "epoch 186; iter: 0; batch classifier loss: 0.391284; batch adversarial loss: 0.591121\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336290; batch adversarial loss: 0.573826\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324325; batch adversarial loss: 0.501872\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338837; batch adversarial loss: 0.578239\n",
      "epoch 190; iter: 0; batch classifier loss: 0.406854; batch adversarial loss: 0.519414\n",
      "epoch 191; iter: 0; batch classifier loss: 0.376264; batch adversarial loss: 0.590135\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359994; batch adversarial loss: 0.550673\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342102; batch adversarial loss: 0.595488\n",
      "epoch 194; iter: 0; batch classifier loss: 0.367625; batch adversarial loss: 0.563036\n",
      "epoch 195; iter: 0; batch classifier loss: 0.430472; batch adversarial loss: 0.518308\n",
      "epoch 196; iter: 0; batch classifier loss: 0.340515; batch adversarial loss: 0.483108\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394448; batch adversarial loss: 0.525581\n",
      "epoch 198; iter: 0; batch classifier loss: 0.401861; batch adversarial loss: 0.534832\n",
      "epoch 199; iter: 0; batch classifier loss: 0.414555; batch adversarial loss: 0.590351\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682362; batch adversarial loss: 0.814283\n",
      "epoch 1; iter: 0; batch classifier loss: 0.880618; batch adversarial loss: 1.001730\n",
      "epoch 2; iter: 0; batch classifier loss: 0.886923; batch adversarial loss: 0.866771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.809906; batch adversarial loss: 0.794007\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634938; batch adversarial loss: 0.697609\n",
      "epoch 5; iter: 0; batch classifier loss: 0.690805; batch adversarial loss: 0.710538\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603624; batch adversarial loss: 0.685318\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604670; batch adversarial loss: 0.614134\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554713; batch adversarial loss: 0.598389\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523929; batch adversarial loss: 0.568101\n",
      "epoch 10; iter: 0; batch classifier loss: 0.631068; batch adversarial loss: 0.579301\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582605; batch adversarial loss: 0.587989\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523473; batch adversarial loss: 0.566960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419823; batch adversarial loss: 0.600172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541769; batch adversarial loss: 0.584182\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502551; batch adversarial loss: 0.550083\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519508; batch adversarial loss: 0.555282\n",
      "epoch 17; iter: 0; batch classifier loss: 0.549193; batch adversarial loss: 0.585159\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453386; batch adversarial loss: 0.540648\n",
      "epoch 19; iter: 0; batch classifier loss: 0.567344; batch adversarial loss: 0.536583\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532327; batch adversarial loss: 0.627577\n",
      "epoch 21; iter: 0; batch classifier loss: 0.505813; batch adversarial loss: 0.591225\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486174; batch adversarial loss: 0.536148\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451728; batch adversarial loss: 0.631079\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468980; batch adversarial loss: 0.559297\n",
      "epoch 25; iter: 0; batch classifier loss: 0.460064; batch adversarial loss: 0.635483\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461598; batch adversarial loss: 0.508220\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456233; batch adversarial loss: 0.493664\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493168; batch adversarial loss: 0.606159\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461686; batch adversarial loss: 0.548355\n",
      "epoch 30; iter: 0; batch classifier loss: 0.544756; batch adversarial loss: 0.524116\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489577; batch adversarial loss: 0.595989\n",
      "epoch 32; iter: 0; batch classifier loss: 0.412195; batch adversarial loss: 0.675634\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408542; batch adversarial loss: 0.543138\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452806; batch adversarial loss: 0.556864\n",
      "epoch 35; iter: 0; batch classifier loss: 0.512833; batch adversarial loss: 0.595933\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454998; batch adversarial loss: 0.457169\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446849; batch adversarial loss: 0.553177\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463878; batch adversarial loss: 0.485379\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480503; batch adversarial loss: 0.542915\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422762; batch adversarial loss: 0.555939\n",
      "epoch 41; iter: 0; batch classifier loss: 0.505613; batch adversarial loss: 0.535735\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449559; batch adversarial loss: 0.593343\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425455; batch adversarial loss: 0.580614\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435679; batch adversarial loss: 0.532233\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432940; batch adversarial loss: 0.568411\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372386; batch adversarial loss: 0.584243\n",
      "epoch 47; iter: 0; batch classifier loss: 0.388583; batch adversarial loss: 0.544295\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425799; batch adversarial loss: 0.517685\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403687; batch adversarial loss: 0.553146\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441256; batch adversarial loss: 0.551759\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464251; batch adversarial loss: 0.538644\n",
      "epoch 52; iter: 0; batch classifier loss: 0.474992; batch adversarial loss: 0.538936\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374971; batch adversarial loss: 0.536065\n",
      "epoch 54; iter: 0; batch classifier loss: 0.370901; batch adversarial loss: 0.545369\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.509504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.448971; batch adversarial loss: 0.481434\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382600; batch adversarial loss: 0.590653\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445972; batch adversarial loss: 0.544741\n",
      "epoch 59; iter: 0; batch classifier loss: 0.450894; batch adversarial loss: 0.464314\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412274; batch adversarial loss: 0.581379\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379852; batch adversarial loss: 0.563034\n",
      "epoch 62; iter: 0; batch classifier loss: 0.518057; batch adversarial loss: 0.535906\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446382; batch adversarial loss: 0.562596\n",
      "epoch 64; iter: 0; batch classifier loss: 0.430801; batch adversarial loss: 0.652157\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409684; batch adversarial loss: 0.526239\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427788; batch adversarial loss: 0.535510\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394985; batch adversarial loss: 0.482109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.479813; batch adversarial loss: 0.589040\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402200; batch adversarial loss: 0.534739\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434274; batch adversarial loss: 0.598311\n",
      "epoch 71; iter: 0; batch classifier loss: 0.458945; batch adversarial loss: 0.528695\n",
      "epoch 72; iter: 0; batch classifier loss: 0.335094; batch adversarial loss: 0.499668\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414481; batch adversarial loss: 0.603678\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393223; batch adversarial loss: 0.581413\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403986; batch adversarial loss: 0.534131\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397927; batch adversarial loss: 0.567245\n",
      "epoch 77; iter: 0; batch classifier loss: 0.334265; batch adversarial loss: 0.519983\n",
      "epoch 78; iter: 0; batch classifier loss: 0.339150; batch adversarial loss: 0.600422\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377200; batch adversarial loss: 0.623185\n",
      "epoch 80; iter: 0; batch classifier loss: 0.493734; batch adversarial loss: 0.579229\n",
      "epoch 81; iter: 0; batch classifier loss: 0.355465; batch adversarial loss: 0.581120\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398432; batch adversarial loss: 0.537676\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443668; batch adversarial loss: 0.599128\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407562; batch adversarial loss: 0.562074\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387897; batch adversarial loss: 0.572680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.450092; batch adversarial loss: 0.489431\n",
      "epoch 87; iter: 0; batch classifier loss: 0.470793; batch adversarial loss: 0.500445\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423963; batch adversarial loss: 0.560621\n",
      "epoch 89; iter: 0; batch classifier loss: 0.354581; batch adversarial loss: 0.525620\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348671; batch adversarial loss: 0.553522\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404052; batch adversarial loss: 0.520132\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406122; batch adversarial loss: 0.517413\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417761; batch adversarial loss: 0.510404\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420798; batch adversarial loss: 0.618600\n",
      "epoch 95; iter: 0; batch classifier loss: 0.454865; batch adversarial loss: 0.536573\n",
      "epoch 96; iter: 0; batch classifier loss: 0.452872; batch adversarial loss: 0.510864\n",
      "epoch 97; iter: 0; batch classifier loss: 0.414149; batch adversarial loss: 0.528325\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387797; batch adversarial loss: 0.525235\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381418; batch adversarial loss: 0.523085\n",
      "epoch 100; iter: 0; batch classifier loss: 0.332320; batch adversarial loss: 0.553232\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347717; batch adversarial loss: 0.584691\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417310; batch adversarial loss: 0.551773\n",
      "epoch 103; iter: 0; batch classifier loss: 0.281302; batch adversarial loss: 0.672461\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349881; batch adversarial loss: 0.489833\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406260; batch adversarial loss: 0.499429\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366355; batch adversarial loss: 0.525753\n",
      "epoch 107; iter: 0; batch classifier loss: 0.414486; batch adversarial loss: 0.583857\n",
      "epoch 108; iter: 0; batch classifier loss: 0.416421; batch adversarial loss: 0.579868\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416204; batch adversarial loss: 0.607863\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367676; batch adversarial loss: 0.526198\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406466; batch adversarial loss: 0.546434\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435709; batch adversarial loss: 0.607889\n",
      "epoch 113; iter: 0; batch classifier loss: 0.359446; batch adversarial loss: 0.578108\n",
      "epoch 114; iter: 0; batch classifier loss: 0.436081; batch adversarial loss: 0.570585\n",
      "epoch 115; iter: 0; batch classifier loss: 0.365617; batch adversarial loss: 0.601043\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398441; batch adversarial loss: 0.543011\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402814; batch adversarial loss: 0.544495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.434220; batch adversarial loss: 0.607300\n",
      "epoch 119; iter: 0; batch classifier loss: 0.411990; batch adversarial loss: 0.562307\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374769; batch adversarial loss: 0.564613\n",
      "epoch 121; iter: 0; batch classifier loss: 0.490122; batch adversarial loss: 0.556256\n",
      "epoch 122; iter: 0; batch classifier loss: 0.419588; batch adversarial loss: 0.651070\n",
      "epoch 123; iter: 0; batch classifier loss: 0.428204; batch adversarial loss: 0.517535\n",
      "epoch 124; iter: 0; batch classifier loss: 0.297656; batch adversarial loss: 0.598149\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410292; batch adversarial loss: 0.671513\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347259; batch adversarial loss: 0.560778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.424159; batch adversarial loss: 0.509400\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381856; batch adversarial loss: 0.578936\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378280; batch adversarial loss: 0.609866\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356565; batch adversarial loss: 0.535606\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371859; batch adversarial loss: 0.510019\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413964; batch adversarial loss: 0.560877\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402094; batch adversarial loss: 0.516801\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346089; batch adversarial loss: 0.463381\n",
      "epoch 135; iter: 0; batch classifier loss: 0.329437; batch adversarial loss: 0.596270\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366676; batch adversarial loss: 0.508515\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369321; batch adversarial loss: 0.553585\n",
      "epoch 138; iter: 0; batch classifier loss: 0.453333; batch adversarial loss: 0.536193\n",
      "epoch 139; iter: 0; batch classifier loss: 0.319649; batch adversarial loss: 0.508689\n",
      "epoch 140; iter: 0; batch classifier loss: 0.357161; batch adversarial loss: 0.608329\n",
      "epoch 141; iter: 0; batch classifier loss: 0.324211; batch adversarial loss: 0.505779\n",
      "epoch 142; iter: 0; batch classifier loss: 0.305530; batch adversarial loss: 0.519891\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412579; batch adversarial loss: 0.535637\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362989; batch adversarial loss: 0.574456\n",
      "epoch 145; iter: 0; batch classifier loss: 0.400579; batch adversarial loss: 0.588503\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352428; batch adversarial loss: 0.491251\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350135; batch adversarial loss: 0.552700\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327650; batch adversarial loss: 0.542526\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382093; batch adversarial loss: 0.481193\n",
      "epoch 150; iter: 0; batch classifier loss: 0.321157; batch adversarial loss: 0.536242\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375848; batch adversarial loss: 0.516162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.396908; batch adversarial loss: 0.489518\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335151; batch adversarial loss: 0.588859\n",
      "epoch 154; iter: 0; batch classifier loss: 0.423057; batch adversarial loss: 0.570704\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364259; batch adversarial loss: 0.555325\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355277; batch adversarial loss: 0.544393\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318460; batch adversarial loss: 0.478993\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380234; batch adversarial loss: 0.525212\n",
      "epoch 159; iter: 0; batch classifier loss: 0.403154; batch adversarial loss: 0.472000\n",
      "epoch 160; iter: 0; batch classifier loss: 0.317753; batch adversarial loss: 0.573333\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357197; batch adversarial loss: 0.561964\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363606; batch adversarial loss: 0.572598\n",
      "epoch 163; iter: 0; batch classifier loss: 0.289567; batch adversarial loss: 0.626230\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374634; batch adversarial loss: 0.554477\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346387; batch adversarial loss: 0.509491\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382517; batch adversarial loss: 0.507624\n",
      "epoch 167; iter: 0; batch classifier loss: 0.327762; batch adversarial loss: 0.564575\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344545; batch adversarial loss: 0.534417\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355977; batch adversarial loss: 0.527316\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299576; batch adversarial loss: 0.519499\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420866; batch adversarial loss: 0.563540\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377518; batch adversarial loss: 0.614385\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302505; batch adversarial loss: 0.601100\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385119; batch adversarial loss: 0.506880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364366; batch adversarial loss: 0.535350\n",
      "epoch 176; iter: 0; batch classifier loss: 0.422923; batch adversarial loss: 0.500370\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363210; batch adversarial loss: 0.481251\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363526; batch adversarial loss: 0.599926\n",
      "epoch 179; iter: 0; batch classifier loss: 0.296047; batch adversarial loss: 0.533482\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360616; batch adversarial loss: 0.634074\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386153; batch adversarial loss: 0.562815\n",
      "epoch 182; iter: 0; batch classifier loss: 0.396148; batch adversarial loss: 0.580624\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304638; batch adversarial loss: 0.544605\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354646; batch adversarial loss: 0.527729\n",
      "epoch 185; iter: 0; batch classifier loss: 0.330413; batch adversarial loss: 0.490840\n",
      "epoch 186; iter: 0; batch classifier loss: 0.372269; batch adversarial loss: 0.568991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.441271; batch adversarial loss: 0.599552\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356168; batch adversarial loss: 0.578604\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357737; batch adversarial loss: 0.535192\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361647; batch adversarial loss: 0.581956\n",
      "epoch 191; iter: 0; batch classifier loss: 0.451047; batch adversarial loss: 0.562818\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384417; batch adversarial loss: 0.570986\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402333; batch adversarial loss: 0.572122\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377789; batch adversarial loss: 0.516164\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374751; batch adversarial loss: 0.570644\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345104; batch adversarial loss: 0.564256\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394807; batch adversarial loss: 0.553867\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309846; batch adversarial loss: 0.580764\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350777; batch adversarial loss: 0.581802\n",
      "epoch 0; iter: 0; batch classifier loss: 0.850193; batch adversarial loss: 0.517253\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605601; batch adversarial loss: 0.655740\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579558; batch adversarial loss: 0.665883\n",
      "epoch 3; iter: 0; batch classifier loss: 0.688576; batch adversarial loss: 0.653012\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565650; batch adversarial loss: 0.693019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575786; batch adversarial loss: 0.608486\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612029; batch adversarial loss: 0.674216\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563183; batch adversarial loss: 0.597706\n",
      "epoch 8; iter: 0; batch classifier loss: 0.659433; batch adversarial loss: 0.622035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517359; batch adversarial loss: 0.639923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570328; batch adversarial loss: 0.618947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493066; batch adversarial loss: 0.594529\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518004; batch adversarial loss: 0.598936\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545265; batch adversarial loss: 0.592392\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484841; batch adversarial loss: 0.581876\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535414; batch adversarial loss: 0.519465\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523509; batch adversarial loss: 0.511803\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539874; batch adversarial loss: 0.466296\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513692; batch adversarial loss: 0.530612\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503802; batch adversarial loss: 0.562519\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487527; batch adversarial loss: 0.623688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474146; batch adversarial loss: 0.541924\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492271; batch adversarial loss: 0.483262\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525238; batch adversarial loss: 0.589455\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446000; batch adversarial loss: 0.589051\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470292; batch adversarial loss: 0.537242\n",
      "epoch 26; iter: 0; batch classifier loss: 0.550387; batch adversarial loss: 0.587841\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476006; batch adversarial loss: 0.509680\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495312; batch adversarial loss: 0.578342\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489351; batch adversarial loss: 0.485303\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418972; batch adversarial loss: 0.501929\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453957; batch adversarial loss: 0.474924\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492771; batch adversarial loss: 0.547177\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433502; batch adversarial loss: 0.563540\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411980; batch adversarial loss: 0.517078\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442359; batch adversarial loss: 0.526992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424896; batch adversarial loss: 0.481714\n",
      "epoch 37; iter: 0; batch classifier loss: 0.396797; batch adversarial loss: 0.616134\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441474; batch adversarial loss: 0.571289\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434848; batch adversarial loss: 0.472367\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460236; batch adversarial loss: 0.489940\n",
      "epoch 41; iter: 0; batch classifier loss: 0.567028; batch adversarial loss: 0.589632\n",
      "epoch 42; iter: 0; batch classifier loss: 0.388490; batch adversarial loss: 0.489832\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430199; batch adversarial loss: 0.417664\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442837; batch adversarial loss: 0.571767\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443143; batch adversarial loss: 0.553549\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455534; batch adversarial loss: 0.561232\n",
      "epoch 47; iter: 0; batch classifier loss: 0.394770; batch adversarial loss: 0.544232\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449556; batch adversarial loss: 0.527277\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471014; batch adversarial loss: 0.525778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.469127; batch adversarial loss: 0.564522\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443932; batch adversarial loss: 0.499504\n",
      "epoch 52; iter: 0; batch classifier loss: 0.364630; batch adversarial loss: 0.599798\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397429; batch adversarial loss: 0.627238\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446135; batch adversarial loss: 0.581726\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405547; batch adversarial loss: 0.526100\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433473; batch adversarial loss: 0.490590\n",
      "epoch 57; iter: 0; batch classifier loss: 0.497872; batch adversarial loss: 0.571157\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464455; batch adversarial loss: 0.543725\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435848; batch adversarial loss: 0.526944\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363922; batch adversarial loss: 0.589403\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380539; batch adversarial loss: 0.553301\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426208; batch adversarial loss: 0.553695\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408482; batch adversarial loss: 0.614521\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405376; batch adversarial loss: 0.507000\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429713; batch adversarial loss: 0.526629\n",
      "epoch 66; iter: 0; batch classifier loss: 0.379139; batch adversarial loss: 0.625771\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405759; batch adversarial loss: 0.554330\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373908; batch adversarial loss: 0.536298\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410687; batch adversarial loss: 0.544539\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444735; batch adversarial loss: 0.626616\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405414; batch adversarial loss: 0.473333\n",
      "epoch 72; iter: 0; batch classifier loss: 0.461594; batch adversarial loss: 0.500504\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371854; batch adversarial loss: 0.471564\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388800; batch adversarial loss: 0.572143\n",
      "epoch 75; iter: 0; batch classifier loss: 0.363296; batch adversarial loss: 0.478482\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382476; batch adversarial loss: 0.547386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406772; batch adversarial loss: 0.536364\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395475; batch adversarial loss: 0.508835\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410576; batch adversarial loss: 0.653132\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371760; batch adversarial loss: 0.518966\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384867; batch adversarial loss: 0.591281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.450540; batch adversarial loss: 0.546006\n",
      "epoch 83; iter: 0; batch classifier loss: 0.435378; batch adversarial loss: 0.535872\n",
      "epoch 84; iter: 0; batch classifier loss: 0.327422; batch adversarial loss: 0.518892\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431333; batch adversarial loss: 0.575069\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385851; batch adversarial loss: 0.528942\n",
      "epoch 87; iter: 0; batch classifier loss: 0.443081; batch adversarial loss: 0.545177\n",
      "epoch 88; iter: 0; batch classifier loss: 0.366182; batch adversarial loss: 0.534941\n",
      "epoch 89; iter: 0; batch classifier loss: 0.450078; batch adversarial loss: 0.508475\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408621; batch adversarial loss: 0.610136\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423123; batch adversarial loss: 0.553070\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413233; batch adversarial loss: 0.515409\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352161; batch adversarial loss: 0.589803\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341097; batch adversarial loss: 0.507554\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424450; batch adversarial loss: 0.563009\n",
      "epoch 96; iter: 0; batch classifier loss: 0.448757; batch adversarial loss: 0.535451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397998; batch adversarial loss: 0.570947\n",
      "epoch 98; iter: 0; batch classifier loss: 0.343828; batch adversarial loss: 0.617111\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400512; batch adversarial loss: 0.526570\n",
      "epoch 100; iter: 0; batch classifier loss: 0.475285; batch adversarial loss: 0.444540\n",
      "epoch 101; iter: 0; batch classifier loss: 0.485495; batch adversarial loss: 0.555013\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361118; batch adversarial loss: 0.536956\n",
      "epoch 103; iter: 0; batch classifier loss: 0.312934; batch adversarial loss: 0.578939\n",
      "epoch 104; iter: 0; batch classifier loss: 0.322322; batch adversarial loss: 0.535244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.506366; batch adversarial loss: 0.579279\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409742; batch adversarial loss: 0.488775\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392813; batch adversarial loss: 0.532967\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340027; batch adversarial loss: 0.525325\n",
      "epoch 109; iter: 0; batch classifier loss: 0.392333; batch adversarial loss: 0.562003\n",
      "epoch 110; iter: 0; batch classifier loss: 0.373905; batch adversarial loss: 0.618242\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400404; batch adversarial loss: 0.542720\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386984; batch adversarial loss: 0.560421\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396137; batch adversarial loss: 0.573130\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327110; batch adversarial loss: 0.516628\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409149; batch adversarial loss: 0.535185\n",
      "epoch 116; iter: 0; batch classifier loss: 0.473134; batch adversarial loss: 0.517141\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362979; batch adversarial loss: 0.515595\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340675; batch adversarial loss: 0.489738\n",
      "epoch 119; iter: 0; batch classifier loss: 0.508919; batch adversarial loss: 0.562434\n",
      "epoch 120; iter: 0; batch classifier loss: 0.365976; batch adversarial loss: 0.489611\n",
      "epoch 121; iter: 0; batch classifier loss: 0.409189; batch adversarial loss: 0.545276\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392678; batch adversarial loss: 0.553937\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368511; batch adversarial loss: 0.571235\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371723; batch adversarial loss: 0.471648\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373066; batch adversarial loss: 0.534461\n",
      "epoch 126; iter: 0; batch classifier loss: 0.309747; batch adversarial loss: 0.543083\n",
      "epoch 127; iter: 0; batch classifier loss: 0.326451; batch adversarial loss: 0.507181\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396325; batch adversarial loss: 0.526586\n",
      "epoch 129; iter: 0; batch classifier loss: 0.357196; batch adversarial loss: 0.572323\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375574; batch adversarial loss: 0.560396\n",
      "epoch 131; iter: 0; batch classifier loss: 0.426905; batch adversarial loss: 0.563498\n",
      "epoch 132; iter: 0; batch classifier loss: 0.449493; batch adversarial loss: 0.571691\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364057; batch adversarial loss: 0.618550\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365831; batch adversarial loss: 0.488359\n",
      "epoch 135; iter: 0; batch classifier loss: 0.470074; batch adversarial loss: 0.581601\n",
      "epoch 136; iter: 0; batch classifier loss: 0.430914; batch adversarial loss: 0.579081\n",
      "epoch 137; iter: 0; batch classifier loss: 0.324323; batch adversarial loss: 0.542601\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328899; batch adversarial loss: 0.590548\n",
      "epoch 139; iter: 0; batch classifier loss: 0.421256; batch adversarial loss: 0.461375\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384550; batch adversarial loss: 0.629534\n",
      "epoch 141; iter: 0; batch classifier loss: 0.477545; batch adversarial loss: 0.508060\n",
      "epoch 142; iter: 0; batch classifier loss: 0.449878; batch adversarial loss: 0.563422\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389517; batch adversarial loss: 0.600047\n",
      "epoch 144; iter: 0; batch classifier loss: 0.391459; batch adversarial loss: 0.583171\n",
      "epoch 145; iter: 0; batch classifier loss: 0.310277; batch adversarial loss: 0.618624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.378308; batch adversarial loss: 0.506588\n",
      "epoch 147; iter: 0; batch classifier loss: 0.314039; batch adversarial loss: 0.526298\n",
      "epoch 148; iter: 0; batch classifier loss: 0.439909; batch adversarial loss: 0.608707\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371655; batch adversarial loss: 0.499214\n",
      "epoch 150; iter: 0; batch classifier loss: 0.415975; batch adversarial loss: 0.553686\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338079; batch adversarial loss: 0.479375\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342047; batch adversarial loss: 0.580878\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357272; batch adversarial loss: 0.497455\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349140; batch adversarial loss: 0.516727\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354896; batch adversarial loss: 0.535841\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347802; batch adversarial loss: 0.562364\n",
      "epoch 157; iter: 0; batch classifier loss: 0.434168; batch adversarial loss: 0.517902\n",
      "epoch 158; iter: 0; batch classifier loss: 0.444023; batch adversarial loss: 0.553223\n",
      "epoch 159; iter: 0; batch classifier loss: 0.411659; batch adversarial loss: 0.535888\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378300; batch adversarial loss: 0.552034\n",
      "epoch 161; iter: 0; batch classifier loss: 0.425959; batch adversarial loss: 0.534990\n",
      "epoch 162; iter: 0; batch classifier loss: 0.462411; batch adversarial loss: 0.453583\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323562; batch adversarial loss: 0.525958\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354943; batch adversarial loss: 0.532800\n",
      "epoch 165; iter: 0; batch classifier loss: 0.437780; batch adversarial loss: 0.545756\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367706; batch adversarial loss: 0.544786\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407422; batch adversarial loss: 0.530651\n",
      "epoch 168; iter: 0; batch classifier loss: 0.341766; batch adversarial loss: 0.544450\n",
      "epoch 169; iter: 0; batch classifier loss: 0.384461; batch adversarial loss: 0.636063\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366798; batch adversarial loss: 0.617363\n",
      "epoch 171; iter: 0; batch classifier loss: 0.301804; batch adversarial loss: 0.551586\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366183; batch adversarial loss: 0.601276\n",
      "epoch 173; iter: 0; batch classifier loss: 0.318792; batch adversarial loss: 0.478834\n",
      "epoch 174; iter: 0; batch classifier loss: 0.300278; batch adversarial loss: 0.561216\n",
      "epoch 175; iter: 0; batch classifier loss: 0.404930; batch adversarial loss: 0.554111\n",
      "epoch 176; iter: 0; batch classifier loss: 0.333548; batch adversarial loss: 0.579625\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319967; batch adversarial loss: 0.515834\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347505; batch adversarial loss: 0.561402\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359510; batch adversarial loss: 0.664624\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351471; batch adversarial loss: 0.562439\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322509; batch adversarial loss: 0.498959\n",
      "epoch 182; iter: 0; batch classifier loss: 0.453438; batch adversarial loss: 0.461434\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341980; batch adversarial loss: 0.508551\n",
      "epoch 184; iter: 0; batch classifier loss: 0.424314; batch adversarial loss: 0.571213\n",
      "epoch 185; iter: 0; batch classifier loss: 0.309753; batch adversarial loss: 0.607671\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396964; batch adversarial loss: 0.599577\n",
      "epoch 187; iter: 0; batch classifier loss: 0.349175; batch adversarial loss: 0.552072\n",
      "epoch 188; iter: 0; batch classifier loss: 0.436179; batch adversarial loss: 0.506782\n",
      "epoch 189; iter: 0; batch classifier loss: 0.374547; batch adversarial loss: 0.544851\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342239; batch adversarial loss: 0.544648\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314617; batch adversarial loss: 0.581085\n",
      "epoch 192; iter: 0; batch classifier loss: 0.440698; batch adversarial loss: 0.525302\n",
      "epoch 193; iter: 0; batch classifier loss: 0.462102; batch adversarial loss: 0.561539\n",
      "epoch 194; iter: 0; batch classifier loss: 0.450745; batch adversarial loss: 0.609479\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364305; batch adversarial loss: 0.525300\n",
      "epoch 196; iter: 0; batch classifier loss: 0.440923; batch adversarial loss: 0.571887\n",
      "epoch 197; iter: 0; batch classifier loss: 0.382496; batch adversarial loss: 0.561190\n",
      "epoch 198; iter: 0; batch classifier loss: 0.312112; batch adversarial loss: 0.527958\n",
      "epoch 199; iter: 0; batch classifier loss: 0.436502; batch adversarial loss: 0.535040\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679747; batch adversarial loss: 0.600327\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627547; batch adversarial loss: 0.616736\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616038; batch adversarial loss: 0.654435\n",
      "epoch 3; iter: 0; batch classifier loss: 0.509638; batch adversarial loss: 0.611865\n",
      "epoch 4; iter: 0; batch classifier loss: 0.620844; batch adversarial loss: 0.702393\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593482; batch adversarial loss: 0.626366\n",
      "epoch 6; iter: 0; batch classifier loss: 0.667325; batch adversarial loss: 0.626945\n",
      "epoch 7; iter: 0; batch classifier loss: 0.655404; batch adversarial loss: 0.574922\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503948; batch adversarial loss: 0.636204\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502251; batch adversarial loss: 0.584757\n",
      "epoch 10; iter: 0; batch classifier loss: 0.605825; batch adversarial loss: 0.581164\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531822; batch adversarial loss: 0.639870\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532249; batch adversarial loss: 0.574094\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535725; batch adversarial loss: 0.541984\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518035; batch adversarial loss: 0.600031\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510491; batch adversarial loss: 0.616981\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547408; batch adversarial loss: 0.590225\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474527; batch adversarial loss: 0.576439\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513460; batch adversarial loss: 0.637801\n",
      "epoch 19; iter: 0; batch classifier loss: 0.574825; batch adversarial loss: 0.530275\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500648; batch adversarial loss: 0.526441\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492012; batch adversarial loss: 0.502281\n",
      "epoch 22; iter: 0; batch classifier loss: 0.413612; batch adversarial loss: 0.545908\n",
      "epoch 23; iter: 0; batch classifier loss: 0.541605; batch adversarial loss: 0.584852\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495069; batch adversarial loss: 0.532583\n",
      "epoch 25; iter: 0; batch classifier loss: 0.534086; batch adversarial loss: 0.563863\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480588; batch adversarial loss: 0.530250\n",
      "epoch 27; iter: 0; batch classifier loss: 0.516190; batch adversarial loss: 0.502496\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439788; batch adversarial loss: 0.499904\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477493; batch adversarial loss: 0.560342\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458600; batch adversarial loss: 0.596822\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469401; batch adversarial loss: 0.494054\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512142; batch adversarial loss: 0.588226\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520354; batch adversarial loss: 0.564170\n",
      "epoch 34; iter: 0; batch classifier loss: 0.383233; batch adversarial loss: 0.491176\n",
      "epoch 35; iter: 0; batch classifier loss: 0.522448; batch adversarial loss: 0.537262\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450071; batch adversarial loss: 0.572860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503350; batch adversarial loss: 0.564807\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512893; batch adversarial loss: 0.507509\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437819; batch adversarial loss: 0.552322\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426084; batch adversarial loss: 0.544558\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453423; batch adversarial loss: 0.561533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.453366; batch adversarial loss: 0.518281\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444593; batch adversarial loss: 0.570556\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443361; batch adversarial loss: 0.589248\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481065; batch adversarial loss: 0.508791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.493017; batch adversarial loss: 0.642473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371311; batch adversarial loss: 0.562475\n",
      "epoch 48; iter: 0; batch classifier loss: 0.458701; batch adversarial loss: 0.508334\n",
      "epoch 49; iter: 0; batch classifier loss: 0.528326; batch adversarial loss: 0.543449\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420317; batch adversarial loss: 0.490700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438845; batch adversarial loss: 0.554035\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410487; batch adversarial loss: 0.561814\n",
      "epoch 53; iter: 0; batch classifier loss: 0.455653; batch adversarial loss: 0.597669\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419165; batch adversarial loss: 0.599268\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466013; batch adversarial loss: 0.595516\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455138; batch adversarial loss: 0.561750\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428779; batch adversarial loss: 0.516740\n",
      "epoch 58; iter: 0; batch classifier loss: 0.537508; batch adversarial loss: 0.527236\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433072; batch adversarial loss: 0.474958\n",
      "epoch 60; iter: 0; batch classifier loss: 0.493513; batch adversarial loss: 0.553897\n",
      "epoch 61; iter: 0; batch classifier loss: 0.415138; batch adversarial loss: 0.562182\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436124; batch adversarial loss: 0.554057\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448329; batch adversarial loss: 0.544546\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432823; batch adversarial loss: 0.580245\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439295; batch adversarial loss: 0.473583\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387232; batch adversarial loss: 0.598447\n",
      "epoch 67; iter: 0; batch classifier loss: 0.479394; batch adversarial loss: 0.508709\n",
      "epoch 68; iter: 0; batch classifier loss: 0.365976; batch adversarial loss: 0.544610\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423682; batch adversarial loss: 0.526573\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427372; batch adversarial loss: 0.472676\n",
      "epoch 71; iter: 0; batch classifier loss: 0.362632; batch adversarial loss: 0.526846\n",
      "epoch 72; iter: 0; batch classifier loss: 0.484792; batch adversarial loss: 0.581132\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391000; batch adversarial loss: 0.554782\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439561; batch adversarial loss: 0.562355\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457898; batch adversarial loss: 0.607831\n",
      "epoch 76; iter: 0; batch classifier loss: 0.447119; batch adversarial loss: 0.572305\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441239; batch adversarial loss: 0.607477\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417287; batch adversarial loss: 0.588501\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392406; batch adversarial loss: 0.571901\n",
      "epoch 80; iter: 0; batch classifier loss: 0.468383; batch adversarial loss: 0.526507\n",
      "epoch 81; iter: 0; batch classifier loss: 0.444412; batch adversarial loss: 0.561611\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397097; batch adversarial loss: 0.605881\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401457; batch adversarial loss: 0.554215\n",
      "epoch 84; iter: 0; batch classifier loss: 0.442603; batch adversarial loss: 0.579451\n",
      "epoch 85; iter: 0; batch classifier loss: 0.325251; batch adversarial loss: 0.546288\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390088; batch adversarial loss: 0.615004\n",
      "epoch 87; iter: 0; batch classifier loss: 0.453046; batch adversarial loss: 0.553627\n",
      "epoch 88; iter: 0; batch classifier loss: 0.410829; batch adversarial loss: 0.597420\n",
      "epoch 89; iter: 0; batch classifier loss: 0.449893; batch adversarial loss: 0.528106\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365691; batch adversarial loss: 0.545490\n",
      "epoch 91; iter: 0; batch classifier loss: 0.437768; batch adversarial loss: 0.572665\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405971; batch adversarial loss: 0.509663\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404519; batch adversarial loss: 0.544870\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392737; batch adversarial loss: 0.499315\n",
      "epoch 95; iter: 0; batch classifier loss: 0.324182; batch adversarial loss: 0.561595\n",
      "epoch 96; iter: 0; batch classifier loss: 0.434917; batch adversarial loss: 0.509129\n",
      "epoch 97; iter: 0; batch classifier loss: 0.497449; batch adversarial loss: 0.553695\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415826; batch adversarial loss: 0.553817\n",
      "epoch 99; iter: 0; batch classifier loss: 0.374655; batch adversarial loss: 0.554115\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375082; batch adversarial loss: 0.535282\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390487; batch adversarial loss: 0.463891\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392547; batch adversarial loss: 0.553759\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434306; batch adversarial loss: 0.571352\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376342; batch adversarial loss: 0.580870\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423555; batch adversarial loss: 0.554429\n",
      "epoch 106; iter: 0; batch classifier loss: 0.296180; batch adversarial loss: 0.554569\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380910; batch adversarial loss: 0.579953\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363276; batch adversarial loss: 0.563779\n",
      "epoch 109; iter: 0; batch classifier loss: 0.436286; batch adversarial loss: 0.634190\n",
      "epoch 110; iter: 0; batch classifier loss: 0.369940; batch adversarial loss: 0.499591\n",
      "epoch 111; iter: 0; batch classifier loss: 0.515944; batch adversarial loss: 0.580688\n",
      "epoch 112; iter: 0; batch classifier loss: 0.327628; batch adversarial loss: 0.571130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.325443; batch adversarial loss: 0.607488\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408237; batch adversarial loss: 0.562621\n",
      "epoch 115; iter: 0; batch classifier loss: 0.419819; batch adversarial loss: 0.481097\n",
      "epoch 116; iter: 0; batch classifier loss: 0.455103; batch adversarial loss: 0.509283\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404756; batch adversarial loss: 0.562446\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387868; batch adversarial loss: 0.624423\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366872; batch adversarial loss: 0.517233\n",
      "epoch 120; iter: 0; batch classifier loss: 0.321335; batch adversarial loss: 0.607007\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395198; batch adversarial loss: 0.616626\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408231; batch adversarial loss: 0.625849\n",
      "epoch 123; iter: 0; batch classifier loss: 0.520427; batch adversarial loss: 0.517276\n",
      "epoch 124; iter: 0; batch classifier loss: 0.460764; batch adversarial loss: 0.579755\n",
      "epoch 125; iter: 0; batch classifier loss: 0.366963; batch adversarial loss: 0.535757\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404167; batch adversarial loss: 0.518325\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385349; batch adversarial loss: 0.616559\n",
      "epoch 128; iter: 0; batch classifier loss: 0.321353; batch adversarial loss: 0.580388\n",
      "epoch 129; iter: 0; batch classifier loss: 0.433409; batch adversarial loss: 0.536992\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349936; batch adversarial loss: 0.536021\n",
      "epoch 131; iter: 0; batch classifier loss: 0.440171; batch adversarial loss: 0.615720\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389248; batch adversarial loss: 0.589181\n",
      "epoch 133; iter: 0; batch classifier loss: 0.351677; batch adversarial loss: 0.580722\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346656; batch adversarial loss: 0.517800\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338468; batch adversarial loss: 0.607338\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397227; batch adversarial loss: 0.526869\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383642; batch adversarial loss: 0.589409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.403254; batch adversarial loss: 0.544206\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341637; batch adversarial loss: 0.562076\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376578; batch adversarial loss: 0.598936\n",
      "epoch 141; iter: 0; batch classifier loss: 0.430104; batch adversarial loss: 0.588810\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384540; batch adversarial loss: 0.563393\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365195; batch adversarial loss: 0.598695\n",
      "epoch 144; iter: 0; batch classifier loss: 0.447892; batch adversarial loss: 0.473226\n",
      "epoch 145; iter: 0; batch classifier loss: 0.446893; batch adversarial loss: 0.607317\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401686; batch adversarial loss: 0.580976\n",
      "epoch 147; iter: 0; batch classifier loss: 0.367140; batch adversarial loss: 0.562044\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368813; batch adversarial loss: 0.516808\n",
      "epoch 149; iter: 0; batch classifier loss: 0.440036; batch adversarial loss: 0.606296\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394204; batch adversarial loss: 0.536065\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355241; batch adversarial loss: 0.571094\n",
      "epoch 152; iter: 0; batch classifier loss: 0.337805; batch adversarial loss: 0.517770\n",
      "epoch 153; iter: 0; batch classifier loss: 0.441022; batch adversarial loss: 0.533712\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373118; batch adversarial loss: 0.517033\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406533; batch adversarial loss: 0.598476\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340219; batch adversarial loss: 0.491235\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377511; batch adversarial loss: 0.572128\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383942; batch adversarial loss: 0.535757\n",
      "epoch 159; iter: 0; batch classifier loss: 0.410075; batch adversarial loss: 0.551965\n",
      "epoch 160; iter: 0; batch classifier loss: 0.334239; batch adversarial loss: 0.562961\n",
      "epoch 161; iter: 0; batch classifier loss: 0.365759; batch adversarial loss: 0.580702\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398723; batch adversarial loss: 0.544707\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353118; batch adversarial loss: 0.508722\n",
      "epoch 164; iter: 0; batch classifier loss: 0.408561; batch adversarial loss: 0.508126\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365732; batch adversarial loss: 0.509863\n",
      "epoch 166; iter: 0; batch classifier loss: 0.412472; batch adversarial loss: 0.536101\n",
      "epoch 167; iter: 0; batch classifier loss: 0.387357; batch adversarial loss: 0.518631\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401722; batch adversarial loss: 0.614287\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379392; batch adversarial loss: 0.445664\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371422; batch adversarial loss: 0.454467\n",
      "epoch 171; iter: 0; batch classifier loss: 0.275173; batch adversarial loss: 0.545531\n",
      "epoch 172; iter: 0; batch classifier loss: 0.411728; batch adversarial loss: 0.562391\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369210; batch adversarial loss: 0.579189\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311712; batch adversarial loss: 0.508932\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400737; batch adversarial loss: 0.617149\n",
      "epoch 176; iter: 0; batch classifier loss: 0.432233; batch adversarial loss: 0.536166\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337209; batch adversarial loss: 0.580852\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374283; batch adversarial loss: 0.588034\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357946; batch adversarial loss: 0.482386\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318010; batch adversarial loss: 0.473211\n",
      "epoch 181; iter: 0; batch classifier loss: 0.436905; batch adversarial loss: 0.579529\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394773; batch adversarial loss: 0.588584\n",
      "epoch 183; iter: 0; batch classifier loss: 0.461789; batch adversarial loss: 0.571132\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344498; batch adversarial loss: 0.571055\n",
      "epoch 185; iter: 0; batch classifier loss: 0.313666; batch adversarial loss: 0.590475\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357689; batch adversarial loss: 0.626021\n",
      "epoch 187; iter: 0; batch classifier loss: 0.347804; batch adversarial loss: 0.543097\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362154; batch adversarial loss: 0.517445\n",
      "epoch 189; iter: 0; batch classifier loss: 0.299526; batch adversarial loss: 0.536025\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345024; batch adversarial loss: 0.535214\n",
      "epoch 191; iter: 0; batch classifier loss: 0.455764; batch adversarial loss: 0.534656\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357892; batch adversarial loss: 0.634162\n",
      "epoch 193; iter: 0; batch classifier loss: 0.260501; batch adversarial loss: 0.499751\n",
      "epoch 194; iter: 0; batch classifier loss: 0.405674; batch adversarial loss: 0.500161\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399822; batch adversarial loss: 0.444757\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357231; batch adversarial loss: 0.536700\n",
      "epoch 197; iter: 0; batch classifier loss: 0.343041; batch adversarial loss: 0.589882\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382985; batch adversarial loss: 0.519701\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363400; batch adversarial loss: 0.518252\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708966; batch adversarial loss: 0.705337\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597219; batch adversarial loss: 0.664534\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570718; batch adversarial loss: 0.656315\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597175; batch adversarial loss: 0.634704\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538741; batch adversarial loss: 0.653439\n",
      "epoch 5; iter: 0; batch classifier loss: 0.615366; batch adversarial loss: 0.589964\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520490; batch adversarial loss: 0.608623\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605983; batch adversarial loss: 0.551966\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544020; batch adversarial loss: 0.619211\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540961; batch adversarial loss: 0.589941\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509459; batch adversarial loss: 0.581098\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580974; batch adversarial loss: 0.585524\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538390; batch adversarial loss: 0.604576\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494520; batch adversarial loss: 0.597087\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501809; batch adversarial loss: 0.536323\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509536; batch adversarial loss: 0.574185\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492123; batch adversarial loss: 0.523807\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495608; batch adversarial loss: 0.587677\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499186; batch adversarial loss: 0.556283\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479424; batch adversarial loss: 0.593952\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495226; batch adversarial loss: 0.555088\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431604; batch adversarial loss: 0.602801\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450522; batch adversarial loss: 0.516698\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466321; batch adversarial loss: 0.527535\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544888; batch adversarial loss: 0.561488\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490201; batch adversarial loss: 0.542470\n",
      "epoch 26; iter: 0; batch classifier loss: 0.488591; batch adversarial loss: 0.653412\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430896; batch adversarial loss: 0.535187\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407079; batch adversarial loss: 0.521678\n",
      "epoch 29; iter: 0; batch classifier loss: 0.536125; batch adversarial loss: 0.511487\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487370; batch adversarial loss: 0.597012\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476306; batch adversarial loss: 0.517095\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500679; batch adversarial loss: 0.552343\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425517; batch adversarial loss: 0.531564\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432032; batch adversarial loss: 0.561628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498565; batch adversarial loss: 0.546473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.507887; batch adversarial loss: 0.441278\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463999; batch adversarial loss: 0.532360\n",
      "epoch 38; iter: 0; batch classifier loss: 0.391242; batch adversarial loss: 0.550614\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423934; batch adversarial loss: 0.604240\n",
      "epoch 40; iter: 0; batch classifier loss: 0.482936; batch adversarial loss: 0.606003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397164; batch adversarial loss: 0.560814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489966; batch adversarial loss: 0.545091\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397242; batch adversarial loss: 0.579598\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412501; batch adversarial loss: 0.499434\n",
      "epoch 45; iter: 0; batch classifier loss: 0.523616; batch adversarial loss: 0.527372\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448478; batch adversarial loss: 0.616120\n",
      "epoch 47; iter: 0; batch classifier loss: 0.489664; batch adversarial loss: 0.569884\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485655; batch adversarial loss: 0.526983\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400845; batch adversarial loss: 0.589651\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411329; batch adversarial loss: 0.553596\n",
      "epoch 51; iter: 0; batch classifier loss: 0.491780; batch adversarial loss: 0.526947\n",
      "epoch 52; iter: 0; batch classifier loss: 0.394530; batch adversarial loss: 0.562754\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379860; batch adversarial loss: 0.534632\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400548; batch adversarial loss: 0.581443\n",
      "epoch 55; iter: 0; batch classifier loss: 0.456366; batch adversarial loss: 0.580971\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455702; batch adversarial loss: 0.655298\n",
      "epoch 57; iter: 0; batch classifier loss: 0.309527; batch adversarial loss: 0.615996\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414286; batch adversarial loss: 0.488760\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421695; batch adversarial loss: 0.626656\n",
      "epoch 60; iter: 0; batch classifier loss: 0.505999; batch adversarial loss: 0.598294\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470788; batch adversarial loss: 0.490862\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434004; batch adversarial loss: 0.526842\n",
      "epoch 63; iter: 0; batch classifier loss: 0.445042; batch adversarial loss: 0.542328\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371838; batch adversarial loss: 0.555530\n",
      "epoch 65; iter: 0; batch classifier loss: 0.399459; batch adversarial loss: 0.555473\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385951; batch adversarial loss: 0.583211\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427239; batch adversarial loss: 0.507662\n",
      "epoch 68; iter: 0; batch classifier loss: 0.509069; batch adversarial loss: 0.482551\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377962; batch adversarial loss: 0.643414\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447102; batch adversarial loss: 0.590014\n",
      "epoch 71; iter: 0; batch classifier loss: 0.441310; batch adversarial loss: 0.589811\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433872; batch adversarial loss: 0.544063\n",
      "epoch 73; iter: 0; batch classifier loss: 0.397357; batch adversarial loss: 0.562492\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457721; batch adversarial loss: 0.518150\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455964; batch adversarial loss: 0.517908\n",
      "epoch 76; iter: 0; batch classifier loss: 0.432806; batch adversarial loss: 0.562906\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362152; batch adversarial loss: 0.562651\n",
      "epoch 78; iter: 0; batch classifier loss: 0.456063; batch adversarial loss: 0.652566\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385421; batch adversarial loss: 0.508279\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377599; batch adversarial loss: 0.526421\n",
      "epoch 81; iter: 0; batch classifier loss: 0.442238; batch adversarial loss: 0.571871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404860; batch adversarial loss: 0.589528\n",
      "epoch 83; iter: 0; batch classifier loss: 0.390594; batch adversarial loss: 0.553584\n",
      "epoch 84; iter: 0; batch classifier loss: 0.384476; batch adversarial loss: 0.499268\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390262; batch adversarial loss: 0.517016\n",
      "epoch 86; iter: 0; batch classifier loss: 0.452650; batch adversarial loss: 0.489824\n",
      "epoch 87; iter: 0; batch classifier loss: 0.403879; batch adversarial loss: 0.517578\n",
      "epoch 88; iter: 0; batch classifier loss: 0.436145; batch adversarial loss: 0.588985\n",
      "epoch 89; iter: 0; batch classifier loss: 0.356990; batch adversarial loss: 0.452569\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410705; batch adversarial loss: 0.554019\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393361; batch adversarial loss: 0.533835\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.580678\n",
      "epoch 93; iter: 0; batch classifier loss: 0.454944; batch adversarial loss: 0.537172\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383978; batch adversarial loss: 0.561732\n",
      "epoch 95; iter: 0; batch classifier loss: 0.346059; batch adversarial loss: 0.535418\n",
      "epoch 96; iter: 0; batch classifier loss: 0.320342; batch adversarial loss: 0.535946\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419295; batch adversarial loss: 0.554065\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385611; batch adversarial loss: 0.644574\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409404; batch adversarial loss: 0.598409\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349700; batch adversarial loss: 0.588854\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410845; batch adversarial loss: 0.553185\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361938; batch adversarial loss: 0.472692\n",
      "epoch 103; iter: 0; batch classifier loss: 0.517313; batch adversarial loss: 0.428109\n",
      "epoch 104; iter: 0; batch classifier loss: 0.298582; batch adversarial loss: 0.535785\n",
      "epoch 105; iter: 0; batch classifier loss: 0.335521; batch adversarial loss: 0.643609\n",
      "epoch 106; iter: 0; batch classifier loss: 0.302505; batch adversarial loss: 0.508434\n",
      "epoch 107; iter: 0; batch classifier loss: 0.439287; batch adversarial loss: 0.562780\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357628; batch adversarial loss: 0.517267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345095; batch adversarial loss: 0.608092\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384384; batch adversarial loss: 0.571911\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344728; batch adversarial loss: 0.571694\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366798; batch adversarial loss: 0.562248\n",
      "epoch 113; iter: 0; batch classifier loss: 0.414251; batch adversarial loss: 0.571598\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420673; batch adversarial loss: 0.536988\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366026; batch adversarial loss: 0.544949\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376332; batch adversarial loss: 0.507737\n",
      "epoch 117; iter: 0; batch classifier loss: 0.315950; batch adversarial loss: 0.499534\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361923; batch adversarial loss: 0.553512\n",
      "epoch 119; iter: 0; batch classifier loss: 0.422413; batch adversarial loss: 0.554729\n",
      "epoch 120; iter: 0; batch classifier loss: 0.318488; batch adversarial loss: 0.535452\n",
      "epoch 121; iter: 0; batch classifier loss: 0.433716; batch adversarial loss: 0.490726\n",
      "epoch 122; iter: 0; batch classifier loss: 0.354467; batch adversarial loss: 0.480761\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423756; batch adversarial loss: 0.535976\n",
      "epoch 124; iter: 0; batch classifier loss: 0.332124; batch adversarial loss: 0.508074\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373775; batch adversarial loss: 0.526292\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381338; batch adversarial loss: 0.617363\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341040; batch adversarial loss: 0.579711\n",
      "epoch 128; iter: 0; batch classifier loss: 0.290583; batch adversarial loss: 0.517525\n",
      "epoch 129; iter: 0; batch classifier loss: 0.300687; batch adversarial loss: 0.544855\n",
      "epoch 130; iter: 0; batch classifier loss: 0.284293; batch adversarial loss: 0.526698\n",
      "epoch 131; iter: 0; batch classifier loss: 0.449544; batch adversarial loss: 0.526993\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394715; batch adversarial loss: 0.489759\n",
      "epoch 133; iter: 0; batch classifier loss: 0.277501; batch adversarial loss: 0.508018\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362833; batch adversarial loss: 0.580961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.370635; batch adversarial loss: 0.626554\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338062; batch adversarial loss: 0.508552\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343083; batch adversarial loss: 0.633845\n",
      "epoch 138; iter: 0; batch classifier loss: 0.448922; batch adversarial loss: 0.580668\n",
      "epoch 139; iter: 0; batch classifier loss: 0.419638; batch adversarial loss: 0.517157\n",
      "epoch 140; iter: 0; batch classifier loss: 0.444590; batch adversarial loss: 0.599052\n",
      "epoch 141; iter: 0; batch classifier loss: 0.410766; batch adversarial loss: 0.508100\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358629; batch adversarial loss: 0.553178\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364538; batch adversarial loss: 0.544346\n",
      "epoch 144; iter: 0; batch classifier loss: 0.407176; batch adversarial loss: 0.462645\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356410; batch adversarial loss: 0.499041\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350261; batch adversarial loss: 0.580906\n",
      "epoch 147; iter: 0; batch classifier loss: 0.386986; batch adversarial loss: 0.599227\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361207; batch adversarial loss: 0.562889\n",
      "epoch 149; iter: 0; batch classifier loss: 0.426045; batch adversarial loss: 0.508625\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347950; batch adversarial loss: 0.643595\n",
      "epoch 151; iter: 0; batch classifier loss: 0.403816; batch adversarial loss: 0.489820\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353980; batch adversarial loss: 0.599209\n",
      "epoch 153; iter: 0; batch classifier loss: 0.304695; batch adversarial loss: 0.598887\n",
      "epoch 154; iter: 0; batch classifier loss: 0.337133; batch adversarial loss: 0.598236\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354725; batch adversarial loss: 0.572818\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384002; batch adversarial loss: 0.617099\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330622; batch adversarial loss: 0.553615\n",
      "epoch 158; iter: 0; batch classifier loss: 0.411473; batch adversarial loss: 0.553873\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391031; batch adversarial loss: 0.526816\n",
      "epoch 160; iter: 0; batch classifier loss: 0.430664; batch adversarial loss: 0.553911\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343554; batch adversarial loss: 0.580396\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356924; batch adversarial loss: 0.544861\n",
      "epoch 163; iter: 0; batch classifier loss: 0.414007; batch adversarial loss: 0.563078\n",
      "epoch 164; iter: 0; batch classifier loss: 0.436592; batch adversarial loss: 0.598824\n",
      "epoch 165; iter: 0; batch classifier loss: 0.328550; batch adversarial loss: 0.489705\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389768; batch adversarial loss: 0.544351\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370219; batch adversarial loss: 0.508640\n",
      "epoch 168; iter: 0; batch classifier loss: 0.436555; batch adversarial loss: 0.490321\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374603; batch adversarial loss: 0.544378\n",
      "epoch 170; iter: 0; batch classifier loss: 0.396136; batch adversarial loss: 0.563235\n",
      "epoch 171; iter: 0; batch classifier loss: 0.365458; batch adversarial loss: 0.571779\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385230; batch adversarial loss: 0.499777\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378190; batch adversarial loss: 0.563031\n",
      "epoch 174; iter: 0; batch classifier loss: 0.303042; batch adversarial loss: 0.552289\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364267; batch adversarial loss: 0.544440\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381087; batch adversarial loss: 0.463030\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372444; batch adversarial loss: 0.607380\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379302; batch adversarial loss: 0.481726\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365899; batch adversarial loss: 0.508808\n",
      "epoch 180; iter: 0; batch classifier loss: 0.320155; batch adversarial loss: 0.661646\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332375; batch adversarial loss: 0.652664\n",
      "epoch 182; iter: 0; batch classifier loss: 0.414570; batch adversarial loss: 0.490016\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381200; batch adversarial loss: 0.544399\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331594; batch adversarial loss: 0.570752\n",
      "epoch 185; iter: 0; batch classifier loss: 0.343721; batch adversarial loss: 0.652963\n",
      "epoch 186; iter: 0; batch classifier loss: 0.294652; batch adversarial loss: 0.571687\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371161; batch adversarial loss: 0.543752\n",
      "epoch 188; iter: 0; batch classifier loss: 0.349769; batch adversarial loss: 0.634384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322117; batch adversarial loss: 0.463529\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390473; batch adversarial loss: 0.453827\n",
      "epoch 191; iter: 0; batch classifier loss: 0.436553; batch adversarial loss: 0.590127\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368835; batch adversarial loss: 0.571312\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361977; batch adversarial loss: 0.562405\n",
      "epoch 194; iter: 0; batch classifier loss: 0.470887; batch adversarial loss: 0.462899\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328795; batch adversarial loss: 0.490486\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381617; batch adversarial loss: 0.517199\n",
      "epoch 197; iter: 0; batch classifier loss: 0.397821; batch adversarial loss: 0.580818\n",
      "epoch 198; iter: 0; batch classifier loss: 0.320193; batch adversarial loss: 0.499122\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379613; batch adversarial loss: 0.552809\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733683; batch adversarial loss: 0.608189\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575606; batch adversarial loss: 0.653681\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580697; batch adversarial loss: 0.629995\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580151; batch adversarial loss: 0.613276\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576017; batch adversarial loss: 0.604783\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561620; batch adversarial loss: 0.588283\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522284; batch adversarial loss: 0.597383\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555273; batch adversarial loss: 0.571864\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482945; batch adversarial loss: 0.588567\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599393; batch adversarial loss: 0.606997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549625; batch adversarial loss: 0.600733\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557850; batch adversarial loss: 0.605425\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545898; batch adversarial loss: 0.603949\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566507; batch adversarial loss: 0.586934\n",
      "epoch 14; iter: 0; batch classifier loss: 0.551487; batch adversarial loss: 0.535981\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440197; batch adversarial loss: 0.615595\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450289; batch adversarial loss: 0.529584\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514511; batch adversarial loss: 0.628686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502273; batch adversarial loss: 0.519008\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455091; batch adversarial loss: 0.572216\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480091; batch adversarial loss: 0.544285\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460179; batch adversarial loss: 0.562662\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450293; batch adversarial loss: 0.554254\n",
      "epoch 23; iter: 0; batch classifier loss: 0.554189; batch adversarial loss: 0.538728\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471554; batch adversarial loss: 0.625744\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502969; batch adversarial loss: 0.610370\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404338; batch adversarial loss: 0.530115\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467144; batch adversarial loss: 0.547342\n",
      "epoch 28; iter: 0; batch classifier loss: 0.400202; batch adversarial loss: 0.574271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468107; batch adversarial loss: 0.543288\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490869; batch adversarial loss: 0.578710\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414111; batch adversarial loss: 0.547149\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458450; batch adversarial loss: 0.517562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.472429; batch adversarial loss: 0.642137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421940; batch adversarial loss: 0.556786\n",
      "epoch 35; iter: 0; batch classifier loss: 0.408883; batch adversarial loss: 0.573952\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407462; batch adversarial loss: 0.574115\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469702; batch adversarial loss: 0.590047\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480447; batch adversarial loss: 0.571226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455019; batch adversarial loss: 0.526785\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465850; batch adversarial loss: 0.624713\n",
      "epoch 41; iter: 0; batch classifier loss: 0.366181; batch adversarial loss: 0.491367\n",
      "epoch 42; iter: 0; batch classifier loss: 0.468415; batch adversarial loss: 0.553615\n",
      "epoch 43; iter: 0; batch classifier loss: 0.411825; batch adversarial loss: 0.562707\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358974; batch adversarial loss: 0.526356\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466159; batch adversarial loss: 0.608374\n",
      "epoch 46; iter: 0; batch classifier loss: 0.368743; batch adversarial loss: 0.562280\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406126; batch adversarial loss: 0.553869\n",
      "epoch 48; iter: 0; batch classifier loss: 0.346665; batch adversarial loss: 0.564092\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474011; batch adversarial loss: 0.535079\n",
      "epoch 50; iter: 0; batch classifier loss: 0.487284; batch adversarial loss: 0.552872\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432027; batch adversarial loss: 0.617286\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460807; batch adversarial loss: 0.545562\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443362; batch adversarial loss: 0.535454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.403072; batch adversarial loss: 0.508449\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396939; batch adversarial loss: 0.526046\n",
      "epoch 56; iter: 0; batch classifier loss: 0.360281; batch adversarial loss: 0.618609\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425265; batch adversarial loss: 0.571477\n",
      "epoch 58; iter: 0; batch classifier loss: 0.352488; batch adversarial loss: 0.486041\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418147; batch adversarial loss: 0.497190\n",
      "epoch 60; iter: 0; batch classifier loss: 0.438465; batch adversarial loss: 0.507676\n",
      "epoch 61; iter: 0; batch classifier loss: 0.384882; batch adversarial loss: 0.591293\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396060; batch adversarial loss: 0.589721\n",
      "epoch 63; iter: 0; batch classifier loss: 0.403971; batch adversarial loss: 0.488857\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358323; batch adversarial loss: 0.563401\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427407; batch adversarial loss: 0.480930\n",
      "epoch 66; iter: 0; batch classifier loss: 0.515164; batch adversarial loss: 0.498692\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351957; batch adversarial loss: 0.535158\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383643; batch adversarial loss: 0.617309\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371692; batch adversarial loss: 0.535090\n",
      "epoch 70; iter: 0; batch classifier loss: 0.388467; batch adversarial loss: 0.554909\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423891; batch adversarial loss: 0.506209\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399782; batch adversarial loss: 0.545199\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368093; batch adversarial loss: 0.572432\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471080; batch adversarial loss: 0.526422\n",
      "epoch 75; iter: 0; batch classifier loss: 0.414923; batch adversarial loss: 0.523359\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427987; batch adversarial loss: 0.515636\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437320; batch adversarial loss: 0.553162\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351759; batch adversarial loss: 0.525888\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390226; batch adversarial loss: 0.519017\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371490; batch adversarial loss: 0.527261\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397590; batch adversarial loss: 0.533832\n",
      "epoch 82; iter: 0; batch classifier loss: 0.466986; batch adversarial loss: 0.572070\n",
      "epoch 83; iter: 0; batch classifier loss: 0.460040; batch adversarial loss: 0.471367\n",
      "epoch 84; iter: 0; batch classifier loss: 0.379336; batch adversarial loss: 0.562932\n",
      "epoch 85; iter: 0; batch classifier loss: 0.418855; batch adversarial loss: 0.523919\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367251; batch adversarial loss: 0.516501\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350595; batch adversarial loss: 0.479650\n",
      "epoch 88; iter: 0; batch classifier loss: 0.480059; batch adversarial loss: 0.618774\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401400; batch adversarial loss: 0.553149\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417907; batch adversarial loss: 0.552599\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454719; batch adversarial loss: 0.535145\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387289; batch adversarial loss: 0.562392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.355099; batch adversarial loss: 0.479206\n",
      "epoch 94; iter: 0; batch classifier loss: 0.369041; batch adversarial loss: 0.532980\n",
      "epoch 95; iter: 0; batch classifier loss: 0.458280; batch adversarial loss: 0.535301\n",
      "epoch 96; iter: 0; batch classifier loss: 0.450029; batch adversarial loss: 0.543366\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396519; batch adversarial loss: 0.560311\n",
      "epoch 98; iter: 0; batch classifier loss: 0.306399; batch adversarial loss: 0.416561\n",
      "epoch 99; iter: 0; batch classifier loss: 0.336984; batch adversarial loss: 0.588814\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386974; batch adversarial loss: 0.552616\n",
      "epoch 101; iter: 0; batch classifier loss: 0.317773; batch adversarial loss: 0.553117\n",
      "epoch 102; iter: 0; batch classifier loss: 0.470621; batch adversarial loss: 0.554329\n",
      "epoch 103; iter: 0; batch classifier loss: 0.351011; batch adversarial loss: 0.497999\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352944; batch adversarial loss: 0.546160\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373956; batch adversarial loss: 0.495413\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382800; batch adversarial loss: 0.526834\n",
      "epoch 107; iter: 0; batch classifier loss: 0.473872; batch adversarial loss: 0.545923\n",
      "epoch 108; iter: 0; batch classifier loss: 0.466567; batch adversarial loss: 0.506299\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360260; batch adversarial loss: 0.563484\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381394; batch adversarial loss: 0.564295\n",
      "epoch 111; iter: 0; batch classifier loss: 0.328921; batch adversarial loss: 0.500444\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339497; batch adversarial loss: 0.554057\n",
      "epoch 113; iter: 0; batch classifier loss: 0.302355; batch adversarial loss: 0.506478\n",
      "epoch 114; iter: 0; batch classifier loss: 0.303368; batch adversarial loss: 0.627391\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332192; batch adversarial loss: 0.616708\n",
      "epoch 116; iter: 0; batch classifier loss: 0.447244; batch adversarial loss: 0.544827\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402819; batch adversarial loss: 0.509362\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410855; batch adversarial loss: 0.562423\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384213; batch adversarial loss: 0.597039\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340917; batch adversarial loss: 0.561552\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345091; batch adversarial loss: 0.518582\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371233; batch adversarial loss: 0.541214\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352647; batch adversarial loss: 0.496260\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347591; batch adversarial loss: 0.560524\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411096; batch adversarial loss: 0.526066\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316432; batch adversarial loss: 0.432516\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417360; batch adversarial loss: 0.580691\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373838; batch adversarial loss: 0.498227\n",
      "epoch 129; iter: 0; batch classifier loss: 0.435406; batch adversarial loss: 0.571167\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340181; batch adversarial loss: 0.544577\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350780; batch adversarial loss: 0.535409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.377364; batch adversarial loss: 0.500232\n",
      "epoch 133; iter: 0; batch classifier loss: 0.348186; batch adversarial loss: 0.524337\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406296; batch adversarial loss: 0.553207\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339785; batch adversarial loss: 0.571222\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385724; batch adversarial loss: 0.527216\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369513; batch adversarial loss: 0.583098\n",
      "epoch 138; iter: 0; batch classifier loss: 0.473271; batch adversarial loss: 0.523278\n",
      "epoch 139; iter: 0; batch classifier loss: 0.320079; batch adversarial loss: 0.454724\n",
      "epoch 140; iter: 0; batch classifier loss: 0.408465; batch adversarial loss: 0.583182\n",
      "epoch 141; iter: 0; batch classifier loss: 0.476575; batch adversarial loss: 0.516886\n",
      "epoch 142; iter: 0; batch classifier loss: 0.440358; batch adversarial loss: 0.498976\n",
      "epoch 143; iter: 0; batch classifier loss: 0.457788; batch adversarial loss: 0.532170\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381429; batch adversarial loss: 0.582153\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351071; batch adversarial loss: 0.482117\n",
      "epoch 146; iter: 0; batch classifier loss: 0.409783; batch adversarial loss: 0.573246\n",
      "epoch 147; iter: 0; batch classifier loss: 0.406597; batch adversarial loss: 0.619731\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303387; batch adversarial loss: 0.573712\n",
      "epoch 149; iter: 0; batch classifier loss: 0.434819; batch adversarial loss: 0.571235\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378839; batch adversarial loss: 0.582433\n",
      "epoch 151; iter: 0; batch classifier loss: 0.292283; batch adversarial loss: 0.545651\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320220; batch adversarial loss: 0.572697\n",
      "epoch 153; iter: 0; batch classifier loss: 0.378282; batch adversarial loss: 0.535477\n",
      "epoch 154; iter: 0; batch classifier loss: 0.410048; batch adversarial loss: 0.553369\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396495; batch adversarial loss: 0.612003\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340724; batch adversarial loss: 0.517067\n",
      "epoch 157; iter: 0; batch classifier loss: 0.398419; batch adversarial loss: 0.562779\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381358; batch adversarial loss: 0.506908\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351531; batch adversarial loss: 0.534603\n",
      "epoch 160; iter: 0; batch classifier loss: 0.442290; batch adversarial loss: 0.451852\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363127; batch adversarial loss: 0.562500\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329617; batch adversarial loss: 0.627379\n",
      "epoch 163; iter: 0; batch classifier loss: 0.313532; batch adversarial loss: 0.526057\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374080; batch adversarial loss: 0.506899\n",
      "epoch 165; iter: 0; batch classifier loss: 0.287746; batch adversarial loss: 0.535834\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339994; batch adversarial loss: 0.515728\n",
      "epoch 167; iter: 0; batch classifier loss: 0.325937; batch adversarial loss: 0.524884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358584; batch adversarial loss: 0.563273\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344084; batch adversarial loss: 0.619001\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336782; batch adversarial loss: 0.527932\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332411; batch adversarial loss: 0.525862\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342713; batch adversarial loss: 0.571171\n",
      "epoch 173; iter: 0; batch classifier loss: 0.395004; batch adversarial loss: 0.524710\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378719; batch adversarial loss: 0.480913\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311882; batch adversarial loss: 0.561052\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323772; batch adversarial loss: 0.572689\n",
      "epoch 177; iter: 0; batch classifier loss: 0.370604; batch adversarial loss: 0.486741\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407844; batch adversarial loss: 0.571897\n",
      "epoch 179; iter: 0; batch classifier loss: 0.363797; batch adversarial loss: 0.516423\n",
      "epoch 180; iter: 0; batch classifier loss: 0.300556; batch adversarial loss: 0.581029\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379700; batch adversarial loss: 0.552454\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368354; batch adversarial loss: 0.488238\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351642; batch adversarial loss: 0.572402\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351969; batch adversarial loss: 0.477563\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338577; batch adversarial loss: 0.580927\n",
      "epoch 186; iter: 0; batch classifier loss: 0.447641; batch adversarial loss: 0.534415\n",
      "epoch 187; iter: 0; batch classifier loss: 0.413803; batch adversarial loss: 0.580777\n",
      "epoch 188; iter: 0; batch classifier loss: 0.295786; batch adversarial loss: 0.536258\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351348; batch adversarial loss: 0.517694\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407594; batch adversarial loss: 0.653963\n",
      "epoch 191; iter: 0; batch classifier loss: 0.406275; batch adversarial loss: 0.470145\n",
      "epoch 192; iter: 0; batch classifier loss: 0.285935; batch adversarial loss: 0.621921\n",
      "epoch 193; iter: 0; batch classifier loss: 0.366197; batch adversarial loss: 0.588714\n",
      "epoch 194; iter: 0; batch classifier loss: 0.276983; batch adversarial loss: 0.554553\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374774; batch adversarial loss: 0.555401\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330824; batch adversarial loss: 0.470670\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365035; batch adversarial loss: 0.572186\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350537; batch adversarial loss: 0.535567\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380153; batch adversarial loss: 0.544053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686219; batch adversarial loss: 0.634694\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598546; batch adversarial loss: 0.641953\n",
      "epoch 2; iter: 0; batch classifier loss: 0.638619; batch adversarial loss: 0.627226\n",
      "epoch 3; iter: 0; batch classifier loss: 0.587595; batch adversarial loss: 0.617325\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617758; batch adversarial loss: 0.691994\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558982; batch adversarial loss: 0.651792\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559126; batch adversarial loss: 0.584657\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514278; batch adversarial loss: 0.550601\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539746; batch adversarial loss: 0.584276\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495132; batch adversarial loss: 0.590814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610770; batch adversarial loss: 0.607471\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517581; batch adversarial loss: 0.545553\n",
      "epoch 12; iter: 0; batch classifier loss: 0.573649; batch adversarial loss: 0.593938\n",
      "epoch 13; iter: 0; batch classifier loss: 0.581435; batch adversarial loss: 0.608074\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515547; batch adversarial loss: 0.618330\n",
      "epoch 15; iter: 0; batch classifier loss: 0.622377; batch adversarial loss: 0.588522\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526949; batch adversarial loss: 0.515999\n",
      "epoch 17; iter: 0; batch classifier loss: 0.575048; batch adversarial loss: 0.554623\n",
      "epoch 18; iter: 0; batch classifier loss: 0.552962; batch adversarial loss: 0.557995\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479285; batch adversarial loss: 0.526209\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517031; batch adversarial loss: 0.507645\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507921; batch adversarial loss: 0.577520\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463040; batch adversarial loss: 0.542062\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478036; batch adversarial loss: 0.514127\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492238; batch adversarial loss: 0.565224\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498283; batch adversarial loss: 0.530915\n",
      "epoch 26; iter: 0; batch classifier loss: 0.521290; batch adversarial loss: 0.563778\n",
      "epoch 27; iter: 0; batch classifier loss: 0.535614; batch adversarial loss: 0.553690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455370; batch adversarial loss: 0.537121\n",
      "epoch 29; iter: 0; batch classifier loss: 0.544287; batch adversarial loss: 0.521953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.437552; batch adversarial loss: 0.598601\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480943; batch adversarial loss: 0.656833\n",
      "epoch 32; iter: 0; batch classifier loss: 0.521163; batch adversarial loss: 0.542305\n",
      "epoch 33; iter: 0; batch classifier loss: 0.551085; batch adversarial loss: 0.572718\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453820; batch adversarial loss: 0.500413\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498485; batch adversarial loss: 0.529220\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451658; batch adversarial loss: 0.564922\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473992; batch adversarial loss: 0.643999\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500554; batch adversarial loss: 0.536648\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427882; batch adversarial loss: 0.590936\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447138; batch adversarial loss: 0.480306\n",
      "epoch 41; iter: 0; batch classifier loss: 0.525695; batch adversarial loss: 0.518837\n",
      "epoch 42; iter: 0; batch classifier loss: 0.486978; batch adversarial loss: 0.609043\n",
      "epoch 43; iter: 0; batch classifier loss: 0.521848; batch adversarial loss: 0.463595\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382451; batch adversarial loss: 0.562663\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438564; batch adversarial loss: 0.616345\n",
      "epoch 46; iter: 0; batch classifier loss: 0.519190; batch adversarial loss: 0.443161\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433104; batch adversarial loss: 0.545601\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401757; batch adversarial loss: 0.544709\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456829; batch adversarial loss: 0.489319\n",
      "epoch 50; iter: 0; batch classifier loss: 0.440227; batch adversarial loss: 0.534827\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462396; batch adversarial loss: 0.563635\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458457; batch adversarial loss: 0.451993\n",
      "epoch 53; iter: 0; batch classifier loss: 0.360155; batch adversarial loss: 0.589712\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411788; batch adversarial loss: 0.572053\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393855; batch adversarial loss: 0.490032\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428003; batch adversarial loss: 0.507981\n",
      "epoch 57; iter: 0; batch classifier loss: 0.527121; batch adversarial loss: 0.508595\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463756; batch adversarial loss: 0.544103\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426349; batch adversarial loss: 0.472193\n",
      "epoch 60; iter: 0; batch classifier loss: 0.500858; batch adversarial loss: 0.553747\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408182; batch adversarial loss: 0.642286\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434283; batch adversarial loss: 0.510695\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362135; batch adversarial loss: 0.617563\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451821; batch adversarial loss: 0.508124\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408728; batch adversarial loss: 0.608380\n",
      "epoch 66; iter: 0; batch classifier loss: 0.469522; batch adversarial loss: 0.563108\n",
      "epoch 67; iter: 0; batch classifier loss: 0.439387; batch adversarial loss: 0.628810\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.563340\n",
      "epoch 69; iter: 0; batch classifier loss: 0.365258; batch adversarial loss: 0.544844\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428111; batch adversarial loss: 0.480057\n",
      "epoch 71; iter: 0; batch classifier loss: 0.461815; batch adversarial loss: 0.508038\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403055; batch adversarial loss: 0.553208\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407758; batch adversarial loss: 0.535003\n",
      "epoch 74; iter: 0; batch classifier loss: 0.417519; batch adversarial loss: 0.470613\n",
      "epoch 75; iter: 0; batch classifier loss: 0.466275; batch adversarial loss: 0.535276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.484649; batch adversarial loss: 0.562899\n",
      "epoch 77; iter: 0; batch classifier loss: 0.476708; batch adversarial loss: 0.544219\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404800; batch adversarial loss: 0.571702\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402187; batch adversarial loss: 0.544683\n",
      "epoch 80; iter: 0; batch classifier loss: 0.461658; batch adversarial loss: 0.590311\n",
      "epoch 81; iter: 0; batch classifier loss: 0.411599; batch adversarial loss: 0.544498\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362778; batch adversarial loss: 0.562763\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426963; batch adversarial loss: 0.562867\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437406; batch adversarial loss: 0.517069\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450410; batch adversarial loss: 0.609013\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419492; batch adversarial loss: 0.480382\n",
      "epoch 87; iter: 0; batch classifier loss: 0.449308; batch adversarial loss: 0.480263\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379052; batch adversarial loss: 0.461708\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428352; batch adversarial loss: 0.617966\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388304; batch adversarial loss: 0.498549\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367128; batch adversarial loss: 0.562326\n",
      "epoch 92; iter: 0; batch classifier loss: 0.380785; batch adversarial loss: 0.561939\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390400; batch adversarial loss: 0.571827\n",
      "epoch 94; iter: 0; batch classifier loss: 0.342916; batch adversarial loss: 0.472539\n",
      "epoch 95; iter: 0; batch classifier loss: 0.390801; batch adversarial loss: 0.534227\n",
      "epoch 96; iter: 0; batch classifier loss: 0.353979; batch adversarial loss: 0.581167\n",
      "epoch 97; iter: 0; batch classifier loss: 0.409441; batch adversarial loss: 0.552376\n",
      "epoch 98; iter: 0; batch classifier loss: 0.440627; batch adversarial loss: 0.553695\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341877; batch adversarial loss: 0.499760\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370314; batch adversarial loss: 0.462260\n",
      "epoch 101; iter: 0; batch classifier loss: 0.428222; batch adversarial loss: 0.535909\n",
      "epoch 102; iter: 0; batch classifier loss: 0.449648; batch adversarial loss: 0.526391\n",
      "epoch 103; iter: 0; batch classifier loss: 0.410885; batch adversarial loss: 0.664476\n",
      "epoch 104; iter: 0; batch classifier loss: 0.526150; batch adversarial loss: 0.507884\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370541; batch adversarial loss: 0.553893\n",
      "epoch 106; iter: 0; batch classifier loss: 0.520885; batch adversarial loss: 0.591010\n",
      "epoch 107; iter: 0; batch classifier loss: 0.342572; batch adversarial loss: 0.526079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366591; batch adversarial loss: 0.525603\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352756; batch adversarial loss: 0.563042\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339745; batch adversarial loss: 0.535311\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335759; batch adversarial loss: 0.599759\n",
      "epoch 112; iter: 0; batch classifier loss: 0.346843; batch adversarial loss: 0.636161\n",
      "epoch 113; iter: 0; batch classifier loss: 0.414698; batch adversarial loss: 0.526003\n",
      "epoch 114; iter: 0; batch classifier loss: 0.455454; batch adversarial loss: 0.461777\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398147; batch adversarial loss: 0.462252\n",
      "epoch 116; iter: 0; batch classifier loss: 0.460421; batch adversarial loss: 0.681706\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416663; batch adversarial loss: 0.480438\n",
      "epoch 118; iter: 0; batch classifier loss: 0.311921; batch adversarial loss: 0.562933\n",
      "epoch 119; iter: 0; batch classifier loss: 0.326276; batch adversarial loss: 0.535753\n",
      "epoch 120; iter: 0; batch classifier loss: 0.304587; batch adversarial loss: 0.544504\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403657; batch adversarial loss: 0.507754\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424930; batch adversarial loss: 0.526256\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414248; batch adversarial loss: 0.553916\n",
      "epoch 124; iter: 0; batch classifier loss: 0.412758; batch adversarial loss: 0.461515\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373218; batch adversarial loss: 0.553843\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413297; batch adversarial loss: 0.498036\n",
      "epoch 127; iter: 0; batch classifier loss: 0.446399; batch adversarial loss: 0.535344\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340807; batch adversarial loss: 0.525836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.429811; batch adversarial loss: 0.554286\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385564; batch adversarial loss: 0.498459\n",
      "epoch 131; iter: 0; batch classifier loss: 0.305202; batch adversarial loss: 0.516800\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404255; batch adversarial loss: 0.599443\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395125; batch adversarial loss: 0.526123\n",
      "epoch 134; iter: 0; batch classifier loss: 0.455539; batch adversarial loss: 0.581131\n",
      "epoch 135; iter: 0; batch classifier loss: 0.416406; batch adversarial loss: 0.600576\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373694; batch adversarial loss: 0.590320\n",
      "epoch 137; iter: 0; batch classifier loss: 0.338508; batch adversarial loss: 0.506788\n",
      "epoch 138; iter: 0; batch classifier loss: 0.297157; batch adversarial loss: 0.589618\n",
      "epoch 139; iter: 0; batch classifier loss: 0.364034; batch adversarial loss: 0.570514\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397861; batch adversarial loss: 0.495527\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342266; batch adversarial loss: 0.540572\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418330; batch adversarial loss: 0.556184\n",
      "epoch 143; iter: 0; batch classifier loss: 0.325927; batch adversarial loss: 0.562329\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302442; batch adversarial loss: 0.589516\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339604; batch adversarial loss: 0.584586\n",
      "epoch 146; iter: 0; batch classifier loss: 0.443378; batch adversarial loss: 0.552119\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312630; batch adversarial loss: 0.563938\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339886; batch adversarial loss: 0.518601\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336027; batch adversarial loss: 0.571471\n",
      "epoch 150; iter: 0; batch classifier loss: 0.332684; batch adversarial loss: 0.462652\n",
      "epoch 151; iter: 0; batch classifier loss: 0.412386; batch adversarial loss: 0.498993\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384359; batch adversarial loss: 0.481598\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372589; batch adversarial loss: 0.517657\n",
      "epoch 154; iter: 0; batch classifier loss: 0.330102; batch adversarial loss: 0.535480\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401390; batch adversarial loss: 0.490487\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370224; batch adversarial loss: 0.535485\n",
      "epoch 157; iter: 0; batch classifier loss: 0.374423; batch adversarial loss: 0.535373\n",
      "epoch 158; iter: 0; batch classifier loss: 0.419364; batch adversarial loss: 0.581227\n",
      "epoch 159; iter: 0; batch classifier loss: 0.408713; batch adversarial loss: 0.425632\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384347; batch adversarial loss: 0.571915\n",
      "epoch 161; iter: 0; batch classifier loss: 0.422587; batch adversarial loss: 0.544637\n",
      "epoch 162; iter: 0; batch classifier loss: 0.365640; batch adversarial loss: 0.498432\n",
      "epoch 163; iter: 0; batch classifier loss: 0.437904; batch adversarial loss: 0.590787\n",
      "epoch 164; iter: 0; batch classifier loss: 0.293720; batch adversarial loss: 0.581130\n",
      "epoch 165; iter: 0; batch classifier loss: 0.350492; batch adversarial loss: 0.544167\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329664; batch adversarial loss: 0.535301\n",
      "epoch 167; iter: 0; batch classifier loss: 0.264861; batch adversarial loss: 0.553443\n",
      "epoch 168; iter: 0; batch classifier loss: 0.420380; batch adversarial loss: 0.571518\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408370; batch adversarial loss: 0.553453\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329363; batch adversarial loss: 0.562936\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353012; batch adversarial loss: 0.517342\n",
      "epoch 172; iter: 0; batch classifier loss: 0.302892; batch adversarial loss: 0.580986\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346676; batch adversarial loss: 0.480320\n",
      "epoch 174; iter: 0; batch classifier loss: 0.403722; batch adversarial loss: 0.517117\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385885; batch adversarial loss: 0.498605\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363864; batch adversarial loss: 0.516918\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417747; batch adversarial loss: 0.507906\n",
      "epoch 178; iter: 0; batch classifier loss: 0.472940; batch adversarial loss: 0.535568\n",
      "epoch 179; iter: 0; batch classifier loss: 0.409416; batch adversarial loss: 0.489487\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324736; batch adversarial loss: 0.508197\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337215; batch adversarial loss: 0.526183\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352495; batch adversarial loss: 0.581338\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342854; batch adversarial loss: 0.526104\n",
      "epoch 184; iter: 0; batch classifier loss: 0.290642; batch adversarial loss: 0.572067\n",
      "epoch 185; iter: 0; batch classifier loss: 0.353423; batch adversarial loss: 0.562937\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399763; batch adversarial loss: 0.599937\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359558; batch adversarial loss: 0.507928\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392543; batch adversarial loss: 0.599857\n",
      "epoch 189; iter: 0; batch classifier loss: 0.289868; batch adversarial loss: 0.572082\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358857; batch adversarial loss: 0.544574\n",
      "epoch 191; iter: 0; batch classifier loss: 0.405419; batch adversarial loss: 0.572262\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403261; batch adversarial loss: 0.572436\n",
      "epoch 193; iter: 0; batch classifier loss: 0.439646; batch adversarial loss: 0.498754\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349028; batch adversarial loss: 0.553840\n",
      "epoch 195; iter: 0; batch classifier loss: 0.464862; batch adversarial loss: 0.489114\n",
      "epoch 196; iter: 0; batch classifier loss: 0.367788; batch adversarial loss: 0.599486\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337001; batch adversarial loss: 0.581271\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365839; batch adversarial loss: 0.526144\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381004; batch adversarial loss: 0.516861\n",
      "epoch 0; iter: 0; batch classifier loss: 0.810898; batch adversarial loss: 0.977644\n",
      "epoch 1; iter: 0; batch classifier loss: 0.799460; batch adversarial loss: 0.967818\n",
      "epoch 2; iter: 0; batch classifier loss: 0.698436; batch adversarial loss: 0.984360\n",
      "epoch 3; iter: 0; batch classifier loss: 0.635715; batch adversarial loss: 0.868327\n",
      "epoch 4; iter: 0; batch classifier loss: 0.641701; batch adversarial loss: 0.771842\n",
      "epoch 5; iter: 0; batch classifier loss: 0.584854; batch adversarial loss: 0.756641\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512762; batch adversarial loss: 0.684636\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538465; batch adversarial loss: 0.676614\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579555; batch adversarial loss: 0.713813\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560770; batch adversarial loss: 0.651808\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571038; batch adversarial loss: 0.613287\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529761; batch adversarial loss: 0.604832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.459570; batch adversarial loss: 0.607293\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569687; batch adversarial loss: 0.658925\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556585; batch adversarial loss: 0.647771\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516282; batch adversarial loss: 0.620452\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513750; batch adversarial loss: 0.590842\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470908; batch adversarial loss: 0.565243\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477927; batch adversarial loss: 0.554472\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523399; batch adversarial loss: 0.561497\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495527; batch adversarial loss: 0.566908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.561409; batch adversarial loss: 0.571756\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483851; batch adversarial loss: 0.549066\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449797; batch adversarial loss: 0.546654\n",
      "epoch 24; iter: 0; batch classifier loss: 0.380455; batch adversarial loss: 0.611894\n",
      "epoch 25; iter: 0; batch classifier loss: 0.435166; batch adversarial loss: 0.585604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.463963; batch adversarial loss: 0.554249\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491099; batch adversarial loss: 0.549619\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513220; batch adversarial loss: 0.488156\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441376; batch adversarial loss: 0.556107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484880; batch adversarial loss: 0.554404\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454461; batch adversarial loss: 0.464127\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467393; batch adversarial loss: 0.533999\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523654; batch adversarial loss: 0.526417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500783; batch adversarial loss: 0.603000\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410159; batch adversarial loss: 0.616061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438822; batch adversarial loss: 0.490091\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508237; batch adversarial loss: 0.463053\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429701; batch adversarial loss: 0.591390\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460548; batch adversarial loss: 0.637258\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410552; batch adversarial loss: 0.549345\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433161; batch adversarial loss: 0.450127\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451881; batch adversarial loss: 0.533387\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423826; batch adversarial loss: 0.553096\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463488; batch adversarial loss: 0.588661\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485465; batch adversarial loss: 0.521814\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410290; batch adversarial loss: 0.547246\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442457; batch adversarial loss: 0.621612\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415431; batch adversarial loss: 0.545666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402048; batch adversarial loss: 0.531418\n",
      "epoch 50; iter: 0; batch classifier loss: 0.487634; batch adversarial loss: 0.562450\n",
      "epoch 51; iter: 0; batch classifier loss: 0.547444; batch adversarial loss: 0.621847\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449997; batch adversarial loss: 0.520544\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425301; batch adversarial loss: 0.572799\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392120; batch adversarial loss: 0.483163\n",
      "epoch 55; iter: 0; batch classifier loss: 0.424546; batch adversarial loss: 0.552772\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442008; batch adversarial loss: 0.564757\n",
      "epoch 57; iter: 0; batch classifier loss: 0.493818; batch adversarial loss: 0.542034\n",
      "epoch 58; iter: 0; batch classifier loss: 0.362105; batch adversarial loss: 0.544148\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433132; batch adversarial loss: 0.580532\n",
      "epoch 60; iter: 0; batch classifier loss: 0.478685; batch adversarial loss: 0.564057\n",
      "epoch 61; iter: 0; batch classifier loss: 0.461123; batch adversarial loss: 0.526782\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433775; batch adversarial loss: 0.553072\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423019; batch adversarial loss: 0.536958\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390865; batch adversarial loss: 0.553556\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430556; batch adversarial loss: 0.552907\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432852; batch adversarial loss: 0.527269\n",
      "epoch 67; iter: 0; batch classifier loss: 0.354944; batch adversarial loss: 0.499211\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376977; batch adversarial loss: 0.617125\n",
      "epoch 69; iter: 0; batch classifier loss: 0.345756; batch adversarial loss: 0.517575\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343878; batch adversarial loss: 0.544501\n",
      "epoch 71; iter: 0; batch classifier loss: 0.456121; batch adversarial loss: 0.536170\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380582; batch adversarial loss: 0.535738\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387848; batch adversarial loss: 0.616686\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464175; batch adversarial loss: 0.527019\n",
      "epoch 75; iter: 0; batch classifier loss: 0.501145; batch adversarial loss: 0.536297\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347411; batch adversarial loss: 0.589254\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402583; batch adversarial loss: 0.580409\n",
      "epoch 78; iter: 0; batch classifier loss: 0.423560; batch adversarial loss: 0.553498\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417063; batch adversarial loss: 0.490406\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421589; batch adversarial loss: 0.498510\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407587; batch adversarial loss: 0.535572\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416599; batch adversarial loss: 0.579807\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398568; batch adversarial loss: 0.505059\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392977; batch adversarial loss: 0.577581\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385782; batch adversarial loss: 0.534129\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403303; batch adversarial loss: 0.524658\n",
      "epoch 87; iter: 0; batch classifier loss: 0.525289; batch adversarial loss: 0.527761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408221; batch adversarial loss: 0.568126\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361410; batch adversarial loss: 0.554940\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353849; batch adversarial loss: 0.523796\n",
      "epoch 91; iter: 0; batch classifier loss: 0.324706; batch adversarial loss: 0.508936\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379253; batch adversarial loss: 0.554494\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412294; batch adversarial loss: 0.555636\n",
      "epoch 94; iter: 0; batch classifier loss: 0.464082; batch adversarial loss: 0.504117\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348385; batch adversarial loss: 0.544628\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387009; batch adversarial loss: 0.526619\n",
      "epoch 97; iter: 0; batch classifier loss: 0.458676; batch adversarial loss: 0.590931\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379029; batch adversarial loss: 0.517870\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376308; batch adversarial loss: 0.571751\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374566; batch adversarial loss: 0.544854\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381945; batch adversarial loss: 0.536891\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328460; batch adversarial loss: 0.527144\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434056; batch adversarial loss: 0.516231\n",
      "epoch 104; iter: 0; batch classifier loss: 0.336933; batch adversarial loss: 0.591318\n",
      "epoch 105; iter: 0; batch classifier loss: 0.319456; batch adversarial loss: 0.605914\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441861; batch adversarial loss: 0.518876\n",
      "epoch 107; iter: 0; batch classifier loss: 0.420149; batch adversarial loss: 0.526866\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388715; batch adversarial loss: 0.550062\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340394; batch adversarial loss: 0.509409\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390914; batch adversarial loss: 0.562094\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344501; batch adversarial loss: 0.527866\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352166; batch adversarial loss: 0.616544\n",
      "epoch 113; iter: 0; batch classifier loss: 0.348452; batch adversarial loss: 0.537012\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405080; batch adversarial loss: 0.566125\n",
      "epoch 115; iter: 0; batch classifier loss: 0.430510; batch adversarial loss: 0.534512\n",
      "epoch 116; iter: 0; batch classifier loss: 0.439821; batch adversarial loss: 0.515705\n",
      "epoch 117; iter: 0; batch classifier loss: 0.309358; batch adversarial loss: 0.500238\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360804; batch adversarial loss: 0.572165\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384555; batch adversarial loss: 0.606481\n",
      "epoch 120; iter: 0; batch classifier loss: 0.446570; batch adversarial loss: 0.497159\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388126; batch adversarial loss: 0.591641\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343871; batch adversarial loss: 0.578877\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354879; batch adversarial loss: 0.514180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.324517; batch adversarial loss: 0.559846\n",
      "epoch 125; iter: 0; batch classifier loss: 0.396379; batch adversarial loss: 0.567694\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350371; batch adversarial loss: 0.564562\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369100; batch adversarial loss: 0.502844\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403430; batch adversarial loss: 0.607903\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365300; batch adversarial loss: 0.526425\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365339; batch adversarial loss: 0.509550\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343764; batch adversarial loss: 0.579823\n",
      "epoch 132; iter: 0; batch classifier loss: 0.309038; batch adversarial loss: 0.466253\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369045; batch adversarial loss: 0.579996\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374629; batch adversarial loss: 0.500304\n",
      "epoch 135; iter: 0; batch classifier loss: 0.330613; batch adversarial loss: 0.546077\n",
      "epoch 136; iter: 0; batch classifier loss: 0.309388; batch adversarial loss: 0.552428\n",
      "epoch 137; iter: 0; batch classifier loss: 0.397188; batch adversarial loss: 0.546099\n",
      "epoch 138; iter: 0; batch classifier loss: 0.329901; batch adversarial loss: 0.570874\n",
      "epoch 139; iter: 0; batch classifier loss: 0.321610; batch adversarial loss: 0.561263\n",
      "epoch 140; iter: 0; batch classifier loss: 0.326063; batch adversarial loss: 0.491932\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328868; batch adversarial loss: 0.544721\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351272; batch adversarial loss: 0.579161\n",
      "epoch 143; iter: 0; batch classifier loss: 0.351186; batch adversarial loss: 0.606601\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384596; batch adversarial loss: 0.552492\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338701; batch adversarial loss: 0.518465\n",
      "epoch 146; iter: 0; batch classifier loss: 0.392324; batch adversarial loss: 0.668392\n",
      "epoch 147; iter: 0; batch classifier loss: 0.291448; batch adversarial loss: 0.465300\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357268; batch adversarial loss: 0.562354\n",
      "epoch 149; iter: 0; batch classifier loss: 0.332215; batch adversarial loss: 0.562365\n",
      "epoch 150; iter: 0; batch classifier loss: 0.428382; batch adversarial loss: 0.500448\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374686; batch adversarial loss: 0.508312\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376064; batch adversarial loss: 0.508902\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368106; batch adversarial loss: 0.580680\n",
      "epoch 154; iter: 0; batch classifier loss: 0.285579; batch adversarial loss: 0.561719\n",
      "epoch 155; iter: 0; batch classifier loss: 0.312127; batch adversarial loss: 0.525460\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361849; batch adversarial loss: 0.509445\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315184; batch adversarial loss: 0.608114\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327538; batch adversarial loss: 0.580417\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348424; batch adversarial loss: 0.482032\n",
      "epoch 160; iter: 0; batch classifier loss: 0.293972; batch adversarial loss: 0.525082\n",
      "epoch 161; iter: 0; batch classifier loss: 0.455115; batch adversarial loss: 0.669663\n",
      "epoch 162; iter: 0; batch classifier loss: 0.330382; batch adversarial loss: 0.453599\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350189; batch adversarial loss: 0.535389\n",
      "epoch 164; iter: 0; batch classifier loss: 0.319956; batch adversarial loss: 0.588513\n",
      "epoch 165; iter: 0; batch classifier loss: 0.338817; batch adversarial loss: 0.563967\n",
      "epoch 166; iter: 0; batch classifier loss: 0.386375; batch adversarial loss: 0.652220\n",
      "epoch 167; iter: 0; batch classifier loss: 0.357966; batch adversarial loss: 0.568753\n",
      "epoch 168; iter: 0; batch classifier loss: 0.461735; batch adversarial loss: 0.504525\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342647; batch adversarial loss: 0.549999\n",
      "epoch 170; iter: 0; batch classifier loss: 0.257012; batch adversarial loss: 0.534150\n",
      "epoch 171; iter: 0; batch classifier loss: 0.318852; batch adversarial loss: 0.600150\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368291; batch adversarial loss: 0.526191\n",
      "epoch 173; iter: 0; batch classifier loss: 0.353148; batch adversarial loss: 0.547129\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333861; batch adversarial loss: 0.608607\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376750; batch adversarial loss: 0.554240\n",
      "epoch 176; iter: 0; batch classifier loss: 0.371667; batch adversarial loss: 0.537071\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378691; batch adversarial loss: 0.560419\n",
      "epoch 178; iter: 0; batch classifier loss: 0.321622; batch adversarial loss: 0.501297\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383924; batch adversarial loss: 0.597935\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327907; batch adversarial loss: 0.597482\n",
      "epoch 181; iter: 0; batch classifier loss: 0.266834; batch adversarial loss: 0.499179\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348535; batch adversarial loss: 0.535819\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373764; batch adversarial loss: 0.597596\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390514; batch adversarial loss: 0.552371\n",
      "epoch 185; iter: 0; batch classifier loss: 0.340462; batch adversarial loss: 0.551980\n",
      "epoch 186; iter: 0; batch classifier loss: 0.423728; batch adversarial loss: 0.525016\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339134; batch adversarial loss: 0.542912\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329556; batch adversarial loss: 0.526086\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361653; batch adversarial loss: 0.645523\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349455; batch adversarial loss: 0.545720\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339166; batch adversarial loss: 0.508131\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298279; batch adversarial loss: 0.597721\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337679; batch adversarial loss: 0.517343\n",
      "epoch 194; iter: 0; batch classifier loss: 0.303082; batch adversarial loss: 0.517619\n",
      "epoch 195; iter: 0; batch classifier loss: 0.389782; batch adversarial loss: 0.501391\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301672; batch adversarial loss: 0.580108\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375769; batch adversarial loss: 0.526043\n",
      "epoch 198; iter: 0; batch classifier loss: 0.307725; batch adversarial loss: 0.544823\n",
      "epoch 199; iter: 0; batch classifier loss: 0.419394; batch adversarial loss: 0.543007\n",
      "epoch 0; iter: 0; batch classifier loss: 0.778978; batch adversarial loss: 0.808289\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608260; batch adversarial loss: 0.760695\n",
      "epoch 2; iter: 0; batch classifier loss: 0.509814; batch adversarial loss: 0.735279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.526937; batch adversarial loss: 0.678415\n",
      "epoch 4; iter: 0; batch classifier loss: 0.665942; batch adversarial loss: 0.662825\n",
      "epoch 5; iter: 0; batch classifier loss: 0.611672; batch adversarial loss: 0.633801\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523927; batch adversarial loss: 0.649981\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524603; batch adversarial loss: 0.610879\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529039; batch adversarial loss: 0.601287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527131; batch adversarial loss: 0.581231\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540737; batch adversarial loss: 0.550844\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491549; batch adversarial loss: 0.561645\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495908; batch adversarial loss: 0.539377\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565804; batch adversarial loss: 0.552234\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538576; batch adversarial loss: 0.587808\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488201; batch adversarial loss: 0.537765\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484074; batch adversarial loss: 0.554220\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478847; batch adversarial loss: 0.575531\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461027; batch adversarial loss: 0.590535\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491802; batch adversarial loss: 0.496308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.459101; batch adversarial loss: 0.528396\n",
      "epoch 21; iter: 0; batch classifier loss: 0.428381; batch adversarial loss: 0.556235\n",
      "epoch 22; iter: 0; batch classifier loss: 0.460869; batch adversarial loss: 0.541494\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467564; batch adversarial loss: 0.563529\n",
      "epoch 24; iter: 0; batch classifier loss: 0.413780; batch adversarial loss: 0.513215\n",
      "epoch 25; iter: 0; batch classifier loss: 0.445432; batch adversarial loss: 0.574461\n",
      "epoch 26; iter: 0; batch classifier loss: 0.503628; batch adversarial loss: 0.523307\n",
      "epoch 27; iter: 0; batch classifier loss: 0.422285; batch adversarial loss: 0.571978\n",
      "epoch 28; iter: 0; batch classifier loss: 0.448253; batch adversarial loss: 0.510292\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441495; batch adversarial loss: 0.544001\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455247; batch adversarial loss: 0.530128\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447510; batch adversarial loss: 0.596858\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432457; batch adversarial loss: 0.557644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370809; batch adversarial loss: 0.537377\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461801; batch adversarial loss: 0.486514\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443174; batch adversarial loss: 0.563395\n",
      "epoch 36; iter: 0; batch classifier loss: 0.530628; batch adversarial loss: 0.502355\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417807; batch adversarial loss: 0.570987\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451625; batch adversarial loss: 0.598885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439728; batch adversarial loss: 0.571823\n",
      "epoch 40; iter: 0; batch classifier loss: 0.397091; batch adversarial loss: 0.483573\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384511; batch adversarial loss: 0.543946\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466091; batch adversarial loss: 0.562597\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461992; batch adversarial loss: 0.660566\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466554; batch adversarial loss: 0.571291\n",
      "epoch 45; iter: 0; batch classifier loss: 0.519678; batch adversarial loss: 0.555038\n",
      "epoch 46; iter: 0; batch classifier loss: 0.360819; batch adversarial loss: 0.527958\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414730; batch adversarial loss: 0.599049\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403008; batch adversarial loss: 0.590002\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420002; batch adversarial loss: 0.498636\n",
      "epoch 50; iter: 0; batch classifier loss: 0.444469; batch adversarial loss: 0.507584\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434376; batch adversarial loss: 0.517895\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458240; batch adversarial loss: 0.588591\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397008; batch adversarial loss: 0.544901\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445679; batch adversarial loss: 0.581381\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450044; batch adversarial loss: 0.526522\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444672; batch adversarial loss: 0.516740\n",
      "epoch 57; iter: 0; batch classifier loss: 0.462330; batch adversarial loss: 0.573370\n",
      "epoch 58; iter: 0; batch classifier loss: 0.371255; batch adversarial loss: 0.562822\n",
      "epoch 59; iter: 0; batch classifier loss: 0.319171; batch adversarial loss: 0.609364\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366798; batch adversarial loss: 0.581162\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399793; batch adversarial loss: 0.553350\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432336; batch adversarial loss: 0.507198\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422892; batch adversarial loss: 0.461083\n",
      "epoch 64; iter: 0; batch classifier loss: 0.517303; batch adversarial loss: 0.526787\n",
      "epoch 65; iter: 0; batch classifier loss: 0.371505; batch adversarial loss: 0.518654\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454604; batch adversarial loss: 0.489448\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401913; batch adversarial loss: 0.526213\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471312; batch adversarial loss: 0.554998\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419809; batch adversarial loss: 0.592146\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398405; batch adversarial loss: 0.450840\n",
      "epoch 71; iter: 0; batch classifier loss: 0.424617; batch adversarial loss: 0.535285\n",
      "epoch 72; iter: 0; batch classifier loss: 0.378441; batch adversarial loss: 0.554774\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396749; batch adversarial loss: 0.553335\n",
      "epoch 74; iter: 0; batch classifier loss: 0.310190; batch adversarial loss: 0.516686\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384571; batch adversarial loss: 0.561603\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358256; batch adversarial loss: 0.480044\n",
      "epoch 77; iter: 0; batch classifier loss: 0.465359; batch adversarial loss: 0.416048\n",
      "epoch 78; iter: 0; batch classifier loss: 0.466158; batch adversarial loss: 0.526801\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419701; batch adversarial loss: 0.572959\n",
      "epoch 80; iter: 0; batch classifier loss: 0.364283; batch adversarial loss: 0.580988\n",
      "epoch 81; iter: 0; batch classifier loss: 0.357953; batch adversarial loss: 0.498369\n",
      "epoch 82; iter: 0; batch classifier loss: 0.473296; batch adversarial loss: 0.599253\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397524; batch adversarial loss: 0.571190\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411351; batch adversarial loss: 0.684026\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410762; batch adversarial loss: 0.545427\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379818; batch adversarial loss: 0.654879\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356033; batch adversarial loss: 0.496765\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348100; batch adversarial loss: 0.588966\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388698; batch adversarial loss: 0.533959\n",
      "epoch 90; iter: 0; batch classifier loss: 0.467715; batch adversarial loss: 0.554148\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388922; batch adversarial loss: 0.554270\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393629; batch adversarial loss: 0.516648\n",
      "epoch 93; iter: 0; batch classifier loss: 0.362004; batch adversarial loss: 0.516447\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402676; batch adversarial loss: 0.461101\n",
      "epoch 95; iter: 0; batch classifier loss: 0.439182; batch adversarial loss: 0.516010\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412096; batch adversarial loss: 0.554707\n",
      "epoch 97; iter: 0; batch classifier loss: 0.349743; batch adversarial loss: 0.571116\n",
      "epoch 98; iter: 0; batch classifier loss: 0.347370; batch adversarial loss: 0.579791\n",
      "epoch 99; iter: 0; batch classifier loss: 0.474249; batch adversarial loss: 0.517876\n",
      "epoch 100; iter: 0; batch classifier loss: 0.326586; batch adversarial loss: 0.544862\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353347; batch adversarial loss: 0.581786\n",
      "epoch 102; iter: 0; batch classifier loss: 0.467735; batch adversarial loss: 0.545492\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397102; batch adversarial loss: 0.507378\n",
      "epoch 104; iter: 0; batch classifier loss: 0.295672; batch adversarial loss: 0.561314\n",
      "epoch 105; iter: 0; batch classifier loss: 0.443097; batch adversarial loss: 0.470409\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345652; batch adversarial loss: 0.525284\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367882; batch adversarial loss: 0.505236\n",
      "epoch 108; iter: 0; batch classifier loss: 0.396140; batch adversarial loss: 0.498199\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375513; batch adversarial loss: 0.489399\n",
      "epoch 110; iter: 0; batch classifier loss: 0.466172; batch adversarial loss: 0.535554\n",
      "epoch 111; iter: 0; batch classifier loss: 0.404739; batch adversarial loss: 0.553554\n",
      "epoch 112; iter: 0; batch classifier loss: 0.431861; batch adversarial loss: 0.505829\n",
      "epoch 113; iter: 0; batch classifier loss: 0.484811; batch adversarial loss: 0.461572\n",
      "epoch 114; iter: 0; batch classifier loss: 0.409116; batch adversarial loss: 0.581997\n",
      "epoch 115; iter: 0; batch classifier loss: 0.376136; batch adversarial loss: 0.581887\n",
      "epoch 116; iter: 0; batch classifier loss: 0.418995; batch adversarial loss: 0.570531\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346873; batch adversarial loss: 0.525544\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359925; batch adversarial loss: 0.545367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.372239; batch adversarial loss: 0.527901\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382909; batch adversarial loss: 0.573664\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361998; batch adversarial loss: 0.545372\n",
      "epoch 122; iter: 0; batch classifier loss: 0.425969; batch adversarial loss: 0.518010\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387789; batch adversarial loss: 0.526792\n",
      "epoch 124; iter: 0; batch classifier loss: 0.413251; batch adversarial loss: 0.526405\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343705; batch adversarial loss: 0.545826\n",
      "epoch 126; iter: 0; batch classifier loss: 0.484278; batch adversarial loss: 0.545699\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419051; batch adversarial loss: 0.543372\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403370; batch adversarial loss: 0.608395\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337347; batch adversarial loss: 0.524907\n",
      "epoch 130; iter: 0; batch classifier loss: 0.453042; batch adversarial loss: 0.592198\n",
      "epoch 131; iter: 0; batch classifier loss: 0.421597; batch adversarial loss: 0.581282\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310334; batch adversarial loss: 0.572524\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347688; batch adversarial loss: 0.582119\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384577; batch adversarial loss: 0.645181\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361443; batch adversarial loss: 0.535330\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355760; batch adversarial loss: 0.543610\n",
      "epoch 137; iter: 0; batch classifier loss: 0.365610; batch adversarial loss: 0.470782\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418941; batch adversarial loss: 0.536162\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334305; batch adversarial loss: 0.527068\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403566; batch adversarial loss: 0.498987\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308629; batch adversarial loss: 0.515741\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347970; batch adversarial loss: 0.507108\n",
      "epoch 143; iter: 0; batch classifier loss: 0.347489; batch adversarial loss: 0.607153\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342963; batch adversarial loss: 0.489466\n",
      "epoch 145; iter: 0; batch classifier loss: 0.442911; batch adversarial loss: 0.508134\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374247; batch adversarial loss: 0.572455\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388829; batch adversarial loss: 0.543585\n",
      "epoch 148; iter: 0; batch classifier loss: 0.435349; batch adversarial loss: 0.534997\n",
      "epoch 149; iter: 0; batch classifier loss: 0.289320; batch adversarial loss: 0.508911\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311325; batch adversarial loss: 0.534503\n",
      "epoch 151; iter: 0; batch classifier loss: 0.453645; batch adversarial loss: 0.562878\n",
      "epoch 152; iter: 0; batch classifier loss: 0.316964; batch adversarial loss: 0.609581\n",
      "epoch 153; iter: 0; batch classifier loss: 0.326467; batch adversarial loss: 0.527061\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402869; batch adversarial loss: 0.598858\n",
      "epoch 155; iter: 0; batch classifier loss: 0.295920; batch adversarial loss: 0.561069\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370569; batch adversarial loss: 0.626353\n",
      "epoch 157; iter: 0; batch classifier loss: 0.426658; batch adversarial loss: 0.547203\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435445; batch adversarial loss: 0.572121\n",
      "epoch 159; iter: 0; batch classifier loss: 0.297705; batch adversarial loss: 0.491859\n",
      "epoch 160; iter: 0; batch classifier loss: 0.312736; batch adversarial loss: 0.545599\n",
      "epoch 161; iter: 0; batch classifier loss: 0.456357; batch adversarial loss: 0.479565\n",
      "epoch 162; iter: 0; batch classifier loss: 0.288678; batch adversarial loss: 0.488365\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353839; batch adversarial loss: 0.553188\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330315; batch adversarial loss: 0.535489\n",
      "epoch 165; iter: 0; batch classifier loss: 0.307775; batch adversarial loss: 0.647577\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384487; batch adversarial loss: 0.554592\n",
      "epoch 167; iter: 0; batch classifier loss: 0.396356; batch adversarial loss: 0.498152\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338456; batch adversarial loss: 0.508044\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368160; batch adversarial loss: 0.556365\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384436; batch adversarial loss: 0.517047\n",
      "epoch 171; iter: 0; batch classifier loss: 0.428664; batch adversarial loss: 0.554551\n",
      "epoch 172; iter: 0; batch classifier loss: 0.315195; batch adversarial loss: 0.563265\n",
      "epoch 173; iter: 0; batch classifier loss: 0.394089; batch adversarial loss: 0.477990\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318378; batch adversarial loss: 0.591933\n",
      "epoch 175; iter: 0; batch classifier loss: 0.396423; batch adversarial loss: 0.526361\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396497; batch adversarial loss: 0.515950\n",
      "epoch 177; iter: 0; batch classifier loss: 0.342956; batch adversarial loss: 0.516626\n",
      "epoch 178; iter: 0; batch classifier loss: 0.273015; batch adversarial loss: 0.480184\n",
      "epoch 179; iter: 0; batch classifier loss: 0.451977; batch adversarial loss: 0.591829\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414547; batch adversarial loss: 0.508417\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386727; batch adversarial loss: 0.535820\n",
      "epoch 182; iter: 0; batch classifier loss: 0.407359; batch adversarial loss: 0.553460\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365026; batch adversarial loss: 0.452325\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335778; batch adversarial loss: 0.579709\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349111; batch adversarial loss: 0.525159\n",
      "epoch 186; iter: 0; batch classifier loss: 0.305471; batch adversarial loss: 0.518533\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314671; batch adversarial loss: 0.546935\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313453; batch adversarial loss: 0.508463\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343418; batch adversarial loss: 0.533433\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366227; batch adversarial loss: 0.544361\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325042; batch adversarial loss: 0.570759\n",
      "epoch 192; iter: 0; batch classifier loss: 0.331933; batch adversarial loss: 0.526434\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338259; batch adversarial loss: 0.572540\n",
      "epoch 194; iter: 0; batch classifier loss: 0.296849; batch adversarial loss: 0.562047\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332381; batch adversarial loss: 0.505120\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306946; batch adversarial loss: 0.572420\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362678; batch adversarial loss: 0.525892\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381503; batch adversarial loss: 0.555080\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323153; batch adversarial loss: 0.525452\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724566; batch adversarial loss: 0.620519\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600210; batch adversarial loss: 0.638500\n",
      "epoch 2; iter: 0; batch classifier loss: 0.636061; batch adversarial loss: 0.623209\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619975; batch adversarial loss: 0.626919\n",
      "epoch 4; iter: 0; batch classifier loss: 0.613578; batch adversarial loss: 0.662467\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516661; batch adversarial loss: 0.621517\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593740; batch adversarial loss: 0.626315\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529211; batch adversarial loss: 0.602446\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524054; batch adversarial loss: 0.699058\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557807; batch adversarial loss: 0.616867\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516309; batch adversarial loss: 0.594152\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543086; batch adversarial loss: 0.578134\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553379; batch adversarial loss: 0.554153\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452474; batch adversarial loss: 0.608952\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549358; batch adversarial loss: 0.579803\n",
      "epoch 15; iter: 0; batch classifier loss: 0.464367; batch adversarial loss: 0.557051\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508521; batch adversarial loss: 0.612042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.459123; batch adversarial loss: 0.557959\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522503; batch adversarial loss: 0.565906\n",
      "epoch 19; iter: 0; batch classifier loss: 0.566758; batch adversarial loss: 0.611140\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492734; batch adversarial loss: 0.562587\n",
      "epoch 21; iter: 0; batch classifier loss: 0.551790; batch adversarial loss: 0.521111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501066; batch adversarial loss: 0.608798\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455663; batch adversarial loss: 0.572070\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467827; batch adversarial loss: 0.567338\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443379; batch adversarial loss: 0.627249\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438300; batch adversarial loss: 0.588950\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499194; batch adversarial loss: 0.546511\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477208; batch adversarial loss: 0.530185\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449360; batch adversarial loss: 0.555501\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464544; batch adversarial loss: 0.596561\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442051; batch adversarial loss: 0.621224\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420302; batch adversarial loss: 0.520364\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456346; batch adversarial loss: 0.544621\n",
      "epoch 34; iter: 0; batch classifier loss: 0.498076; batch adversarial loss: 0.553372\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393254; batch adversarial loss: 0.623214\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435191; batch adversarial loss: 0.491342\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500438; batch adversarial loss: 0.516809\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482083; batch adversarial loss: 0.526892\n",
      "epoch 39; iter: 0; batch classifier loss: 0.508684; batch adversarial loss: 0.578998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.379129; batch adversarial loss: 0.579995\n",
      "epoch 41; iter: 0; batch classifier loss: 0.376621; batch adversarial loss: 0.571901\n",
      "epoch 42; iter: 0; batch classifier loss: 0.368713; batch adversarial loss: 0.562926\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474059; batch adversarial loss: 0.580167\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393739; batch adversarial loss: 0.580417\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417210; batch adversarial loss: 0.535410\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409506; batch adversarial loss: 0.535069\n",
      "epoch 47; iter: 0; batch classifier loss: 0.368849; batch adversarial loss: 0.528414\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392461; batch adversarial loss: 0.544441\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424956; batch adversarial loss: 0.597806\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399105; batch adversarial loss: 0.542878\n",
      "epoch 51; iter: 0; batch classifier loss: 0.467121; batch adversarial loss: 0.589180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422617; batch adversarial loss: 0.554899\n",
      "epoch 53; iter: 0; batch classifier loss: 0.447972; batch adversarial loss: 0.544434\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443556; batch adversarial loss: 0.526785\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428100; batch adversarial loss: 0.605352\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430669; batch adversarial loss: 0.526589\n",
      "epoch 57; iter: 0; batch classifier loss: 0.479072; batch adversarial loss: 0.545195\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419254; batch adversarial loss: 0.579212\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433516; batch adversarial loss: 0.537227\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373933; batch adversarial loss: 0.563306\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467447; batch adversarial loss: 0.526273\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459840; batch adversarial loss: 0.589420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459012; batch adversarial loss: 0.580087\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460547; batch adversarial loss: 0.482570\n",
      "epoch 65; iter: 0; batch classifier loss: 0.479374; batch adversarial loss: 0.625825\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389446; batch adversarial loss: 0.570172\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433450; batch adversarial loss: 0.553413\n",
      "epoch 68; iter: 0; batch classifier loss: 0.329686; batch adversarial loss: 0.518695\n",
      "epoch 69; iter: 0; batch classifier loss: 0.503216; batch adversarial loss: 0.553519\n",
      "epoch 70; iter: 0; batch classifier loss: 0.343189; batch adversarial loss: 0.669599\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420394; batch adversarial loss: 0.588627\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374495; batch adversarial loss: 0.605978\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410540; batch adversarial loss: 0.499503\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405397; batch adversarial loss: 0.544820\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423628; batch adversarial loss: 0.500619\n",
      "epoch 76; iter: 0; batch classifier loss: 0.429104; batch adversarial loss: 0.606240\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402659; batch adversarial loss: 0.474933\n",
      "epoch 78; iter: 0; batch classifier loss: 0.422656; batch adversarial loss: 0.518284\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396394; batch adversarial loss: 0.570783\n",
      "epoch 80; iter: 0; batch classifier loss: 0.492684; batch adversarial loss: 0.526754\n",
      "epoch 81; iter: 0; batch classifier loss: 0.438725; batch adversarial loss: 0.661403\n",
      "epoch 82; iter: 0; batch classifier loss: 0.442048; batch adversarial loss: 0.545620\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423605; batch adversarial loss: 0.554750\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389347; batch adversarial loss: 0.543239\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431779; batch adversarial loss: 0.570617\n",
      "epoch 86; iter: 0; batch classifier loss: 0.447588; batch adversarial loss: 0.561761\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389748; batch adversarial loss: 0.608269\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394705; batch adversarial loss: 0.582291\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431884; batch adversarial loss: 0.526757\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434804; batch adversarial loss: 0.570880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.447592; batch adversarial loss: 0.526540\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347494; batch adversarial loss: 0.544638\n",
      "epoch 93; iter: 0; batch classifier loss: 0.365496; batch adversarial loss: 0.588586\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385578; batch adversarial loss: 0.587252\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368627; batch adversarial loss: 0.516884\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383076; batch adversarial loss: 0.499645\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440883; batch adversarial loss: 0.551712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.325788; batch adversarial loss: 0.632799\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426306; batch adversarial loss: 0.527749\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388582; batch adversarial loss: 0.544660\n",
      "epoch 101; iter: 0; batch classifier loss: 0.444505; batch adversarial loss: 0.482253\n",
      "epoch 102; iter: 0; batch classifier loss: 0.442639; batch adversarial loss: 0.499445\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397457; batch adversarial loss: 0.555171\n",
      "epoch 104; iter: 0; batch classifier loss: 0.450082; batch adversarial loss: 0.571935\n",
      "epoch 105; iter: 0; batch classifier loss: 0.448451; batch adversarial loss: 0.625319\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391569; batch adversarial loss: 0.499103\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405241; batch adversarial loss: 0.563696\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361720; batch adversarial loss: 0.589965\n",
      "epoch 109; iter: 0; batch classifier loss: 0.275085; batch adversarial loss: 0.563273\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395522; batch adversarial loss: 0.615077\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360482; batch adversarial loss: 0.518606\n",
      "epoch 112; iter: 0; batch classifier loss: 0.309590; batch adversarial loss: 0.526580\n",
      "epoch 113; iter: 0; batch classifier loss: 0.404714; batch adversarial loss: 0.482701\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390581; batch adversarial loss: 0.598937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115; iter: 0; batch classifier loss: 0.387997; batch adversarial loss: 0.500433\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401591; batch adversarial loss: 0.562195\n",
      "epoch 117; iter: 0; batch classifier loss: 0.483410; batch adversarial loss: 0.493120\n",
      "epoch 118; iter: 0; batch classifier loss: 0.316221; batch adversarial loss: 0.509439\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352337; batch adversarial loss: 0.544459\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357819; batch adversarial loss: 0.545568\n",
      "epoch 121; iter: 0; batch classifier loss: 0.434225; batch adversarial loss: 0.483595\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421187; batch adversarial loss: 0.605007\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376113; batch adversarial loss: 0.589176\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373109; batch adversarial loss: 0.509118\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373891; batch adversarial loss: 0.491215\n",
      "epoch 126; iter: 0; batch classifier loss: 0.300404; batch adversarial loss: 0.553343\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390678; batch adversarial loss: 0.535026\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389118; batch adversarial loss: 0.563847\n",
      "epoch 129; iter: 0; batch classifier loss: 0.332657; batch adversarial loss: 0.535858\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361208; batch adversarial loss: 0.544769\n",
      "epoch 131; iter: 0; batch classifier loss: 0.412563; batch adversarial loss: 0.597425\n",
      "epoch 132; iter: 0; batch classifier loss: 0.365329; batch adversarial loss: 0.614498\n",
      "epoch 133; iter: 0; batch classifier loss: 0.420431; batch adversarial loss: 0.518181\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406598; batch adversarial loss: 0.616325\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400459; batch adversarial loss: 0.553642\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361750; batch adversarial loss: 0.561764\n",
      "epoch 137; iter: 0; batch classifier loss: 0.457156; batch adversarial loss: 0.578372\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373305; batch adversarial loss: 0.570014\n",
      "epoch 139; iter: 0; batch classifier loss: 0.426447; batch adversarial loss: 0.597942\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346119; batch adversarial loss: 0.536241\n",
      "epoch 141; iter: 0; batch classifier loss: 0.431644; batch adversarial loss: 0.527511\n",
      "epoch 142; iter: 0; batch classifier loss: 0.445438; batch adversarial loss: 0.536244\n",
      "epoch 143; iter: 0; batch classifier loss: 0.428718; batch adversarial loss: 0.537277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.419150; batch adversarial loss: 0.659935\n",
      "epoch 145; iter: 0; batch classifier loss: 0.454569; batch adversarial loss: 0.508767\n",
      "epoch 146; iter: 0; batch classifier loss: 0.319876; batch adversarial loss: 0.563550\n",
      "epoch 147; iter: 0; batch classifier loss: 0.429998; batch adversarial loss: 0.652313\n",
      "epoch 148; iter: 0; batch classifier loss: 0.436939; batch adversarial loss: 0.598105\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350794; batch adversarial loss: 0.580689\n",
      "epoch 150; iter: 0; batch classifier loss: 0.395079; batch adversarial loss: 0.490064\n",
      "epoch 151; iter: 0; batch classifier loss: 0.421044; batch adversarial loss: 0.517744\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373797; batch adversarial loss: 0.500746\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338399; batch adversarial loss: 0.526433\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394533; batch adversarial loss: 0.553042\n",
      "epoch 155; iter: 0; batch classifier loss: 0.393267; batch adversarial loss: 0.553858\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362917; batch adversarial loss: 0.579775\n",
      "epoch 157; iter: 0; batch classifier loss: 0.436686; batch adversarial loss: 0.508517\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369884; batch adversarial loss: 0.553152\n",
      "epoch 159; iter: 0; batch classifier loss: 0.397344; batch adversarial loss: 0.562286\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401651; batch adversarial loss: 0.597507\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359842; batch adversarial loss: 0.597855\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410411; batch adversarial loss: 0.499554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.411661; batch adversarial loss: 0.589330\n",
      "epoch 164; iter: 0; batch classifier loss: 0.412603; batch adversarial loss: 0.581107\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349288; batch adversarial loss: 0.554333\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367887; batch adversarial loss: 0.588629\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321044; batch adversarial loss: 0.590921\n",
      "epoch 168; iter: 0; batch classifier loss: 0.439894; batch adversarial loss: 0.528861\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382946; batch adversarial loss: 0.580790\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342844; batch adversarial loss: 0.545067\n",
      "epoch 171; iter: 0; batch classifier loss: 0.475442; batch adversarial loss: 0.633971\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385309; batch adversarial loss: 0.614484\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377694; batch adversarial loss: 0.589841\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374590; batch adversarial loss: 0.544906\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344986; batch adversarial loss: 0.561706\n",
      "epoch 176; iter: 0; batch classifier loss: 0.449522; batch adversarial loss: 0.563287\n",
      "epoch 177; iter: 0; batch classifier loss: 0.458086; batch adversarial loss: 0.580886\n",
      "epoch 178; iter: 0; batch classifier loss: 0.413527; batch adversarial loss: 0.562047\n",
      "epoch 179; iter: 0; batch classifier loss: 0.311528; batch adversarial loss: 0.615089\n",
      "epoch 180; iter: 0; batch classifier loss: 0.459723; batch adversarial loss: 0.615296\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350250; batch adversarial loss: 0.517876\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318670; batch adversarial loss: 0.579400\n",
      "epoch 183; iter: 0; batch classifier loss: 0.434923; batch adversarial loss: 0.570622\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317490; batch adversarial loss: 0.499706\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319520; batch adversarial loss: 0.517031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.409114; batch adversarial loss: 0.624945\n",
      "epoch 187; iter: 0; batch classifier loss: 0.308657; batch adversarial loss: 0.561589\n",
      "epoch 188; iter: 0; batch classifier loss: 0.458223; batch adversarial loss: 0.509212\n",
      "epoch 189; iter: 0; batch classifier loss: 0.399808; batch adversarial loss: 0.554758\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341301; batch adversarial loss: 0.667744\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392562; batch adversarial loss: 0.536363\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396094; batch adversarial loss: 0.536435\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392218; batch adversarial loss: 0.580337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386315; batch adversarial loss: 0.553692\n",
      "epoch 195; iter: 0; batch classifier loss: 0.305001; batch adversarial loss: 0.563097\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335555; batch adversarial loss: 0.508488\n",
      "epoch 197; iter: 0; batch classifier loss: 0.494391; batch adversarial loss: 0.528100\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338561; batch adversarial loss: 0.535573\n",
      "epoch 199; iter: 0; batch classifier loss: 0.390126; batch adversarial loss: 0.463969\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738508; batch adversarial loss: 0.650704\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645077; batch adversarial loss: 0.597645\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611347; batch adversarial loss: 0.607419\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572235; batch adversarial loss: 0.665297\n",
      "epoch 4; iter: 0; batch classifier loss: 0.512733; batch adversarial loss: 0.608545\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539130; batch adversarial loss: 0.594357\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523346; batch adversarial loss: 0.577104\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494227; batch adversarial loss: 0.612481\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524433; batch adversarial loss: 0.657246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514115; batch adversarial loss: 0.532815\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560047; batch adversarial loss: 0.621832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.545027; batch adversarial loss: 0.575565\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452809; batch adversarial loss: 0.540299\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603829; batch adversarial loss: 0.624753\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481103; batch adversarial loss: 0.637584\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548071; batch adversarial loss: 0.578190\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533005; batch adversarial loss: 0.612360\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552108; batch adversarial loss: 0.684493\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513059; batch adversarial loss: 0.479491\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516360; batch adversarial loss: 0.523184\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461546; batch adversarial loss: 0.546640\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468522; batch adversarial loss: 0.542636\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438389; batch adversarial loss: 0.579470\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452507; batch adversarial loss: 0.497062\n",
      "epoch 24; iter: 0; batch classifier loss: 0.542534; batch adversarial loss: 0.639650\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492463; batch adversarial loss: 0.595755\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519911; batch adversarial loss: 0.592020\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442713; batch adversarial loss: 0.613595\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488916; batch adversarial loss: 0.530333\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482762; batch adversarial loss: 0.607306\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483990; batch adversarial loss: 0.569310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492848; batch adversarial loss: 0.499936\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466900; batch adversarial loss: 0.577071\n",
      "epoch 33; iter: 0; batch classifier loss: 0.382622; batch adversarial loss: 0.478110\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457254; batch adversarial loss: 0.599019\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451403; batch adversarial loss: 0.568476\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435671; batch adversarial loss: 0.571457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454332; batch adversarial loss: 0.585974\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451252; batch adversarial loss: 0.610557\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413079; batch adversarial loss: 0.560425\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408666; batch adversarial loss: 0.557612\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435424; batch adversarial loss: 0.542612\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474102; batch adversarial loss: 0.525037\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479912; batch adversarial loss: 0.465526\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434639; batch adversarial loss: 0.545008\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419662; batch adversarial loss: 0.602382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382271; batch adversarial loss: 0.543115\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484992; batch adversarial loss: 0.574535\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424420; batch adversarial loss: 0.552170\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428566; batch adversarial loss: 0.572492\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424314; batch adversarial loss: 0.506882\n",
      "epoch 51; iter: 0; batch classifier loss: 0.495511; batch adversarial loss: 0.541093\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380305; batch adversarial loss: 0.531372\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461293; batch adversarial loss: 0.548390\n",
      "epoch 54; iter: 0; batch classifier loss: 0.343934; batch adversarial loss: 0.497443\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412919; batch adversarial loss: 0.525255\n",
      "epoch 56; iter: 0; batch classifier loss: 0.360774; batch adversarial loss: 0.656229\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374446; batch adversarial loss: 0.492886\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412137; batch adversarial loss: 0.528605\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422775; batch adversarial loss: 0.585671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426775; batch adversarial loss: 0.547248\n",
      "epoch 61; iter: 0; batch classifier loss: 0.473868; batch adversarial loss: 0.551940\n",
      "epoch 62; iter: 0; batch classifier loss: 0.507779; batch adversarial loss: 0.621707\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423149; batch adversarial loss: 0.628472\n",
      "epoch 64; iter: 0; batch classifier loss: 0.470522; batch adversarial loss: 0.606293\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441287; batch adversarial loss: 0.524832\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397364; batch adversarial loss: 0.533191\n",
      "epoch 67; iter: 0; batch classifier loss: 0.481685; batch adversarial loss: 0.519791\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425117; batch adversarial loss: 0.564441\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451855; batch adversarial loss: 0.473181\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380198; batch adversarial loss: 0.554599\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411209; batch adversarial loss: 0.532623\n",
      "epoch 72; iter: 0; batch classifier loss: 0.341539; batch adversarial loss: 0.588882\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358513; batch adversarial loss: 0.612384\n",
      "epoch 74; iter: 0; batch classifier loss: 0.352288; batch adversarial loss: 0.566064\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424889; batch adversarial loss: 0.540998\n",
      "epoch 76; iter: 0; batch classifier loss: 0.452232; batch adversarial loss: 0.497068\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410353; batch adversarial loss: 0.521978\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368916; batch adversarial loss: 0.545092\n",
      "epoch 79; iter: 0; batch classifier loss: 0.442802; batch adversarial loss: 0.569926\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383581; batch adversarial loss: 0.587918\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408587; batch adversarial loss: 0.554702\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391973; batch adversarial loss: 0.523002\n",
      "epoch 83; iter: 0; batch classifier loss: 0.467511; batch adversarial loss: 0.523873\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389993; batch adversarial loss: 0.554768\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351102; batch adversarial loss: 0.571681\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407541; batch adversarial loss: 0.520388\n",
      "epoch 87; iter: 0; batch classifier loss: 0.407099; batch adversarial loss: 0.530881\n",
      "epoch 88; iter: 0; batch classifier loss: 0.443544; batch adversarial loss: 0.553141\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381412; batch adversarial loss: 0.482042\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427395; batch adversarial loss: 0.571505\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460199; batch adversarial loss: 0.579140\n",
      "epoch 92; iter: 0; batch classifier loss: 0.476742; batch adversarial loss: 0.579285\n",
      "epoch 93; iter: 0; batch classifier loss: 0.372269; batch adversarial loss: 0.596012\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385846; batch adversarial loss: 0.559358\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347046; batch adversarial loss: 0.523771\n",
      "epoch 96; iter: 0; batch classifier loss: 0.442494; batch adversarial loss: 0.490253\n",
      "epoch 97; iter: 0; batch classifier loss: 0.452763; batch adversarial loss: 0.446213\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416644; batch adversarial loss: 0.666104\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363864; batch adversarial loss: 0.464865\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398060; batch adversarial loss: 0.580588\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434572; batch adversarial loss: 0.455303\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376178; batch adversarial loss: 0.623200\n",
      "epoch 103; iter: 0; batch classifier loss: 0.439873; batch adversarial loss: 0.553628\n",
      "epoch 104; iter: 0; batch classifier loss: 0.334176; batch adversarial loss: 0.517608\n",
      "epoch 105; iter: 0; batch classifier loss: 0.474407; batch adversarial loss: 0.543998\n",
      "epoch 106; iter: 0; batch classifier loss: 0.405517; batch adversarial loss: 0.581381\n",
      "epoch 107; iter: 0; batch classifier loss: 0.437195; batch adversarial loss: 0.529614\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411395; batch adversarial loss: 0.554165\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345554; batch adversarial loss: 0.535349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.339278; batch adversarial loss: 0.558602\n",
      "epoch 111; iter: 0; batch classifier loss: 0.295148; batch adversarial loss: 0.563051\n",
      "epoch 112; iter: 0; batch classifier loss: 0.328356; batch adversarial loss: 0.482797\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394494; batch adversarial loss: 0.551534\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354106; batch adversarial loss: 0.559665\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336582; batch adversarial loss: 0.524527\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373814; batch adversarial loss: 0.565174\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378531; batch adversarial loss: 0.522622\n",
      "epoch 118; iter: 0; batch classifier loss: 0.415975; batch adversarial loss: 0.587185\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392906; batch adversarial loss: 0.454684\n",
      "epoch 120; iter: 0; batch classifier loss: 0.393230; batch adversarial loss: 0.576470\n",
      "epoch 121; iter: 0; batch classifier loss: 0.421381; batch adversarial loss: 0.549954\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391368; batch adversarial loss: 0.527358\n",
      "epoch 123; iter: 0; batch classifier loss: 0.333849; batch adversarial loss: 0.481171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.306810; batch adversarial loss: 0.613746\n",
      "epoch 125; iter: 0; batch classifier loss: 0.459111; batch adversarial loss: 0.561552\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386240; batch adversarial loss: 0.612135\n",
      "epoch 127; iter: 0; batch classifier loss: 0.454629; batch adversarial loss: 0.624850\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390141; batch adversarial loss: 0.557268\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334291; batch adversarial loss: 0.510367\n",
      "epoch 130; iter: 0; batch classifier loss: 0.320744; batch adversarial loss: 0.563332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.304421; batch adversarial loss: 0.510040\n",
      "epoch 132; iter: 0; batch classifier loss: 0.398157; batch adversarial loss: 0.517556\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344360; batch adversarial loss: 0.536345\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365879; batch adversarial loss: 0.552579\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364367; batch adversarial loss: 0.597606\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416391; batch adversarial loss: 0.554479\n",
      "epoch 137; iter: 0; batch classifier loss: 0.454551; batch adversarial loss: 0.490680\n",
      "epoch 138; iter: 0; batch classifier loss: 0.417855; batch adversarial loss: 0.553715\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390288; batch adversarial loss: 0.564237\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404754; batch adversarial loss: 0.526713\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346610; batch adversarial loss: 0.585780\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415627; batch adversarial loss: 0.542386\n",
      "epoch 143; iter: 0; batch classifier loss: 0.303494; batch adversarial loss: 0.618726\n",
      "epoch 144; iter: 0; batch classifier loss: 0.333517; batch adversarial loss: 0.597958\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319376; batch adversarial loss: 0.553177\n",
      "epoch 146; iter: 0; batch classifier loss: 0.408848; batch adversarial loss: 0.607726\n",
      "epoch 147; iter: 0; batch classifier loss: 0.414081; batch adversarial loss: 0.594546\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341758; batch adversarial loss: 0.577946\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396183; batch adversarial loss: 0.580041\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365969; batch adversarial loss: 0.578930\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405865; batch adversarial loss: 0.586320\n",
      "epoch 152; iter: 0; batch classifier loss: 0.325821; batch adversarial loss: 0.502792\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430334; batch adversarial loss: 0.597808\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372391; batch adversarial loss: 0.573636\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366299; batch adversarial loss: 0.553718\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391489; batch adversarial loss: 0.509150\n",
      "epoch 157; iter: 0; batch classifier loss: 0.317311; batch adversarial loss: 0.551831\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354629; batch adversarial loss: 0.580320\n",
      "epoch 159; iter: 0; batch classifier loss: 0.399087; batch adversarial loss: 0.584535\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384860; batch adversarial loss: 0.525755\n",
      "epoch 161; iter: 0; batch classifier loss: 0.320944; batch adversarial loss: 0.568980\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370447; batch adversarial loss: 0.499346\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348848; batch adversarial loss: 0.502382\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358188; batch adversarial loss: 0.590050\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387313; batch adversarial loss: 0.509803\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346173; batch adversarial loss: 0.580087\n",
      "epoch 167; iter: 0; batch classifier loss: 0.326498; batch adversarial loss: 0.630466\n",
      "epoch 168; iter: 0; batch classifier loss: 0.303525; batch adversarial loss: 0.455441\n",
      "epoch 169; iter: 0; batch classifier loss: 0.329560; batch adversarial loss: 0.576189\n",
      "epoch 170; iter: 0; batch classifier loss: 0.291315; batch adversarial loss: 0.487844\n",
      "epoch 171; iter: 0; batch classifier loss: 0.275618; batch adversarial loss: 0.577094\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394188; batch adversarial loss: 0.579758\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377956; batch adversarial loss: 0.524860\n",
      "epoch 174; iter: 0; batch classifier loss: 0.440718; batch adversarial loss: 0.522373\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392524; batch adversarial loss: 0.585203\n",
      "epoch 176; iter: 0; batch classifier loss: 0.420111; batch adversarial loss: 0.511366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378861; batch adversarial loss: 0.491377\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382141; batch adversarial loss: 0.599838\n",
      "epoch 179; iter: 0; batch classifier loss: 0.307328; batch adversarial loss: 0.531993\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388183; batch adversarial loss: 0.516981\n",
      "epoch 181; iter: 0; batch classifier loss: 0.443863; batch adversarial loss: 0.538248\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383974; batch adversarial loss: 0.532024\n",
      "epoch 183; iter: 0; batch classifier loss: 0.374880; batch adversarial loss: 0.594614\n",
      "epoch 184; iter: 0; batch classifier loss: 0.498795; batch adversarial loss: 0.466379\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356746; batch adversarial loss: 0.623436\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366653; batch adversarial loss: 0.605186\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345312; batch adversarial loss: 0.617439\n",
      "epoch 188; iter: 0; batch classifier loss: 0.420932; batch adversarial loss: 0.581432\n",
      "epoch 189; iter: 0; batch classifier loss: 0.274084; batch adversarial loss: 0.522687\n",
      "epoch 190; iter: 0; batch classifier loss: 0.433929; batch adversarial loss: 0.470030\n",
      "epoch 191; iter: 0; batch classifier loss: 0.369358; batch adversarial loss: 0.561345\n",
      "epoch 192; iter: 0; batch classifier loss: 0.300955; batch adversarial loss: 0.510740\n",
      "epoch 193; iter: 0; batch classifier loss: 0.321622; batch adversarial loss: 0.570766\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341416; batch adversarial loss: 0.595941\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322584; batch adversarial loss: 0.516749\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400289; batch adversarial loss: 0.517757\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341879; batch adversarial loss: 0.544669\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317708; batch adversarial loss: 0.534816\n",
      "epoch 199; iter: 0; batch classifier loss: 0.310594; batch adversarial loss: 0.543341\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677217; batch adversarial loss: 0.549074\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584456; batch adversarial loss: 0.658927\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562199; batch adversarial loss: 0.671792\n",
      "epoch 3; iter: 0; batch classifier loss: 0.545432; batch adversarial loss: 0.640471\n",
      "epoch 4; iter: 0; batch classifier loss: 0.536175; batch adversarial loss: 0.617367\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560228; batch adversarial loss: 0.731611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.588441; batch adversarial loss: 0.651648\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555434; batch adversarial loss: 0.604748\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543105; batch adversarial loss: 0.595527\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584169; batch adversarial loss: 0.590645\n",
      "epoch 10; iter: 0; batch classifier loss: 0.601196; batch adversarial loss: 0.608745\n",
      "epoch 11; iter: 0; batch classifier loss: 0.594029; batch adversarial loss: 0.616442\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531961; batch adversarial loss: 0.593650\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563974; batch adversarial loss: 0.586954\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476949; batch adversarial loss: 0.564702\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497296; batch adversarial loss: 0.634945\n",
      "epoch 16; iter: 0; batch classifier loss: 0.595550; batch adversarial loss: 0.610401\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462514; batch adversarial loss: 0.549649\n",
      "epoch 18; iter: 0; batch classifier loss: 0.572392; batch adversarial loss: 0.575557\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439976; batch adversarial loss: 0.572180\n",
      "epoch 20; iter: 0; batch classifier loss: 0.526229; batch adversarial loss: 0.549666\n",
      "epoch 21; iter: 0; batch classifier loss: 0.444581; batch adversarial loss: 0.519090\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480225; batch adversarial loss: 0.483047\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466863; batch adversarial loss: 0.564351\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459763; batch adversarial loss: 0.519180\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420344; batch adversarial loss: 0.604715\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482748; batch adversarial loss: 0.546885\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460399; batch adversarial loss: 0.568660\n",
      "epoch 28; iter: 0; batch classifier loss: 0.430673; batch adversarial loss: 0.596358\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481754; batch adversarial loss: 0.537344\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436558; batch adversarial loss: 0.553069\n",
      "epoch 31; iter: 0; batch classifier loss: 0.362905; batch adversarial loss: 0.572600\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502496; batch adversarial loss: 0.543658\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406123; batch adversarial loss: 0.530605\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394331; batch adversarial loss: 0.556714\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448445; batch adversarial loss: 0.659638\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502889; batch adversarial loss: 0.631221\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440323; batch adversarial loss: 0.588334\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455388; batch adversarial loss: 0.656783\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458192; batch adversarial loss: 0.537677\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460139; batch adversarial loss: 0.529018\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404745; batch adversarial loss: 0.578778\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364524; batch adversarial loss: 0.503689\n",
      "epoch 43; iter: 0; batch classifier loss: 0.488666; batch adversarial loss: 0.494995\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388976; batch adversarial loss: 0.587818\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389083; batch adversarial loss: 0.486189\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371422; batch adversarial loss: 0.509177\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412421; batch adversarial loss: 0.534733\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402617; batch adversarial loss: 0.545649\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373382; batch adversarial loss: 0.544347\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378515; batch adversarial loss: 0.570677\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418088; batch adversarial loss: 0.554221\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428153; batch adversarial loss: 0.529163\n",
      "epoch 53; iter: 0; batch classifier loss: 0.477369; batch adversarial loss: 0.465239\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445387; batch adversarial loss: 0.633647\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377632; batch adversarial loss: 0.579911\n",
      "epoch 56; iter: 0; batch classifier loss: 0.481004; batch adversarial loss: 0.678057\n",
      "epoch 57; iter: 0; batch classifier loss: 0.433717; batch adversarial loss: 0.552881\n",
      "epoch 58; iter: 0; batch classifier loss: 0.362221; batch adversarial loss: 0.624247\n",
      "epoch 59; iter: 0; batch classifier loss: 0.377760; batch adversarial loss: 0.605837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.349733; batch adversarial loss: 0.605282\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408341; batch adversarial loss: 0.588124\n",
      "epoch 62; iter: 0; batch classifier loss: 0.418195; batch adversarial loss: 0.587765\n",
      "epoch 63; iter: 0; batch classifier loss: 0.367380; batch adversarial loss: 0.466416\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380054; batch adversarial loss: 0.588103\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393346; batch adversarial loss: 0.544526\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413737; batch adversarial loss: 0.509355\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442056; batch adversarial loss: 0.624057\n",
      "epoch 68; iter: 0; batch classifier loss: 0.446949; batch adversarial loss: 0.579639\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400519; batch adversarial loss: 0.499254\n",
      "epoch 70; iter: 0; batch classifier loss: 0.442821; batch adversarial loss: 0.640922\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426020; batch adversarial loss: 0.590084\n",
      "epoch 72; iter: 0; batch classifier loss: 0.511651; batch adversarial loss: 0.589400\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441914; batch adversarial loss: 0.475841\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401403; batch adversarial loss: 0.596007\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377355; batch adversarial loss: 0.554030\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400595; batch adversarial loss: 0.527994\n",
      "epoch 77; iter: 0; batch classifier loss: 0.464171; batch adversarial loss: 0.562658\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378460; batch adversarial loss: 0.511013\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428667; batch adversarial loss: 0.519218\n",
      "epoch 80; iter: 0; batch classifier loss: 0.311667; batch adversarial loss: 0.571014\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407656; batch adversarial loss: 0.570859\n",
      "epoch 82; iter: 0; batch classifier loss: 0.427914; batch adversarial loss: 0.536292\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409507; batch adversarial loss: 0.492582\n",
      "epoch 84; iter: 0; batch classifier loss: 0.322969; batch adversarial loss: 0.588330\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365197; batch adversarial loss: 0.605575\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402305; batch adversarial loss: 0.502365\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394189; batch adversarial loss: 0.528839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.480149; batch adversarial loss: 0.528403\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382720; batch adversarial loss: 0.630890\n",
      "epoch 90; iter: 0; batch classifier loss: 0.414291; batch adversarial loss: 0.510273\n",
      "epoch 91; iter: 0; batch classifier loss: 0.342165; batch adversarial loss: 0.535736\n",
      "epoch 92; iter: 0; batch classifier loss: 0.455026; batch adversarial loss: 0.614127\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328292; batch adversarial loss: 0.614504\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423579; batch adversarial loss: 0.537667\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378319; batch adversarial loss: 0.546064\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349238; batch adversarial loss: 0.527136\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404386; batch adversarial loss: 0.510330\n",
      "epoch 98; iter: 0; batch classifier loss: 0.426026; batch adversarial loss: 0.553138\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346274; batch adversarial loss: 0.519674\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364329; batch adversarial loss: 0.553840\n",
      "epoch 101; iter: 0; batch classifier loss: 0.475304; batch adversarial loss: 0.528087\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390030; batch adversarial loss: 0.564024\n",
      "epoch 103; iter: 0; batch classifier loss: 0.368030; batch adversarial loss: 0.527432\n",
      "epoch 104; iter: 0; batch classifier loss: 0.340454; batch adversarial loss: 0.527270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.410949; batch adversarial loss: 0.527771\n",
      "epoch 106; iter: 0; batch classifier loss: 0.433655; batch adversarial loss: 0.562311\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372757; batch adversarial loss: 0.545774\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413392; batch adversarial loss: 0.544804\n",
      "epoch 109; iter: 0; batch classifier loss: 0.324943; batch adversarial loss: 0.545003\n",
      "epoch 110; iter: 0; batch classifier loss: 0.318121; batch adversarial loss: 0.553314\n",
      "epoch 111; iter: 0; batch classifier loss: 0.430532; batch adversarial loss: 0.615032\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351397; batch adversarial loss: 0.579731\n",
      "epoch 113; iter: 0; batch classifier loss: 0.464175; batch adversarial loss: 0.631621\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382227; batch adversarial loss: 0.570833\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391937; batch adversarial loss: 0.545196\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369621; batch adversarial loss: 0.545268\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385581; batch adversarial loss: 0.510188\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385682; batch adversarial loss: 0.528099\n",
      "epoch 119; iter: 0; batch classifier loss: 0.355156; batch adversarial loss: 0.492680\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370882; batch adversarial loss: 0.536445\n",
      "epoch 121; iter: 0; batch classifier loss: 0.307134; batch adversarial loss: 0.579765\n",
      "epoch 122; iter: 0; batch classifier loss: 0.428375; batch adversarial loss: 0.527349\n",
      "epoch 123; iter: 0; batch classifier loss: 0.437101; batch adversarial loss: 0.553910\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347603; batch adversarial loss: 0.562500\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374519; batch adversarial loss: 0.526832\n",
      "epoch 126; iter: 0; batch classifier loss: 0.306574; batch adversarial loss: 0.605947\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383042; batch adversarial loss: 0.587762\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322925; batch adversarial loss: 0.502049\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379851; batch adversarial loss: 0.536830\n",
      "epoch 130; iter: 0; batch classifier loss: 0.327641; batch adversarial loss: 0.622356\n",
      "epoch 131; iter: 0; batch classifier loss: 0.307836; batch adversarial loss: 0.579510\n",
      "epoch 132; iter: 0; batch classifier loss: 0.436054; batch adversarial loss: 0.545093\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411771; batch adversarial loss: 0.536253\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374565; batch adversarial loss: 0.493393\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377940; batch adversarial loss: 0.570799\n",
      "epoch 136; iter: 0; batch classifier loss: 0.415919; batch adversarial loss: 0.518797\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349821; batch adversarial loss: 0.596934\n",
      "epoch 138; iter: 0; batch classifier loss: 0.434616; batch adversarial loss: 0.518828\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360200; batch adversarial loss: 0.536322\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399710; batch adversarial loss: 0.536384\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326908; batch adversarial loss: 0.518962\n",
      "epoch 142; iter: 0; batch classifier loss: 0.446806; batch adversarial loss: 0.510181\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371216; batch adversarial loss: 0.571101\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380066; batch adversarial loss: 0.536299\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368282; batch adversarial loss: 0.571297\n",
      "epoch 146; iter: 0; batch classifier loss: 0.424029; batch adversarial loss: 0.614411\n",
      "epoch 147; iter: 0; batch classifier loss: 0.418864; batch adversarial loss: 0.553785\n",
      "epoch 148; iter: 0; batch classifier loss: 0.492652; batch adversarial loss: 0.492741\n",
      "epoch 149; iter: 0; batch classifier loss: 0.464294; batch adversarial loss: 0.623029\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371815; batch adversarial loss: 0.509989\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336582; batch adversarial loss: 0.588479\n",
      "epoch 152; iter: 0; batch classifier loss: 0.371427; batch adversarial loss: 0.510083\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389198; batch adversarial loss: 0.597098\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378954; batch adversarial loss: 0.527278\n",
      "epoch 155; iter: 0; batch classifier loss: 0.466985; batch adversarial loss: 0.553540\n",
      "epoch 156; iter: 0; batch classifier loss: 0.437258; batch adversarial loss: 0.579655\n",
      "epoch 157; iter: 0; batch classifier loss: 0.338873; batch adversarial loss: 0.475464\n",
      "epoch 158; iter: 0; batch classifier loss: 0.338361; batch adversarial loss: 0.510376\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339624; batch adversarial loss: 0.545440\n",
      "epoch 160; iter: 0; batch classifier loss: 0.357234; batch adversarial loss: 0.545098\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346689; batch adversarial loss: 0.606158\n",
      "epoch 162; iter: 0; batch classifier loss: 0.439211; batch adversarial loss: 0.579607\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336043; batch adversarial loss: 0.571082\n",
      "epoch 164; iter: 0; batch classifier loss: 0.331078; batch adversarial loss: 0.579898\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352065; batch adversarial loss: 0.518793\n",
      "epoch 166; iter: 0; batch classifier loss: 0.303340; batch adversarial loss: 0.570872\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379105; batch adversarial loss: 0.536129\n",
      "epoch 168; iter: 0; batch classifier loss: 0.394381; batch adversarial loss: 0.510198\n",
      "epoch 169; iter: 0; batch classifier loss: 0.447926; batch adversarial loss: 0.588342\n",
      "epoch 170; iter: 0; batch classifier loss: 0.452587; batch adversarial loss: 0.605620\n",
      "epoch 171; iter: 0; batch classifier loss: 0.259666; batch adversarial loss: 0.578662\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342630; batch adversarial loss: 0.554374\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367085; batch adversarial loss: 0.554239\n",
      "epoch 174; iter: 0; batch classifier loss: 0.446545; batch adversarial loss: 0.492750\n",
      "epoch 175; iter: 0; batch classifier loss: 0.406459; batch adversarial loss: 0.641000\n",
      "epoch 176; iter: 0; batch classifier loss: 0.307398; batch adversarial loss: 0.553654\n",
      "epoch 177; iter: 0; batch classifier loss: 0.409472; batch adversarial loss: 0.614698\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344143; batch adversarial loss: 0.510073\n",
      "epoch 179; iter: 0; batch classifier loss: 0.324503; batch adversarial loss: 0.545087\n",
      "epoch 180; iter: 0; batch classifier loss: 0.324474; batch adversarial loss: 0.509945\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347194; batch adversarial loss: 0.510146\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374180; batch adversarial loss: 0.606061\n",
      "epoch 183; iter: 0; batch classifier loss: 0.417450; batch adversarial loss: 0.510424\n",
      "epoch 184; iter: 0; batch classifier loss: 0.446084; batch adversarial loss: 0.614674\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352958; batch adversarial loss: 0.544215\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407190; batch adversarial loss: 0.571126\n",
      "epoch 187; iter: 0; batch classifier loss: 0.401203; batch adversarial loss: 0.604747\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377815; batch adversarial loss: 0.605266\n",
      "epoch 189; iter: 0; batch classifier loss: 0.353291; batch adversarial loss: 0.562624\n",
      "epoch 190; iter: 0; batch classifier loss: 0.239792; batch adversarial loss: 0.553742\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354816; batch adversarial loss: 0.518678\n",
      "epoch 192; iter: 0; batch classifier loss: 0.336586; batch adversarial loss: 0.615335\n",
      "epoch 193; iter: 0; batch classifier loss: 0.354009; batch adversarial loss: 0.527166\n",
      "epoch 194; iter: 0; batch classifier loss: 0.355903; batch adversarial loss: 0.579754\n",
      "epoch 195; iter: 0; batch classifier loss: 0.280870; batch adversarial loss: 0.606289\n",
      "epoch 196; iter: 0; batch classifier loss: 0.368613; batch adversarial loss: 0.543358\n",
      "epoch 197; iter: 0; batch classifier loss: 0.389599; batch adversarial loss: 0.491072\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387468; batch adversarial loss: 0.642120\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352473; batch adversarial loss: 0.562956\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717588; batch adversarial loss: 0.870657\n",
      "epoch 1; iter: 0; batch classifier loss: 0.764637; batch adversarial loss: 0.999184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.705722; batch adversarial loss: 0.947849\n",
      "epoch 3; iter: 0; batch classifier loss: 0.643990; batch adversarial loss: 0.886040\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581988; batch adversarial loss: 0.783932\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608903; batch adversarial loss: 0.737844\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554072; batch adversarial loss: 0.704059\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535470; batch adversarial loss: 0.669912\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509777; batch adversarial loss: 0.621861\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517667; batch adversarial loss: 0.647281\n",
      "epoch 10; iter: 0; batch classifier loss: 0.604995; batch adversarial loss: 0.626616\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548899; batch adversarial loss: 0.604158\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555728; batch adversarial loss: 0.602720\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474389; batch adversarial loss: 0.626224\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549466; batch adversarial loss: 0.611135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504023; batch adversarial loss: 0.595506\n",
      "epoch 16; iter: 0; batch classifier loss: 0.572709; batch adversarial loss: 0.623473\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484895; batch adversarial loss: 0.561957\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556095; batch adversarial loss: 0.587215\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514861; batch adversarial loss: 0.580062\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495866; batch adversarial loss: 0.572683\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502911; batch adversarial loss: 0.571010\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452909; batch adversarial loss: 0.584347\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525543; batch adversarial loss: 0.566019\n",
      "epoch 24; iter: 0; batch classifier loss: 0.556301; batch adversarial loss: 0.537485\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463033; batch adversarial loss: 0.546368\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536088; batch adversarial loss: 0.632127\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459352; batch adversarial loss: 0.537023\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438324; batch adversarial loss: 0.583365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.499356; batch adversarial loss: 0.598025\n",
      "epoch 30; iter: 0; batch classifier loss: 0.500486; batch adversarial loss: 0.542480\n",
      "epoch 31; iter: 0; batch classifier loss: 0.418918; batch adversarial loss: 0.489647\n",
      "epoch 32; iter: 0; batch classifier loss: 0.535352; batch adversarial loss: 0.565583\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424013; batch adversarial loss: 0.608051\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478685; batch adversarial loss: 0.515471\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426657; batch adversarial loss: 0.537177\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499861; batch adversarial loss: 0.580935\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425966; batch adversarial loss: 0.559948\n",
      "epoch 38; iter: 0; batch classifier loss: 0.539911; batch adversarial loss: 0.534829\n",
      "epoch 39; iter: 0; batch classifier loss: 0.412575; batch adversarial loss: 0.519542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497989; batch adversarial loss: 0.600353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395612; batch adversarial loss: 0.574397\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398450; batch adversarial loss: 0.577962\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441912; batch adversarial loss: 0.592759\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499273; batch adversarial loss: 0.562820\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449480; batch adversarial loss: 0.522646\n",
      "epoch 46; iter: 0; batch classifier loss: 0.486220; batch adversarial loss: 0.504995\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467833; batch adversarial loss: 0.465054\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440626; batch adversarial loss: 0.576425\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440846; batch adversarial loss: 0.609893\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432260; batch adversarial loss: 0.517131\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426161; batch adversarial loss: 0.579962\n",
      "epoch 52; iter: 0; batch classifier loss: 0.453702; batch adversarial loss: 0.516304\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396718; batch adversarial loss: 0.499962\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427068; batch adversarial loss: 0.527180\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406999; batch adversarial loss: 0.588602\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429749; batch adversarial loss: 0.623473\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415181; batch adversarial loss: 0.529847\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444343; batch adversarial loss: 0.588850\n",
      "epoch 59; iter: 0; batch classifier loss: 0.393525; batch adversarial loss: 0.570247\n",
      "epoch 60; iter: 0; batch classifier loss: 0.463887; batch adversarial loss: 0.554703\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426477; batch adversarial loss: 0.590367\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396096; batch adversarial loss: 0.554263\n",
      "epoch 63; iter: 0; batch classifier loss: 0.339444; batch adversarial loss: 0.544466\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424083; batch adversarial loss: 0.500329\n",
      "epoch 65; iter: 0; batch classifier loss: 0.471356; batch adversarial loss: 0.490349\n",
      "epoch 66; iter: 0; batch classifier loss: 0.362568; batch adversarial loss: 0.518061\n",
      "epoch 67; iter: 0; batch classifier loss: 0.371256; batch adversarial loss: 0.633814\n",
      "epoch 68; iter: 0; batch classifier loss: 0.465333; batch adversarial loss: 0.491433\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388695; batch adversarial loss: 0.562590\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420081; batch adversarial loss: 0.544695\n",
      "epoch 71; iter: 0; batch classifier loss: 0.440627; batch adversarial loss: 0.607561\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388204; batch adversarial loss: 0.490420\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390919; batch adversarial loss: 0.561935\n",
      "epoch 74; iter: 0; batch classifier loss: 0.370159; batch adversarial loss: 0.517360\n",
      "epoch 75; iter: 0; batch classifier loss: 0.463453; batch adversarial loss: 0.640923\n",
      "epoch 76; iter: 0; batch classifier loss: 0.321853; batch adversarial loss: 0.614645\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418611; batch adversarial loss: 0.535016\n",
      "epoch 78; iter: 0; batch classifier loss: 0.478828; batch adversarial loss: 0.564548\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367889; batch adversarial loss: 0.523966\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447155; batch adversarial loss: 0.552571\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367695; batch adversarial loss: 0.534150\n",
      "epoch 82; iter: 0; batch classifier loss: 0.449551; batch adversarial loss: 0.555357\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394272; batch adversarial loss: 0.598735\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353772; batch adversarial loss: 0.482808\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427392; batch adversarial loss: 0.553722\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435930; batch adversarial loss: 0.555128\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398552; batch adversarial loss: 0.590467\n",
      "epoch 88; iter: 0; batch classifier loss: 0.439533; batch adversarial loss: 0.588399\n",
      "epoch 89; iter: 0; batch classifier loss: 0.335479; batch adversarial loss: 0.509103\n",
      "epoch 90; iter: 0; batch classifier loss: 0.486967; batch adversarial loss: 0.572211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.405842; batch adversarial loss: 0.517188\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340877; batch adversarial loss: 0.571415\n",
      "epoch 93; iter: 0; batch classifier loss: 0.416733; batch adversarial loss: 0.561620\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426964; batch adversarial loss: 0.551103\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352185; batch adversarial loss: 0.551979\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392942; batch adversarial loss: 0.553518\n",
      "epoch 97; iter: 0; batch classifier loss: 0.448280; batch adversarial loss: 0.535618\n",
      "epoch 98; iter: 0; batch classifier loss: 0.417902; batch adversarial loss: 0.499689\n",
      "epoch 99; iter: 0; batch classifier loss: 0.450049; batch adversarial loss: 0.490368\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361598; batch adversarial loss: 0.537002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.408306; batch adversarial loss: 0.553539\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335044; batch adversarial loss: 0.560567\n",
      "epoch 103; iter: 0; batch classifier loss: 0.435990; batch adversarial loss: 0.544746\n",
      "epoch 104; iter: 0; batch classifier loss: 0.380122; batch adversarial loss: 0.643225\n",
      "epoch 105; iter: 0; batch classifier loss: 0.441587; batch adversarial loss: 0.517795\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432391; batch adversarial loss: 0.536042\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380889; batch adversarial loss: 0.580318\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369417; batch adversarial loss: 0.473782\n",
      "epoch 109; iter: 0; batch classifier loss: 0.475201; batch adversarial loss: 0.491365\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400920; batch adversarial loss: 0.544518\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433018; batch adversarial loss: 0.499500\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382969; batch adversarial loss: 0.571099\n",
      "epoch 113; iter: 0; batch classifier loss: 0.445742; batch adversarial loss: 0.544243\n",
      "epoch 114; iter: 0; batch classifier loss: 0.299434; batch adversarial loss: 0.643546\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389231; batch adversarial loss: 0.490761\n",
      "epoch 116; iter: 0; batch classifier loss: 0.419857; batch adversarial loss: 0.553035\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345441; batch adversarial loss: 0.579714\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342960; batch adversarial loss: 0.543561\n",
      "epoch 119; iter: 0; batch classifier loss: 0.472877; batch adversarial loss: 0.544875\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357900; batch adversarial loss: 0.543136\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373633; batch adversarial loss: 0.581340\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339769; batch adversarial loss: 0.626613\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399124; batch adversarial loss: 0.482340\n",
      "epoch 124; iter: 0; batch classifier loss: 0.451494; batch adversarial loss: 0.634157\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356876; batch adversarial loss: 0.526757\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385176; batch adversarial loss: 0.535895\n",
      "epoch 127; iter: 0; batch classifier loss: 0.308789; batch adversarial loss: 0.482357\n",
      "epoch 128; iter: 0; batch classifier loss: 0.437599; batch adversarial loss: 0.526156\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376234; batch adversarial loss: 0.517874\n",
      "epoch 130; iter: 0; batch classifier loss: 0.328246; batch adversarial loss: 0.491272\n",
      "epoch 131; iter: 0; batch classifier loss: 0.481858; batch adversarial loss: 0.580486\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388053; batch adversarial loss: 0.500226\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390007; batch adversarial loss: 0.552214\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333623; batch adversarial loss: 0.544011\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358509; batch adversarial loss: 0.471017\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364119; batch adversarial loss: 0.559593\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351506; batch adversarial loss: 0.570315\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376006; batch adversarial loss: 0.600788\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357605; batch adversarial loss: 0.508440\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401040; batch adversarial loss: 0.582057\n",
      "epoch 141; iter: 0; batch classifier loss: 0.440363; batch adversarial loss: 0.510345\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387770; batch adversarial loss: 0.508946\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388874; batch adversarial loss: 0.597804\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340647; batch adversarial loss: 0.481508\n",
      "epoch 145; iter: 0; batch classifier loss: 0.361045; batch adversarial loss: 0.508467\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357200; batch adversarial loss: 0.616100\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317648; batch adversarial loss: 0.600341\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323789; batch adversarial loss: 0.518895\n",
      "epoch 149; iter: 0; batch classifier loss: 0.381780; batch adversarial loss: 0.624501\n",
      "epoch 150; iter: 0; batch classifier loss: 0.324545; batch adversarial loss: 0.527160\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384464; batch adversarial loss: 0.554045\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373754; batch adversarial loss: 0.545490\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379357; batch adversarial loss: 0.527106\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378221; batch adversarial loss: 0.518179\n",
      "epoch 155; iter: 0; batch classifier loss: 0.425720; batch adversarial loss: 0.650804\n",
      "epoch 156; iter: 0; batch classifier loss: 0.437669; batch adversarial loss: 0.624557\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329234; batch adversarial loss: 0.597887\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403538; batch adversarial loss: 0.562269\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377508; batch adversarial loss: 0.544411\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398116; batch adversarial loss: 0.598733\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408247; batch adversarial loss: 0.552028\n",
      "epoch 162; iter: 0; batch classifier loss: 0.324619; batch adversarial loss: 0.578542\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354278; batch adversarial loss: 0.515162\n",
      "epoch 164; iter: 0; batch classifier loss: 0.319108; batch adversarial loss: 0.563362\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395435; batch adversarial loss: 0.574214\n",
      "epoch 166; iter: 0; batch classifier loss: 0.345348; batch adversarial loss: 0.580972\n",
      "epoch 167; iter: 0; batch classifier loss: 0.404426; batch adversarial loss: 0.571071\n",
      "epoch 168; iter: 0; batch classifier loss: 0.382925; batch adversarial loss: 0.608099\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326399; batch adversarial loss: 0.591224\n",
      "epoch 170; iter: 0; batch classifier loss: 0.469515; batch adversarial loss: 0.567549\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367134; batch adversarial loss: 0.473359\n",
      "epoch 172; iter: 0; batch classifier loss: 0.320091; batch adversarial loss: 0.542426\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351527; batch adversarial loss: 0.498070\n",
      "epoch 174; iter: 0; batch classifier loss: 0.386160; batch adversarial loss: 0.502042\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294730; batch adversarial loss: 0.564079\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384997; batch adversarial loss: 0.561746\n",
      "epoch 177; iter: 0; batch classifier loss: 0.297772; batch adversarial loss: 0.580960\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336138; batch adversarial loss: 0.582180\n",
      "epoch 179; iter: 0; batch classifier loss: 0.326357; batch adversarial loss: 0.579132\n",
      "epoch 180; iter: 0; batch classifier loss: 0.295694; batch adversarial loss: 0.501228\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339301; batch adversarial loss: 0.544550\n",
      "epoch 182; iter: 0; batch classifier loss: 0.317836; batch adversarial loss: 0.589606\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342178; batch adversarial loss: 0.509664\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287823; batch adversarial loss: 0.518469\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326574; batch adversarial loss: 0.571247\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313758; batch adversarial loss: 0.580044\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358872; batch adversarial loss: 0.491210\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406162; batch adversarial loss: 0.535940\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332897; batch adversarial loss: 0.553835\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341444; batch adversarial loss: 0.570991\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362691; batch adversarial loss: 0.516292\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371114; batch adversarial loss: 0.599910\n",
      "epoch 193; iter: 0; batch classifier loss: 0.312789; batch adversarial loss: 0.651220\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348660; batch adversarial loss: 0.544662\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366630; batch adversarial loss: 0.578000\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381856; batch adversarial loss: 0.519512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.437208; batch adversarial loss: 0.437437\n",
      "epoch 198; iter: 0; batch classifier loss: 0.395752; batch adversarial loss: 0.581020\n",
      "epoch 199; iter: 0; batch classifier loss: 0.382757; batch adversarial loss: 0.553363\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689927; batch adversarial loss: 0.563974\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556561; batch adversarial loss: 0.646316\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613147; batch adversarial loss: 0.606094\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565877; batch adversarial loss: 0.657678\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565627; batch adversarial loss: 0.625937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554150; batch adversarial loss: 0.592587\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484462; batch adversarial loss: 0.645956\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594979; batch adversarial loss: 0.624416\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526199; batch adversarial loss: 0.649914\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562454; batch adversarial loss: 0.615880\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561069; batch adversarial loss: 0.602938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.510887; batch adversarial loss: 0.584037\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498612; batch adversarial loss: 0.565711\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514894; batch adversarial loss: 0.529771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.455961; batch adversarial loss: 0.541119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487475; batch adversarial loss: 0.511799\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541254; batch adversarial loss: 0.521139\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511338; batch adversarial loss: 0.607636\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493848; batch adversarial loss: 0.535801\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426937; batch adversarial loss: 0.590200\n",
      "epoch 20; iter: 0; batch classifier loss: 0.552230; batch adversarial loss: 0.552325\n",
      "epoch 21; iter: 0; batch classifier loss: 0.580042; batch adversarial loss: 0.540112\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480467; batch adversarial loss: 0.553219\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454144; batch adversarial loss: 0.539395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.532618; batch adversarial loss: 0.531387\n",
      "epoch 25; iter: 0; batch classifier loss: 0.410737; batch adversarial loss: 0.580994\n",
      "epoch 26; iter: 0; batch classifier loss: 0.596420; batch adversarial loss: 0.556053\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476780; batch adversarial loss: 0.556479\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477366; batch adversarial loss: 0.512729\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461635; batch adversarial loss: 0.562752\n",
      "epoch 30; iter: 0; batch classifier loss: 0.566792; batch adversarial loss: 0.536076\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474259; batch adversarial loss: 0.544472\n",
      "epoch 32; iter: 0; batch classifier loss: 0.511760; batch adversarial loss: 0.492171\n",
      "epoch 33; iter: 0; batch classifier loss: 0.534187; batch adversarial loss: 0.519478\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418571; batch adversarial loss: 0.544454\n",
      "epoch 35; iter: 0; batch classifier loss: 0.550714; batch adversarial loss: 0.545015\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428831; batch adversarial loss: 0.509713\n",
      "epoch 37; iter: 0; batch classifier loss: 0.501491; batch adversarial loss: 0.553192\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498376; batch adversarial loss: 0.510242\n",
      "epoch 39; iter: 0; batch classifier loss: 0.542032; batch adversarial loss: 0.553759\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455853; batch adversarial loss: 0.482587\n",
      "epoch 41; iter: 0; batch classifier loss: 0.356161; batch adversarial loss: 0.561881\n",
      "epoch 42; iter: 0; batch classifier loss: 0.507879; batch adversarial loss: 0.518748\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491192; batch adversarial loss: 0.605817\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418210; batch adversarial loss: 0.570153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439649; batch adversarial loss: 0.527348\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409807; batch adversarial loss: 0.535300\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400183; batch adversarial loss: 0.536362\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475431; batch adversarial loss: 0.526671\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441194; batch adversarial loss: 0.616490\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433040; batch adversarial loss: 0.607293\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406833; batch adversarial loss: 0.526413\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418460; batch adversarial loss: 0.561828\n",
      "epoch 53; iter: 0; batch classifier loss: 0.502815; batch adversarial loss: 0.615214\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451418; batch adversarial loss: 0.525403\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441173; batch adversarial loss: 0.517507\n",
      "epoch 56; iter: 0; batch classifier loss: 0.376705; batch adversarial loss: 0.544721\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446234; batch adversarial loss: 0.548023\n",
      "epoch 58; iter: 0; batch classifier loss: 0.511256; batch adversarial loss: 0.539825\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396611; batch adversarial loss: 0.560570\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370123; batch adversarial loss: 0.523956\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427219; batch adversarial loss: 0.534772\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436230; batch adversarial loss: 0.489211\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458386; batch adversarial loss: 0.481616\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389726; batch adversarial loss: 0.505612\n",
      "epoch 65; iter: 0; batch classifier loss: 0.481813; batch adversarial loss: 0.490236\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435857; batch adversarial loss: 0.553443\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443554; batch adversarial loss: 0.613478\n",
      "epoch 68; iter: 0; batch classifier loss: 0.503802; batch adversarial loss: 0.555165\n",
      "epoch 69; iter: 0; batch classifier loss: 0.445614; batch adversarial loss: 0.535361\n",
      "epoch 70; iter: 0; batch classifier loss: 0.450241; batch adversarial loss: 0.554016\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427392; batch adversarial loss: 0.526296\n",
      "epoch 72; iter: 0; batch classifier loss: 0.499711; batch adversarial loss: 0.591450\n",
      "epoch 73; iter: 0; batch classifier loss: 0.455736; batch adversarial loss: 0.516062\n",
      "epoch 74; iter: 0; batch classifier loss: 0.496030; batch adversarial loss: 0.626570\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435268; batch adversarial loss: 0.600689\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421964; batch adversarial loss: 0.543963\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418171; batch adversarial loss: 0.571902\n",
      "epoch 78; iter: 0; batch classifier loss: 0.491334; batch adversarial loss: 0.499829\n",
      "epoch 79; iter: 0; batch classifier loss: 0.435514; batch adversarial loss: 0.499187\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435540; batch adversarial loss: 0.500835\n",
      "epoch 81; iter: 0; batch classifier loss: 0.453538; batch adversarial loss: 0.543340\n",
      "epoch 82; iter: 0; batch classifier loss: 0.428773; batch adversarial loss: 0.517305\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451103; batch adversarial loss: 0.526497\n",
      "epoch 84; iter: 0; batch classifier loss: 0.341746; batch adversarial loss: 0.539900\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398603; batch adversarial loss: 0.606163\n",
      "epoch 86; iter: 0; batch classifier loss: 0.464273; batch adversarial loss: 0.634529\n",
      "epoch 87; iter: 0; batch classifier loss: 0.447249; batch adversarial loss: 0.551735\n",
      "epoch 88; iter: 0; batch classifier loss: 0.432947; batch adversarial loss: 0.563005\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382293; batch adversarial loss: 0.563241\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426249; batch adversarial loss: 0.589185\n",
      "epoch 91; iter: 0; batch classifier loss: 0.521952; batch adversarial loss: 0.553227\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419970; batch adversarial loss: 0.578061\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439615; batch adversarial loss: 0.579946\n",
      "epoch 94; iter: 0; batch classifier loss: 0.454716; batch adversarial loss: 0.507982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.413605; batch adversarial loss: 0.563314\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443165; batch adversarial loss: 0.572614\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387019; batch adversarial loss: 0.527632\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434673; batch adversarial loss: 0.508433\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407394; batch adversarial loss: 0.550013\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392686; batch adversarial loss: 0.488385\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382834; batch adversarial loss: 0.670678\n",
      "epoch 102; iter: 0; batch classifier loss: 0.475394; batch adversarial loss: 0.472570\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361792; batch adversarial loss: 0.588867\n",
      "epoch 104; iter: 0; batch classifier loss: 0.410743; batch adversarial loss: 0.567437\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362845; batch adversarial loss: 0.564107\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420387; batch adversarial loss: 0.600590\n",
      "epoch 107; iter: 0; batch classifier loss: 0.420382; batch adversarial loss: 0.570122\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373884; batch adversarial loss: 0.570243\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367720; batch adversarial loss: 0.571757\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401520; batch adversarial loss: 0.501349\n",
      "epoch 111; iter: 0; batch classifier loss: 0.435953; batch adversarial loss: 0.626061\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396371; batch adversarial loss: 0.519992\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387889; batch adversarial loss: 0.608354\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418404; batch adversarial loss: 0.488637\n",
      "epoch 115; iter: 0; batch classifier loss: 0.456491; batch adversarial loss: 0.584934\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372590; batch adversarial loss: 0.494151\n",
      "epoch 117; iter: 0; batch classifier loss: 0.324525; batch adversarial loss: 0.554480\n",
      "epoch 118; iter: 0; batch classifier loss: 0.416279; batch adversarial loss: 0.564393\n",
      "epoch 119; iter: 0; batch classifier loss: 0.473434; batch adversarial loss: 0.568373\n",
      "epoch 120; iter: 0; batch classifier loss: 0.439110; batch adversarial loss: 0.554552\n",
      "epoch 121; iter: 0; batch classifier loss: 0.449107; batch adversarial loss: 0.588338\n",
      "epoch 122; iter: 0; batch classifier loss: 0.461483; batch adversarial loss: 0.562917\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390574; batch adversarial loss: 0.581879\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351764; batch adversarial loss: 0.527475\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411153; batch adversarial loss: 0.522797\n",
      "epoch 126; iter: 0; batch classifier loss: 0.428025; batch adversarial loss: 0.600042\n",
      "epoch 127; iter: 0; batch classifier loss: 0.448340; batch adversarial loss: 0.519300\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364545; batch adversarial loss: 0.590866\n",
      "epoch 129; iter: 0; batch classifier loss: 0.415420; batch adversarial loss: 0.554719\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321570; batch adversarial loss: 0.535735\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355354; batch adversarial loss: 0.595585\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395343; batch adversarial loss: 0.605731\n",
      "epoch 133; iter: 0; batch classifier loss: 0.422240; batch adversarial loss: 0.587952\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378256; batch adversarial loss: 0.509573\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349916; batch adversarial loss: 0.527286\n",
      "epoch 136; iter: 0; batch classifier loss: 0.294825; batch adversarial loss: 0.592140\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400190; batch adversarial loss: 0.564044\n",
      "epoch 138; iter: 0; batch classifier loss: 0.453378; batch adversarial loss: 0.545501\n",
      "epoch 139; iter: 0; batch classifier loss: 0.434525; batch adversarial loss: 0.528421\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405929; batch adversarial loss: 0.544467\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353328; batch adversarial loss: 0.600084\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376969; batch adversarial loss: 0.517589\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385521; batch adversarial loss: 0.530958\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336988; batch adversarial loss: 0.544774\n",
      "epoch 145; iter: 0; batch classifier loss: 0.460676; batch adversarial loss: 0.557234\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418487; batch adversarial loss: 0.576791\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358568; batch adversarial loss: 0.564454\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339441; batch adversarial loss: 0.598280\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374796; batch adversarial loss: 0.571700\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375201; batch adversarial loss: 0.591120\n",
      "epoch 151; iter: 0; batch classifier loss: 0.318076; batch adversarial loss: 0.488996\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370593; batch adversarial loss: 0.573115\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385537; batch adversarial loss: 0.570527\n",
      "epoch 154; iter: 0; batch classifier loss: 0.414368; batch adversarial loss: 0.472414\n",
      "epoch 155; iter: 0; batch classifier loss: 0.400836; batch adversarial loss: 0.500270\n",
      "epoch 156; iter: 0; batch classifier loss: 0.310247; batch adversarial loss: 0.554886\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392115; batch adversarial loss: 0.565656\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375502; batch adversarial loss: 0.568016\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368848; batch adversarial loss: 0.579420\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405674; batch adversarial loss: 0.520821\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345605; batch adversarial loss: 0.598379\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363947; batch adversarial loss: 0.589196\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403996; batch adversarial loss: 0.616992\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362281; batch adversarial loss: 0.536529\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405725; batch adversarial loss: 0.514412\n",
      "epoch 166; iter: 0; batch classifier loss: 0.418485; batch adversarial loss: 0.507818\n",
      "epoch 167; iter: 0; batch classifier loss: 0.405282; batch adversarial loss: 0.561767\n",
      "epoch 168; iter: 0; batch classifier loss: 0.411352; batch adversarial loss: 0.551748\n",
      "epoch 169; iter: 0; batch classifier loss: 0.414610; batch adversarial loss: 0.500228\n",
      "epoch 170; iter: 0; batch classifier loss: 0.399756; batch adversarial loss: 0.580349\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382150; batch adversarial loss: 0.523623\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373126; batch adversarial loss: 0.579849\n",
      "epoch 173; iter: 0; batch classifier loss: 0.390947; batch adversarial loss: 0.617544\n",
      "epoch 174; iter: 0; batch classifier loss: 0.316864; batch adversarial loss: 0.562258\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382141; batch adversarial loss: 0.646526\n",
      "epoch 176; iter: 0; batch classifier loss: 0.460807; batch adversarial loss: 0.542121\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433043; batch adversarial loss: 0.529804\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309962; batch adversarial loss: 0.513563\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330399; batch adversarial loss: 0.521243\n",
      "epoch 180; iter: 0; batch classifier loss: 0.361713; batch adversarial loss: 0.598931\n",
      "epoch 181; iter: 0; batch classifier loss: 0.396222; batch adversarial loss: 0.605349\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394599; batch adversarial loss: 0.637137\n",
      "epoch 183; iter: 0; batch classifier loss: 0.317329; batch adversarial loss: 0.517100\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401162; batch adversarial loss: 0.556312\n",
      "epoch 185; iter: 0; batch classifier loss: 0.415112; batch adversarial loss: 0.524174\n",
      "epoch 186; iter: 0; batch classifier loss: 0.393826; batch adversarial loss: 0.570100\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352907; batch adversarial loss: 0.587199\n",
      "epoch 188; iter: 0; batch classifier loss: 0.408820; batch adversarial loss: 0.461734\n",
      "epoch 189; iter: 0; batch classifier loss: 0.453393; batch adversarial loss: 0.500984\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357556; batch adversarial loss: 0.516693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.487584; batch adversarial loss: 0.532572\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349628; batch adversarial loss: 0.534067\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353264; batch adversarial loss: 0.486054\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378409; batch adversarial loss: 0.539523\n",
      "epoch 195; iter: 0; batch classifier loss: 0.380196; batch adversarial loss: 0.536584\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327460; batch adversarial loss: 0.597198\n",
      "epoch 197; iter: 0; batch classifier loss: 0.418657; batch adversarial loss: 0.538054\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393167; batch adversarial loss: 0.475744\n",
      "epoch 199; iter: 0; batch classifier loss: 0.506089; batch adversarial loss: 0.578788\n",
      "epoch 0; iter: 0; batch classifier loss: 0.785310; batch adversarial loss: 0.710968\n",
      "epoch 1; iter: 0; batch classifier loss: 0.635338; batch adversarial loss: 0.699699\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596490; batch adversarial loss: 0.711391\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577513; batch adversarial loss: 0.653533\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597699; batch adversarial loss: 0.603901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588123; batch adversarial loss: 0.572682\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574295; batch adversarial loss: 0.565534\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536283; batch adversarial loss: 0.606929\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566403; batch adversarial loss: 0.581661\n",
      "epoch 9; iter: 0; batch classifier loss: 0.605074; batch adversarial loss: 0.588138\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489657; batch adversarial loss: 0.630153\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579559; batch adversarial loss: 0.592881\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582763; batch adversarial loss: 0.579720\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509508; batch adversarial loss: 0.524086\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483268; batch adversarial loss: 0.583132\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493850; batch adversarial loss: 0.687727\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564024; batch adversarial loss: 0.588033\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533307; batch adversarial loss: 0.607995\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499877; batch adversarial loss: 0.604020\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537144; batch adversarial loss: 0.500669\n",
      "epoch 20; iter: 0; batch classifier loss: 0.544702; batch adversarial loss: 0.606158\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515558; batch adversarial loss: 0.509976\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447482; batch adversarial loss: 0.633569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457807; batch adversarial loss: 0.522815\n",
      "epoch 24; iter: 0; batch classifier loss: 0.652011; batch adversarial loss: 0.536438\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472523; batch adversarial loss: 0.541737\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489855; batch adversarial loss: 0.510996\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447944; batch adversarial loss: 0.561545\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513731; batch adversarial loss: 0.598355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453917; batch adversarial loss: 0.547652\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456802; batch adversarial loss: 0.537594\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428194; batch adversarial loss: 0.615820\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481818; batch adversarial loss: 0.599827\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451462; batch adversarial loss: 0.614010\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481098; batch adversarial loss: 0.520148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491493; batch adversarial loss: 0.503823\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488580; batch adversarial loss: 0.579912\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458328; batch adversarial loss: 0.501860\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419841; batch adversarial loss: 0.562414\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463402; batch adversarial loss: 0.473785\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461391; batch adversarial loss: 0.490765\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425706; batch adversarial loss: 0.598430\n",
      "epoch 42; iter: 0; batch classifier loss: 0.395294; batch adversarial loss: 0.570995\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433056; batch adversarial loss: 0.526347\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441348; batch adversarial loss: 0.561564\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402257; batch adversarial loss: 0.543878\n",
      "epoch 46; iter: 0; batch classifier loss: 0.442522; batch adversarial loss: 0.562206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404339; batch adversarial loss: 0.547800\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427867; batch adversarial loss: 0.611344\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418014; batch adversarial loss: 0.508995\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479869; batch adversarial loss: 0.522153\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481674; batch adversarial loss: 0.543091\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424081; batch adversarial loss: 0.572309\n",
      "epoch 53; iter: 0; batch classifier loss: 0.460675; batch adversarial loss: 0.533593\n",
      "epoch 54; iter: 0; batch classifier loss: 0.472062; batch adversarial loss: 0.565941\n",
      "epoch 55; iter: 0; batch classifier loss: 0.504156; batch adversarial loss: 0.597170\n",
      "epoch 56; iter: 0; batch classifier loss: 0.508737; batch adversarial loss: 0.573800\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434785; batch adversarial loss: 0.592782\n",
      "epoch 58; iter: 0; batch classifier loss: 0.509673; batch adversarial loss: 0.553586\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464354; batch adversarial loss: 0.554458\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383641; batch adversarial loss: 0.582074\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406546; batch adversarial loss: 0.570677\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391771; batch adversarial loss: 0.589398\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421276; batch adversarial loss: 0.544753\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384978; batch adversarial loss: 0.553504\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408880; batch adversarial loss: 0.474035\n",
      "epoch 66; iter: 0; batch classifier loss: 0.471473; batch adversarial loss: 0.544773\n",
      "epoch 67; iter: 0; batch classifier loss: 0.557743; batch adversarial loss: 0.561901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395614; batch adversarial loss: 0.526557\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419557; batch adversarial loss: 0.491049\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387698; batch adversarial loss: 0.537120\n",
      "epoch 71; iter: 0; batch classifier loss: 0.333627; batch adversarial loss: 0.526953\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385112; batch adversarial loss: 0.554535\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391985; batch adversarial loss: 0.616649\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416543; batch adversarial loss: 0.516575\n",
      "epoch 75; iter: 0; batch classifier loss: 0.363216; batch adversarial loss: 0.564100\n",
      "epoch 76; iter: 0; batch classifier loss: 0.322346; batch adversarial loss: 0.615867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.432777; batch adversarial loss: 0.579989\n",
      "epoch 78; iter: 0; batch classifier loss: 0.420196; batch adversarial loss: 0.491377\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401370; batch adversarial loss: 0.564063\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431084; batch adversarial loss: 0.526894\n",
      "epoch 81; iter: 0; batch classifier loss: 0.448052; batch adversarial loss: 0.562995\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414239; batch adversarial loss: 0.482141\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383916; batch adversarial loss: 0.527215\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416743; batch adversarial loss: 0.551740\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402762; batch adversarial loss: 0.523439\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425986; batch adversarial loss: 0.500206\n",
      "epoch 87; iter: 0; batch classifier loss: 0.431950; batch adversarial loss: 0.554679\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360243; batch adversarial loss: 0.654533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.484993; batch adversarial loss: 0.552924\n",
      "epoch 90; iter: 0; batch classifier loss: 0.483731; batch adversarial loss: 0.536226\n",
      "epoch 91; iter: 0; batch classifier loss: 0.499566; batch adversarial loss: 0.589858\n",
      "epoch 92; iter: 0; batch classifier loss: 0.327168; batch adversarial loss: 0.582371\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375906; batch adversarial loss: 0.506960\n",
      "epoch 94; iter: 0; batch classifier loss: 0.386223; batch adversarial loss: 0.554098\n",
      "epoch 95; iter: 0; batch classifier loss: 0.351417; batch adversarial loss: 0.479838\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438707; batch adversarial loss: 0.490123\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434096; batch adversarial loss: 0.582043\n",
      "epoch 98; iter: 0; batch classifier loss: 0.452761; batch adversarial loss: 0.508040\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394046; batch adversarial loss: 0.553220\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417940; batch adversarial loss: 0.508760\n",
      "epoch 101; iter: 0; batch classifier loss: 0.422495; batch adversarial loss: 0.545389\n",
      "epoch 102; iter: 0; batch classifier loss: 0.411675; batch adversarial loss: 0.570611\n",
      "epoch 103; iter: 0; batch classifier loss: 0.447004; batch adversarial loss: 0.617501\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384979; batch adversarial loss: 0.535124\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414903; batch adversarial loss: 0.544556\n",
      "epoch 106; iter: 0; batch classifier loss: 0.430190; batch adversarial loss: 0.553432\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412779; batch adversarial loss: 0.563836\n",
      "epoch 108; iter: 0; batch classifier loss: 0.423746; batch adversarial loss: 0.544576\n",
      "epoch 109; iter: 0; batch classifier loss: 0.392397; batch adversarial loss: 0.554442\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346589; batch adversarial loss: 0.562983\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354922; batch adversarial loss: 0.553562\n",
      "epoch 112; iter: 0; batch classifier loss: 0.424919; batch adversarial loss: 0.553788\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418361; batch adversarial loss: 0.544727\n",
      "epoch 114; iter: 0; batch classifier loss: 0.334494; batch adversarial loss: 0.534960\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379402; batch adversarial loss: 0.650684\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346113; batch adversarial loss: 0.581188\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365292; batch adversarial loss: 0.545272\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385578; batch adversarial loss: 0.516235\n",
      "epoch 119; iter: 0; batch classifier loss: 0.437421; batch adversarial loss: 0.579704\n",
      "epoch 120; iter: 0; batch classifier loss: 0.440918; batch adversarial loss: 0.563204\n",
      "epoch 121; iter: 0; batch classifier loss: 0.510519; batch adversarial loss: 0.590453\n",
      "epoch 122; iter: 0; batch classifier loss: 0.442346; batch adversarial loss: 0.590436\n",
      "epoch 123; iter: 0; batch classifier loss: 0.465788; batch adversarial loss: 0.535726\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342972; batch adversarial loss: 0.581280\n",
      "epoch 125; iter: 0; batch classifier loss: 0.333981; batch adversarial loss: 0.471440\n",
      "epoch 126; iter: 0; batch classifier loss: 0.402131; batch adversarial loss: 0.562839\n",
      "epoch 127; iter: 0; batch classifier loss: 0.287886; batch adversarial loss: 0.526380\n",
      "epoch 128; iter: 0; batch classifier loss: 0.384820; batch adversarial loss: 0.590010\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365856; batch adversarial loss: 0.553666\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363459; batch adversarial loss: 0.544424\n",
      "epoch 131; iter: 0; batch classifier loss: 0.420152; batch adversarial loss: 0.553419\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329798; batch adversarial loss: 0.562484\n",
      "epoch 133; iter: 0; batch classifier loss: 0.373858; batch adversarial loss: 0.581127\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400979; batch adversarial loss: 0.517558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373953; batch adversarial loss: 0.481287\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348136; batch adversarial loss: 0.553403\n",
      "epoch 137; iter: 0; batch classifier loss: 0.410729; batch adversarial loss: 0.507848\n",
      "epoch 138; iter: 0; batch classifier loss: 0.443333; batch adversarial loss: 0.526329\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369308; batch adversarial loss: 0.517284\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373408; batch adversarial loss: 0.571726\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358710; batch adversarial loss: 0.435884\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380097; batch adversarial loss: 0.544569\n",
      "epoch 143; iter: 0; batch classifier loss: 0.403719; batch adversarial loss: 0.634609\n",
      "epoch 144; iter: 0; batch classifier loss: 0.419845; batch adversarial loss: 0.589477\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358445; batch adversarial loss: 0.554252\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332497; batch adversarial loss: 0.598154\n",
      "epoch 147; iter: 0; batch classifier loss: 0.389086; batch adversarial loss: 0.535241\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350447; batch adversarial loss: 0.543855\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377920; batch adversarial loss: 0.598822\n",
      "epoch 150; iter: 0; batch classifier loss: 0.437795; batch adversarial loss: 0.554681\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387727; batch adversarial loss: 0.525397\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322560; batch adversarial loss: 0.545762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400672; batch adversarial loss: 0.571440\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372984; batch adversarial loss: 0.534478\n",
      "epoch 155; iter: 0; batch classifier loss: 0.332539; batch adversarial loss: 0.489650\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382559; batch adversarial loss: 0.546017\n",
      "epoch 157; iter: 0; batch classifier loss: 0.418279; batch adversarial loss: 0.526794\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398946; batch adversarial loss: 0.571440\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369212; batch adversarial loss: 0.507666\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365749; batch adversarial loss: 0.571625\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329200; batch adversarial loss: 0.490169\n",
      "epoch 162; iter: 0; batch classifier loss: 0.304956; batch adversarial loss: 0.571796\n",
      "epoch 163; iter: 0; batch classifier loss: 0.376335; batch adversarial loss: 0.607872\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334668; batch adversarial loss: 0.661216\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397205; batch adversarial loss: 0.562447\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351638; batch adversarial loss: 0.562467\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324125; batch adversarial loss: 0.598216\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340906; batch adversarial loss: 0.515622\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341589; batch adversarial loss: 0.543634\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325105; batch adversarial loss: 0.634962\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403438; batch adversarial loss: 0.608644\n",
      "epoch 172; iter: 0; batch classifier loss: 0.422975; batch adversarial loss: 0.516784\n",
      "epoch 173; iter: 0; batch classifier loss: 0.446113; batch adversarial loss: 0.481203\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400625; batch adversarial loss: 0.544446\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337500; batch adversarial loss: 0.553885\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388269; batch adversarial loss: 0.535418\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335606; batch adversarial loss: 0.599204\n",
      "epoch 178; iter: 0; batch classifier loss: 0.457350; batch adversarial loss: 0.545449\n",
      "epoch 179; iter: 0; batch classifier loss: 0.387155; batch adversarial loss: 0.508780\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386257; batch adversarial loss: 0.490089\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364433; batch adversarial loss: 0.517992\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338219; batch adversarial loss: 0.508146\n",
      "epoch 183; iter: 0; batch classifier loss: 0.413468; batch adversarial loss: 0.553641\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336441; batch adversarial loss: 0.453557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.388338; batch adversarial loss: 0.553494\n",
      "epoch 186; iter: 0; batch classifier loss: 0.384695; batch adversarial loss: 0.526296\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374520; batch adversarial loss: 0.544607\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376745; batch adversarial loss: 0.562745\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383485; batch adversarial loss: 0.544549\n",
      "epoch 190; iter: 0; batch classifier loss: 0.295513; batch adversarial loss: 0.580531\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350700; batch adversarial loss: 0.553345\n",
      "epoch 192; iter: 0; batch classifier loss: 0.348793; batch adversarial loss: 0.571453\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395756; batch adversarial loss: 0.580947\n",
      "epoch 194; iter: 0; batch classifier loss: 0.388137; batch adversarial loss: 0.571815\n",
      "epoch 195; iter: 0; batch classifier loss: 0.454566; batch adversarial loss: 0.562754\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330063; batch adversarial loss: 0.589914\n",
      "epoch 197; iter: 0; batch classifier loss: 0.274740; batch adversarial loss: 0.489996\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369145; batch adversarial loss: 0.535452\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309607; batch adversarial loss: 0.553621\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741763; batch adversarial loss: 0.646962\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599720; batch adversarial loss: 0.641317\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577477; batch adversarial loss: 0.658536\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497674; batch adversarial loss: 0.608768\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548702; batch adversarial loss: 0.616310\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601057; batch adversarial loss: 0.611610\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496762; batch adversarial loss: 0.579489\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542372; batch adversarial loss: 0.624624\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527583; batch adversarial loss: 0.616129\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536342; batch adversarial loss: 0.593871\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518208; batch adversarial loss: 0.667408\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564691; batch adversarial loss: 0.590029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463075; batch adversarial loss: 0.578741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502579; batch adversarial loss: 0.646104\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518329; batch adversarial loss: 0.546755\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533418; batch adversarial loss: 0.521366\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498801; batch adversarial loss: 0.604096\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554227; batch adversarial loss: 0.586926\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438475; batch adversarial loss: 0.506965\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499773; batch adversarial loss: 0.570491\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430729; batch adversarial loss: 0.554786\n",
      "epoch 21; iter: 0; batch classifier loss: 0.472903; batch adversarial loss: 0.562935\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485030; batch adversarial loss: 0.530113\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490323; batch adversarial loss: 0.575592\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491949; batch adversarial loss: 0.608805\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440081; batch adversarial loss: 0.516959\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434128; batch adversarial loss: 0.564629\n",
      "epoch 27; iter: 0; batch classifier loss: 0.547084; batch adversarial loss: 0.514777\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454802; batch adversarial loss: 0.510674\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471442; batch adversarial loss: 0.481871\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515479; batch adversarial loss: 0.528876\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473366; batch adversarial loss: 0.537212\n",
      "epoch 32; iter: 0; batch classifier loss: 0.489780; batch adversarial loss: 0.589928\n",
      "epoch 33; iter: 0; batch classifier loss: 0.390678; batch adversarial loss: 0.568636\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482431; batch adversarial loss: 0.556891\n",
      "epoch 35; iter: 0; batch classifier loss: 0.431515; batch adversarial loss: 0.472843\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498086; batch adversarial loss: 0.507098\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469081; batch adversarial loss: 0.604358\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458139; batch adversarial loss: 0.562379\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434368; batch adversarial loss: 0.495156\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435261; batch adversarial loss: 0.526563\n",
      "epoch 41; iter: 0; batch classifier loss: 0.494514; batch adversarial loss: 0.570309\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403904; batch adversarial loss: 0.501887\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386747; batch adversarial loss: 0.605102\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489183; batch adversarial loss: 0.545643\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469672; batch adversarial loss: 0.581000\n",
      "epoch 46; iter: 0; batch classifier loss: 0.564185; batch adversarial loss: 0.563117\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511368; batch adversarial loss: 0.607599\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393611; batch adversarial loss: 0.614307\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477446; batch adversarial loss: 0.527171\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414312; batch adversarial loss: 0.553463\n",
      "epoch 51; iter: 0; batch classifier loss: 0.495280; batch adversarial loss: 0.544353\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436254; batch adversarial loss: 0.589428\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472069; batch adversarial loss: 0.597722\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443964; batch adversarial loss: 0.490969\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449525; batch adversarial loss: 0.571253\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466615; batch adversarial loss: 0.553336\n",
      "epoch 57; iter: 0; batch classifier loss: 0.359489; batch adversarial loss: 0.544436\n",
      "epoch 58; iter: 0; batch classifier loss: 0.363767; batch adversarial loss: 0.562533\n",
      "epoch 59; iter: 0; batch classifier loss: 0.476933; batch adversarial loss: 0.527010\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410258; batch adversarial loss: 0.517991\n",
      "epoch 61; iter: 0; batch classifier loss: 0.363284; batch adversarial loss: 0.519075\n",
      "epoch 62; iter: 0; batch classifier loss: 0.371287; batch adversarial loss: 0.544056\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416061; batch adversarial loss: 0.570693\n",
      "epoch 64; iter: 0; batch classifier loss: 0.459031; batch adversarial loss: 0.551359\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390524; batch adversarial loss: 0.536963\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400586; batch adversarial loss: 0.599575\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374003; batch adversarial loss: 0.525994\n",
      "epoch 68; iter: 0; batch classifier loss: 0.456925; batch adversarial loss: 0.681749\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361716; batch adversarial loss: 0.562810\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476856; batch adversarial loss: 0.599186\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427330; batch adversarial loss: 0.526673\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376916; batch adversarial loss: 0.463129\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382576; batch adversarial loss: 0.472211\n",
      "epoch 74; iter: 0; batch classifier loss: 0.421967; batch adversarial loss: 0.508754\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395834; batch adversarial loss: 0.607746\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394638; batch adversarial loss: 0.526227\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415099; batch adversarial loss: 0.490698\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424371; batch adversarial loss: 0.571336\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384861; batch adversarial loss: 0.526624\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411882; batch adversarial loss: 0.490193\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406426; batch adversarial loss: 0.509122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.460451; batch adversarial loss: 0.579648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.395220; batch adversarial loss: 0.581447\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447696; batch adversarial loss: 0.581445\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380313; batch adversarial loss: 0.534818\n",
      "epoch 86; iter: 0; batch classifier loss: 0.461582; batch adversarial loss: 0.544204\n",
      "epoch 87; iter: 0; batch classifier loss: 0.448572; batch adversarial loss: 0.598433\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362325; batch adversarial loss: 0.559170\n",
      "epoch 89; iter: 0; batch classifier loss: 0.328988; batch adversarial loss: 0.509441\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393957; batch adversarial loss: 0.543484\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406883; batch adversarial loss: 0.527618\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381759; batch adversarial loss: 0.580471\n",
      "epoch 93; iter: 0; batch classifier loss: 0.376163; batch adversarial loss: 0.526995\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430674; batch adversarial loss: 0.526725\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431151; batch adversarial loss: 0.526806\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332624; batch adversarial loss: 0.509710\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423311; batch adversarial loss: 0.562550\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395945; batch adversarial loss: 0.607662\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373025; batch adversarial loss: 0.465007\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352809; batch adversarial loss: 0.554112\n",
      "epoch 101; iter: 0; batch classifier loss: 0.486238; batch adversarial loss: 0.580400\n",
      "epoch 102; iter: 0; batch classifier loss: 0.443197; batch adversarial loss: 0.588798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429297; batch adversarial loss: 0.642907\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363694; batch adversarial loss: 0.625955\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363432; batch adversarial loss: 0.570243\n",
      "epoch 106; iter: 0; batch classifier loss: 0.473931; batch adversarial loss: 0.543306\n",
      "epoch 107; iter: 0; batch classifier loss: 0.462819; batch adversarial loss: 0.643127\n",
      "epoch 108; iter: 0; batch classifier loss: 0.428236; batch adversarial loss: 0.553443\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387470; batch adversarial loss: 0.635730\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372474; batch adversarial loss: 0.616996\n",
      "epoch 111; iter: 0; batch classifier loss: 0.445115; batch adversarial loss: 0.482001\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412291; batch adversarial loss: 0.516358\n",
      "epoch 113; iter: 0; batch classifier loss: 0.425960; batch adversarial loss: 0.617206\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354715; batch adversarial loss: 0.551974\n",
      "epoch 115; iter: 0; batch classifier loss: 0.444438; batch adversarial loss: 0.517590\n",
      "epoch 116; iter: 0; batch classifier loss: 0.295272; batch adversarial loss: 0.607337\n",
      "epoch 117; iter: 0; batch classifier loss: 0.456658; batch adversarial loss: 0.553443\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347884; batch adversarial loss: 0.562355\n",
      "epoch 119; iter: 0; batch classifier loss: 0.429911; batch adversarial loss: 0.615127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400892; batch adversarial loss: 0.518324\n",
      "epoch 121; iter: 0; batch classifier loss: 0.435910; batch adversarial loss: 0.509805\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408330; batch adversarial loss: 0.534874\n",
      "epoch 123; iter: 0; batch classifier loss: 0.358058; batch adversarial loss: 0.491904\n",
      "epoch 124; iter: 0; batch classifier loss: 0.312886; batch adversarial loss: 0.518154\n",
      "epoch 125; iter: 0; batch classifier loss: 0.439452; batch adversarial loss: 0.473057\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382607; batch adversarial loss: 0.580729\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401622; batch adversarial loss: 0.491150\n",
      "epoch 128; iter: 0; batch classifier loss: 0.331338; batch adversarial loss: 0.562903\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378104; batch adversarial loss: 0.650800\n",
      "epoch 130; iter: 0; batch classifier loss: 0.424388; batch adversarial loss: 0.588968\n",
      "epoch 131; iter: 0; batch classifier loss: 0.315054; batch adversarial loss: 0.517712\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317362; batch adversarial loss: 0.498871\n",
      "epoch 133; iter: 0; batch classifier loss: 0.389619; batch adversarial loss: 0.571007\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399946; batch adversarial loss: 0.552246\n",
      "epoch 135; iter: 0; batch classifier loss: 0.383397; batch adversarial loss: 0.526966\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398950; batch adversarial loss: 0.625638\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403513; batch adversarial loss: 0.526750\n",
      "epoch 138; iter: 0; batch classifier loss: 0.352968; batch adversarial loss: 0.652510\n",
      "epoch 139; iter: 0; batch classifier loss: 0.485300; batch adversarial loss: 0.588839\n",
      "epoch 140; iter: 0; batch classifier loss: 0.312901; batch adversarial loss: 0.562520\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383857; batch adversarial loss: 0.562026\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345864; batch adversarial loss: 0.553318\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371491; batch adversarial loss: 0.563350\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351625; batch adversarial loss: 0.535764\n",
      "epoch 145; iter: 0; batch classifier loss: 0.321327; batch adversarial loss: 0.544475\n",
      "epoch 146; iter: 0; batch classifier loss: 0.412786; batch adversarial loss: 0.499576\n",
      "epoch 147; iter: 0; batch classifier loss: 0.407444; batch adversarial loss: 0.508247\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381038; batch adversarial loss: 0.571324\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359200; batch adversarial loss: 0.580761\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355431; batch adversarial loss: 0.590672\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415864; batch adversarial loss: 0.609540\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362637; batch adversarial loss: 0.617188\n",
      "epoch 153; iter: 0; batch classifier loss: 0.427138; batch adversarial loss: 0.498974\n",
      "epoch 154; iter: 0; batch classifier loss: 0.278174; batch adversarial loss: 0.506231\n",
      "epoch 155; iter: 0; batch classifier loss: 0.322537; batch adversarial loss: 0.524328\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328869; batch adversarial loss: 0.625693\n",
      "epoch 157; iter: 0; batch classifier loss: 0.347807; batch adversarial loss: 0.518545\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365396; batch adversarial loss: 0.603180\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394281; batch adversarial loss: 0.516155\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328988; batch adversarial loss: 0.497065\n",
      "epoch 161; iter: 0; batch classifier loss: 0.299141; batch adversarial loss: 0.589290\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394654; batch adversarial loss: 0.606522\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334297; batch adversarial loss: 0.494283\n",
      "epoch 164; iter: 0; batch classifier loss: 0.440714; batch adversarial loss: 0.599325\n",
      "epoch 165; iter: 0; batch classifier loss: 0.416071; batch adversarial loss: 0.562266\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343431; batch adversarial loss: 0.614001\n",
      "epoch 167; iter: 0; batch classifier loss: 0.292427; batch adversarial loss: 0.553261\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357287; batch adversarial loss: 0.590577\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333461; batch adversarial loss: 0.651745\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371775; batch adversarial loss: 0.570510\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349531; batch adversarial loss: 0.518415\n",
      "epoch 172; iter: 0; batch classifier loss: 0.408412; batch adversarial loss: 0.579541\n",
      "epoch 173; iter: 0; batch classifier loss: 0.395186; batch adversarial loss: 0.482505\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404224; batch adversarial loss: 0.508088\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395078; batch adversarial loss: 0.556372\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397977; batch adversarial loss: 0.597295\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340193; batch adversarial loss: 0.526869\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362475; batch adversarial loss: 0.571623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.381982; batch adversarial loss: 0.571455\n",
      "epoch 180; iter: 0; batch classifier loss: 0.429881; batch adversarial loss: 0.555032\n",
      "epoch 181; iter: 0; batch classifier loss: 0.396170; batch adversarial loss: 0.544449\n",
      "epoch 182; iter: 0; batch classifier loss: 0.421462; batch adversarial loss: 0.518008\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336810; batch adversarial loss: 0.580624\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389043; batch adversarial loss: 0.562683\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348436; batch adversarial loss: 0.571397\n",
      "epoch 186; iter: 0; batch classifier loss: 0.348626; batch adversarial loss: 0.571402\n",
      "epoch 187; iter: 0; batch classifier loss: 0.413749; batch adversarial loss: 0.554298\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350842; batch adversarial loss: 0.544837\n",
      "epoch 189; iter: 0; batch classifier loss: 0.310340; batch adversarial loss: 0.482401\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342796; batch adversarial loss: 0.517858\n",
      "epoch 191; iter: 0; batch classifier loss: 0.479985; batch adversarial loss: 0.535158\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333423; batch adversarial loss: 0.634152\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351467; batch adversarial loss: 0.580676\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392481; batch adversarial loss: 0.615990\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337112; batch adversarial loss: 0.527362\n",
      "epoch 196; iter: 0; batch classifier loss: 0.427091; batch adversarial loss: 0.517473\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392644; batch adversarial loss: 0.570805\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403224; batch adversarial loss: 0.543928\n",
      "epoch 199; iter: 0; batch classifier loss: 0.416872; batch adversarial loss: 0.553582\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695715; batch adversarial loss: 0.779294\n",
      "epoch 1; iter: 0; batch classifier loss: 0.709899; batch adversarial loss: 0.767747\n",
      "epoch 2; iter: 0; batch classifier loss: 0.713364; batch adversarial loss: 0.708606\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605977; batch adversarial loss: 0.650159\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532081; batch adversarial loss: 0.647883\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519879; batch adversarial loss: 0.651363\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570355; batch adversarial loss: 0.630012\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544874; batch adversarial loss: 0.619535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587936; batch adversarial loss: 0.574030\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531419; batch adversarial loss: 0.598590\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566684; batch adversarial loss: 0.608022\n",
      "epoch 11; iter: 0; batch classifier loss: 0.608316; batch adversarial loss: 0.570236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.434098; batch adversarial loss: 0.582854\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503506; batch adversarial loss: 0.507579\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506435; batch adversarial loss: 0.586631\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548313; batch adversarial loss: 0.563003\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507335; batch adversarial loss: 0.580216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542558; batch adversarial loss: 0.555342\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534069; batch adversarial loss: 0.555393\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531561; batch adversarial loss: 0.532657\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521661; batch adversarial loss: 0.526344\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475205; batch adversarial loss: 0.578413\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555039; batch adversarial loss: 0.541992\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547945; batch adversarial loss: 0.552246\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421243; batch adversarial loss: 0.528725\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472083; batch adversarial loss: 0.534736\n",
      "epoch 26; iter: 0; batch classifier loss: 0.437322; batch adversarial loss: 0.530193\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460113; batch adversarial loss: 0.530689\n",
      "epoch 28; iter: 0; batch classifier loss: 0.553716; batch adversarial loss: 0.425467\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468224; batch adversarial loss: 0.467314\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416644; batch adversarial loss: 0.532653\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435525; batch adversarial loss: 0.526107\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467383; batch adversarial loss: 0.542511\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489844; batch adversarial loss: 0.517727\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454875; batch adversarial loss: 0.517958\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451637; batch adversarial loss: 0.494110\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422426; batch adversarial loss: 0.539017\n",
      "epoch 37; iter: 0; batch classifier loss: 0.498313; batch adversarial loss: 0.489558\n",
      "epoch 38; iter: 0; batch classifier loss: 0.495539; batch adversarial loss: 0.564049\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485556; batch adversarial loss: 0.585853\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428838; batch adversarial loss: 0.518970\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428969; batch adversarial loss: 0.553184\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471887; batch adversarial loss: 0.480250\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473839; batch adversarial loss: 0.492592\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436095; batch adversarial loss: 0.517568\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502489; batch adversarial loss: 0.532760\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490514; batch adversarial loss: 0.471049\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476833; batch adversarial loss: 0.525831\n",
      "epoch 48; iter: 0; batch classifier loss: 0.365524; batch adversarial loss: 0.551556\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394860; batch adversarial loss: 0.498780\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450023; batch adversarial loss: 0.551907\n",
      "epoch 51; iter: 0; batch classifier loss: 0.412553; batch adversarial loss: 0.478168\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437929; batch adversarial loss: 0.602895\n",
      "epoch 53; iter: 0; batch classifier loss: 0.478923; batch adversarial loss: 0.547095\n",
      "epoch 54; iter: 0; batch classifier loss: 0.351615; batch adversarial loss: 0.530851\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409756; batch adversarial loss: 0.563093\n",
      "epoch 56; iter: 0; batch classifier loss: 0.476690; batch adversarial loss: 0.553914\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414118; batch adversarial loss: 0.599588\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419764; batch adversarial loss: 0.553245\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442247; batch adversarial loss: 0.562921\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352843; batch adversarial loss: 0.562674\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409975; batch adversarial loss: 0.524750\n",
      "epoch 62; iter: 0; batch classifier loss: 0.362482; batch adversarial loss: 0.469294\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444404; batch adversarial loss: 0.590835\n",
      "epoch 64; iter: 0; batch classifier loss: 0.452252; batch adversarial loss: 0.487565\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442753; batch adversarial loss: 0.481073\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366097; batch adversarial loss: 0.573299\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401952; batch adversarial loss: 0.507411\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378320; batch adversarial loss: 0.613493\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397807; batch adversarial loss: 0.525657\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416943; batch adversarial loss: 0.553232\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463850; batch adversarial loss: 0.526205\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462296; batch adversarial loss: 0.544380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.350946; batch adversarial loss: 0.535329\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437271; batch adversarial loss: 0.544277\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389628; batch adversarial loss: 0.516545\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398818; batch adversarial loss: 0.683134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.455496; batch adversarial loss: 0.572490\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350709; batch adversarial loss: 0.581760\n",
      "epoch 79; iter: 0; batch classifier loss: 0.443908; batch adversarial loss: 0.516445\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356922; batch adversarial loss: 0.516586\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397027; batch adversarial loss: 0.544313\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408225; batch adversarial loss: 0.563157\n",
      "epoch 83; iter: 0; batch classifier loss: 0.332699; batch adversarial loss: 0.516544\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375603; batch adversarial loss: 0.563471\n",
      "epoch 85; iter: 0; batch classifier loss: 0.457668; batch adversarial loss: 0.487752\n",
      "epoch 86; iter: 0; batch classifier loss: 0.447565; batch adversarial loss: 0.441268\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366479; batch adversarial loss: 0.506304\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411423; batch adversarial loss: 0.507182\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378750; batch adversarial loss: 0.573112\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365207; batch adversarial loss: 0.563251\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372571; batch adversarial loss: 0.591443\n",
      "epoch 92; iter: 0; batch classifier loss: 0.458752; batch adversarial loss: 0.477734\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353115; batch adversarial loss: 0.610494\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341898; batch adversarial loss: 0.611351\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415166; batch adversarial loss: 0.506310\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349257; batch adversarial loss: 0.534309\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370379; batch adversarial loss: 0.516675\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388487; batch adversarial loss: 0.478698\n",
      "epoch 99; iter: 0; batch classifier loss: 0.382020; batch adversarial loss: 0.572697\n",
      "epoch 100; iter: 0; batch classifier loss: 0.493522; batch adversarial loss: 0.516572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349953; batch adversarial loss: 0.497809\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386194; batch adversarial loss: 0.507071\n",
      "epoch 103; iter: 0; batch classifier loss: 0.441856; batch adversarial loss: 0.497571\n",
      "epoch 104; iter: 0; batch classifier loss: 0.441389; batch adversarial loss: 0.525477\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389220; batch adversarial loss: 0.591042\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382070; batch adversarial loss: 0.619099\n",
      "epoch 107; iter: 0; batch classifier loss: 0.489672; batch adversarial loss: 0.590832\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394123; batch adversarial loss: 0.460612\n",
      "epoch 109; iter: 0; batch classifier loss: 0.325865; batch adversarial loss: 0.534016\n",
      "epoch 110; iter: 0; batch classifier loss: 0.315355; batch adversarial loss: 0.496717\n",
      "epoch 111; iter: 0; batch classifier loss: 0.473003; batch adversarial loss: 0.609922\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391679; batch adversarial loss: 0.551986\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391005; batch adversarial loss: 0.553062\n",
      "epoch 114; iter: 0; batch classifier loss: 0.311193; batch adversarial loss: 0.581362\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363602; batch adversarial loss: 0.553659\n",
      "epoch 116; iter: 0; batch classifier loss: 0.340175; batch adversarial loss: 0.543451\n",
      "epoch 117; iter: 0; batch classifier loss: 0.336984; batch adversarial loss: 0.563305\n",
      "epoch 118; iter: 0; batch classifier loss: 0.440128; batch adversarial loss: 0.609305\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376543; batch adversarial loss: 0.609974\n",
      "epoch 120; iter: 0; batch classifier loss: 0.422642; batch adversarial loss: 0.555641\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358262; batch adversarial loss: 0.478112\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399500; batch adversarial loss: 0.524742\n",
      "epoch 123; iter: 0; batch classifier loss: 0.438111; batch adversarial loss: 0.610240\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379759; batch adversarial loss: 0.582089\n",
      "epoch 125; iter: 0; batch classifier loss: 0.429142; batch adversarial loss: 0.498155\n",
      "epoch 126; iter: 0; batch classifier loss: 0.418079; batch adversarial loss: 0.583050\n",
      "epoch 127; iter: 0; batch classifier loss: 0.320229; batch adversarial loss: 0.535299\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397591; batch adversarial loss: 0.439144\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378978; batch adversarial loss: 0.516097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.475504; batch adversarial loss: 0.431662\n",
      "epoch 131; iter: 0; batch classifier loss: 0.312885; batch adversarial loss: 0.600942\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384980; batch adversarial loss: 0.516355\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343649; batch adversarial loss: 0.610354\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368726; batch adversarial loss: 0.590795\n",
      "epoch 135; iter: 0; batch classifier loss: 0.488815; batch adversarial loss: 0.516320\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411112; batch adversarial loss: 0.657993\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366757; batch adversarial loss: 0.487845\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373435; batch adversarial loss: 0.571346\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415927; batch adversarial loss: 0.489998\n",
      "epoch 140; iter: 0; batch classifier loss: 0.304697; batch adversarial loss: 0.563597\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357136; batch adversarial loss: 0.564400\n",
      "epoch 142; iter: 0; batch classifier loss: 0.462019; batch adversarial loss: 0.462827\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334946; batch adversarial loss: 0.582580\n",
      "epoch 144; iter: 0; batch classifier loss: 0.443801; batch adversarial loss: 0.573492\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368624; batch adversarial loss: 0.582717\n",
      "epoch 146; iter: 0; batch classifier loss: 0.432353; batch adversarial loss: 0.609429\n",
      "epoch 147; iter: 0; batch classifier loss: 0.458165; batch adversarial loss: 0.515709\n",
      "epoch 148; iter: 0; batch classifier loss: 0.399817; batch adversarial loss: 0.571115\n",
      "epoch 149; iter: 0; batch classifier loss: 0.403598; batch adversarial loss: 0.592114\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347107; batch adversarial loss: 0.536328\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417578; batch adversarial loss: 0.536259\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351229; batch adversarial loss: 0.459702\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320679; batch adversarial loss: 0.572817\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402188; batch adversarial loss: 0.451051\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342488; batch adversarial loss: 0.562495\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372675; batch adversarial loss: 0.516857\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323701; batch adversarial loss: 0.516448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.348293; batch adversarial loss: 0.496975\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377928; batch adversarial loss: 0.553174\n",
      "epoch 160; iter: 0; batch classifier loss: 0.281793; batch adversarial loss: 0.497826\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362907; batch adversarial loss: 0.554163\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357623; batch adversarial loss: 0.621292\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355323; batch adversarial loss: 0.544914\n",
      "epoch 164; iter: 0; batch classifier loss: 0.286060; batch adversarial loss: 0.526055\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318243; batch adversarial loss: 0.507173\n",
      "epoch 166; iter: 0; batch classifier loss: 0.289848; batch adversarial loss: 0.496936\n",
      "epoch 167; iter: 0; batch classifier loss: 0.455653; batch adversarial loss: 0.506930\n",
      "epoch 168; iter: 0; batch classifier loss: 0.409367; batch adversarial loss: 0.469157\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350011; batch adversarial loss: 0.582014\n",
      "epoch 170; iter: 0; batch classifier loss: 0.458389; batch adversarial loss: 0.525195\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349131; batch adversarial loss: 0.506794\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334929; batch adversarial loss: 0.486874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.366765; batch adversarial loss: 0.441333\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351021; batch adversarial loss: 0.524688\n",
      "epoch 175; iter: 0; batch classifier loss: 0.271163; batch adversarial loss: 0.732027\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341886; batch adversarial loss: 0.581893\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406807; batch adversarial loss: 0.554072\n",
      "epoch 178; iter: 0; batch classifier loss: 0.401061; batch adversarial loss: 0.469111\n",
      "epoch 179; iter: 0; batch classifier loss: 0.291905; batch adversarial loss: 0.553869\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312304; batch adversarial loss: 0.534725\n",
      "epoch 181; iter: 0; batch classifier loss: 0.276432; batch adversarial loss: 0.488896\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365788; batch adversarial loss: 0.515891\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392486; batch adversarial loss: 0.582619\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385824; batch adversarial loss: 0.573526\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380389; batch adversarial loss: 0.470269\n",
      "epoch 186; iter: 0; batch classifier loss: 0.292170; batch adversarial loss: 0.620069\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385381; batch adversarial loss: 0.536028\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324030; batch adversarial loss: 0.572391\n",
      "epoch 189; iter: 0; batch classifier loss: 0.414018; batch adversarial loss: 0.563809\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364781; batch adversarial loss: 0.516017\n",
      "epoch 191; iter: 0; batch classifier loss: 0.407126; batch adversarial loss: 0.563283\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339881; batch adversarial loss: 0.590813\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388012; batch adversarial loss: 0.677155\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342485; batch adversarial loss: 0.572184\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322720; batch adversarial loss: 0.535524\n",
      "epoch 196; iter: 0; batch classifier loss: 0.364151; batch adversarial loss: 0.488620\n",
      "epoch 197; iter: 0; batch classifier loss: 0.337262; batch adversarial loss: 0.665816\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380366; batch adversarial loss: 0.442105\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345430; batch adversarial loss: 0.423534\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695251; batch adversarial loss: 0.736650\n",
      "epoch 1; iter: 0; batch classifier loss: 0.726588; batch adversarial loss: 0.800552\n",
      "epoch 2; iter: 0; batch classifier loss: 0.863537; batch adversarial loss: 0.756337\n",
      "epoch 3; iter: 0; batch classifier loss: 0.909020; batch adversarial loss: 0.696026\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640976; batch adversarial loss: 0.659749\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552815; batch adversarial loss: 0.629406\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514342; batch adversarial loss: 0.617731\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586539; batch adversarial loss: 0.624482\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517416; batch adversarial loss: 0.577635\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496974; batch adversarial loss: 0.600939\n",
      "epoch 10; iter: 0; batch classifier loss: 0.465668; batch adversarial loss: 0.596852\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537665; batch adversarial loss: 0.582867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501808; batch adversarial loss: 0.592021\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548039; batch adversarial loss: 0.566807\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500011; batch adversarial loss: 0.624837\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528326; batch adversarial loss: 0.580310\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507831; batch adversarial loss: 0.580716\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547772; batch adversarial loss: 0.548647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.436419; batch adversarial loss: 0.631028\n",
      "epoch 19; iter: 0; batch classifier loss: 0.544876; batch adversarial loss: 0.532967\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493997; batch adversarial loss: 0.574367\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474801; batch adversarial loss: 0.595379\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485380; batch adversarial loss: 0.540265\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443386; batch adversarial loss: 0.542557\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512175; batch adversarial loss: 0.511782\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466815; batch adversarial loss: 0.544140\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434408; batch adversarial loss: 0.631548\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468268; batch adversarial loss: 0.625035\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498201; batch adversarial loss: 0.641867\n",
      "epoch 29; iter: 0; batch classifier loss: 0.551668; batch adversarial loss: 0.502490\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439311; batch adversarial loss: 0.588572\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459322; batch adversarial loss: 0.517134\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451029; batch adversarial loss: 0.520393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444630; batch adversarial loss: 0.562293\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491545; batch adversarial loss: 0.530067\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487684; batch adversarial loss: 0.622609\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426964; batch adversarial loss: 0.595421\n",
      "epoch 37; iter: 0; batch classifier loss: 0.488492; batch adversarial loss: 0.545056\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420810; batch adversarial loss: 0.536960\n",
      "epoch 39; iter: 0; batch classifier loss: 0.402707; batch adversarial loss: 0.570179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418613; batch adversarial loss: 0.614545\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466335; batch adversarial loss: 0.526262\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480092; batch adversarial loss: 0.421003\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427431; batch adversarial loss: 0.505616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419423; batch adversarial loss: 0.606177\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445658; batch adversarial loss: 0.490366\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391397; batch adversarial loss: 0.548581\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366096; batch adversarial loss: 0.550550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.497358; batch adversarial loss: 0.578180\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399943; batch adversarial loss: 0.591374\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386132; batch adversarial loss: 0.528980\n",
      "epoch 51; iter: 0; batch classifier loss: 0.378705; batch adversarial loss: 0.528316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409625; batch adversarial loss: 0.561919\n",
      "epoch 53; iter: 0; batch classifier loss: 0.562018; batch adversarial loss: 0.501785\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440962; batch adversarial loss: 0.586396\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402838; batch adversarial loss: 0.537961\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419033; batch adversarial loss: 0.526034\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389960; batch adversarial loss: 0.460057\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423283; batch adversarial loss: 0.545492\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425766; batch adversarial loss: 0.593607\n",
      "epoch 60; iter: 0; batch classifier loss: 0.474415; batch adversarial loss: 0.559904\n",
      "epoch 61; iter: 0; batch classifier loss: 0.368165; batch adversarial loss: 0.545350\n",
      "epoch 62; iter: 0; batch classifier loss: 0.365193; batch adversarial loss: 0.543809\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400369; batch adversarial loss: 0.502186\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419649; batch adversarial loss: 0.536227\n",
      "epoch 65; iter: 0; batch classifier loss: 0.396380; batch adversarial loss: 0.571573\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382564; batch adversarial loss: 0.569698\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361716; batch adversarial loss: 0.564235\n",
      "epoch 68; iter: 0; batch classifier loss: 0.433006; batch adversarial loss: 0.464765\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409508; batch adversarial loss: 0.604038\n",
      "epoch 70; iter: 0; batch classifier loss: 0.338345; batch adversarial loss: 0.606815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.377815; batch adversarial loss: 0.579776\n",
      "epoch 72; iter: 0; batch classifier loss: 0.389438; batch adversarial loss: 0.507256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.347640; batch adversarial loss: 0.591440\n",
      "epoch 74; iter: 0; batch classifier loss: 0.352953; batch adversarial loss: 0.574729\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424900; batch adversarial loss: 0.528666\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375122; batch adversarial loss: 0.541136\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421527; batch adversarial loss: 0.527709\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389893; batch adversarial loss: 0.453016\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409890; batch adversarial loss: 0.552331\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420964; batch adversarial loss: 0.509223\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426016; batch adversarial loss: 0.550050\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420605; batch adversarial loss: 0.576284\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446217; batch adversarial loss: 0.530062\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413623; batch adversarial loss: 0.554054\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395043; batch adversarial loss: 0.551808\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380611; batch adversarial loss: 0.537134\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340992; batch adversarial loss: 0.561864\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429379; batch adversarial loss: 0.571227\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431924; batch adversarial loss: 0.543436\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375984; batch adversarial loss: 0.569552\n",
      "epoch 91; iter: 0; batch classifier loss: 0.332002; batch adversarial loss: 0.562372\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395786; batch adversarial loss: 0.536500\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352259; batch adversarial loss: 0.599115\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419785; batch adversarial loss: 0.519170\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378909; batch adversarial loss: 0.536224\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358492; batch adversarial loss: 0.568130\n",
      "epoch 97; iter: 0; batch classifier loss: 0.421832; batch adversarial loss: 0.561834\n",
      "epoch 98; iter: 0; batch classifier loss: 0.354861; batch adversarial loss: 0.531915\n",
      "epoch 99; iter: 0; batch classifier loss: 0.451179; batch adversarial loss: 0.529982\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364390; batch adversarial loss: 0.470301\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383602; batch adversarial loss: 0.561510\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363753; batch adversarial loss: 0.543988\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356567; batch adversarial loss: 0.549013\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390999; batch adversarial loss: 0.545510\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388225; batch adversarial loss: 0.573209\n",
      "epoch 106; iter: 0; batch classifier loss: 0.344874; batch adversarial loss: 0.591923\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362194; batch adversarial loss: 0.507427\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392915; batch adversarial loss: 0.588631\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351836; batch adversarial loss: 0.496375\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379293; batch adversarial loss: 0.603422\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365818; batch adversarial loss: 0.527295\n",
      "epoch 112; iter: 0; batch classifier loss: 0.320126; batch adversarial loss: 0.607956\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381318; batch adversarial loss: 0.643753\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386881; batch adversarial loss: 0.579516\n",
      "epoch 115; iter: 0; batch classifier loss: 0.358001; batch adversarial loss: 0.554744\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417807; batch adversarial loss: 0.536627\n",
      "epoch 117; iter: 0; batch classifier loss: 0.370919; batch adversarial loss: 0.554006\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354259; batch adversarial loss: 0.634302\n",
      "epoch 119; iter: 0; batch classifier loss: 0.302107; batch adversarial loss: 0.552632\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340870; batch adversarial loss: 0.571002\n",
      "epoch 121; iter: 0; batch classifier loss: 0.363132; batch adversarial loss: 0.607070\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358519; batch adversarial loss: 0.535311\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381546; batch adversarial loss: 0.528078\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336476; batch adversarial loss: 0.546382\n",
      "epoch 125; iter: 0; batch classifier loss: 0.301862; batch adversarial loss: 0.526927\n",
      "epoch 126; iter: 0; batch classifier loss: 0.328578; batch adversarial loss: 0.555118\n",
      "epoch 127; iter: 0; batch classifier loss: 0.284655; batch adversarial loss: 0.589637\n",
      "epoch 128; iter: 0; batch classifier loss: 0.427600; batch adversarial loss: 0.489263\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413142; batch adversarial loss: 0.529659\n",
      "epoch 130; iter: 0; batch classifier loss: 0.433837; batch adversarial loss: 0.501539\n",
      "epoch 131; iter: 0; batch classifier loss: 0.399033; batch adversarial loss: 0.540989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.304621; batch adversarial loss: 0.535535\n",
      "epoch 133; iter: 0; batch classifier loss: 0.434849; batch adversarial loss: 0.546899\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383290; batch adversarial loss: 0.526431\n",
      "epoch 135; iter: 0; batch classifier loss: 0.440311; batch adversarial loss: 0.561985\n",
      "epoch 136; iter: 0; batch classifier loss: 0.445761; batch adversarial loss: 0.616658\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384766; batch adversarial loss: 0.569042\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350409; batch adversarial loss: 0.589243\n",
      "epoch 139; iter: 0; batch classifier loss: 0.391302; batch adversarial loss: 0.510271\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346478; batch adversarial loss: 0.508009\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345393; batch adversarial loss: 0.607352\n",
      "epoch 142; iter: 0; batch classifier loss: 0.353543; batch adversarial loss: 0.604484\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346848; batch adversarial loss: 0.501205\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292800; batch adversarial loss: 0.554929\n",
      "epoch 145; iter: 0; batch classifier loss: 0.378173; batch adversarial loss: 0.570822\n",
      "epoch 146; iter: 0; batch classifier loss: 0.311519; batch adversarial loss: 0.554629\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350894; batch adversarial loss: 0.480267\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349651; batch adversarial loss: 0.571605\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377782; batch adversarial loss: 0.525103\n",
      "epoch 150; iter: 0; batch classifier loss: 0.306980; batch adversarial loss: 0.603001\n",
      "epoch 151; iter: 0; batch classifier loss: 0.307786; batch adversarial loss: 0.463221\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391427; batch adversarial loss: 0.641532\n",
      "epoch 153; iter: 0; batch classifier loss: 0.341064; batch adversarial loss: 0.598177\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395532; batch adversarial loss: 0.543409\n",
      "epoch 155; iter: 0; batch classifier loss: 0.438101; batch adversarial loss: 0.562892\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332695; batch adversarial loss: 0.504134\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405498; batch adversarial loss: 0.516016\n",
      "epoch 158; iter: 0; batch classifier loss: 0.292735; batch adversarial loss: 0.592178\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370461; batch adversarial loss: 0.476396\n",
      "epoch 160; iter: 0; batch classifier loss: 0.264899; batch adversarial loss: 0.531719\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374749; batch adversarial loss: 0.539561\n",
      "epoch 162; iter: 0; batch classifier loss: 0.391949; batch adversarial loss: 0.533998\n",
      "epoch 163; iter: 0; batch classifier loss: 0.420319; batch adversarial loss: 0.555054\n",
      "epoch 164; iter: 0; batch classifier loss: 0.298808; batch adversarial loss: 0.518427\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340308; batch adversarial loss: 0.546451\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374465; batch adversarial loss: 0.571472\n",
      "epoch 167; iter: 0; batch classifier loss: 0.308693; batch adversarial loss: 0.517715\n",
      "epoch 168; iter: 0; batch classifier loss: 0.407187; batch adversarial loss: 0.598558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 169; iter: 0; batch classifier loss: 0.292688; batch adversarial loss: 0.625050\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299874; batch adversarial loss: 0.539219\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333647; batch adversarial loss: 0.509723\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354459; batch adversarial loss: 0.546572\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334036; batch adversarial loss: 0.536327\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326536; batch adversarial loss: 0.554787\n",
      "epoch 175; iter: 0; batch classifier loss: 0.361612; batch adversarial loss: 0.562340\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358561; batch adversarial loss: 0.511101\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387101; batch adversarial loss: 0.525526\n",
      "epoch 178; iter: 0; batch classifier loss: 0.313073; batch adversarial loss: 0.489881\n",
      "epoch 179; iter: 0; batch classifier loss: 0.400476; batch adversarial loss: 0.517444\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338248; batch adversarial loss: 0.534106\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348972; batch adversarial loss: 0.609430\n",
      "epoch 182; iter: 0; batch classifier loss: 0.285613; batch adversarial loss: 0.580285\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366407; batch adversarial loss: 0.516244\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366799; batch adversarial loss: 0.505898\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384551; batch adversarial loss: 0.607117\n",
      "epoch 186; iter: 0; batch classifier loss: 0.286816; batch adversarial loss: 0.563530\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356679; batch adversarial loss: 0.536995\n",
      "epoch 188; iter: 0; batch classifier loss: 0.266680; batch adversarial loss: 0.543324\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358855; batch adversarial loss: 0.534388\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379286; batch adversarial loss: 0.544523\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359650; batch adversarial loss: 0.592717\n",
      "epoch 192; iter: 0; batch classifier loss: 0.306178; batch adversarial loss: 0.501042\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342179; batch adversarial loss: 0.592401\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338194; batch adversarial loss: 0.571209\n",
      "epoch 195; iter: 0; batch classifier loss: 0.348288; batch adversarial loss: 0.621460\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331032; batch adversarial loss: 0.484804\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342607; batch adversarial loss: 0.563538\n",
      "epoch 198; iter: 0; batch classifier loss: 0.388978; batch adversarial loss: 0.565617\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366424; batch adversarial loss: 0.472577\n",
      "epoch 0; iter: 0; batch classifier loss: 0.767144; batch adversarial loss: 1.135770\n",
      "epoch 1; iter: 0; batch classifier loss: 0.878293; batch adversarial loss: 1.173920\n",
      "epoch 2; iter: 0; batch classifier loss: 0.929786; batch adversarial loss: 1.106722\n",
      "epoch 3; iter: 0; batch classifier loss: 1.026086; batch adversarial loss: 1.054087\n",
      "epoch 4; iter: 0; batch classifier loss: 1.013702; batch adversarial loss: 0.980915\n",
      "epoch 5; iter: 0; batch classifier loss: 0.812713; batch adversarial loss: 0.937402\n",
      "epoch 6; iter: 0; batch classifier loss: 0.802136; batch adversarial loss: 0.833802\n",
      "epoch 7; iter: 0; batch classifier loss: 0.713314; batch adversarial loss: 0.766881\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581929; batch adversarial loss: 0.715246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.637546; batch adversarial loss: 0.651309\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540898; batch adversarial loss: 0.640970\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522988; batch adversarial loss: 0.635052\n",
      "epoch 12; iter: 0; batch classifier loss: 0.634583; batch adversarial loss: 0.585311\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524137; batch adversarial loss: 0.562499\n",
      "epoch 14; iter: 0; batch classifier loss: 0.619074; batch adversarial loss: 0.662874\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496464; batch adversarial loss: 0.591991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531460; batch adversarial loss: 0.587828\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547175; batch adversarial loss: 0.586265\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514406; batch adversarial loss: 0.564932\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524908; batch adversarial loss: 0.545011\n",
      "epoch 20; iter: 0; batch classifier loss: 0.560917; batch adversarial loss: 0.602099\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372736; batch adversarial loss: 0.569101\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484213; batch adversarial loss: 0.607597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.574140; batch adversarial loss: 0.565430\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519158; batch adversarial loss: 0.589412\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506891; batch adversarial loss: 0.584764\n",
      "epoch 26; iter: 0; batch classifier loss: 0.522379; batch adversarial loss: 0.592976\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487706; batch adversarial loss: 0.605739\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491815; batch adversarial loss: 0.567804\n",
      "epoch 29; iter: 0; batch classifier loss: 0.543314; batch adversarial loss: 0.529266\n",
      "epoch 30; iter: 0; batch classifier loss: 0.521562; batch adversarial loss: 0.563069\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483471; batch adversarial loss: 0.522902\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502945; batch adversarial loss: 0.604318\n",
      "epoch 33; iter: 0; batch classifier loss: 0.436796; batch adversarial loss: 0.602614\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449387; batch adversarial loss: 0.589998\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496699; batch adversarial loss: 0.576416\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460751; batch adversarial loss: 0.530529\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441492; batch adversarial loss: 0.569654\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478737; batch adversarial loss: 0.558565\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482152; batch adversarial loss: 0.612547\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460581; batch adversarial loss: 0.509303\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493881; batch adversarial loss: 0.606299\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467304; batch adversarial loss: 0.552089\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431945; batch adversarial loss: 0.489226\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382107; batch adversarial loss: 0.568768\n",
      "epoch 45; iter: 0; batch classifier loss: 0.488291; batch adversarial loss: 0.481226\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462912; batch adversarial loss: 0.577845\n",
      "epoch 47; iter: 0; batch classifier loss: 0.345977; batch adversarial loss: 0.531956\n",
      "epoch 48; iter: 0; batch classifier loss: 0.510773; batch adversarial loss: 0.576202\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371351; batch adversarial loss: 0.543671\n",
      "epoch 50; iter: 0; batch classifier loss: 0.484492; batch adversarial loss: 0.581300\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418738; batch adversarial loss: 0.544244\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431888; batch adversarial loss: 0.581092\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468334; batch adversarial loss: 0.455877\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450099; batch adversarial loss: 0.569595\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444817; batch adversarial loss: 0.544940\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443515; batch adversarial loss: 0.598619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391221; batch adversarial loss: 0.544068\n",
      "epoch 58; iter: 0; batch classifier loss: 0.376341; batch adversarial loss: 0.499068\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441448; batch adversarial loss: 0.518001\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473038; batch adversarial loss: 0.460498\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463053; batch adversarial loss: 0.506396\n",
      "epoch 62; iter: 0; batch classifier loss: 0.312544; batch adversarial loss: 0.481075\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402277; batch adversarial loss: 0.552508\n",
      "epoch 64; iter: 0; batch classifier loss: 0.490004; batch adversarial loss: 0.573728\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451740; batch adversarial loss: 0.460393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.416912; batch adversarial loss: 0.575913\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361202; batch adversarial loss: 0.499692\n",
      "epoch 68; iter: 0; batch classifier loss: 0.454002; batch adversarial loss: 0.555455\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426100; batch adversarial loss: 0.579333\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476182; batch adversarial loss: 0.554619\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425686; batch adversarial loss: 0.609798\n",
      "epoch 72; iter: 0; batch classifier loss: 0.323834; batch adversarial loss: 0.487082\n",
      "epoch 73; iter: 0; batch classifier loss: 0.414226; batch adversarial loss: 0.565527\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356951; batch adversarial loss: 0.499466\n",
      "epoch 75; iter: 0; batch classifier loss: 0.464203; batch adversarial loss: 0.491326\n",
      "epoch 76; iter: 0; batch classifier loss: 0.402844; batch adversarial loss: 0.565885\n",
      "epoch 77; iter: 0; batch classifier loss: 0.267554; batch adversarial loss: 0.554556\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415957; batch adversarial loss: 0.461378\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429652; batch adversarial loss: 0.591776\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412617; batch adversarial loss: 0.571219\n",
      "epoch 81; iter: 0; batch classifier loss: 0.469544; batch adversarial loss: 0.561089\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398751; batch adversarial loss: 0.609740\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415091; batch adversarial loss: 0.563216\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435216; batch adversarial loss: 0.452888\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428761; batch adversarial loss: 0.599322\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373446; batch adversarial loss: 0.541281\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392409; batch adversarial loss: 0.486967\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429177; batch adversarial loss: 0.515037\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365038; batch adversarial loss: 0.517304\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383849; batch adversarial loss: 0.524328\n",
      "epoch 91; iter: 0; batch classifier loss: 0.431643; batch adversarial loss: 0.561853\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393938; batch adversarial loss: 0.537268\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422712; batch adversarial loss: 0.527094\n",
      "epoch 94; iter: 0; batch classifier loss: 0.397138; batch adversarial loss: 0.488941\n",
      "epoch 95; iter: 0; batch classifier loss: 0.313547; batch adversarial loss: 0.569898\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374556; batch adversarial loss: 0.498944\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370853; batch adversarial loss: 0.479315\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365187; batch adversarial loss: 0.552926\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393654; batch adversarial loss: 0.627658\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415401; batch adversarial loss: 0.506741\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398886; batch adversarial loss: 0.526045\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409195; batch adversarial loss: 0.552066\n",
      "epoch 103; iter: 0; batch classifier loss: 0.371415; batch adversarial loss: 0.571142\n",
      "epoch 104; iter: 0; batch classifier loss: 0.320508; batch adversarial loss: 0.515993\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361748; batch adversarial loss: 0.483002\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326892; batch adversarial loss: 0.508668\n",
      "epoch 107; iter: 0; batch classifier loss: 0.432495; batch adversarial loss: 0.527201\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334440; batch adversarial loss: 0.516335\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376146; batch adversarial loss: 0.541486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357189; batch adversarial loss: 0.534358\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380099; batch adversarial loss: 0.537019\n",
      "epoch 112; iter: 0; batch classifier loss: 0.332210; batch adversarial loss: 0.542492\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407582; batch adversarial loss: 0.523995\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348722; batch adversarial loss: 0.561698\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406672; batch adversarial loss: 0.585284\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325514; batch adversarial loss: 0.485213\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388223; batch adversarial loss: 0.608519\n",
      "epoch 118; iter: 0; batch classifier loss: 0.471939; batch adversarial loss: 0.560109\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381224; batch adversarial loss: 0.490180\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388337; batch adversarial loss: 0.498000\n",
      "epoch 121; iter: 0; batch classifier loss: 0.292212; batch adversarial loss: 0.549798\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346239; batch adversarial loss: 0.612383\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351153; batch adversarial loss: 0.494433\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370605; batch adversarial loss: 0.495852\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384947; batch adversarial loss: 0.527969\n",
      "epoch 126; iter: 0; batch classifier loss: 0.417303; batch adversarial loss: 0.560045\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347905; batch adversarial loss: 0.514362\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381131; batch adversarial loss: 0.508065\n",
      "epoch 129; iter: 0; batch classifier loss: 0.336935; batch adversarial loss: 0.573346\n",
      "epoch 130; iter: 0; batch classifier loss: 0.335676; batch adversarial loss: 0.601183\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339337; batch adversarial loss: 0.578858\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371520; batch adversarial loss: 0.444399\n",
      "epoch 133; iter: 0; batch classifier loss: 0.444468; batch adversarial loss: 0.583275\n",
      "epoch 134; iter: 0; batch classifier loss: 0.360833; batch adversarial loss: 0.492019\n",
      "epoch 135; iter: 0; batch classifier loss: 0.326669; batch adversarial loss: 0.605232\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336623; batch adversarial loss: 0.527059\n",
      "epoch 137; iter: 0; batch classifier loss: 0.363161; batch adversarial loss: 0.607972\n",
      "epoch 138; iter: 0; batch classifier loss: 0.339311; batch adversarial loss: 0.507478\n",
      "epoch 139; iter: 0; batch classifier loss: 0.354488; batch adversarial loss: 0.562985\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368628; batch adversarial loss: 0.574280\n",
      "epoch 141; iter: 0; batch classifier loss: 0.429879; batch adversarial loss: 0.596909\n",
      "epoch 142; iter: 0; batch classifier loss: 0.323904; batch adversarial loss: 0.574202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.410124; batch adversarial loss: 0.397418\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362040; batch adversarial loss: 0.577055\n",
      "epoch 145; iter: 0; batch classifier loss: 0.392832; batch adversarial loss: 0.547296\n",
      "epoch 146; iter: 0; batch classifier loss: 0.397641; batch adversarial loss: 0.528911\n",
      "epoch 147; iter: 0; batch classifier loss: 0.293516; batch adversarial loss: 0.610179\n",
      "epoch 148; iter: 0; batch classifier loss: 0.306026; batch adversarial loss: 0.556461\n",
      "epoch 149; iter: 0; batch classifier loss: 0.303370; batch adversarial loss: 0.605276\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358170; batch adversarial loss: 0.494112\n",
      "epoch 151; iter: 0; batch classifier loss: 0.412302; batch adversarial loss: 0.495838\n",
      "epoch 152; iter: 0; batch classifier loss: 0.392726; batch adversarial loss: 0.554243\n",
      "epoch 153; iter: 0; batch classifier loss: 0.306039; batch adversarial loss: 0.581037\n",
      "epoch 154; iter: 0; batch classifier loss: 0.485194; batch adversarial loss: 0.478448\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342232; batch adversarial loss: 0.527626\n",
      "epoch 156; iter: 0; batch classifier loss: 0.324658; batch adversarial loss: 0.564526\n",
      "epoch 157; iter: 0; batch classifier loss: 0.407676; batch adversarial loss: 0.580827\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390796; batch adversarial loss: 0.586110\n",
      "epoch 159; iter: 0; batch classifier loss: 0.293891; batch adversarial loss: 0.563139\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349527; batch adversarial loss: 0.516271\n",
      "epoch 161; iter: 0; batch classifier loss: 0.250328; batch adversarial loss: 0.580684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.377870; batch adversarial loss: 0.550513\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339411; batch adversarial loss: 0.514798\n",
      "epoch 164; iter: 0; batch classifier loss: 0.298502; batch adversarial loss: 0.553006\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397732; batch adversarial loss: 0.551524\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355491; batch adversarial loss: 0.473926\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342055; batch adversarial loss: 0.513653\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375321; batch adversarial loss: 0.572091\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333041; batch adversarial loss: 0.550130\n",
      "epoch 170; iter: 0; batch classifier loss: 0.267699; batch adversarial loss: 0.554771\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320919; batch adversarial loss: 0.570109\n",
      "epoch 172; iter: 0; batch classifier loss: 0.382499; batch adversarial loss: 0.561546\n",
      "epoch 173; iter: 0; batch classifier loss: 0.332125; batch adversarial loss: 0.502091\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340427; batch adversarial loss: 0.497724\n",
      "epoch 175; iter: 0; batch classifier loss: 0.299781; batch adversarial loss: 0.569654\n",
      "epoch 176; iter: 0; batch classifier loss: 0.309148; batch adversarial loss: 0.558542\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366763; batch adversarial loss: 0.600803\n",
      "epoch 178; iter: 0; batch classifier loss: 0.375673; batch adversarial loss: 0.520603\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339215; batch adversarial loss: 0.556220\n",
      "epoch 180; iter: 0; batch classifier loss: 0.377922; batch adversarial loss: 0.551349\n",
      "epoch 181; iter: 0; batch classifier loss: 0.373373; batch adversarial loss: 0.495185\n",
      "epoch 182; iter: 0; batch classifier loss: 0.418905; batch adversarial loss: 0.613994\n",
      "epoch 183; iter: 0; batch classifier loss: 0.334764; batch adversarial loss: 0.536439\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294580; batch adversarial loss: 0.527317\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397551; batch adversarial loss: 0.562232\n",
      "epoch 186; iter: 0; batch classifier loss: 0.256393; batch adversarial loss: 0.547954\n",
      "epoch 187; iter: 0; batch classifier loss: 0.399377; batch adversarial loss: 0.545793\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382945; batch adversarial loss: 0.534925\n",
      "epoch 189; iter: 0; batch classifier loss: 0.421623; batch adversarial loss: 0.461510\n",
      "epoch 190; iter: 0; batch classifier loss: 0.408564; batch adversarial loss: 0.561948\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367245; batch adversarial loss: 0.515343\n",
      "epoch 192; iter: 0; batch classifier loss: 0.269526; batch adversarial loss: 0.597703\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284688; batch adversarial loss: 0.461253\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351492; batch adversarial loss: 0.525355\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363460; batch adversarial loss: 0.514686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358780; batch adversarial loss: 0.597651\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370644; batch adversarial loss: 0.474268\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339197; batch adversarial loss: 0.490888\n",
      "epoch 199; iter: 0; batch classifier loss: 0.253538; batch adversarial loss: 0.563885\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725450; batch adversarial loss: 0.654921\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647112; batch adversarial loss: 0.611351\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565788; batch adversarial loss: 0.671534\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558532; batch adversarial loss: 0.582343\n",
      "epoch 4; iter: 0; batch classifier loss: 0.641359; batch adversarial loss: 0.642433\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549828; batch adversarial loss: 0.615901\n",
      "epoch 6; iter: 0; batch classifier loss: 0.481529; batch adversarial loss: 0.577840\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511554; batch adversarial loss: 0.676404\n",
      "epoch 8; iter: 0; batch classifier loss: 0.540001; batch adversarial loss: 0.587123\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523936; batch adversarial loss: 0.581858\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541757; batch adversarial loss: 0.613637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539663; batch adversarial loss: 0.585383\n",
      "epoch 12; iter: 0; batch classifier loss: 0.600145; batch adversarial loss: 0.577133\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554791; batch adversarial loss: 0.574703\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516191; batch adversarial loss: 0.534157\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480511; batch adversarial loss: 0.553388\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525924; batch adversarial loss: 0.562959\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522050; batch adversarial loss: 0.650098\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531998; batch adversarial loss: 0.545978\n",
      "epoch 19; iter: 0; batch classifier loss: 0.613562; batch adversarial loss: 0.537392\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507358; batch adversarial loss: 0.622438\n",
      "epoch 21; iter: 0; batch classifier loss: 0.549192; batch adversarial loss: 0.603484\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506693; batch adversarial loss: 0.564440\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487148; batch adversarial loss: 0.597691\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471143; batch adversarial loss: 0.562432\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528155; batch adversarial loss: 0.571635\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439383; batch adversarial loss: 0.544466\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481009; batch adversarial loss: 0.566180\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510854; batch adversarial loss: 0.538713\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494574; batch adversarial loss: 0.538711\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455734; batch adversarial loss: 0.561870\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443600; batch adversarial loss: 0.529399\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517490; batch adversarial loss: 0.527885\n",
      "epoch 33; iter: 0; batch classifier loss: 0.542259; batch adversarial loss: 0.561938\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477722; batch adversarial loss: 0.579296\n",
      "epoch 35; iter: 0; batch classifier loss: 0.565508; batch adversarial loss: 0.562288\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428336; batch adversarial loss: 0.570771\n",
      "epoch 37; iter: 0; batch classifier loss: 0.522155; batch adversarial loss: 0.475651\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432799; batch adversarial loss: 0.605698\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464600; batch adversarial loss: 0.561511\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430671; batch adversarial loss: 0.544323\n",
      "epoch 41; iter: 0; batch classifier loss: 0.496225; batch adversarial loss: 0.526920\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391385; batch adversarial loss: 0.570619\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431977; batch adversarial loss: 0.536238\n",
      "epoch 44; iter: 0; batch classifier loss: 0.506672; batch adversarial loss: 0.543841\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415622; batch adversarial loss: 0.588429\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383627; batch adversarial loss: 0.519468\n",
      "epoch 47; iter: 0; batch classifier loss: 0.557312; batch adversarial loss: 0.597594\n",
      "epoch 48; iter: 0; batch classifier loss: 0.525641; batch adversarial loss: 0.633332\n",
      "epoch 49; iter: 0; batch classifier loss: 0.524540; batch adversarial loss: 0.508332\n",
      "epoch 50; iter: 0; batch classifier loss: 0.508346; batch adversarial loss: 0.580624\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471165; batch adversarial loss: 0.543955\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406195; batch adversarial loss: 0.517897\n",
      "epoch 53; iter: 0; batch classifier loss: 0.435597; batch adversarial loss: 0.544071\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446610; batch adversarial loss: 0.544062\n",
      "epoch 55; iter: 0; batch classifier loss: 0.457377; batch adversarial loss: 0.597363\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413682; batch adversarial loss: 0.621767\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440600; batch adversarial loss: 0.616033\n",
      "epoch 58; iter: 0; batch classifier loss: 0.493113; batch adversarial loss: 0.590173\n",
      "epoch 59; iter: 0; batch classifier loss: 0.402134; batch adversarial loss: 0.642174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.450350; batch adversarial loss: 0.527692\n",
      "epoch 61; iter: 0; batch classifier loss: 0.481853; batch adversarial loss: 0.538765\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426476; batch adversarial loss: 0.596730\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392111; batch adversarial loss: 0.562832\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434387; batch adversarial loss: 0.572933\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435717; batch adversarial loss: 0.508377\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419632; batch adversarial loss: 0.607237\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418407; batch adversarial loss: 0.552558\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419811; batch adversarial loss: 0.536321\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439233; batch adversarial loss: 0.570462\n",
      "epoch 70; iter: 0; batch classifier loss: 0.529408; batch adversarial loss: 0.515225\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404659; batch adversarial loss: 0.518146\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448968; batch adversarial loss: 0.570495\n",
      "epoch 73; iter: 0; batch classifier loss: 0.345951; batch adversarial loss: 0.536200\n",
      "epoch 74; iter: 0; batch classifier loss: 0.425966; batch adversarial loss: 0.482909\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436038; batch adversarial loss: 0.660644\n",
      "epoch 76; iter: 0; batch classifier loss: 0.356418; batch adversarial loss: 0.517830\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374852; batch adversarial loss: 0.562532\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405612; batch adversarial loss: 0.579133\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378369; batch adversarial loss: 0.578747\n",
      "epoch 80; iter: 0; batch classifier loss: 0.452584; batch adversarial loss: 0.535558\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395710; batch adversarial loss: 0.535689\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386613; batch adversarial loss: 0.580127\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375074; batch adversarial loss: 0.536790\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453653; batch adversarial loss: 0.528130\n",
      "epoch 85; iter: 0; batch classifier loss: 0.486966; batch adversarial loss: 0.577876\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391217; batch adversarial loss: 0.570136\n",
      "epoch 87; iter: 0; batch classifier loss: 0.442912; batch adversarial loss: 0.623064\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376667; batch adversarial loss: 0.562558\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395901; batch adversarial loss: 0.562719\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443409; batch adversarial loss: 0.605115\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417338; batch adversarial loss: 0.535563\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441118; batch adversarial loss: 0.564124\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356094; batch adversarial loss: 0.500809\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348388; batch adversarial loss: 0.553418\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428374; batch adversarial loss: 0.597905\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395178; batch adversarial loss: 0.553488\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.588077\n",
      "epoch 98; iter: 0; batch classifier loss: 0.458662; batch adversarial loss: 0.535923\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424966; batch adversarial loss: 0.518442\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431102; batch adversarial loss: 0.580850\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403961; batch adversarial loss: 0.502262\n",
      "epoch 102; iter: 0; batch classifier loss: 0.452181; batch adversarial loss: 0.510246\n",
      "epoch 103; iter: 0; batch classifier loss: 0.319472; batch adversarial loss: 0.586193\n",
      "epoch 104; iter: 0; batch classifier loss: 0.405082; batch adversarial loss: 0.509523\n",
      "epoch 105; iter: 0; batch classifier loss: 0.349947; batch adversarial loss: 0.563560\n",
      "epoch 106; iter: 0; batch classifier loss: 0.458674; batch adversarial loss: 0.518084\n",
      "epoch 107; iter: 0; batch classifier loss: 0.445071; batch adversarial loss: 0.597662\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390858; batch adversarial loss: 0.616915\n",
      "epoch 109; iter: 0; batch classifier loss: 0.324578; batch adversarial loss: 0.518041\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401552; batch adversarial loss: 0.590573\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412468; batch adversarial loss: 0.586247\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364840; batch adversarial loss: 0.473621\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417132; batch adversarial loss: 0.589229\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397077; batch adversarial loss: 0.553576\n",
      "epoch 115; iter: 0; batch classifier loss: 0.426631; batch adversarial loss: 0.545541\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385903; batch adversarial loss: 0.616348\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386297; batch adversarial loss: 0.544678\n",
      "epoch 118; iter: 0; batch classifier loss: 0.437607; batch adversarial loss: 0.570617\n",
      "epoch 119; iter: 0; batch classifier loss: 0.522446; batch adversarial loss: 0.526675\n",
      "epoch 120; iter: 0; batch classifier loss: 0.318015; batch adversarial loss: 0.524897\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339702; batch adversarial loss: 0.536421\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377762; batch adversarial loss: 0.553638\n",
      "epoch 123; iter: 0; batch classifier loss: 0.454455; batch adversarial loss: 0.580054\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345068; batch adversarial loss: 0.544112\n",
      "epoch 125; iter: 0; batch classifier loss: 0.364731; batch adversarial loss: 0.572238\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384689; batch adversarial loss: 0.543194\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387324; batch adversarial loss: 0.617360\n",
      "epoch 128; iter: 0; batch classifier loss: 0.438727; batch adversarial loss: 0.553812\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343870; batch adversarial loss: 0.555592\n",
      "epoch 130; iter: 0; batch classifier loss: 0.416722; batch adversarial loss: 0.517336\n",
      "epoch 131; iter: 0; batch classifier loss: 0.393986; batch adversarial loss: 0.569797\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325232; batch adversarial loss: 0.588699\n",
      "epoch 133; iter: 0; batch classifier loss: 0.451953; batch adversarial loss: 0.555025\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363469; batch adversarial loss: 0.570567\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394085; batch adversarial loss: 0.534967\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406214; batch adversarial loss: 0.544037\n",
      "epoch 137; iter: 0; batch classifier loss: 0.388195; batch adversarial loss: 0.598797\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380105; batch adversarial loss: 0.457058\n",
      "epoch 139; iter: 0; batch classifier loss: 0.385446; batch adversarial loss: 0.578787\n",
      "epoch 140; iter: 0; batch classifier loss: 0.456377; batch adversarial loss: 0.703976\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379036; batch adversarial loss: 0.586841\n",
      "epoch 142; iter: 0; batch classifier loss: 0.342988; batch adversarial loss: 0.518774\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391023; batch adversarial loss: 0.552522\n",
      "epoch 144; iter: 0; batch classifier loss: 0.335098; batch adversarial loss: 0.553517\n",
      "epoch 145; iter: 0; batch classifier loss: 0.417252; batch adversarial loss: 0.606919\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368909; batch adversarial loss: 0.509619\n",
      "epoch 147; iter: 0; batch classifier loss: 0.420311; batch adversarial loss: 0.537726\n",
      "epoch 148; iter: 0; batch classifier loss: 0.377362; batch adversarial loss: 0.492372\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377109; batch adversarial loss: 0.499160\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370914; batch adversarial loss: 0.570708\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385580; batch adversarial loss: 0.641578\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359721; batch adversarial loss: 0.588595\n",
      "epoch 153; iter: 0; batch classifier loss: 0.406881; batch adversarial loss: 0.579943\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374037; batch adversarial loss: 0.563626\n",
      "epoch 155; iter: 0; batch classifier loss: 0.475881; batch adversarial loss: 0.545787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.337164; batch adversarial loss: 0.588529\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344936; batch adversarial loss: 0.599611\n",
      "epoch 158; iter: 0; batch classifier loss: 0.334749; batch adversarial loss: 0.518073\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394452; batch adversarial loss: 0.446362\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350405; batch adversarial loss: 0.455634\n",
      "epoch 161; iter: 0; batch classifier loss: 0.419377; batch adversarial loss: 0.527117\n",
      "epoch 162; iter: 0; batch classifier loss: 0.437193; batch adversarial loss: 0.473009\n",
      "epoch 163; iter: 0; batch classifier loss: 0.414738; batch adversarial loss: 0.561719\n",
      "epoch 164; iter: 0; batch classifier loss: 0.357118; batch adversarial loss: 0.581020\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330212; batch adversarial loss: 0.587803\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317983; batch adversarial loss: 0.534901\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384823; batch adversarial loss: 0.545199\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366821; batch adversarial loss: 0.597957\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322455; batch adversarial loss: 0.614550\n",
      "epoch 170; iter: 0; batch classifier loss: 0.436185; batch adversarial loss: 0.500447\n",
      "epoch 171; iter: 0; batch classifier loss: 0.319071; batch adversarial loss: 0.581371\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344986; batch adversarial loss: 0.578987\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401788; batch adversarial loss: 0.493166\n",
      "epoch 174; iter: 0; batch classifier loss: 0.308537; batch adversarial loss: 0.579631\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339476; batch adversarial loss: 0.518041\n",
      "epoch 176; iter: 0; batch classifier loss: 0.399294; batch adversarial loss: 0.525649\n",
      "epoch 177; iter: 0; batch classifier loss: 0.350929; batch adversarial loss: 0.510057\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331438; batch adversarial loss: 0.534335\n",
      "epoch 179; iter: 0; batch classifier loss: 0.393349; batch adversarial loss: 0.577961\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316073; batch adversarial loss: 0.527609\n",
      "epoch 181; iter: 0; batch classifier loss: 0.393302; batch adversarial loss: 0.519970\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408229; batch adversarial loss: 0.596092\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381706; batch adversarial loss: 0.649877\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339450; batch adversarial loss: 0.615106\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358247; batch adversarial loss: 0.590850\n",
      "epoch 186; iter: 0; batch classifier loss: 0.307056; batch adversarial loss: 0.561466\n",
      "epoch 187; iter: 0; batch classifier loss: 0.433672; batch adversarial loss: 0.588166\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343198; batch adversarial loss: 0.544147\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383475; batch adversarial loss: 0.517899\n",
      "epoch 190; iter: 0; batch classifier loss: 0.304188; batch adversarial loss: 0.554677\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335361; batch adversarial loss: 0.518979\n",
      "epoch 192; iter: 0; batch classifier loss: 0.331361; batch adversarial loss: 0.473611\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373064; batch adversarial loss: 0.657448\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318371; batch adversarial loss: 0.554281\n",
      "epoch 195; iter: 0; batch classifier loss: 0.385673; batch adversarial loss: 0.552804\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398291; batch adversarial loss: 0.465258\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377842; batch adversarial loss: 0.511943\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380547; batch adversarial loss: 0.474583\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384030; batch adversarial loss: 0.581233\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686898; batch adversarial loss: 0.606534\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632777; batch adversarial loss: 0.655065\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583453; batch adversarial loss: 0.678747\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511907; batch adversarial loss: 0.612564\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558977; batch adversarial loss: 0.617927\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607524; batch adversarial loss: 0.641274\n",
      "epoch 6; iter: 0; batch classifier loss: 0.576050; batch adversarial loss: 0.652369\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517001; batch adversarial loss: 0.594916\n",
      "epoch 8; iter: 0; batch classifier loss: 0.488761; batch adversarial loss: 0.585858\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508358; batch adversarial loss: 0.571010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531303; batch adversarial loss: 0.610472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521623; batch adversarial loss: 0.560309\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550700; batch adversarial loss: 0.570540\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519150; batch adversarial loss: 0.600399\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473589; batch adversarial loss: 0.537373\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483684; batch adversarial loss: 0.614630\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481662; batch adversarial loss: 0.550908\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521259; batch adversarial loss: 0.539573\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460202; batch adversarial loss: 0.557427\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581522; batch adversarial loss: 0.570927\n",
      "epoch 20; iter: 0; batch classifier loss: 0.568903; batch adversarial loss: 0.635474\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482245; batch adversarial loss: 0.557053\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456361; batch adversarial loss: 0.652282\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462442; batch adversarial loss: 0.533880\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547206; batch adversarial loss: 0.453833\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506678; batch adversarial loss: 0.579181\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439704; batch adversarial loss: 0.572017\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433911; batch adversarial loss: 0.608477\n",
      "epoch 28; iter: 0; batch classifier loss: 0.540645; batch adversarial loss: 0.554994\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500137; batch adversarial loss: 0.510448\n",
      "epoch 30; iter: 0; batch classifier loss: 0.539628; batch adversarial loss: 0.510374\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461494; batch adversarial loss: 0.579408\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499098; batch adversarial loss: 0.483795\n",
      "epoch 33; iter: 0; batch classifier loss: 0.377748; batch adversarial loss: 0.607186\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466572; batch adversarial loss: 0.535626\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472333; batch adversarial loss: 0.553936\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379726; batch adversarial loss: 0.526394\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446000; batch adversarial loss: 0.562928\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409387; batch adversarial loss: 0.527073\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442686; batch adversarial loss: 0.544382\n",
      "epoch 40; iter: 0; batch classifier loss: 0.491622; batch adversarial loss: 0.615522\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414767; batch adversarial loss: 0.579755\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420106; batch adversarial loss: 0.471990\n",
      "epoch 43; iter: 0; batch classifier loss: 0.511242; batch adversarial loss: 0.545075\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443999; batch adversarial loss: 0.588734\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414346; batch adversarial loss: 0.563244\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487695; batch adversarial loss: 0.525027\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417839; batch adversarial loss: 0.580965\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411585; batch adversarial loss: 0.535025\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464255; batch adversarial loss: 0.626581\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449533; batch adversarial loss: 0.490408\n",
      "epoch 51; iter: 0; batch classifier loss: 0.467164; batch adversarial loss: 0.590950\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392510; batch adversarial loss: 0.551539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.385729; batch adversarial loss: 0.513717\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395472; batch adversarial loss: 0.492077\n",
      "epoch 55; iter: 0; batch classifier loss: 0.549133; batch adversarial loss: 0.487888\n",
      "epoch 56; iter: 0; batch classifier loss: 0.473748; batch adversarial loss: 0.561350\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446156; batch adversarial loss: 0.525825\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426717; batch adversarial loss: 0.575630\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440207; batch adversarial loss: 0.546359\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412211; batch adversarial loss: 0.555030\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428822; batch adversarial loss: 0.584404\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401963; batch adversarial loss: 0.544747\n",
      "epoch 63; iter: 0; batch classifier loss: 0.508903; batch adversarial loss: 0.533150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402481; batch adversarial loss: 0.544560\n",
      "epoch 65; iter: 0; batch classifier loss: 0.440026; batch adversarial loss: 0.506608\n",
      "epoch 66; iter: 0; batch classifier loss: 0.376608; batch adversarial loss: 0.524704\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426767; batch adversarial loss: 0.482181\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413871; batch adversarial loss: 0.568408\n",
      "epoch 69; iter: 0; batch classifier loss: 0.478324; batch adversarial loss: 0.570120\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398480; batch adversarial loss: 0.555462\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394948; batch adversarial loss: 0.542252\n",
      "epoch 72; iter: 0; batch classifier loss: 0.483557; batch adversarial loss: 0.526452\n",
      "epoch 73; iter: 0; batch classifier loss: 0.370533; batch adversarial loss: 0.572129\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452019; batch adversarial loss: 0.564397\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417293; batch adversarial loss: 0.580748\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376642; batch adversarial loss: 0.505883\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374159; batch adversarial loss: 0.527001\n",
      "epoch 78; iter: 0; batch classifier loss: 0.463292; batch adversarial loss: 0.509741\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359973; batch adversarial loss: 0.576279\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401809; batch adversarial loss: 0.530410\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376054; batch adversarial loss: 0.587696\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400554; batch adversarial loss: 0.546745\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345957; batch adversarial loss: 0.613291\n",
      "epoch 84; iter: 0; batch classifier loss: 0.503514; batch adversarial loss: 0.509626\n",
      "epoch 85; iter: 0; batch classifier loss: 0.444849; batch adversarial loss: 0.488374\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372050; batch adversarial loss: 0.545518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389830; batch adversarial loss: 0.525570\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368278; batch adversarial loss: 0.584714\n",
      "epoch 89; iter: 0; batch classifier loss: 0.423703; batch adversarial loss: 0.562547\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405169; batch adversarial loss: 0.545694\n",
      "epoch 91; iter: 0; batch classifier loss: 0.351668; batch adversarial loss: 0.516583\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377957; batch adversarial loss: 0.592072\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368595; batch adversarial loss: 0.573245\n",
      "epoch 94; iter: 0; batch classifier loss: 0.448798; batch adversarial loss: 0.439750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.494911; batch adversarial loss: 0.590038\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366801; batch adversarial loss: 0.482314\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422742; batch adversarial loss: 0.544233\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381009; batch adversarial loss: 0.610813\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359800; batch adversarial loss: 0.602107\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347685; batch adversarial loss: 0.489848\n",
      "epoch 101; iter: 0; batch classifier loss: 0.457228; batch adversarial loss: 0.516954\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369461; batch adversarial loss: 0.606339\n",
      "epoch 103; iter: 0; batch classifier loss: 0.344685; batch adversarial loss: 0.612166\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398025; batch adversarial loss: 0.524087\n",
      "epoch 105; iter: 0; batch classifier loss: 0.462218; batch adversarial loss: 0.519523\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339177; batch adversarial loss: 0.515371\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391797; batch adversarial loss: 0.559775\n",
      "epoch 108; iter: 0; batch classifier loss: 0.466743; batch adversarial loss: 0.552730\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401204; batch adversarial loss: 0.531685\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391195; batch adversarial loss: 0.462743\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371344; batch adversarial loss: 0.547849\n",
      "epoch 112; iter: 0; batch classifier loss: 0.468488; batch adversarial loss: 0.591666\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335992; batch adversarial loss: 0.590114\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412912; batch adversarial loss: 0.593183\n",
      "epoch 115; iter: 0; batch classifier loss: 0.470411; batch adversarial loss: 0.514514\n",
      "epoch 116; iter: 0; batch classifier loss: 0.462185; batch adversarial loss: 0.526346\n",
      "epoch 117; iter: 0; batch classifier loss: 0.294167; batch adversarial loss: 0.616170\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387206; batch adversarial loss: 0.506420\n",
      "epoch 119; iter: 0; batch classifier loss: 0.327350; batch adversarial loss: 0.527251\n",
      "epoch 120; iter: 0; batch classifier loss: 0.447580; batch adversarial loss: 0.498670\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380060; batch adversarial loss: 0.546175\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380621; batch adversarial loss: 0.599670\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400219; batch adversarial loss: 0.518691\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426732; batch adversarial loss: 0.573836\n",
      "epoch 125; iter: 0; batch classifier loss: 0.436170; batch adversarial loss: 0.544223\n",
      "epoch 126; iter: 0; batch classifier loss: 0.421274; batch adversarial loss: 0.518118\n",
      "epoch 127; iter: 0; batch classifier loss: 0.416684; batch adversarial loss: 0.512556\n",
      "epoch 128; iter: 0; batch classifier loss: 0.433978; batch adversarial loss: 0.496834\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347038; batch adversarial loss: 0.710485\n",
      "epoch 130; iter: 0; batch classifier loss: 0.379893; batch adversarial loss: 0.564862\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427832; batch adversarial loss: 0.506239\n",
      "epoch 132; iter: 0; batch classifier loss: 0.398226; batch adversarial loss: 0.553835\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356200; batch adversarial loss: 0.537836\n",
      "epoch 134; iter: 0; batch classifier loss: 0.436305; batch adversarial loss: 0.568605\n",
      "epoch 135; iter: 0; batch classifier loss: 0.367558; batch adversarial loss: 0.525584\n",
      "epoch 136; iter: 0; batch classifier loss: 0.408132; batch adversarial loss: 0.559366\n",
      "epoch 137; iter: 0; batch classifier loss: 0.325582; batch adversarial loss: 0.604193\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356878; batch adversarial loss: 0.653434\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377264; batch adversarial loss: 0.524463\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402326; batch adversarial loss: 0.564606\n",
      "epoch 141; iter: 0; batch classifier loss: 0.444643; batch adversarial loss: 0.534790\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417321; batch adversarial loss: 0.545052\n",
      "epoch 143; iter: 0; batch classifier loss: 0.436874; batch adversarial loss: 0.594801\n",
      "epoch 144; iter: 0; batch classifier loss: 0.414355; batch adversarial loss: 0.529697\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372961; batch adversarial loss: 0.525627\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386195; batch adversarial loss: 0.608761\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363946; batch adversarial loss: 0.506622\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397546; batch adversarial loss: 0.599484\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363648; batch adversarial loss: 0.610309\n",
      "epoch 150; iter: 0; batch classifier loss: 0.436833; batch adversarial loss: 0.525864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 151; iter: 0; batch classifier loss: 0.380065; batch adversarial loss: 0.499896\n",
      "epoch 152; iter: 0; batch classifier loss: 0.374117; batch adversarial loss: 0.490491\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346939; batch adversarial loss: 0.562478\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382751; batch adversarial loss: 0.573320\n",
      "epoch 155; iter: 0; batch classifier loss: 0.242287; batch adversarial loss: 0.482838\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367395; batch adversarial loss: 0.561851\n",
      "epoch 157; iter: 0; batch classifier loss: 0.402738; batch adversarial loss: 0.526922\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318240; batch adversarial loss: 0.552318\n",
      "epoch 159; iter: 0; batch classifier loss: 0.468556; batch adversarial loss: 0.628235\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356818; batch adversarial loss: 0.552008\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391123; batch adversarial loss: 0.512266\n",
      "epoch 162; iter: 0; batch classifier loss: 0.402462; batch adversarial loss: 0.575029\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375402; batch adversarial loss: 0.560651\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346494; batch adversarial loss: 0.535973\n",
      "epoch 165; iter: 0; batch classifier loss: 0.427742; batch adversarial loss: 0.476340\n",
      "epoch 166; iter: 0; batch classifier loss: 0.423141; batch adversarial loss: 0.611254\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344274; batch adversarial loss: 0.536176\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358319; batch adversarial loss: 0.570739\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352756; batch adversarial loss: 0.522332\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385134; batch adversarial loss: 0.518782\n",
      "epoch 171; iter: 0; batch classifier loss: 0.467503; batch adversarial loss: 0.598510\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388244; batch adversarial loss: 0.528600\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354950; batch adversarial loss: 0.477876\n",
      "epoch 174; iter: 0; batch classifier loss: 0.315612; batch adversarial loss: 0.595094\n",
      "epoch 175; iter: 0; batch classifier loss: 0.335297; batch adversarial loss: 0.505523\n",
      "epoch 176; iter: 0; batch classifier loss: 0.301242; batch adversarial loss: 0.607522\n",
      "epoch 177; iter: 0; batch classifier loss: 0.347817; batch adversarial loss: 0.572099\n",
      "epoch 178; iter: 0; batch classifier loss: 0.429071; batch adversarial loss: 0.500810\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337767; batch adversarial loss: 0.497279\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424993; batch adversarial loss: 0.571022\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370886; batch adversarial loss: 0.544553\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390116; batch adversarial loss: 0.518246\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315598; batch adversarial loss: 0.552572\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318383; batch adversarial loss: 0.518605\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398079; batch adversarial loss: 0.527532\n",
      "epoch 186; iter: 0; batch classifier loss: 0.441770; batch adversarial loss: 0.506520\n",
      "epoch 187; iter: 0; batch classifier loss: 0.512142; batch adversarial loss: 0.623740\n",
      "epoch 188; iter: 0; batch classifier loss: 0.410308; batch adversarial loss: 0.619056\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343730; batch adversarial loss: 0.526798\n",
      "epoch 190; iter: 0; batch classifier loss: 0.428581; batch adversarial loss: 0.525624\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344513; batch adversarial loss: 0.591041\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364281; batch adversarial loss: 0.509914\n",
      "epoch 193; iter: 0; batch classifier loss: 0.426484; batch adversarial loss: 0.606795\n",
      "epoch 194; iter: 0; batch classifier loss: 0.437794; batch adversarial loss: 0.539545\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328680; batch adversarial loss: 0.613196\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332480; batch adversarial loss: 0.478886\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386941; batch adversarial loss: 0.625437\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382720; batch adversarial loss: 0.587067\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352223; batch adversarial loss: 0.562419\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688611; batch adversarial loss: 0.753675\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604317; batch adversarial loss: 0.782818\n",
      "epoch 2; iter: 0; batch classifier loss: 0.636674; batch adversarial loss: 0.734916\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534676; batch adversarial loss: 0.691205\n",
      "epoch 4; iter: 0; batch classifier loss: 0.554318; batch adversarial loss: 0.661887\n",
      "epoch 5; iter: 0; batch classifier loss: 0.618704; batch adversarial loss: 0.643943\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506692; batch adversarial loss: 0.615930\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603778; batch adversarial loss: 0.614669\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530379; batch adversarial loss: 0.597025\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544240; batch adversarial loss: 0.576285\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539993; batch adversarial loss: 0.597507\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540667; batch adversarial loss: 0.552449\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509179; batch adversarial loss: 0.541055\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472943; batch adversarial loss: 0.582708\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513919; batch adversarial loss: 0.594275\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515974; batch adversarial loss: 0.566653\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488181; batch adversarial loss: 0.578745\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522532; batch adversarial loss: 0.483005\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501589; batch adversarial loss: 0.535629\n",
      "epoch 19; iter: 0; batch classifier loss: 0.493749; batch adversarial loss: 0.553178\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476351; batch adversarial loss: 0.624621\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475837; batch adversarial loss: 0.577905\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503839; batch adversarial loss: 0.560961\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502994; batch adversarial loss: 0.554434\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503528; batch adversarial loss: 0.502502\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518236; batch adversarial loss: 0.577257\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474800; batch adversarial loss: 0.560948\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520219; batch adversarial loss: 0.616175\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464759; batch adversarial loss: 0.535757\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429161; batch adversarial loss: 0.621558\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469502; batch adversarial loss: 0.550531\n",
      "epoch 31; iter: 0; batch classifier loss: 0.450136; batch adversarial loss: 0.573928\n",
      "epoch 32; iter: 0; batch classifier loss: 0.565118; batch adversarial loss: 0.539268\n",
      "epoch 33; iter: 0; batch classifier loss: 0.371664; batch adversarial loss: 0.596695\n",
      "epoch 34; iter: 0; batch classifier loss: 0.441069; batch adversarial loss: 0.522606\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442328; batch adversarial loss: 0.496339\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406476; batch adversarial loss: 0.572160\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462410; batch adversarial loss: 0.571087\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440778; batch adversarial loss: 0.587733\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443160; batch adversarial loss: 0.555600\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461551; batch adversarial loss: 0.518989\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462716; batch adversarial loss: 0.632743\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463782; batch adversarial loss: 0.597910\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413279; batch adversarial loss: 0.570484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435737; batch adversarial loss: 0.544759\n",
      "epoch 45; iter: 0; batch classifier loss: 0.510675; batch adversarial loss: 0.563321\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446369; batch adversarial loss: 0.552867\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420632; batch adversarial loss: 0.579540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.451587; batch adversarial loss: 0.529602\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419145; batch adversarial loss: 0.562982\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400571; batch adversarial loss: 0.576457\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409273; batch adversarial loss: 0.525387\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387672; batch adversarial loss: 0.519260\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400465; batch adversarial loss: 0.563850\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445755; batch adversarial loss: 0.587038\n",
      "epoch 55; iter: 0; batch classifier loss: 0.442103; batch adversarial loss: 0.492363\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412022; batch adversarial loss: 0.588436\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441931; batch adversarial loss: 0.500132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.459592; batch adversarial loss: 0.562939\n",
      "epoch 59; iter: 0; batch classifier loss: 0.430079; batch adversarial loss: 0.535084\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447971; batch adversarial loss: 0.614065\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409050; batch adversarial loss: 0.597768\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434171; batch adversarial loss: 0.536425\n",
      "epoch 63; iter: 0; batch classifier loss: 0.484312; batch adversarial loss: 0.536393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.326989; batch adversarial loss: 0.518483\n",
      "epoch 65; iter: 0; batch classifier loss: 0.337758; batch adversarial loss: 0.560483\n",
      "epoch 66; iter: 0; batch classifier loss: 0.490754; batch adversarial loss: 0.546825\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358877; batch adversarial loss: 0.537424\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412311; batch adversarial loss: 0.586814\n",
      "epoch 69; iter: 0; batch classifier loss: 0.455035; batch adversarial loss: 0.550155\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421039; batch adversarial loss: 0.597796\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370659; batch adversarial loss: 0.508471\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444125; batch adversarial loss: 0.553379\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353459; batch adversarial loss: 0.493170\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372836; batch adversarial loss: 0.596097\n",
      "epoch 75; iter: 0; batch classifier loss: 0.349414; batch adversarial loss: 0.595721\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407491; batch adversarial loss: 0.526137\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379097; batch adversarial loss: 0.545519\n",
      "epoch 78; iter: 0; batch classifier loss: 0.418581; batch adversarial loss: 0.552283\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388468; batch adversarial loss: 0.546246\n",
      "epoch 80; iter: 0; batch classifier loss: 0.405232; batch adversarial loss: 0.543830\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416885; batch adversarial loss: 0.571664\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367291; batch adversarial loss: 0.569814\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420164; batch adversarial loss: 0.528801\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382820; batch adversarial loss: 0.578273\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350941; batch adversarial loss: 0.517874\n",
      "epoch 86; iter: 0; batch classifier loss: 0.482507; batch adversarial loss: 0.596798\n",
      "epoch 87; iter: 0; batch classifier loss: 0.348330; batch adversarial loss: 0.579187\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375265; batch adversarial loss: 0.590206\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361782; batch adversarial loss: 0.635777\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364679; batch adversarial loss: 0.633140\n",
      "epoch 91; iter: 0; batch classifier loss: 0.288252; batch adversarial loss: 0.564009\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392561; batch adversarial loss: 0.604584\n",
      "epoch 93; iter: 0; batch classifier loss: 0.343151; batch adversarial loss: 0.586722\n",
      "epoch 94; iter: 0; batch classifier loss: 0.469215; batch adversarial loss: 0.551545\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347503; batch adversarial loss: 0.632601\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383774; batch adversarial loss: 0.510266\n",
      "epoch 97; iter: 0; batch classifier loss: 0.432784; batch adversarial loss: 0.579277\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381296; batch adversarial loss: 0.546990\n",
      "epoch 99; iter: 0; batch classifier loss: 0.323749; batch adversarial loss: 0.519249\n",
      "epoch 100; iter: 0; batch classifier loss: 0.428418; batch adversarial loss: 0.482508\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387500; batch adversarial loss: 0.576601\n",
      "epoch 102; iter: 0; batch classifier loss: 0.439402; batch adversarial loss: 0.550771\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334290; batch adversarial loss: 0.542277\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386565; batch adversarial loss: 0.552560\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351227; batch adversarial loss: 0.623850\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331708; batch adversarial loss: 0.511473\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381970; batch adversarial loss: 0.525092\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403808; batch adversarial loss: 0.463395\n",
      "epoch 109; iter: 0; batch classifier loss: 0.328743; batch adversarial loss: 0.552786\n",
      "epoch 110; iter: 0; batch classifier loss: 0.340508; batch adversarial loss: 0.528073\n",
      "epoch 111; iter: 0; batch classifier loss: 0.413331; batch adversarial loss: 0.532956\n",
      "epoch 112; iter: 0; batch classifier loss: 0.272007; batch adversarial loss: 0.542798\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355187; batch adversarial loss: 0.535004\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352074; batch adversarial loss: 0.540709\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380388; batch adversarial loss: 0.552796\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392509; batch adversarial loss: 0.586576\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382543; batch adversarial loss: 0.512806\n",
      "epoch 118; iter: 0; batch classifier loss: 0.318326; batch adversarial loss: 0.565890\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342853; batch adversarial loss: 0.563854\n",
      "epoch 120; iter: 0; batch classifier loss: 0.449732; batch adversarial loss: 0.616110\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373054; batch adversarial loss: 0.523727\n",
      "epoch 122; iter: 0; batch classifier loss: 0.354838; batch adversarial loss: 0.535856\n",
      "epoch 123; iter: 0; batch classifier loss: 0.386392; batch adversarial loss: 0.493645\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337119; batch adversarial loss: 0.534801\n",
      "epoch 125; iter: 0; batch classifier loss: 0.352303; batch adversarial loss: 0.476565\n",
      "epoch 126; iter: 0; batch classifier loss: 0.440952; batch adversarial loss: 0.458962\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328071; batch adversarial loss: 0.589287\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370821; batch adversarial loss: 0.544740\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401271; batch adversarial loss: 0.554738\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366115; batch adversarial loss: 0.550876\n",
      "epoch 131; iter: 0; batch classifier loss: 0.325817; batch adversarial loss: 0.589258\n",
      "epoch 132; iter: 0; batch classifier loss: 0.332123; batch adversarial loss: 0.525434\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396613; batch adversarial loss: 0.561528\n",
      "epoch 134; iter: 0; batch classifier loss: 0.345292; batch adversarial loss: 0.536951\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341957; batch adversarial loss: 0.589278\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374426; batch adversarial loss: 0.481138\n",
      "epoch 137; iter: 0; batch classifier loss: 0.300047; batch adversarial loss: 0.515588\n",
      "epoch 138; iter: 0; batch classifier loss: 0.281797; batch adversarial loss: 0.536022\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328669; batch adversarial loss: 0.482179\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349041; batch adversarial loss: 0.581369\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342676; batch adversarial loss: 0.577647\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363443; batch adversarial loss: 0.520015\n",
      "epoch 143; iter: 0; batch classifier loss: 0.319891; batch adversarial loss: 0.586224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.403475; batch adversarial loss: 0.604249\n",
      "epoch 145; iter: 0; batch classifier loss: 0.305680; batch adversarial loss: 0.564394\n",
      "epoch 146; iter: 0; batch classifier loss: 0.332098; batch adversarial loss: 0.554287\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347379; batch adversarial loss: 0.529044\n",
      "epoch 148; iter: 0; batch classifier loss: 0.390542; batch adversarial loss: 0.528138\n",
      "epoch 149; iter: 0; batch classifier loss: 0.390040; batch adversarial loss: 0.668473\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390013; batch adversarial loss: 0.499554\n",
      "epoch 151; iter: 0; batch classifier loss: 0.354511; batch adversarial loss: 0.562856\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356627; batch adversarial loss: 0.623268\n",
      "epoch 153; iter: 0; batch classifier loss: 0.415078; batch adversarial loss: 0.526222\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393792; batch adversarial loss: 0.484410\n",
      "epoch 155; iter: 0; batch classifier loss: 0.304040; batch adversarial loss: 0.605430\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357996; batch adversarial loss: 0.525004\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432364; batch adversarial loss: 0.499591\n",
      "epoch 158; iter: 0; batch classifier loss: 0.428165; batch adversarial loss: 0.483094\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407519; batch adversarial loss: 0.561321\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319168; batch adversarial loss: 0.536158\n",
      "epoch 161; iter: 0; batch classifier loss: 0.364155; batch adversarial loss: 0.501093\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352375; batch adversarial loss: 0.492674\n",
      "epoch 163; iter: 0; batch classifier loss: 0.499747; batch adversarial loss: 0.587867\n",
      "epoch 164; iter: 0; batch classifier loss: 0.300533; batch adversarial loss: 0.618066\n",
      "epoch 165; iter: 0; batch classifier loss: 0.384959; batch adversarial loss: 0.573924\n",
      "epoch 166; iter: 0; batch classifier loss: 0.344117; batch adversarial loss: 0.661679\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380543; batch adversarial loss: 0.543403\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373464; batch adversarial loss: 0.491927\n",
      "epoch 169; iter: 0; batch classifier loss: 0.348958; batch adversarial loss: 0.630316\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373113; batch adversarial loss: 0.502912\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409102; batch adversarial loss: 0.605140\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358560; batch adversarial loss: 0.559917\n",
      "epoch 173; iter: 0; batch classifier loss: 0.268553; batch adversarial loss: 0.551842\n",
      "epoch 174; iter: 0; batch classifier loss: 0.419273; batch adversarial loss: 0.535440\n",
      "epoch 175; iter: 0; batch classifier loss: 0.410901; batch adversarial loss: 0.559154\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400846; batch adversarial loss: 0.604993\n",
      "epoch 177; iter: 0; batch classifier loss: 0.393705; batch adversarial loss: 0.569556\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328740; batch adversarial loss: 0.529544\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343667; batch adversarial loss: 0.542165\n",
      "epoch 180; iter: 0; batch classifier loss: 0.404946; batch adversarial loss: 0.509697\n",
      "epoch 181; iter: 0; batch classifier loss: 0.369876; batch adversarial loss: 0.527615\n",
      "epoch 182; iter: 0; batch classifier loss: 0.279277; batch adversarial loss: 0.535494\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333509; batch adversarial loss: 0.573655\n",
      "epoch 184; iter: 0; batch classifier loss: 0.400446; batch adversarial loss: 0.632323\n",
      "epoch 185; iter: 0; batch classifier loss: 0.317208; batch adversarial loss: 0.634167\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373789; batch adversarial loss: 0.534891\n",
      "epoch 187; iter: 0; batch classifier loss: 0.330557; batch adversarial loss: 0.438265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335356; batch adversarial loss: 0.604127\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351953; batch adversarial loss: 0.549143\n",
      "epoch 190; iter: 0; batch classifier loss: 0.290598; batch adversarial loss: 0.481286\n",
      "epoch 191; iter: 0; batch classifier loss: 0.333381; batch adversarial loss: 0.515857\n",
      "epoch 192; iter: 0; batch classifier loss: 0.272539; batch adversarial loss: 0.534390\n",
      "epoch 193; iter: 0; batch classifier loss: 0.323513; batch adversarial loss: 0.544958\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359167; batch adversarial loss: 0.594777\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335584; batch adversarial loss: 0.617880\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313772; batch adversarial loss: 0.587538\n",
      "epoch 197; iter: 0; batch classifier loss: 0.285760; batch adversarial loss: 0.641182\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383234; batch adversarial loss: 0.543025\n",
      "epoch 199; iter: 0; batch classifier loss: 0.378599; batch adversarial loss: 0.570214\n",
      "epoch 0; iter: 0; batch classifier loss: 0.780722; batch adversarial loss: 0.586427\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600982; batch adversarial loss: 0.657719\n",
      "epoch 2; iter: 0; batch classifier loss: 0.548731; batch adversarial loss: 0.665892\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614778; batch adversarial loss: 0.651766\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553527; batch adversarial loss: 0.661524\n",
      "epoch 5; iter: 0; batch classifier loss: 0.680855; batch adversarial loss: 0.642948\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605563; batch adversarial loss: 0.604986\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596198; batch adversarial loss: 0.640977\n",
      "epoch 8; iter: 0; batch classifier loss: 0.667827; batch adversarial loss: 0.621753\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568559; batch adversarial loss: 0.576491\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553055; batch adversarial loss: 0.624884\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556335; batch adversarial loss: 0.601685\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560064; batch adversarial loss: 0.561251\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487327; batch adversarial loss: 0.557839\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529195; batch adversarial loss: 0.534529\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564695; batch adversarial loss: 0.590623\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528309; batch adversarial loss: 0.531175\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493289; batch adversarial loss: 0.609305\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455676; batch adversarial loss: 0.506689\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491953; batch adversarial loss: 0.529124\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532835; batch adversarial loss: 0.615692\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463323; batch adversarial loss: 0.575118\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512725; batch adversarial loss: 0.570530\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495743; batch adversarial loss: 0.557630\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508984; batch adversarial loss: 0.618713\n",
      "epoch 25; iter: 0; batch classifier loss: 0.399279; batch adversarial loss: 0.570978\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467602; batch adversarial loss: 0.555996\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461787; batch adversarial loss: 0.508456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.508260; batch adversarial loss: 0.535282\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490898; batch adversarial loss: 0.554330\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508753; batch adversarial loss: 0.549592\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501332; batch adversarial loss: 0.498663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467770; batch adversarial loss: 0.546205\n",
      "epoch 33; iter: 0; batch classifier loss: 0.479862; batch adversarial loss: 0.581681\n",
      "epoch 34; iter: 0; batch classifier loss: 0.568422; batch adversarial loss: 0.588202\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460540; batch adversarial loss: 0.498756\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444643; batch adversarial loss: 0.542909\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485476; batch adversarial loss: 0.552525\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429985; batch adversarial loss: 0.493142\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457786; batch adversarial loss: 0.578299\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428347; batch adversarial loss: 0.579735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.493410; batch adversarial loss: 0.598527\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436563; batch adversarial loss: 0.571151\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414531; batch adversarial loss: 0.525066\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453817; batch adversarial loss: 0.553640\n",
      "epoch 45; iter: 0; batch classifier loss: 0.474291; batch adversarial loss: 0.570697\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402637; batch adversarial loss: 0.501609\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459927; batch adversarial loss: 0.647272\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400323; batch adversarial loss: 0.510725\n",
      "epoch 49; iter: 0; batch classifier loss: 0.342852; batch adversarial loss: 0.534639\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374412; batch adversarial loss: 0.543508\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427839; batch adversarial loss: 0.544702\n",
      "epoch 52; iter: 0; batch classifier loss: 0.397696; batch adversarial loss: 0.571602\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415708; batch adversarial loss: 0.562107\n",
      "epoch 54; iter: 0; batch classifier loss: 0.367764; batch adversarial loss: 0.542753\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429433; batch adversarial loss: 0.472724\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395689; batch adversarial loss: 0.527216\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379307; batch adversarial loss: 0.526917\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.635605\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447636; batch adversarial loss: 0.599979\n",
      "epoch 60; iter: 0; batch classifier loss: 0.369537; batch adversarial loss: 0.497281\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401418; batch adversarial loss: 0.561684\n",
      "epoch 62; iter: 0; batch classifier loss: 0.420157; batch adversarial loss: 0.544718\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420093; batch adversarial loss: 0.541730\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434095; batch adversarial loss: 0.572682\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403234; batch adversarial loss: 0.546453\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428448; batch adversarial loss: 0.471172\n",
      "epoch 67; iter: 0; batch classifier loss: 0.461374; batch adversarial loss: 0.571231\n",
      "epoch 68; iter: 0; batch classifier loss: 0.357828; batch adversarial loss: 0.543722\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375986; batch adversarial loss: 0.590175\n",
      "epoch 70; iter: 0; batch classifier loss: 0.405629; batch adversarial loss: 0.586581\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418496; batch adversarial loss: 0.489343\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390565; batch adversarial loss: 0.585411\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378650; batch adversarial loss: 0.508134\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399614; batch adversarial loss: 0.533851\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385083; batch adversarial loss: 0.475375\n",
      "epoch 76; iter: 0; batch classifier loss: 0.475784; batch adversarial loss: 0.518646\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387377; batch adversarial loss: 0.545174\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379306; batch adversarial loss: 0.597556\n",
      "epoch 79; iter: 0; batch classifier loss: 0.469037; batch adversarial loss: 0.544006\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429583; batch adversarial loss: 0.570782\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408527; batch adversarial loss: 0.518080\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361987; batch adversarial loss: 0.526525\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368696; batch adversarial loss: 0.553178\n",
      "epoch 84; iter: 0; batch classifier loss: 0.469738; batch adversarial loss: 0.517811\n",
      "epoch 85; iter: 0; batch classifier loss: 0.477097; batch adversarial loss: 0.580605\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415915; batch adversarial loss: 0.580779\n",
      "epoch 87; iter: 0; batch classifier loss: 0.322612; batch adversarial loss: 0.507912\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375538; batch adversarial loss: 0.572257\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369172; batch adversarial loss: 0.561538\n",
      "epoch 90; iter: 0; batch classifier loss: 0.445744; batch adversarial loss: 0.562869\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416144; batch adversarial loss: 0.608493\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397061; batch adversarial loss: 0.544826\n",
      "epoch 93; iter: 0; batch classifier loss: 0.465744; batch adversarial loss: 0.516850\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390598; batch adversarial loss: 0.525801\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394790; batch adversarial loss: 0.525428\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359603; batch adversarial loss: 0.608253\n",
      "epoch 97; iter: 0; batch classifier loss: 0.326256; batch adversarial loss: 0.572119\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391797; batch adversarial loss: 0.572724\n",
      "epoch 99; iter: 0; batch classifier loss: 0.449009; batch adversarial loss: 0.582661\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385298; batch adversarial loss: 0.544348\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426224; batch adversarial loss: 0.607514\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362655; batch adversarial loss: 0.554254\n",
      "epoch 103; iter: 0; batch classifier loss: 0.452080; batch adversarial loss: 0.570610\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341888; batch adversarial loss: 0.579902\n",
      "epoch 105; iter: 0; batch classifier loss: 0.354072; batch adversarial loss: 0.525750\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412495; batch adversarial loss: 0.536134\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345892; batch adversarial loss: 0.563683\n",
      "epoch 108; iter: 0; batch classifier loss: 0.414667; batch adversarial loss: 0.534844\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371194; batch adversarial loss: 0.516290\n",
      "epoch 110; iter: 0; batch classifier loss: 0.419447; batch adversarial loss: 0.589774\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360167; batch adversarial loss: 0.526078\n",
      "epoch 112; iter: 0; batch classifier loss: 0.456131; batch adversarial loss: 0.499469\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413998; batch adversarial loss: 0.535293\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374733; batch adversarial loss: 0.543119\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370498; batch adversarial loss: 0.545146\n",
      "epoch 116; iter: 0; batch classifier loss: 0.333362; batch adversarial loss: 0.600023\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354019; batch adversarial loss: 0.515554\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401575; batch adversarial loss: 0.507419\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407574; batch adversarial loss: 0.579816\n",
      "epoch 120; iter: 0; batch classifier loss: 0.445482; batch adversarial loss: 0.552941\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393499; batch adversarial loss: 0.497974\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377116; batch adversarial loss: 0.478332\n",
      "epoch 123; iter: 0; batch classifier loss: 0.336610; batch adversarial loss: 0.533259\n",
      "epoch 124; iter: 0; batch classifier loss: 0.465283; batch adversarial loss: 0.476390\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377281; batch adversarial loss: 0.543571\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387978; batch adversarial loss: 0.516992\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372186; batch adversarial loss: 0.617839\n",
      "epoch 128; iter: 0; batch classifier loss: 0.430395; batch adversarial loss: 0.600254\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403252; batch adversarial loss: 0.645493\n",
      "epoch 130; iter: 0; batch classifier loss: 0.330576; batch adversarial loss: 0.499775\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367046; batch adversarial loss: 0.515765\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400112; batch adversarial loss: 0.536978\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337556; batch adversarial loss: 0.496468\n",
      "epoch 134; iter: 0; batch classifier loss: 0.455199; batch adversarial loss: 0.589854\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361643; batch adversarial loss: 0.599388\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336347; batch adversarial loss: 0.542713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.401575; batch adversarial loss: 0.526441\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334563; batch adversarial loss: 0.571579\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367031; batch adversarial loss: 0.635980\n",
      "epoch 140; iter: 0; batch classifier loss: 0.315809; batch adversarial loss: 0.554039\n",
      "epoch 141; iter: 0; batch classifier loss: 0.396796; batch adversarial loss: 0.625278\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417431; batch adversarial loss: 0.562284\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388132; batch adversarial loss: 0.554261\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357599; batch adversarial loss: 0.545469\n",
      "epoch 145; iter: 0; batch classifier loss: 0.343386; batch adversarial loss: 0.544093\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369008; batch adversarial loss: 0.544226\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303422; batch adversarial loss: 0.572682\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370123; batch adversarial loss: 0.534546\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342669; batch adversarial loss: 0.498922\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364908; batch adversarial loss: 0.544325\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352085; batch adversarial loss: 0.561782\n",
      "epoch 152; iter: 0; batch classifier loss: 0.329336; batch adversarial loss: 0.608659\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320382; batch adversarial loss: 0.535011\n",
      "epoch 154; iter: 0; batch classifier loss: 0.414902; batch adversarial loss: 0.517872\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316725; batch adversarial loss: 0.534957\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351435; batch adversarial loss: 0.526436\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350381; batch adversarial loss: 0.534617\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347006; batch adversarial loss: 0.545595\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379797; batch adversarial loss: 0.498949\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321602; batch adversarial loss: 0.564596\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407850; batch adversarial loss: 0.526599\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331415; batch adversarial loss: 0.553452\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375773; batch adversarial loss: 0.562452\n",
      "epoch 164; iter: 0; batch classifier loss: 0.468939; batch adversarial loss: 0.535205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343917; batch adversarial loss: 0.581553\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328780; batch adversarial loss: 0.553792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323825; batch adversarial loss: 0.544729\n",
      "epoch 168; iter: 0; batch classifier loss: 0.399754; batch adversarial loss: 0.553348\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390284; batch adversarial loss: 0.572045\n",
      "epoch 170; iter: 0; batch classifier loss: 0.427461; batch adversarial loss: 0.526090\n",
      "epoch 171; iter: 0; batch classifier loss: 0.313005; batch adversarial loss: 0.562677\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362971; batch adversarial loss: 0.572352\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360102; batch adversarial loss: 0.571096\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325226; batch adversarial loss: 0.525811\n",
      "epoch 175; iter: 0; batch classifier loss: 0.432767; batch adversarial loss: 0.517555\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316335; batch adversarial loss: 0.516677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.449596; batch adversarial loss: 0.554866\n",
      "epoch 178; iter: 0; batch classifier loss: 0.283581; batch adversarial loss: 0.598611\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327635; batch adversarial loss: 0.571224\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354809; batch adversarial loss: 0.608411\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350520; batch adversarial loss: 0.507740\n",
      "epoch 182; iter: 0; batch classifier loss: 0.275419; batch adversarial loss: 0.690604\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362042; batch adversarial loss: 0.527228\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313936; batch adversarial loss: 0.617918\n",
      "epoch 185; iter: 0; batch classifier loss: 0.306744; batch adversarial loss: 0.598995\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359203; batch adversarial loss: 0.580874\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357095; batch adversarial loss: 0.535310\n",
      "epoch 188; iter: 0; batch classifier loss: 0.418461; batch adversarial loss: 0.544285\n",
      "epoch 189; iter: 0; batch classifier loss: 0.396141; batch adversarial loss: 0.553259\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342614; batch adversarial loss: 0.627128\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316203; batch adversarial loss: 0.581824\n",
      "epoch 192; iter: 0; batch classifier loss: 0.425600; batch adversarial loss: 0.590233\n",
      "epoch 193; iter: 0; batch classifier loss: 0.281599; batch adversarial loss: 0.527459\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359921; batch adversarial loss: 0.543954\n",
      "epoch 195; iter: 0; batch classifier loss: 0.425369; batch adversarial loss: 0.444664\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323302; batch adversarial loss: 0.681110\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318892; batch adversarial loss: 0.581442\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378856; batch adversarial loss: 0.619056\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384802; batch adversarial loss: 0.490378\n",
      "epoch 0; iter: 0; batch classifier loss: 0.614383; batch adversarial loss: 0.710895\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643556; batch adversarial loss: 0.699808\n",
      "epoch 2; iter: 0; batch classifier loss: 0.552367; batch adversarial loss: 0.664558\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538441; batch adversarial loss: 0.667474\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576387; batch adversarial loss: 0.625667\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613720; batch adversarial loss: 0.598276\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541778; batch adversarial loss: 0.614155\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553534; batch adversarial loss: 0.580670\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532324; batch adversarial loss: 0.569535\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474162; batch adversarial loss: 0.586567\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536946; batch adversarial loss: 0.525273\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505898; batch adversarial loss: 0.583013\n",
      "epoch 12; iter: 0; batch classifier loss: 0.462052; batch adversarial loss: 0.594632\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565574; batch adversarial loss: 0.628084\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522629; batch adversarial loss: 0.537402\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491740; batch adversarial loss: 0.631097\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490857; batch adversarial loss: 0.569662\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481775; batch adversarial loss: 0.582784\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505627; batch adversarial loss: 0.615151\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508127; batch adversarial loss: 0.553182\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499290; batch adversarial loss: 0.583761\n",
      "epoch 21; iter: 0; batch classifier loss: 0.619344; batch adversarial loss: 0.610760\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524811; batch adversarial loss: 0.536531\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499546; batch adversarial loss: 0.631375\n",
      "epoch 24; iter: 0; batch classifier loss: 0.423282; batch adversarial loss: 0.565698\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446935; batch adversarial loss: 0.564706\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473857; batch adversarial loss: 0.548976\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478833; batch adversarial loss: 0.555571\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469697; batch adversarial loss: 0.594644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451050; batch adversarial loss: 0.587052\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495579; batch adversarial loss: 0.563292\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505859; batch adversarial loss: 0.553663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.375815; batch adversarial loss: 0.493789\n",
      "epoch 33; iter: 0; batch classifier loss: 0.490639; batch adversarial loss: 0.589389\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547706; batch adversarial loss: 0.528163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.398284; batch adversarial loss: 0.492992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428445; batch adversarial loss: 0.543870\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447208; batch adversarial loss: 0.554641\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463947; batch adversarial loss: 0.536055\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491293; batch adversarial loss: 0.569784\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453007; batch adversarial loss: 0.487428\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438653; batch adversarial loss: 0.504951\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459508; batch adversarial loss: 0.462520\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446839; batch adversarial loss: 0.571681\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481991; batch adversarial loss: 0.624208\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394923; batch adversarial loss: 0.524761\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426211; batch adversarial loss: 0.515453\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490445; batch adversarial loss: 0.605675\n",
      "epoch 48; iter: 0; batch classifier loss: 0.376419; batch adversarial loss: 0.598773\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380703; batch adversarial loss: 0.594151\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503705; batch adversarial loss: 0.613736\n",
      "epoch 51; iter: 0; batch classifier loss: 0.385118; batch adversarial loss: 0.572119\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444711; batch adversarial loss: 0.564106\n",
      "epoch 53; iter: 0; batch classifier loss: 0.391977; batch adversarial loss: 0.511905\n",
      "epoch 54; iter: 0; batch classifier loss: 0.367916; batch adversarial loss: 0.554103\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426042; batch adversarial loss: 0.511825\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398789; batch adversarial loss: 0.492118\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454128; batch adversarial loss: 0.562994\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390457; batch adversarial loss: 0.580124\n",
      "epoch 59; iter: 0; batch classifier loss: 0.482312; batch adversarial loss: 0.536901\n",
      "epoch 60; iter: 0; batch classifier loss: 0.472475; batch adversarial loss: 0.475701\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419757; batch adversarial loss: 0.509871\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398410; batch adversarial loss: 0.623772\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431546; batch adversarial loss: 0.509393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403199; batch adversarial loss: 0.589000\n",
      "epoch 65; iter: 0; batch classifier loss: 0.471500; batch adversarial loss: 0.562077\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406033; batch adversarial loss: 0.580516\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381276; batch adversarial loss: 0.634054\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420616; batch adversarial loss: 0.527169\n",
      "epoch 69; iter: 0; batch classifier loss: 0.408573; batch adversarial loss: 0.553948\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352578; batch adversarial loss: 0.500230\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428462; batch adversarial loss: 0.518069\n",
      "epoch 72; iter: 0; batch classifier loss: 0.481984; batch adversarial loss: 0.589167\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367402; batch adversarial loss: 0.561854\n",
      "epoch 74; iter: 0; batch classifier loss: 0.492656; batch adversarial loss: 0.598265\n",
      "epoch 75; iter: 0; batch classifier loss: 0.461607; batch adversarial loss: 0.544848\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382085; batch adversarial loss: 0.509185\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344925; batch adversarial loss: 0.616068\n",
      "epoch 78; iter: 0; batch classifier loss: 0.287390; batch adversarial loss: 0.517791\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419601; batch adversarial loss: 0.589471\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449768; batch adversarial loss: 0.545091\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414218; batch adversarial loss: 0.616303\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418311; batch adversarial loss: 0.509832\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395783; batch adversarial loss: 0.535840\n",
      "epoch 84; iter: 0; batch classifier loss: 0.308232; batch adversarial loss: 0.482585\n",
      "epoch 85; iter: 0; batch classifier loss: 0.314521; batch adversarial loss: 0.607102\n",
      "epoch 86; iter: 0; batch classifier loss: 0.363554; batch adversarial loss: 0.579626\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384683; batch adversarial loss: 0.536090\n",
      "epoch 88; iter: 0; batch classifier loss: 0.309928; batch adversarial loss: 0.598491\n",
      "epoch 89; iter: 0; batch classifier loss: 0.440534; batch adversarial loss: 0.624937\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367649; batch adversarial loss: 0.580111\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395100; batch adversarial loss: 0.535838\n",
      "epoch 92; iter: 0; batch classifier loss: 0.352458; batch adversarial loss: 0.580555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.359509; batch adversarial loss: 0.482451\n",
      "epoch 94; iter: 0; batch classifier loss: 0.329175; batch adversarial loss: 0.562699\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397366; batch adversarial loss: 0.589060\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390769; batch adversarial loss: 0.561914\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391255; batch adversarial loss: 0.606497\n",
      "epoch 98; iter: 0; batch classifier loss: 0.491464; batch adversarial loss: 0.536100\n",
      "epoch 99; iter: 0; batch classifier loss: 0.349244; batch adversarial loss: 0.570890\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423808; batch adversarial loss: 0.606984\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390147; batch adversarial loss: 0.599458\n",
      "epoch 102; iter: 0; batch classifier loss: 0.482171; batch adversarial loss: 0.536192\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349136; batch adversarial loss: 0.571411\n",
      "epoch 104; iter: 0; batch classifier loss: 0.375155; batch adversarial loss: 0.562200\n",
      "epoch 105; iter: 0; batch classifier loss: 0.329292; batch adversarial loss: 0.589309\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360733; batch adversarial loss: 0.641977\n",
      "epoch 107; iter: 0; batch classifier loss: 0.435044; batch adversarial loss: 0.534991\n",
      "epoch 108; iter: 0; batch classifier loss: 0.290992; batch adversarial loss: 0.544683\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388633; batch adversarial loss: 0.561378\n",
      "epoch 110; iter: 0; batch classifier loss: 0.317066; batch adversarial loss: 0.606438\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405620; batch adversarial loss: 0.571472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.401834; batch adversarial loss: 0.563275\n",
      "epoch 113; iter: 0; batch classifier loss: 0.342897; batch adversarial loss: 0.607121\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352456; batch adversarial loss: 0.571468\n",
      "epoch 115; iter: 0; batch classifier loss: 0.320096; batch adversarial loss: 0.661619\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413939; batch adversarial loss: 0.526421\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384143; batch adversarial loss: 0.535699\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340001; batch adversarial loss: 0.580157\n",
      "epoch 119; iter: 0; batch classifier loss: 0.332111; batch adversarial loss: 0.517551\n",
      "epoch 120; iter: 0; batch classifier loss: 0.432335; batch adversarial loss: 0.580270\n",
      "epoch 121; iter: 0; batch classifier loss: 0.436731; batch adversarial loss: 0.526682\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410960; batch adversarial loss: 0.464373\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350858; batch adversarial loss: 0.518845\n",
      "epoch 124; iter: 0; batch classifier loss: 0.281386; batch adversarial loss: 0.489640\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382967; batch adversarial loss: 0.606760\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438444; batch adversarial loss: 0.490438\n",
      "epoch 127; iter: 0; batch classifier loss: 0.413942; batch adversarial loss: 0.598875\n",
      "epoch 128; iter: 0; batch classifier loss: 0.306412; batch adversarial loss: 0.526906\n",
      "epoch 129; iter: 0; batch classifier loss: 0.383695; batch adversarial loss: 0.518166\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346710; batch adversarial loss: 0.589524\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331195; batch adversarial loss: 0.491686\n",
      "epoch 132; iter: 0; batch classifier loss: 0.338859; batch adversarial loss: 0.563812\n",
      "epoch 133; iter: 0; batch classifier loss: 0.401423; batch adversarial loss: 0.544687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.457563; batch adversarial loss: 0.528306\n",
      "epoch 135; iter: 0; batch classifier loss: 0.414214; batch adversarial loss: 0.526474\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370017; batch adversarial loss: 0.554171\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405934; batch adversarial loss: 0.517921\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393925; batch adversarial loss: 0.509956\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361920; batch adversarial loss: 0.500127\n",
      "epoch 140; iter: 0; batch classifier loss: 0.292469; batch adversarial loss: 0.509113\n",
      "epoch 141; iter: 0; batch classifier loss: 0.388442; batch adversarial loss: 0.544072\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396374; batch adversarial loss: 0.499961\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330362; batch adversarial loss: 0.588491\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371710; batch adversarial loss: 0.517179\n",
      "epoch 145; iter: 0; batch classifier loss: 0.378008; batch adversarial loss: 0.526138\n",
      "epoch 146; iter: 0; batch classifier loss: 0.317495; batch adversarial loss: 0.677460\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340210; batch adversarial loss: 0.535562\n",
      "epoch 148; iter: 0; batch classifier loss: 0.409791; batch adversarial loss: 0.553178\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319322; batch adversarial loss: 0.554193\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320969; batch adversarial loss: 0.588792\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390476; batch adversarial loss: 0.554442\n",
      "epoch 152; iter: 0; batch classifier loss: 0.276348; batch adversarial loss: 0.553787\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335055; batch adversarial loss: 0.499203\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346867; batch adversarial loss: 0.517217\n",
      "epoch 155; iter: 0; batch classifier loss: 0.421716; batch adversarial loss: 0.561977\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382568; batch adversarial loss: 0.608143\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385354; batch adversarial loss: 0.516596\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336484; batch adversarial loss: 0.572090\n",
      "epoch 159; iter: 0; batch classifier loss: 0.423017; batch adversarial loss: 0.615052\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345709; batch adversarial loss: 0.545555\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400172; batch adversarial loss: 0.482649\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348754; batch adversarial loss: 0.616510\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373829; batch adversarial loss: 0.528545\n",
      "epoch 164; iter: 0; batch classifier loss: 0.382428; batch adversarial loss: 0.590374\n",
      "epoch 165; iter: 0; batch classifier loss: 0.337178; batch adversarial loss: 0.543110\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377098; batch adversarial loss: 0.580609\n",
      "epoch 167; iter: 0; batch classifier loss: 0.404729; batch adversarial loss: 0.571887\n",
      "epoch 168; iter: 0; batch classifier loss: 0.445250; batch adversarial loss: 0.499914\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302692; batch adversarial loss: 0.581503\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404160; batch adversarial loss: 0.561843\n",
      "epoch 171; iter: 0; batch classifier loss: 0.376039; batch adversarial loss: 0.589313\n",
      "epoch 172; iter: 0; batch classifier loss: 0.329909; batch adversarial loss: 0.498622\n",
      "epoch 173; iter: 0; batch classifier loss: 0.450948; batch adversarial loss: 0.588636\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345031; batch adversarial loss: 0.535182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322066; batch adversarial loss: 0.590370\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387095; batch adversarial loss: 0.553422\n",
      "epoch 177; iter: 0; batch classifier loss: 0.399115; batch adversarial loss: 0.526307\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330426; batch adversarial loss: 0.581838\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321094; batch adversarial loss: 0.561465\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326420; batch adversarial loss: 0.608435\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337472; batch adversarial loss: 0.598772\n",
      "epoch 182; iter: 0; batch classifier loss: 0.491111; batch adversarial loss: 0.634279\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342315; batch adversarial loss: 0.606472\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366054; batch adversarial loss: 0.589257\n",
      "epoch 185; iter: 0; batch classifier loss: 0.439301; batch adversarial loss: 0.561833\n",
      "epoch 186; iter: 0; batch classifier loss: 0.289286; batch adversarial loss: 0.624486\n",
      "epoch 187; iter: 0; batch classifier loss: 0.331734; batch adversarial loss: 0.482671\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385853; batch adversarial loss: 0.545529\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376473; batch adversarial loss: 0.572518\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349250; batch adversarial loss: 0.571933\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389032; batch adversarial loss: 0.535732\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359187; batch adversarial loss: 0.579540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378431; batch adversarial loss: 0.597127\n",
      "epoch 194; iter: 0; batch classifier loss: 0.309788; batch adversarial loss: 0.519393\n",
      "epoch 195; iter: 0; batch classifier loss: 0.292927; batch adversarial loss: 0.555017\n",
      "epoch 196; iter: 0; batch classifier loss: 0.384269; batch adversarial loss: 0.508595\n",
      "epoch 197; iter: 0; batch classifier loss: 0.416563; batch adversarial loss: 0.552952\n",
      "epoch 198; iter: 0; batch classifier loss: 0.294802; batch adversarial loss: 0.553744\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351679; batch adversarial loss: 0.526110\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658450; batch adversarial loss: 0.827837\n",
      "epoch 1; iter: 0; batch classifier loss: 0.797167; batch adversarial loss: 1.181591\n",
      "epoch 2; iter: 0; batch classifier loss: 1.199707; batch adversarial loss: 1.246312\n",
      "epoch 3; iter: 0; batch classifier loss: 1.081856; batch adversarial loss: 1.080910\n",
      "epoch 4; iter: 0; batch classifier loss: 1.141807; batch adversarial loss: 1.045091\n",
      "epoch 5; iter: 0; batch classifier loss: 1.298839; batch adversarial loss: 0.958474\n",
      "epoch 6; iter: 0; batch classifier loss: 1.298536; batch adversarial loss: 0.887118\n",
      "epoch 7; iter: 0; batch classifier loss: 1.109376; batch adversarial loss: 0.818734\n",
      "epoch 8; iter: 0; batch classifier loss: 1.212116; batch adversarial loss: 0.761125\n",
      "epoch 9; iter: 0; batch classifier loss: 1.101762; batch adversarial loss: 0.740462\n",
      "epoch 10; iter: 0; batch classifier loss: 1.204347; batch adversarial loss: 0.681164\n",
      "epoch 11; iter: 0; batch classifier loss: 0.858693; batch adversarial loss: 0.618493\n",
      "epoch 12; iter: 0; batch classifier loss: 0.690401; batch adversarial loss: 0.643919\n",
      "epoch 13; iter: 0; batch classifier loss: 0.603484; batch adversarial loss: 0.616923\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601782; batch adversarial loss: 0.612403\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494937; batch adversarial loss: 0.564106\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518812; batch adversarial loss: 0.592436\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496287; batch adversarial loss: 0.572628\n",
      "epoch 18; iter: 0; batch classifier loss: 0.608608; batch adversarial loss: 0.583096\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514391; batch adversarial loss: 0.571034\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506526; batch adversarial loss: 0.530167\n",
      "epoch 21; iter: 0; batch classifier loss: 0.553275; batch adversarial loss: 0.584515\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513553; batch adversarial loss: 0.550464\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488016; batch adversarial loss: 0.597606\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456476; batch adversarial loss: 0.553975\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489687; batch adversarial loss: 0.500542\n",
      "epoch 26; iter: 0; batch classifier loss: 0.579272; batch adversarial loss: 0.561638\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462713; batch adversarial loss: 0.551229\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455032; batch adversarial loss: 0.572868\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449804; batch adversarial loss: 0.540183\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418060; batch adversarial loss: 0.575683\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438268; batch adversarial loss: 0.544501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.452512; batch adversarial loss: 0.470919\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448400; batch adversarial loss: 0.604382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427375; batch adversarial loss: 0.528244\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472794; batch adversarial loss: 0.517456\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496256; batch adversarial loss: 0.536706\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470061; batch adversarial loss: 0.579458\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474011; batch adversarial loss: 0.502351\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439468; batch adversarial loss: 0.531831\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495113; batch adversarial loss: 0.555616\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471371; batch adversarial loss: 0.538652\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446117; batch adversarial loss: 0.512549\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415548; batch adversarial loss: 0.538871\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478187; batch adversarial loss: 0.613993\n",
      "epoch 45; iter: 0; batch classifier loss: 0.410745; batch adversarial loss: 0.606540\n",
      "epoch 46; iter: 0; batch classifier loss: 0.471511; batch adversarial loss: 0.538544\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415929; batch adversarial loss: 0.569308\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509994; batch adversarial loss: 0.513126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437825; batch adversarial loss: 0.605437\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422501; batch adversarial loss: 0.485655\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428899; batch adversarial loss: 0.562781\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469517; batch adversarial loss: 0.562732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429699; batch adversarial loss: 0.570844\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.562456\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445843; batch adversarial loss: 0.622642\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391622; batch adversarial loss: 0.571177\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453554; batch adversarial loss: 0.579392\n",
      "epoch 58; iter: 0; batch classifier loss: 0.345515; batch adversarial loss: 0.545046\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414709; batch adversarial loss: 0.553766\n",
      "epoch 60; iter: 0; batch classifier loss: 0.487070; batch adversarial loss: 0.493130\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417797; batch adversarial loss: 0.528583\n",
      "epoch 62; iter: 0; batch classifier loss: 0.374661; batch adversarial loss: 0.605829\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399676; batch adversarial loss: 0.596696\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407910; batch adversarial loss: 0.510988\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417412; batch adversarial loss: 0.569603\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445335; batch adversarial loss: 0.578596\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436552; batch adversarial loss: 0.569301\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382751; batch adversarial loss: 0.596709\n",
      "epoch 69; iter: 0; batch classifier loss: 0.331189; batch adversarial loss: 0.553660\n",
      "epoch 70; iter: 0; batch classifier loss: 0.472764; batch adversarial loss: 0.657513\n",
      "epoch 71; iter: 0; batch classifier loss: 0.494797; batch adversarial loss: 0.518528\n",
      "epoch 72; iter: 0; batch classifier loss: 0.452382; batch adversarial loss: 0.504916\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436355; batch adversarial loss: 0.553469\n",
      "epoch 74; iter: 0; batch classifier loss: 0.491290; batch adversarial loss: 0.535653\n",
      "epoch 75; iter: 0; batch classifier loss: 0.462771; batch adversarial loss: 0.551013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.509111; batch adversarial loss: 0.542829\n",
      "epoch 77; iter: 0; batch classifier loss: 0.502832; batch adversarial loss: 0.596656\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380086; batch adversarial loss: 0.611920\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394827; batch adversarial loss: 0.589904\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394880; batch adversarial loss: 0.579083\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417862; batch adversarial loss: 0.564096\n",
      "epoch 82; iter: 0; batch classifier loss: 0.279761; batch adversarial loss: 0.458517\n",
      "epoch 83; iter: 0; batch classifier loss: 0.363907; batch adversarial loss: 0.536798\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374714; batch adversarial loss: 0.516758\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344651; batch adversarial loss: 0.570498\n",
      "epoch 86; iter: 0; batch classifier loss: 0.404435; batch adversarial loss: 0.467381\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397735; batch adversarial loss: 0.571236\n",
      "epoch 88; iter: 0; batch classifier loss: 0.338662; batch adversarial loss: 0.595643\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422988; batch adversarial loss: 0.519563\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390920; batch adversarial loss: 0.633454\n",
      "epoch 91; iter: 0; batch classifier loss: 0.459011; batch adversarial loss: 0.509311\n",
      "epoch 92; iter: 0; batch classifier loss: 0.423388; batch adversarial loss: 0.571259\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409435; batch adversarial loss: 0.519111\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437415; batch adversarial loss: 0.564081\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358644; batch adversarial loss: 0.613316\n",
      "epoch 96; iter: 0; batch classifier loss: 0.483955; batch adversarial loss: 0.536728\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362523; batch adversarial loss: 0.508896\n",
      "epoch 98; iter: 0; batch classifier loss: 0.348005; batch adversarial loss: 0.527658\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367167; batch adversarial loss: 0.518701\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394461; batch adversarial loss: 0.545871\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360613; batch adversarial loss: 0.606005\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377965; batch adversarial loss: 0.598870\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346473; batch adversarial loss: 0.576123\n",
      "epoch 104; iter: 0; batch classifier loss: 0.304927; batch adversarial loss: 0.599094\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378135; batch adversarial loss: 0.565094\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387386; batch adversarial loss: 0.567006\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352201; batch adversarial loss: 0.608247\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417169; batch adversarial loss: 0.493709\n",
      "epoch 109; iter: 0; batch classifier loss: 0.323622; batch adversarial loss: 0.571553\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382827; batch adversarial loss: 0.615896\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380612; batch adversarial loss: 0.591218\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394716; batch adversarial loss: 0.562246\n",
      "epoch 113; iter: 0; batch classifier loss: 0.283365; batch adversarial loss: 0.545463\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364502; batch adversarial loss: 0.535268\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341175; batch adversarial loss: 0.510987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357688; batch adversarial loss: 0.632313\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396869; batch adversarial loss: 0.579812\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362476; batch adversarial loss: 0.569239\n",
      "epoch 119; iter: 0; batch classifier loss: 0.330675; batch adversarial loss: 0.602498\n",
      "epoch 120; iter: 0; batch classifier loss: 0.270285; batch adversarial loss: 0.515027\n",
      "epoch 121; iter: 0; batch classifier loss: 0.405796; batch adversarial loss: 0.541989\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366660; batch adversarial loss: 0.553710\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347367; batch adversarial loss: 0.567050\n",
      "epoch 124; iter: 0; batch classifier loss: 0.412458; batch adversarial loss: 0.541416\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377702; batch adversarial loss: 0.526377\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391303; batch adversarial loss: 0.584806\n",
      "epoch 127; iter: 0; batch classifier loss: 0.339959; batch adversarial loss: 0.543162\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330519; batch adversarial loss: 0.619794\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381437; batch adversarial loss: 0.594667\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371957; batch adversarial loss: 0.565859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.345080; batch adversarial loss: 0.581238\n",
      "epoch 132; iter: 0; batch classifier loss: 0.316924; batch adversarial loss: 0.502815\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396758; batch adversarial loss: 0.574523\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381529; batch adversarial loss: 0.591346\n",
      "epoch 135; iter: 0; batch classifier loss: 0.294098; batch adversarial loss: 0.588600\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355642; batch adversarial loss: 0.553681\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414440; batch adversarial loss: 0.580500\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384105; batch adversarial loss: 0.574054\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376884; batch adversarial loss: 0.554033\n",
      "epoch 140; iter: 0; batch classifier loss: 0.292994; batch adversarial loss: 0.578866\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404489; batch adversarial loss: 0.608362\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352907; batch adversarial loss: 0.535187\n",
      "epoch 143; iter: 0; batch classifier loss: 0.311505; batch adversarial loss: 0.591902\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361282; batch adversarial loss: 0.508595\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370352; batch adversarial loss: 0.507819\n",
      "epoch 146; iter: 0; batch classifier loss: 0.398355; batch adversarial loss: 0.580833\n",
      "epoch 147; iter: 0; batch classifier loss: 0.366029; batch adversarial loss: 0.566470\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381683; batch adversarial loss: 0.569391\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373329; batch adversarial loss: 0.475352\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367725; batch adversarial loss: 0.651554\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362978; batch adversarial loss: 0.553637\n",
      "epoch 152; iter: 0; batch classifier loss: 0.296539; batch adversarial loss: 0.516498\n",
      "epoch 153; iter: 0; batch classifier loss: 0.377140; batch adversarial loss: 0.572309\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349750; batch adversarial loss: 0.532723\n",
      "epoch 155; iter: 0; batch classifier loss: 0.426846; batch adversarial loss: 0.551302\n",
      "epoch 156; iter: 0; batch classifier loss: 0.302441; batch adversarial loss: 0.553308\n",
      "epoch 157; iter: 0; batch classifier loss: 0.266199; batch adversarial loss: 0.565322\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372428; batch adversarial loss: 0.551557\n",
      "epoch 159; iter: 0; batch classifier loss: 0.319345; batch adversarial loss: 0.527421\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311007; batch adversarial loss: 0.551734\n",
      "epoch 161; iter: 0; batch classifier loss: 0.263097; batch adversarial loss: 0.523258\n",
      "epoch 162; iter: 0; batch classifier loss: 0.338667; batch adversarial loss: 0.561207\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343279; batch adversarial loss: 0.557215\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333446; batch adversarial loss: 0.564766\n",
      "epoch 165; iter: 0; batch classifier loss: 0.415647; batch adversarial loss: 0.519791\n",
      "epoch 166; iter: 0; batch classifier loss: 0.266429; batch adversarial loss: 0.544797\n",
      "epoch 167; iter: 0; batch classifier loss: 0.322740; batch adversarial loss: 0.560064\n",
      "epoch 168; iter: 0; batch classifier loss: 0.265488; batch adversarial loss: 0.508916\n",
      "epoch 169; iter: 0; batch classifier loss: 0.274494; batch adversarial loss: 0.557224\n",
      "epoch 170; iter: 0; batch classifier loss: 0.387931; batch adversarial loss: 0.636311\n",
      "epoch 171; iter: 0; batch classifier loss: 0.377723; batch adversarial loss: 0.598020\n",
      "epoch 172; iter: 0; batch classifier loss: 0.286861; batch adversarial loss: 0.570844\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313148; batch adversarial loss: 0.560980\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318905; batch adversarial loss: 0.568084\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298847; batch adversarial loss: 0.574844\n",
      "epoch 176; iter: 0; batch classifier loss: 0.345840; batch adversarial loss: 0.557228\n",
      "epoch 177; iter: 0; batch classifier loss: 0.275856; batch adversarial loss: 0.466398\n",
      "epoch 178; iter: 0; batch classifier loss: 0.322514; batch adversarial loss: 0.572431\n",
      "epoch 179; iter: 0; batch classifier loss: 0.262926; batch adversarial loss: 0.553477\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371964; batch adversarial loss: 0.527656\n",
      "epoch 181; iter: 0; batch classifier loss: 0.299611; batch adversarial loss: 0.569873\n",
      "epoch 182; iter: 0; batch classifier loss: 0.279568; batch adversarial loss: 0.583835\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343030; batch adversarial loss: 0.577828\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319061; batch adversarial loss: 0.466771\n",
      "epoch 185; iter: 0; batch classifier loss: 0.309182; batch adversarial loss: 0.516702\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333050; batch adversarial loss: 0.592605\n",
      "epoch 187; iter: 0; batch classifier loss: 0.291318; batch adversarial loss: 0.557217\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338152; batch adversarial loss: 0.480367\n",
      "epoch 189; iter: 0; batch classifier loss: 0.260969; batch adversarial loss: 0.584031\n",
      "epoch 190; iter: 0; batch classifier loss: 0.305101; batch adversarial loss: 0.541919\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305798; batch adversarial loss: 0.594972\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351203; batch adversarial loss: 0.570555\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343024; batch adversarial loss: 0.535168\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316781; batch adversarial loss: 0.550819\n",
      "epoch 195; iter: 0; batch classifier loss: 0.463806; batch adversarial loss: 0.527083\n",
      "epoch 196; iter: 0; batch classifier loss: 0.303686; batch adversarial loss: 0.500701\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332021; batch adversarial loss: 0.569266\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328481; batch adversarial loss: 0.544176\n",
      "epoch 199; iter: 0; batch classifier loss: 0.317939; batch adversarial loss: 0.542549\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713243; batch adversarial loss: 0.815200\n",
      "epoch 1; iter: 0; batch classifier loss: 0.752537; batch adversarial loss: 0.861303\n",
      "epoch 2; iter: 0; batch classifier loss: 0.879339; batch adversarial loss: 0.819170\n",
      "epoch 3; iter: 0; batch classifier loss: 0.920748; batch adversarial loss: 0.763383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.762205; batch adversarial loss: 0.692352\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594776; batch adversarial loss: 0.654483\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561567; batch adversarial loss: 0.604465\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542920; batch adversarial loss: 0.645757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562751; batch adversarial loss: 0.641443\n",
      "epoch 9; iter: 0; batch classifier loss: 0.464930; batch adversarial loss: 0.575679\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469042; batch adversarial loss: 0.584950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562318; batch adversarial loss: 0.569413\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530860; batch adversarial loss: 0.529742\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457491; batch adversarial loss: 0.596467\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516885; batch adversarial loss: 0.566207\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511084; batch adversarial loss: 0.512867\n",
      "epoch 16; iter: 0; batch classifier loss: 0.601216; batch adversarial loss: 0.570804\n",
      "epoch 17; iter: 0; batch classifier loss: 0.446233; batch adversarial loss: 0.599396\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475639; batch adversarial loss: 0.630555\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472363; batch adversarial loss: 0.548159\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494384; batch adversarial loss: 0.541358\n",
      "epoch 21; iter: 0; batch classifier loss: 0.435186; batch adversarial loss: 0.571029\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522550; batch adversarial loss: 0.489345\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509928; batch adversarial loss: 0.476771\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491284; batch adversarial loss: 0.580464\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524814; batch adversarial loss: 0.549574\n",
      "epoch 26; iter: 0; batch classifier loss: 0.571386; batch adversarial loss: 0.622485\n",
      "epoch 27; iter: 0; batch classifier loss: 0.415508; batch adversarial loss: 0.509297\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446524; batch adversarial loss: 0.590768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.448805; batch adversarial loss: 0.575530\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486877; batch adversarial loss: 0.526818\n",
      "epoch 31; iter: 0; batch classifier loss: 0.502499; batch adversarial loss: 0.486964\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451455; batch adversarial loss: 0.535955\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456673; batch adversarial loss: 0.530701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448673; batch adversarial loss: 0.525123\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521814; batch adversarial loss: 0.499019\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479707; batch adversarial loss: 0.512356\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399030; batch adversarial loss: 0.545075\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465036; batch adversarial loss: 0.572498\n",
      "epoch 39; iter: 0; batch classifier loss: 0.518340; batch adversarial loss: 0.453049\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423330; batch adversarial loss: 0.624268\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382746; batch adversarial loss: 0.499970\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469135; batch adversarial loss: 0.561898\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437247; batch adversarial loss: 0.546330\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404718; batch adversarial loss: 0.580266\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384586; batch adversarial loss: 0.492929\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505699; batch adversarial loss: 0.580353\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459748; batch adversarial loss: 0.492001\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429892; batch adversarial loss: 0.439321\n",
      "epoch 49; iter: 0; batch classifier loss: 0.507617; batch adversarial loss: 0.509070\n",
      "epoch 50; iter: 0; batch classifier loss: 0.340716; batch adversarial loss: 0.562226\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458842; batch adversarial loss: 0.545265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446282; batch adversarial loss: 0.552621\n",
      "epoch 53; iter: 0; batch classifier loss: 0.493203; batch adversarial loss: 0.561942\n",
      "epoch 54; iter: 0; batch classifier loss: 0.370544; batch adversarial loss: 0.517755\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453852; batch adversarial loss: 0.651637\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436468; batch adversarial loss: 0.419433\n",
      "epoch 57; iter: 0; batch classifier loss: 0.359213; batch adversarial loss: 0.507787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435479; batch adversarial loss: 0.509238\n",
      "epoch 59; iter: 0; batch classifier loss: 0.336856; batch adversarial loss: 0.446323\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367756; batch adversarial loss: 0.534965\n",
      "epoch 61; iter: 0; batch classifier loss: 0.317220; batch adversarial loss: 0.487964\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392935; batch adversarial loss: 0.553264\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454324; batch adversarial loss: 0.572822\n",
      "epoch 64; iter: 0; batch classifier loss: 0.448314; batch adversarial loss: 0.562238\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400749; batch adversarial loss: 0.561966\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377020; batch adversarial loss: 0.527824\n",
      "epoch 67; iter: 0; batch classifier loss: 0.364211; batch adversarial loss: 0.520129\n",
      "epoch 68; iter: 0; batch classifier loss: 0.369270; batch adversarial loss: 0.527414\n",
      "epoch 69; iter: 0; batch classifier loss: 0.471223; batch adversarial loss: 0.517692\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414116; batch adversarial loss: 0.652166\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432138; batch adversarial loss: 0.516576\n",
      "epoch 72; iter: 0; batch classifier loss: 0.387994; batch adversarial loss: 0.577725\n",
      "epoch 73; iter: 0; batch classifier loss: 0.364079; batch adversarial loss: 0.549159\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430160; batch adversarial loss: 0.525665\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404721; batch adversarial loss: 0.534991\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405037; batch adversarial loss: 0.563290\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413040; batch adversarial loss: 0.534395\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427188; batch adversarial loss: 0.592188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.506195; batch adversarial loss: 0.575836\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420946; batch adversarial loss: 0.591411\n",
      "epoch 81; iter: 0; batch classifier loss: 0.296313; batch adversarial loss: 0.629871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384269; batch adversarial loss: 0.546809\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430758; batch adversarial loss: 0.532612\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412695; batch adversarial loss: 0.538408\n",
      "epoch 85; iter: 0; batch classifier loss: 0.338699; batch adversarial loss: 0.573343\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402155; batch adversarial loss: 0.535252\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412121; batch adversarial loss: 0.500891\n",
      "epoch 88; iter: 0; batch classifier loss: 0.290563; batch adversarial loss: 0.527393\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377256; batch adversarial loss: 0.544091\n",
      "epoch 90; iter: 0; batch classifier loss: 0.429721; batch adversarial loss: 0.654947\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395063; batch adversarial loss: 0.561628\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432740; batch adversarial loss: 0.533435\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363171; batch adversarial loss: 0.599038\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414106; batch adversarial loss: 0.561064\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413806; batch adversarial loss: 0.517635\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380886; batch adversarial loss: 0.518216\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377283; batch adversarial loss: 0.546900\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416202; batch adversarial loss: 0.658695\n",
      "epoch 99; iter: 0; batch classifier loss: 0.330520; batch adversarial loss: 0.541092\n",
      "epoch 100; iter: 0; batch classifier loss: 0.322953; batch adversarial loss: 0.558757\n",
      "epoch 101; iter: 0; batch classifier loss: 0.362505; batch adversarial loss: 0.541101\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353032; batch adversarial loss: 0.565506\n",
      "epoch 103; iter: 0; batch classifier loss: 0.430724; batch adversarial loss: 0.500580\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392673; batch adversarial loss: 0.516493\n",
      "epoch 105; iter: 0; batch classifier loss: 0.367621; batch adversarial loss: 0.506999\n",
      "epoch 106; iter: 0; batch classifier loss: 0.435707; batch adversarial loss: 0.591094\n",
      "epoch 107; iter: 0; batch classifier loss: 0.464011; batch adversarial loss: 0.591142\n",
      "epoch 108; iter: 0; batch classifier loss: 0.418985; batch adversarial loss: 0.561057\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402928; batch adversarial loss: 0.505313\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396232; batch adversarial loss: 0.526652\n",
      "epoch 111; iter: 0; batch classifier loss: 0.397881; batch adversarial loss: 0.507707\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351239; batch adversarial loss: 0.550250\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415830; batch adversarial loss: 0.504779\n",
      "epoch 114; iter: 0; batch classifier loss: 0.277681; batch adversarial loss: 0.594370\n",
      "epoch 115; iter: 0; batch classifier loss: 0.414276; batch adversarial loss: 0.568644\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376741; batch adversarial loss: 0.570244\n",
      "epoch 117; iter: 0; batch classifier loss: 0.363859; batch adversarial loss: 0.578423\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367762; batch adversarial loss: 0.663027\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397668; batch adversarial loss: 0.569110\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398264; batch adversarial loss: 0.602180\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379862; batch adversarial loss: 0.560750\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415660; batch adversarial loss: 0.565804\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334746; batch adversarial loss: 0.628605\n",
      "epoch 124; iter: 0; batch classifier loss: 0.324167; batch adversarial loss: 0.480321\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329463; batch adversarial loss: 0.636072\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368349; batch adversarial loss: 0.518118\n",
      "epoch 127; iter: 0; batch classifier loss: 0.416712; batch adversarial loss: 0.592709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.341259; batch adversarial loss: 0.553656\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413660; batch adversarial loss: 0.560008\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371161; batch adversarial loss: 0.539898\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385001; batch adversarial loss: 0.570867\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.552445\n",
      "epoch 133; iter: 0; batch classifier loss: 0.328078; batch adversarial loss: 0.562696\n",
      "epoch 134; iter: 0; batch classifier loss: 0.273192; batch adversarial loss: 0.472248\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399771; batch adversarial loss: 0.496132\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368203; batch adversarial loss: 0.469042\n",
      "epoch 137; iter: 0; batch classifier loss: 0.304292; batch adversarial loss: 0.552814\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393391; batch adversarial loss: 0.560084\n",
      "epoch 139; iter: 0; batch classifier loss: 0.416481; batch adversarial loss: 0.526665\n",
      "epoch 140; iter: 0; batch classifier loss: 0.305742; batch adversarial loss: 0.527758\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343393; batch adversarial loss: 0.564019\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358072; batch adversarial loss: 0.554718\n",
      "epoch 143; iter: 0; batch classifier loss: 0.444026; batch adversarial loss: 0.565536\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400221; batch adversarial loss: 0.564721\n",
      "epoch 145; iter: 0; batch classifier loss: 0.391894; batch adversarial loss: 0.460458\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370457; batch adversarial loss: 0.598757\n",
      "epoch 147; iter: 0; batch classifier loss: 0.417528; batch adversarial loss: 0.528462\n",
      "epoch 148; iter: 0; batch classifier loss: 0.398308; batch adversarial loss: 0.594507\n",
      "epoch 149; iter: 0; batch classifier loss: 0.435009; batch adversarial loss: 0.558562\n",
      "epoch 150; iter: 0; batch classifier loss: 0.371464; batch adversarial loss: 0.557780\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330396; batch adversarial loss: 0.503953\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355284; batch adversarial loss: 0.497255\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402729; batch adversarial loss: 0.565611\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394771; batch adversarial loss: 0.588374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.310021; batch adversarial loss: 0.529394\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333507; batch adversarial loss: 0.581951\n",
      "epoch 157; iter: 0; batch classifier loss: 0.299521; batch adversarial loss: 0.557317\n",
      "epoch 158; iter: 0; batch classifier loss: 0.458779; batch adversarial loss: 0.552036\n",
      "epoch 159; iter: 0; batch classifier loss: 0.336925; batch adversarial loss: 0.569536\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352598; batch adversarial loss: 0.607045\n",
      "epoch 161; iter: 0; batch classifier loss: 0.371729; batch adversarial loss: 0.523032\n",
      "epoch 162; iter: 0; batch classifier loss: 0.322628; batch adversarial loss: 0.501910\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345861; batch adversarial loss: 0.555170\n",
      "epoch 164; iter: 0; batch classifier loss: 0.433329; batch adversarial loss: 0.503624\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424628; batch adversarial loss: 0.478634\n",
      "epoch 166; iter: 0; batch classifier loss: 0.262951; batch adversarial loss: 0.511481\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383860; batch adversarial loss: 0.509401\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397747; batch adversarial loss: 0.527385\n",
      "epoch 169; iter: 0; batch classifier loss: 0.276232; batch adversarial loss: 0.498947\n",
      "epoch 170; iter: 0; batch classifier loss: 0.264859; batch adversarial loss: 0.579962\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408197; batch adversarial loss: 0.505360\n",
      "epoch 172; iter: 0; batch classifier loss: 0.271617; batch adversarial loss: 0.572254\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329035; batch adversarial loss: 0.519609\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357271; batch adversarial loss: 0.515775\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369904; batch adversarial loss: 0.482450\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320928; batch adversarial loss: 0.554233\n",
      "epoch 177; iter: 0; batch classifier loss: 0.370384; batch adversarial loss: 0.546336\n",
      "epoch 178; iter: 0; batch classifier loss: 0.302559; batch adversarial loss: 0.539856\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369854; batch adversarial loss: 0.600938\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316567; batch adversarial loss: 0.454022\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357603; batch adversarial loss: 0.563554\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382160; batch adversarial loss: 0.523432\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310168; batch adversarial loss: 0.525746\n",
      "epoch 184; iter: 0; batch classifier loss: 0.420878; batch adversarial loss: 0.542714\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364342; batch adversarial loss: 0.547359\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359832; batch adversarial loss: 0.576796\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388603; batch adversarial loss: 0.548457\n",
      "epoch 188; iter: 0; batch classifier loss: 0.457607; batch adversarial loss: 0.629964\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352870; batch adversarial loss: 0.548209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368299; batch adversarial loss: 0.540522\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364773; batch adversarial loss: 0.599583\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368048; batch adversarial loss: 0.520484\n",
      "epoch 193; iter: 0; batch classifier loss: 0.290408; batch adversarial loss: 0.527860\n",
      "epoch 194; iter: 0; batch classifier loss: 0.416015; batch adversarial loss: 0.497755\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397901; batch adversarial loss: 0.454629\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347167; batch adversarial loss: 0.580253\n",
      "epoch 197; iter: 0; batch classifier loss: 0.343862; batch adversarial loss: 0.563530\n",
      "epoch 198; iter: 0; batch classifier loss: 0.367753; batch adversarial loss: 0.444313\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345625; batch adversarial loss: 0.663078\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728734; batch adversarial loss: 0.690615\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580773; batch adversarial loss: 0.633190\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567769; batch adversarial loss: 0.633998\n",
      "epoch 3; iter: 0; batch classifier loss: 0.662292; batch adversarial loss: 0.620517\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583157; batch adversarial loss: 0.602376\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534167; batch adversarial loss: 0.595252\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559247; batch adversarial loss: 0.597538\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564438; batch adversarial loss: 0.590537\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542344; batch adversarial loss: 0.577261\n",
      "epoch 9; iter: 0; batch classifier loss: 0.622954; batch adversarial loss: 0.580160\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535237; batch adversarial loss: 0.578489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528747; batch adversarial loss: 0.625360\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501173; batch adversarial loss: 0.607891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490525; batch adversarial loss: 0.651819\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456127; batch adversarial loss: 0.657474\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536284; batch adversarial loss: 0.545010\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548050; batch adversarial loss: 0.582340\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462730; batch adversarial loss: 0.562427\n",
      "epoch 18; iter: 0; batch classifier loss: 0.415952; batch adversarial loss: 0.525329\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500448; batch adversarial loss: 0.566601\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451638; batch adversarial loss: 0.528068\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512939; batch adversarial loss: 0.528059\n",
      "epoch 22; iter: 0; batch classifier loss: 0.448457; batch adversarial loss: 0.531256\n",
      "epoch 23; iter: 0; batch classifier loss: 0.434836; batch adversarial loss: 0.595850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.488940; batch adversarial loss: 0.564683\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440920; batch adversarial loss: 0.557070\n",
      "epoch 26; iter: 0; batch classifier loss: 0.550722; batch adversarial loss: 0.611396\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474807; batch adversarial loss: 0.547498\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422280; batch adversarial loss: 0.562749\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462806; batch adversarial loss: 0.620725\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427580; batch adversarial loss: 0.587809\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436166; batch adversarial loss: 0.495076\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457221; batch adversarial loss: 0.477175\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440353; batch adversarial loss: 0.536677\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509459; batch adversarial loss: 0.492819\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443426; batch adversarial loss: 0.579743\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435729; batch adversarial loss: 0.544791\n",
      "epoch 37; iter: 0; batch classifier loss: 0.384229; batch adversarial loss: 0.553566\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462994; batch adversarial loss: 0.509515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513232; batch adversarial loss: 0.518318\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447727; batch adversarial loss: 0.553597\n",
      "epoch 41; iter: 0; batch classifier loss: 0.494564; batch adversarial loss: 0.580372\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464057; batch adversarial loss: 0.509052\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400468; batch adversarial loss: 0.553578\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474693; batch adversarial loss: 0.561877\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394914; batch adversarial loss: 0.517367\n",
      "epoch 46; iter: 0; batch classifier loss: 0.343410; batch adversarial loss: 0.586739\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411838; batch adversarial loss: 0.483156\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428070; batch adversarial loss: 0.533403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401259; batch adversarial loss: 0.555207\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399211; batch adversarial loss: 0.606225\n",
      "epoch 51; iter: 0; batch classifier loss: 0.504211; batch adversarial loss: 0.507673\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465081; batch adversarial loss: 0.560650\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411048; batch adversarial loss: 0.542955\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437899; batch adversarial loss: 0.514396\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402212; batch adversarial loss: 0.498804\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441238; batch adversarial loss: 0.556371\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424997; batch adversarial loss: 0.630060\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421746; batch adversarial loss: 0.554705\n",
      "epoch 59; iter: 0; batch classifier loss: 0.486737; batch adversarial loss: 0.563269\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427247; batch adversarial loss: 0.582518\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399467; batch adversarial loss: 0.525878\n",
      "epoch 62; iter: 0; batch classifier loss: 0.368047; batch adversarial loss: 0.507498\n",
      "epoch 63; iter: 0; batch classifier loss: 0.470750; batch adversarial loss: 0.507614\n",
      "epoch 64; iter: 0; batch classifier loss: 0.493494; batch adversarial loss: 0.599815\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380505; batch adversarial loss: 0.608146\n",
      "epoch 66; iter: 0; batch classifier loss: 0.361494; batch adversarial loss: 0.480514\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361150; batch adversarial loss: 0.598298\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396728; batch adversarial loss: 0.472564\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390043; batch adversarial loss: 0.491266\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415859; batch adversarial loss: 0.446138\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433440; batch adversarial loss: 0.517447\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401510; batch adversarial loss: 0.499367\n",
      "epoch 73; iter: 0; batch classifier loss: 0.536992; batch adversarial loss: 0.653683\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413213; batch adversarial loss: 0.626169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393949; batch adversarial loss: 0.590108\n",
      "epoch 76; iter: 0; batch classifier loss: 0.340440; batch adversarial loss: 0.525924\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412974; batch adversarial loss: 0.614741\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366849; batch adversarial loss: 0.590459\n",
      "epoch 79; iter: 0; batch classifier loss: 0.333945; batch adversarial loss: 0.563016\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401571; batch adversarial loss: 0.535623\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397514; batch adversarial loss: 0.517551\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396392; batch adversarial loss: 0.562888\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356242; batch adversarial loss: 0.581024\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412024; batch adversarial loss: 0.580818\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401510; batch adversarial loss: 0.553418\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373986; batch adversarial loss: 0.563828\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423626; batch adversarial loss: 0.634916\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423959; batch adversarial loss: 0.552995\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363525; batch adversarial loss: 0.526129\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397381; batch adversarial loss: 0.598766\n",
      "epoch 91; iter: 0; batch classifier loss: 0.497221; batch adversarial loss: 0.544887\n",
      "epoch 92; iter: 0; batch classifier loss: 0.456047; batch adversarial loss: 0.589183\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367170; batch adversarial loss: 0.598613\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405299; batch adversarial loss: 0.598948\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398735; batch adversarial loss: 0.527526\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371965; batch adversarial loss: 0.563475\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420215; batch adversarial loss: 0.590562\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396813; batch adversarial loss: 0.535224\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400292; batch adversarial loss: 0.570185\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420387; batch adversarial loss: 0.571382\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407373; batch adversarial loss: 0.571035\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383259; batch adversarial loss: 0.545093\n",
      "epoch 103; iter: 0; batch classifier loss: 0.370124; batch adversarial loss: 0.561017\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358695; batch adversarial loss: 0.562905\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398381; batch adversarial loss: 0.545341\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326855; batch adversarial loss: 0.509320\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388130; batch adversarial loss: 0.491207\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395495; batch adversarial loss: 0.661911\n",
      "epoch 109; iter: 0; batch classifier loss: 0.444298; batch adversarial loss: 0.481071\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396890; batch adversarial loss: 0.608422\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363586; batch adversarial loss: 0.543592\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360398; batch adversarial loss: 0.617453\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384602; batch adversarial loss: 0.491333\n",
      "epoch 114; iter: 0; batch classifier loss: 0.451969; batch adversarial loss: 0.590507\n",
      "epoch 115; iter: 0; batch classifier loss: 0.450074; batch adversarial loss: 0.546017\n",
      "epoch 116; iter: 0; batch classifier loss: 0.319949; batch adversarial loss: 0.554748\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338167; batch adversarial loss: 0.586256\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354716; batch adversarial loss: 0.581088\n",
      "epoch 119; iter: 0; batch classifier loss: 0.393081; batch adversarial loss: 0.543840\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399081; batch adversarial loss: 0.571420\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393930; batch adversarial loss: 0.580916\n",
      "epoch 122; iter: 0; batch classifier loss: 0.322766; batch adversarial loss: 0.579213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.335824; batch adversarial loss: 0.588323\n",
      "epoch 124; iter: 0; batch classifier loss: 0.463834; batch adversarial loss: 0.598534\n",
      "epoch 125; iter: 0; batch classifier loss: 0.378897; batch adversarial loss: 0.616055\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350840; batch adversarial loss: 0.483778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382601; batch adversarial loss: 0.488933\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397628; batch adversarial loss: 0.553433\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364165; batch adversarial loss: 0.561458\n",
      "epoch 130; iter: 0; batch classifier loss: 0.431421; batch adversarial loss: 0.572222\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337471; batch adversarial loss: 0.562829\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343024; batch adversarial loss: 0.534063\n",
      "epoch 133; iter: 0; batch classifier loss: 0.489889; batch adversarial loss: 0.499419\n",
      "epoch 134; iter: 0; batch classifier loss: 0.294598; batch adversarial loss: 0.463451\n",
      "epoch 135; iter: 0; batch classifier loss: 0.299513; batch adversarial loss: 0.545747\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341198; batch adversarial loss: 0.534984\n",
      "epoch 137; iter: 0; batch classifier loss: 0.315306; batch adversarial loss: 0.507105\n",
      "epoch 138; iter: 0; batch classifier loss: 0.410894; batch adversarial loss: 0.526313\n",
      "epoch 139; iter: 0; batch classifier loss: 0.436426; batch adversarial loss: 0.553610\n",
      "epoch 140; iter: 0; batch classifier loss: 0.462543; batch adversarial loss: 0.517639\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398355; batch adversarial loss: 0.571301\n",
      "epoch 142; iter: 0; batch classifier loss: 0.474405; batch adversarial loss: 0.471696\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342269; batch adversarial loss: 0.490213\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369300; batch adversarial loss: 0.463841\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404843; batch adversarial loss: 0.563595\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403950; batch adversarial loss: 0.472782\n",
      "epoch 147; iter: 0; batch classifier loss: 0.309155; batch adversarial loss: 0.554499\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343165; batch adversarial loss: 0.555430\n",
      "epoch 149; iter: 0; batch classifier loss: 0.321691; batch adversarial loss: 0.552362\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325401; batch adversarial loss: 0.516557\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352359; batch adversarial loss: 0.572861\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349977; batch adversarial loss: 0.597292\n",
      "epoch 153; iter: 0; batch classifier loss: 0.375778; batch adversarial loss: 0.554548\n",
      "epoch 154; iter: 0; batch classifier loss: 0.392686; batch adversarial loss: 0.515978\n",
      "epoch 155; iter: 0; batch classifier loss: 0.315941; batch adversarial loss: 0.588553\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359735; batch adversarial loss: 0.553050\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391877; batch adversarial loss: 0.553554\n",
      "epoch 158; iter: 0; batch classifier loss: 0.422613; batch adversarial loss: 0.544176\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387584; batch adversarial loss: 0.573229\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300195; batch adversarial loss: 0.543566\n",
      "epoch 161; iter: 0; batch classifier loss: 0.435474; batch adversarial loss: 0.552878\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358490; batch adversarial loss: 0.517905\n",
      "epoch 163; iter: 0; batch classifier loss: 0.447784; batch adversarial loss: 0.571100\n",
      "epoch 164; iter: 0; batch classifier loss: 0.411579; batch adversarial loss: 0.581266\n",
      "epoch 165; iter: 0; batch classifier loss: 0.273897; batch adversarial loss: 0.561910\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356246; batch adversarial loss: 0.643270\n",
      "epoch 167; iter: 0; batch classifier loss: 0.389636; batch adversarial loss: 0.544869\n",
      "epoch 168; iter: 0; batch classifier loss: 0.334055; batch adversarial loss: 0.490147\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349412; batch adversarial loss: 0.608776\n",
      "epoch 170; iter: 0; batch classifier loss: 0.405840; batch adversarial loss: 0.489686\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403376; batch adversarial loss: 0.544833\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373700; batch adversarial loss: 0.573158\n",
      "epoch 173; iter: 0; batch classifier loss: 0.287080; batch adversarial loss: 0.536353\n",
      "epoch 174; iter: 0; batch classifier loss: 0.332534; batch adversarial loss: 0.499664\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366644; batch adversarial loss: 0.545080\n",
      "epoch 176; iter: 0; batch classifier loss: 0.403510; batch adversarial loss: 0.572296\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351477; batch adversarial loss: 0.490937\n",
      "epoch 178; iter: 0; batch classifier loss: 0.290384; batch adversarial loss: 0.492270\n",
      "epoch 179; iter: 0; batch classifier loss: 0.398093; batch adversarial loss: 0.444707\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331831; batch adversarial loss: 0.499064\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353784; batch adversarial loss: 0.624731\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390744; batch adversarial loss: 0.508132\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353187; batch adversarial loss: 0.617710\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381340; batch adversarial loss: 0.526432\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354914; batch adversarial loss: 0.597939\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343250; batch adversarial loss: 0.518347\n",
      "epoch 187; iter: 0; batch classifier loss: 0.311728; batch adversarial loss: 0.571716\n",
      "epoch 188; iter: 0; batch classifier loss: 0.389675; batch adversarial loss: 0.572143\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297829; batch adversarial loss: 0.553341\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358362; batch adversarial loss: 0.568900\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325121; batch adversarial loss: 0.544858\n",
      "epoch 192; iter: 0; batch classifier loss: 0.440706; batch adversarial loss: 0.535833\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353453; batch adversarial loss: 0.598088\n",
      "epoch 194; iter: 0; batch classifier loss: 0.320567; batch adversarial loss: 0.554922\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350599; batch adversarial loss: 0.560340\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370326; batch adversarial loss: 0.534420\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342380; batch adversarial loss: 0.617172\n",
      "epoch 198; iter: 0; batch classifier loss: 0.454282; batch adversarial loss: 0.589822\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372921; batch adversarial loss: 0.607667\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728175; batch adversarial loss: 0.844859\n",
      "epoch 1; iter: 0; batch classifier loss: 0.788339; batch adversarial loss: 0.892450\n",
      "epoch 2; iter: 0; batch classifier loss: 0.780585; batch adversarial loss: 0.850796\n",
      "epoch 3; iter: 0; batch classifier loss: 0.874213; batch adversarial loss: 0.778705\n",
      "epoch 4; iter: 0; batch classifier loss: 0.738366; batch adversarial loss: 0.710197\n",
      "epoch 5; iter: 0; batch classifier loss: 0.629657; batch adversarial loss: 0.665881\n",
      "epoch 6; iter: 0; batch classifier loss: 0.503185; batch adversarial loss: 0.630633\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601278; batch adversarial loss: 0.616249\n",
      "epoch 8; iter: 0; batch classifier loss: 0.597473; batch adversarial loss: 0.598694\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480955; batch adversarial loss: 0.562168\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564032; batch adversarial loss: 0.604867\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580986; batch adversarial loss: 0.570253\n",
      "epoch 12; iter: 0; batch classifier loss: 0.573493; batch adversarial loss: 0.559605\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583387; batch adversarial loss: 0.591127\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544267; batch adversarial loss: 0.577450\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526942; batch adversarial loss: 0.524688\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537287; batch adversarial loss: 0.574311\n",
      "epoch 17; iter: 0; batch classifier loss: 0.564773; batch adversarial loss: 0.559116\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534768; batch adversarial loss: 0.596426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500856; batch adversarial loss: 0.542855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.560636; batch adversarial loss: 0.543668\n",
      "epoch 21; iter: 0; batch classifier loss: 0.438353; batch adversarial loss: 0.550965\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454473; batch adversarial loss: 0.548192\n",
      "epoch 23; iter: 0; batch classifier loss: 0.557465; batch adversarial loss: 0.535379\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503985; batch adversarial loss: 0.544515\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473458; batch adversarial loss: 0.527563\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566098; batch adversarial loss: 0.580350\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414704; batch adversarial loss: 0.508177\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504582; batch adversarial loss: 0.542418\n",
      "epoch 29; iter: 0; batch classifier loss: 0.403592; batch adversarial loss: 0.572420\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493544; batch adversarial loss: 0.554059\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451165; batch adversarial loss: 0.587924\n",
      "epoch 32; iter: 0; batch classifier loss: 0.413708; batch adversarial loss: 0.583091\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520098; batch adversarial loss: 0.581619\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425852; batch adversarial loss: 0.573141\n",
      "epoch 35; iter: 0; batch classifier loss: 0.618186; batch adversarial loss: 0.507523\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515885; batch adversarial loss: 0.529533\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469368; batch adversarial loss: 0.538807\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424281; batch adversarial loss: 0.578909\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458779; batch adversarial loss: 0.529203\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421569; batch adversarial loss: 0.469241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.495275; batch adversarial loss: 0.595462\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483587; batch adversarial loss: 0.494946\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424374; batch adversarial loss: 0.476102\n",
      "epoch 44; iter: 0; batch classifier loss: 0.555690; batch adversarial loss: 0.587991\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477502; batch adversarial loss: 0.622298\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432980; batch adversarial loss: 0.571056\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473682; batch adversarial loss: 0.526892\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421104; batch adversarial loss: 0.536126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.560989; batch adversarial loss: 0.562266\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418659; batch adversarial loss: 0.561712\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432976; batch adversarial loss: 0.580075\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427945; batch adversarial loss: 0.571957\n",
      "epoch 53; iter: 0; batch classifier loss: 0.398524; batch adversarial loss: 0.484246\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445227; batch adversarial loss: 0.597381\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400045; batch adversarial loss: 0.597650\n",
      "epoch 56; iter: 0; batch classifier loss: 0.474328; batch adversarial loss: 0.606598\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370871; batch adversarial loss: 0.580306\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390882; batch adversarial loss: 0.580364\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426456; batch adversarial loss: 0.606154\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384261; batch adversarial loss: 0.518352\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425537; batch adversarial loss: 0.598172\n",
      "epoch 62; iter: 0; batch classifier loss: 0.349583; batch adversarial loss: 0.518072\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420037; batch adversarial loss: 0.597825\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402005; batch adversarial loss: 0.588389\n",
      "epoch 65; iter: 0; batch classifier loss: 0.583559; batch adversarial loss: 0.624694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436862; batch adversarial loss: 0.535918\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358397; batch adversarial loss: 0.545186\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460353; batch adversarial loss: 0.518183\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368139; batch adversarial loss: 0.527300\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418048; batch adversarial loss: 0.500621\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394492; batch adversarial loss: 0.553387\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433394; batch adversarial loss: 0.517853\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403232; batch adversarial loss: 0.650783\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416608; batch adversarial loss: 0.659448\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433201; batch adversarial loss: 0.606348\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363360; batch adversarial loss: 0.500178\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419800; batch adversarial loss: 0.545889\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378372; batch adversarial loss: 0.598656\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350737; batch adversarial loss: 0.491351\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409974; batch adversarial loss: 0.473640\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414330; batch adversarial loss: 0.535881\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435810; batch adversarial loss: 0.536523\n",
      "epoch 83; iter: 0; batch classifier loss: 0.436421; batch adversarial loss: 0.589122\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356330; batch adversarial loss: 0.578813\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369942; batch adversarial loss: 0.536240\n",
      "epoch 86; iter: 0; batch classifier loss: 0.487535; batch adversarial loss: 0.641391\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.483024\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400217; batch adversarial loss: 0.536214\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340268; batch adversarial loss: 0.614580\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345530; batch adversarial loss: 0.516721\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389715; batch adversarial loss: 0.500074\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365125; batch adversarial loss: 0.536163\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393141; batch adversarial loss: 0.536260\n",
      "epoch 94; iter: 0; batch classifier loss: 0.395524; batch adversarial loss: 0.579309\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451460; batch adversarial loss: 0.597566\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328657; batch adversarial loss: 0.544638\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350527; batch adversarial loss: 0.616034\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356821; batch adversarial loss: 0.518936\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415306; batch adversarial loss: 0.502053\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404804; batch adversarial loss: 0.535206\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347399; batch adversarial loss: 0.545030\n",
      "epoch 102; iter: 0; batch classifier loss: 0.432618; batch adversarial loss: 0.607090\n",
      "epoch 103; iter: 0; batch classifier loss: 0.439959; batch adversarial loss: 0.632781\n",
      "epoch 104; iter: 0; batch classifier loss: 0.394445; batch adversarial loss: 0.554498\n",
      "epoch 105; iter: 0; batch classifier loss: 0.464842; batch adversarial loss: 0.615641\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372434; batch adversarial loss: 0.651384\n",
      "epoch 107; iter: 0; batch classifier loss: 0.317237; batch adversarial loss: 0.579514\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367743; batch adversarial loss: 0.526206\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370792; batch adversarial loss: 0.563144\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378292; batch adversarial loss: 0.500514\n",
      "epoch 111; iter: 0; batch classifier loss: 0.437198; batch adversarial loss: 0.544082\n",
      "epoch 112; iter: 0; batch classifier loss: 0.344927; batch adversarial loss: 0.534985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.473876; batch adversarial loss: 0.491279\n",
      "epoch 114; iter: 0; batch classifier loss: 0.529881; batch adversarial loss: 0.571961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.324592; batch adversarial loss: 0.562464\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405953; batch adversarial loss: 0.606059\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415902; batch adversarial loss: 0.517272\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338623; batch adversarial loss: 0.544153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.367114; batch adversarial loss: 0.570745\n",
      "epoch 120; iter: 0; batch classifier loss: 0.392044; batch adversarial loss: 0.527099\n",
      "epoch 121; iter: 0; batch classifier loss: 0.336983; batch adversarial loss: 0.580373\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330420; batch adversarial loss: 0.552767\n",
      "epoch 123; iter: 0; batch classifier loss: 0.321143; batch adversarial loss: 0.536897\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364462; batch adversarial loss: 0.597872\n",
      "epoch 125; iter: 0; batch classifier loss: 0.353904; batch adversarial loss: 0.562507\n",
      "epoch 126; iter: 0; batch classifier loss: 0.335958; batch adversarial loss: 0.544421\n",
      "epoch 127; iter: 0; batch classifier loss: 0.314866; batch adversarial loss: 0.659567\n",
      "epoch 128; iter: 0; batch classifier loss: 0.347387; batch adversarial loss: 0.597189\n",
      "epoch 129; iter: 0; batch classifier loss: 0.300059; batch adversarial loss: 0.588819\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375084; batch adversarial loss: 0.544878\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374156; batch adversarial loss: 0.590229\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318892; batch adversarial loss: 0.516562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360055; batch adversarial loss: 0.544175\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363695; batch adversarial loss: 0.569541\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312033; batch adversarial loss: 0.527484\n",
      "epoch 136; iter: 0; batch classifier loss: 0.314824; batch adversarial loss: 0.526363\n",
      "epoch 137; iter: 0; batch classifier loss: 0.310868; batch adversarial loss: 0.571278\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369462; batch adversarial loss: 0.590255\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360556; batch adversarial loss: 0.552740\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390149; batch adversarial loss: 0.589314\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375003; batch adversarial loss: 0.552392\n",
      "epoch 142; iter: 0; batch classifier loss: 0.366229; batch adversarial loss: 0.508943\n",
      "epoch 143; iter: 0; batch classifier loss: 0.321741; batch adversarial loss: 0.570914\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338452; batch adversarial loss: 0.589149\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359619; batch adversarial loss: 0.553682\n",
      "epoch 146; iter: 0; batch classifier loss: 0.391531; batch adversarial loss: 0.642462\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345930; batch adversarial loss: 0.555145\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310821; batch adversarial loss: 0.529309\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335650; batch adversarial loss: 0.552269\n",
      "epoch 150; iter: 0; batch classifier loss: 0.343805; batch adversarial loss: 0.573171\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326973; batch adversarial loss: 0.596828\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372801; batch adversarial loss: 0.652484\n",
      "epoch 153; iter: 0; batch classifier loss: 0.299919; batch adversarial loss: 0.569822\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343324; batch adversarial loss: 0.587440\n",
      "epoch 155; iter: 0; batch classifier loss: 0.368770; batch adversarial loss: 0.643456\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347527; batch adversarial loss: 0.578905\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366357; batch adversarial loss: 0.547162\n",
      "epoch 158; iter: 0; batch classifier loss: 0.394223; batch adversarial loss: 0.448414\n",
      "epoch 159; iter: 0; batch classifier loss: 0.405942; batch adversarial loss: 0.624773\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352240; batch adversarial loss: 0.635136\n",
      "epoch 161; iter: 0; batch classifier loss: 0.276115; batch adversarial loss: 0.545722\n",
      "epoch 162; iter: 0; batch classifier loss: 0.403724; batch adversarial loss: 0.492453\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382047; batch adversarial loss: 0.561992\n",
      "epoch 164; iter: 0; batch classifier loss: 0.260832; batch adversarial loss: 0.519281\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333156; batch adversarial loss: 0.553810\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389945; batch adversarial loss: 0.632472\n",
      "epoch 167; iter: 0; batch classifier loss: 0.244365; batch adversarial loss: 0.545686\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329710; batch adversarial loss: 0.525511\n",
      "epoch 169; iter: 0; batch classifier loss: 0.305901; batch adversarial loss: 0.545103\n",
      "epoch 170; iter: 0; batch classifier loss: 0.390927; batch adversarial loss: 0.581692\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359254; batch adversarial loss: 0.615794\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384103; batch adversarial loss: 0.607926\n",
      "epoch 173; iter: 0; batch classifier loss: 0.314622; batch adversarial loss: 0.571545\n",
      "epoch 174; iter: 0; batch classifier loss: 0.337782; batch adversarial loss: 0.508431\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365591; batch adversarial loss: 0.596977\n",
      "epoch 176; iter: 0; batch classifier loss: 0.283044; batch adversarial loss: 0.659289\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330324; batch adversarial loss: 0.552533\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358694; batch adversarial loss: 0.606069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356122; batch adversarial loss: 0.597837\n",
      "epoch 180; iter: 0; batch classifier loss: 0.314302; batch adversarial loss: 0.588725\n",
      "epoch 181; iter: 0; batch classifier loss: 0.279730; batch adversarial loss: 0.587454\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344744; batch adversarial loss: 0.482652\n",
      "epoch 183; iter: 0; batch classifier loss: 0.242970; batch adversarial loss: 0.552127\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389455; batch adversarial loss: 0.578148\n",
      "epoch 185; iter: 0; batch classifier loss: 0.385851; batch adversarial loss: 0.472786\n",
      "epoch 186; iter: 0; batch classifier loss: 0.283642; batch adversarial loss: 0.517469\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375116; batch adversarial loss: 0.617254\n",
      "epoch 188; iter: 0; batch classifier loss: 0.349873; batch adversarial loss: 0.555064\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343775; batch adversarial loss: 0.554872\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323055; batch adversarial loss: 0.644976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355646; batch adversarial loss: 0.530160\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362472; batch adversarial loss: 0.562519\n",
      "epoch 193; iter: 0; batch classifier loss: 0.410155; batch adversarial loss: 0.606851\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372673; batch adversarial loss: 0.535179\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354046; batch adversarial loss: 0.524932\n",
      "epoch 196; iter: 0; batch classifier loss: 0.337615; batch adversarial loss: 0.553553\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329169; batch adversarial loss: 0.589993\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360748; batch adversarial loss: 0.563856\n",
      "epoch 199; iter: 0; batch classifier loss: 0.426409; batch adversarial loss: 0.589019\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760897; batch adversarial loss: 0.987163\n",
      "epoch 1; iter: 0; batch classifier loss: 0.899586; batch adversarial loss: 1.088874\n",
      "epoch 2; iter: 0; batch classifier loss: 0.988997; batch adversarial loss: 1.007276\n",
      "epoch 3; iter: 0; batch classifier loss: 1.048363; batch adversarial loss: 0.946888\n",
      "epoch 4; iter: 0; batch classifier loss: 1.167777; batch adversarial loss: 0.931977\n",
      "epoch 5; iter: 0; batch classifier loss: 0.838657; batch adversarial loss: 0.767650\n",
      "epoch 6; iter: 0; batch classifier loss: 0.823190; batch adversarial loss: 0.742554\n",
      "epoch 7; iter: 0; batch classifier loss: 0.703526; batch adversarial loss: 0.688315\n",
      "epoch 8; iter: 0; batch classifier loss: 0.638741; batch adversarial loss: 0.630808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560676; batch adversarial loss: 0.675781\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543493; batch adversarial loss: 0.632387\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563687; batch adversarial loss: 0.620936\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587370; batch adversarial loss: 0.587120\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539335; batch adversarial loss: 0.581227\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573773; batch adversarial loss: 0.555032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.528758; batch adversarial loss: 0.577794\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521297; batch adversarial loss: 0.581724\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557352; batch adversarial loss: 0.480093\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505406; batch adversarial loss: 0.555156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537739; batch adversarial loss: 0.530926\n",
      "epoch 20; iter: 0; batch classifier loss: 0.531265; batch adversarial loss: 0.562059\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468819; batch adversarial loss: 0.548983\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509261; batch adversarial loss: 0.519522\n",
      "epoch 23; iter: 0; batch classifier loss: 0.573326; batch adversarial loss: 0.540938\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484940; batch adversarial loss: 0.559402\n",
      "epoch 25; iter: 0; batch classifier loss: 0.550223; batch adversarial loss: 0.528957\n",
      "epoch 26; iter: 0; batch classifier loss: 0.539868; batch adversarial loss: 0.525189\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459900; batch adversarial loss: 0.580445\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487743; batch adversarial loss: 0.544051\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460575; batch adversarial loss: 0.554364\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472951; batch adversarial loss: 0.485344\n",
      "epoch 31; iter: 0; batch classifier loss: 0.522269; batch adversarial loss: 0.527404\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478060; batch adversarial loss: 0.524488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475354; batch adversarial loss: 0.572382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.519630; batch adversarial loss: 0.571428\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444045; batch adversarial loss: 0.495141\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418905; batch adversarial loss: 0.590832\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449968; batch adversarial loss: 0.608940\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453694; batch adversarial loss: 0.558162\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480346; batch adversarial loss: 0.531612\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495778; batch adversarial loss: 0.590471\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430892; batch adversarial loss: 0.555295\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402045; batch adversarial loss: 0.554292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.472654; batch adversarial loss: 0.555895\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511761; batch adversarial loss: 0.566214\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377673; batch adversarial loss: 0.576433\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414261; batch adversarial loss: 0.536683\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425634; batch adversarial loss: 0.559163\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445963; batch adversarial loss: 0.473482\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451742; batch adversarial loss: 0.511361\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404545; batch adversarial loss: 0.580797\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413355; batch adversarial loss: 0.517456\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400963; batch adversarial loss: 0.488055\n",
      "epoch 53; iter: 0; batch classifier loss: 0.475029; batch adversarial loss: 0.517904\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430881; batch adversarial loss: 0.608865\n",
      "epoch 55; iter: 0; batch classifier loss: 0.519820; batch adversarial loss: 0.563828\n",
      "epoch 56; iter: 0; batch classifier loss: 0.522532; batch adversarial loss: 0.500582\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421530; batch adversarial loss: 0.544438\n",
      "epoch 58; iter: 0; batch classifier loss: 0.336896; batch adversarial loss: 0.573558\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417623; batch adversarial loss: 0.545357\n",
      "epoch 60; iter: 0; batch classifier loss: 0.415542; batch adversarial loss: 0.590798\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403961; batch adversarial loss: 0.545078\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436471; batch adversarial loss: 0.637732\n",
      "epoch 63; iter: 0; batch classifier loss: 0.323150; batch adversarial loss: 0.591026\n",
      "epoch 64; iter: 0; batch classifier loss: 0.461823; batch adversarial loss: 0.590874\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411404; batch adversarial loss: 0.469956\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443339; batch adversarial loss: 0.516507\n",
      "epoch 67; iter: 0; batch classifier loss: 0.455513; batch adversarial loss: 0.581161\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400586; batch adversarial loss: 0.536238\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403260; batch adversarial loss: 0.508653\n",
      "epoch 70; iter: 0; batch classifier loss: 0.469027; batch adversarial loss: 0.509885\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386706; batch adversarial loss: 0.489393\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478400; batch adversarial loss: 0.552431\n",
      "epoch 73; iter: 0; batch classifier loss: 0.473871; batch adversarial loss: 0.498754\n",
      "epoch 74; iter: 0; batch classifier loss: 0.292236; batch adversarial loss: 0.515851\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395508; batch adversarial loss: 0.552830\n",
      "epoch 76; iter: 0; batch classifier loss: 0.334477; batch adversarial loss: 0.508259\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427717; batch adversarial loss: 0.548021\n",
      "epoch 78; iter: 0; batch classifier loss: 0.474297; batch adversarial loss: 0.536862\n",
      "epoch 79; iter: 0; batch classifier loss: 0.363029; batch adversarial loss: 0.564517\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421900; batch adversarial loss: 0.553552\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385727; batch adversarial loss: 0.624709\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396444; batch adversarial loss: 0.507788\n",
      "epoch 83; iter: 0; batch classifier loss: 0.350155; batch adversarial loss: 0.586148\n",
      "epoch 84; iter: 0; batch classifier loss: 0.358195; batch adversarial loss: 0.544355\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456383; batch adversarial loss: 0.463742\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451640; batch adversarial loss: 0.550423\n",
      "epoch 87; iter: 0; batch classifier loss: 0.425701; batch adversarial loss: 0.464092\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414633; batch adversarial loss: 0.517084\n",
      "epoch 89; iter: 0; batch classifier loss: 0.476016; batch adversarial loss: 0.448718\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403573; batch adversarial loss: 0.531644\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452336; batch adversarial loss: 0.506840\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397455; batch adversarial loss: 0.583489\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441424; batch adversarial loss: 0.469117\n",
      "epoch 94; iter: 0; batch classifier loss: 0.450592; batch adversarial loss: 0.558058\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362338; batch adversarial loss: 0.506679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418928; batch adversarial loss: 0.633333\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384989; batch adversarial loss: 0.544180\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416017; batch adversarial loss: 0.535117\n",
      "epoch 99; iter: 0; batch classifier loss: 0.370546; batch adversarial loss: 0.478837\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413640; batch adversarial loss: 0.541443\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382135; batch adversarial loss: 0.614639\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374550; batch adversarial loss: 0.504725\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361289; batch adversarial loss: 0.477615\n",
      "epoch 104; iter: 0; batch classifier loss: 0.491483; batch adversarial loss: 0.496620\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368461; batch adversarial loss: 0.586415\n",
      "epoch 106; iter: 0; batch classifier loss: 0.433795; batch adversarial loss: 0.590858\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368518; batch adversarial loss: 0.548845\n",
      "epoch 108; iter: 0; batch classifier loss: 0.356353; batch adversarial loss: 0.442704\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433005; batch adversarial loss: 0.528695\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383639; batch adversarial loss: 0.518072\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418177; batch adversarial loss: 0.554324\n",
      "epoch 112; iter: 0; batch classifier loss: 0.343267; batch adversarial loss: 0.604239\n",
      "epoch 113; iter: 0; batch classifier loss: 0.365103; batch adversarial loss: 0.425915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.372358; batch adversarial loss: 0.618004\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428384; batch adversarial loss: 0.563936\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350163; batch adversarial loss: 0.513214\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377815; batch adversarial loss: 0.489511\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357176; batch adversarial loss: 0.540170\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410590; batch adversarial loss: 0.561277\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406044; batch adversarial loss: 0.462007\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404137; batch adversarial loss: 0.577558\n",
      "epoch 122; iter: 0; batch classifier loss: 0.344877; batch adversarial loss: 0.509592\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370512; batch adversarial loss: 0.614870\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348243; batch adversarial loss: 0.471294\n",
      "epoch 125; iter: 0; batch classifier loss: 0.315837; batch adversarial loss: 0.573841\n",
      "epoch 126; iter: 0; batch classifier loss: 0.439289; batch adversarial loss: 0.569493\n",
      "epoch 127; iter: 0; batch classifier loss: 0.335772; batch adversarial loss: 0.593456\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322113; batch adversarial loss: 0.544229\n",
      "epoch 129; iter: 0; batch classifier loss: 0.366997; batch adversarial loss: 0.632280\n",
      "epoch 130; iter: 0; batch classifier loss: 0.464021; batch adversarial loss: 0.497367\n",
      "epoch 131; iter: 0; batch classifier loss: 0.409606; batch adversarial loss: 0.574826\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373538; batch adversarial loss: 0.546249\n",
      "epoch 133; iter: 0; batch classifier loss: 0.385229; batch adversarial loss: 0.490579\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367974; batch adversarial loss: 0.603600\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357848; batch adversarial loss: 0.518685\n",
      "epoch 136; iter: 0; batch classifier loss: 0.304351; batch adversarial loss: 0.496038\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369950; batch adversarial loss: 0.618211\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348775; batch adversarial loss: 0.491515\n",
      "epoch 139; iter: 0; batch classifier loss: 0.331995; batch adversarial loss: 0.504784\n",
      "epoch 140; iter: 0; batch classifier loss: 0.432181; batch adversarial loss: 0.507815\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411366; batch adversarial loss: 0.495965\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331376; batch adversarial loss: 0.546812\n",
      "epoch 143; iter: 0; batch classifier loss: 0.336274; batch adversarial loss: 0.515547\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349251; batch adversarial loss: 0.538569\n",
      "epoch 145; iter: 0; batch classifier loss: 0.321486; batch adversarial loss: 0.497807\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359471; batch adversarial loss: 0.649015\n",
      "epoch 147; iter: 0; batch classifier loss: 0.323567; batch adversarial loss: 0.565199\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374938; batch adversarial loss: 0.540117\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396575; batch adversarial loss: 0.506281\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339557; batch adversarial loss: 0.547392\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365746; batch adversarial loss: 0.478900\n",
      "epoch 152; iter: 0; batch classifier loss: 0.409788; batch adversarial loss: 0.584722\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380728; batch adversarial loss: 0.563589\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384703; batch adversarial loss: 0.514718\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355684; batch adversarial loss: 0.526729\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370069; batch adversarial loss: 0.609033\n",
      "epoch 157; iter: 0; batch classifier loss: 0.415050; batch adversarial loss: 0.497666\n",
      "epoch 158; iter: 0; batch classifier loss: 0.297955; batch adversarial loss: 0.440416\n",
      "epoch 159; iter: 0; batch classifier loss: 0.439260; batch adversarial loss: 0.580700\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323909; batch adversarial loss: 0.591689\n",
      "epoch 161; iter: 0; batch classifier loss: 0.353040; batch adversarial loss: 0.524212\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374738; batch adversarial loss: 0.528759\n",
      "epoch 163; iter: 0; batch classifier loss: 0.291360; batch adversarial loss: 0.587775\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341357; batch adversarial loss: 0.555354\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369565; batch adversarial loss: 0.569834\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354410; batch adversarial loss: 0.551062\n",
      "epoch 167; iter: 0; batch classifier loss: 0.459946; batch adversarial loss: 0.486511\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361444; batch adversarial loss: 0.569814\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366312; batch adversarial loss: 0.561914\n",
      "epoch 170; iter: 0; batch classifier loss: 0.442942; batch adversarial loss: 0.532809\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364667; batch adversarial loss: 0.601423\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330737; batch adversarial loss: 0.549108\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382357; batch adversarial loss: 0.493957\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376546; batch adversarial loss: 0.526028\n",
      "epoch 175; iter: 0; batch classifier loss: 0.358126; batch adversarial loss: 0.573060\n",
      "epoch 176; iter: 0; batch classifier loss: 0.431066; batch adversarial loss: 0.513641\n",
      "epoch 177; iter: 0; batch classifier loss: 0.271604; batch adversarial loss: 0.494215\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307793; batch adversarial loss: 0.488509\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321881; batch adversarial loss: 0.625592\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336435; batch adversarial loss: 0.504829\n",
      "epoch 181; iter: 0; batch classifier loss: 0.372444; batch adversarial loss: 0.542179\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382193; batch adversarial loss: 0.530542\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398846; batch adversarial loss: 0.537907\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381961; batch adversarial loss: 0.599199\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366460; batch adversarial loss: 0.495163\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361347; batch adversarial loss: 0.585251\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362165; batch adversarial loss: 0.627517\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361034; batch adversarial loss: 0.563016\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346612; batch adversarial loss: 0.529114\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366269; batch adversarial loss: 0.606900\n",
      "epoch 191; iter: 0; batch classifier loss: 0.361111; batch adversarial loss: 0.577352\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352313; batch adversarial loss: 0.500485\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326124; batch adversarial loss: 0.486102\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419632; batch adversarial loss: 0.575940\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302623; batch adversarial loss: 0.567315\n",
      "epoch 196; iter: 0; batch classifier loss: 0.447295; batch adversarial loss: 0.565335\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368481; batch adversarial loss: 0.511374\n",
      "epoch 198; iter: 0; batch classifier loss: 0.413117; batch adversarial loss: 0.493903\n",
      "epoch 199; iter: 0; batch classifier loss: 0.289499; batch adversarial loss: 0.519034\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722737; batch adversarial loss: 0.837707\n",
      "epoch 1; iter: 0; batch classifier loss: 0.656094; batch adversarial loss: 0.793480\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581975; batch adversarial loss: 0.777471\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617702; batch adversarial loss: 0.709255\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614807; batch adversarial loss: 0.675317\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577782; batch adversarial loss: 0.654998\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569681; batch adversarial loss: 0.647575\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536696; batch adversarial loss: 0.622181\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588026; batch adversarial loss: 0.655808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472636; batch adversarial loss: 0.616919\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496548; batch adversarial loss: 0.592368\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534371; batch adversarial loss: 0.592109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.460896; batch adversarial loss: 0.590527\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516496; batch adversarial loss: 0.572349\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462672; batch adversarial loss: 0.596823\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534747; batch adversarial loss: 0.600350\n",
      "epoch 16; iter: 0; batch classifier loss: 0.573399; batch adversarial loss: 0.564163\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559279; batch adversarial loss: 0.551266\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540471; batch adversarial loss: 0.535834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508755; batch adversarial loss: 0.513269\n",
      "epoch 20; iter: 0; batch classifier loss: 0.443130; batch adversarial loss: 0.633996\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478572; batch adversarial loss: 0.548907\n",
      "epoch 22; iter: 0; batch classifier loss: 0.435106; batch adversarial loss: 0.585011\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519263; batch adversarial loss: 0.641885\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493589; batch adversarial loss: 0.534912\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510231; batch adversarial loss: 0.582369\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428941; batch adversarial loss: 0.552322\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491958; batch adversarial loss: 0.617564\n",
      "epoch 28; iter: 0; batch classifier loss: 0.403512; batch adversarial loss: 0.551025\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.541728\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487605; batch adversarial loss: 0.541020\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464834; batch adversarial loss: 0.551322\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452578; batch adversarial loss: 0.600947\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462496; batch adversarial loss: 0.569156\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430869; batch adversarial loss: 0.619605\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432717; batch adversarial loss: 0.552209\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439955; batch adversarial loss: 0.530924\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431339; batch adversarial loss: 0.551368\n",
      "epoch 38; iter: 0; batch classifier loss: 0.551006; batch adversarial loss: 0.639376\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503563; batch adversarial loss: 0.622287\n",
      "epoch 40; iter: 0; batch classifier loss: 0.526237; batch adversarial loss: 0.546865\n",
      "epoch 41; iter: 0; batch classifier loss: 0.540163; batch adversarial loss: 0.519354\n",
      "epoch 42; iter: 0; batch classifier loss: 0.525091; batch adversarial loss: 0.552204\n",
      "epoch 43; iter: 0; batch classifier loss: 0.490200; batch adversarial loss: 0.589356\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462320; batch adversarial loss: 0.537094\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419354; batch adversarial loss: 0.648727\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419967; batch adversarial loss: 0.589080\n",
      "epoch 47; iter: 0; batch classifier loss: 0.387885; batch adversarial loss: 0.563498\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411610; batch adversarial loss: 0.526174\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432494; batch adversarial loss: 0.538939\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457142; batch adversarial loss: 0.586738\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445722; batch adversarial loss: 0.553145\n",
      "epoch 52; iter: 0; batch classifier loss: 0.506118; batch adversarial loss: 0.607445\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456198; batch adversarial loss: 0.439615\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395724; batch adversarial loss: 0.615785\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394208; batch adversarial loss: 0.563032\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414939; batch adversarial loss: 0.598787\n",
      "epoch 57; iter: 0; batch classifier loss: 0.460118; batch adversarial loss: 0.582228\n",
      "epoch 58; iter: 0; batch classifier loss: 0.383161; batch adversarial loss: 0.650125\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422884; batch adversarial loss: 0.535381\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422781; batch adversarial loss: 0.588826\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428679; batch adversarial loss: 0.545766\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446759; batch adversarial loss: 0.525439\n",
      "epoch 63; iter: 0; batch classifier loss: 0.546391; batch adversarial loss: 0.579286\n",
      "epoch 64; iter: 0; batch classifier loss: 0.344656; batch adversarial loss: 0.660223\n",
      "epoch 65; iter: 0; batch classifier loss: 0.405683; batch adversarial loss: 0.528382\n",
      "epoch 66; iter: 0; batch classifier loss: 0.328888; batch adversarial loss: 0.555299\n",
      "epoch 67; iter: 0; batch classifier loss: 0.498569; batch adversarial loss: 0.484326\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409235; batch adversarial loss: 0.554894\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355900; batch adversarial loss: 0.581270\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392267; batch adversarial loss: 0.570790\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431130; batch adversarial loss: 0.615587\n",
      "epoch 72; iter: 0; batch classifier loss: 0.480466; batch adversarial loss: 0.570831\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405190; batch adversarial loss: 0.492252\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465772; batch adversarial loss: 0.580975\n",
      "epoch 75; iter: 0; batch classifier loss: 0.392094; batch adversarial loss: 0.568864\n",
      "epoch 76; iter: 0; batch classifier loss: 0.426946; batch adversarial loss: 0.563302\n",
      "epoch 77; iter: 0; batch classifier loss: 0.445539; batch adversarial loss: 0.615299\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351236; batch adversarial loss: 0.588366\n",
      "epoch 79; iter: 0; batch classifier loss: 0.441562; batch adversarial loss: 0.552584\n",
      "epoch 80; iter: 0; batch classifier loss: 0.372180; batch adversarial loss: 0.579006\n",
      "epoch 81; iter: 0; batch classifier loss: 0.444973; batch adversarial loss: 0.578663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417352; batch adversarial loss: 0.525024\n",
      "epoch 83; iter: 0; batch classifier loss: 0.350494; batch adversarial loss: 0.614716\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393736; batch adversarial loss: 0.472414\n",
      "epoch 85; iter: 0; batch classifier loss: 0.452302; batch adversarial loss: 0.568921\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400420; batch adversarial loss: 0.538866\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394792; batch adversarial loss: 0.561693\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388379; batch adversarial loss: 0.521219\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340615; batch adversarial loss: 0.591128\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383181; batch adversarial loss: 0.510690\n",
      "epoch 91; iter: 0; batch classifier loss: 0.477354; batch adversarial loss: 0.554057\n",
      "epoch 92; iter: 0; batch classifier loss: 0.470425; batch adversarial loss: 0.543900\n",
      "epoch 93; iter: 0; batch classifier loss: 0.475781; batch adversarial loss: 0.508466\n",
      "epoch 94; iter: 0; batch classifier loss: 0.386609; batch adversarial loss: 0.491119\n",
      "epoch 95; iter: 0; batch classifier loss: 0.388661; batch adversarial loss: 0.526656\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372289; batch adversarial loss: 0.574232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.397928; batch adversarial loss: 0.526474\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389379; batch adversarial loss: 0.535378\n",
      "epoch 99; iter: 0; batch classifier loss: 0.405568; batch adversarial loss: 0.554373\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421382; batch adversarial loss: 0.525328\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388176; batch adversarial loss: 0.586938\n",
      "epoch 102; iter: 0; batch classifier loss: 0.456345; batch adversarial loss: 0.490156\n",
      "epoch 103; iter: 0; batch classifier loss: 0.467710; batch adversarial loss: 0.633711\n",
      "epoch 104; iter: 0; batch classifier loss: 0.367113; batch adversarial loss: 0.536024\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407369; batch adversarial loss: 0.475463\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334706; batch adversarial loss: 0.502110\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377582; batch adversarial loss: 0.588193\n",
      "epoch 108; iter: 0; batch classifier loss: 0.431016; batch adversarial loss: 0.453952\n",
      "epoch 109; iter: 0; batch classifier loss: 0.466918; batch adversarial loss: 0.571303\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401532; batch adversarial loss: 0.580570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.338756; batch adversarial loss: 0.525247\n",
      "epoch 112; iter: 0; batch classifier loss: 0.437242; batch adversarial loss: 0.541852\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368919; batch adversarial loss: 0.571668\n",
      "epoch 114; iter: 0; batch classifier loss: 0.333314; batch adversarial loss: 0.535381\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331139; batch adversarial loss: 0.474013\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368115; batch adversarial loss: 0.592231\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402644; batch adversarial loss: 0.505611\n",
      "epoch 118; iter: 0; batch classifier loss: 0.387309; batch adversarial loss: 0.553756\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392606; batch adversarial loss: 0.543783\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362728; batch adversarial loss: 0.603438\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351515; batch adversarial loss: 0.562899\n",
      "epoch 122; iter: 0; batch classifier loss: 0.446026; batch adversarial loss: 0.545629\n",
      "epoch 123; iter: 0; batch classifier loss: 0.287738; batch adversarial loss: 0.531013\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393514; batch adversarial loss: 0.528081\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382083; batch adversarial loss: 0.578503\n",
      "epoch 126; iter: 0; batch classifier loss: 0.349482; batch adversarial loss: 0.554348\n",
      "epoch 127; iter: 0; batch classifier loss: 0.467818; batch adversarial loss: 0.607292\n",
      "epoch 128; iter: 0; batch classifier loss: 0.421645; batch adversarial loss: 0.551773\n",
      "epoch 129; iter: 0; batch classifier loss: 0.435250; batch adversarial loss: 0.544289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.381775; batch adversarial loss: 0.624143\n",
      "epoch 131; iter: 0; batch classifier loss: 0.278437; batch adversarial loss: 0.626634\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318334; batch adversarial loss: 0.499969\n",
      "epoch 133; iter: 0; batch classifier loss: 0.308905; batch adversarial loss: 0.562132\n",
      "epoch 134; iter: 0; batch classifier loss: 0.410555; batch adversarial loss: 0.625398\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338285; batch adversarial loss: 0.606755\n",
      "epoch 136; iter: 0; batch classifier loss: 0.352088; batch adversarial loss: 0.525867\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368670; batch adversarial loss: 0.568287\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379024; batch adversarial loss: 0.552296\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403823; batch adversarial loss: 0.572617\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377567; batch adversarial loss: 0.587937\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398611; batch adversarial loss: 0.559632\n",
      "epoch 142; iter: 0; batch classifier loss: 0.323362; batch adversarial loss: 0.520407\n",
      "epoch 143; iter: 0; batch classifier loss: 0.393609; batch adversarial loss: 0.572477\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390507; batch adversarial loss: 0.479838\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351281; batch adversarial loss: 0.565448\n",
      "epoch 146; iter: 0; batch classifier loss: 0.458463; batch adversarial loss: 0.505119\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372705; batch adversarial loss: 0.518250\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365711; batch adversarial loss: 0.518105\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329101; batch adversarial loss: 0.613025\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363552; batch adversarial loss: 0.555698\n",
      "epoch 151; iter: 0; batch classifier loss: 0.413504; batch adversarial loss: 0.588560\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347067; batch adversarial loss: 0.528083\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389352; batch adversarial loss: 0.567745\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356947; batch adversarial loss: 0.587388\n",
      "epoch 155; iter: 0; batch classifier loss: 0.432622; batch adversarial loss: 0.572200\n",
      "epoch 156; iter: 0; batch classifier loss: 0.426484; batch adversarial loss: 0.610577\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314533; batch adversarial loss: 0.550854\n",
      "epoch 158; iter: 0; batch classifier loss: 0.456300; batch adversarial loss: 0.517545\n",
      "epoch 159; iter: 0; batch classifier loss: 0.381873; batch adversarial loss: 0.469931\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350204; batch adversarial loss: 0.553898\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380654; batch adversarial loss: 0.533701\n",
      "epoch 162; iter: 0; batch classifier loss: 0.317098; batch adversarial loss: 0.516310\n",
      "epoch 163; iter: 0; batch classifier loss: 0.440021; batch adversarial loss: 0.588268\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344985; batch adversarial loss: 0.625944\n",
      "epoch 165; iter: 0; batch classifier loss: 0.411181; batch adversarial loss: 0.489592\n",
      "epoch 166; iter: 0; batch classifier loss: 0.408540; batch adversarial loss: 0.581202\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398232; batch adversarial loss: 0.643419\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357318; batch adversarial loss: 0.534860\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334821; batch adversarial loss: 0.538609\n",
      "epoch 170; iter: 0; batch classifier loss: 0.484782; batch adversarial loss: 0.507275\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343698; batch adversarial loss: 0.535865\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362525; batch adversarial loss: 0.606730\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383518; batch adversarial loss: 0.568798\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355706; batch adversarial loss: 0.533935\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349053; batch adversarial loss: 0.525134\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327598; batch adversarial loss: 0.560300\n",
      "epoch 177; iter: 0; batch classifier loss: 0.341220; batch adversarial loss: 0.588185\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336622; batch adversarial loss: 0.553766\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308615; batch adversarial loss: 0.627744\n",
      "epoch 180; iter: 0; batch classifier loss: 0.409454; batch adversarial loss: 0.526897\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331060; batch adversarial loss: 0.492068\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344688; batch adversarial loss: 0.518629\n",
      "epoch 183; iter: 0; batch classifier loss: 0.430404; batch adversarial loss: 0.473709\n",
      "epoch 184; iter: 0; batch classifier loss: 0.415379; batch adversarial loss: 0.534654\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358102; batch adversarial loss: 0.573312\n",
      "epoch 186; iter: 0; batch classifier loss: 0.370247; batch adversarial loss: 0.582199\n",
      "epoch 187; iter: 0; batch classifier loss: 0.432144; batch adversarial loss: 0.552010\n",
      "epoch 188; iter: 0; batch classifier loss: 0.320227; batch adversarial loss: 0.550057\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356888; batch adversarial loss: 0.578946\n",
      "epoch 190; iter: 0; batch classifier loss: 0.364234; batch adversarial loss: 0.570593\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366521; batch adversarial loss: 0.555187\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319844; batch adversarial loss: 0.571589\n",
      "epoch 193; iter: 0; batch classifier loss: 0.411694; batch adversarial loss: 0.638626\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342864; batch adversarial loss: 0.578793\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379928; batch adversarial loss: 0.484843\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338265; batch adversarial loss: 0.508532\n",
      "epoch 197; iter: 0; batch classifier loss: 0.423718; batch adversarial loss: 0.570557\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329632; batch adversarial loss: 0.578765\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365492; batch adversarial loss: 0.519033\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713491; batch adversarial loss: 0.658246\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615636; batch adversarial loss: 0.632564\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594263; batch adversarial loss: 0.622127\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568566; batch adversarial loss: 0.630634\n",
      "epoch 4; iter: 0; batch classifier loss: 0.666934; batch adversarial loss: 0.587442\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530025; batch adversarial loss: 0.606923\n",
      "epoch 6; iter: 0; batch classifier loss: 0.470482; batch adversarial loss: 0.599412\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602115; batch adversarial loss: 0.639032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.459536; batch adversarial loss: 0.606303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565846; batch adversarial loss: 0.646818\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573407; batch adversarial loss: 0.609172\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554957; batch adversarial loss: 0.605456\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527376; batch adversarial loss: 0.559328\n",
      "epoch 13; iter: 0; batch classifier loss: 0.632007; batch adversarial loss: 0.579381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510709; batch adversarial loss: 0.562705\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544887; batch adversarial loss: 0.631400\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492217; batch adversarial loss: 0.514995\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468720; batch adversarial loss: 0.553464\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506860; batch adversarial loss: 0.565424\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474150; batch adversarial loss: 0.594568\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462299; batch adversarial loss: 0.640052\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488880; batch adversarial loss: 0.544049\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437967; batch adversarial loss: 0.513835\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504365; batch adversarial loss: 0.602952\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455069; batch adversarial loss: 0.563961\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455547; batch adversarial loss: 0.516029\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424611; batch adversarial loss: 0.572532\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460741; batch adversarial loss: 0.547497\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481712; batch adversarial loss: 0.517442\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413460; batch adversarial loss: 0.555478\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506157; batch adversarial loss: 0.594541\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455069; batch adversarial loss: 0.535184\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468433; batch adversarial loss: 0.588291\n",
      "epoch 33; iter: 0; batch classifier loss: 0.529813; batch adversarial loss: 0.577410\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456384; batch adversarial loss: 0.501802\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420104; batch adversarial loss: 0.623305\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432598; batch adversarial loss: 0.553244\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387275; batch adversarial loss: 0.545921\n",
      "epoch 38; iter: 0; batch classifier loss: 0.397460; batch adversarial loss: 0.622751\n",
      "epoch 39; iter: 0; batch classifier loss: 0.379283; batch adversarial loss: 0.472021\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468480; batch adversarial loss: 0.534147\n",
      "epoch 41; iter: 0; batch classifier loss: 0.435601; batch adversarial loss: 0.473996\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450014; batch adversarial loss: 0.561492\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397709; batch adversarial loss: 0.563635\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428129; batch adversarial loss: 0.588643\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456492; batch adversarial loss: 0.549378\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480309; batch adversarial loss: 0.571533\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434358; batch adversarial loss: 0.543259\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411072; batch adversarial loss: 0.491265\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451346; batch adversarial loss: 0.670535\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465280; batch adversarial loss: 0.598452\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440894; batch adversarial loss: 0.544809\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421309; batch adversarial loss: 0.552911\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402371; batch adversarial loss: 0.508396\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433709; batch adversarial loss: 0.562105\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413810; batch adversarial loss: 0.536493\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447841; batch adversarial loss: 0.544292\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412563; batch adversarial loss: 0.553149\n",
      "epoch 58; iter: 0; batch classifier loss: 0.493614; batch adversarial loss: 0.535279\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422130; batch adversarial loss: 0.571481\n",
      "epoch 60; iter: 0; batch classifier loss: 0.407644; batch adversarial loss: 0.535078\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 0.553334\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432743; batch adversarial loss: 0.563804\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369985; batch adversarial loss: 0.499148\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354248; batch adversarial loss: 0.517883\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406246; batch adversarial loss: 0.545439\n",
      "epoch 66; iter: 0; batch classifier loss: 0.400051; batch adversarial loss: 0.525369\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411422; batch adversarial loss: 0.553312\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363127; batch adversarial loss: 0.581698\n",
      "epoch 69; iter: 0; batch classifier loss: 0.349878; batch adversarial loss: 0.490426\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379694; batch adversarial loss: 0.526012\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399674; batch adversarial loss: 0.517540\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388295; batch adversarial loss: 0.490870\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389226; batch adversarial loss: 0.652645\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356274; batch adversarial loss: 0.553782\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403239; batch adversarial loss: 0.491064\n",
      "epoch 76; iter: 0; batch classifier loss: 0.480608; batch adversarial loss: 0.480683\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401445; batch adversarial loss: 0.535546\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441472; batch adversarial loss: 0.544684\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425486; batch adversarial loss: 0.562778\n",
      "epoch 80; iter: 0; batch classifier loss: 0.348038; batch adversarial loss: 0.544356\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395060; batch adversarial loss: 0.616568\n",
      "epoch 82; iter: 0; batch classifier loss: 0.337181; batch adversarial loss: 0.571557\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417511; batch adversarial loss: 0.535049\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412381; batch adversarial loss: 0.607278\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407921; batch adversarial loss: 0.580563\n",
      "epoch 86; iter: 0; batch classifier loss: 0.382325; batch adversarial loss: 0.598702\n",
      "epoch 87; iter: 0; batch classifier loss: 0.468789; batch adversarial loss: 0.598388\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406398; batch adversarial loss: 0.517622\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413157; batch adversarial loss: 0.454949\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456131; batch adversarial loss: 0.580266\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370105; batch adversarial loss: 0.608174\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412257; batch adversarial loss: 0.545394\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451037; batch adversarial loss: 0.526606\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420337; batch adversarial loss: 0.563050\n",
      "epoch 95; iter: 0; batch classifier loss: 0.388638; batch adversarial loss: 0.553672\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377129; batch adversarial loss: 0.626138\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383206; batch adversarial loss: 0.526644\n",
      "epoch 98; iter: 0; batch classifier loss: 0.466469; batch adversarial loss: 0.544662\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381443; batch adversarial loss: 0.481454\n",
      "epoch 100; iter: 0; batch classifier loss: 0.480293; batch adversarial loss: 0.490678\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347485; batch adversarial loss: 0.490685\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332791; batch adversarial loss: 0.580428\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396138; batch adversarial loss: 0.571389\n",
      "epoch 104; iter: 0; batch classifier loss: 0.304435; batch adversarial loss: 0.535750\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400341; batch adversarial loss: 0.526663\n",
      "epoch 106; iter: 0; batch classifier loss: 0.416427; batch adversarial loss: 0.535538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.384114; batch adversarial loss: 0.553547\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421776; batch adversarial loss: 0.562968\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353238; batch adversarial loss: 0.580587\n",
      "epoch 110; iter: 0; batch classifier loss: 0.330303; batch adversarial loss: 0.607482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348950; batch adversarial loss: 0.571578\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375905; batch adversarial loss: 0.535622\n",
      "epoch 113; iter: 0; batch classifier loss: 0.402549; batch adversarial loss: 0.625607\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411245; batch adversarial loss: 0.499662\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381364; batch adversarial loss: 0.589491\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415643; batch adversarial loss: 0.508439\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351955; batch adversarial loss: 0.517623\n",
      "epoch 118; iter: 0; batch classifier loss: 0.388509; batch adversarial loss: 0.562393\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335885; batch adversarial loss: 0.526645\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366155; batch adversarial loss: 0.553274\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362436; batch adversarial loss: 0.625539\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376288; batch adversarial loss: 0.562665\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350829; batch adversarial loss: 0.598549\n",
      "epoch 124; iter: 0; batch classifier loss: 0.459397; batch adversarial loss: 0.526588\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375010; batch adversarial loss: 0.472722\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383550; batch adversarial loss: 0.544530\n",
      "epoch 127; iter: 0; batch classifier loss: 0.420637; batch adversarial loss: 0.562455\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366249; batch adversarial loss: 0.580650\n",
      "epoch 129; iter: 0; batch classifier loss: 0.405907; batch adversarial loss: 0.499588\n",
      "epoch 130; iter: 0; batch classifier loss: 0.427391; batch adversarial loss: 0.589514\n",
      "epoch 131; iter: 0; batch classifier loss: 0.327986; batch adversarial loss: 0.571465\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371861; batch adversarial loss: 0.598806\n",
      "epoch 133; iter: 0; batch classifier loss: 0.400547; batch adversarial loss: 0.516827\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373890; batch adversarial loss: 0.590070\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360198; batch adversarial loss: 0.561480\n",
      "epoch 136; iter: 0; batch classifier loss: 0.355629; batch adversarial loss: 0.563186\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360839; batch adversarial loss: 0.619611\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338073; batch adversarial loss: 0.562315\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360223; batch adversarial loss: 0.569833\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374907; batch adversarial loss: 0.617731\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409482; batch adversarial loss: 0.553438\n",
      "epoch 142; iter: 0; batch classifier loss: 0.308233; batch adversarial loss: 0.517205\n",
      "epoch 143; iter: 0; batch classifier loss: 0.430567; batch adversarial loss: 0.462472\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408737; batch adversarial loss: 0.559007\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385603; batch adversarial loss: 0.472542\n",
      "epoch 146; iter: 0; batch classifier loss: 0.482292; batch adversarial loss: 0.480222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381035; batch adversarial loss: 0.598517\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336999; batch adversarial loss: 0.537760\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343340; batch adversarial loss: 0.526664\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337681; batch adversarial loss: 0.518407\n",
      "epoch 151; iter: 0; batch classifier loss: 0.451118; batch adversarial loss: 0.571517\n",
      "epoch 152; iter: 0; batch classifier loss: 0.288806; batch adversarial loss: 0.526192\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325465; batch adversarial loss: 0.545218\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402923; batch adversarial loss: 0.589206\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360061; batch adversarial loss: 0.598856\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340272; batch adversarial loss: 0.519041\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409504; batch adversarial loss: 0.597503\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336466; batch adversarial loss: 0.534153\n",
      "epoch 159; iter: 0; batch classifier loss: 0.436105; batch adversarial loss: 0.489307\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385818; batch adversarial loss: 0.543655\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372430; batch adversarial loss: 0.561183\n",
      "epoch 162; iter: 0; batch classifier loss: 0.309280; batch adversarial loss: 0.562844\n",
      "epoch 163; iter: 0; batch classifier loss: 0.377156; batch adversarial loss: 0.552636\n",
      "epoch 164; iter: 0; batch classifier loss: 0.380419; batch adversarial loss: 0.515378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373498; batch adversarial loss: 0.524409\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336043; batch adversarial loss: 0.554982\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355096; batch adversarial loss: 0.589493\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378662; batch adversarial loss: 0.590642\n",
      "epoch 169; iter: 0; batch classifier loss: 0.440396; batch adversarial loss: 0.554694\n",
      "epoch 170; iter: 0; batch classifier loss: 0.413705; batch adversarial loss: 0.560936\n",
      "epoch 171; iter: 0; batch classifier loss: 0.318490; batch adversarial loss: 0.501591\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357729; batch adversarial loss: 0.546366\n",
      "epoch 173; iter: 0; batch classifier loss: 0.431072; batch adversarial loss: 0.616409\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326210; batch adversarial loss: 0.534133\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383338; batch adversarial loss: 0.613931\n",
      "epoch 176; iter: 0; batch classifier loss: 0.322175; batch adversarial loss: 0.565133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.320569; batch adversarial loss: 0.527031\n",
      "epoch 178; iter: 0; batch classifier loss: 0.398913; batch adversarial loss: 0.615545\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369360; batch adversarial loss: 0.491260\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375723; batch adversarial loss: 0.590008\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325018; batch adversarial loss: 0.561506\n",
      "epoch 182; iter: 0; batch classifier loss: 0.413196; batch adversarial loss: 0.580329\n",
      "epoch 183; iter: 0; batch classifier loss: 0.294757; batch adversarial loss: 0.552059\n",
      "epoch 184; iter: 0; batch classifier loss: 0.386992; batch adversarial loss: 0.552996\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316706; batch adversarial loss: 0.607782\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373757; batch adversarial loss: 0.560345\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350780; batch adversarial loss: 0.472342\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346864; batch adversarial loss: 0.537011\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335831; batch adversarial loss: 0.532333\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375999; batch adversarial loss: 0.626630\n",
      "epoch 191; iter: 0; batch classifier loss: 0.318739; batch adversarial loss: 0.498242\n",
      "epoch 192; iter: 0; batch classifier loss: 0.451339; batch adversarial loss: 0.572300\n",
      "epoch 193; iter: 0; batch classifier loss: 0.322239; batch adversarial loss: 0.572976\n",
      "epoch 194; iter: 0; batch classifier loss: 0.333910; batch adversarial loss: 0.561516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.286305; batch adversarial loss: 0.492428\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373184; batch adversarial loss: 0.641408\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339513; batch adversarial loss: 0.580591\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332517; batch adversarial loss: 0.581188\n",
      "epoch 199; iter: 0; batch classifier loss: 0.411244; batch adversarial loss: 0.512981\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720081; batch adversarial loss: 0.590206\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629368; batch adversarial loss: 0.633318\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588869; batch adversarial loss: 0.660821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.570293; batch adversarial loss: 0.679773\n",
      "epoch 4; iter: 0; batch classifier loss: 0.609404; batch adversarial loss: 0.626401\n",
      "epoch 5; iter: 0; batch classifier loss: 0.656575; batch adversarial loss: 0.617412\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559341; batch adversarial loss: 0.661561\n",
      "epoch 7; iter: 0; batch classifier loss: 0.627066; batch adversarial loss: 0.646230\n",
      "epoch 8; iter: 0; batch classifier loss: 0.563489; batch adversarial loss: 0.623464\n",
      "epoch 9; iter: 0; batch classifier loss: 0.607408; batch adversarial loss: 0.555372\n",
      "epoch 10; iter: 0; batch classifier loss: 0.459831; batch adversarial loss: 0.609607\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564632; batch adversarial loss: 0.680772\n",
      "epoch 12; iter: 0; batch classifier loss: 0.604086; batch adversarial loss: 0.608721\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552602; batch adversarial loss: 0.515636\n",
      "epoch 14; iter: 0; batch classifier loss: 0.616646; batch adversarial loss: 0.551356\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543290; batch adversarial loss: 0.549870\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475966; batch adversarial loss: 0.639739\n",
      "epoch 17; iter: 0; batch classifier loss: 0.574627; batch adversarial loss: 0.549533\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535800; batch adversarial loss: 0.537591\n",
      "epoch 19; iter: 0; batch classifier loss: 0.420471; batch adversarial loss: 0.524781\n",
      "epoch 20; iter: 0; batch classifier loss: 0.459045; batch adversarial loss: 0.609114\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494961; batch adversarial loss: 0.520343\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530319; batch adversarial loss: 0.518139\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508704; batch adversarial loss: 0.540057\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528931; batch adversarial loss: 0.577938\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487824; batch adversarial loss: 0.514758\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482824; batch adversarial loss: 0.561785\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470183; batch adversarial loss: 0.528666\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512465; batch adversarial loss: 0.612433\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476204; batch adversarial loss: 0.595797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439634; batch adversarial loss: 0.501377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505229; batch adversarial loss: 0.535902\n",
      "epoch 32; iter: 0; batch classifier loss: 0.437462; batch adversarial loss: 0.526705\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457540; batch adversarial loss: 0.650439\n",
      "epoch 34; iter: 0; batch classifier loss: 0.546069; batch adversarial loss: 0.562702\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422454; batch adversarial loss: 0.607985\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476493; batch adversarial loss: 0.562441\n",
      "epoch 37; iter: 0; batch classifier loss: 0.511101; batch adversarial loss: 0.535766\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400689; batch adversarial loss: 0.544609\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435951; batch adversarial loss: 0.526242\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411988; batch adversarial loss: 0.508343\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462461; batch adversarial loss: 0.534385\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438448; batch adversarial loss: 0.500512\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484672; batch adversarial loss: 0.552397\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429429; batch adversarial loss: 0.578943\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423237; batch adversarial loss: 0.598027\n",
      "epoch 46; iter: 0; batch classifier loss: 0.359240; batch adversarial loss: 0.615769\n",
      "epoch 47; iter: 0; batch classifier loss: 0.547260; batch adversarial loss: 0.590157\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372517; batch adversarial loss: 0.517365\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389761; batch adversarial loss: 0.508656\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443454; batch adversarial loss: 0.617386\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468290; batch adversarial loss: 0.609140\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403283; batch adversarial loss: 0.526546\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443773; batch adversarial loss: 0.580804\n",
      "epoch 54; iter: 0; batch classifier loss: 0.476060; batch adversarial loss: 0.571799\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480221; batch adversarial loss: 0.590255\n",
      "epoch 56; iter: 0; batch classifier loss: 0.382744; batch adversarial loss: 0.517185\n",
      "epoch 57; iter: 0; batch classifier loss: 0.518352; batch adversarial loss: 0.509840\n",
      "epoch 58; iter: 0; batch classifier loss: 0.480493; batch adversarial loss: 0.526376\n",
      "epoch 59; iter: 0; batch classifier loss: 0.496795; batch adversarial loss: 0.553884\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411609; batch adversarial loss: 0.525695\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383326; batch adversarial loss: 0.563641\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408545; batch adversarial loss: 0.721441\n",
      "epoch 63; iter: 0; batch classifier loss: 0.452457; batch adversarial loss: 0.551857\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412577; batch adversarial loss: 0.561516\n",
      "epoch 65; iter: 0; batch classifier loss: 0.440817; batch adversarial loss: 0.554694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.384891; batch adversarial loss: 0.503409\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379634; batch adversarial loss: 0.603115\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397859; batch adversarial loss: 0.545365\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383769; batch adversarial loss: 0.535818\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404535; batch adversarial loss: 0.508679\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377168; batch adversarial loss: 0.445411\n",
      "epoch 72; iter: 0; batch classifier loss: 0.508799; batch adversarial loss: 0.572726\n",
      "epoch 73; iter: 0; batch classifier loss: 0.453347; batch adversarial loss: 0.570010\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452351; batch adversarial loss: 0.556022\n",
      "epoch 75; iter: 0; batch classifier loss: 0.458522; batch adversarial loss: 0.607374\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420767; batch adversarial loss: 0.498293\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421116; batch adversarial loss: 0.499832\n",
      "epoch 78; iter: 0; batch classifier loss: 0.466967; batch adversarial loss: 0.534690\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408987; batch adversarial loss: 0.600014\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365779; batch adversarial loss: 0.617529\n",
      "epoch 81; iter: 0; batch classifier loss: 0.482283; batch adversarial loss: 0.516764\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374196; batch adversarial loss: 0.525953\n",
      "epoch 83; iter: 0; batch classifier loss: 0.350140; batch adversarial loss: 0.517844\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430128; batch adversarial loss: 0.482567\n",
      "epoch 85; iter: 0; batch classifier loss: 0.374164; batch adversarial loss: 0.624515\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408055; batch adversarial loss: 0.616628\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385384; batch adversarial loss: 0.525159\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408069; batch adversarial loss: 0.579601\n",
      "epoch 89; iter: 0; batch classifier loss: 0.475160; batch adversarial loss: 0.572020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407596; batch adversarial loss: 0.525987\n",
      "epoch 91; iter: 0; batch classifier loss: 0.435424; batch adversarial loss: 0.471467\n",
      "epoch 92; iter: 0; batch classifier loss: 0.416043; batch adversarial loss: 0.545965\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354103; batch adversarial loss: 0.518384\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376649; batch adversarial loss: 0.533382\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428633; batch adversarial loss: 0.544212\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336898; batch adversarial loss: 0.596741\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379743; batch adversarial loss: 0.614271\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397399; batch adversarial loss: 0.544290\n",
      "epoch 99; iter: 0; batch classifier loss: 0.451306; batch adversarial loss: 0.584234\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374881; batch adversarial loss: 0.534922\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414298; batch adversarial loss: 0.588813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.408851; batch adversarial loss: 0.553232\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396521; batch adversarial loss: 0.461714\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372442; batch adversarial loss: 0.529034\n",
      "epoch 105; iter: 0; batch classifier loss: 0.356213; batch adversarial loss: 0.630419\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443392; batch adversarial loss: 0.526534\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368623; batch adversarial loss: 0.591907\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379410; batch adversarial loss: 0.469809\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402128; batch adversarial loss: 0.461006\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395508; batch adversarial loss: 0.581424\n",
      "epoch 111; iter: 0; batch classifier loss: 0.338453; batch adversarial loss: 0.535373\n",
      "epoch 112; iter: 0; batch classifier loss: 0.373725; batch adversarial loss: 0.516188\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370157; batch adversarial loss: 0.562338\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327994; batch adversarial loss: 0.617612\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332666; batch adversarial loss: 0.554042\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369962; batch adversarial loss: 0.541980\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374761; batch adversarial loss: 0.553341\n",
      "epoch 118; iter: 0; batch classifier loss: 0.415026; batch adversarial loss: 0.515447\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380286; batch adversarial loss: 0.506824\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394743; batch adversarial loss: 0.587397\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381549; batch adversarial loss: 0.559395\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408883; batch adversarial loss: 0.501264\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389912; batch adversarial loss: 0.537600\n",
      "epoch 124; iter: 0; batch classifier loss: 0.388819; batch adversarial loss: 0.528584\n",
      "epoch 125; iter: 0; batch classifier loss: 0.325335; batch adversarial loss: 0.564497\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329816; batch adversarial loss: 0.499497\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378124; batch adversarial loss: 0.542670\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349287; batch adversarial loss: 0.481768\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339160; batch adversarial loss: 0.506967\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364379; batch adversarial loss: 0.535797\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362652; batch adversarial loss: 0.563281\n",
      "epoch 132; iter: 0; batch classifier loss: 0.314516; batch adversarial loss: 0.564045\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391671; batch adversarial loss: 0.508587\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365707; batch adversarial loss: 0.508107\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348960; batch adversarial loss: 0.562728\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356635; batch adversarial loss: 0.524518\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305172; batch adversarial loss: 0.514041\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376353; batch adversarial loss: 0.587364\n",
      "epoch 139; iter: 0; batch classifier loss: 0.300260; batch adversarial loss: 0.480641\n",
      "epoch 140; iter: 0; batch classifier loss: 0.480281; batch adversarial loss: 0.570350\n",
      "epoch 141; iter: 0; batch classifier loss: 0.303277; batch adversarial loss: 0.529299\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340181; batch adversarial loss: 0.563633\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408430; batch adversarial loss: 0.527149\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409386; batch adversarial loss: 0.554091\n",
      "epoch 145; iter: 0; batch classifier loss: 0.313040; batch adversarial loss: 0.509287\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389102; batch adversarial loss: 0.534304\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387395; batch adversarial loss: 0.543884\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386048; batch adversarial loss: 0.517793\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363086; batch adversarial loss: 0.580826\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364241; batch adversarial loss: 0.562204\n",
      "epoch 151; iter: 0; batch classifier loss: 0.337618; batch adversarial loss: 0.551726\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398998; batch adversarial loss: 0.536229\n",
      "epoch 153; iter: 0; batch classifier loss: 0.347668; batch adversarial loss: 0.571347\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352002; batch adversarial loss: 0.517310\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369766; batch adversarial loss: 0.609388\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402872; batch adversarial loss: 0.518091\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375299; batch adversarial loss: 0.518558\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364606; batch adversarial loss: 0.552734\n",
      "epoch 159; iter: 0; batch classifier loss: 0.382690; batch adversarial loss: 0.588205\n",
      "epoch 160; iter: 0; batch classifier loss: 0.344419; batch adversarial loss: 0.544140\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354752; batch adversarial loss: 0.516862\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398213; batch adversarial loss: 0.595923\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373397; batch adversarial loss: 0.542479\n",
      "epoch 164; iter: 0; batch classifier loss: 0.325303; batch adversarial loss: 0.502266\n",
      "epoch 165; iter: 0; batch classifier loss: 0.464375; batch adversarial loss: 0.472549\n",
      "epoch 166; iter: 0; batch classifier loss: 0.374733; batch adversarial loss: 0.481088\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390008; batch adversarial loss: 0.606361\n",
      "epoch 168; iter: 0; batch classifier loss: 0.295534; batch adversarial loss: 0.551869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326397; batch adversarial loss: 0.560036\n",
      "epoch 170; iter: 0; batch classifier loss: 0.419113; batch adversarial loss: 0.555255\n",
      "epoch 171; iter: 0; batch classifier loss: 0.287088; batch adversarial loss: 0.545172\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353565; batch adversarial loss: 0.525231\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355539; batch adversarial loss: 0.534815\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340896; batch adversarial loss: 0.583751\n",
      "epoch 175; iter: 0; batch classifier loss: 0.310961; batch adversarial loss: 0.607330\n",
      "epoch 176; iter: 0; batch classifier loss: 0.351773; batch adversarial loss: 0.500164\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362198; batch adversarial loss: 0.607231\n",
      "epoch 178; iter: 0; batch classifier loss: 0.300034; batch adversarial loss: 0.508533\n",
      "epoch 179; iter: 0; batch classifier loss: 0.360715; batch adversarial loss: 0.581644\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358962; batch adversarial loss: 0.627179\n",
      "epoch 181; iter: 0; batch classifier loss: 0.409237; batch adversarial loss: 0.527348\n",
      "epoch 182; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.545285\n",
      "epoch 183; iter: 0; batch classifier loss: 0.301511; batch adversarial loss: 0.554582\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383785; batch adversarial loss: 0.535017\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338601; batch adversarial loss: 0.516851\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374590; batch adversarial loss: 0.498430\n",
      "epoch 187; iter: 0; batch classifier loss: 0.408075; batch adversarial loss: 0.517760\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383657; batch adversarial loss: 0.579893\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327508; batch adversarial loss: 0.581432\n",
      "epoch 190; iter: 0; batch classifier loss: 0.251564; batch adversarial loss: 0.490546\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359544; batch adversarial loss: 0.626522\n",
      "epoch 192; iter: 0; batch classifier loss: 0.405125; batch adversarial loss: 0.587443\n",
      "epoch 193; iter: 0; batch classifier loss: 0.357548; batch adversarial loss: 0.514882\n",
      "epoch 194; iter: 0; batch classifier loss: 0.337888; batch adversarial loss: 0.472296\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342713; batch adversarial loss: 0.542939\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354533; batch adversarial loss: 0.586197\n",
      "epoch 197; iter: 0; batch classifier loss: 0.432479; batch adversarial loss: 0.507256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.397667; batch adversarial loss: 0.535566\n",
      "epoch 199; iter: 0; batch classifier loss: 0.325676; batch adversarial loss: 0.555663\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685074; batch adversarial loss: 0.804030\n",
      "epoch 1; iter: 0; batch classifier loss: 0.775009; batch adversarial loss: 0.897418\n",
      "epoch 2; iter: 0; batch classifier loss: 1.031381; batch adversarial loss: 0.868942\n",
      "epoch 3; iter: 0; batch classifier loss: 0.980755; batch adversarial loss: 0.793559\n",
      "epoch 4; iter: 0; batch classifier loss: 0.975286; batch adversarial loss: 0.731246\n",
      "epoch 5; iter: 0; batch classifier loss: 0.764298; batch adversarial loss: 0.681449\n",
      "epoch 6; iter: 0; batch classifier loss: 0.618352; batch adversarial loss: 0.623273\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497007; batch adversarial loss: 0.614532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552154; batch adversarial loss: 0.625064\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541723; batch adversarial loss: 0.574591\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523532; batch adversarial loss: 0.565956\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552678; batch adversarial loss: 0.615033\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505421; batch adversarial loss: 0.583983\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586951; batch adversarial loss: 0.540169\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532767; batch adversarial loss: 0.564728\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584836; batch adversarial loss: 0.548501\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519439; batch adversarial loss: 0.555878\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559281; batch adversarial loss: 0.582212\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475889; batch adversarial loss: 0.583121\n",
      "epoch 19; iter: 0; batch classifier loss: 0.414719; batch adversarial loss: 0.567933\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448633; batch adversarial loss: 0.518819\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508820; batch adversarial loss: 0.571645\n",
      "epoch 22; iter: 0; batch classifier loss: 0.416044; batch adversarial loss: 0.616665\n",
      "epoch 23; iter: 0; batch classifier loss: 0.559108; batch adversarial loss: 0.570209\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454695; batch adversarial loss: 0.587660\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477392; batch adversarial loss: 0.541671\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495523; batch adversarial loss: 0.507340\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445702; batch adversarial loss: 0.519398\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485257; batch adversarial loss: 0.496899\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456097; batch adversarial loss: 0.513690\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442760; batch adversarial loss: 0.466956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453355; batch adversarial loss: 0.631983\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491255; batch adversarial loss: 0.570792\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448834; batch adversarial loss: 0.581974\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488890; batch adversarial loss: 0.511295\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515151; batch adversarial loss: 0.590140\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403037; batch adversarial loss: 0.557545\n",
      "epoch 37; iter: 0; batch classifier loss: 0.397486; batch adversarial loss: 0.530516\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416343; batch adversarial loss: 0.474374\n",
      "epoch 39; iter: 0; batch classifier loss: 0.412403; batch adversarial loss: 0.518680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408058; batch adversarial loss: 0.521801\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407318; batch adversarial loss: 0.564899\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498150; batch adversarial loss: 0.501851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378123; batch adversarial loss: 0.600300\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500273; batch adversarial loss: 0.568735\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489764; batch adversarial loss: 0.564262\n",
      "epoch 46; iter: 0; batch classifier loss: 0.314447; batch adversarial loss: 0.503042\n",
      "epoch 47; iter: 0; batch classifier loss: 0.512000; batch adversarial loss: 0.506093\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415537; batch adversarial loss: 0.443555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464768; batch adversarial loss: 0.541996\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498419; batch adversarial loss: 0.510778\n",
      "epoch 51; iter: 0; batch classifier loss: 0.492052; batch adversarial loss: 0.558521\n",
      "epoch 52; iter: 0; batch classifier loss: 0.472030; batch adversarial loss: 0.577630\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399675; batch adversarial loss: 0.545726\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379166; batch adversarial loss: 0.575858\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408641; batch adversarial loss: 0.433943\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398935; batch adversarial loss: 0.537508\n",
      "epoch 57; iter: 0; batch classifier loss: 0.503942; batch adversarial loss: 0.519474\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421993; batch adversarial loss: 0.463532\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399098; batch adversarial loss: 0.572208\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418177; batch adversarial loss: 0.586151\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388435; batch adversarial loss: 0.510345\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436819; batch adversarial loss: 0.590355\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420913; batch adversarial loss: 0.599536\n",
      "epoch 64; iter: 0; batch classifier loss: 0.445827; batch adversarial loss: 0.501503\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408411; batch adversarial loss: 0.554521\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411248; batch adversarial loss: 0.545516\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391374; batch adversarial loss: 0.527860\n",
      "epoch 68; iter: 0; batch classifier loss: 0.453214; batch adversarial loss: 0.596886\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359689; batch adversarial loss: 0.509799\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420058; batch adversarial loss: 0.579889\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431646; batch adversarial loss: 0.579881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.359898; batch adversarial loss: 0.624101\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375316; batch adversarial loss: 0.527167\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416879; batch adversarial loss: 0.553729\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421702; batch adversarial loss: 0.562083\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421699; batch adversarial loss: 0.641724\n",
      "epoch 77; iter: 0; batch classifier loss: 0.445406; batch adversarial loss: 0.634022\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396065; batch adversarial loss: 0.597427\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397028; batch adversarial loss: 0.633053\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416602; batch adversarial loss: 0.544564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.487306; batch adversarial loss: 0.518460\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411244; batch adversarial loss: 0.562298\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360264; batch adversarial loss: 0.544682\n",
      "epoch 84; iter: 0; batch classifier loss: 0.415729; batch adversarial loss: 0.509177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.508413; batch adversarial loss: 0.571228\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451927; batch adversarial loss: 0.562444\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390738; batch adversarial loss: 0.580005\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373726; batch adversarial loss: 0.606907\n",
      "epoch 89; iter: 0; batch classifier loss: 0.418485; batch adversarial loss: 0.536020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370945; batch adversarial loss: 0.535693\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409607; batch adversarial loss: 0.677913\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421574; batch adversarial loss: 0.562222\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347813; batch adversarial loss: 0.580330\n",
      "epoch 94; iter: 0; batch classifier loss: 0.445950; batch adversarial loss: 0.597915\n",
      "epoch 95; iter: 0; batch classifier loss: 0.406448; batch adversarial loss: 0.561917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.367170; batch adversarial loss: 0.536866\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377303; batch adversarial loss: 0.535718\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361263; batch adversarial loss: 0.624839\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342143; batch adversarial loss: 0.554477\n",
      "epoch 100; iter: 0; batch classifier loss: 0.400266; batch adversarial loss: 0.482313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398731; batch adversarial loss: 0.534937\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426010; batch adversarial loss: 0.554305\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426912; batch adversarial loss: 0.562357\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341985; batch adversarial loss: 0.562136\n",
      "epoch 105; iter: 0; batch classifier loss: 0.451445; batch adversarial loss: 0.571650\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326514; batch adversarial loss: 0.571353\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373389; batch adversarial loss: 0.527021\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435098; batch adversarial loss: 0.571178\n",
      "epoch 109; iter: 0; batch classifier loss: 0.334554; batch adversarial loss: 0.500139\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381840; batch adversarial loss: 0.509209\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359812; batch adversarial loss: 0.526897\n",
      "epoch 112; iter: 0; batch classifier loss: 0.433252; batch adversarial loss: 0.518113\n",
      "epoch 113; iter: 0; batch classifier loss: 0.298121; batch adversarial loss: 0.536035\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371854; batch adversarial loss: 0.509484\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367042; batch adversarial loss: 0.571013\n",
      "epoch 116; iter: 0; batch classifier loss: 0.262239; batch adversarial loss: 0.553712\n",
      "epoch 117; iter: 0; batch classifier loss: 0.423673; batch adversarial loss: 0.491567\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326448; batch adversarial loss: 0.562768\n",
      "epoch 119; iter: 0; batch classifier loss: 0.333073; batch adversarial loss: 0.598106\n",
      "epoch 120; iter: 0; batch classifier loss: 0.314152; batch adversarial loss: 0.562346\n",
      "epoch 121; iter: 0; batch classifier loss: 0.386914; batch adversarial loss: 0.553745\n",
      "epoch 122; iter: 0; batch classifier loss: 0.430455; batch adversarial loss: 0.544647\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369900; batch adversarial loss: 0.571066\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384060; batch adversarial loss: 0.615368\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359501; batch adversarial loss: 0.535835\n",
      "epoch 126; iter: 0; batch classifier loss: 0.309874; batch adversarial loss: 0.624251\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422288; batch adversarial loss: 0.633837\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379271; batch adversarial loss: 0.553178\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367682; batch adversarial loss: 0.571500\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354378; batch adversarial loss: 0.553731\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349782; batch adversarial loss: 0.554011\n",
      "epoch 132; iter: 0; batch classifier loss: 0.340219; batch adversarial loss: 0.509213\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354284; batch adversarial loss: 0.535876\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350436; batch adversarial loss: 0.597802\n",
      "epoch 135; iter: 0; batch classifier loss: 0.280068; batch adversarial loss: 0.535574\n",
      "epoch 136; iter: 0; batch classifier loss: 0.317408; batch adversarial loss: 0.526821\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383004; batch adversarial loss: 0.544767\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330272; batch adversarial loss: 0.482692\n",
      "epoch 139; iter: 0; batch classifier loss: 0.417716; batch adversarial loss: 0.527199\n",
      "epoch 140; iter: 0; batch classifier loss: 0.412452; batch adversarial loss: 0.553954\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350097; batch adversarial loss: 0.518235\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339343; batch adversarial loss: 0.606819\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405796; batch adversarial loss: 0.535825\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369453; batch adversarial loss: 0.545038\n",
      "epoch 145; iter: 0; batch classifier loss: 0.453304; batch adversarial loss: 0.677840\n",
      "epoch 146; iter: 0; batch classifier loss: 0.305305; batch adversarial loss: 0.544579\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337073; batch adversarial loss: 0.571547\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413775; batch adversarial loss: 0.518442\n",
      "epoch 149; iter: 0; batch classifier loss: 0.385314; batch adversarial loss: 0.482923\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360183; batch adversarial loss: 0.492044\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373429; batch adversarial loss: 0.580242\n",
      "epoch 152; iter: 0; batch classifier loss: 0.318296; batch adversarial loss: 0.536090\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302159; batch adversarial loss: 0.589342\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361392; batch adversarial loss: 0.473613\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379716; batch adversarial loss: 0.518223\n",
      "epoch 156; iter: 0; batch classifier loss: 0.254996; batch adversarial loss: 0.526819\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368838; batch adversarial loss: 0.500321\n",
      "epoch 158; iter: 0; batch classifier loss: 0.324566; batch adversarial loss: 0.500345\n",
      "epoch 159; iter: 0; batch classifier loss: 0.272520; batch adversarial loss: 0.536012\n",
      "epoch 160; iter: 0; batch classifier loss: 0.436390; batch adversarial loss: 0.509493\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361745; batch adversarial loss: 0.616021\n",
      "epoch 162; iter: 0; batch classifier loss: 0.336205; batch adversarial loss: 0.571317\n",
      "epoch 163; iter: 0; batch classifier loss: 0.412168; batch adversarial loss: 0.491538\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355055; batch adversarial loss: 0.562559\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355480; batch adversarial loss: 0.562590\n",
      "epoch 166; iter: 0; batch classifier loss: 0.488799; batch adversarial loss: 0.562027\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352173; batch adversarial loss: 0.535511\n",
      "epoch 168; iter: 0; batch classifier loss: 0.273328; batch adversarial loss: 0.624101\n",
      "epoch 169; iter: 0; batch classifier loss: 0.309940; batch adversarial loss: 0.598758\n",
      "epoch 170; iter: 0; batch classifier loss: 0.316612; batch adversarial loss: 0.553859\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333376; batch adversarial loss: 0.615760\n",
      "epoch 172; iter: 0; batch classifier loss: 0.275094; batch adversarial loss: 0.580200\n",
      "epoch 173; iter: 0; batch classifier loss: 0.235334; batch adversarial loss: 0.623919\n",
      "epoch 174; iter: 0; batch classifier loss: 0.291516; batch adversarial loss: 0.553491\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331639; batch adversarial loss: 0.544717\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338198; batch adversarial loss: 0.491690\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337898; batch adversarial loss: 0.509010\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376185; batch adversarial loss: 0.562105\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399471; batch adversarial loss: 0.526642\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346797; batch adversarial loss: 0.544895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.327520; batch adversarial loss: 0.571117\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381159; batch adversarial loss: 0.562428\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333866; batch adversarial loss: 0.526634\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347024; batch adversarial loss: 0.518227\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328008; batch adversarial loss: 0.606813\n",
      "epoch 186; iter: 0; batch classifier loss: 0.390653; batch adversarial loss: 0.562300\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322063; batch adversarial loss: 0.544639\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330640; batch adversarial loss: 0.526453\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335210; batch adversarial loss: 0.518138\n",
      "epoch 190; iter: 0; batch classifier loss: 0.323703; batch adversarial loss: 0.624347\n",
      "epoch 191; iter: 0; batch classifier loss: 0.287125; batch adversarial loss: 0.598250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.376215; batch adversarial loss: 0.589048\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336411; batch adversarial loss: 0.562719\n",
      "epoch 194; iter: 0; batch classifier loss: 0.401334; batch adversarial loss: 0.570898\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363165; batch adversarial loss: 0.562485\n",
      "epoch 196; iter: 0; batch classifier loss: 0.479886; batch adversarial loss: 0.589394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373938; batch adversarial loss: 0.589024\n",
      "epoch 198; iter: 0; batch classifier loss: 0.315000; batch adversarial loss: 0.553766\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384253; batch adversarial loss: 0.544862\n",
      "epoch 0; iter: 0; batch classifier loss: 0.750036; batch adversarial loss: 0.682929\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590224; batch adversarial loss: 0.652871\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574304; batch adversarial loss: 0.653041\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603504; batch adversarial loss: 0.619863\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560752; batch adversarial loss: 0.629240\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554031; batch adversarial loss: 0.630419\n",
      "epoch 6; iter: 0; batch classifier loss: 0.601348; batch adversarial loss: 0.577768\n",
      "epoch 7; iter: 0; batch classifier loss: 0.613122; batch adversarial loss: 0.581920\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520438; batch adversarial loss: 0.578117\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537898; batch adversarial loss: 0.608079\n",
      "epoch 10; iter: 0; batch classifier loss: 0.646532; batch adversarial loss: 0.605356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.479256; batch adversarial loss: 0.577608\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555216; batch adversarial loss: 0.592888\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488566; batch adversarial loss: 0.565477\n",
      "epoch 14; iter: 0; batch classifier loss: 0.594060; batch adversarial loss: 0.601050\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535600; batch adversarial loss: 0.519786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.563974; batch adversarial loss: 0.590341\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515416; batch adversarial loss: 0.565495\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517080; batch adversarial loss: 0.580634\n",
      "epoch 19; iter: 0; batch classifier loss: 0.566810; batch adversarial loss: 0.501169\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463038; batch adversarial loss: 0.516948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468165; batch adversarial loss: 0.534692\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473281; batch adversarial loss: 0.503450\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508928; batch adversarial loss: 0.498721\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508064; batch adversarial loss: 0.513899\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501233; batch adversarial loss: 0.560003\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470540; batch adversarial loss: 0.484356\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513291; batch adversarial loss: 0.596448\n",
      "epoch 28; iter: 0; batch classifier loss: 0.509088; batch adversarial loss: 0.497402\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376332; batch adversarial loss: 0.521746\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461352; batch adversarial loss: 0.553073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456249; batch adversarial loss: 0.605231\n",
      "epoch 32; iter: 0; batch classifier loss: 0.508727; batch adversarial loss: 0.528526\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465495; batch adversarial loss: 0.535743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448384; batch adversarial loss: 0.570487\n",
      "epoch 35; iter: 0; batch classifier loss: 0.518990; batch adversarial loss: 0.553509\n",
      "epoch 36; iter: 0; batch classifier loss: 0.493664; batch adversarial loss: 0.571483\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440776; batch adversarial loss: 0.598260\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469823; batch adversarial loss: 0.544607\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493242; batch adversarial loss: 0.535629\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452259; batch adversarial loss: 0.525936\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411218; batch adversarial loss: 0.471618\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457081; batch adversarial loss: 0.525841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473570; batch adversarial loss: 0.544676\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439651; batch adversarial loss: 0.599125\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416417; batch adversarial loss: 0.635298\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441920; batch adversarial loss: 0.534844\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487413; batch adversarial loss: 0.590243\n",
      "epoch 48; iter: 0; batch classifier loss: 0.355211; batch adversarial loss: 0.554219\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454465; batch adversarial loss: 0.552613\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452139; batch adversarial loss: 0.563483\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399592; batch adversarial loss: 0.435251\n",
      "epoch 52; iter: 0; batch classifier loss: 0.482459; batch adversarial loss: 0.590361\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376490; batch adversarial loss: 0.581693\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431059; batch adversarial loss: 0.608272\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446938; batch adversarial loss: 0.571010\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417684; batch adversarial loss: 0.554973\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427933; batch adversarial loss: 0.608132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410009; batch adversarial loss: 0.609995\n",
      "epoch 59; iter: 0; batch classifier loss: 0.347862; batch adversarial loss: 0.505407\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376363; batch adversarial loss: 0.608388\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470869; batch adversarial loss: 0.506358\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482054; batch adversarial loss: 0.617577\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410599; batch adversarial loss: 0.499881\n",
      "epoch 64; iter: 0; batch classifier loss: 0.318732; batch adversarial loss: 0.562741\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437145; batch adversarial loss: 0.470016\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413242; batch adversarial loss: 0.535184\n",
      "epoch 67; iter: 0; batch classifier loss: 0.441391; batch adversarial loss: 0.577876\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439301; batch adversarial loss: 0.471780\n",
      "epoch 69; iter: 0; batch classifier loss: 0.329402; batch adversarial loss: 0.528174\n",
      "epoch 70; iter: 0; batch classifier loss: 0.400895; batch adversarial loss: 0.533208\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370021; batch adversarial loss: 0.563960\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396125; batch adversarial loss: 0.504898\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409234; batch adversarial loss: 0.525709\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422841; batch adversarial loss: 0.468382\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418154; batch adversarial loss: 0.554664\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413546; batch adversarial loss: 0.516827\n",
      "epoch 77; iter: 0; batch classifier loss: 0.474411; batch adversarial loss: 0.544225\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347081; batch adversarial loss: 0.554808\n",
      "epoch 79; iter: 0; batch classifier loss: 0.495779; batch adversarial loss: 0.508049\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384763; batch adversarial loss: 0.433874\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413683; batch adversarial loss: 0.555908\n",
      "epoch 82; iter: 0; batch classifier loss: 0.410534; batch adversarial loss: 0.553390\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417233; batch adversarial loss: 0.587061\n",
      "epoch 84; iter: 0; batch classifier loss: 0.424148; batch adversarial loss: 0.525370\n",
      "epoch 85; iter: 0; batch classifier loss: 0.454527; batch adversarial loss: 0.497769\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371679; batch adversarial loss: 0.435391\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411852; batch adversarial loss: 0.460600\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401279; batch adversarial loss: 0.578038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.422542; batch adversarial loss: 0.580722\n",
      "epoch 90; iter: 0; batch classifier loss: 0.335010; batch adversarial loss: 0.487417\n",
      "epoch 91; iter: 0; batch classifier loss: 0.418398; batch adversarial loss: 0.486999\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406222; batch adversarial loss: 0.495329\n",
      "epoch 93; iter: 0; batch classifier loss: 0.432706; batch adversarial loss: 0.501240\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421354; batch adversarial loss: 0.507628\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387390; batch adversarial loss: 0.487449\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422050; batch adversarial loss: 0.607359\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361379; batch adversarial loss: 0.543835\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368409; batch adversarial loss: 0.563816\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361222; batch adversarial loss: 0.492027\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401843; batch adversarial loss: 0.502353\n",
      "epoch 101; iter: 0; batch classifier loss: 0.500378; batch adversarial loss: 0.576865\n",
      "epoch 102; iter: 0; batch classifier loss: 0.440881; batch adversarial loss: 0.572830\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416723; batch adversarial loss: 0.516278\n",
      "epoch 104; iter: 0; batch classifier loss: 0.350221; batch adversarial loss: 0.564016\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395921; batch adversarial loss: 0.544300\n",
      "epoch 106; iter: 0; batch classifier loss: 0.330481; batch adversarial loss: 0.561434\n",
      "epoch 107; iter: 0; batch classifier loss: 0.307693; batch adversarial loss: 0.516430\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421240; batch adversarial loss: 0.621234\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364056; batch adversarial loss: 0.533971\n",
      "epoch 110; iter: 0; batch classifier loss: 0.439954; batch adversarial loss: 0.571402\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365450; batch adversarial loss: 0.592949\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403483; batch adversarial loss: 0.552484\n",
      "epoch 113; iter: 0; batch classifier loss: 0.390950; batch adversarial loss: 0.534767\n",
      "epoch 114; iter: 0; batch classifier loss: 0.470200; batch adversarial loss: 0.544045\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345241; batch adversarial loss: 0.542350\n",
      "epoch 116; iter: 0; batch classifier loss: 0.428574; batch adversarial loss: 0.598706\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410851; batch adversarial loss: 0.516748\n",
      "epoch 118; iter: 0; batch classifier loss: 0.287399; batch adversarial loss: 0.538406\n",
      "epoch 119; iter: 0; batch classifier loss: 0.377461; batch adversarial loss: 0.461243\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386587; batch adversarial loss: 0.496662\n",
      "epoch 121; iter: 0; batch classifier loss: 0.401761; batch adversarial loss: 0.563697\n",
      "epoch 122; iter: 0; batch classifier loss: 0.416662; batch adversarial loss: 0.638187\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387712; batch adversarial loss: 0.552868\n",
      "epoch 124; iter: 0; batch classifier loss: 0.409762; batch adversarial loss: 0.555897\n",
      "epoch 125; iter: 0; batch classifier loss: 0.310209; batch adversarial loss: 0.588991\n",
      "epoch 126; iter: 0; batch classifier loss: 0.447431; batch adversarial loss: 0.601097\n",
      "epoch 127; iter: 0; batch classifier loss: 0.435489; batch adversarial loss: 0.488333\n",
      "epoch 128; iter: 0; batch classifier loss: 0.398879; batch adversarial loss: 0.601494\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408053; batch adversarial loss: 0.497864\n",
      "epoch 130; iter: 0; batch classifier loss: 0.332084; batch adversarial loss: 0.564298\n",
      "epoch 131; iter: 0; batch classifier loss: 0.416388; batch adversarial loss: 0.499513\n",
      "epoch 132; iter: 0; batch classifier loss: 0.515671; batch adversarial loss: 0.562790\n",
      "epoch 133; iter: 0; batch classifier loss: 0.313912; batch adversarial loss: 0.491393\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356915; batch adversarial loss: 0.580821\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381379; batch adversarial loss: 0.516831\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354639; batch adversarial loss: 0.651115\n",
      "epoch 137; iter: 0; batch classifier loss: 0.342437; batch adversarial loss: 0.471587\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346998; batch adversarial loss: 0.623483\n",
      "epoch 139; iter: 0; batch classifier loss: 0.430850; batch adversarial loss: 0.561184\n",
      "epoch 140; iter: 0; batch classifier loss: 0.426762; batch adversarial loss: 0.487453\n",
      "epoch 141; iter: 0; batch classifier loss: 0.432828; batch adversarial loss: 0.536272\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341720; batch adversarial loss: 0.473088\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330078; batch adversarial loss: 0.469030\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369829; batch adversarial loss: 0.555732\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370987; batch adversarial loss: 0.582666\n",
      "epoch 146; iter: 0; batch classifier loss: 0.422329; batch adversarial loss: 0.499261\n",
      "epoch 147; iter: 0; batch classifier loss: 0.383361; batch adversarial loss: 0.610475\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338489; batch adversarial loss: 0.638004\n",
      "epoch 149; iter: 0; batch classifier loss: 0.427554; batch adversarial loss: 0.489011\n",
      "epoch 150; iter: 0; batch classifier loss: 0.305894; batch adversarial loss: 0.488328\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359618; batch adversarial loss: 0.550456\n",
      "epoch 152; iter: 0; batch classifier loss: 0.432828; batch adversarial loss: 0.494783\n",
      "epoch 153; iter: 0; batch classifier loss: 0.408756; batch adversarial loss: 0.572512\n",
      "epoch 154; iter: 0; batch classifier loss: 0.461194; batch adversarial loss: 0.459994\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349761; batch adversarial loss: 0.554749\n",
      "epoch 156; iter: 0; batch classifier loss: 0.315380; batch adversarial loss: 0.524214\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381867; batch adversarial loss: 0.469374\n",
      "epoch 158; iter: 0; batch classifier loss: 0.351877; batch adversarial loss: 0.551171\n",
      "epoch 159; iter: 0; batch classifier loss: 0.321724; batch adversarial loss: 0.537107\n",
      "epoch 160; iter: 0; batch classifier loss: 0.274205; batch adversarial loss: 0.469426\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355504; batch adversarial loss: 0.544789\n",
      "epoch 162; iter: 0; batch classifier loss: 0.318040; batch adversarial loss: 0.489913\n",
      "epoch 163; iter: 0; batch classifier loss: 0.417685; batch adversarial loss: 0.459115\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389219; batch adversarial loss: 0.655466\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385786; batch adversarial loss: 0.515242\n",
      "epoch 166; iter: 0; batch classifier loss: 0.395758; batch adversarial loss: 0.563458\n",
      "epoch 167; iter: 0; batch classifier loss: 0.403285; batch adversarial loss: 0.499526\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397290; batch adversarial loss: 0.508458\n",
      "epoch 169; iter: 0; batch classifier loss: 0.315905; batch adversarial loss: 0.517644\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378063; batch adversarial loss: 0.498679\n",
      "epoch 171; iter: 0; batch classifier loss: 0.376131; batch adversarial loss: 0.613889\n",
      "epoch 172; iter: 0; batch classifier loss: 0.437011; batch adversarial loss: 0.479676\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370702; batch adversarial loss: 0.534761\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385339; batch adversarial loss: 0.505233\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328858; batch adversarial loss: 0.542052\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347755; batch adversarial loss: 0.535565\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384116; batch adversarial loss: 0.518597\n",
      "epoch 178; iter: 0; batch classifier loss: 0.365679; batch adversarial loss: 0.551082\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340780; batch adversarial loss: 0.517502\n",
      "epoch 180; iter: 0; batch classifier loss: 0.288307; batch adversarial loss: 0.498009\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387004; batch adversarial loss: 0.515460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342700; batch adversarial loss: 0.542853\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356580; batch adversarial loss: 0.524225\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331066; batch adversarial loss: 0.600175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.356167; batch adversarial loss: 0.560147\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359385; batch adversarial loss: 0.500730\n",
      "epoch 187; iter: 0; batch classifier loss: 0.344859; batch adversarial loss: 0.489862\n",
      "epoch 188; iter: 0; batch classifier loss: 0.298120; batch adversarial loss: 0.582424\n",
      "epoch 189; iter: 0; batch classifier loss: 0.342744; batch adversarial loss: 0.578415\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395298; batch adversarial loss: 0.556234\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336678; batch adversarial loss: 0.589947\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339937; batch adversarial loss: 0.594488\n",
      "epoch 193; iter: 0; batch classifier loss: 0.446769; batch adversarial loss: 0.433488\n",
      "epoch 194; iter: 0; batch classifier loss: 0.337804; batch adversarial loss: 0.615264\n",
      "epoch 195; iter: 0; batch classifier loss: 0.303802; batch adversarial loss: 0.527140\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321452; batch adversarial loss: 0.525421\n",
      "epoch 197; iter: 0; batch classifier loss: 0.302833; batch adversarial loss: 0.535219\n",
      "epoch 198; iter: 0; batch classifier loss: 0.327248; batch adversarial loss: 0.479973\n",
      "epoch 199; iter: 0; batch classifier loss: 0.343975; batch adversarial loss: 0.517544\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715595; batch adversarial loss: 0.650182\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542996; batch adversarial loss: 0.660803\n",
      "epoch 2; iter: 0; batch classifier loss: 0.640288; batch adversarial loss: 0.657398\n",
      "epoch 3; iter: 0; batch classifier loss: 0.648105; batch adversarial loss: 0.627833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.645988; batch adversarial loss: 0.645256\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531386; batch adversarial loss: 0.618924\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559733; batch adversarial loss: 0.636006\n",
      "epoch 7; iter: 0; batch classifier loss: 0.590253; batch adversarial loss: 0.605255\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509522; batch adversarial loss: 0.592311\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541549; batch adversarial loss: 0.525842\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566517; batch adversarial loss: 0.592830\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534142; batch adversarial loss: 0.579601\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542549; batch adversarial loss: 0.572675\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484325; batch adversarial loss: 0.576658\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566701; batch adversarial loss: 0.593127\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566821; batch adversarial loss: 0.600152\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503635; batch adversarial loss: 0.554406\n",
      "epoch 17; iter: 0; batch classifier loss: 0.610739; batch adversarial loss: 0.553044\n",
      "epoch 18; iter: 0; batch classifier loss: 0.596986; batch adversarial loss: 0.630149\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536534; batch adversarial loss: 0.526659\n",
      "epoch 20; iter: 0; batch classifier loss: 0.599050; batch adversarial loss: 0.517831\n",
      "epoch 21; iter: 0; batch classifier loss: 0.560151; batch adversarial loss: 0.573527\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469295; batch adversarial loss: 0.522183\n",
      "epoch 23; iter: 0; batch classifier loss: 0.590990; batch adversarial loss: 0.515148\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493129; batch adversarial loss: 0.542577\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473401; batch adversarial loss: 0.476303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432444; batch adversarial loss: 0.571235\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463728; batch adversarial loss: 0.483347\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465450; batch adversarial loss: 0.563888\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446210; batch adversarial loss: 0.553221\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491779; batch adversarial loss: 0.597697\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463475; batch adversarial loss: 0.520783\n",
      "epoch 32; iter: 0; batch classifier loss: 0.455590; batch adversarial loss: 0.597491\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358197; batch adversarial loss: 0.537052\n",
      "epoch 34; iter: 0; batch classifier loss: 0.506206; batch adversarial loss: 0.502489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486114; batch adversarial loss: 0.518838\n",
      "epoch 36; iter: 0; batch classifier loss: 0.534786; batch adversarial loss: 0.571514\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459555; batch adversarial loss: 0.509836\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424440; batch adversarial loss: 0.518483\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481335; batch adversarial loss: 0.553377\n",
      "epoch 40; iter: 0; batch classifier loss: 0.539179; batch adversarial loss: 0.509370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506416; batch adversarial loss: 0.544724\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490983; batch adversarial loss: 0.632652\n",
      "epoch 43; iter: 0; batch classifier loss: 0.504756; batch adversarial loss: 0.491749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.471790; batch adversarial loss: 0.544695\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445665; batch adversarial loss: 0.545064\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460310; batch adversarial loss: 0.526717\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430973; batch adversarial loss: 0.617198\n",
      "epoch 48; iter: 0; batch classifier loss: 0.394852; batch adversarial loss: 0.545206\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418700; batch adversarial loss: 0.598556\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424010; batch adversarial loss: 0.535089\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453909; batch adversarial loss: 0.545789\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471423; batch adversarial loss: 0.536162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451702; batch adversarial loss: 0.526866\n",
      "epoch 54; iter: 0; batch classifier loss: 0.465284; batch adversarial loss: 0.590214\n",
      "epoch 55; iter: 0; batch classifier loss: 0.457478; batch adversarial loss: 0.571065\n",
      "epoch 56; iter: 0; batch classifier loss: 0.458789; batch adversarial loss: 0.561790\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437117; batch adversarial loss: 0.499633\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441007; batch adversarial loss: 0.499195\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438811; batch adversarial loss: 0.517191\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455729; batch adversarial loss: 0.572122\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385756; batch adversarial loss: 0.570410\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392389; batch adversarial loss: 0.498736\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370281; batch adversarial loss: 0.536263\n",
      "epoch 64; iter: 0; batch classifier loss: 0.453423; batch adversarial loss: 0.508081\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384724; batch adversarial loss: 0.607764\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318812; batch adversarial loss: 0.571708\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429469; batch adversarial loss: 0.456018\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405276; batch adversarial loss: 0.553207\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411701; batch adversarial loss: 0.526115\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459539; batch adversarial loss: 0.554850\n",
      "epoch 71; iter: 0; batch classifier loss: 0.470990; batch adversarial loss: 0.491325\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455534; batch adversarial loss: 0.570224\n",
      "epoch 73; iter: 0; batch classifier loss: 0.331283; batch adversarial loss: 0.564279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405285; batch adversarial loss: 0.553851\n",
      "epoch 75; iter: 0; batch classifier loss: 0.414819; batch adversarial loss: 0.517095\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372397; batch adversarial loss: 0.490533\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399436; batch adversarial loss: 0.599980\n",
      "epoch 78; iter: 0; batch classifier loss: 0.422092; batch adversarial loss: 0.481727\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375644; batch adversarial loss: 0.498287\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423018; batch adversarial loss: 0.588970\n",
      "epoch 81; iter: 0; batch classifier loss: 0.480951; batch adversarial loss: 0.479387\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420521; batch adversarial loss: 0.553879\n",
      "epoch 83; iter: 0; batch classifier loss: 0.454976; batch adversarial loss: 0.634314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.340761; batch adversarial loss: 0.541768\n",
      "epoch 85; iter: 0; batch classifier loss: 0.457308; batch adversarial loss: 0.500132\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392219; batch adversarial loss: 0.519101\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415152; batch adversarial loss: 0.516697\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430455; batch adversarial loss: 0.526226\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427072; batch adversarial loss: 0.617933\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411147; batch adversarial loss: 0.543469\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428257; batch adversarial loss: 0.572871\n",
      "epoch 92; iter: 0; batch classifier loss: 0.470121; batch adversarial loss: 0.507247\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394291; batch adversarial loss: 0.526240\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391867; batch adversarial loss: 0.544321\n",
      "epoch 95; iter: 0; batch classifier loss: 0.474103; batch adversarial loss: 0.599197\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377000; batch adversarial loss: 0.500836\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436931; batch adversarial loss: 0.463609\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398937; batch adversarial loss: 0.490368\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355408; batch adversarial loss: 0.508840\n",
      "epoch 100; iter: 0; batch classifier loss: 0.328955; batch adversarial loss: 0.644073\n",
      "epoch 101; iter: 0; batch classifier loss: 0.438304; batch adversarial loss: 0.580342\n",
      "epoch 102; iter: 0; batch classifier loss: 0.345357; batch adversarial loss: 0.552687\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374775; batch adversarial loss: 0.526396\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387888; batch adversarial loss: 0.571791\n",
      "epoch 105; iter: 0; batch classifier loss: 0.386764; batch adversarial loss: 0.551206\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352907; batch adversarial loss: 0.532576\n",
      "epoch 107; iter: 0; batch classifier loss: 0.422114; batch adversarial loss: 0.534208\n",
      "epoch 108; iter: 0; batch classifier loss: 0.355264; batch adversarial loss: 0.625545\n",
      "epoch 109; iter: 0; batch classifier loss: 0.425697; batch adversarial loss: 0.648522\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370612; batch adversarial loss: 0.527460\n",
      "epoch 111; iter: 0; batch classifier loss: 0.459287; batch adversarial loss: 0.512366\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326048; batch adversarial loss: 0.536816\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352946; batch adversarial loss: 0.509295\n",
      "epoch 114; iter: 0; batch classifier loss: 0.438894; batch adversarial loss: 0.517355\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355330; batch adversarial loss: 0.591591\n",
      "epoch 116; iter: 0; batch classifier loss: 0.416138; batch adversarial loss: 0.660867\n",
      "epoch 117; iter: 0; batch classifier loss: 0.310635; batch adversarial loss: 0.631889\n",
      "epoch 118; iter: 0; batch classifier loss: 0.420427; batch adversarial loss: 0.545068\n",
      "epoch 119; iter: 0; batch classifier loss: 0.503300; batch adversarial loss: 0.589157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413752; batch adversarial loss: 0.490553\n",
      "epoch 121; iter: 0; batch classifier loss: 0.357939; batch adversarial loss: 0.543694\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424296; batch adversarial loss: 0.443797\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401548; batch adversarial loss: 0.543166\n",
      "epoch 124; iter: 0; batch classifier loss: 0.420399; batch adversarial loss: 0.571093\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387561; batch adversarial loss: 0.546313\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368184; batch adversarial loss: 0.543002\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370451; batch adversarial loss: 0.537542\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422614; batch adversarial loss: 0.596957\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337667; batch adversarial loss: 0.528156\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319014; batch adversarial loss: 0.614044\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384426; batch adversarial loss: 0.588929\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331092; batch adversarial loss: 0.490749\n",
      "epoch 133; iter: 0; batch classifier loss: 0.469653; batch adversarial loss: 0.517868\n",
      "epoch 134; iter: 0; batch classifier loss: 0.438270; batch adversarial loss: 0.425072\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372948; batch adversarial loss: 0.548966\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.491608\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328775; batch adversarial loss: 0.517893\n",
      "epoch 138; iter: 0; batch classifier loss: 0.329661; batch adversarial loss: 0.517029\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415059; batch adversarial loss: 0.531752\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339364; batch adversarial loss: 0.582363\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346002; batch adversarial loss: 0.599150\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358995; batch adversarial loss: 0.587790\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374087; batch adversarial loss: 0.590371\n",
      "epoch 144; iter: 0; batch classifier loss: 0.332998; batch adversarial loss: 0.616219\n",
      "epoch 145; iter: 0; batch classifier loss: 0.442988; batch adversarial loss: 0.535185\n",
      "epoch 146; iter: 0; batch classifier loss: 0.448229; batch adversarial loss: 0.607853\n",
      "epoch 147; iter: 0; batch classifier loss: 0.487114; batch adversarial loss: 0.570911\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366029; batch adversarial loss: 0.590550\n",
      "epoch 149; iter: 0; batch classifier loss: 0.424845; batch adversarial loss: 0.563753\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320337; batch adversarial loss: 0.569611\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351712; batch adversarial loss: 0.544775\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375109; batch adversarial loss: 0.555756\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372103; batch adversarial loss: 0.570226\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400844; batch adversarial loss: 0.464927\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408152; batch adversarial loss: 0.543427\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377378; batch adversarial loss: 0.552901\n",
      "epoch 157; iter: 0; batch classifier loss: 0.478193; batch adversarial loss: 0.545361\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397753; batch adversarial loss: 0.485454\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394529; batch adversarial loss: 0.624320\n",
      "epoch 160; iter: 0; batch classifier loss: 0.418735; batch adversarial loss: 0.597796\n",
      "epoch 161; iter: 0; batch classifier loss: 0.429050; batch adversarial loss: 0.525141\n",
      "epoch 162; iter: 0; batch classifier loss: 0.404353; batch adversarial loss: 0.517671\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403488; batch adversarial loss: 0.596501\n",
      "epoch 164; iter: 0; batch classifier loss: 0.321090; batch adversarial loss: 0.535981\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319049; batch adversarial loss: 0.528077\n",
      "epoch 166; iter: 0; batch classifier loss: 0.348448; batch adversarial loss: 0.535668\n",
      "epoch 167; iter: 0; batch classifier loss: 0.459198; batch adversarial loss: 0.487568\n",
      "epoch 168; iter: 0; batch classifier loss: 0.325391; batch adversarial loss: 0.572187\n",
      "epoch 169; iter: 0; batch classifier loss: 0.415357; batch adversarial loss: 0.589808\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329645; batch adversarial loss: 0.599518\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353943; batch adversarial loss: 0.506855\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354932; batch adversarial loss: 0.553986\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410483; batch adversarial loss: 0.533393\n",
      "epoch 174; iter: 0; batch classifier loss: 0.327559; batch adversarial loss: 0.581955\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355325; batch adversarial loss: 0.533969\n",
      "epoch 176; iter: 0; batch classifier loss: 0.442389; batch adversarial loss: 0.551685\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369812; batch adversarial loss: 0.562729\n",
      "epoch 178; iter: 0; batch classifier loss: 0.424092; batch adversarial loss: 0.544387\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368363; batch adversarial loss: 0.472777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.332214; batch adversarial loss: 0.522986\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363327; batch adversarial loss: 0.527446\n",
      "epoch 182; iter: 0; batch classifier loss: 0.350885; batch adversarial loss: 0.492091\n",
      "epoch 183; iter: 0; batch classifier loss: 0.413910; batch adversarial loss: 0.473315\n",
      "epoch 184; iter: 0; batch classifier loss: 0.465007; batch adversarial loss: 0.553366\n",
      "epoch 185; iter: 0; batch classifier loss: 0.341053; batch adversarial loss: 0.553665\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318396; batch adversarial loss: 0.562639\n",
      "epoch 187; iter: 0; batch classifier loss: 0.378828; batch adversarial loss: 0.580917\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373558; batch adversarial loss: 0.546273\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351044; batch adversarial loss: 0.546106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.288224; batch adversarial loss: 0.572220\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355336; batch adversarial loss: 0.510043\n",
      "epoch 192; iter: 0; batch classifier loss: 0.377689; batch adversarial loss: 0.517052\n",
      "epoch 193; iter: 0; batch classifier loss: 0.391115; batch adversarial loss: 0.483061\n",
      "epoch 194; iter: 0; batch classifier loss: 0.421526; batch adversarial loss: 0.587315\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312441; batch adversarial loss: 0.589753\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349411; batch adversarial loss: 0.590453\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323789; batch adversarial loss: 0.564237\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383951; batch adversarial loss: 0.525854\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359005; batch adversarial loss: 0.573381\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662194; batch adversarial loss: 0.776388\n",
      "epoch 1; iter: 0; batch classifier loss: 0.708786; batch adversarial loss: 0.894945\n",
      "epoch 2; iter: 0; batch classifier loss: 0.975904; batch adversarial loss: 0.837575\n",
      "epoch 3; iter: 0; batch classifier loss: 0.912142; batch adversarial loss: 0.760965\n",
      "epoch 4; iter: 0; batch classifier loss: 0.821396; batch adversarial loss: 0.703841\n",
      "epoch 5; iter: 0; batch classifier loss: 0.872923; batch adversarial loss: 0.656317\n",
      "epoch 6; iter: 0; batch classifier loss: 0.635070; batch adversarial loss: 0.601161\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560003; batch adversarial loss: 0.601055\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533648; batch adversarial loss: 0.604768\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568750; batch adversarial loss: 0.573871\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564739; batch adversarial loss: 0.566175\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515611; batch adversarial loss: 0.592959\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498094; batch adversarial loss: 0.545399\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461317; batch adversarial loss: 0.561502\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521513; batch adversarial loss: 0.545365\n",
      "epoch 15; iter: 0; batch classifier loss: 0.567103; batch adversarial loss: 0.544703\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593251; batch adversarial loss: 0.544966\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526624; batch adversarial loss: 0.544475\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483367; batch adversarial loss: 0.567342\n",
      "epoch 19; iter: 0; batch classifier loss: 0.553448; batch adversarial loss: 0.621296\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519483; batch adversarial loss: 0.550876\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509448; batch adversarial loss: 0.516850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484556; batch adversarial loss: 0.557902\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473458; batch adversarial loss: 0.551913\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494942; batch adversarial loss: 0.536070\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519034; batch adversarial loss: 0.562046\n",
      "epoch 26; iter: 0; batch classifier loss: 0.431295; batch adversarial loss: 0.565876\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520498; batch adversarial loss: 0.556659\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461382; batch adversarial loss: 0.573957\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461779; batch adversarial loss: 0.459803\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469435; batch adversarial loss: 0.557281\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445677; batch adversarial loss: 0.598725\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431829; batch adversarial loss: 0.586580\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450525; batch adversarial loss: 0.597205\n",
      "epoch 34; iter: 0; batch classifier loss: 0.541705; batch adversarial loss: 0.579620\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515396; batch adversarial loss: 0.530699\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519468; batch adversarial loss: 0.491385\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455181; batch adversarial loss: 0.574127\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470155; batch adversarial loss: 0.521700\n",
      "epoch 39; iter: 0; batch classifier loss: 0.543002; batch adversarial loss: 0.432822\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452944; batch adversarial loss: 0.600098\n",
      "epoch 41; iter: 0; batch classifier loss: 0.490872; batch adversarial loss: 0.530019\n",
      "epoch 42; iter: 0; batch classifier loss: 0.375697; batch adversarial loss: 0.597495\n",
      "epoch 43; iter: 0; batch classifier loss: 0.549400; batch adversarial loss: 0.581365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.506912; batch adversarial loss: 0.526139\n",
      "epoch 45; iter: 0; batch classifier loss: 0.492186; batch adversarial loss: 0.509254\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495778; batch adversarial loss: 0.543325\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435130; batch adversarial loss: 0.564886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420460; batch adversarial loss: 0.524864\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465420; batch adversarial loss: 0.481825\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452737; batch adversarial loss: 0.521753\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434269; batch adversarial loss: 0.561726\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406728; batch adversarial loss: 0.571229\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425418; batch adversarial loss: 0.606109\n",
      "epoch 54; iter: 0; batch classifier loss: 0.455791; batch adversarial loss: 0.524764\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395302; batch adversarial loss: 0.599667\n",
      "epoch 56; iter: 0; batch classifier loss: 0.376541; batch adversarial loss: 0.587047\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406684; batch adversarial loss: 0.593092\n",
      "epoch 58; iter: 0; batch classifier loss: 0.381782; batch adversarial loss: 0.507501\n",
      "epoch 59; iter: 0; batch classifier loss: 0.366045; batch adversarial loss: 0.539444\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477291; batch adversarial loss: 0.561614\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447113; batch adversarial loss: 0.570267\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395946; batch adversarial loss: 0.506055\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406691; batch adversarial loss: 0.535007\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405241; batch adversarial loss: 0.560671\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401820; batch adversarial loss: 0.517671\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406034; batch adversarial loss: 0.574653\n",
      "epoch 67; iter: 0; batch classifier loss: 0.396197; batch adversarial loss: 0.592083\n",
      "epoch 68; iter: 0; batch classifier loss: 0.331284; batch adversarial loss: 0.508102\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432698; batch adversarial loss: 0.536024\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369256; batch adversarial loss: 0.581239\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420832; batch adversarial loss: 0.526943\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412185; batch adversarial loss: 0.526593\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404300; batch adversarial loss: 0.553606\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404580; batch adversarial loss: 0.544582\n",
      "epoch 75; iter: 0; batch classifier loss: 0.395998; batch adversarial loss: 0.526069\n",
      "epoch 76; iter: 0; batch classifier loss: 0.355932; batch adversarial loss: 0.533741\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345060; batch adversarial loss: 0.608777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.357154; batch adversarial loss: 0.461023\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397469; batch adversarial loss: 0.525875\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419585; batch adversarial loss: 0.591403\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397170; batch adversarial loss: 0.563554\n",
      "epoch 82; iter: 0; batch classifier loss: 0.326062; batch adversarial loss: 0.656073\n",
      "epoch 83; iter: 0; batch classifier loss: 0.343803; batch adversarial loss: 0.637892\n",
      "epoch 84; iter: 0; batch classifier loss: 0.332583; batch adversarial loss: 0.497445\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394870; batch adversarial loss: 0.555532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.318639; batch adversarial loss: 0.507266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440776; batch adversarial loss: 0.610321\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374093; batch adversarial loss: 0.553111\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389566; batch adversarial loss: 0.563531\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397046; batch adversarial loss: 0.471400\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376293; batch adversarial loss: 0.572185\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350542; batch adversarial loss: 0.608659\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347255; batch adversarial loss: 0.627109\n",
      "epoch 94; iter: 0; batch classifier loss: 0.350961; batch adversarial loss: 0.571817\n",
      "epoch 95; iter: 0; batch classifier loss: 0.315269; batch adversarial loss: 0.516728\n",
      "epoch 96; iter: 0; batch classifier loss: 0.467981; batch adversarial loss: 0.517000\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388032; batch adversarial loss: 0.590910\n",
      "epoch 98; iter: 0; batch classifier loss: 0.408579; batch adversarial loss: 0.488575\n",
      "epoch 99; iter: 0; batch classifier loss: 0.327905; batch adversarial loss: 0.488344\n",
      "epoch 100; iter: 0; batch classifier loss: 0.363006; batch adversarial loss: 0.553725\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336601; batch adversarial loss: 0.572197\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418470; batch adversarial loss: 0.452043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440965; batch adversarial loss: 0.470299\n",
      "epoch 104; iter: 0; batch classifier loss: 0.322834; batch adversarial loss: 0.599918\n",
      "epoch 105; iter: 0; batch classifier loss: 0.325030; batch adversarial loss: 0.544452\n",
      "epoch 106; iter: 0; batch classifier loss: 0.337760; batch adversarial loss: 0.525561\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362952; batch adversarial loss: 0.553957\n",
      "epoch 108; iter: 0; batch classifier loss: 0.320330; batch adversarial loss: 0.516467\n",
      "epoch 109; iter: 0; batch classifier loss: 0.520233; batch adversarial loss: 0.553746\n",
      "epoch 110; iter: 0; batch classifier loss: 0.328506; batch adversarial loss: 0.590647\n",
      "epoch 111; iter: 0; batch classifier loss: 0.366789; batch adversarial loss: 0.488955\n",
      "epoch 112; iter: 0; batch classifier loss: 0.323193; batch adversarial loss: 0.461275\n",
      "epoch 113; iter: 0; batch classifier loss: 0.321058; batch adversarial loss: 0.516555\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373894; batch adversarial loss: 0.609287\n",
      "epoch 115; iter: 0; batch classifier loss: 0.314364; batch adversarial loss: 0.562796\n",
      "epoch 116; iter: 0; batch classifier loss: 0.440368; batch adversarial loss: 0.516690\n",
      "epoch 117; iter: 0; batch classifier loss: 0.442441; batch adversarial loss: 0.601017\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391566; batch adversarial loss: 0.571786\n",
      "epoch 119; iter: 0; batch classifier loss: 0.321529; batch adversarial loss: 0.563089\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360377; batch adversarial loss: 0.554346\n",
      "epoch 121; iter: 0; batch classifier loss: 0.285001; batch adversarial loss: 0.535124\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389335; batch adversarial loss: 0.553529\n",
      "epoch 123; iter: 0; batch classifier loss: 0.335596; batch adversarial loss: 0.544664\n",
      "epoch 124; iter: 0; batch classifier loss: 0.300134; batch adversarial loss: 0.600088\n",
      "epoch 125; iter: 0; batch classifier loss: 0.459271; batch adversarial loss: 0.628418\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350709; batch adversarial loss: 0.526257\n",
      "epoch 127; iter: 0; batch classifier loss: 0.336971; batch adversarial loss: 0.507162\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328541; batch adversarial loss: 0.544990\n",
      "epoch 129; iter: 0; batch classifier loss: 0.335112; batch adversarial loss: 0.626642\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358492; batch adversarial loss: 0.571697\n",
      "epoch 131; iter: 0; batch classifier loss: 0.346974; batch adversarial loss: 0.553888\n",
      "epoch 132; iter: 0; batch classifier loss: 0.292996; batch adversarial loss: 0.507642\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367506; batch adversarial loss: 0.544814\n",
      "epoch 134; iter: 0; batch classifier loss: 0.346346; batch adversarial loss: 0.525841\n",
      "epoch 135; iter: 0; batch classifier loss: 0.286198; batch adversarial loss: 0.553485\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334625; batch adversarial loss: 0.562353\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334929; batch adversarial loss: 0.609147\n",
      "epoch 138; iter: 0; batch classifier loss: 0.289812; batch adversarial loss: 0.534930\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355485; batch adversarial loss: 0.544330\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333834; batch adversarial loss: 0.545136\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383990; batch adversarial loss: 0.516304\n",
      "epoch 142; iter: 0; batch classifier loss: 0.406039; batch adversarial loss: 0.525944\n",
      "epoch 143; iter: 0; batch classifier loss: 0.430927; batch adversarial loss: 0.488398\n",
      "epoch 144; iter: 0; batch classifier loss: 0.307316; batch adversarial loss: 0.582359\n",
      "epoch 145; iter: 0; batch classifier loss: 0.279426; batch adversarial loss: 0.543844\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330433; batch adversarial loss: 0.452015\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336788; batch adversarial loss: 0.526539\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310516; batch adversarial loss: 0.591255\n",
      "epoch 149; iter: 0; batch classifier loss: 0.307171; batch adversarial loss: 0.591401\n",
      "epoch 150; iter: 0; batch classifier loss: 0.295996; batch adversarial loss: 0.525277\n",
      "epoch 151; iter: 0; batch classifier loss: 0.296438; batch adversarial loss: 0.553571\n",
      "epoch 152; iter: 0; batch classifier loss: 0.408603; batch adversarial loss: 0.535683\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374241; batch adversarial loss: 0.581200\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393614; batch adversarial loss: 0.554769\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398189; batch adversarial loss: 0.552251\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346118; batch adversarial loss: 0.563586\n",
      "epoch 157; iter: 0; batch classifier loss: 0.281857; batch adversarial loss: 0.591203\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343814; batch adversarial loss: 0.571116\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384172; batch adversarial loss: 0.552955\n",
      "epoch 160; iter: 0; batch classifier loss: 0.310791; batch adversarial loss: 0.543404\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411062; batch adversarial loss: 0.515909\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371639; batch adversarial loss: 0.582046\n",
      "epoch 163; iter: 0; batch classifier loss: 0.283757; batch adversarial loss: 0.480268\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355025; batch adversarial loss: 0.479185\n",
      "epoch 165; iter: 0; batch classifier loss: 0.267914; batch adversarial loss: 0.544773\n",
      "epoch 166; iter: 0; batch classifier loss: 0.297095; batch adversarial loss: 0.506901\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379522; batch adversarial loss: 0.562687\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323767; batch adversarial loss: 0.507594\n",
      "epoch 169; iter: 0; batch classifier loss: 0.315184; batch adversarial loss: 0.534856\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362872; batch adversarial loss: 0.517093\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341129; batch adversarial loss: 0.609968\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364431; batch adversarial loss: 0.574056\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338551; batch adversarial loss: 0.535205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.263008; batch adversarial loss: 0.497991\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375467; batch adversarial loss: 0.599850\n",
      "epoch 176; iter: 0; batch classifier loss: 0.285907; batch adversarial loss: 0.544393\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363636; batch adversarial loss: 0.562972\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354203; batch adversarial loss: 0.498148\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392877; batch adversarial loss: 0.535158\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390571; batch adversarial loss: 0.536191\n",
      "epoch 181; iter: 0; batch classifier loss: 0.299374; batch adversarial loss: 0.525801\n",
      "epoch 182; iter: 0; batch classifier loss: 0.275979; batch adversarial loss: 0.525685\n",
      "epoch 183; iter: 0; batch classifier loss: 0.255835; batch adversarial loss: 0.525929\n",
      "epoch 184; iter: 0; batch classifier loss: 0.293233; batch adversarial loss: 0.534597\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315237; batch adversarial loss: 0.571932\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308531; batch adversarial loss: 0.526323\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319351; batch adversarial loss: 0.553560\n",
      "epoch 188; iter: 0; batch classifier loss: 0.475434; batch adversarial loss: 0.524921\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377552; batch adversarial loss: 0.563538\n",
      "epoch 190; iter: 0; batch classifier loss: 0.396454; batch adversarial loss: 0.470721\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373303; batch adversarial loss: 0.563323\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352121; batch adversarial loss: 0.572571\n",
      "epoch 193; iter: 0; batch classifier loss: 0.411646; batch adversarial loss: 0.497872\n",
      "epoch 194; iter: 0; batch classifier loss: 0.227532; batch adversarial loss: 0.572245\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379714; batch adversarial loss: 0.563798\n",
      "epoch 196; iter: 0; batch classifier loss: 0.436559; batch adversarial loss: 0.573062\n",
      "epoch 197; iter: 0; batch classifier loss: 0.310940; batch adversarial loss: 0.507442\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404689; batch adversarial loss: 0.534699\n",
      "epoch 199; iter: 0; batch classifier loss: 0.275348; batch adversarial loss: 0.534873\n",
      "epoch 0; iter: 0; batch classifier loss: 0.746912; batch adversarial loss: 0.879021\n",
      "epoch 1; iter: 0; batch classifier loss: 0.781000; batch adversarial loss: 0.893145\n",
      "epoch 2; iter: 0; batch classifier loss: 0.895173; batch adversarial loss: 0.841981\n",
      "epoch 3; iter: 0; batch classifier loss: 0.836623; batch adversarial loss: 0.809801\n",
      "epoch 4; iter: 0; batch classifier loss: 0.731834; batch adversarial loss: 0.707901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.638854; batch adversarial loss: 0.641384\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584940; batch adversarial loss: 0.624084\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561918; batch adversarial loss: 0.630148\n",
      "epoch 8; iter: 0; batch classifier loss: 0.452721; batch adversarial loss: 0.619606\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538534; batch adversarial loss: 0.564923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.601566; batch adversarial loss: 0.613171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521225; batch adversarial loss: 0.600008\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542694; batch adversarial loss: 0.600206\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507335; batch adversarial loss: 0.574375\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535447; batch adversarial loss: 0.574911\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478568; batch adversarial loss: 0.578485\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473502; batch adversarial loss: 0.572609\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467548; batch adversarial loss: 0.553165\n",
      "epoch 18; iter: 0; batch classifier loss: 0.587181; batch adversarial loss: 0.522258\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447190; batch adversarial loss: 0.539785\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498585; batch adversarial loss: 0.571982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.554496; batch adversarial loss: 0.634848\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487968; batch adversarial loss: 0.608500\n",
      "epoch 23; iter: 0; batch classifier loss: 0.555243; batch adversarial loss: 0.512247\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452280; batch adversarial loss: 0.493495\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544220; batch adversarial loss: 0.559052\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435774; batch adversarial loss: 0.571678\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468913; batch adversarial loss: 0.592424\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437447; batch adversarial loss: 0.489924\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441290; batch adversarial loss: 0.613047\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523099; batch adversarial loss: 0.491329\n",
      "epoch 31; iter: 0; batch classifier loss: 0.434764; batch adversarial loss: 0.545810\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436002; batch adversarial loss: 0.514309\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475608; batch adversarial loss: 0.520961\n",
      "epoch 34; iter: 0; batch classifier loss: 0.578864; batch adversarial loss: 0.534397\n",
      "epoch 35; iter: 0; batch classifier loss: 0.389508; batch adversarial loss: 0.538670\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479585; batch adversarial loss: 0.557572\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449146; batch adversarial loss: 0.456154\n",
      "epoch 38; iter: 0; batch classifier loss: 0.506830; batch adversarial loss: 0.491170\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411155; batch adversarial loss: 0.470605\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417799; batch adversarial loss: 0.492074\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410147; batch adversarial loss: 0.544287\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440564; batch adversarial loss: 0.535544\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394073; batch adversarial loss: 0.555240\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383079; batch adversarial loss: 0.550045\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458930; batch adversarial loss: 0.556829\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441307; batch adversarial loss: 0.569273\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420148; batch adversarial loss: 0.625943\n",
      "epoch 48; iter: 0; batch classifier loss: 0.519204; batch adversarial loss: 0.553376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448045; batch adversarial loss: 0.482730\n",
      "epoch 50; iter: 0; batch classifier loss: 0.494613; batch adversarial loss: 0.588934\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422245; batch adversarial loss: 0.519284\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447418; batch adversarial loss: 0.544829\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403586; batch adversarial loss: 0.571475\n",
      "epoch 54; iter: 0; batch classifier loss: 0.375545; batch adversarial loss: 0.580116\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440596; batch adversarial loss: 0.570810\n",
      "epoch 56; iter: 0; batch classifier loss: 0.363621; batch adversarial loss: 0.544846\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406010; batch adversarial loss: 0.526831\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440737; batch adversarial loss: 0.501090\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408777; batch adversarial loss: 0.553187\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363746; batch adversarial loss: 0.597816\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407270; batch adversarial loss: 0.562604\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376253; batch adversarial loss: 0.550391\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404510; batch adversarial loss: 0.561761\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382838; batch adversarial loss: 0.596508\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455131; batch adversarial loss: 0.561729\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363199; batch adversarial loss: 0.597485\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406980; batch adversarial loss: 0.595267\n",
      "epoch 68; iter: 0; batch classifier loss: 0.416900; batch adversarial loss: 0.543700\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427463; batch adversarial loss: 0.570842\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426117; batch adversarial loss: 0.570169\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405564; batch adversarial loss: 0.546321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.428534; batch adversarial loss: 0.570192\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382940; batch adversarial loss: 0.535584\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406969; batch adversarial loss: 0.537389\n",
      "epoch 75; iter: 0; batch classifier loss: 0.323392; batch adversarial loss: 0.474007\n",
      "epoch 76; iter: 0; batch classifier loss: 0.437295; batch adversarial loss: 0.588230\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410323; batch adversarial loss: 0.531994\n",
      "epoch 78; iter: 0; batch classifier loss: 0.314758; batch adversarial loss: 0.553674\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401547; batch adversarial loss: 0.532106\n",
      "epoch 80; iter: 0; batch classifier loss: 0.342210; batch adversarial loss: 0.550665\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432827; batch adversarial loss: 0.571952\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390514; batch adversarial loss: 0.514699\n",
      "epoch 83; iter: 0; batch classifier loss: 0.323565; batch adversarial loss: 0.519221\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355510; batch adversarial loss: 0.543048\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441006; batch adversarial loss: 0.562038\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331303; batch adversarial loss: 0.526495\n",
      "epoch 87; iter: 0; batch classifier loss: 0.325781; batch adversarial loss: 0.572139\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424834; batch adversarial loss: 0.499321\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432441; batch adversarial loss: 0.511280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.475185; batch adversarial loss: 0.578306\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421345; batch adversarial loss: 0.607379\n",
      "epoch 92; iter: 0; batch classifier loss: 0.426166; batch adversarial loss: 0.555385\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390451; batch adversarial loss: 0.497914\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364141; batch adversarial loss: 0.519397\n",
      "epoch 95; iter: 0; batch classifier loss: 0.441534; batch adversarial loss: 0.546023\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383157; batch adversarial loss: 0.553061\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385697; batch adversarial loss: 0.545772\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446944; batch adversarial loss: 0.586132\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446964; batch adversarial loss: 0.474501\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420660; batch adversarial loss: 0.568895\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409203; batch adversarial loss: 0.500546\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362313; batch adversarial loss: 0.571504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.435256; batch adversarial loss: 0.526729\n",
      "epoch 104; iter: 0; batch classifier loss: 0.291212; batch adversarial loss: 0.534859\n",
      "epoch 105; iter: 0; batch classifier loss: 0.495490; batch adversarial loss: 0.542902\n",
      "epoch 106; iter: 0; batch classifier loss: 0.346048; batch adversarial loss: 0.491720\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375734; batch adversarial loss: 0.610335\n",
      "epoch 108; iter: 0; batch classifier loss: 0.302078; batch adversarial loss: 0.554895\n",
      "epoch 109; iter: 0; batch classifier loss: 0.378756; batch adversarial loss: 0.524225\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368924; batch adversarial loss: 0.676951\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382344; batch adversarial loss: 0.514629\n",
      "epoch 112; iter: 0; batch classifier loss: 0.417510; batch adversarial loss: 0.541533\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366349; batch adversarial loss: 0.577362\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392177; batch adversarial loss: 0.515846\n",
      "epoch 115; iter: 0; batch classifier loss: 0.313247; batch adversarial loss: 0.562207\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376589; batch adversarial loss: 0.498780\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405338; batch adversarial loss: 0.483000\n",
      "epoch 118; iter: 0; batch classifier loss: 0.446410; batch adversarial loss: 0.511217\n",
      "epoch 119; iter: 0; batch classifier loss: 0.398242; batch adversarial loss: 0.527383\n",
      "epoch 120; iter: 0; batch classifier loss: 0.305972; batch adversarial loss: 0.550710\n",
      "epoch 121; iter: 0; batch classifier loss: 0.359733; batch adversarial loss: 0.569362\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355969; batch adversarial loss: 0.536643\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409411; batch adversarial loss: 0.641100\n",
      "epoch 124; iter: 0; batch classifier loss: 0.458888; batch adversarial loss: 0.588689\n",
      "epoch 125; iter: 0; batch classifier loss: 0.311832; batch adversarial loss: 0.489940\n",
      "epoch 126; iter: 0; batch classifier loss: 0.386980; batch adversarial loss: 0.537778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362272; batch adversarial loss: 0.578696\n",
      "epoch 128; iter: 0; batch classifier loss: 0.371984; batch adversarial loss: 0.620735\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398118; batch adversarial loss: 0.571551\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349067; batch adversarial loss: 0.624331\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406660; batch adversarial loss: 0.534393\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358688; batch adversarial loss: 0.586637\n",
      "epoch 133; iter: 0; batch classifier loss: 0.444218; batch adversarial loss: 0.559282\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.547237\n",
      "epoch 135; iter: 0; batch classifier loss: 0.326064; batch adversarial loss: 0.524730\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403563; batch adversarial loss: 0.572447\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407003; batch adversarial loss: 0.554556\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334858; batch adversarial loss: 0.519240\n",
      "epoch 139; iter: 0; batch classifier loss: 0.436783; batch adversarial loss: 0.558938\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402761; batch adversarial loss: 0.548353\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338611; batch adversarial loss: 0.517463\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341539; batch adversarial loss: 0.544721\n",
      "epoch 143; iter: 0; batch classifier loss: 0.325873; batch adversarial loss: 0.563427\n",
      "epoch 144; iter: 0; batch classifier loss: 0.540699; batch adversarial loss: 0.554645\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399053; batch adversarial loss: 0.598657\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374551; batch adversarial loss: 0.520258\n",
      "epoch 147; iter: 0; batch classifier loss: 0.279259; batch adversarial loss: 0.580355\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303202; batch adversarial loss: 0.570869\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378029; batch adversarial loss: 0.500627\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342655; batch adversarial loss: 0.534022\n",
      "epoch 151; iter: 0; batch classifier loss: 0.313780; batch adversarial loss: 0.567218\n",
      "epoch 152; iter: 0; batch classifier loss: 0.300421; batch adversarial loss: 0.550978\n",
      "epoch 153; iter: 0; batch classifier loss: 0.401679; batch adversarial loss: 0.523851\n",
      "epoch 154; iter: 0; batch classifier loss: 0.413659; batch adversarial loss: 0.598072\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316795; batch adversarial loss: 0.577974\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327123; batch adversarial loss: 0.545077\n",
      "epoch 157; iter: 0; batch classifier loss: 0.473697; batch adversarial loss: 0.519585\n",
      "epoch 158; iter: 0; batch classifier loss: 0.371709; batch adversarial loss: 0.572588\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350379; batch adversarial loss: 0.589930\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363086; batch adversarial loss: 0.544315\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399524; batch adversarial loss: 0.510587\n",
      "epoch 162; iter: 0; batch classifier loss: 0.396248; batch adversarial loss: 0.559827\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342032; batch adversarial loss: 0.651814\n",
      "epoch 164; iter: 0; batch classifier loss: 0.421820; batch adversarial loss: 0.473720\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385279; batch adversarial loss: 0.590109\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342150; batch adversarial loss: 0.470509\n",
      "epoch 167; iter: 0; batch classifier loss: 0.361370; batch adversarial loss: 0.599076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.434981; batch adversarial loss: 0.567595\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365351; batch adversarial loss: 0.597862\n",
      "epoch 170; iter: 0; batch classifier loss: 0.311411; batch adversarial loss: 0.526672\n",
      "epoch 171; iter: 0; batch classifier loss: 0.391366; batch adversarial loss: 0.600885\n",
      "epoch 172; iter: 0; batch classifier loss: 0.379980; batch adversarial loss: 0.534953\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364037; batch adversarial loss: 0.594734\n",
      "epoch 174; iter: 0; batch classifier loss: 0.382508; batch adversarial loss: 0.497111\n",
      "epoch 175; iter: 0; batch classifier loss: 0.300596; batch adversarial loss: 0.519409\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319434; batch adversarial loss: 0.580587\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333929; batch adversarial loss: 0.528379\n",
      "epoch 178; iter: 0; batch classifier loss: 0.472046; batch adversarial loss: 0.531373\n",
      "epoch 179; iter: 0; batch classifier loss: 0.319021; batch adversarial loss: 0.543955\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387208; batch adversarial loss: 0.498170\n",
      "epoch 181; iter: 0; batch classifier loss: 0.449326; batch adversarial loss: 0.566586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.306195; batch adversarial loss: 0.494084\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361787; batch adversarial loss: 0.525638\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351212; batch adversarial loss: 0.538392\n",
      "epoch 185; iter: 0; batch classifier loss: 0.293653; batch adversarial loss: 0.600785\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371319; batch adversarial loss: 0.614564\n",
      "epoch 187; iter: 0; batch classifier loss: 0.416073; batch adversarial loss: 0.568898\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341574; batch adversarial loss: 0.509518\n",
      "epoch 189; iter: 0; batch classifier loss: 0.363956; batch adversarial loss: 0.564387\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372938; batch adversarial loss: 0.577686\n",
      "epoch 191; iter: 0; batch classifier loss: 0.404772; batch adversarial loss: 0.576460\n",
      "epoch 192; iter: 0; batch classifier loss: 0.421130; batch adversarial loss: 0.581188\n",
      "epoch 193; iter: 0; batch classifier loss: 0.323384; batch adversarial loss: 0.521852\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340140; batch adversarial loss: 0.547266\n",
      "epoch 195; iter: 0; batch classifier loss: 0.282102; batch adversarial loss: 0.605416\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339744; batch adversarial loss: 0.603173\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309717; batch adversarial loss: 0.519334\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336574; batch adversarial loss: 0.562719\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336862; batch adversarial loss: 0.535247\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713264; batch adversarial loss: 0.635631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607776; batch adversarial loss: 0.644593\n",
      "epoch 2; iter: 0; batch classifier loss: 0.560828; batch adversarial loss: 0.646546\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614475; batch adversarial loss: 0.627030\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587223; batch adversarial loss: 0.595729\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597435; batch adversarial loss: 0.563705\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568129; batch adversarial loss: 0.596640\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538276; batch adversarial loss: 0.672541\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545240; batch adversarial loss: 0.593866\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579584; batch adversarial loss: 0.602675\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516470; batch adversarial loss: 0.607817\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592142; batch adversarial loss: 0.602734\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530276; batch adversarial loss: 0.569732\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520217; batch adversarial loss: 0.633291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540030; batch adversarial loss: 0.575619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446484; batch adversarial loss: 0.589389\n",
      "epoch 16; iter: 0; batch classifier loss: 0.580243; batch adversarial loss: 0.572318\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494651; batch adversarial loss: 0.572338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518484; batch adversarial loss: 0.550291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511907; batch adversarial loss: 0.594355\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498786; batch adversarial loss: 0.582552\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489043; batch adversarial loss: 0.512010\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436691; batch adversarial loss: 0.531819\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525006; batch adversarial loss: 0.540233\n",
      "epoch 24; iter: 0; batch classifier loss: 0.543696; batch adversarial loss: 0.605356\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481009; batch adversarial loss: 0.528090\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464622; batch adversarial loss: 0.556961\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466029; batch adversarial loss: 0.511864\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481460; batch adversarial loss: 0.571894\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490298; batch adversarial loss: 0.580473\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466276; batch adversarial loss: 0.522248\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484360; batch adversarial loss: 0.503660\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497130; batch adversarial loss: 0.512929\n",
      "epoch 33; iter: 0; batch classifier loss: 0.490901; batch adversarial loss: 0.612391\n",
      "epoch 34; iter: 0; batch classifier loss: 0.397688; batch adversarial loss: 0.553970\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476688; batch adversarial loss: 0.596966\n",
      "epoch 36; iter: 0; batch classifier loss: 0.367456; batch adversarial loss: 0.612378\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443315; batch adversarial loss: 0.560923\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467911; batch adversarial loss: 0.527696\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503298; batch adversarial loss: 0.524966\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411487; batch adversarial loss: 0.551972\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431968; batch adversarial loss: 0.534101\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407156; batch adversarial loss: 0.572768\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433748; batch adversarial loss: 0.562821\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412698; batch adversarial loss: 0.656669\n",
      "epoch 45; iter: 0; batch classifier loss: 0.462433; batch adversarial loss: 0.508510\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414529; batch adversarial loss: 0.555067\n",
      "epoch 47; iter: 0; batch classifier loss: 0.452715; batch adversarial loss: 0.574986\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484052; batch adversarial loss: 0.568319\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460154; batch adversarial loss: 0.542634\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415959; batch adversarial loss: 0.534745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.520699; batch adversarial loss: 0.621497\n",
      "epoch 52; iter: 0; batch classifier loss: 0.481491; batch adversarial loss: 0.514990\n",
      "epoch 53; iter: 0; batch classifier loss: 0.585970; batch adversarial loss: 0.489444\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402118; batch adversarial loss: 0.547032\n",
      "epoch 55; iter: 0; batch classifier loss: 0.369997; batch adversarial loss: 0.473574\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421055; batch adversarial loss: 0.588706\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396215; batch adversarial loss: 0.557315\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447566; batch adversarial loss: 0.603687\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421374; batch adversarial loss: 0.579448\n",
      "epoch 60; iter: 0; batch classifier loss: 0.464648; batch adversarial loss: 0.485551\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376180; batch adversarial loss: 0.556939\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435728; batch adversarial loss: 0.528749\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390344; batch adversarial loss: 0.542761\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457620; batch adversarial loss: 0.499093\n",
      "epoch 65; iter: 0; batch classifier loss: 0.329771; batch adversarial loss: 0.526057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.429483; batch adversarial loss: 0.544040\n",
      "epoch 67; iter: 0; batch classifier loss: 0.443299; batch adversarial loss: 0.516443\n",
      "epoch 68; iter: 0; batch classifier loss: 0.475001; batch adversarial loss: 0.475703\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404976; batch adversarial loss: 0.663772\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464363; batch adversarial loss: 0.658745\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422668; batch adversarial loss: 0.526472\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391070; batch adversarial loss: 0.498209\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410537; batch adversarial loss: 0.532673\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374059; batch adversarial loss: 0.606247\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448825; batch adversarial loss: 0.541680\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468340; batch adversarial loss: 0.561452\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374216; batch adversarial loss: 0.596437\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431377; batch adversarial loss: 0.559250\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407545; batch adversarial loss: 0.528402\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375764; batch adversarial loss: 0.496675\n",
      "epoch 81; iter: 0; batch classifier loss: 0.348150; batch adversarial loss: 0.579712\n",
      "epoch 82; iter: 0; batch classifier loss: 0.424587; batch adversarial loss: 0.591768\n",
      "epoch 83; iter: 0; batch classifier loss: 0.462173; batch adversarial loss: 0.584788\n",
      "epoch 84; iter: 0; batch classifier loss: 0.439303; batch adversarial loss: 0.505066\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414839; batch adversarial loss: 0.561993\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414459; batch adversarial loss: 0.519046\n",
      "epoch 87; iter: 0; batch classifier loss: 0.355921; batch adversarial loss: 0.613771\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414699; batch adversarial loss: 0.532784\n",
      "epoch 89; iter: 0; batch classifier loss: 0.446948; batch adversarial loss: 0.542926\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410957; batch adversarial loss: 0.564384\n",
      "epoch 91; iter: 0; batch classifier loss: 0.450954; batch adversarial loss: 0.634526\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411752; batch adversarial loss: 0.525650\n",
      "epoch 93; iter: 0; batch classifier loss: 0.430735; batch adversarial loss: 0.516484\n",
      "epoch 94; iter: 0; batch classifier loss: 0.347709; batch adversarial loss: 0.624125\n",
      "epoch 95; iter: 0; batch classifier loss: 0.370285; batch adversarial loss: 0.556625\n",
      "epoch 96; iter: 0; batch classifier loss: 0.548289; batch adversarial loss: 0.542374\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390863; batch adversarial loss: 0.589524\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388932; batch adversarial loss: 0.596723\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408747; batch adversarial loss: 0.473968\n",
      "epoch 100; iter: 0; batch classifier loss: 0.462942; batch adversarial loss: 0.550429\n",
      "epoch 101; iter: 0; batch classifier loss: 0.341015; batch adversarial loss: 0.574383\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427289; batch adversarial loss: 0.687071\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365449; batch adversarial loss: 0.541132\n",
      "epoch 104; iter: 0; batch classifier loss: 0.325858; batch adversarial loss: 0.526677\n",
      "epoch 105; iter: 0; batch classifier loss: 0.345390; batch adversarial loss: 0.594093\n",
      "epoch 106; iter: 0; batch classifier loss: 0.375935; batch adversarial loss: 0.547527\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353880; batch adversarial loss: 0.508361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.429719; batch adversarial loss: 0.583241\n",
      "epoch 109; iter: 0; batch classifier loss: 0.490658; batch adversarial loss: 0.541788\n",
      "epoch 110; iter: 0; batch classifier loss: 0.443062; batch adversarial loss: 0.507504\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384326; batch adversarial loss: 0.577057\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396042; batch adversarial loss: 0.629720\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405984; batch adversarial loss: 0.601836\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391266; batch adversarial loss: 0.609489\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428495; batch adversarial loss: 0.563102\n",
      "epoch 116; iter: 0; batch classifier loss: 0.429876; batch adversarial loss: 0.541100\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332772; batch adversarial loss: 0.511863\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405702; batch adversarial loss: 0.591570\n",
      "epoch 119; iter: 0; batch classifier loss: 0.440985; batch adversarial loss: 0.537826\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380938; batch adversarial loss: 0.516859\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393402; batch adversarial loss: 0.584800\n",
      "epoch 122; iter: 0; batch classifier loss: 0.445912; batch adversarial loss: 0.548203\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416131; batch adversarial loss: 0.556164\n",
      "epoch 124; iter: 0; batch classifier loss: 0.424243; batch adversarial loss: 0.482785\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344167; batch adversarial loss: 0.491953\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340483; batch adversarial loss: 0.518586\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366285; batch adversarial loss: 0.571394\n",
      "epoch 128; iter: 0; batch classifier loss: 0.408638; batch adversarial loss: 0.503996\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368566; batch adversarial loss: 0.542598\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406759; batch adversarial loss: 0.488011\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384157; batch adversarial loss: 0.518290\n",
      "epoch 132; iter: 0; batch classifier loss: 0.466596; batch adversarial loss: 0.576445\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383672; batch adversarial loss: 0.489392\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386146; batch adversarial loss: 0.537751\n",
      "epoch 135; iter: 0; batch classifier loss: 0.456077; batch adversarial loss: 0.580917\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396565; batch adversarial loss: 0.639182\n",
      "epoch 137; iter: 0; batch classifier loss: 0.336262; batch adversarial loss: 0.545233\n",
      "epoch 138; iter: 0; batch classifier loss: 0.423105; batch adversarial loss: 0.488537\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356743; batch adversarial loss: 0.541842\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333497; batch adversarial loss: 0.661783\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395019; batch adversarial loss: 0.531516\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403605; batch adversarial loss: 0.492389\n",
      "epoch 143; iter: 0; batch classifier loss: 0.362014; batch adversarial loss: 0.608700\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368102; batch adversarial loss: 0.555137\n",
      "epoch 145; iter: 0; batch classifier loss: 0.395416; batch adversarial loss: 0.653694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.450374; batch adversarial loss: 0.634544\n",
      "epoch 147; iter: 0; batch classifier loss: 0.409797; batch adversarial loss: 0.601232\n",
      "epoch 148; iter: 0; batch classifier loss: 0.348218; batch adversarial loss: 0.570216\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418364; batch adversarial loss: 0.498554\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397784; batch adversarial loss: 0.622710\n",
      "epoch 151; iter: 0; batch classifier loss: 0.443159; batch adversarial loss: 0.425941\n",
      "epoch 152; iter: 0; batch classifier loss: 0.355556; batch adversarial loss: 0.570446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.437569; batch adversarial loss: 0.525053\n",
      "epoch 154; iter: 0; batch classifier loss: 0.449728; batch adversarial loss: 0.519190\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413268; batch adversarial loss: 0.547225\n",
      "epoch 156; iter: 0; batch classifier loss: 0.309184; batch adversarial loss: 0.610548\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400674; batch adversarial loss: 0.564489\n",
      "epoch 158; iter: 0; batch classifier loss: 0.365084; batch adversarial loss: 0.578982\n",
      "epoch 159; iter: 0; batch classifier loss: 0.421477; batch adversarial loss: 0.607651\n",
      "epoch 160; iter: 0; batch classifier loss: 0.389127; batch adversarial loss: 0.539088\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343013; batch adversarial loss: 0.571115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.432815; batch adversarial loss: 0.677307\n",
      "epoch 163; iter: 0; batch classifier loss: 0.464286; batch adversarial loss: 0.566394\n",
      "epoch 164; iter: 0; batch classifier loss: 0.316704; batch adversarial loss: 0.574077\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352905; batch adversarial loss: 0.544625\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356321; batch adversarial loss: 0.602330\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336074; batch adversarial loss: 0.560438\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339643; batch adversarial loss: 0.409652\n",
      "epoch 169; iter: 0; batch classifier loss: 0.436475; batch adversarial loss: 0.558133\n",
      "epoch 170; iter: 0; batch classifier loss: 0.429056; batch adversarial loss: 0.495919\n",
      "epoch 171; iter: 0; batch classifier loss: 0.398998; batch adversarial loss: 0.484200\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392192; batch adversarial loss: 0.647789\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345582; batch adversarial loss: 0.524612\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366651; batch adversarial loss: 0.567267\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372451; batch adversarial loss: 0.461411\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364199; batch adversarial loss: 0.516413\n",
      "epoch 177; iter: 0; batch classifier loss: 0.289713; batch adversarial loss: 0.552845\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376596; batch adversarial loss: 0.549758\n",
      "epoch 179; iter: 0; batch classifier loss: 0.338605; batch adversarial loss: 0.566498\n",
      "epoch 180; iter: 0; batch classifier loss: 0.316093; batch adversarial loss: 0.632434\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401463; batch adversarial loss: 0.596846\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344383; batch adversarial loss: 0.529580\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348166; batch adversarial loss: 0.585292\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383605; batch adversarial loss: 0.629731\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402155; batch adversarial loss: 0.512349\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381727; batch adversarial loss: 0.495869\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370656; batch adversarial loss: 0.525917\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330179; batch adversarial loss: 0.613558\n",
      "epoch 189; iter: 0; batch classifier loss: 0.299881; batch adversarial loss: 0.564807\n",
      "epoch 190; iter: 0; batch classifier loss: 0.396294; batch adversarial loss: 0.499885\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374706; batch adversarial loss: 0.519227\n",
      "epoch 192; iter: 0; batch classifier loss: 0.410161; batch adversarial loss: 0.543245\n",
      "epoch 193; iter: 0; batch classifier loss: 0.434354; batch adversarial loss: 0.510857\n",
      "epoch 194; iter: 0; batch classifier loss: 0.387878; batch adversarial loss: 0.507216\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399610; batch adversarial loss: 0.539045\n",
      "epoch 196; iter: 0; batch classifier loss: 0.416232; batch adversarial loss: 0.529231\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407802; batch adversarial loss: 0.570990\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383610; batch adversarial loss: 0.540575\n",
      "epoch 199; iter: 0; batch classifier loss: 0.296953; batch adversarial loss: 0.515946\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674052; batch adversarial loss: 0.729679\n",
      "epoch 1; iter: 0; batch classifier loss: 0.659675; batch adversarial loss: 0.698702\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586551; batch adversarial loss: 0.649630\n",
      "epoch 3; iter: 0; batch classifier loss: 0.526605; batch adversarial loss: 0.638744\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547120; batch adversarial loss: 0.626845\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567260; batch adversarial loss: 0.620211\n",
      "epoch 6; iter: 0; batch classifier loss: 0.477574; batch adversarial loss: 0.599199\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543376; batch adversarial loss: 0.591994\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535841; batch adversarial loss: 0.619440\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539153; batch adversarial loss: 0.589487\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547954; batch adversarial loss: 0.583069\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493722; batch adversarial loss: 0.537695\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490551; batch adversarial loss: 0.565385\n",
      "epoch 13; iter: 0; batch classifier loss: 0.469297; batch adversarial loss: 0.582382\n",
      "epoch 14; iter: 0; batch classifier loss: 0.550122; batch adversarial loss: 0.553489\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506475; batch adversarial loss: 0.532477\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517155; batch adversarial loss: 0.564531\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529850; batch adversarial loss: 0.544492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503280; batch adversarial loss: 0.505792\n",
      "epoch 19; iter: 0; batch classifier loss: 0.522919; batch adversarial loss: 0.575946\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448318; batch adversarial loss: 0.570109\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539302; batch adversarial loss: 0.607574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515892; batch adversarial loss: 0.637504\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470076; batch adversarial loss: 0.550056\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473313; batch adversarial loss: 0.519168\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466193; batch adversarial loss: 0.556981\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439028; batch adversarial loss: 0.574233\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467583; batch adversarial loss: 0.495825\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495464; batch adversarial loss: 0.553029\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525409; batch adversarial loss: 0.554450\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440010; batch adversarial loss: 0.565725\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456093; batch adversarial loss: 0.555700\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419538; batch adversarial loss: 0.488326\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514900; batch adversarial loss: 0.607210\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417943; batch adversarial loss: 0.602512\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465118; batch adversarial loss: 0.557966\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410743; batch adversarial loss: 0.520962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483997; batch adversarial loss: 0.546439\n",
      "epoch 38; iter: 0; batch classifier loss: 0.489364; batch adversarial loss: 0.579836\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470330; batch adversarial loss: 0.554443\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400420; batch adversarial loss: 0.596919\n",
      "epoch 41; iter: 0; batch classifier loss: 0.393400; batch adversarial loss: 0.562782\n",
      "epoch 42; iter: 0; batch classifier loss: 0.382846; batch adversarial loss: 0.536873\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399535; batch adversarial loss: 0.493929\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408386; batch adversarial loss: 0.536384\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469482; batch adversarial loss: 0.562639\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429577; batch adversarial loss: 0.518646\n",
      "epoch 47; iter: 0; batch classifier loss: 0.380369; batch adversarial loss: 0.518459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409268; batch adversarial loss: 0.553619\n",
      "epoch 49; iter: 0; batch classifier loss: 0.481002; batch adversarial loss: 0.509104\n",
      "epoch 50; iter: 0; batch classifier loss: 0.372693; batch adversarial loss: 0.651563\n",
      "epoch 51; iter: 0; batch classifier loss: 0.488524; batch adversarial loss: 0.553718\n",
      "epoch 52; iter: 0; batch classifier loss: 0.472170; batch adversarial loss: 0.517563\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389412; batch adversarial loss: 0.553652\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402344; batch adversarial loss: 0.616241\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458771; batch adversarial loss: 0.527740\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400849; batch adversarial loss: 0.562441\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428180; batch adversarial loss: 0.491268\n",
      "epoch 58; iter: 0; batch classifier loss: 0.487404; batch adversarial loss: 0.634573\n",
      "epoch 59; iter: 0; batch classifier loss: 0.363589; batch adversarial loss: 0.589586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.436851; batch adversarial loss: 0.517500\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422869; batch adversarial loss: 0.570287\n",
      "epoch 62; iter: 0; batch classifier loss: 0.467493; batch adversarial loss: 0.563812\n",
      "epoch 63; iter: 0; batch classifier loss: 0.360416; batch adversarial loss: 0.580198\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386914; batch adversarial loss: 0.534044\n",
      "epoch 65; iter: 0; batch classifier loss: 0.477229; batch adversarial loss: 0.543367\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377980; batch adversarial loss: 0.509476\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432361; batch adversarial loss: 0.579086\n",
      "epoch 68; iter: 0; batch classifier loss: 0.430008; batch adversarial loss: 0.535257\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361457; batch adversarial loss: 0.544061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354347; batch adversarial loss: 0.525736\n",
      "epoch 71; iter: 0; batch classifier loss: 0.380628; batch adversarial loss: 0.553363\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447937; batch adversarial loss: 0.562832\n",
      "epoch 73; iter: 0; batch classifier loss: 0.472016; batch adversarial loss: 0.535226\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444765; batch adversarial loss: 0.491554\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369690; batch adversarial loss: 0.508187\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407056; batch adversarial loss: 0.552724\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388392; batch adversarial loss: 0.572497\n",
      "epoch 78; iter: 0; batch classifier loss: 0.422549; batch adversarial loss: 0.588856\n",
      "epoch 79; iter: 0; batch classifier loss: 0.454323; batch adversarial loss: 0.482492\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416337; batch adversarial loss: 0.607883\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406489; batch adversarial loss: 0.651296\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457163; batch adversarial loss: 0.606567\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429223; batch adversarial loss: 0.545712\n",
      "epoch 84; iter: 0; batch classifier loss: 0.394581; batch adversarial loss: 0.615857\n",
      "epoch 85; iter: 0; batch classifier loss: 0.334683; batch adversarial loss: 0.536397\n",
      "epoch 86; iter: 0; batch classifier loss: 0.325584; batch adversarial loss: 0.609506\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452323; batch adversarial loss: 0.527339\n",
      "epoch 88; iter: 0; batch classifier loss: 0.353560; batch adversarial loss: 0.480487\n",
      "epoch 89; iter: 0; batch classifier loss: 0.447020; batch adversarial loss: 0.536447\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424749; batch adversarial loss: 0.526102\n",
      "epoch 91; iter: 0; batch classifier loss: 0.401457; batch adversarial loss: 0.527027\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360508; batch adversarial loss: 0.607649\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387121; batch adversarial loss: 0.544437\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430343; batch adversarial loss: 0.578726\n",
      "epoch 95; iter: 0; batch classifier loss: 0.390559; batch adversarial loss: 0.581558\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394903; batch adversarial loss: 0.606465\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375708; batch adversarial loss: 0.580746\n",
      "epoch 98; iter: 0; batch classifier loss: 0.330746; batch adversarial loss: 0.598360\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364767; batch adversarial loss: 0.563015\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418301; batch adversarial loss: 0.554420\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392735; batch adversarial loss: 0.617223\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347153; batch adversarial loss: 0.555946\n",
      "epoch 103; iter: 0; batch classifier loss: 0.415736; batch adversarial loss: 0.491381\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377258; batch adversarial loss: 0.509142\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343736; batch adversarial loss: 0.554254\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380413; batch adversarial loss: 0.616370\n",
      "epoch 107; iter: 0; batch classifier loss: 0.459106; batch adversarial loss: 0.569721\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435599; batch adversarial loss: 0.587475\n",
      "epoch 109; iter: 0; batch classifier loss: 0.436097; batch adversarial loss: 0.545069\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391134; batch adversarial loss: 0.544050\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403343; batch adversarial loss: 0.525631\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414068; batch adversarial loss: 0.535685\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366630; batch adversarial loss: 0.579689\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346687; batch adversarial loss: 0.659441\n",
      "epoch 115; iter: 0; batch classifier loss: 0.452425; batch adversarial loss: 0.625921\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348264; batch adversarial loss: 0.589048\n",
      "epoch 117; iter: 0; batch classifier loss: 0.343098; batch adversarial loss: 0.562638\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391194; batch adversarial loss: 0.678150\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423255; batch adversarial loss: 0.499545\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327260; batch adversarial loss: 0.617128\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420400; batch adversarial loss: 0.588571\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382960; batch adversarial loss: 0.536885\n",
      "epoch 123; iter: 0; batch classifier loss: 0.438637; batch adversarial loss: 0.633885\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336759; batch adversarial loss: 0.464238\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367349; batch adversarial loss: 0.481939\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373210; batch adversarial loss: 0.571264\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386441; batch adversarial loss: 0.597675\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396444; batch adversarial loss: 0.508666\n",
      "epoch 129; iter: 0; batch classifier loss: 0.328099; batch adversarial loss: 0.590006\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380489; batch adversarial loss: 0.545211\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389392; batch adversarial loss: 0.544796\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377407; batch adversarial loss: 0.526073\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354534; batch adversarial loss: 0.581329\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367132; batch adversarial loss: 0.552820\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350943; batch adversarial loss: 0.526928\n",
      "epoch 136; iter: 0; batch classifier loss: 0.441558; batch adversarial loss: 0.563359\n",
      "epoch 137; iter: 0; batch classifier loss: 0.408072; batch adversarial loss: 0.526579\n",
      "epoch 138; iter: 0; batch classifier loss: 0.456145; batch adversarial loss: 0.570761\n",
      "epoch 139; iter: 0; batch classifier loss: 0.434962; batch adversarial loss: 0.509476\n",
      "epoch 140; iter: 0; batch classifier loss: 0.424711; batch adversarial loss: 0.544302\n",
      "epoch 141; iter: 0; batch classifier loss: 0.333359; batch adversarial loss: 0.599152\n",
      "epoch 142; iter: 0; batch classifier loss: 0.452841; batch adversarial loss: 0.562197\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386014; batch adversarial loss: 0.499090\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400861; batch adversarial loss: 0.544236\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397929; batch adversarial loss: 0.658957\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336850; batch adversarial loss: 0.491056\n",
      "epoch 147; iter: 0; batch classifier loss: 0.344197; batch adversarial loss: 0.528650\n",
      "epoch 148; iter: 0; batch classifier loss: 0.296204; batch adversarial loss: 0.571389\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405217; batch adversarial loss: 0.562519\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375965; batch adversarial loss: 0.571977\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344905; batch adversarial loss: 0.553993\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342245; batch adversarial loss: 0.563123\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343971; batch adversarial loss: 0.535911\n",
      "epoch 154; iter: 0; batch classifier loss: 0.408177; batch adversarial loss: 0.499804\n",
      "epoch 155; iter: 0; batch classifier loss: 0.331987; batch adversarial loss: 0.553872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.258990; batch adversarial loss: 0.581004\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361451; batch adversarial loss: 0.562677\n",
      "epoch 158; iter: 0; batch classifier loss: 0.430902; batch adversarial loss: 0.508852\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356708; batch adversarial loss: 0.632973\n",
      "epoch 160; iter: 0; batch classifier loss: 0.461807; batch adversarial loss: 0.536717\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373525; batch adversarial loss: 0.552730\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409638; batch adversarial loss: 0.687785\n",
      "epoch 163; iter: 0; batch classifier loss: 0.316404; batch adversarial loss: 0.561888\n",
      "epoch 164; iter: 0; batch classifier loss: 0.290206; batch adversarial loss: 0.580787\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424943; batch adversarial loss: 0.543356\n",
      "epoch 166; iter: 0; batch classifier loss: 0.393262; batch adversarial loss: 0.544174\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358908; batch adversarial loss: 0.571599\n",
      "epoch 168; iter: 0; batch classifier loss: 0.489456; batch adversarial loss: 0.544292\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382886; batch adversarial loss: 0.542833\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325557; batch adversarial loss: 0.553852\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347778; batch adversarial loss: 0.553606\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385832; batch adversarial loss: 0.623287\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398377; batch adversarial loss: 0.607797\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336893; batch adversarial loss: 0.554118\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375545; batch adversarial loss: 0.572410\n",
      "epoch 176; iter: 0; batch classifier loss: 0.441804; batch adversarial loss: 0.509826\n",
      "epoch 177; iter: 0; batch classifier loss: 0.390592; batch adversarial loss: 0.590525\n",
      "epoch 178; iter: 0; batch classifier loss: 0.432092; batch adversarial loss: 0.517523\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358836; batch adversarial loss: 0.537397\n",
      "epoch 180; iter: 0; batch classifier loss: 0.383352; batch adversarial loss: 0.526417\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305866; batch adversarial loss: 0.552433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.424926; batch adversarial loss: 0.562465\n",
      "epoch 183; iter: 0; batch classifier loss: 0.422333; batch adversarial loss: 0.491606\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379380; batch adversarial loss: 0.544227\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321456; batch adversarial loss: 0.554388\n",
      "epoch 186; iter: 0; batch classifier loss: 0.433940; batch adversarial loss: 0.509048\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385156; batch adversarial loss: 0.597956\n",
      "epoch 188; iter: 0; batch classifier loss: 0.407839; batch adversarial loss: 0.492279\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351469; batch adversarial loss: 0.491091\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336357; batch adversarial loss: 0.563045\n",
      "epoch 191; iter: 0; batch classifier loss: 0.310946; batch adversarial loss: 0.483435\n",
      "epoch 192; iter: 0; batch classifier loss: 0.423254; batch adversarial loss: 0.581321\n",
      "epoch 193; iter: 0; batch classifier loss: 0.417846; batch adversarial loss: 0.545178\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338617; batch adversarial loss: 0.517745\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323474; batch adversarial loss: 0.500832\n",
      "epoch 196; iter: 0; batch classifier loss: 0.385755; batch adversarial loss: 0.518087\n",
      "epoch 197; iter: 0; batch classifier loss: 0.439562; batch adversarial loss: 0.499999\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361330; batch adversarial loss: 0.501020\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335882; batch adversarial loss: 0.615960\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706339; batch adversarial loss: 0.723045\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596315; batch adversarial loss: 0.689113\n",
      "epoch 2; iter: 0; batch classifier loss: 0.532880; batch adversarial loss: 0.668602\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582594; batch adversarial loss: 0.648024\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597268; batch adversarial loss: 0.600441\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558075; batch adversarial loss: 0.596874\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565535; batch adversarial loss: 0.580322\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520305; batch adversarial loss: 0.527902\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578579; batch adversarial loss: 0.577965\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494209; batch adversarial loss: 0.579701\n",
      "epoch 10; iter: 0; batch classifier loss: 0.593278; batch adversarial loss: 0.590287\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542741; batch adversarial loss: 0.536340\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504333; batch adversarial loss: 0.549734\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557931; batch adversarial loss: 0.569227\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509494; batch adversarial loss: 0.551785\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584998; batch adversarial loss: 0.577676\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539263; batch adversarial loss: 0.569328\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536696; batch adversarial loss: 0.564725\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514609; batch adversarial loss: 0.568202\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476181; batch adversarial loss: 0.561602\n",
      "epoch 20; iter: 0; batch classifier loss: 0.615459; batch adversarial loss: 0.588515\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514769; batch adversarial loss: 0.533657\n",
      "epoch 22; iter: 0; batch classifier loss: 0.576162; batch adversarial loss: 0.553426\n",
      "epoch 23; iter: 0; batch classifier loss: 0.563905; batch adversarial loss: 0.530355\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517207; batch adversarial loss: 0.520531\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475133; batch adversarial loss: 0.557242\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470292; batch adversarial loss: 0.547260\n",
      "epoch 27; iter: 0; batch classifier loss: 0.516948; batch adversarial loss: 0.572043\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507821; batch adversarial loss: 0.446165\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485352; batch adversarial loss: 0.528278\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419992; batch adversarial loss: 0.621505\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469518; batch adversarial loss: 0.520562\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494890; batch adversarial loss: 0.571525\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463853; batch adversarial loss: 0.601238\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443561; batch adversarial loss: 0.499129\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475488; batch adversarial loss: 0.532446\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484629; batch adversarial loss: 0.543061\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451627; batch adversarial loss: 0.600642\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415096; batch adversarial loss: 0.600440\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453093; batch adversarial loss: 0.582403\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466197; batch adversarial loss: 0.509957\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424995; batch adversarial loss: 0.546945\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415801; batch adversarial loss: 0.616550\n",
      "epoch 43; iter: 0; batch classifier loss: 0.487326; batch adversarial loss: 0.623423\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424351; batch adversarial loss: 0.491712\n",
      "epoch 45; iter: 0; batch classifier loss: 0.495305; batch adversarial loss: 0.589798\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496966; batch adversarial loss: 0.571729\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412724; batch adversarial loss: 0.472217\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481528; batch adversarial loss: 0.562806\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449476; batch adversarial loss: 0.526900\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431688; batch adversarial loss: 0.635665\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392361; batch adversarial loss: 0.562695\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393327; batch adversarial loss: 0.553646\n",
      "epoch 53; iter: 0; batch classifier loss: 0.452042; batch adversarial loss: 0.581425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.461606; batch adversarial loss: 0.562953\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409419; batch adversarial loss: 0.681330\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418140; batch adversarial loss: 0.590162\n",
      "epoch 57; iter: 0; batch classifier loss: 0.497444; batch adversarial loss: 0.490099\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396567; batch adversarial loss: 0.498808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.471236; batch adversarial loss: 0.553401\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385171; batch adversarial loss: 0.526521\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444234; batch adversarial loss: 0.580539\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430043; batch adversarial loss: 0.564159\n",
      "epoch 63; iter: 0; batch classifier loss: 0.418470; batch adversarial loss: 0.517823\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407513; batch adversarial loss: 0.598523\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381820; batch adversarial loss: 0.472043\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386274; batch adversarial loss: 0.581427\n",
      "epoch 67; iter: 0; batch classifier loss: 0.319156; batch adversarial loss: 0.562387\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427840; batch adversarial loss: 0.425270\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417699; batch adversarial loss: 0.517615\n",
      "epoch 70; iter: 0; batch classifier loss: 0.511558; batch adversarial loss: 0.553837\n",
      "epoch 71; iter: 0; batch classifier loss: 0.335917; batch adversarial loss: 0.591281\n",
      "epoch 72; iter: 0; batch classifier loss: 0.487152; batch adversarial loss: 0.599204\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412052; batch adversarial loss: 0.498052\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387591; batch adversarial loss: 0.535771\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360466; batch adversarial loss: 0.554913\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403507; batch adversarial loss: 0.518229\n",
      "epoch 77; iter: 0; batch classifier loss: 0.490066; batch adversarial loss: 0.607846\n",
      "epoch 78; iter: 0; batch classifier loss: 0.481186; batch adversarial loss: 0.562578\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424128; batch adversarial loss: 0.526146\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402607; batch adversarial loss: 0.544793\n",
      "epoch 81; iter: 0; batch classifier loss: 0.339588; batch adversarial loss: 0.572343\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371699; batch adversarial loss: 0.535325\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412975; batch adversarial loss: 0.507731\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429091; batch adversarial loss: 0.517831\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346797; batch adversarial loss: 0.544776\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356340; batch adversarial loss: 0.535548\n",
      "epoch 87; iter: 0; batch classifier loss: 0.463054; batch adversarial loss: 0.571453\n",
      "epoch 88; iter: 0; batch classifier loss: 0.453291; batch adversarial loss: 0.599205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.354398; batch adversarial loss: 0.553680\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365039; batch adversarial loss: 0.544815\n",
      "epoch 91; iter: 0; batch classifier loss: 0.440037; batch adversarial loss: 0.480810\n",
      "epoch 92; iter: 0; batch classifier loss: 0.409144; batch adversarial loss: 0.572529\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384800; batch adversarial loss: 0.617083\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381171; batch adversarial loss: 0.462841\n",
      "epoch 95; iter: 0; batch classifier loss: 0.441393; batch adversarial loss: 0.572056\n",
      "epoch 96; iter: 0; batch classifier loss: 0.458503; batch adversarial loss: 0.535331\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390856; batch adversarial loss: 0.581291\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418277; batch adversarial loss: 0.562645\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397972; batch adversarial loss: 0.499317\n",
      "epoch 100; iter: 0; batch classifier loss: 0.333519; batch adversarial loss: 0.480733\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342683; batch adversarial loss: 0.554331\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437132; batch adversarial loss: 0.526443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399118; batch adversarial loss: 0.580828\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415072; batch adversarial loss: 0.481395\n",
      "epoch 105; iter: 0; batch classifier loss: 0.353914; batch adversarial loss: 0.498879\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388481; batch adversarial loss: 0.571417\n",
      "epoch 107; iter: 0; batch classifier loss: 0.429104; batch adversarial loss: 0.535144\n",
      "epoch 108; iter: 0; batch classifier loss: 0.414510; batch adversarial loss: 0.563477\n",
      "epoch 109; iter: 0; batch classifier loss: 0.394586; batch adversarial loss: 0.581761\n",
      "epoch 110; iter: 0; batch classifier loss: 0.299210; batch adversarial loss: 0.544138\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389903; batch adversarial loss: 0.525917\n",
      "epoch 112; iter: 0; batch classifier loss: 0.444775; batch adversarial loss: 0.508000\n",
      "epoch 113; iter: 0; batch classifier loss: 0.440723; batch adversarial loss: 0.508735\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365808; batch adversarial loss: 0.553777\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405431; batch adversarial loss: 0.544312\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441302; batch adversarial loss: 0.544564\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369342; batch adversarial loss: 0.607544\n",
      "epoch 118; iter: 0; batch classifier loss: 0.291932; batch adversarial loss: 0.554049\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441260; batch adversarial loss: 0.526899\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401478; batch adversarial loss: 0.598818\n",
      "epoch 121; iter: 0; batch classifier loss: 0.298432; batch adversarial loss: 0.517661\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404681; batch adversarial loss: 0.607587\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381584; batch adversarial loss: 0.608285\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411303; batch adversarial loss: 0.670678\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375089; batch adversarial loss: 0.535736\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355590; batch adversarial loss: 0.517025\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401172; batch adversarial loss: 0.517207\n",
      "epoch 128; iter: 0; batch classifier loss: 0.406139; batch adversarial loss: 0.536024\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376797; batch adversarial loss: 0.599494\n",
      "epoch 130; iter: 0; batch classifier loss: 0.444386; batch adversarial loss: 0.490265\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392960; batch adversarial loss: 0.535030\n",
      "epoch 132; iter: 0; batch classifier loss: 0.496298; batch adversarial loss: 0.508561\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377223; batch adversarial loss: 0.553416\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373787; batch adversarial loss: 0.590658\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411147; batch adversarial loss: 0.590190\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414785; batch adversarial loss: 0.553174\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376288; batch adversarial loss: 0.598939\n",
      "epoch 138; iter: 0; batch classifier loss: 0.307924; batch adversarial loss: 0.553716\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359216; batch adversarial loss: 0.590390\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390369; batch adversarial loss: 0.598461\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400654; batch adversarial loss: 0.589644\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398327; batch adversarial loss: 0.544538\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322962; batch adversarial loss: 0.644465\n",
      "epoch 144; iter: 0; batch classifier loss: 0.305662; batch adversarial loss: 0.609030\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355270; batch adversarial loss: 0.508583\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346064; batch adversarial loss: 0.508601\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340270; batch adversarial loss: 0.535475\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410696; batch adversarial loss: 0.525840\n",
      "epoch 149; iter: 0; batch classifier loss: 0.326872; batch adversarial loss: 0.563113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.292843; batch adversarial loss: 0.535370\n",
      "epoch 151; iter: 0; batch classifier loss: 0.370955; batch adversarial loss: 0.607595\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385883; batch adversarial loss: 0.553516\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365087; batch adversarial loss: 0.517166\n",
      "epoch 154; iter: 0; batch classifier loss: 0.380529; batch adversarial loss: 0.535167\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388088; batch adversarial loss: 0.598826\n",
      "epoch 156; iter: 0; batch classifier loss: 0.407200; batch adversarial loss: 0.480946\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373822; batch adversarial loss: 0.644208\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352824; batch adversarial loss: 0.571510\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366452; batch adversarial loss: 0.545292\n",
      "epoch 160; iter: 0; batch classifier loss: 0.287361; batch adversarial loss: 0.554621\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316137; batch adversarial loss: 0.616871\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401067; batch adversarial loss: 0.553261\n",
      "epoch 163; iter: 0; batch classifier loss: 0.396839; batch adversarial loss: 0.553380\n",
      "epoch 164; iter: 0; batch classifier loss: 0.518519; batch adversarial loss: 0.517178\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319316; batch adversarial loss: 0.589946\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343318; batch adversarial loss: 0.553067\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301440; batch adversarial loss: 0.526118\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320758; batch adversarial loss: 0.543168\n",
      "epoch 169; iter: 0; batch classifier loss: 0.377650; batch adversarial loss: 0.553118\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363141; batch adversarial loss: 0.471457\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373933; batch adversarial loss: 0.571507\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377430; batch adversarial loss: 0.617122\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378283; batch adversarial loss: 0.591063\n",
      "epoch 174; iter: 0; batch classifier loss: 0.441583; batch adversarial loss: 0.498753\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380564; batch adversarial loss: 0.472559\n",
      "epoch 176; iter: 0; batch classifier loss: 0.468872; batch adversarial loss: 0.608993\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433898; batch adversarial loss: 0.599022\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337509; batch adversarial loss: 0.545339\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378527; batch adversarial loss: 0.580451\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327116; batch adversarial loss: 0.553409\n",
      "epoch 181; iter: 0; batch classifier loss: 0.425713; batch adversarial loss: 0.498715\n",
      "epoch 182; iter: 0; batch classifier loss: 0.306181; batch adversarial loss: 0.590747\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378579; batch adversarial loss: 0.552945\n",
      "epoch 184; iter: 0; batch classifier loss: 0.323578; batch adversarial loss: 0.544842\n",
      "epoch 185; iter: 0; batch classifier loss: 0.437321; batch adversarial loss: 0.562267\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332125; batch adversarial loss: 0.534365\n",
      "epoch 187; iter: 0; batch classifier loss: 0.366195; batch adversarial loss: 0.525981\n",
      "epoch 188; iter: 0; batch classifier loss: 0.433306; batch adversarial loss: 0.562252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.476715; batch adversarial loss: 0.516972\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340580; batch adversarial loss: 0.525607\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357750; batch adversarial loss: 0.544201\n",
      "epoch 192; iter: 0; batch classifier loss: 0.430361; batch adversarial loss: 0.661996\n",
      "epoch 193; iter: 0; batch classifier loss: 0.361323; batch adversarial loss: 0.515932\n",
      "epoch 194; iter: 0; batch classifier loss: 0.231603; batch adversarial loss: 0.589553\n",
      "epoch 195; iter: 0; batch classifier loss: 0.318304; batch adversarial loss: 0.598152\n",
      "epoch 196; iter: 0; batch classifier loss: 0.285233; batch adversarial loss: 0.517470\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393014; batch adversarial loss: 0.489406\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323332; batch adversarial loss: 0.553147\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357237; batch adversarial loss: 0.572563\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698163; batch adversarial loss: 0.616688\n",
      "epoch 1; iter: 0; batch classifier loss: 0.663634; batch adversarial loss: 0.633686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566748; batch adversarial loss: 0.670351\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543832; batch adversarial loss: 0.639591\n",
      "epoch 4; iter: 0; batch classifier loss: 0.667085; batch adversarial loss: 0.637647\n",
      "epoch 5; iter: 0; batch classifier loss: 0.478779; batch adversarial loss: 0.599591\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510834; batch adversarial loss: 0.612464\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527659; batch adversarial loss: 0.599992\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523463; batch adversarial loss: 0.616150\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526489; batch adversarial loss: 0.590612\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543052; batch adversarial loss: 0.563765\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553105; batch adversarial loss: 0.599154\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469385; batch adversarial loss: 0.563330\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483855; batch adversarial loss: 0.561141\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511566; batch adversarial loss: 0.599345\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563197; batch adversarial loss: 0.577897\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484378; batch adversarial loss: 0.623053\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491208; batch adversarial loss: 0.673372\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446554; batch adversarial loss: 0.543579\n",
      "epoch 19; iter: 0; batch classifier loss: 0.442644; batch adversarial loss: 0.570831\n",
      "epoch 20; iter: 0; batch classifier loss: 0.545972; batch adversarial loss: 0.601628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452300; batch adversarial loss: 0.560826\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450933; batch adversarial loss: 0.576782\n",
      "epoch 23; iter: 0; batch classifier loss: 0.469123; batch adversarial loss: 0.546533\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507033; batch adversarial loss: 0.568655\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458434; batch adversarial loss: 0.480497\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446214; batch adversarial loss: 0.614589\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411999; batch adversarial loss: 0.662831\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431503; batch adversarial loss: 0.608834\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448213; batch adversarial loss: 0.513665\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462767; batch adversarial loss: 0.614371\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500109; batch adversarial loss: 0.502909\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475053; batch adversarial loss: 0.605553\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421940; batch adversarial loss: 0.543111\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522928; batch adversarial loss: 0.561696\n",
      "epoch 35; iter: 0; batch classifier loss: 0.388277; batch adversarial loss: 0.586395\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460562; batch adversarial loss: 0.563674\n",
      "epoch 37; iter: 0; batch classifier loss: 0.514682; batch adversarial loss: 0.648407\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389121; batch adversarial loss: 0.434735\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490734; batch adversarial loss: 0.508826\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413737; batch adversarial loss: 0.516875\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488315; batch adversarial loss: 0.643916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464142; batch adversarial loss: 0.572130\n",
      "epoch 43; iter: 0; batch classifier loss: 0.525095; batch adversarial loss: 0.624754\n",
      "epoch 44; iter: 0; batch classifier loss: 0.494271; batch adversarial loss: 0.576641\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444572; batch adversarial loss: 0.579900\n",
      "epoch 46; iter: 0; batch classifier loss: 0.472991; batch adversarial loss: 0.539492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.419889; batch adversarial loss: 0.563835\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388235; batch adversarial loss: 0.529040\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474439; batch adversarial loss: 0.501755\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441101; batch adversarial loss: 0.510169\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404636; batch adversarial loss: 0.570876\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422570; batch adversarial loss: 0.588750\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388408; batch adversarial loss: 0.606978\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449673; batch adversarial loss: 0.553478\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406049; batch adversarial loss: 0.562447\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414749; batch adversarial loss: 0.518966\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408109; batch adversarial loss: 0.518545\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399067; batch adversarial loss: 0.563046\n",
      "epoch 59; iter: 0; batch classifier loss: 0.352948; batch adversarial loss: 0.484190\n",
      "epoch 60; iter: 0; batch classifier loss: 0.331216; batch adversarial loss: 0.588450\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455929; batch adversarial loss: 0.597013\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410778; batch adversarial loss: 0.536439\n",
      "epoch 63; iter: 0; batch classifier loss: 0.456774; batch adversarial loss: 0.597304\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398688; batch adversarial loss: 0.545011\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455503; batch adversarial loss: 0.510182\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421780; batch adversarial loss: 0.518600\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366472; batch adversarial loss: 0.484780\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403737; batch adversarial loss: 0.484981\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357736; batch adversarial loss: 0.569965\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397463; batch adversarial loss: 0.545209\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413745; batch adversarial loss: 0.526794\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388137; batch adversarial loss: 0.562688\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436553; batch adversarial loss: 0.561987\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411588; batch adversarial loss: 0.553856\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400579; batch adversarial loss: 0.552514\n",
      "epoch 76; iter: 0; batch classifier loss: 0.347660; batch adversarial loss: 0.578933\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441992; batch adversarial loss: 0.571045\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387848; batch adversarial loss: 0.546150\n",
      "epoch 79; iter: 0; batch classifier loss: 0.467753; batch adversarial loss: 0.571067\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407943; batch adversarial loss: 0.535409\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356604; batch adversarial loss: 0.474705\n",
      "epoch 82; iter: 0; batch classifier loss: 0.454482; batch adversarial loss: 0.577577\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374947; batch adversarial loss: 0.553831\n",
      "epoch 84; iter: 0; batch classifier loss: 0.526510; batch adversarial loss: 0.474611\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363341; batch adversarial loss: 0.599663\n",
      "epoch 86; iter: 0; batch classifier loss: 0.342876; batch adversarial loss: 0.535338\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398969; batch adversarial loss: 0.526490\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367875; batch adversarial loss: 0.517933\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433242; batch adversarial loss: 0.499487\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430976; batch adversarial loss: 0.607517\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356344; batch adversarial loss: 0.519220\n",
      "epoch 92; iter: 0; batch classifier loss: 0.486018; batch adversarial loss: 0.606497\n",
      "epoch 93; iter: 0; batch classifier loss: 0.442062; batch adversarial loss: 0.562118\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407008; batch adversarial loss: 0.554004\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446045; batch adversarial loss: 0.527220\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358003; batch adversarial loss: 0.579044\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419771; batch adversarial loss: 0.544711\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362892; batch adversarial loss: 0.493489\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366874; batch adversarial loss: 0.633352\n",
      "epoch 100; iter: 0; batch classifier loss: 0.468601; batch adversarial loss: 0.598120\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357239; batch adversarial loss: 0.589471\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401509; batch adversarial loss: 0.579708\n",
      "epoch 103; iter: 0; batch classifier loss: 0.329829; batch adversarial loss: 0.518480\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370071; batch adversarial loss: 0.519055\n",
      "epoch 105; iter: 0; batch classifier loss: 0.426258; batch adversarial loss: 0.509853\n",
      "epoch 106; iter: 0; batch classifier loss: 0.442846; batch adversarial loss: 0.491423\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347156; batch adversarial loss: 0.535649\n",
      "epoch 108; iter: 0; batch classifier loss: 0.309692; batch adversarial loss: 0.598772\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371986; batch adversarial loss: 0.561373\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348065; batch adversarial loss: 0.534118\n",
      "epoch 111; iter: 0; batch classifier loss: 0.419802; batch adversarial loss: 0.548970\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391530; batch adversarial loss: 0.494056\n",
      "epoch 113; iter: 0; batch classifier loss: 0.441556; batch adversarial loss: 0.551171\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370403; batch adversarial loss: 0.570455\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326287; batch adversarial loss: 0.463589\n",
      "epoch 116; iter: 0; batch classifier loss: 0.418351; batch adversarial loss: 0.587714\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377984; batch adversarial loss: 0.528158\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335359; batch adversarial loss: 0.538094\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342392; batch adversarial loss: 0.554471\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415368; batch adversarial loss: 0.591491\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358868; batch adversarial loss: 0.520902\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377042; batch adversarial loss: 0.580144\n",
      "epoch 123; iter: 0; batch classifier loss: 0.448679; batch adversarial loss: 0.510184\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391467; batch adversarial loss: 0.680512\n",
      "epoch 125; iter: 0; batch classifier loss: 0.364636; batch adversarial loss: 0.572136\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405601; batch adversarial loss: 0.508925\n",
      "epoch 127; iter: 0; batch classifier loss: 0.430986; batch adversarial loss: 0.544059\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432249; batch adversarial loss: 0.561745\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379758; batch adversarial loss: 0.544827\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362079; batch adversarial loss: 0.491642\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359064; batch adversarial loss: 0.535850\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392293; batch adversarial loss: 0.562887\n",
      "epoch 133; iter: 0; batch classifier loss: 0.322523; batch adversarial loss: 0.554503\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387959; batch adversarial loss: 0.649749\n",
      "epoch 135; iter: 0; batch classifier loss: 0.478504; batch adversarial loss: 0.606730\n",
      "epoch 136; iter: 0; batch classifier loss: 0.283338; batch adversarial loss: 0.553262\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358879; batch adversarial loss: 0.615955\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365903; batch adversarial loss: 0.562435\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395499; batch adversarial loss: 0.562419\n",
      "epoch 140; iter: 0; batch classifier loss: 0.363557; batch adversarial loss: 0.553703\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349708; batch adversarial loss: 0.597719\n",
      "epoch 142; iter: 0; batch classifier loss: 0.416311; batch adversarial loss: 0.580262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.266263; batch adversarial loss: 0.553882\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341428; batch adversarial loss: 0.632829\n",
      "epoch 145; iter: 0; batch classifier loss: 0.326414; batch adversarial loss: 0.535684\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413425; batch adversarial loss: 0.580422\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363659; batch adversarial loss: 0.544938\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405449; batch adversarial loss: 0.598105\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344587; batch adversarial loss: 0.465420\n",
      "epoch 150; iter: 0; batch classifier loss: 0.402501; batch adversarial loss: 0.554041\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347423; batch adversarial loss: 0.606414\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403007; batch adversarial loss: 0.509630\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354262; batch adversarial loss: 0.641724\n",
      "epoch 154; iter: 0; batch classifier loss: 0.361946; batch adversarial loss: 0.588825\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337395; batch adversarial loss: 0.483151\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401096; batch adversarial loss: 0.624262\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351651; batch adversarial loss: 0.553891\n",
      "epoch 158; iter: 0; batch classifier loss: 0.484212; batch adversarial loss: 0.544920\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322237; batch adversarial loss: 0.535847\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316707; batch adversarial loss: 0.668719\n",
      "epoch 161; iter: 0; batch classifier loss: 0.389156; batch adversarial loss: 0.562653\n",
      "epoch 162; iter: 0; batch classifier loss: 0.367110; batch adversarial loss: 0.509190\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399974; batch adversarial loss: 0.527455\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369360; batch adversarial loss: 0.571452\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398309; batch adversarial loss: 0.641610\n",
      "epoch 166; iter: 0; batch classifier loss: 0.420822; batch adversarial loss: 0.518424\n",
      "epoch 167; iter: 0; batch classifier loss: 0.463833; batch adversarial loss: 0.562482\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357871; batch adversarial loss: 0.570762\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327702; batch adversarial loss: 0.571090\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339039; batch adversarial loss: 0.615583\n",
      "epoch 171; iter: 0; batch classifier loss: 0.285589; batch adversarial loss: 0.562350\n",
      "epoch 172; iter: 0; batch classifier loss: 0.351811; batch adversarial loss: 0.491666\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354019; batch adversarial loss: 0.588830\n",
      "epoch 174; iter: 0; batch classifier loss: 0.434682; batch adversarial loss: 0.526808\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364152; batch adversarial loss: 0.474217\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343089; batch adversarial loss: 0.598204\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358463; batch adversarial loss: 0.535743\n",
      "epoch 178; iter: 0; batch classifier loss: 0.346301; batch adversarial loss: 0.562809\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340769; batch adversarial loss: 0.526958\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424242; batch adversarial loss: 0.571310\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334013; batch adversarial loss: 0.527174\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340600; batch adversarial loss: 0.553748\n",
      "epoch 183; iter: 0; batch classifier loss: 0.312534; batch adversarial loss: 0.562668\n",
      "epoch 184; iter: 0; batch classifier loss: 0.370472; batch adversarial loss: 0.580263\n",
      "epoch 185; iter: 0; batch classifier loss: 0.453343; batch adversarial loss: 0.651052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335335; batch adversarial loss: 0.562134\n",
      "epoch 187; iter: 0; batch classifier loss: 0.284518; batch adversarial loss: 0.474016\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348848; batch adversarial loss: 0.553554\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336648; batch adversarial loss: 0.562204\n",
      "epoch 190; iter: 0; batch classifier loss: 0.428165; batch adversarial loss: 0.527296\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335228; batch adversarial loss: 0.579443\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313298; batch adversarial loss: 0.598279\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398699; batch adversarial loss: 0.553398\n",
      "epoch 194; iter: 0; batch classifier loss: 0.294610; batch adversarial loss: 0.535902\n",
      "epoch 195; iter: 0; batch classifier loss: 0.300988; batch adversarial loss: 0.615215\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299253; batch adversarial loss: 0.474469\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364915; batch adversarial loss: 0.615346\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370446; batch adversarial loss: 0.589425\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319890; batch adversarial loss: 0.544312\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692580; batch adversarial loss: 0.728631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.625618; batch adversarial loss: 0.633216\n",
      "epoch 2; iter: 0; batch classifier loss: 0.518341; batch adversarial loss: 0.660397\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562480; batch adversarial loss: 0.704256\n",
      "epoch 4; iter: 0; batch classifier loss: 0.495143; batch adversarial loss: 0.672280\n",
      "epoch 5; iter: 0; batch classifier loss: 0.639994; batch adversarial loss: 0.672769\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554614; batch adversarial loss: 0.610738\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565045; batch adversarial loss: 0.552807\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529702; batch adversarial loss: 0.621675\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537642; batch adversarial loss: 0.594216\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501461; batch adversarial loss: 0.567585\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536304; batch adversarial loss: 0.557632\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549306; batch adversarial loss: 0.564242\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485231; batch adversarial loss: 0.548743\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553698; batch adversarial loss: 0.586097\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527943; batch adversarial loss: 0.542154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510094; batch adversarial loss: 0.523317\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474773; batch adversarial loss: 0.547708\n",
      "epoch 18; iter: 0; batch classifier loss: 0.480005; batch adversarial loss: 0.587007\n",
      "epoch 19; iter: 0; batch classifier loss: 0.461666; batch adversarial loss: 0.543833\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500948; batch adversarial loss: 0.556884\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532641; batch adversarial loss: 0.559722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573511; batch adversarial loss: 0.654526\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505629; batch adversarial loss: 0.527238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471380; batch adversarial loss: 0.541206\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513950; batch adversarial loss: 0.590262\n",
      "epoch 26; iter: 0; batch classifier loss: 0.443787; batch adversarial loss: 0.555842\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440715; batch adversarial loss: 0.449521\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496126; batch adversarial loss: 0.551690\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450206; batch adversarial loss: 0.554859\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477380; batch adversarial loss: 0.586787\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447521; batch adversarial loss: 0.534966\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459413; batch adversarial loss: 0.537272\n",
      "epoch 33; iter: 0; batch classifier loss: 0.527710; batch adversarial loss: 0.560665\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481783; batch adversarial loss: 0.518166\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481966; batch adversarial loss: 0.593271\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401819; batch adversarial loss: 0.507736\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481346; batch adversarial loss: 0.554500\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429613; batch adversarial loss: 0.554044\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438252; batch adversarial loss: 0.612976\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439403; batch adversarial loss: 0.537173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.454481; batch adversarial loss: 0.613260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480334; batch adversarial loss: 0.536635\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395085; batch adversarial loss: 0.519521\n",
      "epoch 44; iter: 0; batch classifier loss: 0.480578; batch adversarial loss: 0.561967\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415532; batch adversarial loss: 0.536304\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410114; batch adversarial loss: 0.544738\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483628; batch adversarial loss: 0.553925\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483274; batch adversarial loss: 0.535945\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475925; batch adversarial loss: 0.588303\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470014; batch adversarial loss: 0.571831\n",
      "epoch 51; iter: 0; batch classifier loss: 0.461885; batch adversarial loss: 0.579833\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466638; batch adversarial loss: 0.526221\n",
      "epoch 53; iter: 0; batch classifier loss: 0.351952; batch adversarial loss: 0.518070\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434934; batch adversarial loss: 0.527559\n",
      "epoch 55; iter: 0; batch classifier loss: 0.474411; batch adversarial loss: 0.466670\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420750; batch adversarial loss: 0.527662\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411942; batch adversarial loss: 0.553797\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439752; batch adversarial loss: 0.571372\n",
      "epoch 59; iter: 0; batch classifier loss: 0.516099; batch adversarial loss: 0.589067\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386751; batch adversarial loss: 0.571761\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381816; batch adversarial loss: 0.570142\n",
      "epoch 62; iter: 0; batch classifier loss: 0.431351; batch adversarial loss: 0.596454\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436490; batch adversarial loss: 0.528460\n",
      "epoch 64; iter: 0; batch classifier loss: 0.343563; batch adversarial loss: 0.536290\n",
      "epoch 65; iter: 0; batch classifier loss: 0.358082; batch adversarial loss: 0.536476\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401315; batch adversarial loss: 0.569432\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404720; batch adversarial loss: 0.534767\n",
      "epoch 68; iter: 0; batch classifier loss: 0.459370; batch adversarial loss: 0.533590\n",
      "epoch 69; iter: 0; batch classifier loss: 0.347210; batch adversarial loss: 0.525947\n",
      "epoch 70; iter: 0; batch classifier loss: 0.390165; batch adversarial loss: 0.534839\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393997; batch adversarial loss: 0.534596\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411721; batch adversarial loss: 0.633375\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373311; batch adversarial loss: 0.491365\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343751; batch adversarial loss: 0.534517\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398599; batch adversarial loss: 0.570915\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400183; batch adversarial loss: 0.518378\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440937; batch adversarial loss: 0.570097\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381931; batch adversarial loss: 0.499972\n",
      "epoch 79; iter: 0; batch classifier loss: 0.414503; batch adversarial loss: 0.564413\n",
      "epoch 80; iter: 0; batch classifier loss: 0.346556; batch adversarial loss: 0.544033\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433773; batch adversarial loss: 0.553728\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415774; batch adversarial loss: 0.544985\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404429; batch adversarial loss: 0.572172\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353589; batch adversarial loss: 0.552749\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397491; batch adversarial loss: 0.554067\n",
      "epoch 86; iter: 0; batch classifier loss: 0.331105; batch adversarial loss: 0.606222\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416521; batch adversarial loss: 0.515970\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371710; batch adversarial loss: 0.457893\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428868; batch adversarial loss: 0.579360\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402145; batch adversarial loss: 0.510153\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408361; batch adversarial loss: 0.589003\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347583; batch adversarial loss: 0.479355\n",
      "epoch 93; iter: 0; batch classifier loss: 0.442777; batch adversarial loss: 0.544718\n",
      "epoch 94; iter: 0; batch classifier loss: 0.453839; batch adversarial loss: 0.579639\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451785; batch adversarial loss: 0.543222\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428135; batch adversarial loss: 0.511505\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436414; batch adversarial loss: 0.596624\n",
      "epoch 98; iter: 0; batch classifier loss: 0.337596; batch adversarial loss: 0.594852\n",
      "epoch 99; iter: 0; batch classifier loss: 0.348875; batch adversarial loss: 0.491491\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387409; batch adversarial loss: 0.536778\n",
      "epoch 101; iter: 0; batch classifier loss: 0.423056; batch adversarial loss: 0.499674\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381271; batch adversarial loss: 0.535271\n",
      "epoch 103; iter: 0; batch classifier loss: 0.452239; batch adversarial loss: 0.595750\n",
      "epoch 104; iter: 0; batch classifier loss: 0.329613; batch adversarial loss: 0.657401\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373978; batch adversarial loss: 0.609280\n",
      "epoch 106; iter: 0; batch classifier loss: 0.500290; batch adversarial loss: 0.590610\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431621; batch adversarial loss: 0.563367\n",
      "epoch 108; iter: 0; batch classifier loss: 0.407097; batch adversarial loss: 0.541238\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379982; batch adversarial loss: 0.534353\n",
      "epoch 110; iter: 0; batch classifier loss: 0.449578; batch adversarial loss: 0.527789\n",
      "epoch 111; iter: 0; batch classifier loss: 0.419841; batch adversarial loss: 0.430186\n",
      "epoch 112; iter: 0; batch classifier loss: 0.408320; batch adversarial loss: 0.483632\n",
      "epoch 113; iter: 0; batch classifier loss: 0.388844; batch adversarial loss: 0.502516\n",
      "epoch 114; iter: 0; batch classifier loss: 0.437470; batch adversarial loss: 0.559540\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386599; batch adversarial loss: 0.560927\n",
      "epoch 116; iter: 0; batch classifier loss: 0.371184; batch adversarial loss: 0.536288\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384064; batch adversarial loss: 0.618123\n",
      "epoch 118; iter: 0; batch classifier loss: 0.393805; batch adversarial loss: 0.501123\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389174; batch adversarial loss: 0.519111\n",
      "epoch 120; iter: 0; batch classifier loss: 0.410566; batch adversarial loss: 0.482439\n",
      "epoch 121; iter: 0; batch classifier loss: 0.418630; batch adversarial loss: 0.510454\n",
      "epoch 122; iter: 0; batch classifier loss: 0.375081; batch adversarial loss: 0.511050\n",
      "epoch 123; iter: 0; batch classifier loss: 0.418781; batch adversarial loss: 0.509294\n",
      "epoch 124; iter: 0; batch classifier loss: 0.445815; batch adversarial loss: 0.562926\n",
      "epoch 125; iter: 0; batch classifier loss: 0.430287; batch adversarial loss: 0.615943\n",
      "epoch 126; iter: 0; batch classifier loss: 0.322797; batch adversarial loss: 0.589576\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387973; batch adversarial loss: 0.498575\n",
      "epoch 128; iter: 0; batch classifier loss: 0.428902; batch adversarial loss: 0.519984\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368157; batch adversarial loss: 0.537739\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372978; batch adversarial loss: 0.544550\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354549; batch adversarial loss: 0.588417\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349922; batch adversarial loss: 0.498119\n",
      "epoch 133; iter: 0; batch classifier loss: 0.389852; batch adversarial loss: 0.559846\n",
      "epoch 134; iter: 0; batch classifier loss: 0.444905; batch adversarial loss: 0.587559\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346059; batch adversarial loss: 0.509177\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421303; batch adversarial loss: 0.499765\n",
      "epoch 137; iter: 0; batch classifier loss: 0.324180; batch adversarial loss: 0.551380\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345832; batch adversarial loss: 0.622965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.393483; batch adversarial loss: 0.516668\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359430; batch adversarial loss: 0.509810\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363219; batch adversarial loss: 0.552735\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326390; batch adversarial loss: 0.559847\n",
      "epoch 143; iter: 0; batch classifier loss: 0.321466; batch adversarial loss: 0.534295\n",
      "epoch 144; iter: 0; batch classifier loss: 0.399210; batch adversarial loss: 0.517678\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424205; batch adversarial loss: 0.517663\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361076; batch adversarial loss: 0.553737\n",
      "epoch 147; iter: 0; batch classifier loss: 0.316981; batch adversarial loss: 0.578721\n",
      "epoch 148; iter: 0; batch classifier loss: 0.411951; batch adversarial loss: 0.508887\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388362; batch adversarial loss: 0.536151\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370916; batch adversarial loss: 0.607916\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349530; batch adversarial loss: 0.593203\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372183; batch adversarial loss: 0.499546\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337212; batch adversarial loss: 0.587220\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389294; batch adversarial loss: 0.590969\n",
      "epoch 155; iter: 0; batch classifier loss: 0.457828; batch adversarial loss: 0.606102\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333475; batch adversarial loss: 0.570413\n",
      "epoch 157; iter: 0; batch classifier loss: 0.419145; batch adversarial loss: 0.632220\n",
      "epoch 158; iter: 0; batch classifier loss: 0.350560; batch adversarial loss: 0.544698\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376542; batch adversarial loss: 0.586294\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375173; batch adversarial loss: 0.621118\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311757; batch adversarial loss: 0.491533\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363943; batch adversarial loss: 0.605483\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366263; batch adversarial loss: 0.572293\n",
      "epoch 164; iter: 0; batch classifier loss: 0.433713; batch adversarial loss: 0.624699\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382638; batch adversarial loss: 0.569866\n",
      "epoch 166; iter: 0; batch classifier loss: 0.415754; batch adversarial loss: 0.553636\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337905; batch adversarial loss: 0.536190\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349688; batch adversarial loss: 0.570995\n",
      "epoch 169; iter: 0; batch classifier loss: 0.486853; batch adversarial loss: 0.575358\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360736; batch adversarial loss: 0.563024\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359441; batch adversarial loss: 0.606289\n",
      "epoch 172; iter: 0; batch classifier loss: 0.442717; batch adversarial loss: 0.596031\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377403; batch adversarial loss: 0.474868\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389588; batch adversarial loss: 0.570467\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364005; batch adversarial loss: 0.537446\n",
      "epoch 176; iter: 0; batch classifier loss: 0.438163; batch adversarial loss: 0.600585\n",
      "epoch 177; iter: 0; batch classifier loss: 0.398913; batch adversarial loss: 0.553874\n",
      "epoch 178; iter: 0; batch classifier loss: 0.349630; batch adversarial loss: 0.526921\n",
      "epoch 179; iter: 0; batch classifier loss: 0.273783; batch adversarial loss: 0.572383\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342226; batch adversarial loss: 0.476052\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330707; batch adversarial loss: 0.600254\n",
      "epoch 182; iter: 0; batch classifier loss: 0.311262; batch adversarial loss: 0.589369\n",
      "epoch 183; iter: 0; batch classifier loss: 0.402761; batch adversarial loss: 0.456188\n",
      "epoch 184; iter: 0; batch classifier loss: 0.281709; batch adversarial loss: 0.537935\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372239; batch adversarial loss: 0.544170\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381967; batch adversarial loss: 0.446631\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385435; batch adversarial loss: 0.536296\n",
      "epoch 188; iter: 0; batch classifier loss: 0.389261; batch adversarial loss: 0.528712\n",
      "epoch 189; iter: 0; batch classifier loss: 0.374126; batch adversarial loss: 0.526953\n",
      "epoch 190; iter: 0; batch classifier loss: 0.355475; batch adversarial loss: 0.537292\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330482; batch adversarial loss: 0.570310\n",
      "epoch 192; iter: 0; batch classifier loss: 0.366665; batch adversarial loss: 0.509942\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342429; batch adversarial loss: 0.594942\n",
      "epoch 194; iter: 0; batch classifier loss: 0.324816; batch adversarial loss: 0.499623\n",
      "epoch 195; iter: 0; batch classifier loss: 0.366638; batch adversarial loss: 0.651134\n",
      "epoch 196; iter: 0; batch classifier loss: 0.324986; batch adversarial loss: 0.571607\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361106; batch adversarial loss: 0.580060\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301611; batch adversarial loss: 0.509965\n",
      "epoch 199; iter: 0; batch classifier loss: 0.280520; batch adversarial loss: 0.633798\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693971; batch adversarial loss: 0.627744\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562859; batch adversarial loss: 0.656388\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569102; batch adversarial loss: 0.688681\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586720; batch adversarial loss: 0.643351\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537831; batch adversarial loss: 0.620422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633568; batch adversarial loss: 0.629181\n",
      "epoch 6; iter: 0; batch classifier loss: 0.647468; batch adversarial loss: 0.660952\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592547; batch adversarial loss: 0.679273\n",
      "epoch 8; iter: 0; batch classifier loss: 0.624179; batch adversarial loss: 0.620442\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501103; batch adversarial loss: 0.635749\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574880; batch adversarial loss: 0.593533\n",
      "epoch 11; iter: 0; batch classifier loss: 0.622457; batch adversarial loss: 0.565507\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515499; batch adversarial loss: 0.610837\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530003; batch adversarial loss: 0.572271\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591990; batch adversarial loss: 0.589192\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502379; batch adversarial loss: 0.526910\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523386; batch adversarial loss: 0.504624\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547871; batch adversarial loss: 0.579291\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508670; batch adversarial loss: 0.527382\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525428; batch adversarial loss: 0.570811\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532822; batch adversarial loss: 0.552571\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473344; batch adversarial loss: 0.520416\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450552; batch adversarial loss: 0.555738\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458822; batch adversarial loss: 0.528926\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509002; batch adversarial loss: 0.586399\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521384; batch adversarial loss: 0.524541\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471397; batch adversarial loss: 0.545262\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537700; batch adversarial loss: 0.611087\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479460; batch adversarial loss: 0.562391\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510047; batch adversarial loss: 0.545400\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510506; batch adversarial loss: 0.580858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481650; batch adversarial loss: 0.605260\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447848; batch adversarial loss: 0.493349\n",
      "epoch 33; iter: 0; batch classifier loss: 0.530405; batch adversarial loss: 0.518572\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447617; batch adversarial loss: 0.543428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.432568; batch adversarial loss: 0.500440\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414102; batch adversarial loss: 0.535829\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463313; batch adversarial loss: 0.492646\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442045; batch adversarial loss: 0.580558\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497867; batch adversarial loss: 0.641890\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500624; batch adversarial loss: 0.526993\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434176; batch adversarial loss: 0.581243\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429656; batch adversarial loss: 0.481611\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471914; batch adversarial loss: 0.535773\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437872; batch adversarial loss: 0.491116\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409924; batch adversarial loss: 0.527323\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440670; batch adversarial loss: 0.509593\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456591; batch adversarial loss: 0.553867\n",
      "epoch 48; iter: 0; batch classifier loss: 0.500139; batch adversarial loss: 0.544389\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398083; batch adversarial loss: 0.563048\n",
      "epoch 50; iter: 0; batch classifier loss: 0.436138; batch adversarial loss: 0.562305\n",
      "epoch 51; iter: 0; batch classifier loss: 0.486108; batch adversarial loss: 0.527492\n",
      "epoch 52; iter: 0; batch classifier loss: 0.465044; batch adversarial loss: 0.508700\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472664; batch adversarial loss: 0.589165\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416568; batch adversarial loss: 0.508423\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394820; batch adversarial loss: 0.554199\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393054; batch adversarial loss: 0.499388\n",
      "epoch 57; iter: 0; batch classifier loss: 0.340939; batch adversarial loss: 0.607470\n",
      "epoch 58; iter: 0; batch classifier loss: 0.397567; batch adversarial loss: 0.526863\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447668; batch adversarial loss: 0.580207\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402966; batch adversarial loss: 0.562051\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380394; batch adversarial loss: 0.517644\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379289; batch adversarial loss: 0.553271\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446519; batch adversarial loss: 0.597481\n",
      "epoch 64; iter: 0; batch classifier loss: 0.455280; batch adversarial loss: 0.580786\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437162; batch adversarial loss: 0.562428\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432187; batch adversarial loss: 0.553529\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402149; batch adversarial loss: 0.589461\n",
      "epoch 68; iter: 0; batch classifier loss: 0.351547; batch adversarial loss: 0.508708\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393386; batch adversarial loss: 0.544795\n",
      "epoch 70; iter: 0; batch classifier loss: 0.454899; batch adversarial loss: 0.553287\n",
      "epoch 71; iter: 0; batch classifier loss: 0.486218; batch adversarial loss: 0.526459\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421272; batch adversarial loss: 0.604981\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383899; batch adversarial loss: 0.605012\n",
      "epoch 74; iter: 0; batch classifier loss: 0.440139; batch adversarial loss: 0.534603\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447710; batch adversarial loss: 0.535799\n",
      "epoch 76; iter: 0; batch classifier loss: 0.430685; batch adversarial loss: 0.572363\n",
      "epoch 77; iter: 0; batch classifier loss: 0.490740; batch adversarial loss: 0.534937\n",
      "epoch 78; iter: 0; batch classifier loss: 0.486518; batch adversarial loss: 0.526934\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401023; batch adversarial loss: 0.535416\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402137; batch adversarial loss: 0.562855\n",
      "epoch 81; iter: 0; batch classifier loss: 0.466646; batch adversarial loss: 0.526070\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426458; batch adversarial loss: 0.589931\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367544; batch adversarial loss: 0.545293\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380901; batch adversarial loss: 0.544355\n",
      "epoch 85; iter: 0; batch classifier loss: 0.429553; batch adversarial loss: 0.562711\n",
      "epoch 86; iter: 0; batch classifier loss: 0.512564; batch adversarial loss: 0.534569\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417194; batch adversarial loss: 0.570783\n",
      "epoch 88; iter: 0; batch classifier loss: 0.375982; batch adversarial loss: 0.563100\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433413; batch adversarial loss: 0.578954\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398749; batch adversarial loss: 0.569387\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381436; batch adversarial loss: 0.574247\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355668; batch adversarial loss: 0.544369\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436696; batch adversarial loss: 0.519092\n",
      "epoch 94; iter: 0; batch classifier loss: 0.445706; batch adversarial loss: 0.527478\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415870; batch adversarial loss: 0.545169\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369672; batch adversarial loss: 0.536637\n",
      "epoch 97; iter: 0; batch classifier loss: 0.403733; batch adversarial loss: 0.492397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434761; batch adversarial loss: 0.616331\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414264; batch adversarial loss: 0.490946\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394799; batch adversarial loss: 0.606623\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400055; batch adversarial loss: 0.553392\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435331; batch adversarial loss: 0.581080\n",
      "epoch 103; iter: 0; batch classifier loss: 0.331451; batch adversarial loss: 0.499802\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341566; batch adversarial loss: 0.527132\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382005; batch adversarial loss: 0.499911\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328382; batch adversarial loss: 0.589219\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353468; batch adversarial loss: 0.562690\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367703; batch adversarial loss: 0.579808\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356499; batch adversarial loss: 0.509322\n",
      "epoch 110; iter: 0; batch classifier loss: 0.431361; batch adversarial loss: 0.562231\n",
      "epoch 111; iter: 0; batch classifier loss: 0.454397; batch adversarial loss: 0.563041\n",
      "epoch 112; iter: 0; batch classifier loss: 0.431974; batch adversarial loss: 0.589607\n",
      "epoch 113; iter: 0; batch classifier loss: 0.309146; batch adversarial loss: 0.517081\n",
      "epoch 114; iter: 0; batch classifier loss: 0.443080; batch adversarial loss: 0.553548\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331486; batch adversarial loss: 0.615941\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348177; batch adversarial loss: 0.589364\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378734; batch adversarial loss: 0.545407\n",
      "epoch 118; iter: 0; batch classifier loss: 0.304735; batch adversarial loss: 0.499784\n",
      "epoch 119; iter: 0; batch classifier loss: 0.450553; batch adversarial loss: 0.561593\n",
      "epoch 120; iter: 0; batch classifier loss: 0.449080; batch adversarial loss: 0.501112\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364694; batch adversarial loss: 0.490866\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394327; batch adversarial loss: 0.544655\n",
      "epoch 123; iter: 0; batch classifier loss: 0.417219; batch adversarial loss: 0.498645\n",
      "epoch 124; iter: 0; batch classifier loss: 0.364120; batch adversarial loss: 0.461433\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365867; batch adversarial loss: 0.580577\n",
      "epoch 126; iter: 0; batch classifier loss: 0.409354; batch adversarial loss: 0.553761\n",
      "epoch 127; iter: 0; batch classifier loss: 0.331712; batch adversarial loss: 0.545294\n",
      "epoch 128; iter: 0; batch classifier loss: 0.452948; batch adversarial loss: 0.683003\n",
      "epoch 129; iter: 0; batch classifier loss: 0.390990; batch adversarial loss: 0.464135\n",
      "epoch 130; iter: 0; batch classifier loss: 0.426415; batch adversarial loss: 0.543977\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356970; batch adversarial loss: 0.581370\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325366; batch adversarial loss: 0.600433\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.509007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.297230; batch adversarial loss: 0.525594\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389188; batch adversarial loss: 0.554842\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361277; batch adversarial loss: 0.472577\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328814; batch adversarial loss: 0.545118\n",
      "epoch 138; iter: 0; batch classifier loss: 0.371803; batch adversarial loss: 0.589161\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386434; batch adversarial loss: 0.545138\n",
      "epoch 140; iter: 0; batch classifier loss: 0.506509; batch adversarial loss: 0.617532\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387161; batch adversarial loss: 0.562856\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338106; batch adversarial loss: 0.624936\n",
      "epoch 143; iter: 0; batch classifier loss: 0.420306; batch adversarial loss: 0.516396\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361653; batch adversarial loss: 0.568412\n",
      "epoch 145; iter: 0; batch classifier loss: 0.439704; batch adversarial loss: 0.517388\n",
      "epoch 146; iter: 0; batch classifier loss: 0.427782; batch adversarial loss: 0.527585\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387678; batch adversarial loss: 0.661345\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357821; batch adversarial loss: 0.562449\n",
      "epoch 149; iter: 0; batch classifier loss: 0.444045; batch adversarial loss: 0.535002\n",
      "epoch 150; iter: 0; batch classifier loss: 0.418903; batch adversarial loss: 0.556155\n",
      "epoch 151; iter: 0; batch classifier loss: 0.427281; batch adversarial loss: 0.484078\n",
      "epoch 152; iter: 0; batch classifier loss: 0.318023; batch adversarial loss: 0.508976\n",
      "epoch 153; iter: 0; batch classifier loss: 0.443337; batch adversarial loss: 0.590215\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377104; batch adversarial loss: 0.580347\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344288; batch adversarial loss: 0.500465\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416292; batch adversarial loss: 0.528030\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392781; batch adversarial loss: 0.527867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.402606; batch adversarial loss: 0.535985\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343939; batch adversarial loss: 0.553265\n",
      "epoch 160; iter: 0; batch classifier loss: 0.435651; batch adversarial loss: 0.562301\n",
      "epoch 161; iter: 0; batch classifier loss: 0.426826; batch adversarial loss: 0.580299\n",
      "epoch 162; iter: 0; batch classifier loss: 0.330757; batch adversarial loss: 0.526679\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351927; batch adversarial loss: 0.483194\n",
      "epoch 164; iter: 0; batch classifier loss: 0.359761; batch adversarial loss: 0.491003\n",
      "epoch 165; iter: 0; batch classifier loss: 0.381010; batch adversarial loss: 0.535997\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354293; batch adversarial loss: 0.500579\n",
      "epoch 167; iter: 0; batch classifier loss: 0.268061; batch adversarial loss: 0.509191\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372767; batch adversarial loss: 0.544798\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321199; batch adversarial loss: 0.419400\n",
      "epoch 170; iter: 0; batch classifier loss: 0.377752; batch adversarial loss: 0.553334\n",
      "epoch 171; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 0.642920\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376504; batch adversarial loss: 0.499495\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356443; batch adversarial loss: 0.517516\n",
      "epoch 174; iter: 0; batch classifier loss: 0.449742; batch adversarial loss: 0.580227\n",
      "epoch 175; iter: 0; batch classifier loss: 0.371550; batch adversarial loss: 0.580845\n",
      "epoch 176; iter: 0; batch classifier loss: 0.418418; batch adversarial loss: 0.508466\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392956; batch adversarial loss: 0.526991\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417900; batch adversarial loss: 0.688816\n",
      "epoch 179; iter: 0; batch classifier loss: 0.441791; batch adversarial loss: 0.490524\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400096; batch adversarial loss: 0.633569\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377675; batch adversarial loss: 0.553558\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380268; batch adversarial loss: 0.553376\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370079; batch adversarial loss: 0.562660\n",
      "epoch 184; iter: 0; batch classifier loss: 0.324665; batch adversarial loss: 0.527046\n",
      "epoch 185; iter: 0; batch classifier loss: 0.473441; batch adversarial loss: 0.589119\n",
      "epoch 186; iter: 0; batch classifier loss: 0.420992; batch adversarial loss: 0.463577\n",
      "epoch 187; iter: 0; batch classifier loss: 0.315923; batch adversarial loss: 0.589164\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383149; batch adversarial loss: 0.562578\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370158; batch adversarial loss: 0.580983\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349650; batch adversarial loss: 0.571593\n",
      "epoch 191; iter: 0; batch classifier loss: 0.371848; batch adversarial loss: 0.518180\n",
      "epoch 192; iter: 0; batch classifier loss: 0.237380; batch adversarial loss: 0.544894\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373916; batch adversarial loss: 0.581221\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336354; batch adversarial loss: 0.625764\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398597; batch adversarial loss: 0.535636\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354974; batch adversarial loss: 0.553430\n",
      "epoch 197; iter: 0; batch classifier loss: 0.374977; batch adversarial loss: 0.572058\n",
      "epoch 198; iter: 0; batch classifier loss: 0.373446; batch adversarial loss: 0.534983\n",
      "epoch 199; iter: 0; batch classifier loss: 0.395243; batch adversarial loss: 0.524922\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722033; batch adversarial loss: 0.900236\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622838; batch adversarial loss: 0.928104\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582321; batch adversarial loss: 0.810685\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567667; batch adversarial loss: 0.773362\n",
      "epoch 4; iter: 0; batch classifier loss: 0.504007; batch adversarial loss: 0.748063\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567343; batch adversarial loss: 0.717534\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574549; batch adversarial loss: 0.625348\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493203; batch adversarial loss: 0.651682\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618351; batch adversarial loss: 0.649627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542248; batch adversarial loss: 0.628505\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550289; batch adversarial loss: 0.573298\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494979; batch adversarial loss: 0.609986\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553787; batch adversarial loss: 0.632917\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538239; batch adversarial loss: 0.588778\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525219; batch adversarial loss: 0.617742\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537401; batch adversarial loss: 0.600482\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498694; batch adversarial loss: 0.586477\n",
      "epoch 17; iter: 0; batch classifier loss: 0.589096; batch adversarial loss: 0.602826\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520337; batch adversarial loss: 0.619735\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525230; batch adversarial loss: 0.619732\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469076; batch adversarial loss: 0.592139\n",
      "epoch 21; iter: 0; batch classifier loss: 0.573157; batch adversarial loss: 0.604652\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446829; batch adversarial loss: 0.556900\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507641; batch adversarial loss: 0.585778\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465536; batch adversarial loss: 0.536550\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516421; batch adversarial loss: 0.543542\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486507; batch adversarial loss: 0.669743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449326; batch adversarial loss: 0.585402\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485072; batch adversarial loss: 0.593715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446576; batch adversarial loss: 0.631895\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470755; batch adversarial loss: 0.550642\n",
      "epoch 31; iter: 0; batch classifier loss: 0.559494; batch adversarial loss: 0.637441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.558046; batch adversarial loss: 0.652019\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406634; batch adversarial loss: 0.547905\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451243; batch adversarial loss: 0.534430\n",
      "epoch 35; iter: 0; batch classifier loss: 0.555288; batch adversarial loss: 0.480572\n",
      "epoch 36; iter: 0; batch classifier loss: 0.396521; batch adversarial loss: 0.595415\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445021; batch adversarial loss: 0.564993\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474965; batch adversarial loss: 0.599453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435926; batch adversarial loss: 0.534520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435256; batch adversarial loss: 0.506988\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434592; batch adversarial loss: 0.577342\n",
      "epoch 42; iter: 0; batch classifier loss: 0.522219; batch adversarial loss: 0.579782\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446352; batch adversarial loss: 0.550934\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489322; batch adversarial loss: 0.571402\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442028; batch adversarial loss: 0.543245\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451095; batch adversarial loss: 0.547211\n",
      "epoch 47; iter: 0; batch classifier loss: 0.474585; batch adversarial loss: 0.493729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430545; batch adversarial loss: 0.640193\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448506; batch adversarial loss: 0.571367\n",
      "epoch 50; iter: 0; batch classifier loss: 0.486844; batch adversarial loss: 0.639889\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374684; batch adversarial loss: 0.553571\n",
      "epoch 52; iter: 0; batch classifier loss: 0.339616; batch adversarial loss: 0.552599\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456453; batch adversarial loss: 0.510297\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445925; batch adversarial loss: 0.630826\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395518; batch adversarial loss: 0.546233\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492785; batch adversarial loss: 0.475644\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415044; batch adversarial loss: 0.578536\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469470; batch adversarial loss: 0.545329\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414786; batch adversarial loss: 0.562402\n",
      "epoch 60; iter: 0; batch classifier loss: 0.511055; batch adversarial loss: 0.476258\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436748; batch adversarial loss: 0.562189\n",
      "epoch 62; iter: 0; batch classifier loss: 0.373675; batch adversarial loss: 0.571085\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400478; batch adversarial loss: 0.527383\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386546; batch adversarial loss: 0.528380\n",
      "epoch 65; iter: 0; batch classifier loss: 0.371191; batch adversarial loss: 0.519090\n",
      "epoch 66; iter: 0; batch classifier loss: 0.448571; batch adversarial loss: 0.579972\n",
      "epoch 67; iter: 0; batch classifier loss: 0.382467; batch adversarial loss: 0.459351\n",
      "epoch 68; iter: 0; batch classifier loss: 0.468500; batch adversarial loss: 0.614815\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405566; batch adversarial loss: 0.562262\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406775; batch adversarial loss: 0.562141\n",
      "epoch 71; iter: 0; batch classifier loss: 0.475436; batch adversarial loss: 0.545066\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369187; batch adversarial loss: 0.545225\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408284; batch adversarial loss: 0.501953\n",
      "epoch 74; iter: 0; batch classifier loss: 0.379640; batch adversarial loss: 0.579168\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380967; batch adversarial loss: 0.696805\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470056; batch adversarial loss: 0.621677\n",
      "epoch 77; iter: 0; batch classifier loss: 0.317797; batch adversarial loss: 0.570481\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437904; batch adversarial loss: 0.550044\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411217; batch adversarial loss: 0.538347\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398622; batch adversarial loss: 0.503982\n",
      "epoch 81; iter: 0; batch classifier loss: 0.485090; batch adversarial loss: 0.509205\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363616; batch adversarial loss: 0.517611\n",
      "epoch 83; iter: 0; batch classifier loss: 0.442864; batch adversarial loss: 0.607531\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371098; batch adversarial loss: 0.614209\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394927; batch adversarial loss: 0.545319\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393823; batch adversarial loss: 0.553774\n",
      "epoch 87; iter: 0; batch classifier loss: 0.406081; batch adversarial loss: 0.527197\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340189; batch adversarial loss: 0.553186\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401346; batch adversarial loss: 0.527295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390842; batch adversarial loss: 0.638896\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406268; batch adversarial loss: 0.581859\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377457; batch adversarial loss: 0.596280\n",
      "epoch 93; iter: 0; batch classifier loss: 0.350426; batch adversarial loss: 0.593730\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401994; batch adversarial loss: 0.544538\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401621; batch adversarial loss: 0.638507\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372992; batch adversarial loss: 0.561985\n",
      "epoch 97; iter: 0; batch classifier loss: 0.305063; batch adversarial loss: 0.520033\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397208; batch adversarial loss: 0.538803\n",
      "epoch 99; iter: 0; batch classifier loss: 0.444317; batch adversarial loss: 0.579845\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364122; batch adversarial loss: 0.574089\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363663; batch adversarial loss: 0.465241\n",
      "epoch 102; iter: 0; batch classifier loss: 0.383911; batch adversarial loss: 0.518844\n",
      "epoch 103; iter: 0; batch classifier loss: 0.359920; batch adversarial loss: 0.499307\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368548; batch adversarial loss: 0.627709\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409449; batch adversarial loss: 0.534636\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352307; batch adversarial loss: 0.595487\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339946; batch adversarial loss: 0.553002\n",
      "epoch 108; iter: 0; batch classifier loss: 0.416916; batch adversarial loss: 0.609895\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386189; batch adversarial loss: 0.611145\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409135; batch adversarial loss: 0.606765\n",
      "epoch 111; iter: 0; batch classifier loss: 0.290818; batch adversarial loss: 0.632429\n",
      "epoch 112; iter: 0; batch classifier loss: 0.317623; batch adversarial loss: 0.545238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.419098; batch adversarial loss: 0.613462\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391219; batch adversarial loss: 0.561617\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379189; batch adversarial loss: 0.502106\n",
      "epoch 116; iter: 0; batch classifier loss: 0.430694; batch adversarial loss: 0.589093\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339687; batch adversarial loss: 0.600164\n",
      "epoch 118; iter: 0; batch classifier loss: 0.350979; batch adversarial loss: 0.538145\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347445; batch adversarial loss: 0.492858\n",
      "epoch 120; iter: 0; batch classifier loss: 0.499434; batch adversarial loss: 0.595041\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370208; batch adversarial loss: 0.553833\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383442; batch adversarial loss: 0.595931\n",
      "epoch 123; iter: 0; batch classifier loss: 0.448299; batch adversarial loss: 0.528482\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373393; batch adversarial loss: 0.640123\n",
      "epoch 125; iter: 0; batch classifier loss: 0.366615; batch adversarial loss: 0.543908\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316567; batch adversarial loss: 0.564558\n",
      "epoch 127; iter: 0; batch classifier loss: 0.409258; batch adversarial loss: 0.587638\n",
      "epoch 128; iter: 0; batch classifier loss: 0.405800; batch adversarial loss: 0.587865\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379500; batch adversarial loss: 0.605908\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360870; batch adversarial loss: 0.536394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.341874; batch adversarial loss: 0.518481\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363336; batch adversarial loss: 0.562535\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411207; batch adversarial loss: 0.563147\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378001; batch adversarial loss: 0.545583\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351141; batch adversarial loss: 0.639838\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348913; batch adversarial loss: 0.502885\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371740; batch adversarial loss: 0.588221\n",
      "epoch 138; iter: 0; batch classifier loss: 0.374629; batch adversarial loss: 0.534475\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402232; batch adversarial loss: 0.501142\n",
      "epoch 140; iter: 0; batch classifier loss: 0.407464; batch adversarial loss: 0.493376\n",
      "epoch 141; iter: 0; batch classifier loss: 0.401411; batch adversarial loss: 0.589975\n",
      "epoch 142; iter: 0; batch classifier loss: 0.441437; batch adversarial loss: 0.553049\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353370; batch adversarial loss: 0.557214\n",
      "epoch 144; iter: 0; batch classifier loss: 0.353018; batch adversarial loss: 0.563570\n",
      "epoch 145; iter: 0; batch classifier loss: 0.310619; batch adversarial loss: 0.588156\n",
      "epoch 146; iter: 0; batch classifier loss: 0.318986; batch adversarial loss: 0.552100\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359332; batch adversarial loss: 0.553694\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349057; batch adversarial loss: 0.510369\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347944; batch adversarial loss: 0.597316\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365077; batch adversarial loss: 0.588620\n",
      "epoch 151; iter: 0; batch classifier loss: 0.411724; batch adversarial loss: 0.545078\n",
      "epoch 152; iter: 0; batch classifier loss: 0.457995; batch adversarial loss: 0.624216\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330177; batch adversarial loss: 0.580148\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342213; batch adversarial loss: 0.588607\n",
      "epoch 155; iter: 0; batch classifier loss: 0.448260; batch adversarial loss: 0.586465\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349432; batch adversarial loss: 0.561721\n",
      "epoch 157; iter: 0; batch classifier loss: 0.316489; batch adversarial loss: 0.510273\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391031; batch adversarial loss: 0.544815\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398225; batch adversarial loss: 0.579175\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374608; batch adversarial loss: 0.631869\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375049; batch adversarial loss: 0.536136\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379186; batch adversarial loss: 0.603846\n",
      "epoch 163; iter: 0; batch classifier loss: 0.444661; batch adversarial loss: 0.545493\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414327; batch adversarial loss: 0.510000\n",
      "epoch 165; iter: 0; batch classifier loss: 0.320318; batch adversarial loss: 0.527908\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404927; batch adversarial loss: 0.520416\n",
      "epoch 167; iter: 0; batch classifier loss: 0.437899; batch adversarial loss: 0.552353\n",
      "epoch 168; iter: 0; batch classifier loss: 0.461955; batch adversarial loss: 0.590319\n",
      "epoch 169; iter: 0; batch classifier loss: 0.474186; batch adversarial loss: 0.615213\n",
      "epoch 170; iter: 0; batch classifier loss: 0.312773; batch adversarial loss: 0.521058\n",
      "epoch 171; iter: 0; batch classifier loss: 0.414993; batch adversarial loss: 0.484166\n",
      "epoch 172; iter: 0; batch classifier loss: 0.298391; batch adversarial loss: 0.468184\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313946; batch adversarial loss: 0.614146\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341989; batch adversarial loss: 0.634561\n",
      "epoch 175; iter: 0; batch classifier loss: 0.413689; batch adversarial loss: 0.563245\n",
      "epoch 176; iter: 0; batch classifier loss: 0.364858; batch adversarial loss: 0.570650\n",
      "epoch 177; iter: 0; batch classifier loss: 0.415931; batch adversarial loss: 0.545533\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345012; batch adversarial loss: 0.477085\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391493; batch adversarial loss: 0.578593\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336110; batch adversarial loss: 0.563591\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313253; batch adversarial loss: 0.536028\n",
      "epoch 182; iter: 0; batch classifier loss: 0.448343; batch adversarial loss: 0.510661\n",
      "epoch 183; iter: 0; batch classifier loss: 0.401233; batch adversarial loss: 0.526531\n",
      "epoch 184; iter: 0; batch classifier loss: 0.284743; batch adversarial loss: 0.509567\n",
      "epoch 185; iter: 0; batch classifier loss: 0.403400; batch adversarial loss: 0.528205\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430682; batch adversarial loss: 0.596775\n",
      "epoch 187; iter: 0; batch classifier loss: 0.303565; batch adversarial loss: 0.570305\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334712; batch adversarial loss: 0.552677\n",
      "epoch 189; iter: 0; batch classifier loss: 0.423360; batch adversarial loss: 0.571506\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338523; batch adversarial loss: 0.579430\n",
      "epoch 191; iter: 0; batch classifier loss: 0.338069; batch adversarial loss: 0.587561\n",
      "epoch 192; iter: 0; batch classifier loss: 0.383069; batch adversarial loss: 0.590567\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337892; batch adversarial loss: 0.485381\n",
      "epoch 194; iter: 0; batch classifier loss: 0.431509; batch adversarial loss: 0.553330\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330240; batch adversarial loss: 0.553150\n",
      "epoch 196; iter: 0; batch classifier loss: 0.419307; batch adversarial loss: 0.553453\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356080; batch adversarial loss: 0.536662\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360489; batch adversarial loss: 0.528254\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362401; batch adversarial loss: 0.570889\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680141; batch adversarial loss: 0.954669\n",
      "epoch 1; iter: 0; batch classifier loss: 0.825876; batch adversarial loss: 1.284789\n",
      "epoch 2; iter: 0; batch classifier loss: 0.998028; batch adversarial loss: 1.294815\n",
      "epoch 3; iter: 0; batch classifier loss: 1.197747; batch adversarial loss: 1.226445\n",
      "epoch 4; iter: 0; batch classifier loss: 1.296541; batch adversarial loss: 1.121750\n",
      "epoch 5; iter: 0; batch classifier loss: 1.131462; batch adversarial loss: 1.025286\n",
      "epoch 6; iter: 0; batch classifier loss: 1.482479; batch adversarial loss: 0.976175\n",
      "epoch 7; iter: 0; batch classifier loss: 1.281626; batch adversarial loss: 0.883011\n",
      "epoch 8; iter: 0; batch classifier loss: 1.251817; batch adversarial loss: 0.823587\n",
      "epoch 9; iter: 0; batch classifier loss: 1.238067; batch adversarial loss: 0.762959\n",
      "epoch 10; iter: 0; batch classifier loss: 1.213951; batch adversarial loss: 0.716064\n",
      "epoch 11; iter: 0; batch classifier loss: 1.108300; batch adversarial loss: 0.686786\n",
      "epoch 12; iter: 0; batch classifier loss: 1.193851; batch adversarial loss: 0.634502\n",
      "epoch 13; iter: 0; batch classifier loss: 1.071985; batch adversarial loss: 0.607469\n",
      "epoch 14; iter: 0; batch classifier loss: 0.693859; batch adversarial loss: 0.580990\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548460; batch adversarial loss: 0.608004\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594101; batch adversarial loss: 0.587077\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560714; batch adversarial loss: 0.604713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513169; batch adversarial loss: 0.591300\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473085; batch adversarial loss: 0.591534\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556496; batch adversarial loss: 0.584966\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502889; batch adversarial loss: 0.553062\n",
      "epoch 22; iter: 0; batch classifier loss: 0.523055; batch adversarial loss: 0.584588\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467741; batch adversarial loss: 0.569144\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494062; batch adversarial loss: 0.582447\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533497; batch adversarial loss: 0.560827\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461238; batch adversarial loss: 0.516702\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421442; batch adversarial loss: 0.556342\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441918; batch adversarial loss: 0.541984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.542187; batch adversarial loss: 0.573882\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475232; batch adversarial loss: 0.526529\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435871; batch adversarial loss: 0.554608\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427290; batch adversarial loss: 0.509596\n",
      "epoch 33; iter: 0; batch classifier loss: 0.591422; batch adversarial loss: 0.581808\n",
      "epoch 34; iter: 0; batch classifier loss: 0.512826; batch adversarial loss: 0.603930\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397018; batch adversarial loss: 0.542701\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478859; batch adversarial loss: 0.514573\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423303; batch adversarial loss: 0.590588\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470471; batch adversarial loss: 0.490044\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460089; batch adversarial loss: 0.625852\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475645; batch adversarial loss: 0.581455\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427239; batch adversarial loss: 0.508781\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476086; batch adversarial loss: 0.565132\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442212; batch adversarial loss: 0.567956\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472126; batch adversarial loss: 0.552859\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502476; batch adversarial loss: 0.650654\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461420; batch adversarial loss: 0.580903\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423525; batch adversarial loss: 0.580331\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440962; batch adversarial loss: 0.608825\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383600; batch adversarial loss: 0.580280\n",
      "epoch 50; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.602082\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468498; batch adversarial loss: 0.556507\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426035; batch adversarial loss: 0.583379\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427759; batch adversarial loss: 0.457162\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467034; batch adversarial loss: 0.527315\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376079; batch adversarial loss: 0.576672\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432524; batch adversarial loss: 0.552712\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442752; batch adversarial loss: 0.562786\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414856; batch adversarial loss: 0.571378\n",
      "epoch 59; iter: 0; batch classifier loss: 0.388016; batch adversarial loss: 0.537298\n",
      "epoch 60; iter: 0; batch classifier loss: 0.486538; batch adversarial loss: 0.534454\n",
      "epoch 61; iter: 0; batch classifier loss: 0.473209; batch adversarial loss: 0.501004\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450604; batch adversarial loss: 0.582172\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458380; batch adversarial loss: 0.614962\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420595; batch adversarial loss: 0.484053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.458601; batch adversarial loss: 0.669517\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415019; batch adversarial loss: 0.527941\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414952; batch adversarial loss: 0.535850\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428052; batch adversarial loss: 0.606459\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425203; batch adversarial loss: 0.570954\n",
      "epoch 70; iter: 0; batch classifier loss: 0.503484; batch adversarial loss: 0.549748\n",
      "epoch 71; iter: 0; batch classifier loss: 0.469836; batch adversarial loss: 0.546124\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427049; batch adversarial loss: 0.532732\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349948; batch adversarial loss: 0.568096\n",
      "epoch 74; iter: 0; batch classifier loss: 0.442393; batch adversarial loss: 0.532820\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377371; batch adversarial loss: 0.525912\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400197; batch adversarial loss: 0.543170\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417598; batch adversarial loss: 0.573726\n",
      "epoch 78; iter: 0; batch classifier loss: 0.469791; batch adversarial loss: 0.506823\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395885; batch adversarial loss: 0.558398\n",
      "epoch 80; iter: 0; batch classifier loss: 0.348652; batch adversarial loss: 0.600795\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392460; batch adversarial loss: 0.534622\n",
      "epoch 82; iter: 0; batch classifier loss: 0.460952; batch adversarial loss: 0.648656\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403168; batch adversarial loss: 0.568507\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404778; batch adversarial loss: 0.560340\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380874; batch adversarial loss: 0.518836\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456993; batch adversarial loss: 0.543879\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340670; batch adversarial loss: 0.536781\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420490; batch adversarial loss: 0.569589\n",
      "epoch 89; iter: 0; batch classifier loss: 0.465116; batch adversarial loss: 0.524486\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434685; batch adversarial loss: 0.570520\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414340; batch adversarial loss: 0.574224\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391210; batch adversarial loss: 0.546413\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402451; batch adversarial loss: 0.542671\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406169; batch adversarial loss: 0.597721\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374456; batch adversarial loss: 0.574410\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405738; batch adversarial loss: 0.507548\n",
      "epoch 97; iter: 0; batch classifier loss: 0.353224; batch adversarial loss: 0.498581\n",
      "epoch 98; iter: 0; batch classifier loss: 0.405403; batch adversarial loss: 0.518318\n",
      "epoch 99; iter: 0; batch classifier loss: 0.323364; batch adversarial loss: 0.519000\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424055; batch adversarial loss: 0.627778\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408948; batch adversarial loss: 0.515112\n",
      "epoch 102; iter: 0; batch classifier loss: 0.376681; batch adversarial loss: 0.539242\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373615; batch adversarial loss: 0.600125\n",
      "epoch 104; iter: 0; batch classifier loss: 0.471691; batch adversarial loss: 0.553328\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378147; batch adversarial loss: 0.546601\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389597; batch adversarial loss: 0.574433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.376769; batch adversarial loss: 0.552970\n",
      "epoch 108; iter: 0; batch classifier loss: 0.350104; batch adversarial loss: 0.579715\n",
      "epoch 109; iter: 0; batch classifier loss: 0.299243; batch adversarial loss: 0.553434\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356140; batch adversarial loss: 0.517062\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354150; batch adversarial loss: 0.581762\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366613; batch adversarial loss: 0.596560\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338557; batch adversarial loss: 0.571745\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411664; batch adversarial loss: 0.479629\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355485; batch adversarial loss: 0.554434\n",
      "epoch 116; iter: 0; batch classifier loss: 0.277737; batch adversarial loss: 0.626209\n",
      "epoch 117; iter: 0; batch classifier loss: 0.328990; batch adversarial loss: 0.561994\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340900; batch adversarial loss: 0.598424\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368678; batch adversarial loss: 0.617344\n",
      "epoch 120; iter: 0; batch classifier loss: 0.336845; batch adversarial loss: 0.555969\n",
      "epoch 121; iter: 0; batch classifier loss: 0.344107; batch adversarial loss: 0.546484\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386890; batch adversarial loss: 0.492703\n",
      "epoch 123; iter: 0; batch classifier loss: 0.340128; batch adversarial loss: 0.601941\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358871; batch adversarial loss: 0.565930\n",
      "epoch 125; iter: 0; batch classifier loss: 0.374746; batch adversarial loss: 0.580161\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398252; batch adversarial loss: 0.545423\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388803; batch adversarial loss: 0.613676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.336064; batch adversarial loss: 0.516457\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342413; batch adversarial loss: 0.517386\n",
      "epoch 130; iter: 0; batch classifier loss: 0.419982; batch adversarial loss: 0.490867\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371319; batch adversarial loss: 0.590407\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333613; batch adversarial loss: 0.525762\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398868; batch adversarial loss: 0.570913\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371625; batch adversarial loss: 0.652318\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373720; batch adversarial loss: 0.471372\n",
      "epoch 136; iter: 0; batch classifier loss: 0.347614; batch adversarial loss: 0.597958\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345154; batch adversarial loss: 0.579545\n",
      "epoch 138; iter: 0; batch classifier loss: 0.431897; batch adversarial loss: 0.561820\n",
      "epoch 139; iter: 0; batch classifier loss: 0.421788; batch adversarial loss: 0.614360\n",
      "epoch 140; iter: 0; batch classifier loss: 0.385182; batch adversarial loss: 0.516146\n",
      "epoch 141; iter: 0; batch classifier loss: 0.310299; batch adversarial loss: 0.534388\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397496; batch adversarial loss: 0.589221\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360171; batch adversarial loss: 0.536466\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366330; batch adversarial loss: 0.572322\n",
      "epoch 145; iter: 0; batch classifier loss: 0.423667; batch adversarial loss: 0.553583\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377146; batch adversarial loss: 0.551627\n",
      "epoch 147; iter: 0; batch classifier loss: 0.320074; batch adversarial loss: 0.569996\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352630; batch adversarial loss: 0.589514\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376460; batch adversarial loss: 0.562177\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364871; batch adversarial loss: 0.501199\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398189; batch adversarial loss: 0.613778\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354534; batch adversarial loss: 0.518969\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329404; batch adversarial loss: 0.617705\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342751; batch adversarial loss: 0.554178\n",
      "epoch 155; iter: 0; batch classifier loss: 0.291603; batch adversarial loss: 0.527130\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313319; batch adversarial loss: 0.589798\n",
      "epoch 157; iter: 0; batch classifier loss: 0.327370; batch adversarial loss: 0.562330\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355134; batch adversarial loss: 0.582691\n",
      "epoch 159; iter: 0; batch classifier loss: 0.270147; batch adversarial loss: 0.579519\n",
      "epoch 160; iter: 0; batch classifier loss: 0.280864; batch adversarial loss: 0.568973\n",
      "epoch 161; iter: 0; batch classifier loss: 0.323183; batch adversarial loss: 0.563903\n",
      "epoch 162; iter: 0; batch classifier loss: 0.285947; batch adversarial loss: 0.561049\n",
      "epoch 163; iter: 0; batch classifier loss: 0.297885; batch adversarial loss: 0.624661\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410256; batch adversarial loss: 0.563505\n",
      "epoch 165; iter: 0; batch classifier loss: 0.287631; batch adversarial loss: 0.545583\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361167; batch adversarial loss: 0.573875\n",
      "epoch 167; iter: 0; batch classifier loss: 0.403782; batch adversarial loss: 0.588812\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337540; batch adversarial loss: 0.607257\n",
      "epoch 169; iter: 0; batch classifier loss: 0.409358; batch adversarial loss: 0.537072\n",
      "epoch 170; iter: 0; batch classifier loss: 0.294482; batch adversarial loss: 0.533490\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323367; batch adversarial loss: 0.542269\n",
      "epoch 172; iter: 0; batch classifier loss: 0.330094; batch adversarial loss: 0.597115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.313983; batch adversarial loss: 0.563152\n",
      "epoch 174; iter: 0; batch classifier loss: 0.291280; batch adversarial loss: 0.615817\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332805; batch adversarial loss: 0.571516\n",
      "epoch 176; iter: 0; batch classifier loss: 0.277675; batch adversarial loss: 0.474250\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344334; batch adversarial loss: 0.531605\n",
      "epoch 178; iter: 0; batch classifier loss: 0.265544; batch adversarial loss: 0.545081\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377020; batch adversarial loss: 0.530124\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326034; batch adversarial loss: 0.514748\n",
      "epoch 181; iter: 0; batch classifier loss: 0.303604; batch adversarial loss: 0.542209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370615; batch adversarial loss: 0.507982\n",
      "epoch 183; iter: 0; batch classifier loss: 0.300918; batch adversarial loss: 0.571502\n",
      "epoch 184; iter: 0; batch classifier loss: 0.255883; batch adversarial loss: 0.564264\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354626; batch adversarial loss: 0.490313\n",
      "epoch 186; iter: 0; batch classifier loss: 0.284431; batch adversarial loss: 0.567307\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333432; batch adversarial loss: 0.509518\n",
      "epoch 188; iter: 0; batch classifier loss: 0.316989; batch adversarial loss: 0.560124\n",
      "epoch 189; iter: 0; batch classifier loss: 0.237477; batch adversarial loss: 0.473104\n",
      "epoch 190; iter: 0; batch classifier loss: 0.261349; batch adversarial loss: 0.544054\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324190; batch adversarial loss: 0.577878\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384848; batch adversarial loss: 0.474381\n",
      "epoch 193; iter: 0; batch classifier loss: 0.271878; batch adversarial loss: 0.547431\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338774; batch adversarial loss: 0.623262\n",
      "epoch 195; iter: 0; batch classifier loss: 0.414495; batch adversarial loss: 0.509434\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316823; batch adversarial loss: 0.615800\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368090; batch adversarial loss: 0.616725\n",
      "epoch 198; iter: 0; batch classifier loss: 0.298635; batch adversarial loss: 0.593295\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350312; batch adversarial loss: 0.580807\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675191; batch adversarial loss: 0.788089\n",
      "epoch 1; iter: 0; batch classifier loss: 0.755782; batch adversarial loss: 1.046188\n",
      "epoch 2; iter: 0; batch classifier loss: 0.844611; batch adversarial loss: 0.952412\n",
      "epoch 3; iter: 0; batch classifier loss: 0.953410; batch adversarial loss: 0.874421\n",
      "epoch 4; iter: 0; batch classifier loss: 1.024472; batch adversarial loss: 0.796013\n",
      "epoch 5; iter: 0; batch classifier loss: 0.757968; batch adversarial loss: 0.747197\n",
      "epoch 6; iter: 0; batch classifier loss: 0.830180; batch adversarial loss: 0.674117\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619619; batch adversarial loss: 0.653724\n",
      "epoch 8; iter: 0; batch classifier loss: 0.675658; batch adversarial loss: 0.617821\n",
      "epoch 9; iter: 0; batch classifier loss: 0.603978; batch adversarial loss: 0.623693\n",
      "epoch 10; iter: 0; batch classifier loss: 0.613161; batch adversarial loss: 0.629017\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490016; batch adversarial loss: 0.601925\n",
      "epoch 12; iter: 0; batch classifier loss: 0.592187; batch adversarial loss: 0.588214\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536390; batch adversarial loss: 0.549011\n",
      "epoch 14; iter: 0; batch classifier loss: 0.453821; batch adversarial loss: 0.600725\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589900; batch adversarial loss: 0.552842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471602; batch adversarial loss: 0.539513\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534480; batch adversarial loss: 0.597176\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466549; batch adversarial loss: 0.578805\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478385; batch adversarial loss: 0.505790\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451141; batch adversarial loss: 0.621048\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482566; batch adversarial loss: 0.525089\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492921; batch adversarial loss: 0.598792\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478508; batch adversarial loss: 0.594370\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464006; batch adversarial loss: 0.590074\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437355; batch adversarial loss: 0.586576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.534986; batch adversarial loss: 0.536146\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491181; batch adversarial loss: 0.542366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478384; batch adversarial loss: 0.532342\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480054; batch adversarial loss: 0.581844\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437212; batch adversarial loss: 0.504270\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458934; batch adversarial loss: 0.579272\n",
      "epoch 32; iter: 0; batch classifier loss: 0.375950; batch adversarial loss: 0.554772\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401187; batch adversarial loss: 0.545180\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469114; batch adversarial loss: 0.530383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476027; batch adversarial loss: 0.613210\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433553; batch adversarial loss: 0.562501\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481692; batch adversarial loss: 0.666610\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463819; batch adversarial loss: 0.570730\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466801; batch adversarial loss: 0.596743\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456003; batch adversarial loss: 0.581002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459745; batch adversarial loss: 0.573636\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406286; batch adversarial loss: 0.622596\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394596; batch adversarial loss: 0.555292\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451216; batch adversarial loss: 0.469275\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443430; batch adversarial loss: 0.544549\n",
      "epoch 46; iter: 0; batch classifier loss: 0.575821; batch adversarial loss: 0.529786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464880; batch adversarial loss: 0.493798\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397689; batch adversarial loss: 0.570816\n",
      "epoch 49; iter: 0; batch classifier loss: 0.453572; batch adversarial loss: 0.519325\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438727; batch adversarial loss: 0.605692\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422468; batch adversarial loss: 0.528164\n",
      "epoch 52; iter: 0; batch classifier loss: 0.500710; batch adversarial loss: 0.571400\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394655; batch adversarial loss: 0.650469\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462881; batch adversarial loss: 0.510094\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400404; batch adversarial loss: 0.500501\n",
      "epoch 56; iter: 0; batch classifier loss: 0.364082; batch adversarial loss: 0.579856\n",
      "epoch 57; iter: 0; batch classifier loss: 0.424252; batch adversarial loss: 0.474950\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384169; batch adversarial loss: 0.500692\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428953; batch adversarial loss: 0.527825\n",
      "epoch 60; iter: 0; batch classifier loss: 0.342035; batch adversarial loss: 0.641535\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401838; batch adversarial loss: 0.483070\n",
      "epoch 62; iter: 0; batch classifier loss: 0.454178; batch adversarial loss: 0.554170\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410662; batch adversarial loss: 0.535976\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388734; batch adversarial loss: 0.518536\n",
      "epoch 65; iter: 0; batch classifier loss: 0.418805; batch adversarial loss: 0.518269\n",
      "epoch 66; iter: 0; batch classifier loss: 0.507700; batch adversarial loss: 0.571144\n",
      "epoch 67; iter: 0; batch classifier loss: 0.343479; batch adversarial loss: 0.466210\n",
      "epoch 68; iter: 0; batch classifier loss: 0.327873; batch adversarial loss: 0.615075\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417659; batch adversarial loss: 0.474143\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364264; batch adversarial loss: 0.580130\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387946; batch adversarial loss: 0.597425\n",
      "epoch 72; iter: 0; batch classifier loss: 0.450845; batch adversarial loss: 0.579543\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405405; batch adversarial loss: 0.518111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.344532; batch adversarial loss: 0.562245\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360985; batch adversarial loss: 0.500993\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359218; batch adversarial loss: 0.544791\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390352; batch adversarial loss: 0.527286\n",
      "epoch 78; iter: 0; batch classifier loss: 0.433873; batch adversarial loss: 0.640518\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406157; batch adversarial loss: 0.535650\n",
      "epoch 80; iter: 0; batch classifier loss: 0.440150; batch adversarial loss: 0.571797\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435515; batch adversarial loss: 0.544764\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379344; batch adversarial loss: 0.606392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341709; batch adversarial loss: 0.510269\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441197; batch adversarial loss: 0.581005\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409903; batch adversarial loss: 0.597230\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367307; batch adversarial loss: 0.561927\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417546; batch adversarial loss: 0.570692\n",
      "epoch 88; iter: 0; batch classifier loss: 0.453011; batch adversarial loss: 0.616151\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369606; batch adversarial loss: 0.501634\n",
      "epoch 90; iter: 0; batch classifier loss: 0.416700; batch adversarial loss: 0.526320\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448562; batch adversarial loss: 0.561896\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347205; batch adversarial loss: 0.588964\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375650; batch adversarial loss: 0.571717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.353293; batch adversarial loss: 0.587384\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333034; batch adversarial loss: 0.544069\n",
      "epoch 96; iter: 0; batch classifier loss: 0.385744; batch adversarial loss: 0.517442\n",
      "epoch 97; iter: 0; batch classifier loss: 0.463868; batch adversarial loss: 0.536574\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377265; batch adversarial loss: 0.500735\n",
      "epoch 99; iter: 0; batch classifier loss: 0.352612; batch adversarial loss: 0.623623\n",
      "epoch 100; iter: 0; batch classifier loss: 0.462928; batch adversarial loss: 0.589232\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342880; batch adversarial loss: 0.560845\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354434; batch adversarial loss: 0.447010\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337691; batch adversarial loss: 0.571156\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358636; batch adversarial loss: 0.519257\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404089; batch adversarial loss: 0.526511\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379863; batch adversarial loss: 0.509659\n",
      "epoch 107; iter: 0; batch classifier loss: 0.436692; batch adversarial loss: 0.482210\n",
      "epoch 108; iter: 0; batch classifier loss: 0.336278; batch adversarial loss: 0.544687\n",
      "epoch 109; iter: 0; batch classifier loss: 0.339724; batch adversarial loss: 0.588979\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404615; batch adversarial loss: 0.517438\n",
      "epoch 111; iter: 0; batch classifier loss: 0.341654; batch adversarial loss: 0.667409\n",
      "epoch 112; iter: 0; batch classifier loss: 0.460583; batch adversarial loss: 0.537507\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351730; batch adversarial loss: 0.517005\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433511; batch adversarial loss: 0.465504\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411959; batch adversarial loss: 0.535270\n",
      "epoch 116; iter: 0; batch classifier loss: 0.306001; batch adversarial loss: 0.572198\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340286; batch adversarial loss: 0.571745\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395913; batch adversarial loss: 0.605372\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385270; batch adversarial loss: 0.615676\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379723; batch adversarial loss: 0.579685\n",
      "epoch 121; iter: 0; batch classifier loss: 0.402199; batch adversarial loss: 0.483312\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369559; batch adversarial loss: 0.589702\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401363; batch adversarial loss: 0.573119\n",
      "epoch 124; iter: 0; batch classifier loss: 0.314795; batch adversarial loss: 0.668711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.365319; batch adversarial loss: 0.466505\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348146; batch adversarial loss: 0.626020\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385373; batch adversarial loss: 0.621646\n",
      "epoch 128; iter: 0; batch classifier loss: 0.294583; batch adversarial loss: 0.509497\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373174; batch adversarial loss: 0.491317\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425962; batch adversarial loss: 0.573185\n",
      "epoch 131; iter: 0; batch classifier loss: 0.341035; batch adversarial loss: 0.597641\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342667; batch adversarial loss: 0.500623\n",
      "epoch 133; iter: 0; batch classifier loss: 0.348779; batch adversarial loss: 0.500970\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338166; batch adversarial loss: 0.581727\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368604; batch adversarial loss: 0.562120\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361813; batch adversarial loss: 0.606374\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400295; batch adversarial loss: 0.554055\n",
      "epoch 138; iter: 0; batch classifier loss: 0.286918; batch adversarial loss: 0.526689\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336453; batch adversarial loss: 0.508225\n",
      "epoch 140; iter: 0; batch classifier loss: 0.316510; batch adversarial loss: 0.501075\n",
      "epoch 141; iter: 0; batch classifier loss: 0.301179; batch adversarial loss: 0.597439\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354916; batch adversarial loss: 0.546089\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369452; batch adversarial loss: 0.501131\n",
      "epoch 144; iter: 0; batch classifier loss: 0.434431; batch adversarial loss: 0.598823\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362394; batch adversarial loss: 0.490395\n",
      "epoch 146; iter: 0; batch classifier loss: 0.326027; batch adversarial loss: 0.634034\n",
      "epoch 147; iter: 0; batch classifier loss: 0.297508; batch adversarial loss: 0.622849\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417651; batch adversarial loss: 0.588956\n",
      "epoch 149; iter: 0; batch classifier loss: 0.425611; batch adversarial loss: 0.545131\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412733; batch adversarial loss: 0.589079\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353264; batch adversarial loss: 0.554500\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366031; batch adversarial loss: 0.528488\n",
      "epoch 153; iter: 0; batch classifier loss: 0.312687; batch adversarial loss: 0.508941\n",
      "epoch 154; iter: 0; batch classifier loss: 0.270467; batch adversarial loss: 0.587768\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408156; batch adversarial loss: 0.490609\n",
      "epoch 156; iter: 0; batch classifier loss: 0.326607; batch adversarial loss: 0.483516\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340304; batch adversarial loss: 0.545049\n",
      "epoch 158; iter: 0; batch classifier loss: 0.311396; batch adversarial loss: 0.492900\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367199; batch adversarial loss: 0.484723\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381452; batch adversarial loss: 0.597841\n",
      "epoch 161; iter: 0; batch classifier loss: 0.275657; batch adversarial loss: 0.597477\n",
      "epoch 162; iter: 0; batch classifier loss: 0.314414; batch adversarial loss: 0.587554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.394961; batch adversarial loss: 0.562987\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312950; batch adversarial loss: 0.562678\n",
      "epoch 165; iter: 0; batch classifier loss: 0.302251; batch adversarial loss: 0.517811\n",
      "epoch 166; iter: 0; batch classifier loss: 0.349330; batch adversarial loss: 0.545505\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398440; batch adversarial loss: 0.580552\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318600; batch adversarial loss: 0.448698\n",
      "epoch 169; iter: 0; batch classifier loss: 0.413604; batch adversarial loss: 0.508559\n",
      "epoch 170; iter: 0; batch classifier loss: 0.248374; batch adversarial loss: 0.544684\n",
      "epoch 171; iter: 0; batch classifier loss: 0.319769; batch adversarial loss: 0.536453\n",
      "epoch 172; iter: 0; batch classifier loss: 0.429348; batch adversarial loss: 0.553113\n",
      "epoch 173; iter: 0; batch classifier loss: 0.379099; batch adversarial loss: 0.535006\n",
      "epoch 174; iter: 0; batch classifier loss: 0.332348; batch adversarial loss: 0.589098\n",
      "epoch 175; iter: 0; batch classifier loss: 0.442451; batch adversarial loss: 0.559837\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344910; batch adversarial loss: 0.608735\n",
      "epoch 177; iter: 0; batch classifier loss: 0.415206; batch adversarial loss: 0.625389\n",
      "epoch 178; iter: 0; batch classifier loss: 0.349909; batch adversarial loss: 0.562851\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337910; batch adversarial loss: 0.571555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335681; batch adversarial loss: 0.595855\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331098; batch adversarial loss: 0.678634\n",
      "epoch 182; iter: 0; batch classifier loss: 0.310769; batch adversarial loss: 0.554071\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382495; batch adversarial loss: 0.534126\n",
      "epoch 184; iter: 0; batch classifier loss: 0.318416; batch adversarial loss: 0.553695\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423093; batch adversarial loss: 0.572395\n",
      "epoch 186; iter: 0; batch classifier loss: 0.302555; batch adversarial loss: 0.492884\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398254; batch adversarial loss: 0.483626\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346404; batch adversarial loss: 0.562525\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341203; batch adversarial loss: 0.589709\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346773; batch adversarial loss: 0.554384\n",
      "epoch 191; iter: 0; batch classifier loss: 0.371527; batch adversarial loss: 0.571969\n",
      "epoch 192; iter: 0; batch classifier loss: 0.353035; batch adversarial loss: 0.552223\n",
      "epoch 193; iter: 0; batch classifier loss: 0.245099; batch adversarial loss: 0.509295\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347477; batch adversarial loss: 0.533939\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322200; batch adversarial loss: 0.553511\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378011; batch adversarial loss: 0.518297\n",
      "epoch 197; iter: 0; batch classifier loss: 0.299502; batch adversarial loss: 0.482874\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403807; batch adversarial loss: 0.527050\n",
      "epoch 199; iter: 0; batch classifier loss: 0.320440; batch adversarial loss: 0.598973\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690421; batch adversarial loss: 0.552006\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588556; batch adversarial loss: 0.643077\n",
      "epoch 2; iter: 0; batch classifier loss: 0.666040; batch adversarial loss: 0.659170\n",
      "epoch 3; iter: 0; batch classifier loss: 0.552181; batch adversarial loss: 0.645610\n",
      "epoch 4; iter: 0; batch classifier loss: 0.592807; batch adversarial loss: 0.672903\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612418; batch adversarial loss: 0.662409\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560570; batch adversarial loss: 0.631121\n",
      "epoch 7; iter: 0; batch classifier loss: 0.482603; batch adversarial loss: 0.581695\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543839; batch adversarial loss: 0.542135\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554718; batch adversarial loss: 0.618952\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519355; batch adversarial loss: 0.622347\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496196; batch adversarial loss: 0.572212\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559103; batch adversarial loss: 0.618784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536444; batch adversarial loss: 0.556134\n",
      "epoch 14; iter: 0; batch classifier loss: 0.552197; batch adversarial loss: 0.561808\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546070; batch adversarial loss: 0.507556\n",
      "epoch 16; iter: 0; batch classifier loss: 0.535256; batch adversarial loss: 0.540374\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516969; batch adversarial loss: 0.532301\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498332; batch adversarial loss: 0.572827\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530951; batch adversarial loss: 0.608758\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440857; batch adversarial loss: 0.563786\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513661; batch adversarial loss: 0.555458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458943; batch adversarial loss: 0.545911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.562588; batch adversarial loss: 0.596000\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476484; batch adversarial loss: 0.545989\n",
      "epoch 25; iter: 0; batch classifier loss: 0.384345; batch adversarial loss: 0.613084\n",
      "epoch 26; iter: 0; batch classifier loss: 0.417502; batch adversarial loss: 0.546473\n",
      "epoch 27; iter: 0; batch classifier loss: 0.422296; batch adversarial loss: 0.570845\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462058; batch adversarial loss: 0.520034\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472703; batch adversarial loss: 0.512299\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444819; batch adversarial loss: 0.639454\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489376; batch adversarial loss: 0.571260\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491936; batch adversarial loss: 0.553319\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472500; batch adversarial loss: 0.501135\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485610; batch adversarial loss: 0.589095\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428118; batch adversarial loss: 0.589797\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486629; batch adversarial loss: 0.525681\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388140; batch adversarial loss: 0.579912\n",
      "epoch 38; iter: 0; batch classifier loss: 0.485950; batch adversarial loss: 0.501212\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413975; batch adversarial loss: 0.589612\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403916; batch adversarial loss: 0.519261\n",
      "epoch 41; iter: 0; batch classifier loss: 0.495185; batch adversarial loss: 0.570371\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464709; batch adversarial loss: 0.648100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396148; batch adversarial loss: 0.483942\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468989; batch adversarial loss: 0.596412\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415982; batch adversarial loss: 0.527160\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441426; batch adversarial loss: 0.552989\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462944; batch adversarial loss: 0.554121\n",
      "epoch 48; iter: 0; batch classifier loss: 0.535901; batch adversarial loss: 0.519089\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388287; batch adversarial loss: 0.500963\n",
      "epoch 50; iter: 0; batch classifier loss: 0.375320; batch adversarial loss: 0.623682\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440717; batch adversarial loss: 0.620816\n",
      "epoch 52; iter: 0; batch classifier loss: 0.459474; batch adversarial loss: 0.579411\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454078; batch adversarial loss: 0.615011\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445179; batch adversarial loss: 0.598033\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421610; batch adversarial loss: 0.517848\n",
      "epoch 56; iter: 0; batch classifier loss: 0.349146; batch adversarial loss: 0.528839\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393469; batch adversarial loss: 0.518896\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419318; batch adversarial loss: 0.615306\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468094; batch adversarial loss: 0.561292\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425575; batch adversarial loss: 0.553070\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427167; batch adversarial loss: 0.561944\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434932; batch adversarial loss: 0.536978\n",
      "epoch 63; iter: 0; batch classifier loss: 0.427737; batch adversarial loss: 0.614302\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406430; batch adversarial loss: 0.658473\n",
      "epoch 65; iter: 0; batch classifier loss: 0.440396; batch adversarial loss: 0.580196\n",
      "epoch 66; iter: 0; batch classifier loss: 0.466798; batch adversarial loss: 0.526770\n",
      "epoch 67; iter: 0; batch classifier loss: 0.390215; batch adversarial loss: 0.588311\n",
      "epoch 68; iter: 0; batch classifier loss: 0.343555; batch adversarial loss: 0.499386\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423724; batch adversarial loss: 0.552036\n",
      "epoch 70; iter: 0; batch classifier loss: 0.365483; batch adversarial loss: 0.554267\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412585; batch adversarial loss: 0.519689\n",
      "epoch 72; iter: 0; batch classifier loss: 0.443637; batch adversarial loss: 0.579263\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385934; batch adversarial loss: 0.619985\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468554; batch adversarial loss: 0.527252\n",
      "epoch 75; iter: 0; batch classifier loss: 0.483000; batch adversarial loss: 0.626562\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400892; batch adversarial loss: 0.474057\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407476; batch adversarial loss: 0.491250\n",
      "epoch 78; iter: 0; batch classifier loss: 0.422823; batch adversarial loss: 0.554798\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357940; batch adversarial loss: 0.560342\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356089; batch adversarial loss: 0.534917\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404596; batch adversarial loss: 0.544176\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359292; batch adversarial loss: 0.563834\n",
      "epoch 83; iter: 0; batch classifier loss: 0.340382; batch adversarial loss: 0.535677\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370571; batch adversarial loss: 0.599499\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377755; batch adversarial loss: 0.552795\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433306; batch adversarial loss: 0.526805\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373460; batch adversarial loss: 0.518504\n",
      "epoch 88; iter: 0; batch classifier loss: 0.380723; batch adversarial loss: 0.553078\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419417; batch adversarial loss: 0.580751\n",
      "epoch 90; iter: 0; batch classifier loss: 0.441970; batch adversarial loss: 0.500867\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363688; batch adversarial loss: 0.593873\n",
      "epoch 92; iter: 0; batch classifier loss: 0.460803; batch adversarial loss: 0.615594\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450387; batch adversarial loss: 0.625354\n",
      "epoch 94; iter: 0; batch classifier loss: 0.417998; batch adversarial loss: 0.641555\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352959; batch adversarial loss: 0.507880\n",
      "epoch 96; iter: 0; batch classifier loss: 0.467181; batch adversarial loss: 0.579947\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359585; batch adversarial loss: 0.607413\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395103; batch adversarial loss: 0.526798\n",
      "epoch 99; iter: 0; batch classifier loss: 0.284343; batch adversarial loss: 0.581407\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370760; batch adversarial loss: 0.536280\n",
      "epoch 101; iter: 0; batch classifier loss: 0.343065; batch adversarial loss: 0.544918\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369522; batch adversarial loss: 0.571285\n",
      "epoch 103; iter: 0; batch classifier loss: 0.382162; batch adversarial loss: 0.518601\n",
      "epoch 104; iter: 0; batch classifier loss: 0.433170; batch adversarial loss: 0.465310\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388567; batch adversarial loss: 0.598129\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343003; batch adversarial loss: 0.544992\n",
      "epoch 107; iter: 0; batch classifier loss: 0.433547; batch adversarial loss: 0.510016\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372129; batch adversarial loss: 0.490613\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359159; batch adversarial loss: 0.492628\n",
      "epoch 110; iter: 0; batch classifier loss: 0.435476; batch adversarial loss: 0.598064\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354898; batch adversarial loss: 0.570884\n",
      "epoch 112; iter: 0; batch classifier loss: 0.326951; batch adversarial loss: 0.597462\n",
      "epoch 113; iter: 0; batch classifier loss: 0.427280; batch adversarial loss: 0.535596\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381763; batch adversarial loss: 0.589498\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391187; batch adversarial loss: 0.596907\n",
      "epoch 116; iter: 0; batch classifier loss: 0.435974; batch adversarial loss: 0.554132\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416914; batch adversarial loss: 0.554315\n",
      "epoch 118; iter: 0; batch classifier loss: 0.407520; batch adversarial loss: 0.535922\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373649; batch adversarial loss: 0.571467\n",
      "epoch 120; iter: 0; batch classifier loss: 0.517525; batch adversarial loss: 0.509012\n",
      "epoch 121; iter: 0; batch classifier loss: 0.384680; batch adversarial loss: 0.553315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.316492; batch adversarial loss: 0.535564\n",
      "epoch 123; iter: 0; batch classifier loss: 0.371197; batch adversarial loss: 0.491429\n",
      "epoch 124; iter: 0; batch classifier loss: 0.332490; batch adversarial loss: 0.517492\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330114; batch adversarial loss: 0.597416\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360028; batch adversarial loss: 0.518159\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443774; batch adversarial loss: 0.536129\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418146; batch adversarial loss: 0.570987\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380550; batch adversarial loss: 0.491481\n",
      "epoch 130; iter: 0; batch classifier loss: 0.440424; batch adversarial loss: 0.526430\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367435; batch adversarial loss: 0.535571\n",
      "epoch 132; iter: 0; batch classifier loss: 0.397256; batch adversarial loss: 0.545164\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376206; batch adversarial loss: 0.526335\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369173; batch adversarial loss: 0.570843\n",
      "epoch 135; iter: 0; batch classifier loss: 0.393315; batch adversarial loss: 0.634074\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402041; batch adversarial loss: 0.544637\n",
      "epoch 137; iter: 0; batch classifier loss: 0.415605; batch adversarial loss: 0.579571\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346393; batch adversarial loss: 0.500348\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336155; batch adversarial loss: 0.570460\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387529; batch adversarial loss: 0.473574\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389420; batch adversarial loss: 0.571031\n",
      "epoch 142; iter: 0; batch classifier loss: 0.407124; batch adversarial loss: 0.580613\n",
      "epoch 143; iter: 0; batch classifier loss: 0.430512; batch adversarial loss: 0.491880\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346995; batch adversarial loss: 0.544024\n",
      "epoch 145; iter: 0; batch classifier loss: 0.354459; batch adversarial loss: 0.598092\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371876; batch adversarial loss: 0.571616\n",
      "epoch 147; iter: 0; batch classifier loss: 0.371209; batch adversarial loss: 0.535381\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328475; batch adversarial loss: 0.597267\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373111; batch adversarial loss: 0.500232\n",
      "epoch 150; iter: 0; batch classifier loss: 0.386103; batch adversarial loss: 0.535980\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351891; batch adversarial loss: 0.588181\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341125; batch adversarial loss: 0.553649\n",
      "epoch 153; iter: 0; batch classifier loss: 0.277843; batch adversarial loss: 0.544100\n",
      "epoch 154; iter: 0; batch classifier loss: 0.324371; batch adversarial loss: 0.518748\n",
      "epoch 155; iter: 0; batch classifier loss: 0.393781; batch adversarial loss: 0.571391\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340320; batch adversarial loss: 0.570606\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339062; batch adversarial loss: 0.544506\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361564; batch adversarial loss: 0.571611\n",
      "epoch 159; iter: 0; batch classifier loss: 0.378235; batch adversarial loss: 0.527120\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339241; batch adversarial loss: 0.606081\n",
      "epoch 161; iter: 0; batch classifier loss: 0.418223; batch adversarial loss: 0.544489\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350401; batch adversarial loss: 0.544855\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354957; batch adversarial loss: 0.482370\n",
      "epoch 164; iter: 0; batch classifier loss: 0.394706; batch adversarial loss: 0.571229\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377842; batch adversarial loss: 0.535474\n",
      "epoch 166; iter: 0; batch classifier loss: 0.251839; batch adversarial loss: 0.534513\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401847; batch adversarial loss: 0.545270\n",
      "epoch 168; iter: 0; batch classifier loss: 0.410816; batch adversarial loss: 0.545301\n",
      "epoch 169; iter: 0; batch classifier loss: 0.373231; batch adversarial loss: 0.641044\n",
      "epoch 170; iter: 0; batch classifier loss: 0.293690; batch adversarial loss: 0.641141\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329601; batch adversarial loss: 0.554204\n",
      "epoch 172; iter: 0; batch classifier loss: 0.325102; batch adversarial loss: 0.623798\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410543; batch adversarial loss: 0.570483\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377261; batch adversarial loss: 0.587642\n",
      "epoch 175; iter: 0; batch classifier loss: 0.327434; batch adversarial loss: 0.561840\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366821; batch adversarial loss: 0.535814\n",
      "epoch 177; iter: 0; batch classifier loss: 0.356463; batch adversarial loss: 0.482700\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360431; batch adversarial loss: 0.554339\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347715; batch adversarial loss: 0.571300\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340463; batch adversarial loss: 0.527189\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364617; batch adversarial loss: 0.588808\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382631; batch adversarial loss: 0.508837\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370798; batch adversarial loss: 0.509419\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358827; batch adversarial loss: 0.553664\n",
      "epoch 185; iter: 0; batch classifier loss: 0.436252; batch adversarial loss: 0.553847\n",
      "epoch 186; iter: 0; batch classifier loss: 0.352109; batch adversarial loss: 0.535997\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313758; batch adversarial loss: 0.535924\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356231; batch adversarial loss: 0.500198\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379992; batch adversarial loss: 0.534380\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368402; batch adversarial loss: 0.438907\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359836; batch adversarial loss: 0.569336\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319657; batch adversarial loss: 0.526323\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403235; batch adversarial loss: 0.519256\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361310; batch adversarial loss: 0.553104\n",
      "epoch 195; iter: 0; batch classifier loss: 0.407734; batch adversarial loss: 0.641800\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323723; batch adversarial loss: 0.543223\n",
      "epoch 197; iter: 0; batch classifier loss: 0.372355; batch adversarial loss: 0.518569\n",
      "epoch 198; iter: 0; batch classifier loss: 0.498608; batch adversarial loss: 0.624749\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362283; batch adversarial loss: 0.553832\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733122; batch adversarial loss: 0.692935\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551500; batch adversarial loss: 0.656457\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596091; batch adversarial loss: 0.651998\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547670; batch adversarial loss: 0.660297\n",
      "epoch 4; iter: 0; batch classifier loss: 0.499685; batch adversarial loss: 0.626627\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633915; batch adversarial loss: 0.627931\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542431; batch adversarial loss: 0.611513\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555940; batch adversarial loss: 0.567910\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582247; batch adversarial loss: 0.611699\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518977; batch adversarial loss: 0.582024\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548574; batch adversarial loss: 0.586383\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573560; batch adversarial loss: 0.563111\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543095; batch adversarial loss: 0.559267\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501714; batch adversarial loss: 0.547868\n",
      "epoch 14; iter: 0; batch classifier loss: 0.609197; batch adversarial loss: 0.646182\n",
      "epoch 15; iter: 0; batch classifier loss: 0.450165; batch adversarial loss: 0.591876\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529138; batch adversarial loss: 0.498910\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528187; batch adversarial loss: 0.543788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.498842; batch adversarial loss: 0.574871\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475457; batch adversarial loss: 0.579616\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489009; batch adversarial loss: 0.560703\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504515; batch adversarial loss: 0.563611\n",
      "epoch 22; iter: 0; batch classifier loss: 0.425570; batch adversarial loss: 0.496083\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504174; batch adversarial loss: 0.514809\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461480; batch adversarial loss: 0.559862\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510120; batch adversarial loss: 0.550216\n",
      "epoch 26; iter: 0; batch classifier loss: 0.525560; batch adversarial loss: 0.606992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440592; batch adversarial loss: 0.515530\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468020; batch adversarial loss: 0.561386\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413340; batch adversarial loss: 0.523955\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496794; batch adversarial loss: 0.671881\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432725; batch adversarial loss: 0.563807\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444302; batch adversarial loss: 0.546645\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474756; batch adversarial loss: 0.546705\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430389; batch adversarial loss: 0.562838\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427231; batch adversarial loss: 0.589272\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486837; batch adversarial loss: 0.563457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446470; batch adversarial loss: 0.562990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420476; batch adversarial loss: 0.617569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432427; batch adversarial loss: 0.530575\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449249; batch adversarial loss: 0.554699\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469038; batch adversarial loss: 0.528273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.401268; batch adversarial loss: 0.483100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412407; batch adversarial loss: 0.572558\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389014; batch adversarial loss: 0.543856\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471971; batch adversarial loss: 0.525548\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430643; batch adversarial loss: 0.507923\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451965; batch adversarial loss: 0.561878\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372334; batch adversarial loss: 0.572138\n",
      "epoch 49; iter: 0; batch classifier loss: 0.536256; batch adversarial loss: 0.570613\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431188; batch adversarial loss: 0.534491\n",
      "epoch 51; iter: 0; batch classifier loss: 0.457671; batch adversarial loss: 0.535317\n",
      "epoch 52; iter: 0; batch classifier loss: 0.473059; batch adversarial loss: 0.515266\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420974; batch adversarial loss: 0.561005\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384003; batch adversarial loss: 0.554197\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428103; batch adversarial loss: 0.515681\n",
      "epoch 56; iter: 0; batch classifier loss: 0.367400; batch adversarial loss: 0.517863\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401076; batch adversarial loss: 0.544482\n",
      "epoch 58; iter: 0; batch classifier loss: 0.379296; batch adversarial loss: 0.571250\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439155; batch adversarial loss: 0.507672\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440068; batch adversarial loss: 0.635604\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366430; batch adversarial loss: 0.535290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.473296; batch adversarial loss: 0.508411\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439201; batch adversarial loss: 0.552534\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397052; batch adversarial loss: 0.526426\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441042; batch adversarial loss: 0.552416\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426457; batch adversarial loss: 0.573210\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402349; batch adversarial loss: 0.608706\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425601; batch adversarial loss: 0.534060\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457655; batch adversarial loss: 0.535344\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412996; batch adversarial loss: 0.516303\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414680; batch adversarial loss: 0.590501\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413259; batch adversarial loss: 0.561023\n",
      "epoch 73; iter: 0; batch classifier loss: 0.397256; batch adversarial loss: 0.533973\n",
      "epoch 74; iter: 0; batch classifier loss: 0.370647; batch adversarial loss: 0.553724\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412316; batch adversarial loss: 0.500360\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396349; batch adversarial loss: 0.526517\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383739; batch adversarial loss: 0.544758\n",
      "epoch 78; iter: 0; batch classifier loss: 0.477820; batch adversarial loss: 0.535039\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394532; batch adversarial loss: 0.471512\n",
      "epoch 80; iter: 0; batch classifier loss: 0.397452; batch adversarial loss: 0.525472\n",
      "epoch 81; iter: 0; batch classifier loss: 0.319973; batch adversarial loss: 0.562832\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401160; batch adversarial loss: 0.516837\n",
      "epoch 83; iter: 0; batch classifier loss: 0.339254; batch adversarial loss: 0.434903\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368650; batch adversarial loss: 0.462400\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367994; batch adversarial loss: 0.499057\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389691; batch adversarial loss: 0.517237\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366177; batch adversarial loss: 0.507928\n",
      "epoch 88; iter: 0; batch classifier loss: 0.399637; batch adversarial loss: 0.590104\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425760; batch adversarial loss: 0.517171\n",
      "epoch 90; iter: 0; batch classifier loss: 0.479292; batch adversarial loss: 0.544442\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402542; batch adversarial loss: 0.498936\n",
      "epoch 92; iter: 0; batch classifier loss: 0.448619; batch adversarial loss: 0.535263\n",
      "epoch 93; iter: 0; batch classifier loss: 0.425963; batch adversarial loss: 0.608195\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348755; batch adversarial loss: 0.563002\n",
      "epoch 95; iter: 0; batch classifier loss: 0.338273; batch adversarial loss: 0.599341\n",
      "epoch 96; iter: 0; batch classifier loss: 0.323267; batch adversarial loss: 0.498961\n",
      "epoch 97; iter: 0; batch classifier loss: 0.380242; batch adversarial loss: 0.517226\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410985; batch adversarial loss: 0.508013\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414123; batch adversarial loss: 0.526719\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387754; batch adversarial loss: 0.571328\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408465; batch adversarial loss: 0.599442\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390763; batch adversarial loss: 0.461684\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369458; batch adversarial loss: 0.498611\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401593; batch adversarial loss: 0.572137\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396150; batch adversarial loss: 0.554177\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339799; batch adversarial loss: 0.590186\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358326; batch adversarial loss: 0.562836\n",
      "epoch 108; iter: 0; batch classifier loss: 0.429221; batch adversarial loss: 0.608540\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387289; batch adversarial loss: 0.535404\n",
      "epoch 110; iter: 0; batch classifier loss: 0.441546; batch adversarial loss: 0.534820\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388513; batch adversarial loss: 0.544377\n",
      "epoch 112; iter: 0; batch classifier loss: 0.451114; batch adversarial loss: 0.517788\n",
      "epoch 113; iter: 0; batch classifier loss: 0.450433; batch adversarial loss: 0.507725\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412625; batch adversarial loss: 0.553746\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423533; batch adversarial loss: 0.571711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.371347; batch adversarial loss: 0.626939\n",
      "epoch 117; iter: 0; batch classifier loss: 0.361243; batch adversarial loss: 0.517252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390943; batch adversarial loss: 0.535314\n",
      "epoch 119; iter: 0; batch classifier loss: 0.364561; batch adversarial loss: 0.581793\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391240; batch adversarial loss: 0.590230\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392236; batch adversarial loss: 0.516773\n",
      "epoch 122; iter: 0; batch classifier loss: 0.435427; batch adversarial loss: 0.563226\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389320; batch adversarial loss: 0.498715\n",
      "epoch 124; iter: 0; batch classifier loss: 0.312940; batch adversarial loss: 0.525834\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401792; batch adversarial loss: 0.554053\n",
      "epoch 126; iter: 0; batch classifier loss: 0.422749; batch adversarial loss: 0.470646\n",
      "epoch 127; iter: 0; batch classifier loss: 0.434245; batch adversarial loss: 0.543479\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402367; batch adversarial loss: 0.562660\n",
      "epoch 129; iter: 0; batch classifier loss: 0.433396; batch adversarial loss: 0.608730\n",
      "epoch 130; iter: 0; batch classifier loss: 0.407104; batch adversarial loss: 0.589797\n",
      "epoch 131; iter: 0; batch classifier loss: 0.327994; batch adversarial loss: 0.508119\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376387; batch adversarial loss: 0.580979\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426626; batch adversarial loss: 0.543755\n",
      "epoch 134; iter: 0; batch classifier loss: 0.495972; batch adversarial loss: 0.526121\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353702; batch adversarial loss: 0.639461\n",
      "epoch 136; iter: 0; batch classifier loss: 0.407281; batch adversarial loss: 0.526867\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413348; batch adversarial loss: 0.553559\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386589; batch adversarial loss: 0.535469\n",
      "epoch 139; iter: 0; batch classifier loss: 0.419353; batch adversarial loss: 0.589999\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346202; batch adversarial loss: 0.562790\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342741; batch adversarial loss: 0.625679\n",
      "epoch 142; iter: 0; batch classifier loss: 0.365349; batch adversarial loss: 0.526521\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355014; batch adversarial loss: 0.553796\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340035; batch adversarial loss: 0.516995\n",
      "epoch 145; iter: 0; batch classifier loss: 0.394189; batch adversarial loss: 0.526586\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403264; batch adversarial loss: 0.608798\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347038; batch adversarial loss: 0.590244\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381696; batch adversarial loss: 0.498773\n",
      "epoch 149; iter: 0; batch classifier loss: 0.406748; batch adversarial loss: 0.507350\n",
      "epoch 150; iter: 0; batch classifier loss: 0.272807; batch adversarial loss: 0.599415\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386897; batch adversarial loss: 0.517203\n",
      "epoch 152; iter: 0; batch classifier loss: 0.287652; batch adversarial loss: 0.534884\n",
      "epoch 153; iter: 0; batch classifier loss: 0.417386; batch adversarial loss: 0.544355\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373520; batch adversarial loss: 0.627208\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323520; batch adversarial loss: 0.517141\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341046; batch adversarial loss: 0.572073\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377772; batch adversarial loss: 0.462385\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392759; batch adversarial loss: 0.526115\n",
      "epoch 159; iter: 0; batch classifier loss: 0.423083; batch adversarial loss: 0.508417\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319077; batch adversarial loss: 0.572626\n",
      "epoch 161; iter: 0; batch classifier loss: 0.458117; batch adversarial loss: 0.570641\n",
      "epoch 162; iter: 0; batch classifier loss: 0.388143; batch adversarial loss: 0.507720\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358689; batch adversarial loss: 0.580702\n",
      "epoch 164; iter: 0; batch classifier loss: 0.447451; batch adversarial loss: 0.543808\n",
      "epoch 165; iter: 0; batch classifier loss: 0.304901; batch adversarial loss: 0.471452\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351873; batch adversarial loss: 0.544562\n",
      "epoch 167; iter: 0; batch classifier loss: 0.411592; batch adversarial loss: 0.516829\n",
      "epoch 168; iter: 0; batch classifier loss: 0.389050; batch adversarial loss: 0.535393\n",
      "epoch 169; iter: 0; batch classifier loss: 0.513375; batch adversarial loss: 0.479664\n",
      "epoch 170; iter: 0; batch classifier loss: 0.402649; batch adversarial loss: 0.536218\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384586; batch adversarial loss: 0.591016\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366511; batch adversarial loss: 0.554264\n",
      "epoch 173; iter: 0; batch classifier loss: 0.368620; batch adversarial loss: 0.571296\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366763; batch adversarial loss: 0.516319\n",
      "epoch 175; iter: 0; batch classifier loss: 0.425795; batch adversarial loss: 0.470337\n",
      "epoch 176; iter: 0; batch classifier loss: 0.269606; batch adversarial loss: 0.488945\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324252; batch adversarial loss: 0.625532\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367547; batch adversarial loss: 0.554346\n",
      "epoch 179; iter: 0; batch classifier loss: 0.411683; batch adversarial loss: 0.570708\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382632; batch adversarial loss: 0.499297\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323794; batch adversarial loss: 0.561879\n",
      "epoch 182; iter: 0; batch classifier loss: 0.325603; batch adversarial loss: 0.554893\n",
      "epoch 183; iter: 0; batch classifier loss: 0.325013; batch adversarial loss: 0.536656\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352940; batch adversarial loss: 0.543756\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321538; batch adversarial loss: 0.571383\n",
      "epoch 186; iter: 0; batch classifier loss: 0.417266; batch adversarial loss: 0.598504\n",
      "epoch 187; iter: 0; batch classifier loss: 0.418829; batch adversarial loss: 0.534120\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384820; batch adversarial loss: 0.543167\n",
      "epoch 189; iter: 0; batch classifier loss: 0.312581; batch adversarial loss: 0.671692\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379030; batch adversarial loss: 0.526915\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325218; batch adversarial loss: 0.580077\n",
      "epoch 192; iter: 0; batch classifier loss: 0.407796; batch adversarial loss: 0.645795\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389207; batch adversarial loss: 0.509536\n",
      "epoch 194; iter: 0; batch classifier loss: 0.402874; batch adversarial loss: 0.611771\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370796; batch adversarial loss: 0.516366\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312321; batch adversarial loss: 0.451959\n",
      "epoch 197; iter: 0; batch classifier loss: 0.314999; batch adversarial loss: 0.535604\n",
      "epoch 198; iter: 0; batch classifier loss: 0.313806; batch adversarial loss: 0.656456\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323287; batch adversarial loss: 0.535324\n",
      "epoch 0; iter: 0; batch classifier loss: 0.827333; batch adversarial loss: 0.878801\n",
      "epoch 1; iter: 0; batch classifier loss: 0.777170; batch adversarial loss: 0.832248\n",
      "epoch 2; iter: 0; batch classifier loss: 0.790063; batch adversarial loss: 0.760237\n",
      "epoch 3; iter: 0; batch classifier loss: 0.713697; batch adversarial loss: 0.718827\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598298; batch adversarial loss: 0.698537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543474; batch adversarial loss: 0.617202\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590374; batch adversarial loss: 0.596448\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537734; batch adversarial loss: 0.607866\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533441; batch adversarial loss: 0.624395\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529044; batch adversarial loss: 0.626251\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540905; batch adversarial loss: 0.622629\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540744; batch adversarial loss: 0.611317\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531300; batch adversarial loss: 0.578287\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542337; batch adversarial loss: 0.534448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.571302; batch adversarial loss: 0.569169\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554400; batch adversarial loss: 0.542034\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477025; batch adversarial loss: 0.590805\n",
      "epoch 17; iter: 0; batch classifier loss: 0.581761; batch adversarial loss: 0.552434\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547356; batch adversarial loss: 0.563324\n",
      "epoch 19; iter: 0; batch classifier loss: 0.466332; batch adversarial loss: 0.531097\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532587; batch adversarial loss: 0.584983\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498067; batch adversarial loss: 0.501029\n",
      "epoch 22; iter: 0; batch classifier loss: 0.559671; batch adversarial loss: 0.653226\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471788; batch adversarial loss: 0.518094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474291; batch adversarial loss: 0.571129\n",
      "epoch 25; iter: 0; batch classifier loss: 0.529985; batch adversarial loss: 0.562824\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560211; batch adversarial loss: 0.557133\n",
      "epoch 27; iter: 0; batch classifier loss: 0.519775; batch adversarial loss: 0.538789\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529631; batch adversarial loss: 0.618761\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466916; batch adversarial loss: 0.471516\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416414; batch adversarial loss: 0.588270\n",
      "epoch 31; iter: 0; batch classifier loss: 0.607085; batch adversarial loss: 0.546322\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527160; batch adversarial loss: 0.543802\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443648; batch adversarial loss: 0.569095\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500677; batch adversarial loss: 0.542852\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406130; batch adversarial loss: 0.521351\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458374; batch adversarial loss: 0.564716\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465113; batch adversarial loss: 0.554309\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452385; batch adversarial loss: 0.597937\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485822; batch adversarial loss: 0.515049\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412503; batch adversarial loss: 0.640533\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422754; batch adversarial loss: 0.564336\n",
      "epoch 42; iter: 0; batch classifier loss: 0.521686; batch adversarial loss: 0.528101\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470754; batch adversarial loss: 0.511928\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422066; batch adversarial loss: 0.563087\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457468; batch adversarial loss: 0.536395\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460908; batch adversarial loss: 0.545141\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437589; batch adversarial loss: 0.519017\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409286; batch adversarial loss: 0.571134\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470831; batch adversarial loss: 0.571187\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442573; batch adversarial loss: 0.579681\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463217; batch adversarial loss: 0.597703\n",
      "epoch 52; iter: 0; batch classifier loss: 0.381859; batch adversarial loss: 0.562339\n",
      "epoch 53; iter: 0; batch classifier loss: 0.436348; batch adversarial loss: 0.607173\n",
      "epoch 54; iter: 0; batch classifier loss: 0.475131; batch adversarial loss: 0.535253\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429926; batch adversarial loss: 0.561866\n",
      "epoch 56; iter: 0; batch classifier loss: 0.474285; batch adversarial loss: 0.543294\n",
      "epoch 57; iter: 0; batch classifier loss: 0.482626; batch adversarial loss: 0.553067\n",
      "epoch 58; iter: 0; batch classifier loss: 0.475910; batch adversarial loss: 0.527560\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416988; batch adversarial loss: 0.536570\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477987; batch adversarial loss: 0.587203\n",
      "epoch 61; iter: 0; batch classifier loss: 0.491843; batch adversarial loss: 0.542399\n",
      "epoch 62; iter: 0; batch classifier loss: 0.497288; batch adversarial loss: 0.536053\n",
      "epoch 63; iter: 0; batch classifier loss: 0.380907; batch adversarial loss: 0.596457\n",
      "epoch 64; iter: 0; batch classifier loss: 0.472644; batch adversarial loss: 0.438088\n",
      "epoch 65; iter: 0; batch classifier loss: 0.494709; batch adversarial loss: 0.545268\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421865; batch adversarial loss: 0.588175\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379330; batch adversarial loss: 0.597398\n",
      "epoch 68; iter: 0; batch classifier loss: 0.445880; batch adversarial loss: 0.535252\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475560; batch adversarial loss: 0.550253\n",
      "epoch 70; iter: 0; batch classifier loss: 0.347404; batch adversarial loss: 0.546497\n",
      "epoch 71; iter: 0; batch classifier loss: 0.462613; batch adversarial loss: 0.557972\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345957; batch adversarial loss: 0.557132\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393723; batch adversarial loss: 0.561660\n",
      "epoch 74; iter: 0; batch classifier loss: 0.449683; batch adversarial loss: 0.537629\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387425; batch adversarial loss: 0.586790\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372869; batch adversarial loss: 0.520188\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343295; batch adversarial loss: 0.500887\n",
      "epoch 78; iter: 0; batch classifier loss: 0.466746; batch adversarial loss: 0.551969\n",
      "epoch 79; iter: 0; batch classifier loss: 0.418123; batch adversarial loss: 0.519644\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375313; batch adversarial loss: 0.461158\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422445; batch adversarial loss: 0.557888\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376931; batch adversarial loss: 0.517547\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394934; batch adversarial loss: 0.549687\n",
      "epoch 84; iter: 0; batch classifier loss: 0.402151; batch adversarial loss: 0.514940\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394387; batch adversarial loss: 0.483987\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392990; batch adversarial loss: 0.601423\n",
      "epoch 87; iter: 0; batch classifier loss: 0.466448; batch adversarial loss: 0.536219\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381425; batch adversarial loss: 0.509084\n",
      "epoch 89; iter: 0; batch classifier loss: 0.419720; batch adversarial loss: 0.548842\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430349; batch adversarial loss: 0.505230\n",
      "epoch 91; iter: 0; batch classifier loss: 0.336108; batch adversarial loss: 0.554053\n",
      "epoch 92; iter: 0; batch classifier loss: 0.449963; batch adversarial loss: 0.570336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337499; batch adversarial loss: 0.570882\n",
      "epoch 94; iter: 0; batch classifier loss: 0.341339; batch adversarial loss: 0.625083\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425595; batch adversarial loss: 0.505466\n",
      "epoch 96; iter: 0; batch classifier loss: 0.334462; batch adversarial loss: 0.483356\n",
      "epoch 97; iter: 0; batch classifier loss: 0.328826; batch adversarial loss: 0.519619\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362186; batch adversarial loss: 0.584895\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397395; batch adversarial loss: 0.571576\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360468; batch adversarial loss: 0.641318\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396541; batch adversarial loss: 0.542890\n",
      "epoch 102; iter: 0; batch classifier loss: 0.424791; batch adversarial loss: 0.571498\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379420; batch adversarial loss: 0.533987\n",
      "epoch 104; iter: 0; batch classifier loss: 0.326783; batch adversarial loss: 0.592011\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374591; batch adversarial loss: 0.557539\n",
      "epoch 106; iter: 0; batch classifier loss: 0.435966; batch adversarial loss: 0.575873\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371857; batch adversarial loss: 0.608712\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363380; batch adversarial loss: 0.536267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401074; batch adversarial loss: 0.528671\n",
      "epoch 110; iter: 0; batch classifier loss: 0.433255; batch adversarial loss: 0.472450\n",
      "epoch 111; iter: 0; batch classifier loss: 0.403314; batch adversarial loss: 0.601765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.390108; batch adversarial loss: 0.599218\n",
      "epoch 113; iter: 0; batch classifier loss: 0.405699; batch adversarial loss: 0.575283\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384912; batch adversarial loss: 0.528118\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404947; batch adversarial loss: 0.543127\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394031; batch adversarial loss: 0.621690\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411558; batch adversarial loss: 0.510567\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371688; batch adversarial loss: 0.570779\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402782; batch adversarial loss: 0.479437\n",
      "epoch 120; iter: 0; batch classifier loss: 0.433347; batch adversarial loss: 0.583968\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369510; batch adversarial loss: 0.461995\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398261; batch adversarial loss: 0.587315\n",
      "epoch 123; iter: 0; batch classifier loss: 0.386263; batch adversarial loss: 0.563978\n",
      "epoch 124; iter: 0; batch classifier loss: 0.316486; batch adversarial loss: 0.543560\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355002; batch adversarial loss: 0.506754\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390678; batch adversarial loss: 0.516508\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346932; batch adversarial loss: 0.558003\n",
      "epoch 128; iter: 0; batch classifier loss: 0.386119; batch adversarial loss: 0.528717\n",
      "epoch 129; iter: 0; batch classifier loss: 0.351510; batch adversarial loss: 0.534678\n",
      "epoch 130; iter: 0; batch classifier loss: 0.307245; batch adversarial loss: 0.563887\n",
      "epoch 131; iter: 0; batch classifier loss: 0.402052; batch adversarial loss: 0.588079\n",
      "epoch 132; iter: 0; batch classifier loss: 0.429979; batch adversarial loss: 0.542910\n",
      "epoch 133; iter: 0; batch classifier loss: 0.454495; batch adversarial loss: 0.589980\n",
      "epoch 134; iter: 0; batch classifier loss: 0.315463; batch adversarial loss: 0.597018\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402140; batch adversarial loss: 0.616276\n",
      "epoch 136; iter: 0; batch classifier loss: 0.376552; batch adversarial loss: 0.536560\n",
      "epoch 137; iter: 0; batch classifier loss: 0.415443; batch adversarial loss: 0.532814\n",
      "epoch 138; iter: 0; batch classifier loss: 0.417916; batch adversarial loss: 0.492592\n",
      "epoch 139; iter: 0; batch classifier loss: 0.399531; batch adversarial loss: 0.530307\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396401; batch adversarial loss: 0.542726\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353724; batch adversarial loss: 0.586632\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348301; batch adversarial loss: 0.520291\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331334; batch adversarial loss: 0.527546\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349768; batch adversarial loss: 0.602525\n",
      "epoch 145; iter: 0; batch classifier loss: 0.410147; batch adversarial loss: 0.585629\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357193; batch adversarial loss: 0.555453\n",
      "epoch 147; iter: 0; batch classifier loss: 0.434248; batch adversarial loss: 0.576138\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329644; batch adversarial loss: 0.536250\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378496; batch adversarial loss: 0.625160\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399626; batch adversarial loss: 0.523319\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364359; batch adversarial loss: 0.568288\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348744; batch adversarial loss: 0.579832\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381757; batch adversarial loss: 0.519616\n",
      "epoch 154; iter: 0; batch classifier loss: 0.344753; batch adversarial loss: 0.554004\n",
      "epoch 155; iter: 0; batch classifier loss: 0.390463; batch adversarial loss: 0.600726\n",
      "epoch 156; iter: 0; batch classifier loss: 0.316745; batch adversarial loss: 0.514718\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337369; batch adversarial loss: 0.514287\n",
      "epoch 158; iter: 0; batch classifier loss: 0.426989; batch adversarial loss: 0.558524\n",
      "epoch 159; iter: 0; batch classifier loss: 0.340669; batch adversarial loss: 0.490230\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385222; batch adversarial loss: 0.616086\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344030; batch adversarial loss: 0.578034\n",
      "epoch 162; iter: 0; batch classifier loss: 0.361764; batch adversarial loss: 0.500377\n",
      "epoch 163; iter: 0; batch classifier loss: 0.313219; batch adversarial loss: 0.499490\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366337; batch adversarial loss: 0.526103\n",
      "epoch 165; iter: 0; batch classifier loss: 0.312449; batch adversarial loss: 0.666190\n",
      "epoch 166; iter: 0; batch classifier loss: 0.457617; batch adversarial loss: 0.506908\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355898; batch adversarial loss: 0.569857\n",
      "epoch 168; iter: 0; batch classifier loss: 0.360283; batch adversarial loss: 0.533345\n",
      "epoch 169; iter: 0; batch classifier loss: 0.274681; batch adversarial loss: 0.631193\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374020; batch adversarial loss: 0.542961\n",
      "epoch 171; iter: 0; batch classifier loss: 0.293647; batch adversarial loss: 0.551616\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389807; batch adversarial loss: 0.528107\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386907; batch adversarial loss: 0.531784\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365083; batch adversarial loss: 0.526687\n",
      "epoch 175; iter: 0; batch classifier loss: 0.425565; batch adversarial loss: 0.573165\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376137; batch adversarial loss: 0.616985\n",
      "epoch 177; iter: 0; batch classifier loss: 0.400265; batch adversarial loss: 0.495133\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364621; batch adversarial loss: 0.525149\n",
      "epoch 179; iter: 0; batch classifier loss: 0.287190; batch adversarial loss: 0.537630\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343593; batch adversarial loss: 0.551245\n",
      "epoch 181; iter: 0; batch classifier loss: 0.412454; batch adversarial loss: 0.569923\n",
      "epoch 182; iter: 0; batch classifier loss: 0.424727; batch adversarial loss: 0.527707\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371958; batch adversarial loss: 0.561467\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377149; batch adversarial loss: 0.589129\n",
      "epoch 185; iter: 0; batch classifier loss: 0.416585; batch adversarial loss: 0.609872\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347194; batch adversarial loss: 0.514546\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348990; batch adversarial loss: 0.543254\n",
      "epoch 188; iter: 0; batch classifier loss: 0.325422; batch adversarial loss: 0.544678\n",
      "epoch 189; iter: 0; batch classifier loss: 0.314749; batch adversarial loss: 0.583817\n",
      "epoch 190; iter: 0; batch classifier loss: 0.330322; batch adversarial loss: 0.657516\n",
      "epoch 191; iter: 0; batch classifier loss: 0.271415; batch adversarial loss: 0.569589\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397283; batch adversarial loss: 0.623087\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318336; batch adversarial loss: 0.546444\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358042; batch adversarial loss: 0.570924\n",
      "epoch 195; iter: 0; batch classifier loss: 0.410419; batch adversarial loss: 0.474789\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369246; batch adversarial loss: 0.565415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.316030; batch adversarial loss: 0.447856\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359677; batch adversarial loss: 0.478087\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333791; batch adversarial loss: 0.620197\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723104; batch adversarial loss: 0.679360\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534835; batch adversarial loss: 0.637502\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574335; batch adversarial loss: 0.622542\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605024; batch adversarial loss: 0.609766\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519189; batch adversarial loss: 0.629810\n",
      "epoch 5; iter: 0; batch classifier loss: 0.547673; batch adversarial loss: 0.645724\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551230; batch adversarial loss: 0.604481\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525820; batch adversarial loss: 0.572395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.574415; batch adversarial loss: 0.653755\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553170; batch adversarial loss: 0.624898\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602882; batch adversarial loss: 0.668071\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538991; batch adversarial loss: 0.581043\n",
      "epoch 12; iter: 0; batch classifier loss: 0.617597; batch adversarial loss: 0.622731\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515622; batch adversarial loss: 0.634163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531629; batch adversarial loss: 0.577851\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502712; batch adversarial loss: 0.576434\n",
      "epoch 16; iter: 0; batch classifier loss: 0.549511; batch adversarial loss: 0.588612\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524914; batch adversarial loss: 0.631261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481469; batch adversarial loss: 0.557029\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458829; batch adversarial loss: 0.503809\n",
      "epoch 20; iter: 0; batch classifier loss: 0.460093; batch adversarial loss: 0.575336\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470915; batch adversarial loss: 0.583321\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491393; batch adversarial loss: 0.614643\n",
      "epoch 23; iter: 0; batch classifier loss: 0.434413; batch adversarial loss: 0.559076\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475836; batch adversarial loss: 0.533537\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511758; batch adversarial loss: 0.540178\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440111; batch adversarial loss: 0.523341\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450188; batch adversarial loss: 0.554539\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496360; batch adversarial loss: 0.553874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.470063; batch adversarial loss: 0.495580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508308; batch adversarial loss: 0.571228\n",
      "epoch 31; iter: 0; batch classifier loss: 0.369192; batch adversarial loss: 0.545338\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451624; batch adversarial loss: 0.538392\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435740; batch adversarial loss: 0.526467\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479097; batch adversarial loss: 0.580974\n",
      "epoch 35; iter: 0; batch classifier loss: 0.559996; batch adversarial loss: 0.580521\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477215; batch adversarial loss: 0.464571\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431052; batch adversarial loss: 0.518970\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406064; batch adversarial loss: 0.500777\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452732; batch adversarial loss: 0.509583\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456288; batch adversarial loss: 0.499424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468620; batch adversarial loss: 0.579733\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398244; batch adversarial loss: 0.465057\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423765; batch adversarial loss: 0.597477\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402615; batch adversarial loss: 0.535775\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480037; batch adversarial loss: 0.484483\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457658; batch adversarial loss: 0.518071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438932; batch adversarial loss: 0.570488\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460155; batch adversarial loss: 0.553357\n",
      "epoch 49; iter: 0; batch classifier loss: 0.364860; batch adversarial loss: 0.598689\n",
      "epoch 50; iter: 0; batch classifier loss: 0.529462; batch adversarial loss: 0.606611\n",
      "epoch 51; iter: 0; batch classifier loss: 0.321996; batch adversarial loss: 0.526705\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424785; batch adversarial loss: 0.545832\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446679; batch adversarial loss: 0.613744\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417121; batch adversarial loss: 0.639961\n",
      "epoch 55; iter: 0; batch classifier loss: 0.493595; batch adversarial loss: 0.589334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.482553; batch adversarial loss: 0.631108\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379622; batch adversarial loss: 0.507382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438421; batch adversarial loss: 0.569214\n",
      "epoch 59; iter: 0; batch classifier loss: 0.513672; batch adversarial loss: 0.650007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.414286; batch adversarial loss: 0.490506\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432932; batch adversarial loss: 0.528530\n",
      "epoch 62; iter: 0; batch classifier loss: 0.505745; batch adversarial loss: 0.552040\n",
      "epoch 63; iter: 0; batch classifier loss: 0.393443; batch adversarial loss: 0.562529\n",
      "epoch 64; iter: 0; batch classifier loss: 0.353304; batch adversarial loss: 0.499257\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377640; batch adversarial loss: 0.554157\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403968; batch adversarial loss: 0.552476\n",
      "epoch 67; iter: 0; batch classifier loss: 0.450679; batch adversarial loss: 0.580887\n",
      "epoch 68; iter: 0; batch classifier loss: 0.501390; batch adversarial loss: 0.571444\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387520; batch adversarial loss: 0.508893\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417775; batch adversarial loss: 0.553494\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404260; batch adversarial loss: 0.527908\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390906; batch adversarial loss: 0.544979\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433257; batch adversarial loss: 0.544688\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399575; batch adversarial loss: 0.544210\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459609; batch adversarial loss: 0.508672\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421800; batch adversarial loss: 0.624037\n",
      "epoch 77; iter: 0; batch classifier loss: 0.384536; batch adversarial loss: 0.608265\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440260; batch adversarial loss: 0.589262\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429481; batch adversarial loss: 0.553443\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447527; batch adversarial loss: 0.599078\n",
      "epoch 81; iter: 0; batch classifier loss: 0.457881; batch adversarial loss: 0.625275\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378881; batch adversarial loss: 0.554846\n",
      "epoch 83; iter: 0; batch classifier loss: 0.450605; batch adversarial loss: 0.590430\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356853; batch adversarial loss: 0.482630\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373518; batch adversarial loss: 0.508799\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440114; batch adversarial loss: 0.643568\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428216; batch adversarial loss: 0.571300\n",
      "epoch 88; iter: 0; batch classifier loss: 0.506859; batch adversarial loss: 0.660307\n",
      "epoch 89; iter: 0; batch classifier loss: 0.461592; batch adversarial loss: 0.526809\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403122; batch adversarial loss: 0.553979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384061; batch adversarial loss: 0.527177\n",
      "epoch 92; iter: 0; batch classifier loss: 0.517398; batch adversarial loss: 0.643143\n",
      "epoch 93; iter: 0; batch classifier loss: 0.401997; batch adversarial loss: 0.535620\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404478; batch adversarial loss: 0.571835\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399697; batch adversarial loss: 0.543418\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399746; batch adversarial loss: 0.570456\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377707; batch adversarial loss: 0.574815\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397937; batch adversarial loss: 0.532726\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376802; batch adversarial loss: 0.499396\n",
      "epoch 100; iter: 0; batch classifier loss: 0.328098; batch adversarial loss: 0.562913\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430660; batch adversarial loss: 0.616041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372597; batch adversarial loss: 0.579603\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399916; batch adversarial loss: 0.536723\n",
      "epoch 104; iter: 0; batch classifier loss: 0.431521; batch adversarial loss: 0.553678\n",
      "epoch 105; iter: 0; batch classifier loss: 0.469540; batch adversarial loss: 0.561860\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390123; batch adversarial loss: 0.492600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.417320; batch adversarial loss: 0.587870\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388081; batch adversarial loss: 0.605306\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380112; batch adversarial loss: 0.563198\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365714; batch adversarial loss: 0.614451\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391985; batch adversarial loss: 0.589366\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409555; batch adversarial loss: 0.526832\n",
      "epoch 113; iter: 0; batch classifier loss: 0.365347; batch adversarial loss: 0.534970\n",
      "epoch 114; iter: 0; batch classifier loss: 0.447184; batch adversarial loss: 0.589818\n",
      "epoch 115; iter: 0; batch classifier loss: 0.439343; batch adversarial loss: 0.561590\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381187; batch adversarial loss: 0.517017\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371120; batch adversarial loss: 0.587956\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386754; batch adversarial loss: 0.562695\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392757; batch adversarial loss: 0.476280\n",
      "epoch 120; iter: 0; batch classifier loss: 0.410353; batch adversarial loss: 0.614973\n",
      "epoch 121; iter: 0; batch classifier loss: 0.490021; batch adversarial loss: 0.507636\n",
      "epoch 122; iter: 0; batch classifier loss: 0.434645; batch adversarial loss: 0.588571\n",
      "epoch 123; iter: 0; batch classifier loss: 0.306701; batch adversarial loss: 0.482442\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334867; batch adversarial loss: 0.590244\n",
      "epoch 125; iter: 0; batch classifier loss: 0.421506; batch adversarial loss: 0.545069\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400908; batch adversarial loss: 0.581237\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370506; batch adversarial loss: 0.508043\n",
      "epoch 128; iter: 0; batch classifier loss: 0.388306; batch adversarial loss: 0.544600\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406154; batch adversarial loss: 0.553529\n",
      "epoch 130; iter: 0; batch classifier loss: 0.404641; batch adversarial loss: 0.607279\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387802; batch adversarial loss: 0.526449\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334229; batch adversarial loss: 0.616966\n",
      "epoch 133; iter: 0; batch classifier loss: 0.323608; batch adversarial loss: 0.553373\n",
      "epoch 134; iter: 0; batch classifier loss: 0.442129; batch adversarial loss: 0.662809\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369630; batch adversarial loss: 0.580855\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341200; batch adversarial loss: 0.509662\n",
      "epoch 137; iter: 0; batch classifier loss: 0.432318; batch adversarial loss: 0.509983\n",
      "epoch 138; iter: 0; batch classifier loss: 0.397211; batch adversarial loss: 0.614771\n",
      "epoch 139; iter: 0; batch classifier loss: 0.436361; batch adversarial loss: 0.553041\n",
      "epoch 140; iter: 0; batch classifier loss: 0.392472; batch adversarial loss: 0.518758\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365477; batch adversarial loss: 0.571657\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333250; batch adversarial loss: 0.579764\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328881; batch adversarial loss: 0.545080\n",
      "epoch 144; iter: 0; batch classifier loss: 0.385360; batch adversarial loss: 0.500254\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362751; batch adversarial loss: 0.535782\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381097; batch adversarial loss: 0.561912\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391501; batch adversarial loss: 0.553181\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371008; batch adversarial loss: 0.490799\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370413; batch adversarial loss: 0.508985\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391031; batch adversarial loss: 0.518156\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368921; batch adversarial loss: 0.527184\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344631; batch adversarial loss: 0.544659\n",
      "epoch 153; iter: 0; batch classifier loss: 0.315491; batch adversarial loss: 0.545053\n",
      "epoch 154; iter: 0; batch classifier loss: 0.359497; batch adversarial loss: 0.562639\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317334; batch adversarial loss: 0.579062\n",
      "epoch 156; iter: 0; batch classifier loss: 0.346836; batch adversarial loss: 0.571511\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399472; batch adversarial loss: 0.509930\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361641; batch adversarial loss: 0.596087\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371790; batch adversarial loss: 0.570670\n",
      "epoch 160; iter: 0; batch classifier loss: 0.425430; batch adversarial loss: 0.581120\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373304; batch adversarial loss: 0.527040\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344093; batch adversarial loss: 0.545411\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357223; batch adversarial loss: 0.562673\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395988; batch adversarial loss: 0.500392\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372171; batch adversarial loss: 0.580682\n",
      "epoch 166; iter: 0; batch classifier loss: 0.296905; batch adversarial loss: 0.533453\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371842; batch adversarial loss: 0.508686\n",
      "epoch 168; iter: 0; batch classifier loss: 0.409740; batch adversarial loss: 0.508876\n",
      "epoch 169; iter: 0; batch classifier loss: 0.485399; batch adversarial loss: 0.511479\n",
      "epoch 170; iter: 0; batch classifier loss: 0.441321; batch adversarial loss: 0.553752\n",
      "epoch 171; iter: 0; batch classifier loss: 0.421891; batch adversarial loss: 0.536383\n",
      "epoch 172; iter: 0; batch classifier loss: 0.436697; batch adversarial loss: 0.554798\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339743; batch adversarial loss: 0.527857\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378757; batch adversarial loss: 0.536505\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355217; batch adversarial loss: 0.590333\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379445; batch adversarial loss: 0.509009\n",
      "epoch 177; iter: 0; batch classifier loss: 0.263544; batch adversarial loss: 0.653663\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372459; batch adversarial loss: 0.535180\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392636; batch adversarial loss: 0.499067\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424757; batch adversarial loss: 0.535793\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363076; batch adversarial loss: 0.517862\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357696; batch adversarial loss: 0.482474\n",
      "epoch 183; iter: 0; batch classifier loss: 0.431015; batch adversarial loss: 0.562993\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365593; batch adversarial loss: 0.508835\n",
      "epoch 185; iter: 0; batch classifier loss: 0.385906; batch adversarial loss: 0.562053\n",
      "epoch 186; iter: 0; batch classifier loss: 0.463511; batch adversarial loss: 0.553334\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387441; batch adversarial loss: 0.544816\n",
      "epoch 188; iter: 0; batch classifier loss: 0.466283; batch adversarial loss: 0.517870\n",
      "epoch 189; iter: 0; batch classifier loss: 0.522470; batch adversarial loss: 0.491100\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347396; batch adversarial loss: 0.527450\n",
      "epoch 191; iter: 0; batch classifier loss: 0.300742; batch adversarial loss: 0.589239\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365981; batch adversarial loss: 0.553723\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342313; batch adversarial loss: 0.579882\n",
      "epoch 194; iter: 0; batch classifier loss: 0.297354; batch adversarial loss: 0.482637\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369483; batch adversarial loss: 0.482136\n",
      "epoch 196; iter: 0; batch classifier loss: 0.403397; batch adversarial loss: 0.579859\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307640; batch adversarial loss: 0.544554\n",
      "epoch 198; iter: 0; batch classifier loss: 0.469456; batch adversarial loss: 0.553994\n",
      "epoch 199; iter: 0; batch classifier loss: 0.377971; batch adversarial loss: 0.553667\n",
      "epoch 0; iter: 0; batch classifier loss: 0.646929; batch adversarial loss: 0.701756\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587056; batch adversarial loss: 0.689838\n",
      "epoch 2; iter: 0; batch classifier loss: 0.641435; batch adversarial loss: 0.693020\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580261; batch adversarial loss: 0.667900\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569700; batch adversarial loss: 0.615696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.599456; batch adversarial loss: 0.576690\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482254; batch adversarial loss: 0.580944\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552256; batch adversarial loss: 0.568971\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536787; batch adversarial loss: 0.568399\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495500; batch adversarial loss: 0.534287\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544395; batch adversarial loss: 0.582389\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516749; batch adversarial loss: 0.622954\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571015; batch adversarial loss: 0.613000\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564329; batch adversarial loss: 0.626849\n",
      "epoch 14; iter: 0; batch classifier loss: 0.561006; batch adversarial loss: 0.517796\n",
      "epoch 15; iter: 0; batch classifier loss: 0.583943; batch adversarial loss: 0.584638\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533971; batch adversarial loss: 0.552583\n",
      "epoch 17; iter: 0; batch classifier loss: 0.574835; batch adversarial loss: 0.641891\n",
      "epoch 18; iter: 0; batch classifier loss: 0.590226; batch adversarial loss: 0.572553\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592471; batch adversarial loss: 0.574654\n",
      "epoch 20; iter: 0; batch classifier loss: 0.481016; batch adversarial loss: 0.525262\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508947; batch adversarial loss: 0.558804\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531213; batch adversarial loss: 0.542821\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475629; batch adversarial loss: 0.527331\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489334; batch adversarial loss: 0.578096\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498410; batch adversarial loss: 0.577331\n",
      "epoch 26; iter: 0; batch classifier loss: 0.503898; batch adversarial loss: 0.437522\n",
      "epoch 27; iter: 0; batch classifier loss: 0.496907; batch adversarial loss: 0.483927\n",
      "epoch 28; iter: 0; batch classifier loss: 0.396328; batch adversarial loss: 0.570070\n",
      "epoch 29; iter: 0; batch classifier loss: 0.418673; batch adversarial loss: 0.510996\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452982; batch adversarial loss: 0.557234\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468111; batch adversarial loss: 0.539549\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469773; batch adversarial loss: 0.465619\n",
      "epoch 33; iter: 0; batch classifier loss: 0.500313; batch adversarial loss: 0.585183\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466510; batch adversarial loss: 0.517642\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444103; batch adversarial loss: 0.508657\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436735; batch adversarial loss: 0.542071\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467375; batch adversarial loss: 0.529352\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417116; batch adversarial loss: 0.516331\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497391; batch adversarial loss: 0.544981\n",
      "epoch 40; iter: 0; batch classifier loss: 0.496451; batch adversarial loss: 0.509742\n",
      "epoch 41; iter: 0; batch classifier loss: 0.550598; batch adversarial loss: 0.490942\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410808; batch adversarial loss: 0.482825\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429368; batch adversarial loss: 0.613610\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475098; batch adversarial loss: 0.546761\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429452; batch adversarial loss: 0.571021\n",
      "epoch 46; iter: 0; batch classifier loss: 0.387099; batch adversarial loss: 0.524180\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462281; batch adversarial loss: 0.572828\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440885; batch adversarial loss: 0.537690\n",
      "epoch 49; iter: 0; batch classifier loss: 0.531959; batch adversarial loss: 0.542842\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458774; batch adversarial loss: 0.515923\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441760; batch adversarial loss: 0.524264\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390594; batch adversarial loss: 0.525971\n",
      "epoch 53; iter: 0; batch classifier loss: 0.448680; batch adversarial loss: 0.514649\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474707; batch adversarial loss: 0.555217\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432829; batch adversarial loss: 0.537230\n",
      "epoch 56; iter: 0; batch classifier loss: 0.461530; batch adversarial loss: 0.516748\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428850; batch adversarial loss: 0.570548\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435024; batch adversarial loss: 0.608366\n",
      "epoch 59; iter: 0; batch classifier loss: 0.373750; batch adversarial loss: 0.468527\n",
      "epoch 60; iter: 0; batch classifier loss: 0.508430; batch adversarial loss: 0.518617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407159; batch adversarial loss: 0.534406\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449821; batch adversarial loss: 0.554290\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383931; batch adversarial loss: 0.620979\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374216; batch adversarial loss: 0.582383\n",
      "epoch 65; iter: 0; batch classifier loss: 0.460208; batch adversarial loss: 0.507051\n",
      "epoch 66; iter: 0; batch classifier loss: 0.352886; batch adversarial loss: 0.571763\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394616; batch adversarial loss: 0.612768\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382643; batch adversarial loss: 0.460829\n",
      "epoch 69; iter: 0; batch classifier loss: 0.369882; batch adversarial loss: 0.479287\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407557; batch adversarial loss: 0.520208\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412080; batch adversarial loss: 0.571047\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381426; batch adversarial loss: 0.497786\n",
      "epoch 73; iter: 0; batch classifier loss: 0.452899; batch adversarial loss: 0.565902\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456005; batch adversarial loss: 0.581127\n",
      "epoch 75; iter: 0; batch classifier loss: 0.428907; batch adversarial loss: 0.461660\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388432; batch adversarial loss: 0.537575\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421249; batch adversarial loss: 0.479583\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387320; batch adversarial loss: 0.562036\n",
      "epoch 79; iter: 0; batch classifier loss: 0.461553; batch adversarial loss: 0.628681\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418563; batch adversarial loss: 0.535788\n",
      "epoch 81; iter: 0; batch classifier loss: 0.420440; batch adversarial loss: 0.550280\n",
      "epoch 82; iter: 0; batch classifier loss: 0.495113; batch adversarial loss: 0.561786\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446222; batch adversarial loss: 0.627159\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363278; batch adversarial loss: 0.540062\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431681; batch adversarial loss: 0.452073\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357040; batch adversarial loss: 0.503946\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400854; batch adversarial loss: 0.537969\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394298; batch adversarial loss: 0.525482\n",
      "epoch 89; iter: 0; batch classifier loss: 0.495048; batch adversarial loss: 0.555924\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353522; batch adversarial loss: 0.468244\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393976; batch adversarial loss: 0.604258\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419839; batch adversarial loss: 0.517148\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394974; batch adversarial loss: 0.561221\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415815; batch adversarial loss: 0.594062\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407191; batch adversarial loss: 0.541425\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425470; batch adversarial loss: 0.541249\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437739; batch adversarial loss: 0.531489\n",
      "epoch 98; iter: 0; batch classifier loss: 0.536209; batch adversarial loss: 0.571164\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312544; batch adversarial loss: 0.583036\n",
      "epoch 100; iter: 0; batch classifier loss: 0.337671; batch adversarial loss: 0.535706\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370951; batch adversarial loss: 0.494551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.459284; batch adversarial loss: 0.535581\n",
      "epoch 103; iter: 0; batch classifier loss: 0.339552; batch adversarial loss: 0.450403\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399674; batch adversarial loss: 0.558703\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395939; batch adversarial loss: 0.504532\n",
      "epoch 106; iter: 0; batch classifier loss: 0.375391; batch adversarial loss: 0.533505\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375951; batch adversarial loss: 0.604047\n",
      "epoch 108; iter: 0; batch classifier loss: 0.426227; batch adversarial loss: 0.538779\n",
      "epoch 109; iter: 0; batch classifier loss: 0.446843; batch adversarial loss: 0.575375\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343304; batch adversarial loss: 0.565884\n",
      "epoch 111; iter: 0; batch classifier loss: 0.442887; batch adversarial loss: 0.576496\n",
      "epoch 112; iter: 0; batch classifier loss: 0.337529; batch adversarial loss: 0.478417\n",
      "epoch 113; iter: 0; batch classifier loss: 0.416667; batch adversarial loss: 0.555353\n",
      "epoch 114; iter: 0; batch classifier loss: 0.468518; batch adversarial loss: 0.571480\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378926; batch adversarial loss: 0.543834\n",
      "epoch 116; iter: 0; batch classifier loss: 0.414241; batch adversarial loss: 0.496128\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391545; batch adversarial loss: 0.555152\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370413; batch adversarial loss: 0.554486\n",
      "epoch 119; iter: 0; batch classifier loss: 0.361525; batch adversarial loss: 0.536538\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385742; batch adversarial loss: 0.562542\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412933; batch adversarial loss: 0.469685\n",
      "epoch 122; iter: 0; batch classifier loss: 0.422708; batch adversarial loss: 0.582255\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341482; batch adversarial loss: 0.524426\n",
      "epoch 124; iter: 0; batch classifier loss: 0.459757; batch adversarial loss: 0.525741\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346262; batch adversarial loss: 0.593684\n",
      "epoch 126; iter: 0; batch classifier loss: 0.428232; batch adversarial loss: 0.519091\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358086; batch adversarial loss: 0.527452\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361841; batch adversarial loss: 0.552108\n",
      "epoch 129; iter: 0; batch classifier loss: 0.400439; batch adversarial loss: 0.495886\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393232; batch adversarial loss: 0.571558\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371427; batch adversarial loss: 0.534219\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384634; batch adversarial loss: 0.533886\n",
      "epoch 133; iter: 0; batch classifier loss: 0.294705; batch adversarial loss: 0.515956\n",
      "epoch 134; iter: 0; batch classifier loss: 0.411225; batch adversarial loss: 0.509397\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400013; batch adversarial loss: 0.513973\n",
      "epoch 136; iter: 0; batch classifier loss: 0.417092; batch adversarial loss: 0.546370\n",
      "epoch 137; iter: 0; batch classifier loss: 0.319390; batch adversarial loss: 0.497789\n",
      "epoch 138; iter: 0; batch classifier loss: 0.431048; batch adversarial loss: 0.515936\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401656; batch adversarial loss: 0.488344\n",
      "epoch 140; iter: 0; batch classifier loss: 0.321887; batch adversarial loss: 0.553470\n",
      "epoch 141; iter: 0; batch classifier loss: 0.442037; batch adversarial loss: 0.551667\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335542; batch adversarial loss: 0.490702\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412079; batch adversarial loss: 0.535399\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369365; batch adversarial loss: 0.479493\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403561; batch adversarial loss: 0.522538\n",
      "epoch 146; iter: 0; batch classifier loss: 0.300492; batch adversarial loss: 0.470325\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400408; batch adversarial loss: 0.497019\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332567; batch adversarial loss: 0.622377\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410269; batch adversarial loss: 0.461684\n",
      "epoch 150; iter: 0; batch classifier loss: 0.406786; batch adversarial loss: 0.591420\n",
      "epoch 151; iter: 0; batch classifier loss: 0.430336; batch adversarial loss: 0.561681\n",
      "epoch 152; iter: 0; batch classifier loss: 0.426916; batch adversarial loss: 0.550918\n",
      "epoch 153; iter: 0; batch classifier loss: 0.414525; batch adversarial loss: 0.503703\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401402; batch adversarial loss: 0.576092\n",
      "epoch 155; iter: 0; batch classifier loss: 0.485774; batch adversarial loss: 0.541013\n",
      "epoch 156; iter: 0; batch classifier loss: 0.445858; batch adversarial loss: 0.603099\n",
      "epoch 157; iter: 0; batch classifier loss: 0.429635; batch adversarial loss: 0.574155\n",
      "epoch 158; iter: 0; batch classifier loss: 0.410623; batch adversarial loss: 0.611837\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388300; batch adversarial loss: 0.575025\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340818; batch adversarial loss: 0.534338\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408640; batch adversarial loss: 0.605892\n",
      "epoch 162; iter: 0; batch classifier loss: 0.408628; batch adversarial loss: 0.451380\n",
      "epoch 163; iter: 0; batch classifier loss: 0.289632; batch adversarial loss: 0.593592\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323145; batch adversarial loss: 0.489591\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373178; batch adversarial loss: 0.583112\n",
      "epoch 166; iter: 0; batch classifier loss: 0.348297; batch adversarial loss: 0.562001\n",
      "epoch 167; iter: 0; batch classifier loss: 0.438352; batch adversarial loss: 0.499689\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315017; batch adversarial loss: 0.618734\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358835; batch adversarial loss: 0.533523\n",
      "epoch 170; iter: 0; batch classifier loss: 0.310096; batch adversarial loss: 0.535716\n",
      "epoch 171; iter: 0; batch classifier loss: 0.373917; batch adversarial loss: 0.559391\n",
      "epoch 172; iter: 0; batch classifier loss: 0.535912; batch adversarial loss: 0.563564\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372504; batch adversarial loss: 0.534437\n",
      "epoch 174; iter: 0; batch classifier loss: 0.454658; batch adversarial loss: 0.584922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.364187; batch adversarial loss: 0.469245\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387604; batch adversarial loss: 0.534261\n",
      "epoch 177; iter: 0; batch classifier loss: 0.388364; batch adversarial loss: 0.616445\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362201; batch adversarial loss: 0.489914\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330432; batch adversarial loss: 0.593039\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334524; batch adversarial loss: 0.607926\n",
      "epoch 181; iter: 0; batch classifier loss: 0.417163; batch adversarial loss: 0.487768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304107; batch adversarial loss: 0.544036\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355209; batch adversarial loss: 0.524848\n",
      "epoch 184; iter: 0; batch classifier loss: 0.369671; batch adversarial loss: 0.552199\n",
      "epoch 185; iter: 0; batch classifier loss: 0.363786; batch adversarial loss: 0.517291\n",
      "epoch 186; iter: 0; batch classifier loss: 0.416674; batch adversarial loss: 0.488987\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355003; batch adversarial loss: 0.553242\n",
      "epoch 188; iter: 0; batch classifier loss: 0.305991; batch adversarial loss: 0.505695\n",
      "epoch 189; iter: 0; batch classifier loss: 0.375706; batch adversarial loss: 0.534786\n",
      "epoch 190; iter: 0; batch classifier loss: 0.389648; batch adversarial loss: 0.526417\n",
      "epoch 191; iter: 0; batch classifier loss: 0.409642; batch adversarial loss: 0.555050\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358944; batch adversarial loss: 0.544313\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388809; batch adversarial loss: 0.468698\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348114; batch adversarial loss: 0.577742\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338784; batch adversarial loss: 0.498034\n",
      "epoch 196; iter: 0; batch classifier loss: 0.413077; batch adversarial loss: 0.628234\n",
      "epoch 197; iter: 0; batch classifier loss: 0.425401; batch adversarial loss: 0.560760\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358696; batch adversarial loss: 0.497299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.370378; batch adversarial loss: 0.613157\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663428; batch adversarial loss: 0.710292\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605184; batch adversarial loss: 0.690401\n",
      "epoch 2; iter: 0; batch classifier loss: 0.578606; batch adversarial loss: 0.658401\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565830; batch adversarial loss: 0.641248\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574585; batch adversarial loss: 0.608440\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543840; batch adversarial loss: 0.587099\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555778; batch adversarial loss: 0.605094\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527504; batch adversarial loss: 0.610892\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557201; batch adversarial loss: 0.602947\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493737; batch adversarial loss: 0.536383\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462456; batch adversarial loss: 0.577887\n",
      "epoch 11; iter: 0; batch classifier loss: 0.561417; batch adversarial loss: 0.561105\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549063; batch adversarial loss: 0.534943\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566984; batch adversarial loss: 0.561645\n",
      "epoch 14; iter: 0; batch classifier loss: 0.585262; batch adversarial loss: 0.558029\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511950; batch adversarial loss: 0.503176\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548697; batch adversarial loss: 0.584801\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527376; batch adversarial loss: 0.597033\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504846; batch adversarial loss: 0.604061\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545396; batch adversarial loss: 0.586789\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528499; batch adversarial loss: 0.613296\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439915; batch adversarial loss: 0.490411\n",
      "epoch 22; iter: 0; batch classifier loss: 0.597948; batch adversarial loss: 0.511372\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430214; batch adversarial loss: 0.559921\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504305; batch adversarial loss: 0.610782\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452248; batch adversarial loss: 0.577568\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501538; batch adversarial loss: 0.579390\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507250; batch adversarial loss: 0.508491\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425065; batch adversarial loss: 0.586029\n",
      "epoch 29; iter: 0; batch classifier loss: 0.420081; batch adversarial loss: 0.540408\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471967; batch adversarial loss: 0.550702\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438051; batch adversarial loss: 0.520841\n",
      "epoch 32; iter: 0; batch classifier loss: 0.507549; batch adversarial loss: 0.580997\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484588; batch adversarial loss: 0.473681\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447535; batch adversarial loss: 0.508751\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403374; batch adversarial loss: 0.528313\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452049; batch adversarial loss: 0.572083\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443103; batch adversarial loss: 0.551536\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435849; batch adversarial loss: 0.509908\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446227; batch adversarial loss: 0.549735\n",
      "epoch 40; iter: 0; batch classifier loss: 0.382103; batch adversarial loss: 0.557377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454869; batch adversarial loss: 0.546683\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391471; batch adversarial loss: 0.606492\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402515; batch adversarial loss: 0.483328\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433420; batch adversarial loss: 0.618010\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457367; batch adversarial loss: 0.634376\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500505; batch adversarial loss: 0.571262\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421533; batch adversarial loss: 0.589677\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467692; batch adversarial loss: 0.598140\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422816; batch adversarial loss: 0.482000\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439762; batch adversarial loss: 0.553251\n",
      "epoch 51; iter: 0; batch classifier loss: 0.499793; batch adversarial loss: 0.561923\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.612683\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470302; batch adversarial loss: 0.488979\n",
      "epoch 54; iter: 0; batch classifier loss: 0.389018; batch adversarial loss: 0.595866\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408100; batch adversarial loss: 0.570587\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409720; batch adversarial loss: 0.542393\n",
      "epoch 57; iter: 0; batch classifier loss: 0.499800; batch adversarial loss: 0.538825\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441123; batch adversarial loss: 0.586233\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396795; batch adversarial loss: 0.599372\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397334; batch adversarial loss: 0.505774\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418764; batch adversarial loss: 0.572196\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446545; batch adversarial loss: 0.529899\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377544; batch adversarial loss: 0.479980\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400690; batch adversarial loss: 0.506250\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439751; batch adversarial loss: 0.565929\n",
      "epoch 66; iter: 0; batch classifier loss: 0.369987; batch adversarial loss: 0.555234\n",
      "epoch 67; iter: 0; batch classifier loss: 0.484020; batch adversarial loss: 0.490428\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420988; batch adversarial loss: 0.518074\n",
      "epoch 69; iter: 0; batch classifier loss: 0.468824; batch adversarial loss: 0.546429\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446811; batch adversarial loss: 0.670119\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412168; batch adversarial loss: 0.479549\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428434; batch adversarial loss: 0.581587\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390572; batch adversarial loss: 0.469966\n",
      "epoch 74; iter: 0; batch classifier loss: 0.463634; batch adversarial loss: 0.561090\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387033; batch adversarial loss: 0.506986\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465922; batch adversarial loss: 0.517235\n",
      "epoch 77; iter: 0; batch classifier loss: 0.452752; batch adversarial loss: 0.580908\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412255; batch adversarial loss: 0.544706\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439470; batch adversarial loss: 0.610670\n",
      "epoch 80; iter: 0; batch classifier loss: 0.346742; batch adversarial loss: 0.591918\n",
      "epoch 81; iter: 0; batch classifier loss: 0.356440; batch adversarial loss: 0.553806\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409465; batch adversarial loss: 0.525292\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358171; batch adversarial loss: 0.591175\n",
      "epoch 84; iter: 0; batch classifier loss: 0.476356; batch adversarial loss: 0.590568\n",
      "epoch 85; iter: 0; batch classifier loss: 0.420284; batch adversarial loss: 0.562971\n",
      "epoch 86; iter: 0; batch classifier loss: 0.372859; batch adversarial loss: 0.498506\n",
      "epoch 87; iter: 0; batch classifier loss: 0.456299; batch adversarial loss: 0.508297\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392298; batch adversarial loss: 0.609223\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416798; batch adversarial loss: 0.571768\n",
      "epoch 90; iter: 0; batch classifier loss: 0.422897; batch adversarial loss: 0.544323\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340675; batch adversarial loss: 0.544901\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396264; batch adversarial loss: 0.535503\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397981; batch adversarial loss: 0.544514\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357704; batch adversarial loss: 0.552869\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378513; batch adversarial loss: 0.636012\n",
      "epoch 96; iter: 0; batch classifier loss: 0.491029; batch adversarial loss: 0.517582\n",
      "epoch 97; iter: 0; batch classifier loss: 0.467796; batch adversarial loss: 0.554244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.430231; batch adversarial loss: 0.536036\n",
      "epoch 99; iter: 0; batch classifier loss: 0.438640; batch adversarial loss: 0.499176\n",
      "epoch 100; iter: 0; batch classifier loss: 0.321984; batch adversarial loss: 0.543613\n",
      "epoch 101; iter: 0; batch classifier loss: 0.343016; batch adversarial loss: 0.489594\n",
      "epoch 102; iter: 0; batch classifier loss: 0.400372; batch adversarial loss: 0.552689\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413272; batch adversarial loss: 0.608140\n",
      "epoch 104; iter: 0; batch classifier loss: 0.394456; batch adversarial loss: 0.508150\n",
      "epoch 105; iter: 0; batch classifier loss: 0.485095; batch adversarial loss: 0.517003\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389573; batch adversarial loss: 0.609263\n",
      "epoch 107; iter: 0; batch classifier loss: 0.414887; batch adversarial loss: 0.498613\n",
      "epoch 108; iter: 0; batch classifier loss: 0.459228; batch adversarial loss: 0.590409\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416725; batch adversarial loss: 0.507304\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391260; batch adversarial loss: 0.571919\n",
      "epoch 111; iter: 0; batch classifier loss: 0.466200; batch adversarial loss: 0.599031\n",
      "epoch 112; iter: 0; batch classifier loss: 0.401757; batch adversarial loss: 0.471502\n",
      "epoch 113; iter: 0; batch classifier loss: 0.431542; batch adversarial loss: 0.618650\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420513; batch adversarial loss: 0.563586\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369919; batch adversarial loss: 0.571289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427784; batch adversarial loss: 0.628256\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416211; batch adversarial loss: 0.580597\n",
      "epoch 118; iter: 0; batch classifier loss: 0.441376; batch adversarial loss: 0.535847\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394643; batch adversarial loss: 0.524595\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378805; batch adversarial loss: 0.532730\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353375; batch adversarial loss: 0.534378\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386796; batch adversarial loss: 0.501154\n",
      "epoch 123; iter: 0; batch classifier loss: 0.453452; batch adversarial loss: 0.552744\n",
      "epoch 124; iter: 0; batch classifier loss: 0.477740; batch adversarial loss: 0.550167\n",
      "epoch 125; iter: 0; batch classifier loss: 0.433373; batch adversarial loss: 0.526723\n",
      "epoch 126; iter: 0; batch classifier loss: 0.428688; batch adversarial loss: 0.466044\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366238; batch adversarial loss: 0.576854\n",
      "epoch 128; iter: 0; batch classifier loss: 0.490764; batch adversarial loss: 0.560440\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402671; batch adversarial loss: 0.537680\n",
      "epoch 130; iter: 0; batch classifier loss: 0.306090; batch adversarial loss: 0.580824\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360968; batch adversarial loss: 0.497402\n",
      "epoch 132; iter: 0; batch classifier loss: 0.322886; batch adversarial loss: 0.545263\n",
      "epoch 133; iter: 0; batch classifier loss: 0.470910; batch adversarial loss: 0.498129\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386793; batch adversarial loss: 0.487857\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358358; batch adversarial loss: 0.544052\n",
      "epoch 136; iter: 0; batch classifier loss: 0.434796; batch adversarial loss: 0.553575\n",
      "epoch 137; iter: 0; batch classifier loss: 0.381445; batch adversarial loss: 0.526592\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388929; batch adversarial loss: 0.562582\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332217; batch adversarial loss: 0.527028\n",
      "epoch 140; iter: 0; batch classifier loss: 0.482197; batch adversarial loss: 0.471282\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370203; batch adversarial loss: 0.481209\n",
      "epoch 142; iter: 0; batch classifier loss: 0.460149; batch adversarial loss: 0.608173\n",
      "epoch 143; iter: 0; batch classifier loss: 0.398462; batch adversarial loss: 0.498754\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367696; batch adversarial loss: 0.554091\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404172; batch adversarial loss: 0.571532\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367084; batch adversarial loss: 0.599674\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372559; batch adversarial loss: 0.563088\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330928; batch adversarial loss: 0.572284\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376222; batch adversarial loss: 0.591149\n",
      "epoch 150; iter: 0; batch classifier loss: 0.435340; batch adversarial loss: 0.608690\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334075; batch adversarial loss: 0.525634\n",
      "epoch 152; iter: 0; batch classifier loss: 0.358736; batch adversarial loss: 0.589683\n",
      "epoch 153; iter: 0; batch classifier loss: 0.410192; batch adversarial loss: 0.543784\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373208; batch adversarial loss: 0.525854\n",
      "epoch 155; iter: 0; batch classifier loss: 0.481186; batch adversarial loss: 0.543009\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370856; batch adversarial loss: 0.502035\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381097; batch adversarial loss: 0.569179\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396475; batch adversarial loss: 0.634189\n",
      "epoch 159; iter: 0; batch classifier loss: 0.453057; batch adversarial loss: 0.562700\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336405; batch adversarial loss: 0.572806\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375694; batch adversarial loss: 0.618586\n",
      "epoch 162; iter: 0; batch classifier loss: 0.318101; batch adversarial loss: 0.635399\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392177; batch adversarial loss: 0.564624\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398684; batch adversarial loss: 0.639854\n",
      "epoch 165; iter: 0; batch classifier loss: 0.301862; batch adversarial loss: 0.506564\n",
      "epoch 166; iter: 0; batch classifier loss: 0.439604; batch adversarial loss: 0.571613\n",
      "epoch 167; iter: 0; batch classifier loss: 0.338054; batch adversarial loss: 0.517788\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387182; batch adversarial loss: 0.461507\n",
      "epoch 169; iter: 0; batch classifier loss: 0.401910; batch adversarial loss: 0.545418\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360849; batch adversarial loss: 0.508695\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340073; batch adversarial loss: 0.590546\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346621; batch adversarial loss: 0.580038\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373590; batch adversarial loss: 0.639133\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380408; batch adversarial loss: 0.543586\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409487; batch adversarial loss: 0.461462\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396210; batch adversarial loss: 0.581155\n",
      "epoch 177; iter: 0; batch classifier loss: 0.430257; batch adversarial loss: 0.562389\n",
      "epoch 178; iter: 0; batch classifier loss: 0.374898; batch adversarial loss: 0.498377\n",
      "epoch 179; iter: 0; batch classifier loss: 0.464544; batch adversarial loss: 0.488902\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389960; batch adversarial loss: 0.545337\n",
      "epoch 181; iter: 0; batch classifier loss: 0.412424; batch adversarial loss: 0.535138\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327139; batch adversarial loss: 0.562873\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396674; batch adversarial loss: 0.571148\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397098; batch adversarial loss: 0.517083\n",
      "epoch 185; iter: 0; batch classifier loss: 0.334501; batch adversarial loss: 0.552801\n",
      "epoch 186; iter: 0; batch classifier loss: 0.417226; batch adversarial loss: 0.516483\n",
      "epoch 187; iter: 0; batch classifier loss: 0.330980; batch adversarial loss: 0.544095\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359516; batch adversarial loss: 0.525844\n",
      "epoch 189; iter: 0; batch classifier loss: 0.401785; batch adversarial loss: 0.516097\n",
      "epoch 190; iter: 0; batch classifier loss: 0.437380; batch adversarial loss: 0.516394\n",
      "epoch 191; iter: 0; batch classifier loss: 0.437557; batch adversarial loss: 0.562175\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345809; batch adversarial loss: 0.553107\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390327; batch adversarial loss: 0.590338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.459655; batch adversarial loss: 0.572210\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371450; batch adversarial loss: 0.506785\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341287; batch adversarial loss: 0.590231\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393373; batch adversarial loss: 0.490327\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378240; batch adversarial loss: 0.527254\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365172; batch adversarial loss: 0.608502\n",
      "epoch 0; iter: 0; batch classifier loss: 0.848212; batch adversarial loss: 0.565437\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546905; batch adversarial loss: 0.656448\n",
      "epoch 2; iter: 0; batch classifier loss: 0.564548; batch adversarial loss: 0.646651\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619050; batch adversarial loss: 0.649256\n",
      "epoch 4; iter: 0; batch classifier loss: 0.628697; batch adversarial loss: 0.644970\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574319; batch adversarial loss: 0.590989\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570148; batch adversarial loss: 0.637985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571190; batch adversarial loss: 0.612775\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562059; batch adversarial loss: 0.625922\n",
      "epoch 9; iter: 0; batch classifier loss: 0.593223; batch adversarial loss: 0.632589\n",
      "epoch 10; iter: 0; batch classifier loss: 0.615007; batch adversarial loss: 0.547748\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593081; batch adversarial loss: 0.562516\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575884; batch adversarial loss: 0.605419\n",
      "epoch 13; iter: 0; batch classifier loss: 0.582171; batch adversarial loss: 0.582592\n",
      "epoch 14; iter: 0; batch classifier loss: 0.596646; batch adversarial loss: 0.565513\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533467; batch adversarial loss: 0.520376\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501310; batch adversarial loss: 0.521825\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492457; batch adversarial loss: 0.504723\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549962; batch adversarial loss: 0.586503\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501799; batch adversarial loss: 0.557799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527987; batch adversarial loss: 0.576978\n",
      "epoch 21; iter: 0; batch classifier loss: 0.434476; batch adversarial loss: 0.559748\n",
      "epoch 22; iter: 0; batch classifier loss: 0.504570; batch adversarial loss: 0.517917\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517500; batch adversarial loss: 0.628067\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488019; batch adversarial loss: 0.568400\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531652; batch adversarial loss: 0.533790\n",
      "epoch 26; iter: 0; batch classifier loss: 0.526520; batch adversarial loss: 0.511782\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492452; batch adversarial loss: 0.521291\n",
      "epoch 28; iter: 0; batch classifier loss: 0.449710; batch adversarial loss: 0.521372\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413416; batch adversarial loss: 0.518862\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512450; batch adversarial loss: 0.565463\n",
      "epoch 31; iter: 0; batch classifier loss: 0.423243; batch adversarial loss: 0.541759\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506967; batch adversarial loss: 0.532106\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429397; batch adversarial loss: 0.581784\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432552; batch adversarial loss: 0.477038\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452646; batch adversarial loss: 0.603128\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406116; batch adversarial loss: 0.491239\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464484; batch adversarial loss: 0.627540\n",
      "epoch 38; iter: 0; batch classifier loss: 0.413049; batch adversarial loss: 0.490905\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431110; batch adversarial loss: 0.502145\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488028; batch adversarial loss: 0.494967\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459975; batch adversarial loss: 0.474776\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443623; batch adversarial loss: 0.555570\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444043; batch adversarial loss: 0.527523\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504299; batch adversarial loss: 0.562080\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456265; batch adversarial loss: 0.555502\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474479; batch adversarial loss: 0.527446\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457353; batch adversarial loss: 0.571035\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392066; batch adversarial loss: 0.588948\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416982; batch adversarial loss: 0.632686\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415787; batch adversarial loss: 0.542979\n",
      "epoch 51; iter: 0; batch classifier loss: 0.403618; batch adversarial loss: 0.526746\n",
      "epoch 52; iter: 0; batch classifier loss: 0.369326; batch adversarial loss: 0.516600\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418604; batch adversarial loss: 0.599088\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463796; batch adversarial loss: 0.517383\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476938; batch adversarial loss: 0.554109\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463108; batch adversarial loss: 0.619826\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443081; batch adversarial loss: 0.618983\n",
      "epoch 58; iter: 0; batch classifier loss: 0.380625; batch adversarial loss: 0.479209\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371283; batch adversarial loss: 0.562834\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373736; batch adversarial loss: 0.525693\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427371; batch adversarial loss: 0.498439\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424889; batch adversarial loss: 0.526486\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447266; batch adversarial loss: 0.479304\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386898; batch adversarial loss: 0.516481\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428986; batch adversarial loss: 0.478431\n",
      "epoch 66; iter: 0; batch classifier loss: 0.342717; batch adversarial loss: 0.544518\n",
      "epoch 67; iter: 0; batch classifier loss: 0.419777; batch adversarial loss: 0.525921\n",
      "epoch 68; iter: 0; batch classifier loss: 0.448002; batch adversarial loss: 0.544153\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384034; batch adversarial loss: 0.581034\n",
      "epoch 70; iter: 0; batch classifier loss: 0.486955; batch adversarial loss: 0.562659\n",
      "epoch 71; iter: 0; batch classifier loss: 0.490687; batch adversarial loss: 0.514025\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422676; batch adversarial loss: 0.525133\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374233; batch adversarial loss: 0.581678\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436201; batch adversarial loss: 0.516726\n",
      "epoch 75; iter: 0; batch classifier loss: 0.471995; batch adversarial loss: 0.516259\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335742; batch adversarial loss: 0.545383\n",
      "epoch 77; iter: 0; batch classifier loss: 0.397228; batch adversarial loss: 0.498364\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424042; batch adversarial loss: 0.516317\n",
      "epoch 79; iter: 0; batch classifier loss: 0.328033; batch adversarial loss: 0.552947\n",
      "epoch 80; iter: 0; batch classifier loss: 0.428570; batch adversarial loss: 0.572634\n",
      "epoch 81; iter: 0; batch classifier loss: 0.447554; batch adversarial loss: 0.571237\n",
      "epoch 82; iter: 0; batch classifier loss: 0.402929; batch adversarial loss: 0.516834\n",
      "epoch 83; iter: 0; batch classifier loss: 0.445884; batch adversarial loss: 0.600231\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366865; batch adversarial loss: 0.498536\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403514; batch adversarial loss: 0.554441\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378917; batch adversarial loss: 0.582542\n",
      "epoch 87; iter: 0; batch classifier loss: 0.344543; batch adversarial loss: 0.452000\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378175; batch adversarial loss: 0.498213\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346106; batch adversarial loss: 0.592596\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401948; batch adversarial loss: 0.563897\n",
      "epoch 91; iter: 0; batch classifier loss: 0.347723; batch adversarial loss: 0.610480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.376418; batch adversarial loss: 0.535197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.439766; batch adversarial loss: 0.517452\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348453; batch adversarial loss: 0.478816\n",
      "epoch 95; iter: 0; batch classifier loss: 0.389406; batch adversarial loss: 0.581138\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428662; batch adversarial loss: 0.544357\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374372; batch adversarial loss: 0.498267\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390849; batch adversarial loss: 0.507764\n",
      "epoch 99; iter: 0; batch classifier loss: 0.442123; batch adversarial loss: 0.563148\n",
      "epoch 100; iter: 0; batch classifier loss: 0.429470; batch adversarial loss: 0.601357\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413147; batch adversarial loss: 0.590379\n",
      "epoch 102; iter: 0; batch classifier loss: 0.368105; batch adversarial loss: 0.498435\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409011; batch adversarial loss: 0.507071\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354127; batch adversarial loss: 0.600793\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423114; batch adversarial loss: 0.544351\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370058; batch adversarial loss: 0.497515\n",
      "epoch 107; iter: 0; batch classifier loss: 0.512982; batch adversarial loss: 0.535030\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401984; batch adversarial loss: 0.534925\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402795; batch adversarial loss: 0.498109\n",
      "epoch 110; iter: 0; batch classifier loss: 0.340173; batch adversarial loss: 0.451202\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367215; batch adversarial loss: 0.516851\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405571; batch adversarial loss: 0.544671\n",
      "epoch 113; iter: 0; batch classifier loss: 0.423694; batch adversarial loss: 0.544330\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385793; batch adversarial loss: 0.497703\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401372; batch adversarial loss: 0.525278\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325901; batch adversarial loss: 0.544939\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379853; batch adversarial loss: 0.590792\n",
      "epoch 118; iter: 0; batch classifier loss: 0.492146; batch adversarial loss: 0.573166\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349743; batch adversarial loss: 0.553968\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343506; batch adversarial loss: 0.497903\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364608; batch adversarial loss: 0.581793\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399779; batch adversarial loss: 0.516603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408118; batch adversarial loss: 0.562759\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375992; batch adversarial loss: 0.591179\n",
      "epoch 125; iter: 0; batch classifier loss: 0.323301; batch adversarial loss: 0.638118\n",
      "epoch 126; iter: 0; batch classifier loss: 0.444243; batch adversarial loss: 0.581512\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438158; batch adversarial loss: 0.563080\n",
      "epoch 128; iter: 0; batch classifier loss: 0.307742; batch adversarial loss: 0.582078\n",
      "epoch 129; iter: 0; batch classifier loss: 0.417026; batch adversarial loss: 0.554276\n",
      "epoch 130; iter: 0; batch classifier loss: 0.446108; batch adversarial loss: 0.544170\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408021; batch adversarial loss: 0.516360\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355626; batch adversarial loss: 0.591021\n",
      "epoch 133; iter: 0; batch classifier loss: 0.457754; batch adversarial loss: 0.525973\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369164; batch adversarial loss: 0.488055\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348650; batch adversarial loss: 0.665785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385234; batch adversarial loss: 0.544625\n",
      "epoch 137; iter: 0; batch classifier loss: 0.429239; batch adversarial loss: 0.535096\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375252; batch adversarial loss: 0.553845\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361403; batch adversarial loss: 0.601055\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396144; batch adversarial loss: 0.525755\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400937; batch adversarial loss: 0.478698\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428273; batch adversarial loss: 0.572591\n",
      "epoch 143; iter: 0; batch classifier loss: 0.355309; batch adversarial loss: 0.544752\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350035; batch adversarial loss: 0.506762\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379225; batch adversarial loss: 0.498516\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418599; batch adversarial loss: 0.470050\n",
      "epoch 147; iter: 0; batch classifier loss: 0.352019; batch adversarial loss: 0.479549\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354535; batch adversarial loss: 0.525621\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375404; batch adversarial loss: 0.571974\n",
      "epoch 150; iter: 0; batch classifier loss: 0.434580; batch adversarial loss: 0.534767\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349814; batch adversarial loss: 0.460233\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397035; batch adversarial loss: 0.496959\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334097; batch adversarial loss: 0.526514\n",
      "epoch 154; iter: 0; batch classifier loss: 0.429613; batch adversarial loss: 0.544156\n",
      "epoch 155; iter: 0; batch classifier loss: 0.416905; batch adversarial loss: 0.534621\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333989; batch adversarial loss: 0.562618\n",
      "epoch 157; iter: 0; batch classifier loss: 0.436776; batch adversarial loss: 0.506542\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330907; batch adversarial loss: 0.600658\n",
      "epoch 159; iter: 0; batch classifier loss: 0.358070; batch adversarial loss: 0.553697\n",
      "epoch 160; iter: 0; batch classifier loss: 0.464361; batch adversarial loss: 0.610406\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383594; batch adversarial loss: 0.694608\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375622; batch adversarial loss: 0.544724\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366590; batch adversarial loss: 0.497989\n",
      "epoch 164; iter: 0; batch classifier loss: 0.343676; batch adversarial loss: 0.592015\n",
      "epoch 165; iter: 0; batch classifier loss: 0.418476; batch adversarial loss: 0.508597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.289254; batch adversarial loss: 0.600472\n",
      "epoch 167; iter: 0; batch classifier loss: 0.338684; batch adversarial loss: 0.506999\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353533; batch adversarial loss: 0.599874\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368046; batch adversarial loss: 0.533587\n",
      "epoch 170; iter: 0; batch classifier loss: 0.447153; batch adversarial loss: 0.627863\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364841; batch adversarial loss: 0.507581\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369741; batch adversarial loss: 0.488499\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329312; batch adversarial loss: 0.479227\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340133; batch adversarial loss: 0.573034\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325344; batch adversarial loss: 0.536291\n",
      "epoch 176; iter: 0; batch classifier loss: 0.436659; batch adversarial loss: 0.536160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.397881; batch adversarial loss: 0.563578\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336026; batch adversarial loss: 0.488410\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350916; batch adversarial loss: 0.535337\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342039; batch adversarial loss: 0.544537\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362331; batch adversarial loss: 0.581565\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402826; batch adversarial loss: 0.527032\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351160; batch adversarial loss: 0.525594\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319935; batch adversarial loss: 0.506224\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360743; batch adversarial loss: 0.480047\n",
      "epoch 186; iter: 0; batch classifier loss: 0.426321; batch adversarial loss: 0.423424\n",
      "epoch 187; iter: 0; batch classifier loss: 0.439699; batch adversarial loss: 0.591198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.400021; batch adversarial loss: 0.478959\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364421; batch adversarial loss: 0.646890\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401043; batch adversarial loss: 0.497873\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351390; batch adversarial loss: 0.582404\n",
      "epoch 192; iter: 0; batch classifier loss: 0.419491; batch adversarial loss: 0.536163\n",
      "epoch 193; iter: 0; batch classifier loss: 0.310828; batch adversarial loss: 0.563555\n",
      "epoch 194; iter: 0; batch classifier loss: 0.412736; batch adversarial loss: 0.478707\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398540; batch adversarial loss: 0.517025\n",
      "epoch 196; iter: 0; batch classifier loss: 0.371450; batch adversarial loss: 0.544347\n",
      "epoch 197; iter: 0; batch classifier loss: 0.288775; batch adversarial loss: 0.526115\n",
      "epoch 198; iter: 0; batch classifier loss: 0.339953; batch adversarial loss: 0.525509\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385587; batch adversarial loss: 0.534792\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660917; batch adversarial loss: 0.733091\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586079; batch adversarial loss: 0.689417\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569138; batch adversarial loss: 0.676069\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614219; batch adversarial loss: 0.670962\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595977; batch adversarial loss: 0.657904\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543765; batch adversarial loss: 0.601070\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588817; batch adversarial loss: 0.609773\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501084; batch adversarial loss: 0.595134\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504953; batch adversarial loss: 0.533815\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534143; batch adversarial loss: 0.640240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.449002; batch adversarial loss: 0.563804\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607335; batch adversarial loss: 0.568939\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544456; batch adversarial loss: 0.524492\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516595; batch adversarial loss: 0.607181\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520076; batch adversarial loss: 0.562790\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546042; batch adversarial loss: 0.553566\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512079; batch adversarial loss: 0.545117\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484701; batch adversarial loss: 0.541505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.578488; batch adversarial loss: 0.632072\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463158; batch adversarial loss: 0.587502\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480044; batch adversarial loss: 0.588785\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489547; batch adversarial loss: 0.559844\n",
      "epoch 22; iter: 0; batch classifier loss: 0.558444; batch adversarial loss: 0.589927\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450146; batch adversarial loss: 0.530540\n",
      "epoch 24; iter: 0; batch classifier loss: 0.535400; batch adversarial loss: 0.520000\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525267; batch adversarial loss: 0.566926\n",
      "epoch 26; iter: 0; batch classifier loss: 0.487591; batch adversarial loss: 0.620060\n",
      "epoch 27; iter: 0; batch classifier loss: 0.422077; batch adversarial loss: 0.581846\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487937; batch adversarial loss: 0.588905\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443952; batch adversarial loss: 0.508736\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471137; batch adversarial loss: 0.533605\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496632; batch adversarial loss: 0.619129\n",
      "epoch 32; iter: 0; batch classifier loss: 0.532840; batch adversarial loss: 0.540808\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520294; batch adversarial loss: 0.572640\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446305; batch adversarial loss: 0.554933\n",
      "epoch 35; iter: 0; batch classifier loss: 0.509216; batch adversarial loss: 0.520510\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432423; batch adversarial loss: 0.536731\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426712; batch adversarial loss: 0.527809\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442079; batch adversarial loss: 0.553581\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485120; batch adversarial loss: 0.527619\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425341; batch adversarial loss: 0.535588\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464000; batch adversarial loss: 0.615515\n",
      "epoch 42; iter: 0; batch classifier loss: 0.437153; batch adversarial loss: 0.579303\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422135; batch adversarial loss: 0.525450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390542; batch adversarial loss: 0.496457\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425976; batch adversarial loss: 0.522421\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444275; batch adversarial loss: 0.497536\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427829; batch adversarial loss: 0.557891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.472709; batch adversarial loss: 0.588843\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420516; batch adversarial loss: 0.593260\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392209; batch adversarial loss: 0.453485\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411372; batch adversarial loss: 0.624334\n",
      "epoch 52; iter: 0; batch classifier loss: 0.490290; batch adversarial loss: 0.529440\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397656; batch adversarial loss: 0.465129\n",
      "epoch 54; iter: 0; batch classifier loss: 0.403894; batch adversarial loss: 0.544670\n",
      "epoch 55; iter: 0; batch classifier loss: 0.381682; batch adversarial loss: 0.556926\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394752; batch adversarial loss: 0.567984\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440488; batch adversarial loss: 0.546048\n",
      "epoch 58; iter: 0; batch classifier loss: 0.382492; batch adversarial loss: 0.505802\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375416; batch adversarial loss: 0.591587\n",
      "epoch 60; iter: 0; batch classifier loss: 0.368137; batch adversarial loss: 0.505944\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440468; batch adversarial loss: 0.592629\n",
      "epoch 62; iter: 0; batch classifier loss: 0.363776; batch adversarial loss: 0.562283\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396860; batch adversarial loss: 0.553950\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432709; batch adversarial loss: 0.517008\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370793; batch adversarial loss: 0.491297\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452807; batch adversarial loss: 0.609252\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433666; batch adversarial loss: 0.566498\n",
      "epoch 68; iter: 0; batch classifier loss: 0.462339; batch adversarial loss: 0.493078\n",
      "epoch 69; iter: 0; batch classifier loss: 0.506500; batch adversarial loss: 0.623036\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444201; batch adversarial loss: 0.579675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419443; batch adversarial loss: 0.491140\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401458; batch adversarial loss: 0.534153\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447551; batch adversarial loss: 0.590900\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437945; batch adversarial loss: 0.544712\n",
      "epoch 75; iter: 0; batch classifier loss: 0.323753; batch adversarial loss: 0.551930\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396954; batch adversarial loss: 0.581256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.527095; batch adversarial loss: 0.535799\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341203; batch adversarial loss: 0.540640\n",
      "epoch 79; iter: 0; batch classifier loss: 0.336637; batch adversarial loss: 0.599217\n",
      "epoch 80; iter: 0; batch classifier loss: 0.328968; batch adversarial loss: 0.538503\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398411; batch adversarial loss: 0.554916\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.544896\n",
      "epoch 83; iter: 0; batch classifier loss: 0.446238; batch adversarial loss: 0.571814\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430161; batch adversarial loss: 0.498424\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433704; batch adversarial loss: 0.563117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.385096; batch adversarial loss: 0.534886\n",
      "epoch 87; iter: 0; batch classifier loss: 0.346988; batch adversarial loss: 0.597732\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381846; batch adversarial loss: 0.518322\n",
      "epoch 89; iter: 0; batch classifier loss: 0.352697; batch adversarial loss: 0.580389\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359762; batch adversarial loss: 0.485562\n",
      "epoch 91; iter: 0; batch classifier loss: 0.337186; batch adversarial loss: 0.588314\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350125; batch adversarial loss: 0.570993\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437453; batch adversarial loss: 0.552031\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406302; batch adversarial loss: 0.489201\n",
      "epoch 95; iter: 0; batch classifier loss: 0.340970; batch adversarial loss: 0.525485\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350087; batch adversarial loss: 0.648823\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375087; batch adversarial loss: 0.558284\n",
      "epoch 98; iter: 0; batch classifier loss: 0.305194; batch adversarial loss: 0.589120\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389741; batch adversarial loss: 0.555713\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413357; batch adversarial loss: 0.492135\n",
      "epoch 101; iter: 0; batch classifier loss: 0.429947; batch adversarial loss: 0.556772\n",
      "epoch 102; iter: 0; batch classifier loss: 0.340951; batch adversarial loss: 0.536142\n",
      "epoch 103; iter: 0; batch classifier loss: 0.321318; batch adversarial loss: 0.571085\n",
      "epoch 104; iter: 0; batch classifier loss: 0.376313; batch adversarial loss: 0.524398\n",
      "epoch 105; iter: 0; batch classifier loss: 0.335435; batch adversarial loss: 0.600852\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386821; batch adversarial loss: 0.491190\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410058; batch adversarial loss: 0.555405\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364629; batch adversarial loss: 0.526580\n",
      "epoch 109; iter: 0; batch classifier loss: 0.389249; batch adversarial loss: 0.670722\n",
      "epoch 110; iter: 0; batch classifier loss: 0.417920; batch adversarial loss: 0.508059\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405855; batch adversarial loss: 0.507302\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357002; batch adversarial loss: 0.544541\n",
      "epoch 113; iter: 0; batch classifier loss: 0.569943; batch adversarial loss: 0.662960\n",
      "epoch 114; iter: 0; batch classifier loss: 0.320847; batch adversarial loss: 0.617450\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404027; batch adversarial loss: 0.535793\n",
      "epoch 116; iter: 0; batch classifier loss: 0.524145; batch adversarial loss: 0.580696\n",
      "epoch 117; iter: 0; batch classifier loss: 0.323548; batch adversarial loss: 0.626881\n",
      "epoch 118; iter: 0; batch classifier loss: 0.461251; batch adversarial loss: 0.525895\n",
      "epoch 119; iter: 0; batch classifier loss: 0.375554; batch adversarial loss: 0.507800\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338342; batch adversarial loss: 0.508612\n",
      "epoch 121; iter: 0; batch classifier loss: 0.304763; batch adversarial loss: 0.618051\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346317; batch adversarial loss: 0.590406\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353105; batch adversarial loss: 0.589074\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368532; batch adversarial loss: 0.487578\n",
      "epoch 125; iter: 0; batch classifier loss: 0.381022; batch adversarial loss: 0.533942\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338002; batch adversarial loss: 0.556106\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395696; batch adversarial loss: 0.490661\n",
      "epoch 128; iter: 0; batch classifier loss: 0.428982; batch adversarial loss: 0.507136\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361407; batch adversarial loss: 0.526735\n",
      "epoch 130; iter: 0; batch classifier loss: 0.334925; batch adversarial loss: 0.499923\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339639; batch adversarial loss: 0.491066\n",
      "epoch 132; iter: 0; batch classifier loss: 0.432971; batch adversarial loss: 0.572552\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378113; batch adversarial loss: 0.508494\n",
      "epoch 134; iter: 0; batch classifier loss: 0.276127; batch adversarial loss: 0.535322\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375346; batch adversarial loss: 0.554018\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382360; batch adversarial loss: 0.499783\n",
      "epoch 137; iter: 0; batch classifier loss: 0.337664; batch adversarial loss: 0.599088\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392168; batch adversarial loss: 0.553117\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383906; batch adversarial loss: 0.635411\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378142; batch adversarial loss: 0.554078\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403663; batch adversarial loss: 0.489249\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343129; batch adversarial loss: 0.516776\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329210; batch adversarial loss: 0.570845\n",
      "epoch 144; iter: 0; batch classifier loss: 0.360090; batch adversarial loss: 0.534740\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347437; batch adversarial loss: 0.526145\n",
      "epoch 146; iter: 0; batch classifier loss: 0.432546; batch adversarial loss: 0.562639\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387395; batch adversarial loss: 0.552868\n",
      "epoch 148; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.616825\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349144; batch adversarial loss: 0.571663\n",
      "epoch 150; iter: 0; batch classifier loss: 0.302150; batch adversarial loss: 0.608062\n",
      "epoch 151; iter: 0; batch classifier loss: 0.308834; batch adversarial loss: 0.609235\n",
      "epoch 152; iter: 0; batch classifier loss: 0.400330; batch adversarial loss: 0.562243\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328438; batch adversarial loss: 0.536360\n",
      "epoch 154; iter: 0; batch classifier loss: 0.327025; batch adversarial loss: 0.507364\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381797; batch adversarial loss: 0.499676\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378134; batch adversarial loss: 0.580590\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379697; batch adversarial loss: 0.534133\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321297; batch adversarial loss: 0.489202\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337880; batch adversarial loss: 0.518254\n",
      "epoch 160; iter: 0; batch classifier loss: 0.416775; batch adversarial loss: 0.554165\n",
      "epoch 161; iter: 0; batch classifier loss: 0.282037; batch adversarial loss: 0.579441\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392021; batch adversarial loss: 0.527662\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326762; batch adversarial loss: 0.544693\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330851; batch adversarial loss: 0.472547\n",
      "epoch 165; iter: 0; batch classifier loss: 0.366728; batch adversarial loss: 0.607467\n",
      "epoch 166; iter: 0; batch classifier loss: 0.260901; batch adversarial loss: 0.499114\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339644; batch adversarial loss: 0.608976\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306035; batch adversarial loss: 0.525877\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408959; batch adversarial loss: 0.499390\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353633; batch adversarial loss: 0.535127\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374857; batch adversarial loss: 0.572363\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378268; batch adversarial loss: 0.506924\n",
      "epoch 173; iter: 0; batch classifier loss: 0.432100; batch adversarial loss: 0.516391\n",
      "epoch 174; iter: 0; batch classifier loss: 0.342850; batch adversarial loss: 0.561491\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330120; batch adversarial loss: 0.516343\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374560; batch adversarial loss: 0.608675\n",
      "epoch 177; iter: 0; batch classifier loss: 0.326001; batch adversarial loss: 0.479242\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360914; batch adversarial loss: 0.517163\n",
      "epoch 179; iter: 0; batch classifier loss: 0.325329; batch adversarial loss: 0.535319\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367076; batch adversarial loss: 0.617046\n",
      "epoch 181; iter: 0; batch classifier loss: 0.468270; batch adversarial loss: 0.523987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.302651; batch adversarial loss: 0.471402\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388242; batch adversarial loss: 0.565251\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317041; batch adversarial loss: 0.509190\n",
      "epoch 185; iter: 0; batch classifier loss: 0.395849; batch adversarial loss: 0.589177\n",
      "epoch 186; iter: 0; batch classifier loss: 0.278431; batch adversarial loss: 0.580231\n",
      "epoch 187; iter: 0; batch classifier loss: 0.384677; batch adversarial loss: 0.472642\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376956; batch adversarial loss: 0.499201\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383153; batch adversarial loss: 0.625434\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383612; batch adversarial loss: 0.472763\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322912; batch adversarial loss: 0.653343\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337527; batch adversarial loss: 0.625671\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351176; batch adversarial loss: 0.489965\n",
      "epoch 194; iter: 0; batch classifier loss: 0.337488; batch adversarial loss: 0.526281\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370846; batch adversarial loss: 0.489339\n",
      "epoch 196; iter: 0; batch classifier loss: 0.464767; batch adversarial loss: 0.535522\n",
      "epoch 197; iter: 0; batch classifier loss: 0.371539; batch adversarial loss: 0.653392\n",
      "epoch 198; iter: 0; batch classifier loss: 0.427077; batch adversarial loss: 0.553178\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336114; batch adversarial loss: 0.562494\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730608; batch adversarial loss: 0.811004\n",
      "epoch 1; iter: 0; batch classifier loss: 0.801915; batch adversarial loss: 0.847659\n",
      "epoch 2; iter: 0; batch classifier loss: 0.742467; batch adversarial loss: 0.744491\n",
      "epoch 3; iter: 0; batch classifier loss: 0.796778; batch adversarial loss: 0.707281\n",
      "epoch 4; iter: 0; batch classifier loss: 0.655110; batch adversarial loss: 0.634889\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561052; batch adversarial loss: 0.634790\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600378; batch adversarial loss: 0.609268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516282; batch adversarial loss: 0.636522\n",
      "epoch 8; iter: 0; batch classifier loss: 0.488539; batch adversarial loss: 0.566566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589455; batch adversarial loss: 0.638345\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509823; batch adversarial loss: 0.604519\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565441; batch adversarial loss: 0.588365\n",
      "epoch 12; iter: 0; batch classifier loss: 0.573420; batch adversarial loss: 0.628521\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503143; batch adversarial loss: 0.491584\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560519; batch adversarial loss: 0.609217\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550788; batch adversarial loss: 0.575549\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476077; batch adversarial loss: 0.537257\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496593; batch adversarial loss: 0.502176\n",
      "epoch 18; iter: 0; batch classifier loss: 0.538759; batch adversarial loss: 0.567294\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554534; batch adversarial loss: 0.553130\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492433; batch adversarial loss: 0.542202\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499020; batch adversarial loss: 0.585976\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462085; batch adversarial loss: 0.598387\n",
      "epoch 23; iter: 0; batch classifier loss: 0.441947; batch adversarial loss: 0.510756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457763; batch adversarial loss: 0.512951\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481330; batch adversarial loss: 0.573569\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492815; batch adversarial loss: 0.538292\n",
      "epoch 27; iter: 0; batch classifier loss: 0.498454; batch adversarial loss: 0.605661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442018; batch adversarial loss: 0.524056\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490644; batch adversarial loss: 0.592088\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459034; batch adversarial loss: 0.505402\n",
      "epoch 31; iter: 0; batch classifier loss: 0.530305; batch adversarial loss: 0.468291\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453929; batch adversarial loss: 0.583266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440129; batch adversarial loss: 0.519387\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462376; batch adversarial loss: 0.522546\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487569; batch adversarial loss: 0.532583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418021; batch adversarial loss: 0.641674\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414889; batch adversarial loss: 0.460007\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449495; batch adversarial loss: 0.503601\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433128; batch adversarial loss: 0.638638\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396996; batch adversarial loss: 0.559301\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464247; batch adversarial loss: 0.509048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474523; batch adversarial loss: 0.519326\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467378; batch adversarial loss: 0.533749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427920; batch adversarial loss: 0.555111\n",
      "epoch 45; iter: 0; batch classifier loss: 0.372473; batch adversarial loss: 0.452487\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447222; batch adversarial loss: 0.608033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.500749; batch adversarial loss: 0.544956\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454246; batch adversarial loss: 0.591197\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472984; batch adversarial loss: 0.471394\n",
      "epoch 50; iter: 0; batch classifier loss: 0.481366; batch adversarial loss: 0.553622\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455353; batch adversarial loss: 0.489716\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420806; batch adversarial loss: 0.581577\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450731; batch adversarial loss: 0.552930\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451414; batch adversarial loss: 0.516735\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448904; batch adversarial loss: 0.571139\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409046; batch adversarial loss: 0.591465\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443059; batch adversarial loss: 0.517400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390693; batch adversarial loss: 0.534444\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462050; batch adversarial loss: 0.499195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439749; batch adversarial loss: 0.524801\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383441; batch adversarial loss: 0.610948\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410775; batch adversarial loss: 0.507353\n",
      "epoch 63; iter: 0; batch classifier loss: 0.484272; batch adversarial loss: 0.552561\n",
      "epoch 64; iter: 0; batch classifier loss: 0.355139; batch adversarial loss: 0.506350\n",
      "epoch 65; iter: 0; batch classifier loss: 0.360376; batch adversarial loss: 0.489406\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422716; batch adversarial loss: 0.592637\n",
      "epoch 67; iter: 0; batch classifier loss: 0.359948; batch adversarial loss: 0.543622\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441800; batch adversarial loss: 0.554034\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427932; batch adversarial loss: 0.619839\n",
      "epoch 70; iter: 0; batch classifier loss: 0.453362; batch adversarial loss: 0.543949\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373093; batch adversarial loss: 0.469237\n",
      "epoch 72; iter: 0; batch classifier loss: 0.453551; batch adversarial loss: 0.591566\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411783; batch adversarial loss: 0.565231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.463387; batch adversarial loss: 0.635376\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416194; batch adversarial loss: 0.526306\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363251; batch adversarial loss: 0.532341\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389863; batch adversarial loss: 0.582519\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413577; batch adversarial loss: 0.575344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79; iter: 0; batch classifier loss: 0.441403; batch adversarial loss: 0.536888\n",
      "epoch 80; iter: 0; batch classifier loss: 0.434205; batch adversarial loss: 0.612249\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398677; batch adversarial loss: 0.518473\n",
      "epoch 82; iter: 0; batch classifier loss: 0.336781; batch adversarial loss: 0.602925\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385891; batch adversarial loss: 0.543205\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363407; batch adversarial loss: 0.560413\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450995; batch adversarial loss: 0.517427\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440195; batch adversarial loss: 0.499680\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422221; batch adversarial loss: 0.526037\n",
      "epoch 88; iter: 0; batch classifier loss: 0.327098; batch adversarial loss: 0.575127\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426901; batch adversarial loss: 0.507712\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411152; batch adversarial loss: 0.506189\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406892; batch adversarial loss: 0.583497\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397358; batch adversarial loss: 0.515658\n",
      "epoch 93; iter: 0; batch classifier loss: 0.399876; batch adversarial loss: 0.503678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357228; batch adversarial loss: 0.474782\n",
      "epoch 95; iter: 0; batch classifier loss: 0.313047; batch adversarial loss: 0.527282\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336589; batch adversarial loss: 0.495291\n",
      "epoch 97; iter: 0; batch classifier loss: 0.435724; batch adversarial loss: 0.561061\n",
      "epoch 98; iter: 0; batch classifier loss: 0.395953; batch adversarial loss: 0.591694\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396278; batch adversarial loss: 0.544481\n",
      "epoch 100; iter: 0; batch classifier loss: 0.476923; batch adversarial loss: 0.533537\n",
      "epoch 101; iter: 0; batch classifier loss: 0.555879; batch adversarial loss: 0.597652\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364638; batch adversarial loss: 0.524649\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389540; batch adversarial loss: 0.543437\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386762; batch adversarial loss: 0.619905\n",
      "epoch 105; iter: 0; batch classifier loss: 0.438815; batch adversarial loss: 0.567208\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412433; batch adversarial loss: 0.534711\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405380; batch adversarial loss: 0.533956\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383139; batch adversarial loss: 0.505588\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419078; batch adversarial loss: 0.524816\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370871; batch adversarial loss: 0.507894\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376306; batch adversarial loss: 0.560635\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388600; batch adversarial loss: 0.489970\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352208; batch adversarial loss: 0.543217\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411765; batch adversarial loss: 0.583065\n",
      "epoch 115; iter: 0; batch classifier loss: 0.422924; batch adversarial loss: 0.554952\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381841; batch adversarial loss: 0.587894\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367106; batch adversarial loss: 0.544123\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376334; batch adversarial loss: 0.560455\n",
      "epoch 119; iter: 0; batch classifier loss: 0.439907; batch adversarial loss: 0.569740\n",
      "epoch 120; iter: 0; batch classifier loss: 0.339764; batch adversarial loss: 0.544464\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392583; batch adversarial loss: 0.515740\n",
      "epoch 122; iter: 0; batch classifier loss: 0.393237; batch adversarial loss: 0.514801\n",
      "epoch 123; iter: 0; batch classifier loss: 0.434071; batch adversarial loss: 0.504668\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380548; batch adversarial loss: 0.573783\n",
      "epoch 125; iter: 0; batch classifier loss: 0.476006; batch adversarial loss: 0.535213\n",
      "epoch 126; iter: 0; batch classifier loss: 0.368319; batch adversarial loss: 0.533853\n",
      "epoch 127; iter: 0; batch classifier loss: 0.337138; batch adversarial loss: 0.547355\n",
      "epoch 128; iter: 0; batch classifier loss: 0.466636; batch adversarial loss: 0.480731\n",
      "epoch 129; iter: 0; batch classifier loss: 0.447255; batch adversarial loss: 0.566588\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340822; batch adversarial loss: 0.546418\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368838; batch adversarial loss: 0.496684\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372803; batch adversarial loss: 0.547314\n",
      "epoch 133; iter: 0; batch classifier loss: 0.319969; batch adversarial loss: 0.600096\n",
      "epoch 134; iter: 0; batch classifier loss: 0.308779; batch adversarial loss: 0.533726\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408046; batch adversarial loss: 0.542688\n",
      "epoch 136; iter: 0; batch classifier loss: 0.335210; batch adversarial loss: 0.570228\n",
      "epoch 137; iter: 0; batch classifier loss: 0.438080; batch adversarial loss: 0.519023\n",
      "epoch 138; iter: 0; batch classifier loss: 0.303703; batch adversarial loss: 0.582832\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367923; batch adversarial loss: 0.532479\n",
      "epoch 140; iter: 0; batch classifier loss: 0.439104; batch adversarial loss: 0.563130\n",
      "epoch 141; iter: 0; batch classifier loss: 0.394420; batch adversarial loss: 0.560237\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336873; batch adversarial loss: 0.544262\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380344; batch adversarial loss: 0.524647\n",
      "epoch 144; iter: 0; batch classifier loss: 0.402399; batch adversarial loss: 0.495707\n",
      "epoch 145; iter: 0; batch classifier loss: 0.395308; batch adversarial loss: 0.535666\n",
      "epoch 146; iter: 0; batch classifier loss: 0.322546; batch adversarial loss: 0.625232\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346556; batch adversarial loss: 0.526959\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327253; batch adversarial loss: 0.547424\n",
      "epoch 149; iter: 0; batch classifier loss: 0.307058; batch adversarial loss: 0.526103\n",
      "epoch 150; iter: 0; batch classifier loss: 0.322814; batch adversarial loss: 0.639123\n",
      "epoch 151; iter: 0; batch classifier loss: 0.408913; batch adversarial loss: 0.572092\n",
      "epoch 152; iter: 0; batch classifier loss: 0.371877; batch adversarial loss: 0.542490\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367174; batch adversarial loss: 0.598010\n",
      "epoch 154; iter: 0; batch classifier loss: 0.403625; batch adversarial loss: 0.487817\n",
      "epoch 155; iter: 0; batch classifier loss: 0.296434; batch adversarial loss: 0.506816\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356440; batch adversarial loss: 0.572387\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367811; batch adversarial loss: 0.523693\n",
      "epoch 158; iter: 0; batch classifier loss: 0.474864; batch adversarial loss: 0.532936\n",
      "epoch 159; iter: 0; batch classifier loss: 0.429527; batch adversarial loss: 0.592611\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333490; batch adversarial loss: 0.582456\n",
      "epoch 161; iter: 0; batch classifier loss: 0.445896; batch adversarial loss: 0.507480\n",
      "epoch 162; iter: 0; batch classifier loss: 0.322536; batch adversarial loss: 0.600701\n",
      "epoch 163; iter: 0; batch classifier loss: 0.337031; batch adversarial loss: 0.600496\n",
      "epoch 164; iter: 0; batch classifier loss: 0.364915; batch adversarial loss: 0.477704\n",
      "epoch 165; iter: 0; batch classifier loss: 0.347818; batch adversarial loss: 0.551259\n",
      "epoch 166; iter: 0; batch classifier loss: 0.407695; batch adversarial loss: 0.577309\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328075; batch adversarial loss: 0.497929\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339814; batch adversarial loss: 0.431081\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351382; batch adversarial loss: 0.666593\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380813; batch adversarial loss: 0.525397\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367474; batch adversarial loss: 0.487138\n",
      "epoch 172; iter: 0; batch classifier loss: 0.354820; batch adversarial loss: 0.515123\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380640; batch adversarial loss: 0.525565\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366275; batch adversarial loss: 0.458736\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316290; batch adversarial loss: 0.572112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.439658; batch adversarial loss: 0.612825\n",
      "epoch 177; iter: 0; batch classifier loss: 0.411525; batch adversarial loss: 0.477989\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330165; batch adversarial loss: 0.561370\n",
      "epoch 179; iter: 0; batch classifier loss: 0.228993; batch adversarial loss: 0.591494\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343286; batch adversarial loss: 0.570489\n",
      "epoch 181; iter: 0; batch classifier loss: 0.366729; batch adversarial loss: 0.536768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.424248; batch adversarial loss: 0.479205\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357798; batch adversarial loss: 0.525450\n",
      "epoch 184; iter: 0; batch classifier loss: 0.309950; batch adversarial loss: 0.553571\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358342; batch adversarial loss: 0.618106\n",
      "epoch 186; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.506523\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317691; batch adversarial loss: 0.552419\n",
      "epoch 188; iter: 0; batch classifier loss: 0.299996; batch adversarial loss: 0.573227\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378909; batch adversarial loss: 0.477926\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336680; batch adversarial loss: 0.495870\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321650; batch adversarial loss: 0.510293\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357171; batch adversarial loss: 0.536239\n",
      "epoch 193; iter: 0; batch classifier loss: 0.449482; batch adversarial loss: 0.481473\n",
      "epoch 194; iter: 0; batch classifier loss: 0.298328; batch adversarial loss: 0.542086\n",
      "epoch 195; iter: 0; batch classifier loss: 0.413654; batch adversarial loss: 0.608268\n",
      "epoch 196; iter: 0; batch classifier loss: 0.437223; batch adversarial loss: 0.517157\n",
      "epoch 197; iter: 0; batch classifier loss: 0.391464; batch adversarial loss: 0.505098\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333631; batch adversarial loss: 0.575856\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328761; batch adversarial loss: 0.649589\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689531; batch adversarial loss: 0.732320\n",
      "epoch 1; iter: 0; batch classifier loss: 0.687534; batch adversarial loss: 0.705693\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609095; batch adversarial loss: 0.656382\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549904; batch adversarial loss: 0.643408\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545004; batch adversarial loss: 0.619936\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575727; batch adversarial loss: 0.641617\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556195; batch adversarial loss: 0.589007\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546537; batch adversarial loss: 0.606219\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517247; batch adversarial loss: 0.608844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610900; batch adversarial loss: 0.636613\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520518; batch adversarial loss: 0.611031\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499707; batch adversarial loss: 0.565236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511594; batch adversarial loss: 0.600089\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566816; batch adversarial loss: 0.651407\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531941; batch adversarial loss: 0.630911\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522650; batch adversarial loss: 0.559399\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521878; batch adversarial loss: 0.574192\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541495; batch adversarial loss: 0.583425\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463830; batch adversarial loss: 0.582201\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531839; batch adversarial loss: 0.622227\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429895; batch adversarial loss: 0.572363\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493043; batch adversarial loss: 0.476004\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491090; batch adversarial loss: 0.521143\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531380; batch adversarial loss: 0.564873\n",
      "epoch 24; iter: 0; batch classifier loss: 0.414734; batch adversarial loss: 0.558802\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424925; batch adversarial loss: 0.593674\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502591; batch adversarial loss: 0.563026\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421752; batch adversarial loss: 0.563176\n",
      "epoch 28; iter: 0; batch classifier loss: 0.410799; batch adversarial loss: 0.506115\n",
      "epoch 29; iter: 0; batch classifier loss: 0.410810; batch adversarial loss: 0.611760\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465657; batch adversarial loss: 0.588332\n",
      "epoch 31; iter: 0; batch classifier loss: 0.396579; batch adversarial loss: 0.655540\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495229; batch adversarial loss: 0.571187\n",
      "epoch 33; iter: 0; batch classifier loss: 0.396435; batch adversarial loss: 0.579435\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467231; batch adversarial loss: 0.570953\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423149; batch adversarial loss: 0.544890\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426030; batch adversarial loss: 0.544876\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473028; batch adversarial loss: 0.562052\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408539; batch adversarial loss: 0.553768\n",
      "epoch 39; iter: 0; batch classifier loss: 0.487047; batch adversarial loss: 0.561939\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522030; batch adversarial loss: 0.562314\n",
      "epoch 41; iter: 0; batch classifier loss: 0.571883; batch adversarial loss: 0.537136\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425445; batch adversarial loss: 0.478061\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415579; batch adversarial loss: 0.489819\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419607; batch adversarial loss: 0.489252\n",
      "epoch 45; iter: 0; batch classifier loss: 0.478336; batch adversarial loss: 0.526459\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454982; batch adversarial loss: 0.533788\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463593; batch adversarial loss: 0.571666\n",
      "epoch 48; iter: 0; batch classifier loss: 0.514557; batch adversarial loss: 0.443483\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439317; batch adversarial loss: 0.528573\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416558; batch adversarial loss: 0.552257\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408097; batch adversarial loss: 0.553972\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439209; batch adversarial loss: 0.493125\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443821; batch adversarial loss: 0.538318\n",
      "epoch 54; iter: 0; batch classifier loss: 0.487966; batch adversarial loss: 0.546319\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450852; batch adversarial loss: 0.551388\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452066; batch adversarial loss: 0.551597\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443835; batch adversarial loss: 0.508406\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401619; batch adversarial loss: 0.569117\n",
      "epoch 59; iter: 0; batch classifier loss: 0.390202; batch adversarial loss: 0.597969\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374397; batch adversarial loss: 0.575247\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410506; batch adversarial loss: 0.557632\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390499; batch adversarial loss: 0.543177\n",
      "epoch 63; iter: 0; batch classifier loss: 0.457421; batch adversarial loss: 0.484505\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425532; batch adversarial loss: 0.470412\n",
      "epoch 65; iter: 0; batch classifier loss: 0.392459; batch adversarial loss: 0.591388\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374102; batch adversarial loss: 0.579775\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401721; batch adversarial loss: 0.562710\n",
      "epoch 68; iter: 0; batch classifier loss: 0.512457; batch adversarial loss: 0.512148\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424681; batch adversarial loss: 0.525654\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451119; batch adversarial loss: 0.589494\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428387; batch adversarial loss: 0.553306\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422846; batch adversarial loss: 0.535196\n",
      "epoch 73; iter: 0; batch classifier loss: 0.413491; batch adversarial loss: 0.606344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.380176; batch adversarial loss: 0.643555\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457442; batch adversarial loss: 0.505856\n",
      "epoch 76; iter: 0; batch classifier loss: 0.469081; batch adversarial loss: 0.542204\n",
      "epoch 77; iter: 0; batch classifier loss: 0.478996; batch adversarial loss: 0.554436\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428743; batch adversarial loss: 0.583198\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452076; batch adversarial loss: 0.506058\n",
      "epoch 80; iter: 0; batch classifier loss: 0.396944; batch adversarial loss: 0.595834\n",
      "epoch 81; iter: 0; batch classifier loss: 0.432644; batch adversarial loss: 0.481657\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418075; batch adversarial loss: 0.592907\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341377; batch adversarial loss: 0.544335\n",
      "epoch 84; iter: 0; batch classifier loss: 0.488942; batch adversarial loss: 0.534038\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400944; batch adversarial loss: 0.474087\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413460; batch adversarial loss: 0.552329\n",
      "epoch 87; iter: 0; batch classifier loss: 0.419921; batch adversarial loss: 0.507035\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426264; batch adversarial loss: 0.436228\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355882; batch adversarial loss: 0.485975\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372731; batch adversarial loss: 0.548232\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367724; batch adversarial loss: 0.612218\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379959; batch adversarial loss: 0.502142\n",
      "epoch 93; iter: 0; batch classifier loss: 0.481545; batch adversarial loss: 0.542533\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382054; batch adversarial loss: 0.578679\n",
      "epoch 95; iter: 0; batch classifier loss: 0.447461; batch adversarial loss: 0.614151\n",
      "epoch 96; iter: 0; batch classifier loss: 0.453982; batch adversarial loss: 0.546686\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363596; batch adversarial loss: 0.577364\n",
      "epoch 98; iter: 0; batch classifier loss: 0.425148; batch adversarial loss: 0.572849\n",
      "epoch 99; iter: 0; batch classifier loss: 0.478296; batch adversarial loss: 0.592864\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439052; batch adversarial loss: 0.515375\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365614; batch adversarial loss: 0.584409\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354774; batch adversarial loss: 0.514084\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366704; batch adversarial loss: 0.500380\n",
      "epoch 104; iter: 0; batch classifier loss: 0.447151; batch adversarial loss: 0.570617\n",
      "epoch 105; iter: 0; batch classifier loss: 0.443382; batch adversarial loss: 0.563375\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441789; batch adversarial loss: 0.510148\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346511; batch adversarial loss: 0.556326\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387504; batch adversarial loss: 0.627033\n",
      "epoch 109; iter: 0; batch classifier loss: 0.429094; batch adversarial loss: 0.560248\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402363; batch adversarial loss: 0.564241\n",
      "epoch 111; iter: 0; batch classifier loss: 0.365921; batch adversarial loss: 0.508644\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351398; batch adversarial loss: 0.577910\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415989; batch adversarial loss: 0.525669\n",
      "epoch 114; iter: 0; batch classifier loss: 0.463927; batch adversarial loss: 0.479076\n",
      "epoch 115; iter: 0; batch classifier loss: 0.501585; batch adversarial loss: 0.571973\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393938; batch adversarial loss: 0.496577\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390523; batch adversarial loss: 0.554842\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398794; batch adversarial loss: 0.580428\n",
      "epoch 119; iter: 0; batch classifier loss: 0.478142; batch adversarial loss: 0.565655\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377502; batch adversarial loss: 0.450712\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406087; batch adversarial loss: 0.624456\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349374; batch adversarial loss: 0.542914\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395629; batch adversarial loss: 0.514719\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407602; batch adversarial loss: 0.559763\n",
      "epoch 125; iter: 0; batch classifier loss: 0.357548; batch adversarial loss: 0.542021\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345941; batch adversarial loss: 0.619214\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369898; batch adversarial loss: 0.599106\n",
      "epoch 128; iter: 0; batch classifier loss: 0.285889; batch adversarial loss: 0.544354\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368348; batch adversarial loss: 0.556027\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355473; batch adversarial loss: 0.569698\n",
      "epoch 131; iter: 0; batch classifier loss: 0.316546; batch adversarial loss: 0.505165\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372873; batch adversarial loss: 0.454309\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369295; batch adversarial loss: 0.653442\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375372; batch adversarial loss: 0.575105\n",
      "epoch 135; iter: 0; batch classifier loss: 0.430585; batch adversarial loss: 0.535141\n",
      "epoch 136; iter: 0; batch classifier loss: 0.444511; batch adversarial loss: 0.541626\n",
      "epoch 137; iter: 0; batch classifier loss: 0.427303; batch adversarial loss: 0.568587\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379197; batch adversarial loss: 0.478775\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415444; batch adversarial loss: 0.586990\n",
      "epoch 140; iter: 0; batch classifier loss: 0.428650; batch adversarial loss: 0.486983\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391863; batch adversarial loss: 0.538625\n",
      "epoch 142; iter: 0; batch classifier loss: 0.384290; batch adversarial loss: 0.572202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361985; batch adversarial loss: 0.478493\n",
      "epoch 144; iter: 0; batch classifier loss: 0.455060; batch adversarial loss: 0.474245\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372082; batch adversarial loss: 0.645951\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387954; batch adversarial loss: 0.579867\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397494; batch adversarial loss: 0.572572\n",
      "epoch 148; iter: 0; batch classifier loss: 0.476554; batch adversarial loss: 0.575977\n",
      "epoch 149; iter: 0; batch classifier loss: 0.419426; batch adversarial loss: 0.579099\n",
      "epoch 150; iter: 0; batch classifier loss: 0.318420; batch adversarial loss: 0.539810\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390758; batch adversarial loss: 0.538330\n",
      "epoch 152; iter: 0; batch classifier loss: 0.378736; batch adversarial loss: 0.556795\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358113; batch adversarial loss: 0.490690\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424064; batch adversarial loss: 0.572502\n",
      "epoch 155; iter: 0; batch classifier loss: 0.398885; batch adversarial loss: 0.555989\n",
      "epoch 156; iter: 0; batch classifier loss: 0.385762; batch adversarial loss: 0.591218\n",
      "epoch 157; iter: 0; batch classifier loss: 0.292688; batch adversarial loss: 0.525938\n",
      "epoch 158; iter: 0; batch classifier loss: 0.455974; batch adversarial loss: 0.536920\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362527; batch adversarial loss: 0.481281\n",
      "epoch 160; iter: 0; batch classifier loss: 0.441820; batch adversarial loss: 0.568211\n",
      "epoch 161; iter: 0; batch classifier loss: 0.438013; batch adversarial loss: 0.558129\n",
      "epoch 162; iter: 0; batch classifier loss: 0.491703; batch adversarial loss: 0.549506\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350763; batch adversarial loss: 0.536013\n",
      "epoch 164; iter: 0; batch classifier loss: 0.357340; batch adversarial loss: 0.613012\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386320; batch adversarial loss: 0.570434\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387894; batch adversarial loss: 0.611006\n",
      "epoch 167; iter: 0; batch classifier loss: 0.467772; batch adversarial loss: 0.494698\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376664; batch adversarial loss: 0.463370\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368326; batch adversarial loss: 0.536479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.374343; batch adversarial loss: 0.599005\n",
      "epoch 171; iter: 0; batch classifier loss: 0.487147; batch adversarial loss: 0.506757\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392064; batch adversarial loss: 0.511083\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380975; batch adversarial loss: 0.544623\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334664; batch adversarial loss: 0.498359\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346162; batch adversarial loss: 0.555623\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361050; batch adversarial loss: 0.575400\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314502; batch adversarial loss: 0.508074\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317493; batch adversarial loss: 0.462403\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364339; batch adversarial loss: 0.616033\n",
      "epoch 180; iter: 0; batch classifier loss: 0.373280; batch adversarial loss: 0.630886\n",
      "epoch 181; iter: 0; batch classifier loss: 0.369689; batch adversarial loss: 0.501542\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374671; batch adversarial loss: 0.553618\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349272; batch adversarial loss: 0.524650\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337059; batch adversarial loss: 0.615349\n",
      "epoch 185; iter: 0; batch classifier loss: 0.394742; batch adversarial loss: 0.590300\n",
      "epoch 186; iter: 0; batch classifier loss: 0.321752; batch adversarial loss: 0.506404\n",
      "epoch 187; iter: 0; batch classifier loss: 0.406836; batch adversarial loss: 0.544317\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391306; batch adversarial loss: 0.414966\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358127; batch adversarial loss: 0.582525\n",
      "epoch 190; iter: 0; batch classifier loss: 0.398770; batch adversarial loss: 0.533824\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329082; batch adversarial loss: 0.525923\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374678; batch adversarial loss: 0.444199\n",
      "epoch 193; iter: 0; batch classifier loss: 0.394257; batch adversarial loss: 0.574140\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403536; batch adversarial loss: 0.539876\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383549; batch adversarial loss: 0.560576\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362834; batch adversarial loss: 0.506055\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412591; batch adversarial loss: 0.518656\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377733; batch adversarial loss: 0.563759\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379039; batch adversarial loss: 0.667211\n",
      "epoch 0; iter: 0; batch classifier loss: 0.646307; batch adversarial loss: 0.806454\n",
      "epoch 1; iter: 0; batch classifier loss: 0.770596; batch adversarial loss: 0.844824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.849442; batch adversarial loss: 0.825544\n",
      "epoch 3; iter: 0; batch classifier loss: 0.827196; batch adversarial loss: 0.762055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.791013; batch adversarial loss: 0.694646\n",
      "epoch 5; iter: 0; batch classifier loss: 0.636986; batch adversarial loss: 0.669509\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540063; batch adversarial loss: 0.619523\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529363; batch adversarial loss: 0.611843\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506504; batch adversarial loss: 0.614936\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552531; batch adversarial loss: 0.594687\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504518; batch adversarial loss: 0.582376\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549234; batch adversarial loss: 0.550075\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534302; batch adversarial loss: 0.587170\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533347; batch adversarial loss: 0.545652\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510499; batch adversarial loss: 0.597193\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523114; batch adversarial loss: 0.573632\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548821; batch adversarial loss: 0.540475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.562754; batch adversarial loss: 0.525797\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531542; batch adversarial loss: 0.598059\n",
      "epoch 19; iter: 0; batch classifier loss: 0.419574; batch adversarial loss: 0.538566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487161; batch adversarial loss: 0.538547\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539848; batch adversarial loss: 0.561675\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492403; batch adversarial loss: 0.632837\n",
      "epoch 23; iter: 0; batch classifier loss: 0.427082; batch adversarial loss: 0.535135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.438199; batch adversarial loss: 0.549619\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527150; batch adversarial loss: 0.539085\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494613; batch adversarial loss: 0.500736\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477279; batch adversarial loss: 0.524371\n",
      "epoch 28; iter: 0; batch classifier loss: 0.547982; batch adversarial loss: 0.585259\n",
      "epoch 29; iter: 0; batch classifier loss: 0.407503; batch adversarial loss: 0.532601\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489815; batch adversarial loss: 0.566788\n",
      "epoch 31; iter: 0; batch classifier loss: 0.423158; batch adversarial loss: 0.528258\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416068; batch adversarial loss: 0.564083\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435329; batch adversarial loss: 0.603044\n",
      "epoch 34; iter: 0; batch classifier loss: 0.528992; batch adversarial loss: 0.571096\n",
      "epoch 35; iter: 0; batch classifier loss: 0.523549; batch adversarial loss: 0.521635\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459718; batch adversarial loss: 0.598837\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446608; batch adversarial loss: 0.554864\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439590; batch adversarial loss: 0.615576\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392045; batch adversarial loss: 0.590623\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436524; batch adversarial loss: 0.478551\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424941; batch adversarial loss: 0.555194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.507928; batch adversarial loss: 0.494389\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463551; batch adversarial loss: 0.561655\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385645; batch adversarial loss: 0.570620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440370; batch adversarial loss: 0.476818\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451575; batch adversarial loss: 0.613115\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415070; batch adversarial loss: 0.533661\n",
      "epoch 48; iter: 0; batch classifier loss: 0.462817; batch adversarial loss: 0.595379\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384467; batch adversarial loss: 0.500620\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391441; batch adversarial loss: 0.563967\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409464; batch adversarial loss: 0.518925\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452872; batch adversarial loss: 0.580742\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393324; batch adversarial loss: 0.563025\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 0.573021\n",
      "epoch 55; iter: 0; batch classifier loss: 0.463459; batch adversarial loss: 0.499009\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463576; batch adversarial loss: 0.561271\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426648; batch adversarial loss: 0.536325\n",
      "epoch 58; iter: 0; batch classifier loss: 0.379996; batch adversarial loss: 0.570600\n",
      "epoch 59; iter: 0; batch classifier loss: 0.334586; batch adversarial loss: 0.554241\n",
      "epoch 60; iter: 0; batch classifier loss: 0.338324; batch adversarial loss: 0.589871\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398307; batch adversarial loss: 0.617039\n",
      "epoch 62; iter: 0; batch classifier loss: 0.359230; batch adversarial loss: 0.572647\n",
      "epoch 63; iter: 0; batch classifier loss: 0.470882; batch adversarial loss: 0.598621\n",
      "epoch 64; iter: 0; batch classifier loss: 0.443279; batch adversarial loss: 0.563281\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356848; batch adversarial loss: 0.545238\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426105; batch adversarial loss: 0.490493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376423; batch adversarial loss: 0.616785\n",
      "epoch 68; iter: 0; batch classifier loss: 0.358012; batch adversarial loss: 0.517165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.460739; batch adversarial loss: 0.545429\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451976; batch adversarial loss: 0.571675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393921; batch adversarial loss: 0.590092\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386845; batch adversarial loss: 0.508518\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379596; batch adversarial loss: 0.516256\n",
      "epoch 74; iter: 0; batch classifier loss: 0.375486; batch adversarial loss: 0.454244\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412759; batch adversarial loss: 0.580862\n",
      "epoch 76; iter: 0; batch classifier loss: 0.341836; batch adversarial loss: 0.599052\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409598; batch adversarial loss: 0.535077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377303; batch adversarial loss: 0.489570\n",
      "epoch 79; iter: 0; batch classifier loss: 0.465629; batch adversarial loss: 0.535460\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402059; batch adversarial loss: 0.589485\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430460; batch adversarial loss: 0.516459\n",
      "epoch 82; iter: 0; batch classifier loss: 0.307364; batch adversarial loss: 0.617794\n",
      "epoch 83; iter: 0; batch classifier loss: 0.306475; batch adversarial loss: 0.517735\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389278; batch adversarial loss: 0.526166\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413213; batch adversarial loss: 0.526984\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370020; batch adversarial loss: 0.509981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369246; batch adversarial loss: 0.526758\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368774; batch adversarial loss: 0.518423\n",
      "epoch 89; iter: 0; batch classifier loss: 0.344039; batch adversarial loss: 0.544369\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403072; batch adversarial loss: 0.616471\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366197; batch adversarial loss: 0.525966\n",
      "epoch 92; iter: 0; batch classifier loss: 0.446222; batch adversarial loss: 0.453639\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427880; batch adversarial loss: 0.553842\n",
      "epoch 94; iter: 0; batch classifier loss: 0.331287; batch adversarial loss: 0.517377\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397374; batch adversarial loss: 0.553794\n",
      "epoch 96; iter: 0; batch classifier loss: 0.330669; batch adversarial loss: 0.508299\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344536; batch adversarial loss: 0.507876\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357182; batch adversarial loss: 0.508298\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429312; batch adversarial loss: 0.498566\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390320; batch adversarial loss: 0.535700\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398623; batch adversarial loss: 0.535659\n",
      "epoch 102; iter: 0; batch classifier loss: 0.428245; batch adversarial loss: 0.580904\n",
      "epoch 103; iter: 0; batch classifier loss: 0.452807; batch adversarial loss: 0.526466\n",
      "epoch 104; iter: 0; batch classifier loss: 0.395623; batch adversarial loss: 0.499231\n",
      "epoch 105; iter: 0; batch classifier loss: 0.437705; batch adversarial loss: 0.526810\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371636; batch adversarial loss: 0.563203\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356222; batch adversarial loss: 0.490679\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373366; batch adversarial loss: 0.534777\n",
      "epoch 109; iter: 0; batch classifier loss: 0.329786; batch adversarial loss: 0.563668\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349368; batch adversarial loss: 0.554042\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347488; batch adversarial loss: 0.570453\n",
      "epoch 112; iter: 0; batch classifier loss: 0.342317; batch adversarial loss: 0.519499\n",
      "epoch 113; iter: 0; batch classifier loss: 0.409296; batch adversarial loss: 0.561672\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377744; batch adversarial loss: 0.545272\n",
      "epoch 115; iter: 0; batch classifier loss: 0.318918; batch adversarial loss: 0.570714\n",
      "epoch 116; iter: 0; batch classifier loss: 0.413204; batch adversarial loss: 0.562923\n",
      "epoch 117; iter: 0; batch classifier loss: 0.304404; batch adversarial loss: 0.570812\n",
      "epoch 118; iter: 0; batch classifier loss: 0.323153; batch adversarial loss: 0.536071\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369623; batch adversarial loss: 0.516946\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428798; batch adversarial loss: 0.553916\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.553512\n",
      "epoch 122; iter: 0; batch classifier loss: 0.315454; batch adversarial loss: 0.581004\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351037; batch adversarial loss: 0.608521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366058; batch adversarial loss: 0.543698\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368989; batch adversarial loss: 0.516965\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336656; batch adversarial loss: 0.525014\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360167; batch adversarial loss: 0.535729\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370662; batch adversarial loss: 0.571760\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369777; batch adversarial loss: 0.553707\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319560; batch adversarial loss: 0.571559\n",
      "epoch 131; iter: 0; batch classifier loss: 0.280693; batch adversarial loss: 0.598447\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347782; batch adversarial loss: 0.590095\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375429; batch adversarial loss: 0.553119\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390088; batch adversarial loss: 0.563252\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338729; batch adversarial loss: 0.499276\n",
      "epoch 136; iter: 0; batch classifier loss: 0.479789; batch adversarial loss: 0.617503\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358799; batch adversarial loss: 0.499024\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355488; batch adversarial loss: 0.563142\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402762; batch adversarial loss: 0.508240\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348932; batch adversarial loss: 0.599400\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395195; batch adversarial loss: 0.553627\n",
      "epoch 142; iter: 0; batch classifier loss: 0.328338; batch adversarial loss: 0.526524\n",
      "epoch 143; iter: 0; batch classifier loss: 0.284710; batch adversarial loss: 0.626334\n",
      "epoch 144; iter: 0; batch classifier loss: 0.260861; batch adversarial loss: 0.553929\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334870; batch adversarial loss: 0.544785\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383340; batch adversarial loss: 0.626054\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350770; batch adversarial loss: 0.553112\n",
      "epoch 148; iter: 0; batch classifier loss: 0.430349; batch adversarial loss: 0.544739\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413842; batch adversarial loss: 0.563322\n",
      "epoch 150; iter: 0; batch classifier loss: 0.294306; batch adversarial loss: 0.544992\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339384; batch adversarial loss: 0.537045\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391439; batch adversarial loss: 0.579965\n",
      "epoch 153; iter: 0; batch classifier loss: 0.323322; batch adversarial loss: 0.509028\n",
      "epoch 154; iter: 0; batch classifier loss: 0.326898; batch adversarial loss: 0.597114\n",
      "epoch 155; iter: 0; batch classifier loss: 0.377317; batch adversarial loss: 0.545486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350279; batch adversarial loss: 0.525738\n",
      "epoch 157; iter: 0; batch classifier loss: 0.328756; batch adversarial loss: 0.544080\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320718; batch adversarial loss: 0.508466\n",
      "epoch 159; iter: 0; batch classifier loss: 0.315765; batch adversarial loss: 0.654333\n",
      "epoch 160; iter: 0; batch classifier loss: 0.430147; batch adversarial loss: 0.543506\n",
      "epoch 161; iter: 0; batch classifier loss: 0.339897; batch adversarial loss: 0.580210\n",
      "epoch 162; iter: 0; batch classifier loss: 0.298527; batch adversarial loss: 0.544853\n",
      "epoch 163; iter: 0; batch classifier loss: 0.317223; batch adversarial loss: 0.552974\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322933; batch adversarial loss: 0.608414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.360011; batch adversarial loss: 0.561948\n",
      "epoch 166; iter: 0; batch classifier loss: 0.320498; batch adversarial loss: 0.562436\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344159; batch adversarial loss: 0.607687\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387507; batch adversarial loss: 0.564054\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390126; batch adversarial loss: 0.534246\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368278; batch adversarial loss: 0.544262\n",
      "epoch 171; iter: 0; batch classifier loss: 0.360586; batch adversarial loss: 0.617528\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362228; batch adversarial loss: 0.608248\n",
      "epoch 173; iter: 0; batch classifier loss: 0.488574; batch adversarial loss: 0.507305\n",
      "epoch 174; iter: 0; batch classifier loss: 0.254219; batch adversarial loss: 0.608472\n",
      "epoch 175; iter: 0; batch classifier loss: 0.293836; batch adversarial loss: 0.490070\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310401; batch adversarial loss: 0.633538\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386179; batch adversarial loss: 0.589677\n",
      "epoch 178; iter: 0; batch classifier loss: 0.292845; batch adversarial loss: 0.525716\n",
      "epoch 179; iter: 0; batch classifier loss: 0.285172; batch adversarial loss: 0.481539\n",
      "epoch 180; iter: 0; batch classifier loss: 0.365787; batch adversarial loss: 0.607740\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314773; batch adversarial loss: 0.562961\n",
      "epoch 182; iter: 0; batch classifier loss: 0.423378; batch adversarial loss: 0.571103\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304158; batch adversarial loss: 0.526170\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371504; batch adversarial loss: 0.517722\n",
      "epoch 185; iter: 0; batch classifier loss: 0.265913; batch adversarial loss: 0.490869\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350970; batch adversarial loss: 0.625879\n",
      "epoch 187; iter: 0; batch classifier loss: 0.363896; batch adversarial loss: 0.571941\n",
      "epoch 188; iter: 0; batch classifier loss: 0.389074; batch adversarial loss: 0.526396\n",
      "epoch 189; iter: 0; batch classifier loss: 0.407892; batch adversarial loss: 0.554129\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359151; batch adversarial loss: 0.589900\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324739; batch adversarial loss: 0.526751\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333884; batch adversarial loss: 0.562370\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284928; batch adversarial loss: 0.553771\n",
      "epoch 194; iter: 0; batch classifier loss: 0.409813; batch adversarial loss: 0.553700\n",
      "epoch 195; iter: 0; batch classifier loss: 0.343662; batch adversarial loss: 0.508615\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342689; batch adversarial loss: 0.625864\n",
      "epoch 197; iter: 0; batch classifier loss: 0.336999; batch adversarial loss: 0.544512\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384537; batch adversarial loss: 0.535191\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380607; batch adversarial loss: 0.526644\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720402; batch adversarial loss: 1.031092\n",
      "epoch 1; iter: 0; batch classifier loss: 0.875903; batch adversarial loss: 1.303970\n",
      "epoch 2; iter: 0; batch classifier loss: 1.020299; batch adversarial loss: 1.205071\n",
      "epoch 3; iter: 0; batch classifier loss: 1.224514; batch adversarial loss: 1.195458\n",
      "epoch 4; iter: 0; batch classifier loss: 1.184222; batch adversarial loss: 1.094746\n",
      "epoch 5; iter: 0; batch classifier loss: 1.123634; batch adversarial loss: 1.000196\n",
      "epoch 6; iter: 0; batch classifier loss: 1.257241; batch adversarial loss: 0.926413\n",
      "epoch 7; iter: 0; batch classifier loss: 1.172900; batch adversarial loss: 0.855896\n",
      "epoch 8; iter: 0; batch classifier loss: 1.173757; batch adversarial loss: 0.808091\n",
      "epoch 9; iter: 0; batch classifier loss: 1.254023; batch adversarial loss: 0.765215\n",
      "epoch 10; iter: 0; batch classifier loss: 1.281253; batch adversarial loss: 0.701692\n",
      "epoch 11; iter: 0; batch classifier loss: 1.016572; batch adversarial loss: 0.664442\n",
      "epoch 12; iter: 0; batch classifier loss: 0.995278; batch adversarial loss: 0.647438\n",
      "epoch 13; iter: 0; batch classifier loss: 0.658296; batch adversarial loss: 0.621182\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533432; batch adversarial loss: 0.606366\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541025; batch adversarial loss: 0.581154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.563131; batch adversarial loss: 0.548679\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481869; batch adversarial loss: 0.565544\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522395; batch adversarial loss: 0.599475\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502215; batch adversarial loss: 0.582179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532268; batch adversarial loss: 0.620523\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538015; batch adversarial loss: 0.540111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.543262; batch adversarial loss: 0.543068\n",
      "epoch 23; iter: 0; batch classifier loss: 0.544840; batch adversarial loss: 0.533114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458536; batch adversarial loss: 0.656757\n",
      "epoch 25; iter: 0; batch classifier loss: 0.459182; batch adversarial loss: 0.592340\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442073; batch adversarial loss: 0.571504\n",
      "epoch 27; iter: 0; batch classifier loss: 0.575778; batch adversarial loss: 0.628062\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486422; batch adversarial loss: 0.561732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474527; batch adversarial loss: 0.568671\n",
      "epoch 30; iter: 0; batch classifier loss: 0.536861; batch adversarial loss: 0.600835\n",
      "epoch 31; iter: 0; batch classifier loss: 0.522727; batch adversarial loss: 0.605151\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492469; batch adversarial loss: 0.566347\n",
      "epoch 33; iter: 0; batch classifier loss: 0.579005; batch adversarial loss: 0.489461\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430711; batch adversarial loss: 0.626927\n",
      "epoch 35; iter: 0; batch classifier loss: 0.513037; batch adversarial loss: 0.478708\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472533; batch adversarial loss: 0.580443\n",
      "epoch 37; iter: 0; batch classifier loss: 0.492314; batch adversarial loss: 0.570871\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434035; batch adversarial loss: 0.554946\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423660; batch adversarial loss: 0.558516\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460075; batch adversarial loss: 0.562215\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458616; batch adversarial loss: 0.561228\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501335; batch adversarial loss: 0.527355\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471198; batch adversarial loss: 0.564975\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499520; batch adversarial loss: 0.509672\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444382; batch adversarial loss: 0.543844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461996; batch adversarial loss: 0.625466\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429010; batch adversarial loss: 0.585155\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402665; batch adversarial loss: 0.576993\n",
      "epoch 49; iter: 0; batch classifier loss: 0.360486; batch adversarial loss: 0.547020\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469129; batch adversarial loss: 0.631038\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411728; batch adversarial loss: 0.615913\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391845; batch adversarial loss: 0.587851\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432164; batch adversarial loss: 0.569202\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410195; batch adversarial loss: 0.569460\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394077; batch adversarial loss: 0.533606\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449397; batch adversarial loss: 0.526012\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437527; batch adversarial loss: 0.508326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.387834; batch adversarial loss: 0.466202\n",
      "epoch 59; iter: 0; batch classifier loss: 0.365242; batch adversarial loss: 0.535585\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356131; batch adversarial loss: 0.527516\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413247; batch adversarial loss: 0.581458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.448819; batch adversarial loss: 0.613455\n",
      "epoch 63; iter: 0; batch classifier loss: 0.505339; batch adversarial loss: 0.535880\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406778; batch adversarial loss: 0.563461\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403398; batch adversarial loss: 0.579477\n",
      "epoch 66; iter: 0; batch classifier loss: 0.325808; batch adversarial loss: 0.578722\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447443; batch adversarial loss: 0.578439\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417894; batch adversarial loss: 0.527282\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397993; batch adversarial loss: 0.553996\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408006; batch adversarial loss: 0.537598\n",
      "epoch 71; iter: 0; batch classifier loss: 0.443447; batch adversarial loss: 0.535242\n",
      "epoch 72; iter: 0; batch classifier loss: 0.351014; batch adversarial loss: 0.571002\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371981; batch adversarial loss: 0.562867\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384385; batch adversarial loss: 0.502001\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381627; batch adversarial loss: 0.502375\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422828; batch adversarial loss: 0.562587\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368815; batch adversarial loss: 0.580274\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416087; batch adversarial loss: 0.554412\n",
      "epoch 79; iter: 0; batch classifier loss: 0.414232; batch adversarial loss: 0.570758\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390158; batch adversarial loss: 0.510293\n",
      "epoch 81; iter: 0; batch classifier loss: 0.308600; batch adversarial loss: 0.535524\n",
      "epoch 82; iter: 0; batch classifier loss: 0.449385; batch adversarial loss: 0.527216\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326066; batch adversarial loss: 0.622043\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364936; batch adversarial loss: 0.604983\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373564; batch adversarial loss: 0.603848\n",
      "epoch 86; iter: 0; batch classifier loss: 0.323842; batch adversarial loss: 0.578474\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363362; batch adversarial loss: 0.572190\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377190; batch adversarial loss: 0.559290\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382694; batch adversarial loss: 0.642217\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349579; batch adversarial loss: 0.492281\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407206; batch adversarial loss: 0.545528\n",
      "epoch 92; iter: 0; batch classifier loss: 0.356285; batch adversarial loss: 0.588328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.382434; batch adversarial loss: 0.640735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.410691; batch adversarial loss: 0.578216\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348647; batch adversarial loss: 0.560380\n",
      "epoch 96; iter: 0; batch classifier loss: 0.458425; batch adversarial loss: 0.614370\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439158; batch adversarial loss: 0.649250\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390773; batch adversarial loss: 0.534329\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339010; batch adversarial loss: 0.538047\n",
      "epoch 100; iter: 0; batch classifier loss: 0.326796; batch adversarial loss: 0.546010\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357159; batch adversarial loss: 0.581599\n",
      "epoch 102; iter: 0; batch classifier loss: 0.456838; batch adversarial loss: 0.580159\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416548; batch adversarial loss: 0.518671\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344841; batch adversarial loss: 0.560858\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411963; batch adversarial loss: 0.608953\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391326; batch adversarial loss: 0.562514\n",
      "epoch 107; iter: 0; batch classifier loss: 0.303654; batch adversarial loss: 0.473959\n",
      "epoch 108; iter: 0; batch classifier loss: 0.353298; batch adversarial loss: 0.619817\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368685; batch adversarial loss: 0.561604\n",
      "epoch 110; iter: 0; batch classifier loss: 0.341782; batch adversarial loss: 0.554161\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356011; batch adversarial loss: 0.525817\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397416; batch adversarial loss: 0.655868\n",
      "epoch 113; iter: 0; batch classifier loss: 0.402600; batch adversarial loss: 0.554910\n",
      "epoch 114; iter: 0; batch classifier loss: 0.338717; batch adversarial loss: 0.465433\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346283; batch adversarial loss: 0.594651\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339304; batch adversarial loss: 0.578125\n",
      "epoch 117; iter: 0; batch classifier loss: 0.366562; batch adversarial loss: 0.540809\n",
      "epoch 118; iter: 0; batch classifier loss: 0.365218; batch adversarial loss: 0.568672\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373016; batch adversarial loss: 0.518892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.273909; batch adversarial loss: 0.502831\n",
      "epoch 121; iter: 0; batch classifier loss: 0.416856; batch adversarial loss: 0.511267\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382400; batch adversarial loss: 0.596580\n",
      "epoch 123; iter: 0; batch classifier loss: 0.364984; batch adversarial loss: 0.554068\n",
      "epoch 124; iter: 0; batch classifier loss: 0.350077; batch adversarial loss: 0.502648\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334900; batch adversarial loss: 0.571027\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362078; batch adversarial loss: 0.578969\n",
      "epoch 127; iter: 0; batch classifier loss: 0.385672; batch adversarial loss: 0.574359\n",
      "epoch 128; iter: 0; batch classifier loss: 0.307782; batch adversarial loss: 0.565081\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348275; batch adversarial loss: 0.574984\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345219; batch adversarial loss: 0.639574\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359970; batch adversarial loss: 0.563818\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354029; batch adversarial loss: 0.495067\n",
      "epoch 133; iter: 0; batch classifier loss: 0.275735; batch adversarial loss: 0.560823\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333944; batch adversarial loss: 0.592832\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399221; batch adversarial loss: 0.570912\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328264; batch adversarial loss: 0.488436\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349842; batch adversarial loss: 0.573077\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365683; batch adversarial loss: 0.439578\n",
      "epoch 139; iter: 0; batch classifier loss: 0.385124; batch adversarial loss: 0.580148\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346977; batch adversarial loss: 0.604863\n",
      "epoch 141; iter: 0; batch classifier loss: 0.405292; batch adversarial loss: 0.587561\n",
      "epoch 142; iter: 0; batch classifier loss: 0.377253; batch adversarial loss: 0.500350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342766; batch adversarial loss: 0.585717\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347120; batch adversarial loss: 0.517836\n",
      "epoch 145; iter: 0; batch classifier loss: 0.354195; batch adversarial loss: 0.510490\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347531; batch adversarial loss: 0.571796\n",
      "epoch 147; iter: 0; batch classifier loss: 0.297489; batch adversarial loss: 0.535685\n",
      "epoch 148; iter: 0; batch classifier loss: 0.273273; batch adversarial loss: 0.545593\n",
      "epoch 149; iter: 0; batch classifier loss: 0.465909; batch adversarial loss: 0.496634\n",
      "epoch 150; iter: 0; batch classifier loss: 0.322259; batch adversarial loss: 0.553675\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349975; batch adversarial loss: 0.588197\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343142; batch adversarial loss: 0.558186\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350908; batch adversarial loss: 0.599068\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320635; batch adversarial loss: 0.527510\n",
      "epoch 155; iter: 0; batch classifier loss: 0.308437; batch adversarial loss: 0.583806\n",
      "epoch 156; iter: 0; batch classifier loss: 0.292591; batch adversarial loss: 0.554880\n",
      "epoch 157; iter: 0; batch classifier loss: 0.348510; batch adversarial loss: 0.580047\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380651; batch adversarial loss: 0.568085\n",
      "epoch 159; iter: 0; batch classifier loss: 0.309401; batch adversarial loss: 0.589272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.392965; batch adversarial loss: 0.597808\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342819; batch adversarial loss: 0.553348\n",
      "epoch 162; iter: 0; batch classifier loss: 0.374391; batch adversarial loss: 0.558198\n",
      "epoch 163; iter: 0; batch classifier loss: 0.315034; batch adversarial loss: 0.519128\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353908; batch adversarial loss: 0.561062\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374769; batch adversarial loss: 0.534446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333293; batch adversarial loss: 0.690736\n",
      "epoch 167; iter: 0; batch classifier loss: 0.368459; batch adversarial loss: 0.566211\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359702; batch adversarial loss: 0.505249\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372500; batch adversarial loss: 0.548900\n",
      "epoch 170; iter: 0; batch classifier loss: 0.311701; batch adversarial loss: 0.575927\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334864; batch adversarial loss: 0.613577\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357260; batch adversarial loss: 0.563650\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362107; batch adversarial loss: 0.527141\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389745; batch adversarial loss: 0.581955\n",
      "epoch 175; iter: 0; batch classifier loss: 0.309525; batch adversarial loss: 0.595270\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339906; batch adversarial loss: 0.495630\n",
      "epoch 177; iter: 0; batch classifier loss: 0.317135; batch adversarial loss: 0.553069\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323760; batch adversarial loss: 0.510601\n",
      "epoch 179; iter: 0; batch classifier loss: 0.417345; batch adversarial loss: 0.607831\n",
      "epoch 180; iter: 0; batch classifier loss: 0.281942; batch adversarial loss: 0.555069\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354136; batch adversarial loss: 0.534231\n",
      "epoch 182; iter: 0; batch classifier loss: 0.278958; batch adversarial loss: 0.616802\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364609; batch adversarial loss: 0.513751\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358234; batch adversarial loss: 0.559404\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392262; batch adversarial loss: 0.528517\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322782; batch adversarial loss: 0.577516\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361120; batch adversarial loss: 0.544086\n",
      "epoch 188; iter: 0; batch classifier loss: 0.320127; batch adversarial loss: 0.545336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.442224; batch adversarial loss: 0.556006\n",
      "epoch 190; iter: 0; batch classifier loss: 0.263829; batch adversarial loss: 0.602814\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330928; batch adversarial loss: 0.503247\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349214; batch adversarial loss: 0.540486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.434298; batch adversarial loss: 0.554160\n",
      "epoch 194; iter: 0; batch classifier loss: 0.264234; batch adversarial loss: 0.561658\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335638; batch adversarial loss: 0.567907\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321598; batch adversarial loss: 0.583901\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385181; batch adversarial loss: 0.575434\n",
      "epoch 198; iter: 0; batch classifier loss: 0.288581; batch adversarial loss: 0.603970\n",
      "epoch 199; iter: 0; batch classifier loss: 0.293583; batch adversarial loss: 0.564191\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711853; batch adversarial loss: 0.756095\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591838; batch adversarial loss: 0.691346\n",
      "epoch 2; iter: 0; batch classifier loss: 0.560911; batch adversarial loss: 0.668052\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589293; batch adversarial loss: 0.654707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517793; batch adversarial loss: 0.635977\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530199; batch adversarial loss: 0.610340\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561751; batch adversarial loss: 0.608854\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514909; batch adversarial loss: 0.567776\n",
      "epoch 8; iter: 0; batch classifier loss: 0.436191; batch adversarial loss: 0.590920\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554546; batch adversarial loss: 0.599471\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578795; batch adversarial loss: 0.627537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538091; batch adversarial loss: 0.579016\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519528; batch adversarial loss: 0.582520\n",
      "epoch 13; iter: 0; batch classifier loss: 0.453245; batch adversarial loss: 0.603723\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531757; batch adversarial loss: 0.571571\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521869; batch adversarial loss: 0.594664\n",
      "epoch 16; iter: 0; batch classifier loss: 0.434542; batch adversarial loss: 0.589500\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469037; batch adversarial loss: 0.528711\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534484; batch adversarial loss: 0.533529\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498215; batch adversarial loss: 0.561556\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480933; batch adversarial loss: 0.574381\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427941; batch adversarial loss: 0.592731\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495741; batch adversarial loss: 0.596893\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509678; batch adversarial loss: 0.559367\n",
      "epoch 24; iter: 0; batch classifier loss: 0.520545; batch adversarial loss: 0.505779\n",
      "epoch 25; iter: 0; batch classifier loss: 0.409554; batch adversarial loss: 0.563920\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472093; batch adversarial loss: 0.518399\n",
      "epoch 27; iter: 0; batch classifier loss: 0.523087; batch adversarial loss: 0.524456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469348; batch adversarial loss: 0.563275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406892; batch adversarial loss: 0.536966\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448103; batch adversarial loss: 0.673492\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481689; batch adversarial loss: 0.493932\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426514; batch adversarial loss: 0.503321\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466220; batch adversarial loss: 0.586508\n",
      "epoch 34; iter: 0; batch classifier loss: 0.399845; batch adversarial loss: 0.511030\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423301; batch adversarial loss: 0.537751\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474601; batch adversarial loss: 0.580405\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469456; batch adversarial loss: 0.580194\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488293; batch adversarial loss: 0.501388\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474945; batch adversarial loss: 0.527311\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414086; batch adversarial loss: 0.578940\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420063; batch adversarial loss: 0.544986\n",
      "epoch 42; iter: 0; batch classifier loss: 0.491851; batch adversarial loss: 0.482611\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483139; batch adversarial loss: 0.543086\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454413; batch adversarial loss: 0.480838\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446542; batch adversarial loss: 0.542214\n",
      "epoch 46; iter: 0; batch classifier loss: 0.390835; batch adversarial loss: 0.581615\n",
      "epoch 47; iter: 0; batch classifier loss: 0.526029; batch adversarial loss: 0.534713\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495383; batch adversarial loss: 0.531686\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396447; batch adversarial loss: 0.532484\n",
      "epoch 50; iter: 0; batch classifier loss: 0.339039; batch adversarial loss: 0.581503\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413119; batch adversarial loss: 0.550511\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416566; batch adversarial loss: 0.527506\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381261; batch adversarial loss: 0.599258\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452837; batch adversarial loss: 0.495003\n",
      "epoch 55; iter: 0; batch classifier loss: 0.469450; batch adversarial loss: 0.526164\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437035; batch adversarial loss: 0.535395\n",
      "epoch 57; iter: 0; batch classifier loss: 0.371602; batch adversarial loss: 0.553604\n",
      "epoch 58; iter: 0; batch classifier loss: 0.481273; batch adversarial loss: 0.593758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.358518; batch adversarial loss: 0.576279\n",
      "epoch 60; iter: 0; batch classifier loss: 0.454173; batch adversarial loss: 0.514038\n",
      "epoch 61; iter: 0; batch classifier loss: 0.443672; batch adversarial loss: 0.528033\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427381; batch adversarial loss: 0.541634\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450686; batch adversarial loss: 0.571435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439095; batch adversarial loss: 0.610092\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374694; batch adversarial loss: 0.609120\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415728; batch adversarial loss: 0.563005\n",
      "epoch 67; iter: 0; batch classifier loss: 0.456004; batch adversarial loss: 0.562522\n",
      "epoch 68; iter: 0; batch classifier loss: 0.449221; batch adversarial loss: 0.542255\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431014; batch adversarial loss: 0.524996\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414629; batch adversarial loss: 0.535233\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413924; batch adversarial loss: 0.538532\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416919; batch adversarial loss: 0.496258\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376670; batch adversarial loss: 0.481788\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392076; batch adversarial loss: 0.524185\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400731; batch adversarial loss: 0.564932\n",
      "epoch 76; iter: 0; batch classifier loss: 0.483671; batch adversarial loss: 0.497565\n",
      "epoch 77; iter: 0; batch classifier loss: 0.505414; batch adversarial loss: 0.524488\n",
      "epoch 78; iter: 0; batch classifier loss: 0.474389; batch adversarial loss: 0.542507\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400004; batch adversarial loss: 0.532810\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393819; batch adversarial loss: 0.549966\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426103; batch adversarial loss: 0.496194\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394806; batch adversarial loss: 0.530447\n",
      "epoch 83; iter: 0; batch classifier loss: 0.439248; batch adversarial loss: 0.555720\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399516; batch adversarial loss: 0.527175\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373317; batch adversarial loss: 0.574794\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395642; batch adversarial loss: 0.514170\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364531; batch adversarial loss: 0.494936\n",
      "epoch 88; iter: 0; batch classifier loss: 0.405559; batch adversarial loss: 0.523074\n",
      "epoch 89; iter: 0; batch classifier loss: 0.345529; batch adversarial loss: 0.491395\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367876; batch adversarial loss: 0.526624\n",
      "epoch 91; iter: 0; batch classifier loss: 0.500900; batch adversarial loss: 0.560095\n",
      "epoch 92; iter: 0; batch classifier loss: 0.319491; batch adversarial loss: 0.581469\n",
      "epoch 93; iter: 0; batch classifier loss: 0.469416; batch adversarial loss: 0.490036\n",
      "epoch 94; iter: 0; batch classifier loss: 0.320678; batch adversarial loss: 0.523660\n",
      "epoch 95; iter: 0; batch classifier loss: 0.330319; batch adversarial loss: 0.568846\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335995; batch adversarial loss: 0.618868\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378595; batch adversarial loss: 0.568009\n",
      "epoch 98; iter: 0; batch classifier loss: 0.284474; batch adversarial loss: 0.505564\n",
      "epoch 99; iter: 0; batch classifier loss: 0.371282; batch adversarial loss: 0.554750\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410305; batch adversarial loss: 0.516787\n",
      "epoch 101; iter: 0; batch classifier loss: 0.344450; batch adversarial loss: 0.495276\n",
      "epoch 102; iter: 0; batch classifier loss: 0.430955; batch adversarial loss: 0.524122\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404394; batch adversarial loss: 0.540001\n",
      "epoch 104; iter: 0; batch classifier loss: 0.507466; batch adversarial loss: 0.505393\n",
      "epoch 105; iter: 0; batch classifier loss: 0.368053; batch adversarial loss: 0.543034\n",
      "epoch 106; iter: 0; batch classifier loss: 0.483914; batch adversarial loss: 0.553779\n",
      "epoch 107; iter: 0; batch classifier loss: 0.324912; batch adversarial loss: 0.579974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327511; batch adversarial loss: 0.554663\n",
      "epoch 109; iter: 0; batch classifier loss: 0.320512; batch adversarial loss: 0.534869\n",
      "epoch 110; iter: 0; batch classifier loss: 0.451649; batch adversarial loss: 0.513640\n",
      "epoch 111; iter: 0; batch classifier loss: 0.404410; batch adversarial loss: 0.495880\n",
      "epoch 112; iter: 0; batch classifier loss: 0.304812; batch adversarial loss: 0.625875\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421164; batch adversarial loss: 0.533597\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401556; batch adversarial loss: 0.605171\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420316; batch adversarial loss: 0.573545\n",
      "epoch 116; iter: 0; batch classifier loss: 0.460670; batch adversarial loss: 0.511283\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426800; batch adversarial loss: 0.534876\n",
      "epoch 118; iter: 0; batch classifier loss: 0.339724; batch adversarial loss: 0.461890\n",
      "epoch 119; iter: 0; batch classifier loss: 0.311366; batch adversarial loss: 0.596192\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360631; batch adversarial loss: 0.506596\n",
      "epoch 121; iter: 0; batch classifier loss: 0.269853; batch adversarial loss: 0.526416\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389267; batch adversarial loss: 0.609190\n",
      "epoch 123; iter: 0; batch classifier loss: 0.432211; batch adversarial loss: 0.556212\n",
      "epoch 124; iter: 0; batch classifier loss: 0.433393; batch adversarial loss: 0.495714\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411138; batch adversarial loss: 0.471726\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385236; batch adversarial loss: 0.464727\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345324; batch adversarial loss: 0.520786\n",
      "epoch 128; iter: 0; batch classifier loss: 0.450054; batch adversarial loss: 0.531783\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377034; batch adversarial loss: 0.616833\n",
      "epoch 130; iter: 0; batch classifier loss: 0.376503; batch adversarial loss: 0.590527\n",
      "epoch 131; iter: 0; batch classifier loss: 0.317534; batch adversarial loss: 0.468464\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334191; batch adversarial loss: 0.488756\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402119; batch adversarial loss: 0.553911\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413657; batch adversarial loss: 0.583193\n",
      "epoch 135; iter: 0; batch classifier loss: 0.307584; batch adversarial loss: 0.574549\n",
      "epoch 136; iter: 0; batch classifier loss: 0.295782; batch adversarial loss: 0.571467\n",
      "epoch 137; iter: 0; batch classifier loss: 0.459379; batch adversarial loss: 0.586288\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323690; batch adversarial loss: 0.578345\n",
      "epoch 139; iter: 0; batch classifier loss: 0.470833; batch adversarial loss: 0.491327\n",
      "epoch 140; iter: 0; batch classifier loss: 0.393009; batch adversarial loss: 0.473310\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377764; batch adversarial loss: 0.579709\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392794; batch adversarial loss: 0.504288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361558; batch adversarial loss: 0.553235\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388541; batch adversarial loss: 0.526312\n",
      "epoch 145; iter: 0; batch classifier loss: 0.317876; batch adversarial loss: 0.459493\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329550; batch adversarial loss: 0.546820\n",
      "epoch 147; iter: 0; batch classifier loss: 0.464131; batch adversarial loss: 0.548420\n",
      "epoch 148; iter: 0; batch classifier loss: 0.390793; batch adversarial loss: 0.598866\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396881; batch adversarial loss: 0.542918\n",
      "epoch 150; iter: 0; batch classifier loss: 0.262304; batch adversarial loss: 0.638000\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390840; batch adversarial loss: 0.547090\n",
      "epoch 152; iter: 0; batch classifier loss: 0.414974; batch adversarial loss: 0.693957\n",
      "epoch 153; iter: 0; batch classifier loss: 0.424587; batch adversarial loss: 0.565485\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369402; batch adversarial loss: 0.613966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.338442; batch adversarial loss: 0.530495\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344368; batch adversarial loss: 0.508008\n",
      "epoch 157; iter: 0; batch classifier loss: 0.316857; batch adversarial loss: 0.533324\n",
      "epoch 158; iter: 0; batch classifier loss: 0.329334; batch adversarial loss: 0.586552\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345985; batch adversarial loss: 0.496894\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318095; batch adversarial loss: 0.534893\n",
      "epoch 161; iter: 0; batch classifier loss: 0.428326; batch adversarial loss: 0.588609\n",
      "epoch 162; iter: 0; batch classifier loss: 0.404531; batch adversarial loss: 0.510234\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326412; batch adversarial loss: 0.557929\n",
      "epoch 164; iter: 0; batch classifier loss: 0.319880; batch adversarial loss: 0.492566\n",
      "epoch 165; iter: 0; batch classifier loss: 0.421396; batch adversarial loss: 0.539279\n",
      "epoch 166; iter: 0; batch classifier loss: 0.451661; batch adversarial loss: 0.534015\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359895; batch adversarial loss: 0.470833\n",
      "epoch 168; iter: 0; batch classifier loss: 0.365699; batch adversarial loss: 0.557104\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366772; batch adversarial loss: 0.538356\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395471; batch adversarial loss: 0.518514\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409740; batch adversarial loss: 0.461689\n",
      "epoch 172; iter: 0; batch classifier loss: 0.324395; batch adversarial loss: 0.588158\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341102; batch adversarial loss: 0.618482\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371455; batch adversarial loss: 0.458739\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306726; batch adversarial loss: 0.648076\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354336; batch adversarial loss: 0.525286\n",
      "epoch 177; iter: 0; batch classifier loss: 0.294081; batch adversarial loss: 0.551636\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320489; batch adversarial loss: 0.487683\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350879; batch adversarial loss: 0.570429\n",
      "epoch 180; iter: 0; batch classifier loss: 0.416992; batch adversarial loss: 0.469371\n",
      "epoch 181; iter: 0; batch classifier loss: 0.372377; batch adversarial loss: 0.537432\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334944; batch adversarial loss: 0.556924\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358795; batch adversarial loss: 0.535159\n",
      "epoch 184; iter: 0; batch classifier loss: 0.428948; batch adversarial loss: 0.631445\n",
      "epoch 185; iter: 0; batch classifier loss: 0.335959; batch adversarial loss: 0.606569\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359025; batch adversarial loss: 0.539739\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372280; batch adversarial loss: 0.514487\n",
      "epoch 188; iter: 0; batch classifier loss: 0.399213; batch adversarial loss: 0.486720\n",
      "epoch 189; iter: 0; batch classifier loss: 0.285409; batch adversarial loss: 0.588276\n",
      "epoch 190; iter: 0; batch classifier loss: 0.409422; batch adversarial loss: 0.488276\n",
      "epoch 191; iter: 0; batch classifier loss: 0.302616; batch adversarial loss: 0.515931\n",
      "epoch 192; iter: 0; batch classifier loss: 0.364162; batch adversarial loss: 0.554877\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309786; batch adversarial loss: 0.620898\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379905; batch adversarial loss: 0.521385\n",
      "epoch 195; iter: 0; batch classifier loss: 0.355155; batch adversarial loss: 0.538058\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356382; batch adversarial loss: 0.510834\n",
      "epoch 197; iter: 0; batch classifier loss: 0.404976; batch adversarial loss: 0.514197\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363890; batch adversarial loss: 0.591645\n",
      "epoch 199; iter: 0; batch classifier loss: 0.406487; batch adversarial loss: 0.456222\n",
      "epoch 0; iter: 0; batch classifier loss: 0.656229; batch adversarial loss: 0.682437\n",
      "epoch 1; iter: 0; batch classifier loss: 0.636084; batch adversarial loss: 0.659208\n",
      "epoch 2; iter: 0; batch classifier loss: 0.495500; batch adversarial loss: 0.664916\n",
      "epoch 3; iter: 0; batch classifier loss: 0.638019; batch adversarial loss: 0.626394\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547475; batch adversarial loss: 0.596130\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528286; batch adversarial loss: 0.603798\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567500; batch adversarial loss: 0.617891\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596894; batch adversarial loss: 0.619715\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610812; batch adversarial loss: 0.575621\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514925; batch adversarial loss: 0.630199\n",
      "epoch 10; iter: 0; batch classifier loss: 0.534954; batch adversarial loss: 0.534428\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565593; batch adversarial loss: 0.552890\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514212; batch adversarial loss: 0.585988\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537811; batch adversarial loss: 0.603088\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591158; batch adversarial loss: 0.600929\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508436; batch adversarial loss: 0.541712\n",
      "epoch 16; iter: 0; batch classifier loss: 0.575814; batch adversarial loss: 0.516661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480701; batch adversarial loss: 0.609717\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482382; batch adversarial loss: 0.609620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539211; batch adversarial loss: 0.579432\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490902; batch adversarial loss: 0.548075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504002; batch adversarial loss: 0.593611\n",
      "epoch 22; iter: 0; batch classifier loss: 0.429588; batch adversarial loss: 0.518245\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458725; batch adversarial loss: 0.544001\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459004; batch adversarial loss: 0.512936\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482140; batch adversarial loss: 0.458689\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489998; batch adversarial loss: 0.649374\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520492; batch adversarial loss: 0.575234\n",
      "epoch 28; iter: 0; batch classifier loss: 0.517875; batch adversarial loss: 0.544669\n",
      "epoch 29; iter: 0; batch classifier loss: 0.478161; batch adversarial loss: 0.596938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.527276; batch adversarial loss: 0.530681\n",
      "epoch 31; iter: 0; batch classifier loss: 0.506440; batch adversarial loss: 0.546163\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439635; batch adversarial loss: 0.522661\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430652; batch adversarial loss: 0.562208\n",
      "epoch 34; iter: 0; batch classifier loss: 0.498395; batch adversarial loss: 0.530501\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424551; batch adversarial loss: 0.573954\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482292; batch adversarial loss: 0.567623\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430576; batch adversarial loss: 0.581109\n",
      "epoch 38; iter: 0; batch classifier loss: 0.506416; batch adversarial loss: 0.476341\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463949; batch adversarial loss: 0.536653\n",
      "epoch 40; iter: 0; batch classifier loss: 0.479045; batch adversarial loss: 0.629801\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509667; batch adversarial loss: 0.553338\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447879; batch adversarial loss: 0.509341\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426166; batch adversarial loss: 0.614563\n",
      "epoch 44; iter: 0; batch classifier loss: 0.480257; batch adversarial loss: 0.516993\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451053; batch adversarial loss: 0.527509\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464372; batch adversarial loss: 0.533955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424597; batch adversarial loss: 0.536836\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408017; batch adversarial loss: 0.580005\n",
      "epoch 49; iter: 0; batch classifier loss: 0.514622; batch adversarial loss: 0.553898\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426964; batch adversarial loss: 0.561602\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428822; batch adversarial loss: 0.518371\n",
      "epoch 52; iter: 0; batch classifier loss: 0.511265; batch adversarial loss: 0.571908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.475850; batch adversarial loss: 0.616971\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452989; batch adversarial loss: 0.553114\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420331; batch adversarial loss: 0.554200\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442509; batch adversarial loss: 0.570573\n",
      "epoch 57; iter: 0; batch classifier loss: 0.485380; batch adversarial loss: 0.570121\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428056; batch adversarial loss: 0.482085\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467819; batch adversarial loss: 0.499433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436653; batch adversarial loss: 0.580040\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410072; batch adversarial loss: 0.590851\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438697; batch adversarial loss: 0.571272\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450559; batch adversarial loss: 0.571674\n",
      "epoch 64; iter: 0; batch classifier loss: 0.525892; batch adversarial loss: 0.519345\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432594; batch adversarial loss: 0.598673\n",
      "epoch 66; iter: 0; batch classifier loss: 0.493520; batch adversarial loss: 0.535627\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401063; batch adversarial loss: 0.526192\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439578; batch adversarial loss: 0.641413\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447053; batch adversarial loss: 0.535351\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382723; batch adversarial loss: 0.490648\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384312; batch adversarial loss: 0.598694\n",
      "epoch 72; iter: 0; batch classifier loss: 0.451250; batch adversarial loss: 0.510069\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372405; batch adversarial loss: 0.552939\n",
      "epoch 74; iter: 0; batch classifier loss: 0.458709; batch adversarial loss: 0.509106\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425826; batch adversarial loss: 0.553344\n",
      "epoch 76; iter: 0; batch classifier loss: 0.357529; batch adversarial loss: 0.500425\n",
      "epoch 77; iter: 0; batch classifier loss: 0.478757; batch adversarial loss: 0.472859\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372772; batch adversarial loss: 0.598798\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373366; batch adversarial loss: 0.446023\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451977; batch adversarial loss: 0.473575\n",
      "epoch 81; iter: 0; batch classifier loss: 0.493056; batch adversarial loss: 0.499917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.486171; batch adversarial loss: 0.651607\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441576; batch adversarial loss: 0.535698\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365906; batch adversarial loss: 0.553725\n",
      "epoch 85; iter: 0; batch classifier loss: 0.439316; batch adversarial loss: 0.518504\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451002; batch adversarial loss: 0.607264\n",
      "epoch 87; iter: 0; batch classifier loss: 0.422794; batch adversarial loss: 0.553771\n",
      "epoch 88; iter: 0; batch classifier loss: 0.448295; batch adversarial loss: 0.454597\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407297; batch adversarial loss: 0.562354\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415098; batch adversarial loss: 0.588912\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448036; batch adversarial loss: 0.624310\n",
      "epoch 92; iter: 0; batch classifier loss: 0.423382; batch adversarial loss: 0.598008\n",
      "epoch 93; iter: 0; batch classifier loss: 0.503999; batch adversarial loss: 0.571312\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365756; batch adversarial loss: 0.544533\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350706; batch adversarial loss: 0.561691\n",
      "epoch 96; iter: 0; batch classifier loss: 0.451757; batch adversarial loss: 0.545035\n",
      "epoch 97; iter: 0; batch classifier loss: 0.427927; batch adversarial loss: 0.526640\n",
      "epoch 98; iter: 0; batch classifier loss: 0.424849; batch adversarial loss: 0.571429\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363708; batch adversarial loss: 0.535312\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420035; batch adversarial loss: 0.535630\n",
      "epoch 101; iter: 0; batch classifier loss: 0.422825; batch adversarial loss: 0.527132\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367292; batch adversarial loss: 0.499922\n",
      "epoch 103; iter: 0; batch classifier loss: 0.432540; batch adversarial loss: 0.598545\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390653; batch adversarial loss: 0.518024\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363342; batch adversarial loss: 0.500345\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408105; batch adversarial loss: 0.571257\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361867; batch adversarial loss: 0.562432\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377499; batch adversarial loss: 0.544376\n",
      "epoch 109; iter: 0; batch classifier loss: 0.502698; batch adversarial loss: 0.607376\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399785; batch adversarial loss: 0.508711\n",
      "epoch 111; iter: 0; batch classifier loss: 0.322228; batch adversarial loss: 0.562316\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383152; batch adversarial loss: 0.571412\n",
      "epoch 113; iter: 0; batch classifier loss: 0.538214; batch adversarial loss: 0.589281\n",
      "epoch 114; iter: 0; batch classifier loss: 0.357827; batch adversarial loss: 0.651592\n",
      "epoch 115; iter: 0; batch classifier loss: 0.502065; batch adversarial loss: 0.616486\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393968; batch adversarial loss: 0.517656\n",
      "epoch 117; iter: 0; batch classifier loss: 0.405936; batch adversarial loss: 0.534831\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390527; batch adversarial loss: 0.516312\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404771; batch adversarial loss: 0.506786\n",
      "epoch 120; iter: 0; batch classifier loss: 0.483896; batch adversarial loss: 0.506481\n",
      "epoch 121; iter: 0; batch classifier loss: 0.372037; batch adversarial loss: 0.651189\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404828; batch adversarial loss: 0.499596\n",
      "epoch 123; iter: 0; batch classifier loss: 0.450385; batch adversarial loss: 0.548324\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397204; batch adversarial loss: 0.552991\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372711; batch adversarial loss: 0.607224\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377003; batch adversarial loss: 0.508331\n",
      "epoch 127; iter: 0; batch classifier loss: 0.426985; batch adversarial loss: 0.528623\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376251; batch adversarial loss: 0.632987\n",
      "epoch 129; iter: 0; batch classifier loss: 0.396633; batch adversarial loss: 0.544542\n",
      "epoch 130; iter: 0; batch classifier loss: 0.417706; batch adversarial loss: 0.456487\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356363; batch adversarial loss: 0.607568\n",
      "epoch 132; iter: 0; batch classifier loss: 0.429826; batch adversarial loss: 0.545280\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393723; batch adversarial loss: 0.669620\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393685; batch adversarial loss: 0.554925\n",
      "epoch 135; iter: 0; batch classifier loss: 0.432548; batch adversarial loss: 0.562952\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416898; batch adversarial loss: 0.480851\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340491; batch adversarial loss: 0.589373\n",
      "epoch 138; iter: 0; batch classifier loss: 0.438618; batch adversarial loss: 0.489607\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395633; batch adversarial loss: 0.499783\n",
      "epoch 140; iter: 0; batch classifier loss: 0.416305; batch adversarial loss: 0.510347\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386633; batch adversarial loss: 0.508643\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418730; batch adversarial loss: 0.552357\n",
      "epoch 143; iter: 0; batch classifier loss: 0.336851; batch adversarial loss: 0.597087\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389330; batch adversarial loss: 0.624187\n",
      "epoch 145; iter: 0; batch classifier loss: 0.345438; batch adversarial loss: 0.544192\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358676; batch adversarial loss: 0.563107\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372622; batch adversarial loss: 0.526252\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410673; batch adversarial loss: 0.501508\n",
      "epoch 149; iter: 0; batch classifier loss: 0.420564; batch adversarial loss: 0.507713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.366079; batch adversarial loss: 0.554964\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380405; batch adversarial loss: 0.552056\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342799; batch adversarial loss: 0.527705\n",
      "epoch 153; iter: 0; batch classifier loss: 0.471057; batch adversarial loss: 0.547647\n",
      "epoch 154; iter: 0; batch classifier loss: 0.436336; batch adversarial loss: 0.562976\n",
      "epoch 155; iter: 0; batch classifier loss: 0.378173; batch adversarial loss: 0.483309\n",
      "epoch 156; iter: 0; batch classifier loss: 0.451298; batch adversarial loss: 0.606848\n",
      "epoch 157; iter: 0; batch classifier loss: 0.329294; batch adversarial loss: 0.561020\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388583; batch adversarial loss: 0.526368\n",
      "epoch 159; iter: 0; batch classifier loss: 0.446225; batch adversarial loss: 0.633462\n",
      "epoch 160; iter: 0; batch classifier loss: 0.299463; batch adversarial loss: 0.509601\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416407; batch adversarial loss: 0.519654\n",
      "epoch 162; iter: 0; batch classifier loss: 0.319019; batch adversarial loss: 0.591648\n",
      "epoch 163; iter: 0; batch classifier loss: 0.458384; batch adversarial loss: 0.554086\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373358; batch adversarial loss: 0.572091\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393463; batch adversarial loss: 0.526041\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388594; batch adversarial loss: 0.589024\n",
      "epoch 167; iter: 0; batch classifier loss: 0.415032; batch adversarial loss: 0.578667\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358340; batch adversarial loss: 0.544594\n",
      "epoch 169; iter: 0; batch classifier loss: 0.445356; batch adversarial loss: 0.581638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363094; batch adversarial loss: 0.598865\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347654; batch adversarial loss: 0.580406\n",
      "epoch 172; iter: 0; batch classifier loss: 0.464782; batch adversarial loss: 0.518327\n",
      "epoch 173; iter: 0; batch classifier loss: 0.406268; batch adversarial loss: 0.491015\n",
      "epoch 174; iter: 0; batch classifier loss: 0.472905; batch adversarial loss: 0.588291\n",
      "epoch 175; iter: 0; batch classifier loss: 0.303074; batch adversarial loss: 0.597872\n",
      "epoch 176; iter: 0; batch classifier loss: 0.302308; batch adversarial loss: 0.625952\n",
      "epoch 177; iter: 0; batch classifier loss: 0.405959; batch adversarial loss: 0.597332\n",
      "epoch 178; iter: 0; batch classifier loss: 0.397333; batch adversarial loss: 0.589471\n",
      "epoch 179; iter: 0; batch classifier loss: 0.398012; batch adversarial loss: 0.506305\n",
      "epoch 180; iter: 0; batch classifier loss: 0.472570; batch adversarial loss: 0.506867\n",
      "epoch 181; iter: 0; batch classifier loss: 0.426698; batch adversarial loss: 0.553768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.335336; batch adversarial loss: 0.554241\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386714; batch adversarial loss: 0.598717\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338173; batch adversarial loss: 0.599308\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402693; batch adversarial loss: 0.499750\n",
      "epoch 186; iter: 0; batch classifier loss: 0.306493; batch adversarial loss: 0.535690\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376734; batch adversarial loss: 0.545669\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385014; batch adversarial loss: 0.606399\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379758; batch adversarial loss: 0.597783\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379711; batch adversarial loss: 0.500740\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366257; batch adversarial loss: 0.598120\n",
      "epoch 192; iter: 0; batch classifier loss: 0.356403; batch adversarial loss: 0.526244\n",
      "epoch 193; iter: 0; batch classifier loss: 0.405900; batch adversarial loss: 0.633661\n",
      "epoch 194; iter: 0; batch classifier loss: 0.320802; batch adversarial loss: 0.527861\n",
      "epoch 195; iter: 0; batch classifier loss: 0.429349; batch adversarial loss: 0.508799\n",
      "epoch 196; iter: 0; batch classifier loss: 0.400307; batch adversarial loss: 0.589005\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352338; batch adversarial loss: 0.482468\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334429; batch adversarial loss: 0.571273\n",
      "epoch 199; iter: 0; batch classifier loss: 0.432999; batch adversarial loss: 0.517738\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677906; batch adversarial loss: 0.714448\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590032; batch adversarial loss: 0.690233\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567578; batch adversarial loss: 0.659838\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582787; batch adversarial loss: 0.624058\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634353; batch adversarial loss: 0.582792\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505430; batch adversarial loss: 0.618840\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523365; batch adversarial loss: 0.592917\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555820; batch adversarial loss: 0.615978\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596289; batch adversarial loss: 0.588157\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487723; batch adversarial loss: 0.570277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479889; batch adversarial loss: 0.552785\n",
      "epoch 11; iter: 0; batch classifier loss: 0.468960; batch adversarial loss: 0.577798\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538565; batch adversarial loss: 0.601154\n",
      "epoch 13; iter: 0; batch classifier loss: 0.604264; batch adversarial loss: 0.574588\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601064; batch adversarial loss: 0.583700\n",
      "epoch 15; iter: 0; batch classifier loss: 0.552286; batch adversarial loss: 0.598164\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577100; batch adversarial loss: 0.543271\n",
      "epoch 17; iter: 0; batch classifier loss: 0.601550; batch adversarial loss: 0.586978\n",
      "epoch 18; iter: 0; batch classifier loss: 0.550157; batch adversarial loss: 0.559224\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513110; batch adversarial loss: 0.564099\n",
      "epoch 20; iter: 0; batch classifier loss: 0.545762; batch adversarial loss: 0.576868\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503681; batch adversarial loss: 0.633912\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573925; batch adversarial loss: 0.575402\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492394; batch adversarial loss: 0.587872\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518291; batch adversarial loss: 0.559706\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479656; batch adversarial loss: 0.517595\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502514; batch adversarial loss: 0.579971\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474347; batch adversarial loss: 0.522976\n",
      "epoch 28; iter: 0; batch classifier loss: 0.367204; batch adversarial loss: 0.603683\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440754; batch adversarial loss: 0.554849\n",
      "epoch 30; iter: 0; batch classifier loss: 0.554993; batch adversarial loss: 0.511993\n",
      "epoch 31; iter: 0; batch classifier loss: 0.518375; batch adversarial loss: 0.571485\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517803; batch adversarial loss: 0.579240\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476541; batch adversarial loss: 0.596141\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433399; batch adversarial loss: 0.457728\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460717; batch adversarial loss: 0.596090\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422824; batch adversarial loss: 0.483749\n",
      "epoch 37; iter: 0; batch classifier loss: 0.393841; batch adversarial loss: 0.491525\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414328; batch adversarial loss: 0.482588\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460180; batch adversarial loss: 0.553954\n",
      "epoch 40; iter: 0; batch classifier loss: 0.368079; batch adversarial loss: 0.624332\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408966; batch adversarial loss: 0.588896\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448598; batch adversarial loss: 0.500126\n",
      "epoch 43; iter: 0; batch classifier loss: 0.379277; batch adversarial loss: 0.501100\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454888; batch adversarial loss: 0.542521\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473699; batch adversarial loss: 0.551921\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432391; batch adversarial loss: 0.527104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.466223; batch adversarial loss: 0.542212\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447605; batch adversarial loss: 0.518741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468281; batch adversarial loss: 0.545546\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453180; batch adversarial loss: 0.507708\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427327; batch adversarial loss: 0.562851\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415155; batch adversarial loss: 0.517040\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390817; batch adversarial loss: 0.480498\n",
      "epoch 54; iter: 0; batch classifier loss: 0.312518; batch adversarial loss: 0.536329\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423189; batch adversarial loss: 0.533661\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441853; batch adversarial loss: 0.500305\n",
      "epoch 57; iter: 0; batch classifier loss: 0.373703; batch adversarial loss: 0.536463\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410202; batch adversarial loss: 0.490535\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376420; batch adversarial loss: 0.514608\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441355; batch adversarial loss: 0.488501\n",
      "epoch 61; iter: 0; batch classifier loss: 0.324419; batch adversarial loss: 0.531383\n",
      "epoch 62; iter: 0; batch classifier loss: 0.499868; batch adversarial loss: 0.560168\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421744; batch adversarial loss: 0.526241\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442231; batch adversarial loss: 0.591400\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442498; batch adversarial loss: 0.600337\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421796; batch adversarial loss: 0.489106\n",
      "epoch 67; iter: 0; batch classifier loss: 0.471711; batch adversarial loss: 0.574310\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418524; batch adversarial loss: 0.589085\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448408; batch adversarial loss: 0.562961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446349; batch adversarial loss: 0.559301\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377577; batch adversarial loss: 0.525840\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466093; batch adversarial loss: 0.601623\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425581; batch adversarial loss: 0.517508\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389927; batch adversarial loss: 0.634765\n",
      "epoch 75; iter: 0; batch classifier loss: 0.484266; batch adversarial loss: 0.644985\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400086; batch adversarial loss: 0.443990\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376261; batch adversarial loss: 0.515670\n",
      "epoch 78; iter: 0; batch classifier loss: 0.408666; batch adversarial loss: 0.567908\n",
      "epoch 79; iter: 0; batch classifier loss: 0.473613; batch adversarial loss: 0.516961\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347042; batch adversarial loss: 0.540365\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430139; batch adversarial loss: 0.508966\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407654; batch adversarial loss: 0.455653\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381075; batch adversarial loss: 0.496212\n",
      "epoch 84; iter: 0; batch classifier loss: 0.492869; batch adversarial loss: 0.537087\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438695; batch adversarial loss: 0.592640\n",
      "epoch 86; iter: 0; batch classifier loss: 0.318450; batch adversarial loss: 0.516355\n",
      "epoch 87; iter: 0; batch classifier loss: 0.436483; batch adversarial loss: 0.488575\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341455; batch adversarial loss: 0.626568\n",
      "epoch 89; iter: 0; batch classifier loss: 0.485979; batch adversarial loss: 0.582079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393689; batch adversarial loss: 0.580976\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411792; batch adversarial loss: 0.517263\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450349; batch adversarial loss: 0.570542\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353757; batch adversarial loss: 0.574786\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372298; batch adversarial loss: 0.516747\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398405; batch adversarial loss: 0.533590\n",
      "epoch 96; iter: 0; batch classifier loss: 0.432075; batch adversarial loss: 0.565968\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388901; batch adversarial loss: 0.482766\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409551; batch adversarial loss: 0.624671\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354584; batch adversarial loss: 0.550783\n",
      "epoch 100; iter: 0; batch classifier loss: 0.419336; batch adversarial loss: 0.611737\n",
      "epoch 101; iter: 0; batch classifier loss: 0.486789; batch adversarial loss: 0.543765\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371972; batch adversarial loss: 0.482172\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417130; batch adversarial loss: 0.535713\n",
      "epoch 104; iter: 0; batch classifier loss: 0.457330; batch adversarial loss: 0.640775\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370489; batch adversarial loss: 0.544306\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380901; batch adversarial loss: 0.609344\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368606; batch adversarial loss: 0.625778\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413401; batch adversarial loss: 0.515156\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340395; batch adversarial loss: 0.538912\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344377; batch adversarial loss: 0.547375\n",
      "epoch 111; iter: 0; batch classifier loss: 0.377984; batch adversarial loss: 0.558859\n",
      "epoch 112; iter: 0; batch classifier loss: 0.408090; batch adversarial loss: 0.564734\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384124; batch adversarial loss: 0.545022\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418871; batch adversarial loss: 0.564677\n",
      "epoch 115; iter: 0; batch classifier loss: 0.317550; batch adversarial loss: 0.470902\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382496; batch adversarial loss: 0.619658\n",
      "epoch 117; iter: 0; batch classifier loss: 0.379342; batch adversarial loss: 0.479189\n",
      "epoch 118; iter: 0; batch classifier loss: 0.349061; batch adversarial loss: 0.547939\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390249; batch adversarial loss: 0.513843\n",
      "epoch 120; iter: 0; batch classifier loss: 0.457023; batch adversarial loss: 0.496813\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388496; batch adversarial loss: 0.607725\n",
      "epoch 122; iter: 0; batch classifier loss: 0.420572; batch adversarial loss: 0.538486\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377989; batch adversarial loss: 0.458251\n",
      "epoch 124; iter: 0; batch classifier loss: 0.428032; batch adversarial loss: 0.492947\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384169; batch adversarial loss: 0.535920\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403481; batch adversarial loss: 0.514345\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410171; batch adversarial loss: 0.517214\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410215; batch adversarial loss: 0.588796\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385225; batch adversarial loss: 0.653013\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354914; batch adversarial loss: 0.637270\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365821; batch adversarial loss: 0.518743\n",
      "epoch 132; iter: 0; batch classifier loss: 0.408523; batch adversarial loss: 0.566948\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383412; batch adversarial loss: 0.458976\n",
      "epoch 134; iter: 0; batch classifier loss: 0.417301; batch adversarial loss: 0.473407\n",
      "epoch 135; iter: 0; batch classifier loss: 0.405420; batch adversarial loss: 0.528402\n",
      "epoch 136; iter: 0; batch classifier loss: 0.388578; batch adversarial loss: 0.514657\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386005; batch adversarial loss: 0.525471\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346772; batch adversarial loss: 0.442245\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398653; batch adversarial loss: 0.488977\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339696; batch adversarial loss: 0.580899\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400504; batch adversarial loss: 0.553830\n",
      "epoch 142; iter: 0; batch classifier loss: 0.401511; batch adversarial loss: 0.473735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.425841; batch adversarial loss: 0.526221\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351503; batch adversarial loss: 0.570940\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365641; batch adversarial loss: 0.537315\n",
      "epoch 146; iter: 0; batch classifier loss: 0.319515; batch adversarial loss: 0.570209\n",
      "epoch 147; iter: 0; batch classifier loss: 0.415183; batch adversarial loss: 0.553730\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357341; batch adversarial loss: 0.577637\n",
      "epoch 149; iter: 0; batch classifier loss: 0.434706; batch adversarial loss: 0.573452\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368148; batch adversarial loss: 0.572441\n",
      "epoch 151; iter: 0; batch classifier loss: 0.346427; batch adversarial loss: 0.592664\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338529; batch adversarial loss: 0.562044\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391308; batch adversarial loss: 0.533915\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372499; batch adversarial loss: 0.550145\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346531; batch adversarial loss: 0.615935\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344473; batch adversarial loss: 0.565795\n",
      "epoch 157; iter: 0; batch classifier loss: 0.436061; batch adversarial loss: 0.592134\n",
      "epoch 158; iter: 0; batch classifier loss: 0.317221; batch adversarial loss: 0.560155\n",
      "epoch 159; iter: 0; batch classifier loss: 0.330603; batch adversarial loss: 0.526901\n",
      "epoch 160; iter: 0; batch classifier loss: 0.366044; batch adversarial loss: 0.509571\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410244; batch adversarial loss: 0.505297\n",
      "epoch 162; iter: 0; batch classifier loss: 0.464523; batch adversarial loss: 0.526535\n",
      "epoch 163; iter: 0; batch classifier loss: 0.396341; batch adversarial loss: 0.588895\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414775; batch adversarial loss: 0.486226\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349433; batch adversarial loss: 0.538558\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380572; batch adversarial loss: 0.683957\n",
      "epoch 167; iter: 0; batch classifier loss: 0.410723; batch adversarial loss: 0.538162\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318920; batch adversarial loss: 0.573898\n",
      "epoch 169; iter: 0; batch classifier loss: 0.420459; batch adversarial loss: 0.545797\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369059; batch adversarial loss: 0.542524\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375957; batch adversarial loss: 0.528695\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360882; batch adversarial loss: 0.624387\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356996; batch adversarial loss: 0.514859\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357441; batch adversarial loss: 0.507749\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321358; batch adversarial loss: 0.526313\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383913; batch adversarial loss: 0.582260\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337735; batch adversarial loss: 0.537008\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339520; batch adversarial loss: 0.506303\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306602; batch adversarial loss: 0.534704\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364898; batch adversarial loss: 0.536819\n",
      "epoch 181; iter: 0; batch classifier loss: 0.272591; batch adversarial loss: 0.550671\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337486; batch adversarial loss: 0.578782\n",
      "epoch 183; iter: 0; batch classifier loss: 0.406465; batch adversarial loss: 0.562812\n",
      "epoch 184; iter: 0; batch classifier loss: 0.406139; batch adversarial loss: 0.525572\n",
      "epoch 185; iter: 0; batch classifier loss: 0.489163; batch adversarial loss: 0.531765\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341110; batch adversarial loss: 0.577657\n",
      "epoch 187; iter: 0; batch classifier loss: 0.300923; batch adversarial loss: 0.496522\n",
      "epoch 188; iter: 0; batch classifier loss: 0.280463; batch adversarial loss: 0.579110\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385595; batch adversarial loss: 0.537427\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345250; batch adversarial loss: 0.583060\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352023; batch adversarial loss: 0.471251\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330742; batch adversarial loss: 0.506131\n",
      "epoch 193; iter: 0; batch classifier loss: 0.427936; batch adversarial loss: 0.507385\n",
      "epoch 194; iter: 0; batch classifier loss: 0.487728; batch adversarial loss: 0.562862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.403747; batch adversarial loss: 0.527122\n",
      "epoch 196; iter: 0; batch classifier loss: 0.345383; batch adversarial loss: 0.505784\n",
      "epoch 197; iter: 0; batch classifier loss: 0.391385; batch adversarial loss: 0.510135\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336742; batch adversarial loss: 0.564401\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364137; batch adversarial loss: 0.534318\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710731; batch adversarial loss: 0.622564\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591616; batch adversarial loss: 0.630507\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610030; batch adversarial loss: 0.638671\n",
      "epoch 3; iter: 0; batch classifier loss: 0.560141; batch adversarial loss: 0.587925\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605010; batch adversarial loss: 0.654108\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555355; batch adversarial loss: 0.637749\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600656; batch adversarial loss: 0.616274\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539452; batch adversarial loss: 0.618905\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519501; batch adversarial loss: 0.585773\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567402; batch adversarial loss: 0.610511\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477187; batch adversarial loss: 0.605544\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559964; batch adversarial loss: 0.601068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578975; batch adversarial loss: 0.610930\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553242; batch adversarial loss: 0.549972\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502161; batch adversarial loss: 0.530247\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536341; batch adversarial loss: 0.561012\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492480; batch adversarial loss: 0.590429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497763; batch adversarial loss: 0.554758\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532141; batch adversarial loss: 0.539049\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439744; batch adversarial loss: 0.529619\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522015; batch adversarial loss: 0.601939\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525821; batch adversarial loss: 0.587431\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513821; batch adversarial loss: 0.562813\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527729; batch adversarial loss: 0.587361\n",
      "epoch 24; iter: 0; batch classifier loss: 0.437826; batch adversarial loss: 0.571886\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424762; batch adversarial loss: 0.536635\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452877; batch adversarial loss: 0.582032\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440467; batch adversarial loss: 0.586345\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538509; batch adversarial loss: 0.596931\n",
      "epoch 29; iter: 0; batch classifier loss: 0.414852; batch adversarial loss: 0.586801\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446278; batch adversarial loss: 0.672351\n",
      "epoch 31; iter: 0; batch classifier loss: 0.386493; batch adversarial loss: 0.519402\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460866; batch adversarial loss: 0.565111\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415496; batch adversarial loss: 0.570113\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454751; batch adversarial loss: 0.672950\n",
      "epoch 35; iter: 0; batch classifier loss: 0.373461; batch adversarial loss: 0.520441\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473506; batch adversarial loss: 0.606582\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415403; batch adversarial loss: 0.521188\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422839; batch adversarial loss: 0.595339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.431864; batch adversarial loss: 0.483102\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444530; batch adversarial loss: 0.527441\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489282; batch adversarial loss: 0.554160\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441311; batch adversarial loss: 0.622449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.532556; batch adversarial loss: 0.527580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366194; batch adversarial loss: 0.561287\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427791; batch adversarial loss: 0.614146\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418252; batch adversarial loss: 0.656799\n",
      "epoch 47; iter: 0; batch classifier loss: 0.349028; batch adversarial loss: 0.499568\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445409; batch adversarial loss: 0.517342\n",
      "epoch 49; iter: 0; batch classifier loss: 0.486466; batch adversarial loss: 0.539854\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463370; batch adversarial loss: 0.552103\n",
      "epoch 51; iter: 0; batch classifier loss: 0.407498; batch adversarial loss: 0.536009\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406709; batch adversarial loss: 0.596307\n",
      "epoch 53; iter: 0; batch classifier loss: 0.380696; batch adversarial loss: 0.524956\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399778; batch adversarial loss: 0.558527\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448455; batch adversarial loss: 0.555581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463550; batch adversarial loss: 0.573451\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396045; batch adversarial loss: 0.579578\n",
      "epoch 58; iter: 0; batch classifier loss: 0.527998; batch adversarial loss: 0.570104\n",
      "epoch 59; iter: 0; batch classifier loss: 0.492109; batch adversarial loss: 0.511629\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410857; batch adversarial loss: 0.562938\n",
      "epoch 61; iter: 0; batch classifier loss: 0.361912; batch adversarial loss: 0.589186\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453279; batch adversarial loss: 0.598236\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383406; batch adversarial loss: 0.545648\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413773; batch adversarial loss: 0.571867\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429590; batch adversarial loss: 0.537253\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413657; batch adversarial loss: 0.621954\n",
      "epoch 67; iter: 0; batch classifier loss: 0.389316; batch adversarial loss: 0.536600\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396604; batch adversarial loss: 0.562239\n",
      "epoch 69; iter: 0; batch classifier loss: 0.464562; batch adversarial loss: 0.544573\n",
      "epoch 70; iter: 0; batch classifier loss: 0.439238; batch adversarial loss: 0.588010\n",
      "epoch 71; iter: 0; batch classifier loss: 0.509283; batch adversarial loss: 0.484411\n",
      "epoch 72; iter: 0; batch classifier loss: 0.334537; batch adversarial loss: 0.579510\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398037; batch adversarial loss: 0.588226\n",
      "epoch 74; iter: 0; batch classifier loss: 0.450240; batch adversarial loss: 0.605734\n",
      "epoch 75; iter: 0; batch classifier loss: 0.351453; batch adversarial loss: 0.510338\n",
      "epoch 76; iter: 0; batch classifier loss: 0.351156; batch adversarial loss: 0.640474\n",
      "epoch 77; iter: 0; batch classifier loss: 0.481375; batch adversarial loss: 0.553435\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369591; batch adversarial loss: 0.597007\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406070; batch adversarial loss: 0.588247\n",
      "epoch 80; iter: 0; batch classifier loss: 0.440647; batch adversarial loss: 0.631771\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386434; batch adversarial loss: 0.492632\n",
      "epoch 82; iter: 0; batch classifier loss: 0.448413; batch adversarial loss: 0.562482\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369054; batch adversarial loss: 0.579798\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412321; batch adversarial loss: 0.510554\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382525; batch adversarial loss: 0.545094\n",
      "epoch 86; iter: 0; batch classifier loss: 0.347871; batch adversarial loss: 0.596572\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378446; batch adversarial loss: 0.596852\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358211; batch adversarial loss: 0.510396\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353335; batch adversarial loss: 0.518801\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407952; batch adversarial loss: 0.501657\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397495; batch adversarial loss: 0.527974\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383363; batch adversarial loss: 0.518391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403884; batch adversarial loss: 0.597296\n",
      "epoch 94; iter: 0; batch classifier loss: 0.426277; batch adversarial loss: 0.492259\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382886; batch adversarial loss: 0.570627\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414582; batch adversarial loss: 0.545214\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355431; batch adversarial loss: 0.622441\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372231; batch adversarial loss: 0.562240\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361638; batch adversarial loss: 0.518874\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390606; batch adversarial loss: 0.570364\n",
      "epoch 101; iter: 0; batch classifier loss: 0.325253; batch adversarial loss: 0.510659\n",
      "epoch 102; iter: 0; batch classifier loss: 0.449352; batch adversarial loss: 0.579900\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426044; batch adversarial loss: 0.588130\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397107; batch adversarial loss: 0.606087\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365341; batch adversarial loss: 0.535988\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379238; batch adversarial loss: 0.528266\n",
      "epoch 107; iter: 0; batch classifier loss: 0.301265; batch adversarial loss: 0.570401\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390468; batch adversarial loss: 0.570936\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356612; batch adversarial loss: 0.501797\n",
      "epoch 110; iter: 0; batch classifier loss: 0.459710; batch adversarial loss: 0.484976\n",
      "epoch 111; iter: 0; batch classifier loss: 0.370897; batch adversarial loss: 0.588056\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403691; batch adversarial loss: 0.571130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340602; batch adversarial loss: 0.510499\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345460; batch adversarial loss: 0.527701\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354954; batch adversarial loss: 0.545035\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357568; batch adversarial loss: 0.536434\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357858; batch adversarial loss: 0.552932\n",
      "epoch 118; iter: 0; batch classifier loss: 0.417394; batch adversarial loss: 0.536474\n",
      "epoch 119; iter: 0; batch classifier loss: 0.453037; batch adversarial loss: 0.552580\n",
      "epoch 120; iter: 0; batch classifier loss: 0.313911; batch adversarial loss: 0.596396\n",
      "epoch 121; iter: 0; batch classifier loss: 0.431391; batch adversarial loss: 0.526592\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371942; batch adversarial loss: 0.528222\n",
      "epoch 123; iter: 0; batch classifier loss: 0.391311; batch adversarial loss: 0.605404\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387092; batch adversarial loss: 0.597681\n",
      "epoch 125; iter: 0; batch classifier loss: 0.325910; batch adversarial loss: 0.587924\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438865; batch adversarial loss: 0.528300\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382662; batch adversarial loss: 0.579062\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364122; batch adversarial loss: 0.543820\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394213; batch adversarial loss: 0.570365\n",
      "epoch 130; iter: 0; batch classifier loss: 0.388089; batch adversarial loss: 0.570452\n",
      "epoch 131; iter: 0; batch classifier loss: 0.341942; batch adversarial loss: 0.535683\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312796; batch adversarial loss: 0.535230\n",
      "epoch 133; iter: 0; batch classifier loss: 0.297370; batch adversarial loss: 0.544330\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352642; batch adversarial loss: 0.579008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.313328; batch adversarial loss: 0.535844\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375069; batch adversarial loss: 0.579607\n",
      "epoch 137; iter: 0; batch classifier loss: 0.326343; batch adversarial loss: 0.622662\n",
      "epoch 138; iter: 0; batch classifier loss: 0.385523; batch adversarial loss: 0.588555\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374757; batch adversarial loss: 0.571071\n",
      "epoch 140; iter: 0; batch classifier loss: 0.416631; batch adversarial loss: 0.528213\n",
      "epoch 141; iter: 0; batch classifier loss: 0.315658; batch adversarial loss: 0.510264\n",
      "epoch 142; iter: 0; batch classifier loss: 0.288192; batch adversarial loss: 0.588928\n",
      "epoch 143; iter: 0; batch classifier loss: 0.277107; batch adversarial loss: 0.623261\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415302; batch adversarial loss: 0.511214\n",
      "epoch 145; iter: 0; batch classifier loss: 0.411775; batch adversarial loss: 0.596804\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363998; batch adversarial loss: 0.545801\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373916; batch adversarial loss: 0.536732\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375181; batch adversarial loss: 0.517821\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334376; batch adversarial loss: 0.623571\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376954; batch adversarial loss: 0.553620\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323661; batch adversarial loss: 0.553904\n",
      "epoch 152; iter: 0; batch classifier loss: 0.410586; batch adversarial loss: 0.597547\n",
      "epoch 153; iter: 0; batch classifier loss: 0.272320; batch adversarial loss: 0.597042\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404305; batch adversarial loss: 0.527332\n",
      "epoch 155; iter: 0; batch classifier loss: 0.409407; batch adversarial loss: 0.587629\n",
      "epoch 156; iter: 0; batch classifier loss: 0.347905; batch adversarial loss: 0.544903\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378200; batch adversarial loss: 0.492903\n",
      "epoch 158; iter: 0; batch classifier loss: 0.316307; batch adversarial loss: 0.570590\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407862; batch adversarial loss: 0.553507\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378023; batch adversarial loss: 0.528140\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362391; batch adversarial loss: 0.640734\n",
      "epoch 162; iter: 0; batch classifier loss: 0.307766; batch adversarial loss: 0.579021\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311620; batch adversarial loss: 0.519483\n",
      "epoch 164; iter: 0; batch classifier loss: 0.404677; batch adversarial loss: 0.483358\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342638; batch adversarial loss: 0.518582\n",
      "epoch 166; iter: 0; batch classifier loss: 0.418041; batch adversarial loss: 0.605613\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384947; batch adversarial loss: 0.510700\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369445; batch adversarial loss: 0.466560\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344551; batch adversarial loss: 0.563185\n",
      "epoch 170; iter: 0; batch classifier loss: 0.340901; batch adversarial loss: 0.476029\n",
      "epoch 171; iter: 0; batch classifier loss: 0.335181; batch adversarial loss: 0.501847\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377608; batch adversarial loss: 0.587604\n",
      "epoch 173; iter: 0; batch classifier loss: 0.366780; batch adversarial loss: 0.623310\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344902; batch adversarial loss: 0.509663\n",
      "epoch 175; iter: 0; batch classifier loss: 0.425802; batch adversarial loss: 0.579453\n",
      "epoch 176; iter: 0; batch classifier loss: 0.362698; batch adversarial loss: 0.579436\n",
      "epoch 177; iter: 0; batch classifier loss: 0.393197; batch adversarial loss: 0.518855\n",
      "epoch 178; iter: 0; batch classifier loss: 0.392312; batch adversarial loss: 0.649105\n",
      "epoch 179; iter: 0; batch classifier loss: 0.392444; batch adversarial loss: 0.580045\n",
      "epoch 180; iter: 0; batch classifier loss: 0.431455; batch adversarial loss: 0.510517\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377903; batch adversarial loss: 0.535138\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382955; batch adversarial loss: 0.596605\n",
      "epoch 183; iter: 0; batch classifier loss: 0.326879; batch adversarial loss: 0.527082\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358162; batch adversarial loss: 0.623583\n",
      "epoch 185; iter: 0; batch classifier loss: 0.385839; batch adversarial loss: 0.560783\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392069; batch adversarial loss: 0.554358\n",
      "epoch 187; iter: 0; batch classifier loss: 0.309289; batch adversarial loss: 0.545470\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347019; batch adversarial loss: 0.536292\n",
      "epoch 189; iter: 0; batch classifier loss: 0.423635; batch adversarial loss: 0.615475\n",
      "epoch 190; iter: 0; batch classifier loss: 0.435674; batch adversarial loss: 0.604501\n",
      "epoch 191; iter: 0; batch classifier loss: 0.273741; batch adversarial loss: 0.562426\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389084; batch adversarial loss: 0.588982\n",
      "epoch 193; iter: 0; batch classifier loss: 0.228890; batch adversarial loss: 0.614601\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378641; batch adversarial loss: 0.424007\n",
      "epoch 195; iter: 0; batch classifier loss: 0.420431; batch adversarial loss: 0.544541\n",
      "epoch 196; iter: 0; batch classifier loss: 0.388025; batch adversarial loss: 0.579460\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385321; batch adversarial loss: 0.544024\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389928; batch adversarial loss: 0.552519\n",
      "epoch 199; iter: 0; batch classifier loss: 0.325113; batch adversarial loss: 0.518580\n",
      "epoch 0; iter: 0; batch classifier loss: 0.769282; batch adversarial loss: 0.936166\n",
      "epoch 1; iter: 0; batch classifier loss: 0.866172; batch adversarial loss: 1.005325\n",
      "epoch 2; iter: 0; batch classifier loss: 0.940676; batch adversarial loss: 0.953736\n",
      "epoch 3; iter: 0; batch classifier loss: 0.971348; batch adversarial loss: 0.882074\n",
      "epoch 4; iter: 0; batch classifier loss: 0.953546; batch adversarial loss: 0.818955\n",
      "epoch 5; iter: 0; batch classifier loss: 0.926904; batch adversarial loss: 0.780228\n",
      "epoch 6; iter: 0; batch classifier loss: 0.787237; batch adversarial loss: 0.694405\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624246; batch adversarial loss: 0.640658\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611367; batch adversarial loss: 0.602927\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545702; batch adversarial loss: 0.657888\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507042; batch adversarial loss: 0.613069\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512773; batch adversarial loss: 0.637417\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512302; batch adversarial loss: 0.621186\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518495; batch adversarial loss: 0.586884\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578756; batch adversarial loss: 0.648929\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553402; batch adversarial loss: 0.588991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518228; batch adversarial loss: 0.562966\n",
      "epoch 17; iter: 0; batch classifier loss: 0.593211; batch adversarial loss: 0.545372\n",
      "epoch 18; iter: 0; batch classifier loss: 0.480148; batch adversarial loss: 0.564731\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509442; batch adversarial loss: 0.564215\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471228; batch adversarial loss: 0.565651\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462449; batch adversarial loss: 0.559013\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530217; batch adversarial loss: 0.522716\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506546; batch adversarial loss: 0.559218\n",
      "epoch 24; iter: 0; batch classifier loss: 0.471171; batch adversarial loss: 0.561184\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442716; batch adversarial loss: 0.505619\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511957; batch adversarial loss: 0.531772\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477991; batch adversarial loss: 0.528197\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457845; batch adversarial loss: 0.563503\n",
      "epoch 29; iter: 0; batch classifier loss: 0.544087; batch adversarial loss: 0.575913\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508005; batch adversarial loss: 0.643363\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523087; batch adversarial loss: 0.559623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.484875; batch adversarial loss: 0.671459\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472075; batch adversarial loss: 0.606883\n",
      "epoch 34; iter: 0; batch classifier loss: 0.573490; batch adversarial loss: 0.560318\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481009; batch adversarial loss: 0.603164\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402855; batch adversarial loss: 0.600559\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460080; batch adversarial loss: 0.523061\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472789; batch adversarial loss: 0.546788\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411104; batch adversarial loss: 0.483409\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453877; batch adversarial loss: 0.511584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413883; batch adversarial loss: 0.547775\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456891; batch adversarial loss: 0.597904\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377005; batch adversarial loss: 0.554005\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441770; batch adversarial loss: 0.458636\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441448; batch adversarial loss: 0.535677\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448161; batch adversarial loss: 0.617895\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467470; batch adversarial loss: 0.514423\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388852; batch adversarial loss: 0.527456\n",
      "epoch 49; iter: 0; batch classifier loss: 0.496498; batch adversarial loss: 0.519768\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391569; batch adversarial loss: 0.568954\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421996; batch adversarial loss: 0.518932\n",
      "epoch 52; iter: 0; batch classifier loss: 0.366819; batch adversarial loss: 0.457735\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383880; batch adversarial loss: 0.630544\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451901; batch adversarial loss: 0.606601\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450658; batch adversarial loss: 0.569391\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398436; batch adversarial loss: 0.554960\n",
      "epoch 57; iter: 0; batch classifier loss: 0.470824; batch adversarial loss: 0.406307\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384272; batch adversarial loss: 0.526667\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433413; batch adversarial loss: 0.571590\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441405; batch adversarial loss: 0.545835\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404484; batch adversarial loss: 0.624454\n",
      "epoch 62; iter: 0; batch classifier loss: 0.369623; batch adversarial loss: 0.597084\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390015; batch adversarial loss: 0.545196\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365291; batch adversarial loss: 0.570315\n",
      "epoch 65; iter: 0; batch classifier loss: 0.404008; batch adversarial loss: 0.518992\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408616; batch adversarial loss: 0.597374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440126; batch adversarial loss: 0.535999\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403924; batch adversarial loss: 0.527806\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406103; batch adversarial loss: 0.544204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433158; batch adversarial loss: 0.537523\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377660; batch adversarial loss: 0.519940\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433463; batch adversarial loss: 0.544482\n",
      "epoch 73; iter: 0; batch classifier loss: 0.443436; batch adversarial loss: 0.596137\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372590; batch adversarial loss: 0.546390\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393329; batch adversarial loss: 0.571585\n",
      "epoch 76; iter: 0; batch classifier loss: 0.303458; batch adversarial loss: 0.535145\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404317; batch adversarial loss: 0.536525\n",
      "epoch 78; iter: 0; batch classifier loss: 0.385386; batch adversarial loss: 0.526341\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396305; batch adversarial loss: 0.640435\n",
      "epoch 80; iter: 0; batch classifier loss: 0.428010; batch adversarial loss: 0.597200\n",
      "epoch 81; iter: 0; batch classifier loss: 0.336441; batch adversarial loss: 0.572721\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389574; batch adversarial loss: 0.572156\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411052; batch adversarial loss: 0.503430\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354269; batch adversarial loss: 0.617288\n",
      "epoch 85; iter: 0; batch classifier loss: 0.384427; batch adversarial loss: 0.571320\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370158; batch adversarial loss: 0.554030\n",
      "epoch 87; iter: 0; batch classifier loss: 0.327347; batch adversarial loss: 0.590161\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358820; batch adversarial loss: 0.561597\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379336; batch adversarial loss: 0.624554\n",
      "epoch 90; iter: 0; batch classifier loss: 0.447011; batch adversarial loss: 0.508668\n",
      "epoch 91; iter: 0; batch classifier loss: 0.315880; batch adversarial loss: 0.535919\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425983; batch adversarial loss: 0.551120\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404607; batch adversarial loss: 0.526470\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419637; batch adversarial loss: 0.552942\n",
      "epoch 95; iter: 0; batch classifier loss: 0.455388; batch adversarial loss: 0.546258\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419798; batch adversarial loss: 0.640125\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394126; batch adversarial loss: 0.571463\n",
      "epoch 98; iter: 0; batch classifier loss: 0.430882; batch adversarial loss: 0.589708\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367959; batch adversarial loss: 0.563226\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346991; batch adversarial loss: 0.563633\n",
      "epoch 101; iter: 0; batch classifier loss: 0.315822; batch adversarial loss: 0.509373\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385803; batch adversarial loss: 0.622720\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353984; batch adversarial loss: 0.528176\n",
      "epoch 104; iter: 0; batch classifier loss: 0.329451; batch adversarial loss: 0.554497\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416716; batch adversarial loss: 0.529203\n",
      "epoch 106; iter: 0; batch classifier loss: 0.445921; batch adversarial loss: 0.580392\n",
      "epoch 107; iter: 0; batch classifier loss: 0.475560; batch adversarial loss: 0.527079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364115; batch adversarial loss: 0.589463\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360156; batch adversarial loss: 0.573273\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395842; batch adversarial loss: 0.499403\n",
      "epoch 111; iter: 0; batch classifier loss: 0.287744; batch adversarial loss: 0.552959\n",
      "epoch 112; iter: 0; batch classifier loss: 0.342027; batch adversarial loss: 0.519223\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374009; batch adversarial loss: 0.597504\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377194; batch adversarial loss: 0.599422\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412995; batch adversarial loss: 0.606709\n",
      "epoch 116; iter: 0; batch classifier loss: 0.338813; batch adversarial loss: 0.519098\n",
      "epoch 117; iter: 0; batch classifier loss: 0.274403; batch adversarial loss: 0.517811\n",
      "epoch 118; iter: 0; batch classifier loss: 0.339231; batch adversarial loss: 0.560098\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379438; batch adversarial loss: 0.561704\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377260; batch adversarial loss: 0.501774\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353053; batch adversarial loss: 0.569070\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350944; batch adversarial loss: 0.587825\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343146; batch adversarial loss: 0.560999\n",
      "epoch 124; iter: 0; batch classifier loss: 0.409366; batch adversarial loss: 0.518923\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330845; batch adversarial loss: 0.588014\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344949; batch adversarial loss: 0.525884\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367264; batch adversarial loss: 0.563126\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360384; batch adversarial loss: 0.526788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.393518; batch adversarial loss: 0.647428\n",
      "epoch 130; iter: 0; batch classifier loss: 0.324979; batch adversarial loss: 0.544373\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380509; batch adversarial loss: 0.492186\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402156; batch adversarial loss: 0.620962\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350928; batch adversarial loss: 0.492629\n",
      "epoch 134; iter: 0; batch classifier loss: 0.313079; batch adversarial loss: 0.560558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.396769; batch adversarial loss: 0.534783\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370196; batch adversarial loss: 0.571351\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350755; batch adversarial loss: 0.529170\n",
      "epoch 138; iter: 0; batch classifier loss: 0.441051; batch adversarial loss: 0.544937\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358978; batch adversarial loss: 0.554903\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329323; batch adversarial loss: 0.630998\n",
      "epoch 141; iter: 0; batch classifier loss: 0.296889; batch adversarial loss: 0.492315\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374128; batch adversarial loss: 0.536492\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386105; batch adversarial loss: 0.483860\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374165; batch adversarial loss: 0.546318\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376886; batch adversarial loss: 0.552188\n",
      "epoch 146; iter: 0; batch classifier loss: 0.321314; batch adversarial loss: 0.510076\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343509; batch adversarial loss: 0.546010\n",
      "epoch 148; iter: 0; batch classifier loss: 0.305328; batch adversarial loss: 0.596778\n",
      "epoch 149; iter: 0; batch classifier loss: 0.453603; batch adversarial loss: 0.483956\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356959; batch adversarial loss: 0.615575\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323991; batch adversarial loss: 0.562294\n",
      "epoch 152; iter: 0; batch classifier loss: 0.390382; batch adversarial loss: 0.554424\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321156; batch adversarial loss: 0.519932\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384635; batch adversarial loss: 0.527049\n",
      "epoch 155; iter: 0; batch classifier loss: 0.321391; batch adversarial loss: 0.537896\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329604; batch adversarial loss: 0.554656\n",
      "epoch 157; iter: 0; batch classifier loss: 0.347431; batch adversarial loss: 0.585816\n",
      "epoch 158; iter: 0; batch classifier loss: 0.335689; batch adversarial loss: 0.536168\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389637; batch adversarial loss: 0.534732\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372571; batch adversarial loss: 0.656790\n",
      "epoch 161; iter: 0; batch classifier loss: 0.432837; batch adversarial loss: 0.518559\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376743; batch adversarial loss: 0.623671\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344645; batch adversarial loss: 0.553497\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392400; batch adversarial loss: 0.489888\n",
      "epoch 165; iter: 0; batch classifier loss: 0.419679; batch adversarial loss: 0.596682\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336055; batch adversarial loss: 0.545788\n",
      "epoch 167; iter: 0; batch classifier loss: 0.304923; batch adversarial loss: 0.597921\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347105; batch adversarial loss: 0.571673\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332989; batch adversarial loss: 0.659344\n",
      "epoch 170; iter: 0; batch classifier loss: 0.350436; batch adversarial loss: 0.590778\n",
      "epoch 171; iter: 0; batch classifier loss: 0.387792; batch adversarial loss: 0.535907\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361390; batch adversarial loss: 0.549862\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380938; batch adversarial loss: 0.526987\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347669; batch adversarial loss: 0.525743\n",
      "epoch 175; iter: 0; batch classifier loss: 0.340148; batch adversarial loss: 0.571171\n",
      "epoch 176; iter: 0; batch classifier loss: 0.412403; batch adversarial loss: 0.545784\n",
      "epoch 177; iter: 0; batch classifier loss: 0.279953; batch adversarial loss: 0.465602\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370965; batch adversarial loss: 0.615325\n",
      "epoch 179; iter: 0; batch classifier loss: 0.300874; batch adversarial loss: 0.519406\n",
      "epoch 180; iter: 0; batch classifier loss: 0.298816; batch adversarial loss: 0.552561\n",
      "epoch 181; iter: 0; batch classifier loss: 0.450042; batch adversarial loss: 0.537477\n",
      "epoch 182; iter: 0; batch classifier loss: 0.328486; batch adversarial loss: 0.568826\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343622; batch adversarial loss: 0.511912\n",
      "epoch 184; iter: 0; batch classifier loss: 0.300523; batch adversarial loss: 0.573487\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320617; batch adversarial loss: 0.561784\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380907; batch adversarial loss: 0.589788\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385239; batch adversarial loss: 0.640925\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343583; batch adversarial loss: 0.489214\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339574; batch adversarial loss: 0.520124\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332465; batch adversarial loss: 0.481732\n",
      "epoch 191; iter: 0; batch classifier loss: 0.294936; batch adversarial loss: 0.525816\n",
      "epoch 192; iter: 0; batch classifier loss: 0.279633; batch adversarial loss: 0.537270\n",
      "epoch 193; iter: 0; batch classifier loss: 0.406660; batch adversarial loss: 0.597684\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361818; batch adversarial loss: 0.569640\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340333; batch adversarial loss: 0.572770\n",
      "epoch 196; iter: 0; batch classifier loss: 0.397667; batch adversarial loss: 0.608364\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370280; batch adversarial loss: 0.605165\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317213; batch adversarial loss: 0.571778\n",
      "epoch 199; iter: 0; batch classifier loss: 0.327813; batch adversarial loss: 0.520939\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770987; batch adversarial loss: 1.059802\n",
      "epoch 1; iter: 0; batch classifier loss: 0.872711; batch adversarial loss: 1.103217\n",
      "epoch 2; iter: 0; batch classifier loss: 0.865782; batch adversarial loss: 1.033580\n",
      "epoch 3; iter: 0; batch classifier loss: 1.201836; batch adversarial loss: 1.097062\n",
      "epoch 4; iter: 0; batch classifier loss: 0.944915; batch adversarial loss: 0.902055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.940921; batch adversarial loss: 0.875065\n",
      "epoch 6; iter: 0; batch classifier loss: 0.755658; batch adversarial loss: 0.748559\n",
      "epoch 7; iter: 0; batch classifier loss: 0.780783; batch adversarial loss: 0.790577\n",
      "epoch 8; iter: 0; batch classifier loss: 0.699933; batch adversarial loss: 0.720691\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604908; batch adversarial loss: 0.677780\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575722; batch adversarial loss: 0.580786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570969; batch adversarial loss: 0.634176\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560371; batch adversarial loss: 0.547543\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549031; batch adversarial loss: 0.591873\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521774; batch adversarial loss: 0.608268\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490902; batch adversarial loss: 0.530331\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483356; batch adversarial loss: 0.634687\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547499; batch adversarial loss: 0.622362\n",
      "epoch 18; iter: 0; batch classifier loss: 0.571297; batch adversarial loss: 0.536028\n",
      "epoch 19; iter: 0; batch classifier loss: 0.584108; batch adversarial loss: 0.557859\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451859; batch adversarial loss: 0.548589\n",
      "epoch 21; iter: 0; batch classifier loss: 0.483917; batch adversarial loss: 0.565977\n",
      "epoch 22; iter: 0; batch classifier loss: 0.379173; batch adversarial loss: 0.641112\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526385; batch adversarial loss: 0.596115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.546956; batch adversarial loss: 0.643512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494495; batch adversarial loss: 0.570531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.430572; batch adversarial loss: 0.575143\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506578; batch adversarial loss: 0.516213\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510277; batch adversarial loss: 0.519180\n",
      "epoch 29; iter: 0; batch classifier loss: 0.519295; batch adversarial loss: 0.557454\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425669; batch adversarial loss: 0.495551\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467506; batch adversarial loss: 0.534647\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430535; batch adversarial loss: 0.531348\n",
      "epoch 33; iter: 0; batch classifier loss: 0.532391; batch adversarial loss: 0.531709\n",
      "epoch 34; iter: 0; batch classifier loss: 0.490593; batch adversarial loss: 0.530577\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430333; batch adversarial loss: 0.632385\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480665; batch adversarial loss: 0.496187\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443979; batch adversarial loss: 0.475504\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447092; batch adversarial loss: 0.604231\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438298; batch adversarial loss: 0.541963\n",
      "epoch 40; iter: 0; batch classifier loss: 0.366411; batch adversarial loss: 0.458342\n",
      "epoch 41; iter: 0; batch classifier loss: 0.371778; batch adversarial loss: 0.559096\n",
      "epoch 42; iter: 0; batch classifier loss: 0.535715; batch adversarial loss: 0.554501\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415243; batch adversarial loss: 0.527441\n",
      "epoch 44; iter: 0; batch classifier loss: 0.528896; batch adversarial loss: 0.535609\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417012; batch adversarial loss: 0.598091\n",
      "epoch 46; iter: 0; batch classifier loss: 0.456258; batch adversarial loss: 0.641102\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436046; batch adversarial loss: 0.573261\n",
      "epoch 48; iter: 0; batch classifier loss: 0.458947; batch adversarial loss: 0.569139\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461895; batch adversarial loss: 0.544653\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393224; batch adversarial loss: 0.565464\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464304; batch adversarial loss: 0.537674\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400922; batch adversarial loss: 0.566639\n",
      "epoch 53; iter: 0; batch classifier loss: 0.438882; batch adversarial loss: 0.494467\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454236; batch adversarial loss: 0.456137\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420294; batch adversarial loss: 0.518020\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433376; batch adversarial loss: 0.586344\n",
      "epoch 57; iter: 0; batch classifier loss: 0.486164; batch adversarial loss: 0.524001\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409824; batch adversarial loss: 0.564900\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422740; batch adversarial loss: 0.572003\n",
      "epoch 60; iter: 0; batch classifier loss: 0.372235; batch adversarial loss: 0.493024\n",
      "epoch 61; iter: 0; batch classifier loss: 0.482275; batch adversarial loss: 0.495072\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409199; batch adversarial loss: 0.592175\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447362; batch adversarial loss: 0.571288\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436763; batch adversarial loss: 0.599201\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445365; batch adversarial loss: 0.610694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407893; batch adversarial loss: 0.545179\n",
      "epoch 67; iter: 0; batch classifier loss: 0.466621; batch adversarial loss: 0.590554\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421187; batch adversarial loss: 0.552474\n",
      "epoch 69; iter: 0; batch classifier loss: 0.345570; batch adversarial loss: 0.500192\n",
      "epoch 70; iter: 0; batch classifier loss: 0.376303; batch adversarial loss: 0.588686\n",
      "epoch 71; iter: 0; batch classifier loss: 0.350876; batch adversarial loss: 0.616176\n",
      "epoch 72; iter: 0; batch classifier loss: 0.420730; batch adversarial loss: 0.597160\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400561; batch adversarial loss: 0.519046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422755; batch adversarial loss: 0.526415\n",
      "epoch 75; iter: 0; batch classifier loss: 0.465479; batch adversarial loss: 0.544881\n",
      "epoch 76; iter: 0; batch classifier loss: 0.351715; batch adversarial loss: 0.572258\n",
      "epoch 77; iter: 0; batch classifier loss: 0.353055; batch adversarial loss: 0.491250\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406222; batch adversarial loss: 0.580460\n",
      "epoch 79; iter: 0; batch classifier loss: 0.295791; batch adversarial loss: 0.543615\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442759; batch adversarial loss: 0.572435\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374604; batch adversarial loss: 0.607556\n",
      "epoch 82; iter: 0; batch classifier loss: 0.345815; batch adversarial loss: 0.634741\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385511; batch adversarial loss: 0.544093\n",
      "epoch 84; iter: 0; batch classifier loss: 0.344723; batch adversarial loss: 0.633995\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401669; batch adversarial loss: 0.481026\n",
      "epoch 86; iter: 0; batch classifier loss: 0.422427; batch adversarial loss: 0.544785\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452779; batch adversarial loss: 0.525326\n",
      "epoch 88; iter: 0; batch classifier loss: 0.331387; batch adversarial loss: 0.490760\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433569; batch adversarial loss: 0.552082\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430915; batch adversarial loss: 0.634970\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412682; batch adversarial loss: 0.518269\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355616; batch adversarial loss: 0.526500\n",
      "epoch 93; iter: 0; batch classifier loss: 0.318824; batch adversarial loss: 0.527330\n",
      "epoch 94; iter: 0; batch classifier loss: 0.393042; batch adversarial loss: 0.571986\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333664; batch adversarial loss: 0.525890\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416880; batch adversarial loss: 0.527397\n",
      "epoch 97; iter: 0; batch classifier loss: 0.471664; batch adversarial loss: 0.517371\n",
      "epoch 98; iter: 0; batch classifier loss: 0.340232; batch adversarial loss: 0.480514\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360315; batch adversarial loss: 0.535951\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403579; batch adversarial loss: 0.544725\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324322; batch adversarial loss: 0.607124\n",
      "epoch 102; iter: 0; batch classifier loss: 0.303805; batch adversarial loss: 0.508168\n",
      "epoch 103; iter: 0; batch classifier loss: 0.421486; batch adversarial loss: 0.598189\n",
      "epoch 104; iter: 0; batch classifier loss: 0.325618; batch adversarial loss: 0.517130\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396670; batch adversarial loss: 0.499832\n",
      "epoch 106; iter: 0; batch classifier loss: 0.342574; batch adversarial loss: 0.589495\n",
      "epoch 107; iter: 0; batch classifier loss: 0.445492; batch adversarial loss: 0.517332\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404677; batch adversarial loss: 0.501293\n",
      "epoch 109; iter: 0; batch classifier loss: 0.398162; batch adversarial loss: 0.570766\n",
      "epoch 110; iter: 0; batch classifier loss: 0.317104; batch adversarial loss: 0.509271\n",
      "epoch 111; iter: 0; batch classifier loss: 0.428899; batch adversarial loss: 0.607360\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375581; batch adversarial loss: 0.553154\n",
      "epoch 113; iter: 0; batch classifier loss: 0.342693; batch adversarial loss: 0.561658\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378352; batch adversarial loss: 0.499349\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360419; batch adversarial loss: 0.616500\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323412; batch adversarial loss: 0.545076\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358971; batch adversarial loss: 0.508147\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360788; batch adversarial loss: 0.536640\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425057; batch adversarial loss: 0.608761\n",
      "epoch 120; iter: 0; batch classifier loss: 0.334933; batch adversarial loss: 0.491342\n",
      "epoch 121; iter: 0; batch classifier loss: 0.328698; batch adversarial loss: 0.624841\n",
      "epoch 122; iter: 0; batch classifier loss: 0.443895; batch adversarial loss: 0.571281\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385613; batch adversarial loss: 0.625044\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346353; batch adversarial loss: 0.589276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.319106; batch adversarial loss: 0.564022\n",
      "epoch 126; iter: 0; batch classifier loss: 0.440028; batch adversarial loss: 0.573187\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408135; batch adversarial loss: 0.553393\n",
      "epoch 128; iter: 0; batch classifier loss: 0.304302; batch adversarial loss: 0.572677\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372978; batch adversarial loss: 0.560990\n",
      "epoch 130; iter: 0; batch classifier loss: 0.422878; batch adversarial loss: 0.536380\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321485; batch adversarial loss: 0.472516\n",
      "epoch 132; iter: 0; batch classifier loss: 0.476020; batch adversarial loss: 0.571060\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350850; batch adversarial loss: 0.600107\n",
      "epoch 134; iter: 0; batch classifier loss: 0.468090; batch adversarial loss: 0.573776\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400453; batch adversarial loss: 0.544169\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343515; batch adversarial loss: 0.598640\n",
      "epoch 137; iter: 0; batch classifier loss: 0.361401; batch adversarial loss: 0.588510\n",
      "epoch 138; iter: 0; batch classifier loss: 0.306508; batch adversarial loss: 0.606393\n",
      "epoch 139; iter: 0; batch classifier loss: 0.322304; batch adversarial loss: 0.538451\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358047; batch adversarial loss: 0.590515\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322121; batch adversarial loss: 0.580404\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.524765\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386742; batch adversarial loss: 0.536785\n",
      "epoch 144; iter: 0; batch classifier loss: 0.317317; batch adversarial loss: 0.524926\n",
      "epoch 145; iter: 0; batch classifier loss: 0.388574; batch adversarial loss: 0.563489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.303467; batch adversarial loss: 0.561194\n",
      "epoch 147; iter: 0; batch classifier loss: 0.327761; batch adversarial loss: 0.560839\n",
      "epoch 148; iter: 0; batch classifier loss: 0.292066; batch adversarial loss: 0.523975\n",
      "epoch 149; iter: 0; batch classifier loss: 0.282125; batch adversarial loss: 0.632979\n",
      "epoch 150; iter: 0; batch classifier loss: 0.454259; batch adversarial loss: 0.587366\n",
      "epoch 151; iter: 0; batch classifier loss: 0.369127; batch adversarial loss: 0.544152\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351265; batch adversarial loss: 0.543033\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365550; batch adversarial loss: 0.544308\n",
      "epoch 154; iter: 0; batch classifier loss: 0.347150; batch adversarial loss: 0.497212\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349382; batch adversarial loss: 0.481655\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372410; batch adversarial loss: 0.579103\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298886; batch adversarial loss: 0.613373\n",
      "epoch 158; iter: 0; batch classifier loss: 0.297218; batch adversarial loss: 0.537073\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338224; batch adversarial loss: 0.525609\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363453; batch adversarial loss: 0.525918\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335506; batch adversarial loss: 0.588561\n",
      "epoch 162; iter: 0; batch classifier loss: 0.439191; batch adversarial loss: 0.581805\n",
      "epoch 163; iter: 0; batch classifier loss: 0.383203; batch adversarial loss: 0.583095\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362410; batch adversarial loss: 0.545473\n",
      "epoch 165; iter: 0; batch classifier loss: 0.286404; batch adversarial loss: 0.565134\n",
      "epoch 166; iter: 0; batch classifier loss: 0.400659; batch adversarial loss: 0.588391\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367317; batch adversarial loss: 0.651918\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376164; batch adversarial loss: 0.518744\n",
      "epoch 169; iter: 0; batch classifier loss: 0.365557; batch adversarial loss: 0.616532\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345251; batch adversarial loss: 0.569610\n",
      "epoch 171; iter: 0; batch classifier loss: 0.456130; batch adversarial loss: 0.480626\n",
      "epoch 172; iter: 0; batch classifier loss: 0.334813; batch adversarial loss: 0.598125\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324790; batch adversarial loss: 0.634710\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375993; batch adversarial loss: 0.536952\n",
      "epoch 175; iter: 0; batch classifier loss: 0.255661; batch adversarial loss: 0.500879\n",
      "epoch 176; iter: 0; batch classifier loss: 0.282761; batch adversarial loss: 0.526845\n",
      "epoch 177; iter: 0; batch classifier loss: 0.274706; batch adversarial loss: 0.482370\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328767; batch adversarial loss: 0.490335\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395164; batch adversarial loss: 0.535708\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381447; batch adversarial loss: 0.572444\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382364; batch adversarial loss: 0.527697\n",
      "epoch 182; iter: 0; batch classifier loss: 0.361057; batch adversarial loss: 0.515178\n",
      "epoch 183; iter: 0; batch classifier loss: 0.426670; batch adversarial loss: 0.544809\n",
      "epoch 184; iter: 0; batch classifier loss: 0.305219; batch adversarial loss: 0.606154\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390289; batch adversarial loss: 0.562215\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355382; batch adversarial loss: 0.580339\n",
      "epoch 187; iter: 0; batch classifier loss: 0.333439; batch adversarial loss: 0.507388\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385515; batch adversarial loss: 0.461732\n",
      "epoch 189; iter: 0; batch classifier loss: 0.325234; batch adversarial loss: 0.569538\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360123; batch adversarial loss: 0.508098\n",
      "epoch 191; iter: 0; batch classifier loss: 0.261442; batch adversarial loss: 0.526431\n",
      "epoch 192; iter: 0; batch classifier loss: 0.490886; batch adversarial loss: 0.570677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353305; batch adversarial loss: 0.445245\n",
      "epoch 194; iter: 0; batch classifier loss: 0.368496; batch adversarial loss: 0.600052\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358638; batch adversarial loss: 0.509472\n",
      "epoch 196; iter: 0; batch classifier loss: 0.426600; batch adversarial loss: 0.553672\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329867; batch adversarial loss: 0.580020\n",
      "epoch 198; iter: 0; batch classifier loss: 0.313252; batch adversarial loss: 0.578898\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351781; batch adversarial loss: 0.507170\n",
      "epoch 0; iter: 0; batch classifier loss: 0.871900; batch adversarial loss: 0.546335\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626655; batch adversarial loss: 0.680406\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619121; batch adversarial loss: 0.630587\n",
      "epoch 3; iter: 0; batch classifier loss: 0.599335; batch adversarial loss: 0.608197\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562366; batch adversarial loss: 0.671809\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619116; batch adversarial loss: 0.705052\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545191; batch adversarial loss: 0.589242\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614187; batch adversarial loss: 0.715427\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575649; batch adversarial loss: 0.664273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.654585; batch adversarial loss: 0.635526\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518109; batch adversarial loss: 0.651750\n",
      "epoch 11; iter: 0; batch classifier loss: 0.600304; batch adversarial loss: 0.675035\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526258; batch adversarial loss: 0.548698\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546018; batch adversarial loss: 0.550907\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505060; batch adversarial loss: 0.568661\n",
      "epoch 15; iter: 0; batch classifier loss: 0.460356; batch adversarial loss: 0.579142\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513881; batch adversarial loss: 0.528317\n",
      "epoch 17; iter: 0; batch classifier loss: 0.610309; batch adversarial loss: 0.557608\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477250; batch adversarial loss: 0.558298\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519848; batch adversarial loss: 0.516121\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489567; batch adversarial loss: 0.647418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.516901; batch adversarial loss: 0.579659\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516096; batch adversarial loss: 0.536678\n",
      "epoch 23; iter: 0; batch classifier loss: 0.572568; batch adversarial loss: 0.543334\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434081; batch adversarial loss: 0.503892\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527181; batch adversarial loss: 0.614649\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456686; batch adversarial loss: 0.531834\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491065; batch adversarial loss: 0.480228\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440790; batch adversarial loss: 0.513094\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455385; batch adversarial loss: 0.521083\n",
      "epoch 30; iter: 0; batch classifier loss: 0.469003; batch adversarial loss: 0.441477\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491249; batch adversarial loss: 0.583480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513257; batch adversarial loss: 0.547996\n",
      "epoch 33; iter: 0; batch classifier loss: 0.552962; batch adversarial loss: 0.633110\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492300; batch adversarial loss: 0.483193\n",
      "epoch 35; iter: 0; batch classifier loss: 0.528931; batch adversarial loss: 0.624169\n",
      "epoch 36; iter: 0; batch classifier loss: 0.531546; batch adversarial loss: 0.642255\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472186; batch adversarial loss: 0.517922\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475022; batch adversarial loss: 0.607629\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474920; batch adversarial loss: 0.553709\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472386; batch adversarial loss: 0.517024\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419369; batch adversarial loss: 0.544375\n",
      "epoch 42; iter: 0; batch classifier loss: 0.512944; batch adversarial loss: 0.507170\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378013; batch adversarial loss: 0.470649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.482220; batch adversarial loss: 0.526302\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481133; batch adversarial loss: 0.579863\n",
      "epoch 46; iter: 0; batch classifier loss: 0.478648; batch adversarial loss: 0.476924\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434786; batch adversarial loss: 0.591879\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482821; batch adversarial loss: 0.571101\n",
      "epoch 49; iter: 0; batch classifier loss: 0.362940; batch adversarial loss: 0.534610\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503668; batch adversarial loss: 0.497712\n",
      "epoch 51; iter: 0; batch classifier loss: 0.451208; batch adversarial loss: 0.550788\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446129; batch adversarial loss: 0.515115\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425727; batch adversarial loss: 0.553874\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463476; batch adversarial loss: 0.589638\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427223; batch adversarial loss: 0.545130\n",
      "epoch 56; iter: 0; batch classifier loss: 0.483842; batch adversarial loss: 0.559031\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438690; batch adversarial loss: 0.598966\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402436; batch adversarial loss: 0.546020\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445659; batch adversarial loss: 0.600741\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455017; batch adversarial loss: 0.527004\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463531; batch adversarial loss: 0.537148\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451269; batch adversarial loss: 0.544948\n",
      "epoch 63; iter: 0; batch classifier loss: 0.530953; batch adversarial loss: 0.553517\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369919; batch adversarial loss: 0.615685\n",
      "epoch 65; iter: 0; batch classifier loss: 0.499304; batch adversarial loss: 0.526984\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457635; batch adversarial loss: 0.517891\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437750; batch adversarial loss: 0.517332\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420944; batch adversarial loss: 0.526339\n",
      "epoch 69; iter: 0; batch classifier loss: 0.394182; batch adversarial loss: 0.553578\n",
      "epoch 70; iter: 0; batch classifier loss: 0.495565; batch adversarial loss: 0.498720\n",
      "epoch 71; iter: 0; batch classifier loss: 0.458879; batch adversarial loss: 0.507869\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435501; batch adversarial loss: 0.571380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376847; batch adversarial loss: 0.628158\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404730; batch adversarial loss: 0.523967\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436186; batch adversarial loss: 0.590995\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468057; batch adversarial loss: 0.536689\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398690; batch adversarial loss: 0.572299\n",
      "epoch 78; iter: 0; batch classifier loss: 0.446684; batch adversarial loss: 0.544587\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388583; batch adversarial loss: 0.544617\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347357; batch adversarial loss: 0.535613\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388958; batch adversarial loss: 0.481591\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385959; batch adversarial loss: 0.544693\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388833; batch adversarial loss: 0.571833\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411324; batch adversarial loss: 0.571533\n",
      "epoch 85; iter: 0; batch classifier loss: 0.508816; batch adversarial loss: 0.571664\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369135; batch adversarial loss: 0.500139\n",
      "epoch 87; iter: 0; batch classifier loss: 0.456530; batch adversarial loss: 0.590212\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426896; batch adversarial loss: 0.517117\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408843; batch adversarial loss: 0.562900\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378776; batch adversarial loss: 0.543643\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403501; batch adversarial loss: 0.618864\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385863; batch adversarial loss: 0.553461\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455259; batch adversarial loss: 0.510336\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449910; batch adversarial loss: 0.560908\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431025; batch adversarial loss: 0.534842\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328154; batch adversarial loss: 0.538234\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425290; batch adversarial loss: 0.471604\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.498493\n",
      "epoch 99; iter: 0; batch classifier loss: 0.462382; batch adversarial loss: 0.491027\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404932; batch adversarial loss: 0.593539\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430542; batch adversarial loss: 0.503908\n",
      "epoch 102; iter: 0; batch classifier loss: 0.451228; batch adversarial loss: 0.615960\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381922; batch adversarial loss: 0.569983\n",
      "epoch 104; iter: 0; batch classifier loss: 0.380702; batch adversarial loss: 0.544201\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411055; batch adversarial loss: 0.472691\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395148; batch adversarial loss: 0.580388\n",
      "epoch 107; iter: 0; batch classifier loss: 0.431515; batch adversarial loss: 0.562943\n",
      "epoch 108; iter: 0; batch classifier loss: 0.368476; batch adversarial loss: 0.463116\n",
      "epoch 109; iter: 0; batch classifier loss: 0.341445; batch adversarial loss: 0.571326\n",
      "epoch 110; iter: 0; batch classifier loss: 0.387398; batch adversarial loss: 0.535040\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353184; batch adversarial loss: 0.535473\n",
      "epoch 112; iter: 0; batch classifier loss: 0.519059; batch adversarial loss: 0.480306\n",
      "epoch 113; iter: 0; batch classifier loss: 0.412065; batch adversarial loss: 0.581276\n",
      "epoch 114; iter: 0; batch classifier loss: 0.461493; batch adversarial loss: 0.517777\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344373; batch adversarial loss: 0.562587\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396102; batch adversarial loss: 0.580337\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372892; batch adversarial loss: 0.562224\n",
      "epoch 118; iter: 0; batch classifier loss: 0.428994; batch adversarial loss: 0.526427\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372879; batch adversarial loss: 0.544567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.356229; batch adversarial loss: 0.562364\n",
      "epoch 121; iter: 0; batch classifier loss: 0.404295; batch adversarial loss: 0.552875\n",
      "epoch 122; iter: 0; batch classifier loss: 0.395431; batch adversarial loss: 0.572056\n",
      "epoch 123; iter: 0; batch classifier loss: 0.283088; batch adversarial loss: 0.580826\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345339; batch adversarial loss: 0.572357\n",
      "epoch 125; iter: 0; batch classifier loss: 0.452250; batch adversarial loss: 0.562647\n",
      "epoch 126; iter: 0; batch classifier loss: 0.404369; batch adversarial loss: 0.571785\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376617; batch adversarial loss: 0.562742\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367432; batch adversarial loss: 0.598295\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377625; batch adversarial loss: 0.516753\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393392; batch adversarial loss: 0.534951\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352223; batch adversarial loss: 0.517305\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330130; batch adversarial loss: 0.545417\n",
      "epoch 133; iter: 0; batch classifier loss: 0.429891; batch adversarial loss: 0.517215\n",
      "epoch 134; iter: 0; batch classifier loss: 0.300615; batch adversarial loss: 0.571966\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402517; batch adversarial loss: 0.572199\n",
      "epoch 136; iter: 0; batch classifier loss: 0.419403; batch adversarial loss: 0.535240\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399173; batch adversarial loss: 0.561936\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403310; batch adversarial loss: 0.617903\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390822; batch adversarial loss: 0.636141\n",
      "epoch 140; iter: 0; batch classifier loss: 0.466095; batch adversarial loss: 0.498585\n",
      "epoch 141; iter: 0; batch classifier loss: 0.376314; batch adversarial loss: 0.599595\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354088; batch adversarial loss: 0.480744\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364369; batch adversarial loss: 0.544910\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401926; batch adversarial loss: 0.572043\n",
      "epoch 145; iter: 0; batch classifier loss: 0.342381; batch adversarial loss: 0.626652\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389001; batch adversarial loss: 0.526451\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377797; batch adversarial loss: 0.590530\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327413; batch adversarial loss: 0.506595\n",
      "epoch 149; iter: 0; batch classifier loss: 0.411878; batch adversarial loss: 0.526782\n",
      "epoch 150; iter: 0; batch classifier loss: 0.483475; batch adversarial loss: 0.507059\n",
      "epoch 151; iter: 0; batch classifier loss: 0.357903; batch adversarial loss: 0.526394\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348698; batch adversarial loss: 0.580679\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362965; batch adversarial loss: 0.553216\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351852; batch adversarial loss: 0.462121\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387101; batch adversarial loss: 0.452973\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374462; batch adversarial loss: 0.553853\n",
      "epoch 157; iter: 0; batch classifier loss: 0.468977; batch adversarial loss: 0.516983\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384830; batch adversarial loss: 0.517849\n",
      "epoch 159; iter: 0; batch classifier loss: 0.414055; batch adversarial loss: 0.507983\n",
      "epoch 160; iter: 0; batch classifier loss: 0.442926; batch adversarial loss: 0.608705\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347579; batch adversarial loss: 0.525568\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331900; batch adversarial loss: 0.545125\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326955; batch adversarial loss: 0.571665\n",
      "epoch 164; iter: 0; batch classifier loss: 0.422528; batch adversarial loss: 0.544201\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373682; batch adversarial loss: 0.544884\n",
      "epoch 166; iter: 0; batch classifier loss: 0.417226; batch adversarial loss: 0.544378\n",
      "epoch 167; iter: 0; batch classifier loss: 0.434938; batch adversarial loss: 0.489506\n",
      "epoch 168; iter: 0; batch classifier loss: 0.357234; batch adversarial loss: 0.508475\n",
      "epoch 169; iter: 0; batch classifier loss: 0.428861; batch adversarial loss: 0.518135\n",
      "epoch 170; iter: 0; batch classifier loss: 0.443638; batch adversarial loss: 0.526526\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347713; batch adversarial loss: 0.618583\n",
      "epoch 172; iter: 0; batch classifier loss: 0.383614; batch adversarial loss: 0.425459\n",
      "epoch 173; iter: 0; batch classifier loss: 0.425452; batch adversarial loss: 0.562147\n",
      "epoch 174; iter: 0; batch classifier loss: 0.402196; batch adversarial loss: 0.526357\n",
      "epoch 175; iter: 0; batch classifier loss: 0.440753; batch adversarial loss: 0.543311\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358937; batch adversarial loss: 0.554406\n",
      "epoch 177; iter: 0; batch classifier loss: 0.402878; batch adversarial loss: 0.534879\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390972; batch adversarial loss: 0.536261\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378169; batch adversarial loss: 0.506579\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360664; batch adversarial loss: 0.480349\n",
      "epoch 181; iter: 0; batch classifier loss: 0.381266; batch adversarial loss: 0.535403\n",
      "epoch 182; iter: 0; batch classifier loss: 0.473309; batch adversarial loss: 0.582419\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396328; batch adversarial loss: 0.489751\n",
      "epoch 184; iter: 0; batch classifier loss: 0.428957; batch adversarial loss: 0.490784\n",
      "epoch 185; iter: 0; batch classifier loss: 0.495072; batch adversarial loss: 0.572422\n",
      "epoch 186; iter: 0; batch classifier loss: 0.246593; batch adversarial loss: 0.600384\n",
      "epoch 187; iter: 0; batch classifier loss: 0.453821; batch adversarial loss: 0.571833\n",
      "epoch 188; iter: 0; batch classifier loss: 0.349368; batch adversarial loss: 0.535591\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371349; batch adversarial loss: 0.544617\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361975; batch adversarial loss: 0.562950\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355798; batch adversarial loss: 0.480931\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345852; batch adversarial loss: 0.518772\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390185; batch adversarial loss: 0.489656\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315378; batch adversarial loss: 0.553747\n",
      "epoch 195; iter: 0; batch classifier loss: 0.469156; batch adversarial loss: 0.599413\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320400; batch adversarial loss: 0.562484\n",
      "epoch 197; iter: 0; batch classifier loss: 0.417441; batch adversarial loss: 0.627103\n",
      "epoch 198; iter: 0; batch classifier loss: 0.423928; batch adversarial loss: 0.526320\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356443; batch adversarial loss: 0.563125\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729434; batch adversarial loss: 0.653773\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582908; batch adversarial loss: 0.648510\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575025; batch adversarial loss: 0.641137\n",
      "epoch 3; iter: 0; batch classifier loss: 0.622466; batch adversarial loss: 0.649025\n",
      "epoch 4; iter: 0; batch classifier loss: 0.486207; batch adversarial loss: 0.618476\n",
      "epoch 5; iter: 0; batch classifier loss: 0.625247; batch adversarial loss: 0.634729\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521750; batch adversarial loss: 0.629769\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586073; batch adversarial loss: 0.577758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528996; batch adversarial loss: 0.633606\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601700; batch adversarial loss: 0.593733\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514776; batch adversarial loss: 0.579600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.451739; batch adversarial loss: 0.611742\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521847; batch adversarial loss: 0.583894\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486823; batch adversarial loss: 0.625101\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493535; batch adversarial loss: 0.546285\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509634; batch adversarial loss: 0.565887\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528930; batch adversarial loss: 0.597996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.550205; batch adversarial loss: 0.576478\n",
      "epoch 18; iter: 0; batch classifier loss: 0.400177; batch adversarial loss: 0.529831\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480619; batch adversarial loss: 0.560501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462738; batch adversarial loss: 0.577046\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520573; batch adversarial loss: 0.528087\n",
      "epoch 22; iter: 0; batch classifier loss: 0.554138; batch adversarial loss: 0.504676\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517006; batch adversarial loss: 0.486364\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473548; batch adversarial loss: 0.467837\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467959; batch adversarial loss: 0.587766\n",
      "epoch 26; iter: 0; batch classifier loss: 0.507321; batch adversarial loss: 0.545664\n",
      "epoch 27; iter: 0; batch classifier loss: 0.476148; batch adversarial loss: 0.503937\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490319; batch adversarial loss: 0.587937\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444475; batch adversarial loss: 0.605272\n",
      "epoch 30; iter: 0; batch classifier loss: 0.413797; batch adversarial loss: 0.570988\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417510; batch adversarial loss: 0.492587\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481848; batch adversarial loss: 0.535811\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386338; batch adversarial loss: 0.623765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380497; batch adversarial loss: 0.552092\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440194; batch adversarial loss: 0.534747\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455852; batch adversarial loss: 0.542955\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409977; batch adversarial loss: 0.502312\n",
      "epoch 38; iter: 0; batch classifier loss: 0.372753; batch adversarial loss: 0.543188\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480512; batch adversarial loss: 0.524457\n",
      "epoch 40; iter: 0; batch classifier loss: 0.531122; batch adversarial loss: 0.527768\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481539; batch adversarial loss: 0.527160\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424712; batch adversarial loss: 0.456776\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391100; batch adversarial loss: 0.533536\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422440; batch adversarial loss: 0.563374\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443453; batch adversarial loss: 0.582003\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452959; batch adversarial loss: 0.591533\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490512; batch adversarial loss: 0.541416\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442846; batch adversarial loss: 0.558417\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388462; batch adversarial loss: 0.564290\n",
      "epoch 50; iter: 0; batch classifier loss: 0.367273; batch adversarial loss: 0.505170\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458843; batch adversarial loss: 0.497434\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457382; batch adversarial loss: 0.575241\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399555; batch adversarial loss: 0.563955\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429921; batch adversarial loss: 0.574959\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434830; batch adversarial loss: 0.526126\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444168; batch adversarial loss: 0.591169\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421449; batch adversarial loss: 0.571691\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390547; batch adversarial loss: 0.582420\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399182; batch adversarial loss: 0.509273\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425436; batch adversarial loss: 0.525494\n",
      "epoch 61; iter: 0; batch classifier loss: 0.473787; batch adversarial loss: 0.531238\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432110; batch adversarial loss: 0.468794\n",
      "epoch 63; iter: 0; batch classifier loss: 0.367260; batch adversarial loss: 0.610656\n",
      "epoch 64; iter: 0; batch classifier loss: 0.417151; batch adversarial loss: 0.638819\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420615; batch adversarial loss: 0.443842\n",
      "epoch 66; iter: 0; batch classifier loss: 0.474554; batch adversarial loss: 0.606300\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374471; batch adversarial loss: 0.583569\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397848; batch adversarial loss: 0.528786\n",
      "epoch 69; iter: 0; batch classifier loss: 0.464850; batch adversarial loss: 0.516081\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404516; batch adversarial loss: 0.507829\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392734; batch adversarial loss: 0.546730\n",
      "epoch 72; iter: 0; batch classifier loss: 0.445703; batch adversarial loss: 0.606219\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433862; batch adversarial loss: 0.554699\n",
      "epoch 74; iter: 0; batch classifier loss: 0.373858; batch adversarial loss: 0.554685\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389918; batch adversarial loss: 0.578105\n",
      "epoch 76; iter: 0; batch classifier loss: 0.471427; batch adversarial loss: 0.597921\n",
      "epoch 77; iter: 0; batch classifier loss: 0.428786; batch adversarial loss: 0.546486\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407672; batch adversarial loss: 0.535979\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384351; batch adversarial loss: 0.543363\n",
      "epoch 80; iter: 0; batch classifier loss: 0.414263; batch adversarial loss: 0.570410\n",
      "epoch 81; iter: 0; batch classifier loss: 0.355196; batch adversarial loss: 0.641826\n",
      "epoch 82; iter: 0; batch classifier loss: 0.445098; batch adversarial loss: 0.527738\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364604; batch adversarial loss: 0.526265\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445641; batch adversarial loss: 0.518182\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396015; batch adversarial loss: 0.538816\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425309; batch adversarial loss: 0.602808\n",
      "epoch 87; iter: 0; batch classifier loss: 0.332658; batch adversarial loss: 0.526709\n",
      "epoch 88; iter: 0; batch classifier loss: 0.316246; batch adversarial loss: 0.595896\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371793; batch adversarial loss: 0.573278\n",
      "epoch 90; iter: 0; batch classifier loss: 0.448529; batch adversarial loss: 0.501436\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388318; batch adversarial loss: 0.547925\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360505; batch adversarial loss: 0.620731\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320997; batch adversarial loss: 0.556201\n",
      "epoch 94; iter: 0; batch classifier loss: 0.451747; batch adversarial loss: 0.533766\n",
      "epoch 95; iter: 0; batch classifier loss: 0.327154; batch adversarial loss: 0.488353\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391566; batch adversarial loss: 0.491605\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408553; batch adversarial loss: 0.563685\n",
      "epoch 98; iter: 0; batch classifier loss: 0.321889; batch adversarial loss: 0.651352\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402962; batch adversarial loss: 0.580555\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387128; batch adversarial loss: 0.499036\n",
      "epoch 101; iter: 0; batch classifier loss: 0.494408; batch adversarial loss: 0.569566\n",
      "epoch 102; iter: 0; batch classifier loss: 0.472085; batch adversarial loss: 0.563336\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369414; batch adversarial loss: 0.525721\n",
      "epoch 104; iter: 0; batch classifier loss: 0.372697; batch adversarial loss: 0.556170\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352886; batch adversarial loss: 0.525403\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349632; batch adversarial loss: 0.554640\n",
      "epoch 107; iter: 0; batch classifier loss: 0.435064; batch adversarial loss: 0.570961\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409112; batch adversarial loss: 0.570011\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384329; batch adversarial loss: 0.597950\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386291; batch adversarial loss: 0.513210\n",
      "epoch 111; iter: 0; batch classifier loss: 0.482344; batch adversarial loss: 0.544642\n",
      "epoch 112; iter: 0; batch classifier loss: 0.293595; batch adversarial loss: 0.528740\n",
      "epoch 113; iter: 0; batch classifier loss: 0.433565; batch adversarial loss: 0.532635\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428212; batch adversarial loss: 0.545881\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403566; batch adversarial loss: 0.578318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.392642; batch adversarial loss: 0.600243\n",
      "epoch 117; iter: 0; batch classifier loss: 0.466474; batch adversarial loss: 0.563577\n",
      "epoch 118; iter: 0; batch classifier loss: 0.424648; batch adversarial loss: 0.610152\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388845; batch adversarial loss: 0.560880\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391527; batch adversarial loss: 0.536229\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381173; batch adversarial loss: 0.540492\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391866; batch adversarial loss: 0.581721\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351328; batch adversarial loss: 0.481512\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418568; batch adversarial loss: 0.560826\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403493; batch adversarial loss: 0.596448\n",
      "epoch 126; iter: 0; batch classifier loss: 0.415573; batch adversarial loss: 0.582012\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347372; batch adversarial loss: 0.618400\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365759; batch adversarial loss: 0.525447\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354098; batch adversarial loss: 0.505952\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389058; batch adversarial loss: 0.499674\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385382; batch adversarial loss: 0.506255\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368834; batch adversarial loss: 0.562023\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346224; batch adversarial loss: 0.460267\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402129; batch adversarial loss: 0.538886\n",
      "epoch 135; iter: 0; batch classifier loss: 0.327974; batch adversarial loss: 0.552069\n",
      "epoch 136; iter: 0; batch classifier loss: 0.265202; batch adversarial loss: 0.525355\n",
      "epoch 137; iter: 0; batch classifier loss: 0.397098; batch adversarial loss: 0.623306\n",
      "epoch 138; iter: 0; batch classifier loss: 0.464143; batch adversarial loss: 0.541410\n",
      "epoch 139; iter: 0; batch classifier loss: 0.318648; batch adversarial loss: 0.594032\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373324; batch adversarial loss: 0.588502\n",
      "epoch 141; iter: 0; batch classifier loss: 0.420309; batch adversarial loss: 0.545988\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363229; batch adversarial loss: 0.591948\n",
      "epoch 143; iter: 0; batch classifier loss: 0.416768; batch adversarial loss: 0.528347\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336724; batch adversarial loss: 0.597968\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338394; batch adversarial loss: 0.593344\n",
      "epoch 146; iter: 0; batch classifier loss: 0.438332; batch adversarial loss: 0.526438\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359665; batch adversarial loss: 0.478160\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351556; batch adversarial loss: 0.617732\n",
      "epoch 149; iter: 0; batch classifier loss: 0.318806; batch adversarial loss: 0.535862\n",
      "epoch 150; iter: 0; batch classifier loss: 0.374487; batch adversarial loss: 0.587791\n",
      "epoch 151; iter: 0; batch classifier loss: 0.396151; batch adversarial loss: 0.515577\n",
      "epoch 152; iter: 0; batch classifier loss: 0.313223; batch adversarial loss: 0.553717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.299087; batch adversarial loss: 0.532256\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375913; batch adversarial loss: 0.527628\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342478; batch adversarial loss: 0.627479\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387459; batch adversarial loss: 0.605711\n",
      "epoch 157; iter: 0; batch classifier loss: 0.338125; batch adversarial loss: 0.509834\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375784; batch adversarial loss: 0.573246\n",
      "epoch 159; iter: 0; batch classifier loss: 0.422182; batch adversarial loss: 0.564096\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368514; batch adversarial loss: 0.525681\n",
      "epoch 161; iter: 0; batch classifier loss: 0.421723; batch adversarial loss: 0.478796\n",
      "epoch 162; iter: 0; batch classifier loss: 0.389293; batch adversarial loss: 0.536248\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319350; batch adversarial loss: 0.619179\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340954; batch adversarial loss: 0.596285\n",
      "epoch 165; iter: 0; batch classifier loss: 0.409053; batch adversarial loss: 0.518787\n",
      "epoch 166; iter: 0; batch classifier loss: 0.386834; batch adversarial loss: 0.481845\n",
      "epoch 167; iter: 0; batch classifier loss: 0.399665; batch adversarial loss: 0.580359\n",
      "epoch 168; iter: 0; batch classifier loss: 0.373873; batch adversarial loss: 0.486822\n",
      "epoch 169; iter: 0; batch classifier loss: 0.291161; batch adversarial loss: 0.481849\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341486; batch adversarial loss: 0.634502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.379497; batch adversarial loss: 0.489759\n",
      "epoch 172; iter: 0; batch classifier loss: 0.403490; batch adversarial loss: 0.508628\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357584; batch adversarial loss: 0.582456\n",
      "epoch 174; iter: 0; batch classifier loss: 0.357346; batch adversarial loss: 0.495321\n",
      "epoch 175; iter: 0; batch classifier loss: 0.426573; batch adversarial loss: 0.561996\n",
      "epoch 176; iter: 0; batch classifier loss: 0.355876; batch adversarial loss: 0.572820\n",
      "epoch 177; iter: 0; batch classifier loss: 0.412415; batch adversarial loss: 0.509353\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376941; batch adversarial loss: 0.480262\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365747; batch adversarial loss: 0.564271\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387344; batch adversarial loss: 0.562307\n",
      "epoch 181; iter: 0; batch classifier loss: 0.452954; batch adversarial loss: 0.517618\n",
      "epoch 182; iter: 0; batch classifier loss: 0.301427; batch adversarial loss: 0.589607\n",
      "epoch 183; iter: 0; batch classifier loss: 0.383627; batch adversarial loss: 0.563946\n",
      "epoch 184; iter: 0; batch classifier loss: 0.388159; batch adversarial loss: 0.569004\n",
      "epoch 185; iter: 0; batch classifier loss: 0.410970; batch adversarial loss: 0.486163\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331540; batch adversarial loss: 0.535178\n",
      "epoch 187; iter: 0; batch classifier loss: 0.481431; batch adversarial loss: 0.552182\n",
      "epoch 188; iter: 0; batch classifier loss: 0.354852; batch adversarial loss: 0.546468\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367814; batch adversarial loss: 0.555047\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361280; batch adversarial loss: 0.507976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299343; batch adversarial loss: 0.516797\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352078; batch adversarial loss: 0.555280\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402067; batch adversarial loss: 0.507583\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349260; batch adversarial loss: 0.666522\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371363; batch adversarial loss: 0.545812\n",
      "epoch 196; iter: 0; batch classifier loss: 0.275561; batch adversarial loss: 0.545355\n",
      "epoch 197; iter: 0; batch classifier loss: 0.451639; batch adversarial loss: 0.491115\n",
      "epoch 198; iter: 0; batch classifier loss: 0.299233; batch adversarial loss: 0.512477\n",
      "epoch 199; iter: 0; batch classifier loss: 0.301093; batch adversarial loss: 0.559717\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688528; batch adversarial loss: 0.645133\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565611; batch adversarial loss: 0.637680\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612141; batch adversarial loss: 0.669384\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544421; batch adversarial loss: 0.630314\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598977; batch adversarial loss: 0.643256\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562718; batch adversarial loss: 0.604909\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536831; batch adversarial loss: 0.584284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605614; batch adversarial loss: 0.592828\n",
      "epoch 8; iter: 0; batch classifier loss: 0.606125; batch adversarial loss: 0.559485\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578750; batch adversarial loss: 0.624489\n",
      "epoch 10; iter: 0; batch classifier loss: 0.530043; batch adversarial loss: 0.550317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541963; batch adversarial loss: 0.610302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.585945; batch adversarial loss: 0.593107\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457424; batch adversarial loss: 0.589250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.518399; batch adversarial loss: 0.601591\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482324; batch adversarial loss: 0.568884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537601; batch adversarial loss: 0.578161\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485370; batch adversarial loss: 0.561183\n",
      "epoch 18; iter: 0; batch classifier loss: 0.553938; batch adversarial loss: 0.622038\n",
      "epoch 19; iter: 0; batch classifier loss: 0.571939; batch adversarial loss: 0.581459\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513930; batch adversarial loss: 0.616133\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517716; batch adversarial loss: 0.549340\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457374; batch adversarial loss: 0.572941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489139; batch adversarial loss: 0.612212\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489999; batch adversarial loss: 0.516759\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429268; batch adversarial loss: 0.531322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434238; batch adversarial loss: 0.569497\n",
      "epoch 27; iter: 0; batch classifier loss: 0.426888; batch adversarial loss: 0.538505\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462517; batch adversarial loss: 0.529488\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441113; batch adversarial loss: 0.587614\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433786; batch adversarial loss: 0.563729\n",
      "epoch 31; iter: 0; batch classifier loss: 0.401146; batch adversarial loss: 0.512082\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462014; batch adversarial loss: 0.588117\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466110; batch adversarial loss: 0.585905\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418884; batch adversarial loss: 0.495094\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443666; batch adversarial loss: 0.580669\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488181; batch adversarial loss: 0.544309\n",
      "epoch 37; iter: 0; batch classifier loss: 0.530696; batch adversarial loss: 0.523638\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403592; batch adversarial loss: 0.562594\n",
      "epoch 39; iter: 0; batch classifier loss: 0.495945; batch adversarial loss: 0.526497\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426554; batch adversarial loss: 0.577631\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432273; batch adversarial loss: 0.548302\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419983; batch adversarial loss: 0.606610\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383639; batch adversarial loss: 0.464493\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433024; batch adversarial loss: 0.571287\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413721; batch adversarial loss: 0.630810\n",
      "epoch 46; iter: 0; batch classifier loss: 0.442912; batch adversarial loss: 0.552188\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477564; batch adversarial loss: 0.472911\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401129; batch adversarial loss: 0.568984\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440958; batch adversarial loss: 0.478812\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453179; batch adversarial loss: 0.515788\n",
      "epoch 51; iter: 0; batch classifier loss: 0.419276; batch adversarial loss: 0.515325\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464562; batch adversarial loss: 0.596568\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404988; batch adversarial loss: 0.597422\n",
      "epoch 54; iter: 0; batch classifier loss: 0.528311; batch adversarial loss: 0.605786\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407509; batch adversarial loss: 0.594554\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450620; batch adversarial loss: 0.523460\n",
      "epoch 57; iter: 0; batch classifier loss: 0.348536; batch adversarial loss: 0.537520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.374206; batch adversarial loss: 0.597641\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457016; batch adversarial loss: 0.584120\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381400; batch adversarial loss: 0.605838\n",
      "epoch 61; iter: 0; batch classifier loss: 0.448394; batch adversarial loss: 0.605007\n",
      "epoch 62; iter: 0; batch classifier loss: 0.359010; batch adversarial loss: 0.538918\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385807; batch adversarial loss: 0.554221\n",
      "epoch 64; iter: 0; batch classifier loss: 0.514756; batch adversarial loss: 0.551999\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431324; batch adversarial loss: 0.564620\n",
      "epoch 66; iter: 0; batch classifier loss: 0.372023; batch adversarial loss: 0.556104\n",
      "epoch 67; iter: 0; batch classifier loss: 0.483097; batch adversarial loss: 0.538494\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417965; batch adversarial loss: 0.546288\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382365; batch adversarial loss: 0.552754\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427160; batch adversarial loss: 0.552071\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392004; batch adversarial loss: 0.605070\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395063; batch adversarial loss: 0.587405\n",
      "epoch 73; iter: 0; batch classifier loss: 0.349179; batch adversarial loss: 0.501598\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410327; batch adversarial loss: 0.554563\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375446; batch adversarial loss: 0.483699\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386605; batch adversarial loss: 0.562301\n",
      "epoch 77; iter: 0; batch classifier loss: 0.331316; batch adversarial loss: 0.494125\n",
      "epoch 78; iter: 0; batch classifier loss: 0.459331; batch adversarial loss: 0.519034\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394432; batch adversarial loss: 0.625310\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431240; batch adversarial loss: 0.600029\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445277; batch adversarial loss: 0.534295\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386407; batch adversarial loss: 0.485241\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441875; batch adversarial loss: 0.546369\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360385; batch adversarial loss: 0.592991\n",
      "epoch 85; iter: 0; batch classifier loss: 0.432680; batch adversarial loss: 0.494919\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409938; batch adversarial loss: 0.575678\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357044; batch adversarial loss: 0.579819\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408155; batch adversarial loss: 0.620767\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395904; batch adversarial loss: 0.579558\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411957; batch adversarial loss: 0.545880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382977; batch adversarial loss: 0.654482\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364890; batch adversarial loss: 0.614066\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385625; batch adversarial loss: 0.553183\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363504; batch adversarial loss: 0.587900\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414638; batch adversarial loss: 0.528607\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388783; batch adversarial loss: 0.527914\n",
      "epoch 97; iter: 0; batch classifier loss: 0.412474; batch adversarial loss: 0.518955\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401336; batch adversarial loss: 0.572048\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360755; batch adversarial loss: 0.578767\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421068; batch adversarial loss: 0.509930\n",
      "epoch 101; iter: 0; batch classifier loss: 0.450933; batch adversarial loss: 0.587424\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426050; batch adversarial loss: 0.607605\n",
      "epoch 103; iter: 0; batch classifier loss: 0.447480; batch adversarial loss: 0.562795\n",
      "epoch 104; iter: 0; batch classifier loss: 0.474054; batch adversarial loss: 0.554112\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372214; batch adversarial loss: 0.526165\n",
      "epoch 106; iter: 0; batch classifier loss: 0.292414; batch adversarial loss: 0.639005\n",
      "epoch 107; iter: 0; batch classifier loss: 0.360707; batch adversarial loss: 0.544911\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373010; batch adversarial loss: 0.563179\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400799; batch adversarial loss: 0.630857\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407888; batch adversarial loss: 0.587453\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348601; batch adversarial loss: 0.632274\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359057; batch adversarial loss: 0.683540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.383019; batch adversarial loss: 0.528044\n",
      "epoch 114; iter: 0; batch classifier loss: 0.332382; batch adversarial loss: 0.579296\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391996; batch adversarial loss: 0.536854\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401998; batch adversarial loss: 0.484717\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391068; batch adversarial loss: 0.596728\n",
      "epoch 118; iter: 0; batch classifier loss: 0.336684; batch adversarial loss: 0.562214\n",
      "epoch 119; iter: 0; batch classifier loss: 0.288333; batch adversarial loss: 0.562325\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381464; batch adversarial loss: 0.553494\n",
      "epoch 121; iter: 0; batch classifier loss: 0.405945; batch adversarial loss: 0.519173\n",
      "epoch 122; iter: 0; batch classifier loss: 0.436682; batch adversarial loss: 0.579705\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367448; batch adversarial loss: 0.519347\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334794; batch adversarial loss: 0.501002\n",
      "epoch 125; iter: 0; batch classifier loss: 0.321040; batch adversarial loss: 0.528023\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329578; batch adversarial loss: 0.528166\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360052; batch adversarial loss: 0.501818\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377554; batch adversarial loss: 0.570744\n",
      "epoch 129; iter: 0; batch classifier loss: 0.378577; batch adversarial loss: 0.536499\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346959; batch adversarial loss: 0.579437\n",
      "epoch 131; iter: 0; batch classifier loss: 0.296112; batch adversarial loss: 0.501986\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417207; batch adversarial loss: 0.467507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337317; batch adversarial loss: 0.596334\n",
      "epoch 134; iter: 0; batch classifier loss: 0.353063; batch adversarial loss: 0.518843\n",
      "epoch 135; iter: 0; batch classifier loss: 0.426501; batch adversarial loss: 0.665743\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374698; batch adversarial loss: 0.605401\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372656; batch adversarial loss: 0.545155\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418532; batch adversarial loss: 0.485017\n",
      "epoch 139; iter: 0; batch classifier loss: 0.447075; batch adversarial loss: 0.579259\n",
      "epoch 140; iter: 0; batch classifier loss: 0.529772; batch adversarial loss: 0.475614\n",
      "epoch 141; iter: 0; batch classifier loss: 0.429094; batch adversarial loss: 0.615199\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336225; batch adversarial loss: 0.571270\n",
      "epoch 143; iter: 0; batch classifier loss: 0.392003; batch adversarial loss: 0.465808\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370264; batch adversarial loss: 0.579197\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399355; batch adversarial loss: 0.544305\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358398; batch adversarial loss: 0.550373\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317110; batch adversarial loss: 0.611251\n",
      "epoch 148; iter: 0; batch classifier loss: 0.320107; batch adversarial loss: 0.585929\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361885; batch adversarial loss: 0.509530\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353855; batch adversarial loss: 0.497415\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422322; batch adversarial loss: 0.501873\n",
      "epoch 152; iter: 0; batch classifier loss: 0.278904; batch adversarial loss: 0.561404\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348006; batch adversarial loss: 0.587618\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346771; batch adversarial loss: 0.577721\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379103; batch adversarial loss: 0.556091\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380260; batch adversarial loss: 0.511530\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383837; batch adversarial loss: 0.502093\n",
      "epoch 158; iter: 0; batch classifier loss: 0.398661; batch adversarial loss: 0.632444\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396590; batch adversarial loss: 0.565086\n",
      "epoch 160; iter: 0; batch classifier loss: 0.323769; batch adversarial loss: 0.519801\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318186; batch adversarial loss: 0.569608\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409467; batch adversarial loss: 0.488153\n",
      "epoch 163; iter: 0; batch classifier loss: 0.418915; batch adversarial loss: 0.512648\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362838; batch adversarial loss: 0.487282\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321759; batch adversarial loss: 0.629854\n",
      "epoch 166; iter: 0; batch classifier loss: 0.406994; batch adversarial loss: 0.629476\n",
      "epoch 167; iter: 0; batch classifier loss: 0.307512; batch adversarial loss: 0.588494\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397971; batch adversarial loss: 0.503623\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337845; batch adversarial loss: 0.596482\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.519853\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323309; batch adversarial loss: 0.485018\n",
      "epoch 172; iter: 0; batch classifier loss: 0.399694; batch adversarial loss: 0.587882\n",
      "epoch 173; iter: 0; batch classifier loss: 0.450179; batch adversarial loss: 0.588684\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377859; batch adversarial loss: 0.545269\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325568; batch adversarial loss: 0.545056\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327480; batch adversarial loss: 0.588033\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394995; batch adversarial loss: 0.579227\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390312; batch adversarial loss: 0.570538\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388003; batch adversarial loss: 0.527887\n",
      "epoch 180; iter: 0; batch classifier loss: 0.406808; batch adversarial loss: 0.483417\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314663; batch adversarial loss: 0.597076\n",
      "epoch 182; iter: 0; batch classifier loss: 0.413779; batch adversarial loss: 0.622567\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387274; batch adversarial loss: 0.571609\n",
      "epoch 184; iter: 0; batch classifier loss: 0.311697; batch adversarial loss: 0.596377\n",
      "epoch 185; iter: 0; batch classifier loss: 0.310408; batch adversarial loss: 0.485169\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392168; batch adversarial loss: 0.623212\n",
      "epoch 187; iter: 0; batch classifier loss: 0.384348; batch adversarial loss: 0.631223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337568; batch adversarial loss: 0.649414\n",
      "epoch 189; iter: 0; batch classifier loss: 0.312108; batch adversarial loss: 0.562730\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343603; batch adversarial loss: 0.519186\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319511; batch adversarial loss: 0.519373\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367806; batch adversarial loss: 0.519661\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341141; batch adversarial loss: 0.527962\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384023; batch adversarial loss: 0.545051\n",
      "epoch 195; iter: 0; batch classifier loss: 0.403225; batch adversarial loss: 0.536561\n",
      "epoch 196; iter: 0; batch classifier loss: 0.424233; batch adversarial loss: 0.579208\n",
      "epoch 197; iter: 0; batch classifier loss: 0.374080; batch adversarial loss: 0.518996\n",
      "epoch 198; iter: 0; batch classifier loss: 0.328508; batch adversarial loss: 0.553152\n",
      "epoch 199; iter: 0; batch classifier loss: 0.429022; batch adversarial loss: 0.527781\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691522; batch adversarial loss: 0.673010\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588143; batch adversarial loss: 0.655334\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544446; batch adversarial loss: 0.616356\n",
      "epoch 3; iter: 0; batch classifier loss: 0.504443; batch adversarial loss: 0.628695\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569079; batch adversarial loss: 0.613829\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578810; batch adversarial loss: 0.628501\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521768; batch adversarial loss: 0.592063\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553416; batch adversarial loss: 0.617085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585906; batch adversarial loss: 0.604179\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535623; batch adversarial loss: 0.595609\n",
      "epoch 10; iter: 0; batch classifier loss: 0.628663; batch adversarial loss: 0.601931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.541929; batch adversarial loss: 0.527015\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515752; batch adversarial loss: 0.560454\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499500; batch adversarial loss: 0.554973\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464588; batch adversarial loss: 0.593781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538868; batch adversarial loss: 0.595169\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524534; batch adversarial loss: 0.509167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499144; batch adversarial loss: 0.564839\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522029; batch adversarial loss: 0.538805\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525666; batch adversarial loss: 0.574746\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490920; batch adversarial loss: 0.530983\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517731; batch adversarial loss: 0.528073\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574122; batch adversarial loss: 0.549366\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471426; batch adversarial loss: 0.555135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481270; batch adversarial loss: 0.530147\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472621; batch adversarial loss: 0.546610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.416063; batch adversarial loss: 0.488410\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444414; batch adversarial loss: 0.512827\n",
      "epoch 28; iter: 0; batch classifier loss: 0.552770; batch adversarial loss: 0.562609\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425744; batch adversarial loss: 0.570925\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467162; batch adversarial loss: 0.527372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491076; batch adversarial loss: 0.545087\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458155; batch adversarial loss: 0.604644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434793; batch adversarial loss: 0.598516\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435137; batch adversarial loss: 0.525752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468573; batch adversarial loss: 0.498729\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464330; batch adversarial loss: 0.599550\n",
      "epoch 37; iter: 0; batch classifier loss: 0.367701; batch adversarial loss: 0.481146\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467814; batch adversarial loss: 0.545095\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468533; batch adversarial loss: 0.680949\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466426; batch adversarial loss: 0.580769\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417032; batch adversarial loss: 0.535428\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409238; batch adversarial loss: 0.544086\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458418; batch adversarial loss: 0.631269\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465715; batch adversarial loss: 0.535666\n",
      "epoch 45; iter: 0; batch classifier loss: 0.387111; batch adversarial loss: 0.527975\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467038; batch adversarial loss: 0.581594\n",
      "epoch 47; iter: 0; batch classifier loss: 0.470131; batch adversarial loss: 0.553477\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395939; batch adversarial loss: 0.479162\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437575; batch adversarial loss: 0.534819\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460204; batch adversarial loss: 0.554267\n",
      "epoch 51; iter: 0; batch classifier loss: 0.541198; batch adversarial loss: 0.553823\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466513; batch adversarial loss: 0.600496\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414169; batch adversarial loss: 0.618401\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442153; batch adversarial loss: 0.581523\n",
      "epoch 55; iter: 0; batch classifier loss: 0.503623; batch adversarial loss: 0.516931\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398720; batch adversarial loss: 0.589848\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454374; batch adversarial loss: 0.543457\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421019; batch adversarial loss: 0.499110\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408967; batch adversarial loss: 0.590522\n",
      "epoch 60; iter: 0; batch classifier loss: 0.488519; batch adversarial loss: 0.516978\n",
      "epoch 61; iter: 0; batch classifier loss: 0.367488; batch adversarial loss: 0.517497\n",
      "epoch 62; iter: 0; batch classifier loss: 0.514850; batch adversarial loss: 0.552545\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448156; batch adversarial loss: 0.555558\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393840; batch adversarial loss: 0.561843\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398452; batch adversarial loss: 0.470690\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412927; batch adversarial loss: 0.591300\n",
      "epoch 67; iter: 0; batch classifier loss: 0.466339; batch adversarial loss: 0.561498\n",
      "epoch 68; iter: 0; batch classifier loss: 0.453181; batch adversarial loss: 0.526852\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451559; batch adversarial loss: 0.515245\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408392; batch adversarial loss: 0.600636\n",
      "epoch 71; iter: 0; batch classifier loss: 0.454034; batch adversarial loss: 0.471248\n",
      "epoch 72; iter: 0; batch classifier loss: 0.453633; batch adversarial loss: 0.561294\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380269; batch adversarial loss: 0.545055\n",
      "epoch 74; iter: 0; batch classifier loss: 0.505065; batch adversarial loss: 0.552390\n",
      "epoch 75; iter: 0; batch classifier loss: 0.469856; batch adversarial loss: 0.592234\n",
      "epoch 76; iter: 0; batch classifier loss: 0.475228; batch adversarial loss: 0.573526\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417442; batch adversarial loss: 0.542583\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398179; batch adversarial loss: 0.572060\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429774; batch adversarial loss: 0.508488\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380368; batch adversarial loss: 0.480394\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422160; batch adversarial loss: 0.566853\n",
      "epoch 82; iter: 0; batch classifier loss: 0.344608; batch adversarial loss: 0.544300\n",
      "epoch 83; iter: 0; batch classifier loss: 0.366056; batch adversarial loss: 0.617167\n",
      "epoch 84; iter: 0; batch classifier loss: 0.448143; batch adversarial loss: 0.553955\n",
      "epoch 85; iter: 0; batch classifier loss: 0.340764; batch adversarial loss: 0.541938\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419296; batch adversarial loss: 0.544796\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368188; batch adversarial loss: 0.562796\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384316; batch adversarial loss: 0.527197\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404501; batch adversarial loss: 0.535352\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407667; batch adversarial loss: 0.508515\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381329; batch adversarial loss: 0.534702\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425599; batch adversarial loss: 0.496680\n",
      "epoch 93; iter: 0; batch classifier loss: 0.463209; batch adversarial loss: 0.591438\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368250; batch adversarial loss: 0.590154\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373351; batch adversarial loss: 0.563633\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423939; batch adversarial loss: 0.469354\n",
      "epoch 97; iter: 0; batch classifier loss: 0.471870; batch adversarial loss: 0.610024\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387811; batch adversarial loss: 0.627433\n",
      "epoch 99; iter: 0; batch classifier loss: 0.391385; batch adversarial loss: 0.534558\n",
      "epoch 100; iter: 0; batch classifier loss: 0.330445; batch adversarial loss: 0.524152\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399231; batch adversarial loss: 0.527427\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323502; batch adversarial loss: 0.412512\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334764; batch adversarial loss: 0.517658\n",
      "epoch 104; iter: 0; batch classifier loss: 0.410081; batch adversarial loss: 0.602483\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414772; batch adversarial loss: 0.608341\n",
      "epoch 106; iter: 0; batch classifier loss: 0.425674; batch adversarial loss: 0.553034\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406769; batch adversarial loss: 0.515893\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385175; batch adversarial loss: 0.479304\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385934; batch adversarial loss: 0.563225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.309962; batch adversarial loss: 0.477960\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336384; batch adversarial loss: 0.508082\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349072; batch adversarial loss: 0.548127\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343603; batch adversarial loss: 0.580894\n",
      "epoch 114; iter: 0; batch classifier loss: 0.421038; batch adversarial loss: 0.562059\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401010; batch adversarial loss: 0.527118\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346913; batch adversarial loss: 0.601216\n",
      "epoch 117; iter: 0; batch classifier loss: 0.273922; batch adversarial loss: 0.592308\n",
      "epoch 118; iter: 0; batch classifier loss: 0.322865; batch adversarial loss: 0.610028\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338940; batch adversarial loss: 0.562438\n",
      "epoch 120; iter: 0; batch classifier loss: 0.445966; batch adversarial loss: 0.505381\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389632; batch adversarial loss: 0.471975\n",
      "epoch 122; iter: 0; batch classifier loss: 0.306677; batch adversarial loss: 0.554415\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339718; batch adversarial loss: 0.566990\n",
      "epoch 124; iter: 0; batch classifier loss: 0.330081; batch adversarial loss: 0.583280\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415954; batch adversarial loss: 0.582983\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337465; batch adversarial loss: 0.544398\n",
      "epoch 127; iter: 0; batch classifier loss: 0.336472; batch adversarial loss: 0.637543\n",
      "epoch 128; iter: 0; batch classifier loss: 0.353378; batch adversarial loss: 0.516777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385646; batch adversarial loss: 0.525837\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373706; batch adversarial loss: 0.544786\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379898; batch adversarial loss: 0.543309\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405689; batch adversarial loss: 0.497711\n",
      "epoch 133; iter: 0; batch classifier loss: 0.428306; batch adversarial loss: 0.572064\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367306; batch adversarial loss: 0.599669\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348762; batch adversarial loss: 0.543545\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403655; batch adversarial loss: 0.580000\n",
      "epoch 137; iter: 0; batch classifier loss: 0.309012; batch adversarial loss: 0.534841\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380542; batch adversarial loss: 0.572310\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390730; batch adversarial loss: 0.590845\n",
      "epoch 140; iter: 0; batch classifier loss: 0.318513; batch adversarial loss: 0.570897\n",
      "epoch 141; iter: 0; batch classifier loss: 0.418884; batch adversarial loss: 0.523966\n",
      "epoch 142; iter: 0; batch classifier loss: 0.399135; batch adversarial loss: 0.554288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371889; batch adversarial loss: 0.610382\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381392; batch adversarial loss: 0.478602\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390465; batch adversarial loss: 0.524111\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378192; batch adversarial loss: 0.499823\n",
      "epoch 147; iter: 0; batch classifier loss: 0.371192; batch adversarial loss: 0.581864\n",
      "epoch 148; iter: 0; batch classifier loss: 0.388029; batch adversarial loss: 0.535043\n",
      "epoch 149; iter: 0; batch classifier loss: 0.304968; batch adversarial loss: 0.526902\n",
      "epoch 150; iter: 0; batch classifier loss: 0.393386; batch adversarial loss: 0.526825\n",
      "epoch 151; iter: 0; batch classifier loss: 0.342625; batch adversarial loss: 0.451184\n",
      "epoch 152; iter: 0; batch classifier loss: 0.432819; batch adversarial loss: 0.663397\n",
      "epoch 153; iter: 0; batch classifier loss: 0.309075; batch adversarial loss: 0.600311\n",
      "epoch 154; iter: 0; batch classifier loss: 0.328147; batch adversarial loss: 0.482433\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342134; batch adversarial loss: 0.535631\n",
      "epoch 156; iter: 0; batch classifier loss: 0.382878; batch adversarial loss: 0.497296\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365045; batch adversarial loss: 0.526877\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396142; batch adversarial loss: 0.527019\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360999; batch adversarial loss: 0.552226\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343123; batch adversarial loss: 0.599792\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350387; batch adversarial loss: 0.536978\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383705; batch adversarial loss: 0.554450\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341301; batch adversarial loss: 0.543402\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345271; batch adversarial loss: 0.506099\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349747; batch adversarial loss: 0.563397\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323659; batch adversarial loss: 0.507616\n",
      "epoch 167; iter: 0; batch classifier loss: 0.275479; batch adversarial loss: 0.451257\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326443; batch adversarial loss: 0.574947\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362709; batch adversarial loss: 0.570128\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335353; batch adversarial loss: 0.497517\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330962; batch adversarial loss: 0.583325\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317788; batch adversarial loss: 0.581462\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372755; batch adversarial loss: 0.563072\n",
      "epoch 174; iter: 0; batch classifier loss: 0.333378; batch adversarial loss: 0.609995\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390193; batch adversarial loss: 0.526207\n",
      "epoch 176; iter: 0; batch classifier loss: 0.437870; batch adversarial loss: 0.609366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384234; batch adversarial loss: 0.553084\n",
      "epoch 178; iter: 0; batch classifier loss: 0.404280; batch adversarial loss: 0.617275\n",
      "epoch 179; iter: 0; batch classifier loss: 0.326262; batch adversarial loss: 0.553246\n",
      "epoch 180; iter: 0; batch classifier loss: 0.298564; batch adversarial loss: 0.527369\n",
      "epoch 181; iter: 0; batch classifier loss: 0.316852; batch adversarial loss: 0.496635\n",
      "epoch 182; iter: 0; batch classifier loss: 0.330489; batch adversarial loss: 0.515508\n",
      "epoch 183; iter: 0; batch classifier loss: 0.370575; batch adversarial loss: 0.589303\n",
      "epoch 184; iter: 0; batch classifier loss: 0.299732; batch adversarial loss: 0.572354\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303705; batch adversarial loss: 0.555274\n",
      "epoch 186; iter: 0; batch classifier loss: 0.269038; batch adversarial loss: 0.480792\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352122; batch adversarial loss: 0.602364\n",
      "epoch 188; iter: 0; batch classifier loss: 0.269250; batch adversarial loss: 0.581681\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369670; batch adversarial loss: 0.510006\n",
      "epoch 190; iter: 0; batch classifier loss: 0.433155; batch adversarial loss: 0.611782\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319699; batch adversarial loss: 0.573208\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371070; batch adversarial loss: 0.544119\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327214; batch adversarial loss: 0.499742\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322476; batch adversarial loss: 0.544738\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332473; batch adversarial loss: 0.478252\n",
      "epoch 196; iter: 0; batch classifier loss: 0.296056; batch adversarial loss: 0.487465\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390647; batch adversarial loss: 0.655912\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352333; batch adversarial loss: 0.573228\n",
      "epoch 199; iter: 0; batch classifier loss: 0.344171; batch adversarial loss: 0.534995\n",
      "epoch 0; iter: 0; batch classifier loss: 0.792628; batch adversarial loss: 0.754041\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582902; batch adversarial loss: 0.676958\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565738; batch adversarial loss: 0.666786\n",
      "epoch 3; iter: 0; batch classifier loss: 0.503159; batch adversarial loss: 0.638233\n",
      "epoch 4; iter: 0; batch classifier loss: 0.554961; batch adversarial loss: 0.618974\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572027; batch adversarial loss: 0.597201\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582814; batch adversarial loss: 0.608013\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542507; batch adversarial loss: 0.560066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.509035; batch adversarial loss: 0.581722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557196; batch adversarial loss: 0.572452\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491338; batch adversarial loss: 0.556175\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511778; batch adversarial loss: 0.602493\n",
      "epoch 12; iter: 0; batch classifier loss: 0.433005; batch adversarial loss: 0.550305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547489; batch adversarial loss: 0.583799\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509133; batch adversarial loss: 0.548783\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543847; batch adversarial loss: 0.540482\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467616; batch adversarial loss: 0.534659\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493268; batch adversarial loss: 0.561651\n",
      "epoch 18; iter: 0; batch classifier loss: 0.580750; batch adversarial loss: 0.542844\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534332; batch adversarial loss: 0.633484\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451056; batch adversarial loss: 0.521747\n",
      "epoch 21; iter: 0; batch classifier loss: 0.547096; batch adversarial loss: 0.549509\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505487; batch adversarial loss: 0.578640\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464383; batch adversarial loss: 0.584325\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462096; batch adversarial loss: 0.612292\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528609; batch adversarial loss: 0.560105\n",
      "epoch 26; iter: 0; batch classifier loss: 0.402052; batch adversarial loss: 0.548493\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459774; batch adversarial loss: 0.579355\n",
      "epoch 28; iter: 0; batch classifier loss: 0.522556; batch adversarial loss: 0.545586\n",
      "epoch 29; iter: 0; batch classifier loss: 0.517590; batch adversarial loss: 0.537736\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437552; batch adversarial loss: 0.597723\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498619; batch adversarial loss: 0.522303\n",
      "epoch 32; iter: 0; batch classifier loss: 0.501694; batch adversarial loss: 0.530063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.540415; batch adversarial loss: 0.587749\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447893; batch adversarial loss: 0.545522\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468096; batch adversarial loss: 0.596687\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453399; batch adversarial loss: 0.588304\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383064; batch adversarial loss: 0.492330\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497618; batch adversarial loss: 0.544778\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459612; batch adversarial loss: 0.535184\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448432; batch adversarial loss: 0.562469\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430336; batch adversarial loss: 0.570771\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448390; batch adversarial loss: 0.527724\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424862; batch adversarial loss: 0.589419\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463322; batch adversarial loss: 0.635425\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477975; batch adversarial loss: 0.517434\n",
      "epoch 46; iter: 0; batch classifier loss: 0.351621; batch adversarial loss: 0.495763\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487190; batch adversarial loss: 0.532361\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402225; batch adversarial loss: 0.544634\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379668; batch adversarial loss: 0.581341\n",
      "epoch 50; iter: 0; batch classifier loss: 0.452828; batch adversarial loss: 0.562246\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445204; batch adversarial loss: 0.574242\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413888; batch adversarial loss: 0.616271\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421960; batch adversarial loss: 0.563656\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464588; batch adversarial loss: 0.563348\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410246; batch adversarial loss: 0.543867\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378733; batch adversarial loss: 0.571512\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420028; batch adversarial loss: 0.615925\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421806; batch adversarial loss: 0.545797\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399688; batch adversarial loss: 0.517385\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437432; batch adversarial loss: 0.598794\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423581; batch adversarial loss: 0.562587\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441088; batch adversarial loss: 0.597912\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426844; batch adversarial loss: 0.535529\n",
      "epoch 64; iter: 0; batch classifier loss: 0.417857; batch adversarial loss: 0.599258\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412727; batch adversarial loss: 0.599548\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382853; batch adversarial loss: 0.572305\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378550; batch adversarial loss: 0.607828\n",
      "epoch 68; iter: 0; batch classifier loss: 0.332575; batch adversarial loss: 0.517627\n",
      "epoch 69; iter: 0; batch classifier loss: 0.379667; batch adversarial loss: 0.571376\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404082; batch adversarial loss: 0.608182\n",
      "epoch 71; iter: 0; batch classifier loss: 0.441708; batch adversarial loss: 0.508319\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395382; batch adversarial loss: 0.561788\n",
      "epoch 73; iter: 0; batch classifier loss: 0.432369; batch adversarial loss: 0.580513\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388697; batch adversarial loss: 0.509601\n",
      "epoch 75; iter: 0; batch classifier loss: 0.509432; batch adversarial loss: 0.580019\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403790; batch adversarial loss: 0.498423\n",
      "epoch 77; iter: 0; batch classifier loss: 0.365615; batch adversarial loss: 0.607449\n",
      "epoch 78; iter: 0; batch classifier loss: 0.343044; batch adversarial loss: 0.544660\n",
      "epoch 79; iter: 0; batch classifier loss: 0.344415; batch adversarial loss: 0.544720\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449252; batch adversarial loss: 0.543667\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404374; batch adversarial loss: 0.582205\n",
      "epoch 82; iter: 0; batch classifier loss: 0.359770; batch adversarial loss: 0.497542\n",
      "epoch 83; iter: 0; batch classifier loss: 0.495568; batch adversarial loss: 0.517390\n",
      "epoch 84; iter: 0; batch classifier loss: 0.424763; batch adversarial loss: 0.573465\n",
      "epoch 85; iter: 0; batch classifier loss: 0.384018; batch adversarial loss: 0.581434\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395877; batch adversarial loss: 0.600094\n",
      "epoch 87; iter: 0; batch classifier loss: 0.409741; batch adversarial loss: 0.525658\n",
      "epoch 88; iter: 0; batch classifier loss: 0.334497; batch adversarial loss: 0.562526\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425557; batch adversarial loss: 0.644648\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375202; batch adversarial loss: 0.553408\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400957; batch adversarial loss: 0.608027\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393679; batch adversarial loss: 0.500084\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379933; batch adversarial loss: 0.470198\n",
      "epoch 94; iter: 0; batch classifier loss: 0.510140; batch adversarial loss: 0.526886\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368885; batch adversarial loss: 0.573017\n",
      "epoch 96; iter: 0; batch classifier loss: 0.425205; batch adversarial loss: 0.554161\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430097; batch adversarial loss: 0.498975\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402560; batch adversarial loss: 0.518626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.442990; batch adversarial loss: 0.534269\n",
      "epoch 100; iter: 0; batch classifier loss: 0.323380; batch adversarial loss: 0.553509\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335085; batch adversarial loss: 0.588957\n",
      "epoch 102; iter: 0; batch classifier loss: 0.368348; batch adversarial loss: 0.562807\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394641; batch adversarial loss: 0.496389\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363893; batch adversarial loss: 0.551445\n",
      "epoch 105; iter: 0; batch classifier loss: 0.412094; batch adversarial loss: 0.525417\n",
      "epoch 106; iter: 0; batch classifier loss: 0.392368; batch adversarial loss: 0.581086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.380521; batch adversarial loss: 0.542763\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401794; batch adversarial loss: 0.635880\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352480; batch adversarial loss: 0.489376\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383946; batch adversarial loss: 0.580719\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363690; batch adversarial loss: 0.553900\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339944; batch adversarial loss: 0.506877\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360507; batch adversarial loss: 0.526468\n",
      "epoch 114; iter: 0; batch classifier loss: 0.413518; batch adversarial loss: 0.516519\n",
      "epoch 115; iter: 0; batch classifier loss: 0.488034; batch adversarial loss: 0.507138\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438475; batch adversarial loss: 0.526888\n",
      "epoch 117; iter: 0; batch classifier loss: 0.441123; batch adversarial loss: 0.534931\n",
      "epoch 118; iter: 0; batch classifier loss: 0.468285; batch adversarial loss: 0.534970\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335409; batch adversarial loss: 0.517157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.443070; batch adversarial loss: 0.516652\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394889; batch adversarial loss: 0.573535\n",
      "epoch 122; iter: 0; batch classifier loss: 0.427006; batch adversarial loss: 0.579880\n",
      "epoch 123; iter: 0; batch classifier loss: 0.452525; batch adversarial loss: 0.563048\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367811; batch adversarial loss: 0.570158\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395250; batch adversarial loss: 0.524919\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340220; batch adversarial loss: 0.518071\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390866; batch adversarial loss: 0.473252\n",
      "epoch 128; iter: 0; batch classifier loss: 0.458166; batch adversarial loss: 0.528826\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337608; batch adversarial loss: 0.537739\n",
      "epoch 130; iter: 0; batch classifier loss: 0.446519; batch adversarial loss: 0.507492\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356859; batch adversarial loss: 0.573938\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368062; batch adversarial loss: 0.562695\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337351; batch adversarial loss: 0.559726\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337862; batch adversarial loss: 0.463808\n",
      "epoch 135; iter: 0; batch classifier loss: 0.338208; batch adversarial loss: 0.574465\n",
      "epoch 136; iter: 0; batch classifier loss: 0.323325; batch adversarial loss: 0.480768\n",
      "epoch 137; iter: 0; batch classifier loss: 0.422818; batch adversarial loss: 0.600031\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404248; batch adversarial loss: 0.580267\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377269; batch adversarial loss: 0.565553\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334011; batch adversarial loss: 0.500530\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422846; batch adversarial loss: 0.626647\n",
      "epoch 142; iter: 0; batch classifier loss: 0.394800; batch adversarial loss: 0.628321\n",
      "epoch 143; iter: 0; batch classifier loss: 0.535271; batch adversarial loss: 0.563170\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338221; batch adversarial loss: 0.582685\n",
      "epoch 145; iter: 0; batch classifier loss: 0.349920; batch adversarial loss: 0.562950\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369939; batch adversarial loss: 0.535966\n",
      "epoch 147; iter: 0; batch classifier loss: 0.411711; batch adversarial loss: 0.535201\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380026; batch adversarial loss: 0.607425\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396043; batch adversarial loss: 0.517326\n",
      "epoch 150; iter: 0; batch classifier loss: 0.374986; batch adversarial loss: 0.580721\n",
      "epoch 151; iter: 0; batch classifier loss: 0.454005; batch adversarial loss: 0.580558\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383016; batch adversarial loss: 0.572353\n",
      "epoch 153; iter: 0; batch classifier loss: 0.396614; batch adversarial loss: 0.490191\n",
      "epoch 154; iter: 0; batch classifier loss: 0.308272; batch adversarial loss: 0.517054\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392589; batch adversarial loss: 0.578958\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344820; batch adversarial loss: 0.679486\n",
      "epoch 157; iter: 0; batch classifier loss: 0.415510; batch adversarial loss: 0.480163\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396357; batch adversarial loss: 0.560820\n",
      "epoch 159; iter: 0; batch classifier loss: 0.328421; batch adversarial loss: 0.581622\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375124; batch adversarial loss: 0.484001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407694; batch adversarial loss: 0.617708\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386111; batch adversarial loss: 0.609102\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363185; batch adversarial loss: 0.492078\n",
      "epoch 164; iter: 0; batch classifier loss: 0.348802; batch adversarial loss: 0.491697\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399138; batch adversarial loss: 0.516968\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335187; batch adversarial loss: 0.525451\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369788; batch adversarial loss: 0.550806\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361655; batch adversarial loss: 0.532861\n",
      "epoch 169; iter: 0; batch classifier loss: 0.328348; batch adversarial loss: 0.463787\n",
      "epoch 170; iter: 0; batch classifier loss: 0.330093; batch adversarial loss: 0.508264\n",
      "epoch 171; iter: 0; batch classifier loss: 0.306075; batch adversarial loss: 0.571984\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365142; batch adversarial loss: 0.498305\n",
      "epoch 173; iter: 0; batch classifier loss: 0.409601; batch adversarial loss: 0.524720\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361236; batch adversarial loss: 0.515983\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383579; batch adversarial loss: 0.525430\n",
      "epoch 176; iter: 0; batch classifier loss: 0.448519; batch adversarial loss: 0.571423\n",
      "epoch 177; iter: 0; batch classifier loss: 0.401243; batch adversarial loss: 0.597018\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363860; batch adversarial loss: 0.568627\n",
      "epoch 179; iter: 0; batch classifier loss: 0.382294; batch adversarial loss: 0.569685\n",
      "epoch 180; iter: 0; batch classifier loss: 0.348897; batch adversarial loss: 0.417095\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337644; batch adversarial loss: 0.490231\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351434; batch adversarial loss: 0.608906\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351568; batch adversarial loss: 0.544153\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328218; batch adversarial loss: 0.571031\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366093; batch adversarial loss: 0.582182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.300172; batch adversarial loss: 0.606224\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346699; batch adversarial loss: 0.544521\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345571; batch adversarial loss: 0.592503\n",
      "epoch 189; iter: 0; batch classifier loss: 0.360935; batch adversarial loss: 0.525287\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339071; batch adversarial loss: 0.488860\n",
      "epoch 191; iter: 0; batch classifier loss: 0.462978; batch adversarial loss: 0.563381\n",
      "epoch 192; iter: 0; batch classifier loss: 0.416548; batch adversarial loss: 0.535334\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376146; batch adversarial loss: 0.543975\n",
      "epoch 194; iter: 0; batch classifier loss: 0.298670; batch adversarial loss: 0.594849\n",
      "epoch 195; iter: 0; batch classifier loss: 0.392982; batch adversarial loss: 0.580372\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313364; batch adversarial loss: 0.464751\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344312; batch adversarial loss: 0.519120\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375893; batch adversarial loss: 0.526442\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332881; batch adversarial loss: 0.533567\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699824; batch adversarial loss: 0.734056\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622520; batch adversarial loss: 0.696723\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562632; batch adversarial loss: 0.661715\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603142; batch adversarial loss: 0.639196\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545773; batch adversarial loss: 0.614781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.543757; batch adversarial loss: 0.614193\n",
      "epoch 6; iter: 0; batch classifier loss: 0.619611; batch adversarial loss: 0.579270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521658; batch adversarial loss: 0.632254\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555754; batch adversarial loss: 0.613943\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518817; batch adversarial loss: 0.604569\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515052; batch adversarial loss: 0.641400\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517217; batch adversarial loss: 0.588531\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500152; batch adversarial loss: 0.598580\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487532; batch adversarial loss: 0.531486\n",
      "epoch 14; iter: 0; batch classifier loss: 0.446881; batch adversarial loss: 0.519559\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500549; batch adversarial loss: 0.659140\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488671; batch adversarial loss: 0.580564\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528684; batch adversarial loss: 0.559652\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479598; batch adversarial loss: 0.569789\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455489; batch adversarial loss: 0.577765\n",
      "epoch 20; iter: 0; batch classifier loss: 0.413942; batch adversarial loss: 0.573259\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545934; batch adversarial loss: 0.636318\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443682; batch adversarial loss: 0.569291\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482849; batch adversarial loss: 0.609671\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497792; batch adversarial loss: 0.477272\n",
      "epoch 25; iter: 0; batch classifier loss: 0.398724; batch adversarial loss: 0.587299\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467291; batch adversarial loss: 0.593848\n",
      "epoch 27; iter: 0; batch classifier loss: 0.524445; batch adversarial loss: 0.476305\n",
      "epoch 28; iter: 0; batch classifier loss: 0.594118; batch adversarial loss: 0.549881\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484010; batch adversarial loss: 0.498371\n",
      "epoch 30; iter: 0; batch classifier loss: 0.483268; batch adversarial loss: 0.526955\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402740; batch adversarial loss: 0.554480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.546232; batch adversarial loss: 0.480346\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458539; batch adversarial loss: 0.609218\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464638; batch adversarial loss: 0.572334\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435735; batch adversarial loss: 0.606403\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441465; batch adversarial loss: 0.495679\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426035; batch adversarial loss: 0.536849\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457499; batch adversarial loss: 0.519893\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431733; batch adversarial loss: 0.623109\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430520; batch adversarial loss: 0.492241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.492714; batch adversarial loss: 0.518341\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391917; batch adversarial loss: 0.579880\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403572; batch adversarial loss: 0.448288\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383340; batch adversarial loss: 0.473285\n",
      "epoch 45; iter: 0; batch classifier loss: 0.381594; batch adversarial loss: 0.543397\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412070; batch adversarial loss: 0.582606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393041; batch adversarial loss: 0.587190\n",
      "epoch 48; iter: 0; batch classifier loss: 0.402564; batch adversarial loss: 0.489513\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477959; batch adversarial loss: 0.530737\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455210; batch adversarial loss: 0.568468\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497429; batch adversarial loss: 0.632122\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456912; batch adversarial loss: 0.580124\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431103; batch adversarial loss: 0.537048\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453207; batch adversarial loss: 0.533249\n",
      "epoch 55; iter: 0; batch classifier loss: 0.516737; batch adversarial loss: 0.575436\n",
      "epoch 56; iter: 0; batch classifier loss: 0.349849; batch adversarial loss: 0.554085\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412541; batch adversarial loss: 0.558052\n",
      "epoch 58; iter: 0; batch classifier loss: 0.371841; batch adversarial loss: 0.596612\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383099; batch adversarial loss: 0.506826\n",
      "epoch 60; iter: 0; batch classifier loss: 0.448619; batch adversarial loss: 0.526712\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459884; batch adversarial loss: 0.593541\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426554; batch adversarial loss: 0.669954\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431789; batch adversarial loss: 0.582105\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407354; batch adversarial loss: 0.582213\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376869; batch adversarial loss: 0.516207\n",
      "epoch 66; iter: 0; batch classifier loss: 0.394631; batch adversarial loss: 0.590504\n",
      "epoch 67; iter: 0; batch classifier loss: 0.352708; batch adversarial loss: 0.553326\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403768; batch adversarial loss: 0.479133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406023; batch adversarial loss: 0.535314\n",
      "epoch 70; iter: 0; batch classifier loss: 0.453608; batch adversarial loss: 0.507585\n",
      "epoch 71; iter: 0; batch classifier loss: 0.468175; batch adversarial loss: 0.563022\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382744; batch adversarial loss: 0.434202\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400479; batch adversarial loss: 0.563210\n",
      "epoch 74; iter: 0; batch classifier loss: 0.418202; batch adversarial loss: 0.580368\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423690; batch adversarial loss: 0.626804\n",
      "epoch 76; iter: 0; batch classifier loss: 0.474146; batch adversarial loss: 0.580313\n",
      "epoch 77; iter: 0; batch classifier loss: 0.456171; batch adversarial loss: 0.499313\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355529; batch adversarial loss: 0.587859\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380821; batch adversarial loss: 0.598742\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394285; batch adversarial loss: 0.591286\n",
      "epoch 81; iter: 0; batch classifier loss: 0.323767; batch adversarial loss: 0.554485\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384692; batch adversarial loss: 0.498553\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417914; batch adversarial loss: 0.564922\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429933; batch adversarial loss: 0.508102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.323240; batch adversarial loss: 0.580697\n",
      "epoch 86; iter: 0; batch classifier loss: 0.363794; batch adversarial loss: 0.554484\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363601; batch adversarial loss: 0.535618\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426820; batch adversarial loss: 0.480268\n",
      "epoch 89; iter: 0; batch classifier loss: 0.455557; batch adversarial loss: 0.617139\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426740; batch adversarial loss: 0.562669\n",
      "epoch 91; iter: 0; batch classifier loss: 0.472683; batch adversarial loss: 0.598729\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382065; batch adversarial loss: 0.580470\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349131; batch adversarial loss: 0.507564\n",
      "epoch 94; iter: 0; batch classifier loss: 0.330930; batch adversarial loss: 0.499779\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426492; batch adversarial loss: 0.479679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.427526; batch adversarial loss: 0.598910\n",
      "epoch 97; iter: 0; batch classifier loss: 0.465600; batch adversarial loss: 0.571762\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420054; batch adversarial loss: 0.537429\n",
      "epoch 99; iter: 0; batch classifier loss: 0.427710; batch adversarial loss: 0.571963\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388583; batch adversarial loss: 0.534766\n",
      "epoch 101; iter: 0; batch classifier loss: 0.424228; batch adversarial loss: 0.472013\n",
      "epoch 102; iter: 0; batch classifier loss: 0.433260; batch adversarial loss: 0.563513\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413479; batch adversarial loss: 0.581694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.326201; batch adversarial loss: 0.635691\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414009; batch adversarial loss: 0.553302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410151; batch adversarial loss: 0.508778\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373179; batch adversarial loss: 0.526381\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370704; batch adversarial loss: 0.533405\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410700; batch adversarial loss: 0.526246\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347998; batch adversarial loss: 0.535433\n",
      "epoch 111; iter: 0; batch classifier loss: 0.424630; batch adversarial loss: 0.570256\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355293; batch adversarial loss: 0.570216\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406375; batch adversarial loss: 0.517165\n",
      "epoch 114; iter: 0; batch classifier loss: 0.342056; batch adversarial loss: 0.545666\n",
      "epoch 115; iter: 0; batch classifier loss: 0.309159; batch adversarial loss: 0.580421\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381081; batch adversarial loss: 0.517468\n",
      "epoch 117; iter: 0; batch classifier loss: 0.507698; batch adversarial loss: 0.581230\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412957; batch adversarial loss: 0.524910\n",
      "epoch 119; iter: 0; batch classifier loss: 0.416410; batch adversarial loss: 0.554265\n",
      "epoch 120; iter: 0; batch classifier loss: 0.381436; batch adversarial loss: 0.598958\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394027; batch adversarial loss: 0.580525\n",
      "epoch 122; iter: 0; batch classifier loss: 0.314824; batch adversarial loss: 0.507320\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367850; batch adversarial loss: 0.636462\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371511; batch adversarial loss: 0.506639\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412104; batch adversarial loss: 0.562244\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382623; batch adversarial loss: 0.562589\n",
      "epoch 127; iter: 0; batch classifier loss: 0.331254; batch adversarial loss: 0.597390\n",
      "epoch 128; iter: 0; batch classifier loss: 0.424309; batch adversarial loss: 0.600430\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393150; batch adversarial loss: 0.525671\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408594; batch adversarial loss: 0.564386\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367586; batch adversarial loss: 0.588927\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357024; batch adversarial loss: 0.517581\n",
      "epoch 133; iter: 0; batch classifier loss: 0.321791; batch adversarial loss: 0.525292\n",
      "epoch 134; iter: 0; batch classifier loss: 0.439436; batch adversarial loss: 0.527891\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395272; batch adversarial loss: 0.508949\n",
      "epoch 136; iter: 0; batch classifier loss: 0.435316; batch adversarial loss: 0.543481\n",
      "epoch 137; iter: 0; batch classifier loss: 0.419282; batch adversarial loss: 0.544863\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376267; batch adversarial loss: 0.490793\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395668; batch adversarial loss: 0.518127\n",
      "epoch 140; iter: 0; batch classifier loss: 0.420219; batch adversarial loss: 0.608256\n",
      "epoch 141; iter: 0; batch classifier loss: 0.318137; batch adversarial loss: 0.498418\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374186; batch adversarial loss: 0.618423\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331319; batch adversarial loss: 0.571701\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396331; batch adversarial loss: 0.545238\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398358; batch adversarial loss: 0.516323\n",
      "epoch 146; iter: 0; batch classifier loss: 0.355563; batch adversarial loss: 0.533838\n",
      "epoch 147; iter: 0; batch classifier loss: 0.380695; batch adversarial loss: 0.608881\n",
      "epoch 148; iter: 0; batch classifier loss: 0.398509; batch adversarial loss: 0.463027\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392837; batch adversarial loss: 0.553351\n",
      "epoch 150; iter: 0; batch classifier loss: 0.301709; batch adversarial loss: 0.580439\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344063; batch adversarial loss: 0.525335\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373235; batch adversarial loss: 0.462742\n",
      "epoch 153; iter: 0; batch classifier loss: 0.395392; batch adversarial loss: 0.618034\n",
      "epoch 154; iter: 0; batch classifier loss: 0.427140; batch adversarial loss: 0.562633\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392700; batch adversarial loss: 0.525842\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395778; batch adversarial loss: 0.570180\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405439; batch adversarial loss: 0.544997\n",
      "epoch 158; iter: 0; batch classifier loss: 0.357214; batch adversarial loss: 0.599251\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324017; batch adversarial loss: 0.471869\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356627; batch adversarial loss: 0.691202\n",
      "epoch 161; iter: 0; batch classifier loss: 0.321003; batch adversarial loss: 0.615199\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360865; batch adversarial loss: 0.653689\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345389; batch adversarial loss: 0.508283\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410997; batch adversarial loss: 0.590651\n",
      "epoch 165; iter: 0; batch classifier loss: 0.332824; batch adversarial loss: 0.580404\n",
      "epoch 166; iter: 0; batch classifier loss: 0.313889; batch adversarial loss: 0.561722\n",
      "epoch 167; iter: 0; batch classifier loss: 0.331669; batch adversarial loss: 0.534390\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398379; batch adversarial loss: 0.544706\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320142; batch adversarial loss: 0.572164\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344959; batch adversarial loss: 0.545631\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374607; batch adversarial loss: 0.526261\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373832; batch adversarial loss: 0.571169\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315355; batch adversarial loss: 0.490186\n",
      "epoch 174; iter: 0; batch classifier loss: 0.431189; batch adversarial loss: 0.516263\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357119; batch adversarial loss: 0.589159\n",
      "epoch 176; iter: 0; batch classifier loss: 0.369699; batch adversarial loss: 0.553698\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406739; batch adversarial loss: 0.590018\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337757; batch adversarial loss: 0.599654\n",
      "epoch 179; iter: 0; batch classifier loss: 0.417897; batch adversarial loss: 0.634476\n",
      "epoch 180; iter: 0; batch classifier loss: 0.279339; batch adversarial loss: 0.590572\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411355; batch adversarial loss: 0.544379\n",
      "epoch 182; iter: 0; batch classifier loss: 0.305360; batch adversarial loss: 0.490007\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367532; batch adversarial loss: 0.480471\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337345; batch adversarial loss: 0.516451\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372237; batch adversarial loss: 0.563280\n",
      "epoch 186; iter: 0; batch classifier loss: 0.398486; batch adversarial loss: 0.498814\n",
      "epoch 187; iter: 0; batch classifier loss: 0.432200; batch adversarial loss: 0.508354\n",
      "epoch 188; iter: 0; batch classifier loss: 0.312447; batch adversarial loss: 0.561263\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380089; batch adversarial loss: 0.453408\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380024; batch adversarial loss: 0.515799\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399509; batch adversarial loss: 0.572751\n",
      "epoch 192; iter: 0; batch classifier loss: 0.391835; batch adversarial loss: 0.517537\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347800; batch adversarial loss: 0.590368\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362095; batch adversarial loss: 0.617999\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335117; batch adversarial loss: 0.618319\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362212; batch adversarial loss: 0.534449\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332055; batch adversarial loss: 0.509653\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366229; batch adversarial loss: 0.544507\n",
      "epoch 199; iter: 0; batch classifier loss: 0.446260; batch adversarial loss: 0.499772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.704358; batch adversarial loss: 0.733119\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615554; batch adversarial loss: 0.695471\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599819; batch adversarial loss: 0.677809\n",
      "epoch 3; iter: 0; batch classifier loss: 0.571297; batch adversarial loss: 0.669197\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581369; batch adversarial loss: 0.643515\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539261; batch adversarial loss: 0.616711\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588225; batch adversarial loss: 0.592166\n",
      "epoch 7; iter: 0; batch classifier loss: 0.473535; batch adversarial loss: 0.608824\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539447; batch adversarial loss: 0.591115\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579655; batch adversarial loss: 0.601725\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589089; batch adversarial loss: 0.569081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489843; batch adversarial loss: 0.566350\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556856; batch adversarial loss: 0.522623\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524105; batch adversarial loss: 0.606842\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543559; batch adversarial loss: 0.559284\n",
      "epoch 15; iter: 0; batch classifier loss: 0.603915; batch adversarial loss: 0.572723\n",
      "epoch 16; iter: 0; batch classifier loss: 0.589443; batch adversarial loss: 0.570789\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426879; batch adversarial loss: 0.597443\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560931; batch adversarial loss: 0.635536\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525208; batch adversarial loss: 0.564801\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478769; batch adversarial loss: 0.609447\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524497; batch adversarial loss: 0.601255\n",
      "epoch 22; iter: 0; batch classifier loss: 0.534091; batch adversarial loss: 0.603153\n",
      "epoch 23; iter: 0; batch classifier loss: 0.535834; batch adversarial loss: 0.521882\n",
      "epoch 24; iter: 0; batch classifier loss: 0.443409; batch adversarial loss: 0.569559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513017; batch adversarial loss: 0.590659\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490770; batch adversarial loss: 0.585111\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490647; batch adversarial loss: 0.557177\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479608; batch adversarial loss: 0.543308\n",
      "epoch 29; iter: 0; batch classifier loss: 0.546686; batch adversarial loss: 0.597771\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481414; batch adversarial loss: 0.542007\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505245; batch adversarial loss: 0.564584\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423036; batch adversarial loss: 0.593850\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503540; batch adversarial loss: 0.618252\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497603; batch adversarial loss: 0.619654\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498277; batch adversarial loss: 0.570627\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437430; batch adversarial loss: 0.545928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467913; batch adversarial loss: 0.545916\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482501; batch adversarial loss: 0.570774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.508553; batch adversarial loss: 0.604236\n",
      "epoch 40; iter: 0; batch classifier loss: 0.530704; batch adversarial loss: 0.561984\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509475; batch adversarial loss: 0.561414\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453911; batch adversarial loss: 0.495069\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430655; batch adversarial loss: 0.605731\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459685; batch adversarial loss: 0.579706\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463062; batch adversarial loss: 0.562754\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457736; batch adversarial loss: 0.536668\n",
      "epoch 47; iter: 0; batch classifier loss: 0.388011; batch adversarial loss: 0.586711\n",
      "epoch 48; iter: 0; batch classifier loss: 0.589337; batch adversarial loss: 0.637382\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449709; batch adversarial loss: 0.562177\n",
      "epoch 50; iter: 0; batch classifier loss: 0.478357; batch adversarial loss: 0.519106\n",
      "epoch 51; iter: 0; batch classifier loss: 0.475045; batch adversarial loss: 0.544426\n",
      "epoch 52; iter: 0; batch classifier loss: 0.461263; batch adversarial loss: 0.561855\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412172; batch adversarial loss: 0.595486\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422690; batch adversarial loss: 0.622173\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415468; batch adversarial loss: 0.552959\n",
      "epoch 56; iter: 0; batch classifier loss: 0.401125; batch adversarial loss: 0.562294\n",
      "epoch 57; iter: 0; batch classifier loss: 0.517372; batch adversarial loss: 0.629546\n",
      "epoch 58; iter: 0; batch classifier loss: 0.377568; batch adversarial loss: 0.535314\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419330; batch adversarial loss: 0.528514\n",
      "epoch 60; iter: 0; batch classifier loss: 0.513699; batch adversarial loss: 0.561850\n",
      "epoch 61; iter: 0; batch classifier loss: 0.511047; batch adversarial loss: 0.560777\n",
      "epoch 62; iter: 0; batch classifier loss: 0.357735; batch adversarial loss: 0.504098\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421555; batch adversarial loss: 0.598272\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381985; batch adversarial loss: 0.624966\n",
      "epoch 65; iter: 0; batch classifier loss: 0.465202; batch adversarial loss: 0.536195\n",
      "epoch 66; iter: 0; batch classifier loss: 0.466970; batch adversarial loss: 0.484210\n",
      "epoch 67; iter: 0; batch classifier loss: 0.453183; batch adversarial loss: 0.579136\n",
      "epoch 68; iter: 0; batch classifier loss: 0.512836; batch adversarial loss: 0.535915\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389329; batch adversarial loss: 0.570516\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414803; batch adversarial loss: 0.536053\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402249; batch adversarial loss: 0.538388\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417408; batch adversarial loss: 0.526911\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419333; batch adversarial loss: 0.563178\n",
      "epoch 74; iter: 0; batch classifier loss: 0.521621; batch adversarial loss: 0.536886\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423696; batch adversarial loss: 0.545200\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408197; batch adversarial loss: 0.562375\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351039; batch adversarial loss: 0.587992\n",
      "epoch 78; iter: 0; batch classifier loss: 0.380925; batch adversarial loss: 0.467069\n",
      "epoch 79; iter: 0; batch classifier loss: 0.512680; batch adversarial loss: 0.562040\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432100; batch adversarial loss: 0.535955\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374255; batch adversarial loss: 0.579822\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423490; batch adversarial loss: 0.537129\n",
      "epoch 83; iter: 0; batch classifier loss: 0.437215; batch adversarial loss: 0.666691\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400346; batch adversarial loss: 0.571380\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363777; batch adversarial loss: 0.545432\n",
      "epoch 86; iter: 0; batch classifier loss: 0.352078; batch adversarial loss: 0.631981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423508; batch adversarial loss: 0.588472\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389936; batch adversarial loss: 0.562490\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380158; batch adversarial loss: 0.570924\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378565; batch adversarial loss: 0.492879\n",
      "epoch 91; iter: 0; batch classifier loss: 0.415691; batch adversarial loss: 0.622689\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407261; batch adversarial loss: 0.596834\n",
      "epoch 93; iter: 0; batch classifier loss: 0.467414; batch adversarial loss: 0.571186\n",
      "epoch 94; iter: 0; batch classifier loss: 0.488473; batch adversarial loss: 0.561735\n",
      "epoch 95; iter: 0; batch classifier loss: 0.445745; batch adversarial loss: 0.553606\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364888; batch adversarial loss: 0.537357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.416577; batch adversarial loss: 0.527660\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393154; batch adversarial loss: 0.509957\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380394; batch adversarial loss: 0.570742\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397227; batch adversarial loss: 0.598333\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399723; batch adversarial loss: 0.632042\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392702; batch adversarial loss: 0.562601\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401188; batch adversarial loss: 0.588822\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.476100\n",
      "epoch 105; iter: 0; batch classifier loss: 0.278194; batch adversarial loss: 0.502170\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383955; batch adversarial loss: 0.519282\n",
      "epoch 107; iter: 0; batch classifier loss: 0.503963; batch adversarial loss: 0.544823\n",
      "epoch 108; iter: 0; batch classifier loss: 0.438733; batch adversarial loss: 0.553745\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355609; batch adversarial loss: 0.639906\n",
      "epoch 110; iter: 0; batch classifier loss: 0.438583; batch adversarial loss: 0.536307\n",
      "epoch 111; iter: 0; batch classifier loss: 0.449978; batch adversarial loss: 0.519330\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394061; batch adversarial loss: 0.502399\n",
      "epoch 113; iter: 0; batch classifier loss: 0.444904; batch adversarial loss: 0.536813\n",
      "epoch 114; iter: 0; batch classifier loss: 0.413194; batch adversarial loss: 0.570989\n",
      "epoch 115; iter: 0; batch classifier loss: 0.453021; batch adversarial loss: 0.527811\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398900; batch adversarial loss: 0.588054\n",
      "epoch 117; iter: 0; batch classifier loss: 0.509211; batch adversarial loss: 0.484513\n",
      "epoch 118; iter: 0; batch classifier loss: 0.449914; batch adversarial loss: 0.570698\n",
      "epoch 119; iter: 0; batch classifier loss: 0.416686; batch adversarial loss: 0.562473\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383086; batch adversarial loss: 0.536527\n",
      "epoch 121; iter: 0; batch classifier loss: 0.467418; batch adversarial loss: 0.588197\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372452; batch adversarial loss: 0.588237\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396993; batch adversarial loss: 0.622643\n",
      "epoch 124; iter: 0; batch classifier loss: 0.396156; batch adversarial loss: 0.545110\n",
      "epoch 125; iter: 0; batch classifier loss: 0.442671; batch adversarial loss: 0.510776\n",
      "epoch 126; iter: 0; batch classifier loss: 0.403639; batch adversarial loss: 0.553428\n",
      "epoch 127; iter: 0; batch classifier loss: 0.446211; batch adversarial loss: 0.544706\n",
      "epoch 128; iter: 0; batch classifier loss: 0.431176; batch adversarial loss: 0.570922\n",
      "epoch 129; iter: 0; batch classifier loss: 0.325890; batch adversarial loss: 0.622047\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345520; batch adversarial loss: 0.588158\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339731; batch adversarial loss: 0.519131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320644; batch adversarial loss: 0.545187\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391178; batch adversarial loss: 0.553833\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349370; batch adversarial loss: 0.579682\n",
      "epoch 135; iter: 0; batch classifier loss: 0.437072; batch adversarial loss: 0.649015\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348281; batch adversarial loss: 0.536424\n",
      "epoch 137; iter: 0; batch classifier loss: 0.467312; batch adversarial loss: 0.614293\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405504; batch adversarial loss: 0.545527\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349350; batch adversarial loss: 0.536690\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400499; batch adversarial loss: 0.519156\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366103; batch adversarial loss: 0.570904\n",
      "epoch 142; iter: 0; batch classifier loss: 0.466999; batch adversarial loss: 0.493016\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381181; batch adversarial loss: 0.579930\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336078; batch adversarial loss: 0.614272\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364973; batch adversarial loss: 0.544794\n",
      "epoch 146; iter: 0; batch classifier loss: 0.442973; batch adversarial loss: 0.544665\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374146; batch adversarial loss: 0.579974\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354949; batch adversarial loss: 0.562726\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345891; batch adversarial loss: 0.588443\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369768; batch adversarial loss: 0.631483\n",
      "epoch 151; iter: 0; batch classifier loss: 0.397796; batch adversarial loss: 0.544704\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342109; batch adversarial loss: 0.571025\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349786; batch adversarial loss: 0.519197\n",
      "epoch 154; iter: 0; batch classifier loss: 0.386048; batch adversarial loss: 0.536182\n",
      "epoch 155; iter: 0; batch classifier loss: 0.417266; batch adversarial loss: 0.588141\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357252; batch adversarial loss: 0.570804\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432908; batch adversarial loss: 0.571065\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400568; batch adversarial loss: 0.614627\n",
      "epoch 159; iter: 0; batch classifier loss: 0.420373; batch adversarial loss: 0.571366\n",
      "epoch 160; iter: 0; batch classifier loss: 0.418615; batch adversarial loss: 0.597437\n",
      "epoch 161; iter: 0; batch classifier loss: 0.425262; batch adversarial loss: 0.510616\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370666; batch adversarial loss: 0.562316\n",
      "epoch 163; iter: 0; batch classifier loss: 0.443015; batch adversarial loss: 0.562395\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385550; batch adversarial loss: 0.622436\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333954; batch adversarial loss: 0.536723\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369435; batch adversarial loss: 0.613991\n",
      "epoch 167; iter: 0; batch classifier loss: 0.317170; batch adversarial loss: 0.519365\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354814; batch adversarial loss: 0.544630\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372079; batch adversarial loss: 0.571103\n",
      "epoch 170; iter: 0; batch classifier loss: 0.421630; batch adversarial loss: 0.562351\n",
      "epoch 171; iter: 0; batch classifier loss: 0.391334; batch adversarial loss: 0.570825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.352074; batch adversarial loss: 0.588411\n",
      "epoch 173; iter: 0; batch classifier loss: 0.376923; batch adversarial loss: 0.475596\n",
      "epoch 174; iter: 0; batch classifier loss: 0.383090; batch adversarial loss: 0.571161\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388858; batch adversarial loss: 0.605240\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400908; batch adversarial loss: 0.535924\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383461; batch adversarial loss: 0.518512\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320033; batch adversarial loss: 0.519015\n",
      "epoch 179; iter: 0; batch classifier loss: 0.413631; batch adversarial loss: 0.536728\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344056; batch adversarial loss: 0.605234\n",
      "epoch 181; iter: 0; batch classifier loss: 0.460850; batch adversarial loss: 0.553993\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415324; batch adversarial loss: 0.648118\n",
      "epoch 183; iter: 0; batch classifier loss: 0.310694; batch adversarial loss: 0.553592\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377038; batch adversarial loss: 0.518747\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372901; batch adversarial loss: 0.553908\n",
      "epoch 186; iter: 0; batch classifier loss: 0.451485; batch adversarial loss: 0.544739\n",
      "epoch 187; iter: 0; batch classifier loss: 0.390120; batch adversarial loss: 0.562410\n",
      "epoch 188; iter: 0; batch classifier loss: 0.351957; batch adversarial loss: 0.622746\n",
      "epoch 189; iter: 0; batch classifier loss: 0.438362; batch adversarial loss: 0.484994\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349821; batch adversarial loss: 0.614105\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374147; batch adversarial loss: 0.545005\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373944; batch adversarial loss: 0.493562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.405014; batch adversarial loss: 0.528264\n",
      "epoch 194; iter: 0; batch classifier loss: 0.409756; batch adversarial loss: 0.657247\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365122; batch adversarial loss: 0.605493\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360787; batch adversarial loss: 0.614150\n",
      "epoch 197; iter: 0; batch classifier loss: 0.334053; batch adversarial loss: 0.613985\n",
      "epoch 198; iter: 0; batch classifier loss: 0.409655; batch adversarial loss: 0.553352\n",
      "epoch 199; iter: 0; batch classifier loss: 0.444506; batch adversarial loss: 0.510533\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724268; batch adversarial loss: 0.649209\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592228; batch adversarial loss: 0.678893\n",
      "epoch 2; iter: 0; batch classifier loss: 0.537215; batch adversarial loss: 0.663485\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572471; batch adversarial loss: 0.638122\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581783; batch adversarial loss: 0.640135\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527660; batch adversarial loss: 0.626969\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510974; batch adversarial loss: 0.634503\n",
      "epoch 7; iter: 0; batch classifier loss: 0.589021; batch adversarial loss: 0.609845\n",
      "epoch 8; iter: 0; batch classifier loss: 0.607930; batch adversarial loss: 0.612268\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578057; batch adversarial loss: 0.585912\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538937; batch adversarial loss: 0.607020\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564272; batch adversarial loss: 0.531813\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519226; batch adversarial loss: 0.529178\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523449; batch adversarial loss: 0.577767\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476020; batch adversarial loss: 0.585504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484716; batch adversarial loss: 0.503003\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478123; batch adversarial loss: 0.553029\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465682; batch adversarial loss: 0.535084\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547119; batch adversarial loss: 0.561020\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462088; batch adversarial loss: 0.603488\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462420; batch adversarial loss: 0.590421\n",
      "epoch 21; iter: 0; batch classifier loss: 0.564902; batch adversarial loss: 0.561179\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522236; batch adversarial loss: 0.621441\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481313; batch adversarial loss: 0.516374\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495333; batch adversarial loss: 0.542445\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474195; batch adversarial loss: 0.551121\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455536; batch adversarial loss: 0.572288\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493485; batch adversarial loss: 0.550834\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459176; batch adversarial loss: 0.532107\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436497; batch adversarial loss: 0.521680\n",
      "epoch 30; iter: 0; batch classifier loss: 0.500410; batch adversarial loss: 0.537858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416974; batch adversarial loss: 0.516278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430142; batch adversarial loss: 0.553375\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494528; batch adversarial loss: 0.629726\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455383; batch adversarial loss: 0.538595\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479172; batch adversarial loss: 0.599639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480421; batch adversarial loss: 0.513980\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465126; batch adversarial loss: 0.571815\n",
      "epoch 38; iter: 0; batch classifier loss: 0.384014; batch adversarial loss: 0.518074\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513163; batch adversarial loss: 0.466655\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459413; batch adversarial loss: 0.560830\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398347; batch adversarial loss: 0.560749\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483360; batch adversarial loss: 0.677634\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474163; batch adversarial loss: 0.605176\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453186; batch adversarial loss: 0.501974\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422463; batch adversarial loss: 0.554689\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449043; batch adversarial loss: 0.535190\n",
      "epoch 47; iter: 0; batch classifier loss: 0.573677; batch adversarial loss: 0.571560\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420411; batch adversarial loss: 0.553108\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419213; batch adversarial loss: 0.586634\n",
      "epoch 50; iter: 0; batch classifier loss: 0.397258; batch adversarial loss: 0.542598\n",
      "epoch 51; iter: 0; batch classifier loss: 0.474438; batch adversarial loss: 0.562184\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392935; batch adversarial loss: 0.569620\n",
      "epoch 53; iter: 0; batch classifier loss: 0.519166; batch adversarial loss: 0.604222\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481284; batch adversarial loss: 0.627362\n",
      "epoch 55; iter: 0; batch classifier loss: 0.392264; batch adversarial loss: 0.552039\n",
      "epoch 56; iter: 0; batch classifier loss: 0.407291; batch adversarial loss: 0.500817\n",
      "epoch 57; iter: 0; batch classifier loss: 0.461137; batch adversarial loss: 0.578671\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462311; batch adversarial loss: 0.517898\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375296; batch adversarial loss: 0.615227\n",
      "epoch 60; iter: 0; batch classifier loss: 0.342078; batch adversarial loss: 0.551512\n",
      "epoch 61; iter: 0; batch classifier loss: 0.535119; batch adversarial loss: 0.583079\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406490; batch adversarial loss: 0.624585\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387123; batch adversarial loss: 0.563389\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420233; batch adversarial loss: 0.476647\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391398; batch adversarial loss: 0.476629\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427247; batch adversarial loss: 0.571069\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404240; batch adversarial loss: 0.528239\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443447; batch adversarial loss: 0.614098\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403458; batch adversarial loss: 0.604768\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404652; batch adversarial loss: 0.630201\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369857; batch adversarial loss: 0.527448\n",
      "epoch 72; iter: 0; batch classifier loss: 0.420897; batch adversarial loss: 0.561537\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393546; batch adversarial loss: 0.527242\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393531; batch adversarial loss: 0.572505\n",
      "epoch 75; iter: 0; batch classifier loss: 0.481205; batch adversarial loss: 0.544417\n",
      "epoch 76; iter: 0; batch classifier loss: 0.447992; batch adversarial loss: 0.580603\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420159; batch adversarial loss: 0.517542\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382151; batch adversarial loss: 0.580002\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408791; batch adversarial loss: 0.562837\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435626; batch adversarial loss: 0.526447\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406165; batch adversarial loss: 0.536414\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447620; batch adversarial loss: 0.508600\n",
      "epoch 83; iter: 0; batch classifier loss: 0.436525; batch adversarial loss: 0.554533\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383534; batch adversarial loss: 0.658166\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406350; batch adversarial loss: 0.580641\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421069; batch adversarial loss: 0.561500\n",
      "epoch 87; iter: 0; batch classifier loss: 0.457213; batch adversarial loss: 0.519090\n",
      "epoch 88; iter: 0; batch classifier loss: 0.461072; batch adversarial loss: 0.563349\n",
      "epoch 89; iter: 0; batch classifier loss: 0.302308; batch adversarial loss: 0.642539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.427796; batch adversarial loss: 0.606243\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383852; batch adversarial loss: 0.609053\n",
      "epoch 92; iter: 0; batch classifier loss: 0.446177; batch adversarial loss: 0.508881\n",
      "epoch 93; iter: 0; batch classifier loss: 0.327481; batch adversarial loss: 0.508967\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425768; batch adversarial loss: 0.458359\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412565; batch adversarial loss: 0.546360\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368569; batch adversarial loss: 0.572525\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386740; batch adversarial loss: 0.536236\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358446; batch adversarial loss: 0.579270\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363061; batch adversarial loss: 0.535422\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383142; batch adversarial loss: 0.581594\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393046; batch adversarial loss: 0.589911\n",
      "epoch 102; iter: 0; batch classifier loss: 0.444515; batch adversarial loss: 0.519309\n",
      "epoch 103; iter: 0; batch classifier loss: 0.347371; batch adversarial loss: 0.544222\n",
      "epoch 104; iter: 0; batch classifier loss: 0.486802; batch adversarial loss: 0.589193\n",
      "epoch 105; iter: 0; batch classifier loss: 0.440265; batch adversarial loss: 0.518723\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394074; batch adversarial loss: 0.544956\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412972; batch adversarial loss: 0.519068\n",
      "epoch 108; iter: 0; batch classifier loss: 0.374202; batch adversarial loss: 0.544871\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402387; batch adversarial loss: 0.624598\n",
      "epoch 110; iter: 0; batch classifier loss: 0.308802; batch adversarial loss: 0.642054\n",
      "epoch 111; iter: 0; batch classifier loss: 0.299468; batch adversarial loss: 0.500785\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360849; batch adversarial loss: 0.632981\n",
      "epoch 113; iter: 0; batch classifier loss: 0.416262; batch adversarial loss: 0.527246\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433294; batch adversarial loss: 0.544850\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366437; batch adversarial loss: 0.535796\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427209; batch adversarial loss: 0.500997\n",
      "epoch 117; iter: 0; batch classifier loss: 0.441236; batch adversarial loss: 0.528164\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392941; batch adversarial loss: 0.517530\n",
      "epoch 119; iter: 0; batch classifier loss: 0.455670; batch adversarial loss: 0.526883\n",
      "epoch 120; iter: 0; batch classifier loss: 0.428337; batch adversarial loss: 0.500584\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398703; batch adversarial loss: 0.589508\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384351; batch adversarial loss: 0.545872\n",
      "epoch 123; iter: 0; batch classifier loss: 0.417704; batch adversarial loss: 0.561975\n",
      "epoch 124; iter: 0; batch classifier loss: 0.332836; batch adversarial loss: 0.580258\n",
      "epoch 125; iter: 0; batch classifier loss: 0.388921; batch adversarial loss: 0.597295\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344945; batch adversarial loss: 0.615875\n",
      "epoch 127; iter: 0; batch classifier loss: 0.403501; batch adversarial loss: 0.606748\n",
      "epoch 128; iter: 0; batch classifier loss: 0.458596; batch adversarial loss: 0.562424\n",
      "epoch 129; iter: 0; batch classifier loss: 0.432721; batch adversarial loss: 0.518616\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394540; batch adversarial loss: 0.482639\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375950; batch adversarial loss: 0.553592\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351389; batch adversarial loss: 0.562522\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347774; batch adversarial loss: 0.561691\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333459; batch adversarial loss: 0.535691\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376993; batch adversarial loss: 0.553981\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357032; batch adversarial loss: 0.571912\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374594; batch adversarial loss: 0.518742\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394853; batch adversarial loss: 0.535703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.300152; batch adversarial loss: 0.597060\n",
      "epoch 140; iter: 0; batch classifier loss: 0.323119; batch adversarial loss: 0.562063\n",
      "epoch 141; iter: 0; batch classifier loss: 0.384887; batch adversarial loss: 0.535511\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354042; batch adversarial loss: 0.641367\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361651; batch adversarial loss: 0.553674\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367290; batch adversarial loss: 0.492491\n",
      "epoch 145; iter: 0; batch classifier loss: 0.446066; batch adversarial loss: 0.553769\n",
      "epoch 146; iter: 0; batch classifier loss: 0.312756; batch adversarial loss: 0.562463\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368210; batch adversarial loss: 0.544693\n",
      "epoch 148; iter: 0; batch classifier loss: 0.415973; batch adversarial loss: 0.509507\n",
      "epoch 149; iter: 0; batch classifier loss: 0.456653; batch adversarial loss: 0.553521\n",
      "epoch 150; iter: 0; batch classifier loss: 0.330263; batch adversarial loss: 0.500815\n",
      "epoch 151; iter: 0; batch classifier loss: 0.396147; batch adversarial loss: 0.518500\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385110; batch adversarial loss: 0.483410\n",
      "epoch 153; iter: 0; batch classifier loss: 0.297990; batch adversarial loss: 0.456513\n",
      "epoch 154; iter: 0; batch classifier loss: 0.375141; batch adversarial loss: 0.579880\n",
      "epoch 155; iter: 0; batch classifier loss: 0.352982; batch adversarial loss: 0.580429\n",
      "epoch 156; iter: 0; batch classifier loss: 0.353085; batch adversarial loss: 0.553275\n",
      "epoch 157; iter: 0; batch classifier loss: 0.288424; batch adversarial loss: 0.597491\n",
      "epoch 158; iter: 0; batch classifier loss: 0.422318; batch adversarial loss: 0.509482\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346384; batch adversarial loss: 0.517588\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353022; batch adversarial loss: 0.527470\n",
      "epoch 161; iter: 0; batch classifier loss: 0.364008; batch adversarial loss: 0.553667\n",
      "epoch 162; iter: 0; batch classifier loss: 0.339589; batch adversarial loss: 0.544032\n",
      "epoch 163; iter: 0; batch classifier loss: 0.462016; batch adversarial loss: 0.580512\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361182; batch adversarial loss: 0.518050\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399133; batch adversarial loss: 0.554062\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358155; batch adversarial loss: 0.621479\n",
      "epoch 167; iter: 0; batch classifier loss: 0.377312; batch adversarial loss: 0.598401\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390348; batch adversarial loss: 0.589166\n",
      "epoch 169; iter: 0; batch classifier loss: 0.303538; batch adversarial loss: 0.578248\n",
      "epoch 170; iter: 0; batch classifier loss: 0.391259; batch adversarial loss: 0.499276\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359588; batch adversarial loss: 0.572461\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360069; batch adversarial loss: 0.569350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.422435; batch adversarial loss: 0.553951\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369905; batch adversarial loss: 0.588663\n",
      "epoch 175; iter: 0; batch classifier loss: 0.426704; batch adversarial loss: 0.537093\n",
      "epoch 176; iter: 0; batch classifier loss: 0.285721; batch adversarial loss: 0.613547\n",
      "epoch 177; iter: 0; batch classifier loss: 0.440911; batch adversarial loss: 0.545480\n",
      "epoch 178; iter: 0; batch classifier loss: 0.419792; batch adversarial loss: 0.562132\n",
      "epoch 179; iter: 0; batch classifier loss: 0.345619; batch adversarial loss: 0.536629\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362102; batch adversarial loss: 0.597244\n",
      "epoch 181; iter: 0; batch classifier loss: 0.435455; batch adversarial loss: 0.588584\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352535; batch adversarial loss: 0.510301\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366214; batch adversarial loss: 0.562766\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357255; batch adversarial loss: 0.606143\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371211; batch adversarial loss: 0.536126\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375730; batch adversarial loss: 0.632391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187; iter: 0; batch classifier loss: 0.284945; batch adversarial loss: 0.474755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.388997; batch adversarial loss: 0.527115\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367507; batch adversarial loss: 0.579888\n",
      "epoch 190; iter: 0; batch classifier loss: 0.374717; batch adversarial loss: 0.570851\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372691; batch adversarial loss: 0.500602\n",
      "epoch 192; iter: 0; batch classifier loss: 0.265055; batch adversarial loss: 0.518383\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362244; batch adversarial loss: 0.545279\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314493; batch adversarial loss: 0.677597\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363244; batch adversarial loss: 0.570172\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394247; batch adversarial loss: 0.500198\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313284; batch adversarial loss: 0.535777\n",
      "epoch 198; iter: 0; batch classifier loss: 0.315493; batch adversarial loss: 0.562335\n",
      "epoch 199; iter: 0; batch classifier loss: 0.294359; batch adversarial loss: 0.482372\n",
      "epoch 0; iter: 0; batch classifier loss: 0.744249; batch adversarial loss: 0.696982\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580308; batch adversarial loss: 0.697514\n",
      "epoch 2; iter: 0; batch classifier loss: 0.534636; batch adversarial loss: 0.657340\n",
      "epoch 3; iter: 0; batch classifier loss: 0.505078; batch adversarial loss: 0.618899\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538559; batch adversarial loss: 0.600652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524899; batch adversarial loss: 0.588020\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575105; batch adversarial loss: 0.609339\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559827; batch adversarial loss: 0.587225\n",
      "epoch 8; iter: 0; batch classifier loss: 0.548951; batch adversarial loss: 0.574809\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567497; batch adversarial loss: 0.620081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506662; batch adversarial loss: 0.570098\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465540; batch adversarial loss: 0.562895\n",
      "epoch 12; iter: 0; batch classifier loss: 0.623455; batch adversarial loss: 0.628365\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513285; batch adversarial loss: 0.658417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.653523; batch adversarial loss: 0.593838\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520506; batch adversarial loss: 0.616918\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529128; batch adversarial loss: 0.572213\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498161; batch adversarial loss: 0.510746\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476198; batch adversarial loss: 0.534435\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514995; batch adversarial loss: 0.555219\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453092; batch adversarial loss: 0.528385\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492082; batch adversarial loss: 0.539213\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473049; batch adversarial loss: 0.530253\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521071; batch adversarial loss: 0.597280\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400199; batch adversarial loss: 0.567749\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457353; batch adversarial loss: 0.507589\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425864; batch adversarial loss: 0.583254\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472796; batch adversarial loss: 0.522485\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478453; batch adversarial loss: 0.499634\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413986; batch adversarial loss: 0.498168\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460160; batch adversarial loss: 0.531964\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483819; batch adversarial loss: 0.513964\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468161; batch adversarial loss: 0.512920\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470022; batch adversarial loss: 0.476436\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453201; batch adversarial loss: 0.509197\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436148; batch adversarial loss: 0.527654\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368336; batch adversarial loss: 0.501063\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472706; batch adversarial loss: 0.632497\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439597; batch adversarial loss: 0.536916\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405731; batch adversarial loss: 0.527601\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416906; batch adversarial loss: 0.597618\n",
      "epoch 41; iter: 0; batch classifier loss: 0.503234; batch adversarial loss: 0.553599\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383419; batch adversarial loss: 0.590785\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386981; batch adversarial loss: 0.623820\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477679; batch adversarial loss: 0.552540\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489626; batch adversarial loss: 0.625320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396679; batch adversarial loss: 0.571089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.369620; batch adversarial loss: 0.544641\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421682; batch adversarial loss: 0.581261\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408044; batch adversarial loss: 0.499577\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388979; batch adversarial loss: 0.562592\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481173; batch adversarial loss: 0.516812\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430849; batch adversarial loss: 0.544811\n",
      "epoch 53; iter: 0; batch classifier loss: 0.380086; batch adversarial loss: 0.542554\n",
      "epoch 54; iter: 0; batch classifier loss: 0.466766; batch adversarial loss: 0.616130\n",
      "epoch 55; iter: 0; batch classifier loss: 0.355013; batch adversarial loss: 0.554169\n",
      "epoch 56; iter: 0; batch classifier loss: 0.347257; batch adversarial loss: 0.436293\n",
      "epoch 57; iter: 0; batch classifier loss: 0.486560; batch adversarial loss: 0.599461\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403134; batch adversarial loss: 0.481068\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424318; batch adversarial loss: 0.572832\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385500; batch adversarial loss: 0.508936\n",
      "epoch 61; iter: 0; batch classifier loss: 0.363669; batch adversarial loss: 0.589749\n",
      "epoch 62; iter: 0; batch classifier loss: 0.345162; batch adversarial loss: 0.517816\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406446; batch adversarial loss: 0.559505\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489022; batch adversarial loss: 0.500020\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436619; batch adversarial loss: 0.505707\n",
      "epoch 66; iter: 0; batch classifier loss: 0.465579; batch adversarial loss: 0.559674\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365666; batch adversarial loss: 0.508806\n",
      "epoch 68; iter: 0; batch classifier loss: 0.489233; batch adversarial loss: 0.506347\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398352; batch adversarial loss: 0.509484\n",
      "epoch 70; iter: 0; batch classifier loss: 0.442183; batch adversarial loss: 0.552841\n",
      "epoch 71; iter: 0; batch classifier loss: 0.430835; batch adversarial loss: 0.544387\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424790; batch adversarial loss: 0.516725\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379878; batch adversarial loss: 0.528510\n",
      "epoch 74; iter: 0; batch classifier loss: 0.328793; batch adversarial loss: 0.578121\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346632; batch adversarial loss: 0.553409\n",
      "epoch 76; iter: 0; batch classifier loss: 0.353042; batch adversarial loss: 0.522995\n",
      "epoch 77; iter: 0; batch classifier loss: 0.347593; batch adversarial loss: 0.491449\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438615; batch adversarial loss: 0.632995\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402675; batch adversarial loss: 0.543015\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407833; batch adversarial loss: 0.562177\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360490; batch adversarial loss: 0.538236\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358938; batch adversarial loss: 0.635800\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388358; batch adversarial loss: 0.525693\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355252; batch adversarial loss: 0.491445\n",
      "epoch 85; iter: 0; batch classifier loss: 0.379638; batch adversarial loss: 0.604727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.415858; batch adversarial loss: 0.518027\n",
      "epoch 87; iter: 0; batch classifier loss: 0.317551; batch adversarial loss: 0.537576\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394935; batch adversarial loss: 0.581449\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384543; batch adversarial loss: 0.546870\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368684; batch adversarial loss: 0.481228\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361745; batch adversarial loss: 0.543934\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360651; batch adversarial loss: 0.505392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410294; batch adversarial loss: 0.561650\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419080; batch adversarial loss: 0.517002\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359645; batch adversarial loss: 0.605423\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355569; batch adversarial loss: 0.536459\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402541; batch adversarial loss: 0.545525\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377615; batch adversarial loss: 0.526256\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332618; batch adversarial loss: 0.598967\n",
      "epoch 100; iter: 0; batch classifier loss: 0.340822; batch adversarial loss: 0.599035\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353395; batch adversarial loss: 0.572957\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326914; batch adversarial loss: 0.561245\n",
      "epoch 103; iter: 0; batch classifier loss: 0.317043; batch adversarial loss: 0.570611\n",
      "epoch 104; iter: 0; batch classifier loss: 0.419028; batch adversarial loss: 0.481403\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358634; batch adversarial loss: 0.530177\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395734; batch adversarial loss: 0.509099\n",
      "epoch 107; iter: 0; batch classifier loss: 0.336625; batch adversarial loss: 0.517032\n",
      "epoch 108; iter: 0; batch classifier loss: 0.478656; batch adversarial loss: 0.571434\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375497; batch adversarial loss: 0.535615\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390253; batch adversarial loss: 0.624984\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369412; batch adversarial loss: 0.508321\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391791; batch adversarial loss: 0.517127\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379947; batch adversarial loss: 0.598862\n",
      "epoch 114; iter: 0; batch classifier loss: 0.432929; batch adversarial loss: 0.564408\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363357; batch adversarial loss: 0.455576\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343668; batch adversarial loss: 0.554659\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332743; batch adversarial loss: 0.609436\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360775; batch adversarial loss: 0.607511\n",
      "epoch 119; iter: 0; batch classifier loss: 0.355409; batch adversarial loss: 0.498756\n",
      "epoch 120; iter: 0; batch classifier loss: 0.310742; batch adversarial loss: 0.618196\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376955; batch adversarial loss: 0.589142\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379886; batch adversarial loss: 0.546843\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348650; batch adversarial loss: 0.552503\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377549; batch adversarial loss: 0.580903\n",
      "epoch 125; iter: 0; batch classifier loss: 0.431604; batch adversarial loss: 0.535459\n",
      "epoch 126; iter: 0; batch classifier loss: 0.408397; batch adversarial loss: 0.498275\n",
      "epoch 127; iter: 0; batch classifier loss: 0.403523; batch adversarial loss: 0.581775\n",
      "epoch 128; iter: 0; batch classifier loss: 0.394395; batch adversarial loss: 0.568102\n",
      "epoch 129; iter: 0; batch classifier loss: 0.332492; batch adversarial loss: 0.489211\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359217; batch adversarial loss: 0.535810\n",
      "epoch 131; iter: 0; batch classifier loss: 0.320112; batch adversarial loss: 0.490303\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368640; batch adversarial loss: 0.471045\n",
      "epoch 133; iter: 0; batch classifier loss: 0.488076; batch adversarial loss: 0.642996\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343629; batch adversarial loss: 0.525390\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394180; batch adversarial loss: 0.506067\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366980; batch adversarial loss: 0.517524\n",
      "epoch 137; iter: 0; batch classifier loss: 0.387308; batch adversarial loss: 0.527256\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309374; batch adversarial loss: 0.570244\n",
      "epoch 139; iter: 0; batch classifier loss: 0.470687; batch adversarial loss: 0.564405\n",
      "epoch 140; iter: 0; batch classifier loss: 0.445365; batch adversarial loss: 0.534469\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364576; batch adversarial loss: 0.453921\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364084; batch adversarial loss: 0.555847\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380165; batch adversarial loss: 0.499899\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358125; batch adversarial loss: 0.600878\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347847; batch adversarial loss: 0.452868\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375312; batch adversarial loss: 0.545648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400049; batch adversarial loss: 0.534755\n",
      "epoch 148; iter: 0; batch classifier loss: 0.333492; batch adversarial loss: 0.542519\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349507; batch adversarial loss: 0.544913\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325615; batch adversarial loss: 0.507377\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382341; batch adversarial loss: 0.581481\n",
      "epoch 152; iter: 0; batch classifier loss: 0.440634; batch adversarial loss: 0.524844\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367824; batch adversarial loss: 0.497068\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365865; batch adversarial loss: 0.534361\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349623; batch adversarial loss: 0.581811\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371025; batch adversarial loss: 0.564689\n",
      "epoch 157; iter: 0; batch classifier loss: 0.307894; batch adversarial loss: 0.513624\n",
      "epoch 158; iter: 0; batch classifier loss: 0.385046; batch adversarial loss: 0.582408\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353029; batch adversarial loss: 0.599594\n",
      "epoch 160; iter: 0; batch classifier loss: 0.280800; batch adversarial loss: 0.614904\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363432; batch adversarial loss: 0.534955\n",
      "epoch 162; iter: 0; batch classifier loss: 0.281372; batch adversarial loss: 0.534963\n",
      "epoch 163; iter: 0; batch classifier loss: 0.376014; batch adversarial loss: 0.542315\n",
      "epoch 164; iter: 0; batch classifier loss: 0.481930; batch adversarial loss: 0.514609\n",
      "epoch 165; iter: 0; batch classifier loss: 0.265563; batch adversarial loss: 0.443998\n",
      "epoch 166; iter: 0; batch classifier loss: 0.391684; batch adversarial loss: 0.678678\n",
      "epoch 167; iter: 0; batch classifier loss: 0.315775; batch adversarial loss: 0.605669\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364740; batch adversarial loss: 0.533548\n",
      "epoch 169; iter: 0; batch classifier loss: 0.322422; batch adversarial loss: 0.561331\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318580; batch adversarial loss: 0.518222\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295560; batch adversarial loss: 0.480562\n",
      "epoch 172; iter: 0; batch classifier loss: 0.347857; batch adversarial loss: 0.654330\n",
      "epoch 173; iter: 0; batch classifier loss: 0.415408; batch adversarial loss: 0.525771\n",
      "epoch 174; iter: 0; batch classifier loss: 0.294168; batch adversarial loss: 0.600818\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378011; batch adversarial loss: 0.518065\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340572; batch adversarial loss: 0.541657\n",
      "epoch 177; iter: 0; batch classifier loss: 0.369396; batch adversarial loss: 0.544372\n",
      "epoch 178; iter: 0; batch classifier loss: 0.297437; batch adversarial loss: 0.592358\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306415; batch adversarial loss: 0.535638\n",
      "epoch 180; iter: 0; batch classifier loss: 0.440654; batch adversarial loss: 0.502197\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362918; batch adversarial loss: 0.614914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.285408; batch adversarial loss: 0.545393\n",
      "epoch 183; iter: 0; batch classifier loss: 0.434971; batch adversarial loss: 0.481548\n",
      "epoch 184; iter: 0; batch classifier loss: 0.400947; batch adversarial loss: 0.536103\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397232; batch adversarial loss: 0.631748\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379152; batch adversarial loss: 0.561329\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332570; batch adversarial loss: 0.598850\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348221; batch adversarial loss: 0.582663\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339258; batch adversarial loss: 0.471522\n",
      "epoch 190; iter: 0; batch classifier loss: 0.405124; batch adversarial loss: 0.588708\n",
      "epoch 191; iter: 0; batch classifier loss: 0.301792; batch adversarial loss: 0.514924\n",
      "epoch 192; iter: 0; batch classifier loss: 0.374193; batch adversarial loss: 0.492465\n",
      "epoch 193; iter: 0; batch classifier loss: 0.324383; batch adversarial loss: 0.572024\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392008; batch adversarial loss: 0.562571\n",
      "epoch 195; iter: 0; batch classifier loss: 0.351571; batch adversarial loss: 0.535208\n",
      "epoch 196; iter: 0; batch classifier loss: 0.416080; batch adversarial loss: 0.533208\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.565576\n",
      "epoch 198; iter: 0; batch classifier loss: 0.283071; batch adversarial loss: 0.642853\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386811; batch adversarial loss: 0.565258\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685601; batch adversarial loss: 0.641441\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551079; batch adversarial loss: 0.639927\n",
      "epoch 2; iter: 0; batch classifier loss: 0.653939; batch adversarial loss: 0.620765\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538186; batch adversarial loss: 0.635989\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587503; batch adversarial loss: 0.647955\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578993; batch adversarial loss: 0.603264\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577047; batch adversarial loss: 0.658611\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513443; batch adversarial loss: 0.609715\n",
      "epoch 8; iter: 0; batch classifier loss: 0.635855; batch adversarial loss: 0.610255\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470765; batch adversarial loss: 0.640724\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544910; batch adversarial loss: 0.611059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.572676; batch adversarial loss: 0.579271\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556684; batch adversarial loss: 0.585617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476266; batch adversarial loss: 0.580496\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502268; batch adversarial loss: 0.616912\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502165; batch adversarial loss: 0.601267\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489023; batch adversarial loss: 0.606282\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559666; batch adversarial loss: 0.576345\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498154; batch adversarial loss: 0.540626\n",
      "epoch 19; iter: 0; batch classifier loss: 0.571683; batch adversarial loss: 0.563506\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527229; batch adversarial loss: 0.528255\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436448; batch adversarial loss: 0.558260\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427891; batch adversarial loss: 0.469417\n",
      "epoch 23; iter: 0; batch classifier loss: 0.402100; batch adversarial loss: 0.547565\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473419; batch adversarial loss: 0.499009\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485593; batch adversarial loss: 0.514459\n",
      "epoch 26; iter: 0; batch classifier loss: 0.422338; batch adversarial loss: 0.529956\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440148; batch adversarial loss: 0.528937\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450786; batch adversarial loss: 0.528411\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514947; batch adversarial loss: 0.561437\n",
      "epoch 30; iter: 0; batch classifier loss: 0.527750; batch adversarial loss: 0.545835\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435121; batch adversarial loss: 0.571631\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473031; batch adversarial loss: 0.536889\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452348; batch adversarial loss: 0.475892\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470423; batch adversarial loss: 0.545781\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459930; batch adversarial loss: 0.491746\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483134; batch adversarial loss: 0.570549\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475400; batch adversarial loss: 0.572008\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408851; batch adversarial loss: 0.524913\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453824; batch adversarial loss: 0.481836\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416485; batch adversarial loss: 0.470634\n",
      "epoch 41; iter: 0; batch classifier loss: 0.480005; batch adversarial loss: 0.498679\n",
      "epoch 42; iter: 0; batch classifier loss: 0.513335; batch adversarial loss: 0.578746\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416690; batch adversarial loss: 0.564695\n",
      "epoch 44; iter: 0; batch classifier loss: 0.567971; batch adversarial loss: 0.481458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432000; batch adversarial loss: 0.517725\n",
      "epoch 46; iter: 0; batch classifier loss: 0.507056; batch adversarial loss: 0.535867\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482963; batch adversarial loss: 0.499167\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367501; batch adversarial loss: 0.489111\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480464; batch adversarial loss: 0.544961\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445682; batch adversarial loss: 0.554560\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476252; batch adversarial loss: 0.525345\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372159; batch adversarial loss: 0.633774\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379406; batch adversarial loss: 0.616473\n",
      "epoch 54; iter: 0; batch classifier loss: 0.475470; batch adversarial loss: 0.507499\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411582; batch adversarial loss: 0.564247\n",
      "epoch 56; iter: 0; batch classifier loss: 0.502721; batch adversarial loss: 0.523570\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441087; batch adversarial loss: 0.546111\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430407; batch adversarial loss: 0.596206\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387938; batch adversarial loss: 0.545289\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439303; batch adversarial loss: 0.498872\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463247; batch adversarial loss: 0.510875\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398790; batch adversarial loss: 0.515991\n",
      "epoch 63; iter: 0; batch classifier loss: 0.363082; batch adversarial loss: 0.532104\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368238; batch adversarial loss: 0.579848\n",
      "epoch 65; iter: 0; batch classifier loss: 0.474406; batch adversarial loss: 0.552100\n",
      "epoch 66; iter: 0; batch classifier loss: 0.343728; batch adversarial loss: 0.518499\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385317; batch adversarial loss: 0.536443\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356447; batch adversarial loss: 0.482038\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449543; batch adversarial loss: 0.561360\n",
      "epoch 70; iter: 0; batch classifier loss: 0.439987; batch adversarial loss: 0.534552\n",
      "epoch 71; iter: 0; batch classifier loss: 0.536960; batch adversarial loss: 0.593716\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433620; batch adversarial loss: 0.580737\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438376; batch adversarial loss: 0.572083\n",
      "epoch 74; iter: 0; batch classifier loss: 0.509607; batch adversarial loss: 0.580073\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386736; batch adversarial loss: 0.590567\n",
      "epoch 76; iter: 0; batch classifier loss: 0.404261; batch adversarial loss: 0.516651\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416229; batch adversarial loss: 0.502972\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358082; batch adversarial loss: 0.598995\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380650; batch adversarial loss: 0.516142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.427182; batch adversarial loss: 0.527381\n",
      "epoch 81; iter: 0; batch classifier loss: 0.354978; batch adversarial loss: 0.573540\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378142; batch adversarial loss: 0.552544\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358757; batch adversarial loss: 0.552555\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446709; batch adversarial loss: 0.525191\n",
      "epoch 85; iter: 0; batch classifier loss: 0.316965; batch adversarial loss: 0.608464\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370063; batch adversarial loss: 0.488715\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427443; batch adversarial loss: 0.622642\n",
      "epoch 88; iter: 0; batch classifier loss: 0.403794; batch adversarial loss: 0.578345\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422441; batch adversarial loss: 0.612991\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391313; batch adversarial loss: 0.553287\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423535; batch adversarial loss: 0.582480\n",
      "epoch 92; iter: 0; batch classifier loss: 0.401854; batch adversarial loss: 0.498772\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383280; batch adversarial loss: 0.615867\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404562; batch adversarial loss: 0.536016\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375881; batch adversarial loss: 0.553802\n",
      "epoch 96; iter: 0; batch classifier loss: 0.318721; batch adversarial loss: 0.515720\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360526; batch adversarial loss: 0.599794\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370364; batch adversarial loss: 0.527037\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393209; batch adversarial loss: 0.496409\n",
      "epoch 100; iter: 0; batch classifier loss: 0.334882; batch adversarial loss: 0.500395\n",
      "epoch 101; iter: 0; batch classifier loss: 0.317708; batch adversarial loss: 0.581236\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391412; batch adversarial loss: 0.534213\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434006; batch adversarial loss: 0.597784\n",
      "epoch 104; iter: 0; batch classifier loss: 0.525029; batch adversarial loss: 0.525490\n",
      "epoch 105; iter: 0; batch classifier loss: 0.325974; batch adversarial loss: 0.525739\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412327; batch adversarial loss: 0.595197\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380885; batch adversarial loss: 0.543067\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388227; batch adversarial loss: 0.598144\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396728; batch adversarial loss: 0.562096\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408346; batch adversarial loss: 0.542808\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335375; batch adversarial loss: 0.524714\n",
      "epoch 112; iter: 0; batch classifier loss: 0.452179; batch adversarial loss: 0.488357\n",
      "epoch 113; iter: 0; batch classifier loss: 0.417097; batch adversarial loss: 0.472863\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383220; batch adversarial loss: 0.558923\n",
      "epoch 115; iter: 0; batch classifier loss: 0.324836; batch adversarial loss: 0.535852\n",
      "epoch 116; iter: 0; batch classifier loss: 0.310235; batch adversarial loss: 0.573307\n",
      "epoch 117; iter: 0; batch classifier loss: 0.454630; batch adversarial loss: 0.553534\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374359; batch adversarial loss: 0.507340\n",
      "epoch 119; iter: 0; batch classifier loss: 0.447932; batch adversarial loss: 0.600504\n",
      "epoch 120; iter: 0; batch classifier loss: 0.363174; batch adversarial loss: 0.542316\n",
      "epoch 121; iter: 0; batch classifier loss: 0.332266; batch adversarial loss: 0.534942\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378540; batch adversarial loss: 0.680075\n",
      "epoch 123; iter: 0; batch classifier loss: 0.403414; batch adversarial loss: 0.612109\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408243; batch adversarial loss: 0.610754\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415540; batch adversarial loss: 0.563325\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353255; batch adversarial loss: 0.546267\n",
      "epoch 127; iter: 0; batch classifier loss: 0.305794; batch adversarial loss: 0.534713\n",
      "epoch 128; iter: 0; batch classifier loss: 0.363143; batch adversarial loss: 0.568322\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388354; batch adversarial loss: 0.506778\n",
      "epoch 130; iter: 0; batch classifier loss: 0.436642; batch adversarial loss: 0.534611\n",
      "epoch 131; iter: 0; batch classifier loss: 0.404435; batch adversarial loss: 0.551651\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406221; batch adversarial loss: 0.451779\n",
      "epoch 133; iter: 0; batch classifier loss: 0.330153; batch adversarial loss: 0.518469\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344865; batch adversarial loss: 0.558764\n",
      "epoch 135; iter: 0; batch classifier loss: 0.358896; batch adversarial loss: 0.559251\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349028; batch adversarial loss: 0.504258\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385513; batch adversarial loss: 0.612961\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392585; batch adversarial loss: 0.518702\n",
      "epoch 139; iter: 0; batch classifier loss: 0.336907; batch adversarial loss: 0.540619\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384938; batch adversarial loss: 0.555110\n",
      "epoch 141; iter: 0; batch classifier loss: 0.296107; batch adversarial loss: 0.597784\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376006; batch adversarial loss: 0.474118\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406151; batch adversarial loss: 0.620106\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379651; batch adversarial loss: 0.582329\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403463; batch adversarial loss: 0.534885\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350254; batch adversarial loss: 0.607180\n",
      "epoch 147; iter: 0; batch classifier loss: 0.320541; batch adversarial loss: 0.542732\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366396; batch adversarial loss: 0.632567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.394335; batch adversarial loss: 0.590380\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368708; batch adversarial loss: 0.477935\n",
      "epoch 151; iter: 0; batch classifier loss: 0.282006; batch adversarial loss: 0.605312\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340578; batch adversarial loss: 0.513951\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343835; batch adversarial loss: 0.508561\n",
      "epoch 154; iter: 0; batch classifier loss: 0.367822; batch adversarial loss: 0.623833\n",
      "epoch 155; iter: 0; batch classifier loss: 0.338635; batch adversarial loss: 0.499272\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352862; batch adversarial loss: 0.516927\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357774; batch adversarial loss: 0.547142\n",
      "epoch 158; iter: 0; batch classifier loss: 0.298613; batch adversarial loss: 0.541947\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345470; batch adversarial loss: 0.553092\n",
      "epoch 160; iter: 0; batch classifier loss: 0.296635; batch adversarial loss: 0.572455\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318976; batch adversarial loss: 0.498924\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410377; batch adversarial loss: 0.543846\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367713; batch adversarial loss: 0.483569\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358954; batch adversarial loss: 0.505695\n",
      "epoch 165; iter: 0; batch classifier loss: 0.280388; batch adversarial loss: 0.526419\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373063; batch adversarial loss: 0.525699\n",
      "epoch 167; iter: 0; batch classifier loss: 0.426206; batch adversarial loss: 0.583414\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338819; batch adversarial loss: 0.497860\n",
      "epoch 169; iter: 0; batch classifier loss: 0.443826; batch adversarial loss: 0.589521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341920; batch adversarial loss: 0.509123\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332543; batch adversarial loss: 0.593619\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328769; batch adversarial loss: 0.511498\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380879; batch adversarial loss: 0.518057\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349044; batch adversarial loss: 0.514642\n",
      "epoch 175; iter: 0; batch classifier loss: 0.407455; batch adversarial loss: 0.497033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.445602; batch adversarial loss: 0.495620\n",
      "epoch 177; iter: 0; batch classifier loss: 0.323709; batch adversarial loss: 0.536242\n",
      "epoch 178; iter: 0; batch classifier loss: 0.315256; batch adversarial loss: 0.546657\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380103; batch adversarial loss: 0.527674\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342684; batch adversarial loss: 0.506761\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342756; batch adversarial loss: 0.561181\n",
      "epoch 182; iter: 0; batch classifier loss: 0.433798; batch adversarial loss: 0.649959\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346372; batch adversarial loss: 0.510736\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330266; batch adversarial loss: 0.586319\n",
      "epoch 185; iter: 0; batch classifier loss: 0.353801; batch adversarial loss: 0.553578\n",
      "epoch 186; iter: 0; batch classifier loss: 0.378210; batch adversarial loss: 0.482902\n",
      "epoch 187; iter: 0; batch classifier loss: 0.344525; batch adversarial loss: 0.623128\n",
      "epoch 188; iter: 0; batch classifier loss: 0.309353; batch adversarial loss: 0.520799\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369889; batch adversarial loss: 0.532918\n",
      "epoch 190; iter: 0; batch classifier loss: 0.348504; batch adversarial loss: 0.604567\n",
      "epoch 191; iter: 0; batch classifier loss: 0.330375; batch adversarial loss: 0.572060\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389973; batch adversarial loss: 0.492008\n",
      "epoch 193; iter: 0; batch classifier loss: 0.391550; batch adversarial loss: 0.605766\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359015; batch adversarial loss: 0.561124\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337330; batch adversarial loss: 0.550255\n",
      "epoch 196; iter: 0; batch classifier loss: 0.389715; batch adversarial loss: 0.601606\n",
      "epoch 197; iter: 0; batch classifier loss: 0.391613; batch adversarial loss: 0.560729\n",
      "epoch 198; iter: 0; batch classifier loss: 0.332998; batch adversarial loss: 0.559310\n",
      "epoch 199; iter: 0; batch classifier loss: 0.389567; batch adversarial loss: 0.569967\n",
      "epoch 0; iter: 0; batch classifier loss: 0.819875; batch adversarial loss: 0.833190\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572613; batch adversarial loss: 0.754995\n",
      "epoch 2; iter: 0; batch classifier loss: 0.559691; batch adversarial loss: 0.697529\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531526; batch adversarial loss: 0.681073\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601281; batch adversarial loss: 0.642327\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578072; batch adversarial loss: 0.643130\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575604; batch adversarial loss: 0.636022\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558059; batch adversarial loss: 0.638410\n",
      "epoch 8; iter: 0; batch classifier loss: 0.608123; batch adversarial loss: 0.591406\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543125; batch adversarial loss: 0.613431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.465969; batch adversarial loss: 0.568937\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430493; batch adversarial loss: 0.560048\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528017; batch adversarial loss: 0.522575\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564233; batch adversarial loss: 0.582510\n",
      "epoch 14; iter: 0; batch classifier loss: 0.455502; batch adversarial loss: 0.573053\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508289; batch adversarial loss: 0.561655\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564711; batch adversarial loss: 0.547750\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517150; batch adversarial loss: 0.506521\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534612; batch adversarial loss: 0.578064\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542083; batch adversarial loss: 0.586056\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476171; batch adversarial loss: 0.521928\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480864; batch adversarial loss: 0.501846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446232; batch adversarial loss: 0.584199\n",
      "epoch 23; iter: 0; batch classifier loss: 0.427224; batch adversarial loss: 0.552096\n",
      "epoch 24; iter: 0; batch classifier loss: 0.569504; batch adversarial loss: 0.575188\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525906; batch adversarial loss: 0.473538\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453002; batch adversarial loss: 0.573425\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466518; batch adversarial loss: 0.515270\n",
      "epoch 28; iter: 0; batch classifier loss: 0.410733; batch adversarial loss: 0.520305\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505439; batch adversarial loss: 0.499684\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485800; batch adversarial loss: 0.490993\n",
      "epoch 31; iter: 0; batch classifier loss: 0.385080; batch adversarial loss: 0.520288\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536463; batch adversarial loss: 0.609839\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466983; batch adversarial loss: 0.583187\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398590; batch adversarial loss: 0.648241\n",
      "epoch 35; iter: 0; batch classifier loss: 0.381851; batch adversarial loss: 0.527953\n",
      "epoch 36; iter: 0; batch classifier loss: 0.431054; batch adversarial loss: 0.530611\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454417; batch adversarial loss: 0.498608\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469392; batch adversarial loss: 0.563061\n",
      "epoch 39; iter: 0; batch classifier loss: 0.522797; batch adversarial loss: 0.512219\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435385; batch adversarial loss: 0.490956\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437236; batch adversarial loss: 0.580069\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419258; batch adversarial loss: 0.518000\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492603; batch adversarial loss: 0.562976\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394743; batch adversarial loss: 0.490564\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422969; batch adversarial loss: 0.545358\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459383; batch adversarial loss: 0.553482\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429161; batch adversarial loss: 0.500311\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428083; batch adversarial loss: 0.535870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455839; batch adversarial loss: 0.602200\n",
      "epoch 50; iter: 0; batch classifier loss: 0.523737; batch adversarial loss: 0.499639\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399375; batch adversarial loss: 0.663833\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439404; batch adversarial loss: 0.543834\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375334; batch adversarial loss: 0.607787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.459739; batch adversarial loss: 0.553646\n",
      "epoch 55; iter: 0; batch classifier loss: 0.375622; batch adversarial loss: 0.553564\n",
      "epoch 56; iter: 0; batch classifier loss: 0.480758; batch adversarial loss: 0.526702\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435319; batch adversarial loss: 0.525845\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434777; batch adversarial loss: 0.581338\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433339; batch adversarial loss: 0.544089\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420737; batch adversarial loss: 0.478871\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408809; batch adversarial loss: 0.564930\n",
      "epoch 62; iter: 0; batch classifier loss: 0.355080; batch adversarial loss: 0.527164\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431453; batch adversarial loss: 0.507997\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409389; batch adversarial loss: 0.545479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.349801; batch adversarial loss: 0.525403\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363423; batch adversarial loss: 0.564431\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431889; batch adversarial loss: 0.535379\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418115; batch adversarial loss: 0.599975\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407748; batch adversarial loss: 0.618571\n",
      "epoch 70; iter: 0; batch classifier loss: 0.373895; batch adversarial loss: 0.553865\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420751; batch adversarial loss: 0.508968\n",
      "epoch 72; iter: 0; batch classifier loss: 0.446207; batch adversarial loss: 0.591897\n",
      "epoch 73; iter: 0; batch classifier loss: 0.493449; batch adversarial loss: 0.515156\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354482; batch adversarial loss: 0.545987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.385046; batch adversarial loss: 0.574209\n",
      "epoch 76; iter: 0; batch classifier loss: 0.362087; batch adversarial loss: 0.572017\n",
      "epoch 77; iter: 0; batch classifier loss: 0.462932; batch adversarial loss: 0.581315\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379616; batch adversarial loss: 0.535515\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388380; batch adversarial loss: 0.470783\n",
      "epoch 80; iter: 0; batch classifier loss: 0.391955; batch adversarial loss: 0.581359\n",
      "epoch 81; iter: 0; batch classifier loss: 0.444530; batch adversarial loss: 0.498623\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407952; batch adversarial loss: 0.498216\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383904; batch adversarial loss: 0.609096\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378434; batch adversarial loss: 0.525934\n",
      "epoch 85; iter: 0; batch classifier loss: 0.448407; batch adversarial loss: 0.608490\n",
      "epoch 86; iter: 0; batch classifier loss: 0.438268; batch adversarial loss: 0.590985\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387549; batch adversarial loss: 0.507994\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395843; batch adversarial loss: 0.571959\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379235; batch adversarial loss: 0.535136\n",
      "epoch 90; iter: 0; batch classifier loss: 0.336698; batch adversarial loss: 0.533717\n",
      "epoch 91; iter: 0; batch classifier loss: 0.438002; batch adversarial loss: 0.526597\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372159; batch adversarial loss: 0.563017\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375668; batch adversarial loss: 0.534582\n",
      "epoch 94; iter: 0; batch classifier loss: 0.393920; batch adversarial loss: 0.543869\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380494; batch adversarial loss: 0.534047\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396758; batch adversarial loss: 0.535127\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415164; batch adversarial loss: 0.544275\n",
      "epoch 98; iter: 0; batch classifier loss: 0.430916; batch adversarial loss: 0.563877\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404708; batch adversarial loss: 0.579463\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352774; batch adversarial loss: 0.672754\n",
      "epoch 101; iter: 0; batch classifier loss: 0.317350; batch adversarial loss: 0.514488\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385413; batch adversarial loss: 0.571520\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399189; batch adversarial loss: 0.581596\n",
      "epoch 104; iter: 0; batch classifier loss: 0.334973; batch adversarial loss: 0.553029\n",
      "epoch 105; iter: 0; batch classifier loss: 0.388892; batch adversarial loss: 0.544593\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350069; batch adversarial loss: 0.600771\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350675; batch adversarial loss: 0.590028\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393704; batch adversarial loss: 0.570322\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385631; batch adversarial loss: 0.544755\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403612; batch adversarial loss: 0.646768\n",
      "epoch 111; iter: 0; batch classifier loss: 0.402318; batch adversarial loss: 0.519434\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384475; batch adversarial loss: 0.553142\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392278; batch adversarial loss: 0.588936\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392255; batch adversarial loss: 0.506551\n",
      "epoch 115; iter: 0; batch classifier loss: 0.299506; batch adversarial loss: 0.563324\n",
      "epoch 116; iter: 0; batch classifier loss: 0.315120; batch adversarial loss: 0.526450\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381679; batch adversarial loss: 0.507923\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378639; batch adversarial loss: 0.527478\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423567; batch adversarial loss: 0.489073\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373034; batch adversarial loss: 0.570960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378910; batch adversarial loss: 0.488677\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380554; batch adversarial loss: 0.527412\n",
      "epoch 123; iter: 0; batch classifier loss: 0.332014; batch adversarial loss: 0.525481\n",
      "epoch 124; iter: 0; batch classifier loss: 0.399604; batch adversarial loss: 0.507460\n",
      "epoch 125; iter: 0; batch classifier loss: 0.436700; batch adversarial loss: 0.518228\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334194; batch adversarial loss: 0.524472\n",
      "epoch 127; iter: 0; batch classifier loss: 0.318564; batch adversarial loss: 0.610713\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350135; batch adversarial loss: 0.498238\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403811; batch adversarial loss: 0.581444\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393722; batch adversarial loss: 0.581197\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438859; batch adversarial loss: 0.545391\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352968; batch adversarial loss: 0.571424\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341463; batch adversarial loss: 0.573454\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375675; batch adversarial loss: 0.563739\n",
      "epoch 135; iter: 0; batch classifier loss: 0.391167; batch adversarial loss: 0.479944\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406427; batch adversarial loss: 0.517586\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359853; batch adversarial loss: 0.610157\n",
      "epoch 138; iter: 0; batch classifier loss: 0.462190; batch adversarial loss: 0.572150\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349850; batch adversarial loss: 0.608666\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309482; batch adversarial loss: 0.534830\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338410; batch adversarial loss: 0.543859\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351393; batch adversarial loss: 0.498743\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350654; batch adversarial loss: 0.562918\n",
      "epoch 144; iter: 0; batch classifier loss: 0.444958; batch adversarial loss: 0.553890\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341460; batch adversarial loss: 0.526350\n",
      "epoch 146; iter: 0; batch classifier loss: 0.401664; batch adversarial loss: 0.525463\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334115; batch adversarial loss: 0.608742\n",
      "epoch 148; iter: 0; batch classifier loss: 0.337533; batch adversarial loss: 0.553488\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348347; batch adversarial loss: 0.570336\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353773; batch adversarial loss: 0.581316\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405226; batch adversarial loss: 0.535935\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335614; batch adversarial loss: 0.526208\n",
      "epoch 153; iter: 0; batch classifier loss: 0.345247; batch adversarial loss: 0.553318\n",
      "epoch 154; iter: 0; batch classifier loss: 0.447364; batch adversarial loss: 0.507051\n",
      "epoch 155; iter: 0; batch classifier loss: 0.348753; batch adversarial loss: 0.534276\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338484; batch adversarial loss: 0.533693\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392750; batch adversarial loss: 0.516743\n",
      "epoch 158; iter: 0; batch classifier loss: 0.351619; batch adversarial loss: 0.581356\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398287; batch adversarial loss: 0.517220\n",
      "epoch 160; iter: 0; batch classifier loss: 0.393079; batch adversarial loss: 0.506583\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357003; batch adversarial loss: 0.619038\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359476; batch adversarial loss: 0.580788\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325363; batch adversarial loss: 0.536315\n",
      "epoch 164; iter: 0; batch classifier loss: 0.406360; batch adversarial loss: 0.581387\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388689; batch adversarial loss: 0.581659\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357452; batch adversarial loss: 0.498645\n",
      "epoch 167; iter: 0; batch classifier loss: 0.351490; batch adversarial loss: 0.597261\n",
      "epoch 168; iter: 0; batch classifier loss: 0.321407; batch adversarial loss: 0.526677\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339792; batch adversarial loss: 0.561631\n",
      "epoch 170; iter: 0; batch classifier loss: 0.356500; batch adversarial loss: 0.581230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.375288; batch adversarial loss: 0.516099\n",
      "epoch 172; iter: 0; batch classifier loss: 0.419527; batch adversarial loss: 0.525276\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367578; batch adversarial loss: 0.536325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.385810; batch adversarial loss: 0.498085\n",
      "epoch 175; iter: 0; batch classifier loss: 0.289236; batch adversarial loss: 0.488356\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430850; batch adversarial loss: 0.479723\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387673; batch adversarial loss: 0.527337\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318340; batch adversarial loss: 0.525965\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406800; batch adversarial loss: 0.562298\n",
      "epoch 180; iter: 0; batch classifier loss: 0.466495; batch adversarial loss: 0.554733\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330053; batch adversarial loss: 0.639315\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383390; batch adversarial loss: 0.525978\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329545; batch adversarial loss: 0.582819\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328649; batch adversarial loss: 0.524745\n",
      "epoch 185; iter: 0; batch classifier loss: 0.407492; batch adversarial loss: 0.590946\n",
      "epoch 186; iter: 0; batch classifier loss: 0.366362; batch adversarial loss: 0.544217\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319534; batch adversarial loss: 0.564225\n",
      "epoch 188; iter: 0; batch classifier loss: 0.442407; batch adversarial loss: 0.579796\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341535; batch adversarial loss: 0.600170\n",
      "epoch 190; iter: 0; batch classifier loss: 0.405945; batch adversarial loss: 0.552476\n",
      "epoch 191; iter: 0; batch classifier loss: 0.413564; batch adversarial loss: 0.534990\n",
      "epoch 192; iter: 0; batch classifier loss: 0.439251; batch adversarial loss: 0.526372\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332760; batch adversarial loss: 0.563699\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344478; batch adversarial loss: 0.526164\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363255; batch adversarial loss: 0.507740\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359103; batch adversarial loss: 0.589439\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367160; batch adversarial loss: 0.601400\n",
      "epoch 198; iter: 0; batch classifier loss: 0.282455; batch adversarial loss: 0.441737\n",
      "epoch 199; iter: 0; batch classifier loss: 0.423917; batch adversarial loss: 0.498507\n",
      "epoch 0; iter: 0; batch classifier loss: 0.746851; batch adversarial loss: 0.530908\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627987; batch adversarial loss: 0.627883\n",
      "epoch 2; iter: 0; batch classifier loss: 0.658130; batch adversarial loss: 0.697053\n",
      "epoch 3; iter: 0; batch classifier loss: 0.525619; batch adversarial loss: 0.680082\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601773; batch adversarial loss: 0.611534\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531917; batch adversarial loss: 0.643767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569785; batch adversarial loss: 0.662577\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523645; batch adversarial loss: 0.583929\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578102; batch adversarial loss: 0.603525\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580616; batch adversarial loss: 0.609073\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576449; batch adversarial loss: 0.574912\n",
      "epoch 11; iter: 0; batch classifier loss: 0.415942; batch adversarial loss: 0.512422\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547384; batch adversarial loss: 0.578767\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472982; batch adversarial loss: 0.625614\n",
      "epoch 14; iter: 0; batch classifier loss: 0.577529; batch adversarial loss: 0.596121\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513568; batch adversarial loss: 0.565427\n",
      "epoch 16; iter: 0; batch classifier loss: 0.548549; batch adversarial loss: 0.612907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494687; batch adversarial loss: 0.544501\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495936; batch adversarial loss: 0.556390\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464478; batch adversarial loss: 0.584423\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506609; batch adversarial loss: 0.607923\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507998; batch adversarial loss: 0.540674\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456024; batch adversarial loss: 0.549226\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495284; batch adversarial loss: 0.605734\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421539; batch adversarial loss: 0.521458\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449980; batch adversarial loss: 0.575247\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457217; batch adversarial loss: 0.547529\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449376; batch adversarial loss: 0.593180\n",
      "epoch 28; iter: 0; batch classifier loss: 0.536581; batch adversarial loss: 0.552447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525927; batch adversarial loss: 0.548738\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414102; batch adversarial loss: 0.455633\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445982; batch adversarial loss: 0.529444\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461712; batch adversarial loss: 0.587969\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407035; batch adversarial loss: 0.579225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363418; batch adversarial loss: 0.619741\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474088; batch adversarial loss: 0.516365\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471289; batch adversarial loss: 0.552166\n",
      "epoch 37; iter: 0; batch classifier loss: 0.413810; batch adversarial loss: 0.527320\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497187; batch adversarial loss: 0.587727\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418680; batch adversarial loss: 0.612579\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463470; batch adversarial loss: 0.532395\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434195; batch adversarial loss: 0.509404\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372792; batch adversarial loss: 0.545091\n",
      "epoch 43; iter: 0; batch classifier loss: 0.472127; batch adversarial loss: 0.584902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426032; batch adversarial loss: 0.529184\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408442; batch adversarial loss: 0.510936\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432755; batch adversarial loss: 0.518860\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455755; batch adversarial loss: 0.510288\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452684; batch adversarial loss: 0.552043\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463449; batch adversarial loss: 0.537771\n",
      "epoch 50; iter: 0; batch classifier loss: 0.496005; batch adversarial loss: 0.577784\n",
      "epoch 51; iter: 0; batch classifier loss: 0.459905; batch adversarial loss: 0.544704\n",
      "epoch 52; iter: 0; batch classifier loss: 0.532781; batch adversarial loss: 0.578971\n",
      "epoch 53; iter: 0; batch classifier loss: 0.496217; batch adversarial loss: 0.535024\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400606; batch adversarial loss: 0.471858\n",
      "epoch 55; iter: 0; batch classifier loss: 0.346029; batch adversarial loss: 0.571704\n",
      "epoch 56; iter: 0; batch classifier loss: 0.323151; batch adversarial loss: 0.579334\n",
      "epoch 57; iter: 0; batch classifier loss: 0.345249; batch adversarial loss: 0.535285\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452889; batch adversarial loss: 0.588839\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442158; batch adversarial loss: 0.525294\n",
      "epoch 60; iter: 0; batch classifier loss: 0.520836; batch adversarial loss: 0.503063\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373051; batch adversarial loss: 0.559969\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389045; batch adversarial loss: 0.547062\n",
      "epoch 63; iter: 0; batch classifier loss: 0.486169; batch adversarial loss: 0.458537\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388486; batch adversarial loss: 0.493330\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380485; batch adversarial loss: 0.600882\n",
      "epoch 66; iter: 0; batch classifier loss: 0.393865; batch adversarial loss: 0.586978\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437042; batch adversarial loss: 0.536689\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423204; batch adversarial loss: 0.573366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.427114; batch adversarial loss: 0.595573\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407641; batch adversarial loss: 0.609110\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403846; batch adversarial loss: 0.595815\n",
      "epoch 72; iter: 0; batch classifier loss: 0.436111; batch adversarial loss: 0.581470\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437978; batch adversarial loss: 0.570352\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385192; batch adversarial loss: 0.526193\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449236; batch adversarial loss: 0.502625\n",
      "epoch 76; iter: 0; batch classifier loss: 0.332366; batch adversarial loss: 0.518461\n",
      "epoch 77; iter: 0; batch classifier loss: 0.447293; batch adversarial loss: 0.663676\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387414; batch adversarial loss: 0.519550\n",
      "epoch 79; iter: 0; batch classifier loss: 0.461649; batch adversarial loss: 0.562210\n",
      "epoch 80; iter: 0; batch classifier loss: 0.433912; batch adversarial loss: 0.642166\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405899; batch adversarial loss: 0.606440\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404958; batch adversarial loss: 0.553050\n",
      "epoch 83; iter: 0; batch classifier loss: 0.343097; batch adversarial loss: 0.553450\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411850; batch adversarial loss: 0.545540\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367602; batch adversarial loss: 0.658879\n",
      "epoch 86; iter: 0; batch classifier loss: 0.393988; batch adversarial loss: 0.563176\n",
      "epoch 87; iter: 0; batch classifier loss: 0.353309; batch adversarial loss: 0.657070\n",
      "epoch 88; iter: 0; batch classifier loss: 0.432689; batch adversarial loss: 0.563217\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391471; batch adversarial loss: 0.578893\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456203; batch adversarial loss: 0.510230\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374460; batch adversarial loss: 0.571820\n",
      "epoch 92; iter: 0; batch classifier loss: 0.445560; batch adversarial loss: 0.493015\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361600; batch adversarial loss: 0.492868\n",
      "epoch 94; iter: 0; batch classifier loss: 0.418174; batch adversarial loss: 0.528093\n",
      "epoch 95; iter: 0; batch classifier loss: 0.331330; batch adversarial loss: 0.716008\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341926; batch adversarial loss: 0.545316\n",
      "epoch 97; iter: 0; batch classifier loss: 0.354316; batch adversarial loss: 0.606458\n",
      "epoch 98; iter: 0; batch classifier loss: 0.374714; batch adversarial loss: 0.544822\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422131; batch adversarial loss: 0.529778\n",
      "epoch 100; iter: 0; batch classifier loss: 0.431720; batch adversarial loss: 0.527969\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409044; batch adversarial loss: 0.535777\n",
      "epoch 102; iter: 0; batch classifier loss: 0.406474; batch adversarial loss: 0.612498\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360070; batch adversarial loss: 0.645997\n",
      "epoch 104; iter: 0; batch classifier loss: 0.360219; batch adversarial loss: 0.529296\n",
      "epoch 105; iter: 0; batch classifier loss: 0.367524; batch adversarial loss: 0.553536\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372299; batch adversarial loss: 0.631825\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378078; batch adversarial loss: 0.513050\n",
      "epoch 108; iter: 0; batch classifier loss: 0.339046; batch adversarial loss: 0.628269\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406171; batch adversarial loss: 0.554873\n",
      "epoch 110; iter: 0; batch classifier loss: 0.292580; batch adversarial loss: 0.553418\n",
      "epoch 111; iter: 0; batch classifier loss: 0.336221; batch adversarial loss: 0.543527\n",
      "epoch 112; iter: 0; batch classifier loss: 0.303517; batch adversarial loss: 0.520071\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406813; batch adversarial loss: 0.503532\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382013; batch adversarial loss: 0.587396\n",
      "epoch 115; iter: 0; batch classifier loss: 0.392013; batch adversarial loss: 0.554664\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350559; batch adversarial loss: 0.499696\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346150; batch adversarial loss: 0.554942\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335224; batch adversarial loss: 0.511124\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379893; batch adversarial loss: 0.536097\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367430; batch adversarial loss: 0.611662\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419638; batch adversarial loss: 0.561023\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339952; batch adversarial loss: 0.528657\n",
      "epoch 123; iter: 0; batch classifier loss: 0.371332; batch adversarial loss: 0.510211\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410059; batch adversarial loss: 0.544626\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376401; batch adversarial loss: 0.606213\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346660; batch adversarial loss: 0.588321\n",
      "epoch 127; iter: 0; batch classifier loss: 0.318608; batch adversarial loss: 0.493904\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379160; batch adversarial loss: 0.553985\n",
      "epoch 129; iter: 0; batch classifier loss: 0.411445; batch adversarial loss: 0.647767\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387932; batch adversarial loss: 0.511755\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383249; batch adversarial loss: 0.561618\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358778; batch adversarial loss: 0.596690\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347316; batch adversarial loss: 0.539148\n",
      "epoch 134; iter: 0; batch classifier loss: 0.336992; batch adversarial loss: 0.554929\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352922; batch adversarial loss: 0.519910\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370015; batch adversarial loss: 0.613889\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377619; batch adversarial loss: 0.581577\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355051; batch adversarial loss: 0.576072\n",
      "epoch 139; iter: 0; batch classifier loss: 0.438641; batch adversarial loss: 0.518953\n",
      "epoch 140; iter: 0; batch classifier loss: 0.406057; batch adversarial loss: 0.578682\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380033; batch adversarial loss: 0.572174\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347982; batch adversarial loss: 0.493655\n",
      "epoch 143; iter: 0; batch classifier loss: 0.400110; batch adversarial loss: 0.639641\n",
      "epoch 144; iter: 0; batch classifier loss: 0.419948; batch adversarial loss: 0.553953\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351001; batch adversarial loss: 0.579820\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373396; batch adversarial loss: 0.509945\n",
      "epoch 147; iter: 0; batch classifier loss: 0.438312; batch adversarial loss: 0.546504\n",
      "epoch 148; iter: 0; batch classifier loss: 0.320217; batch adversarial loss: 0.578579\n",
      "epoch 149; iter: 0; batch classifier loss: 0.426563; batch adversarial loss: 0.527781\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347749; batch adversarial loss: 0.537799\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327481; batch adversarial loss: 0.607654\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384856; batch adversarial loss: 0.562217\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336169; batch adversarial loss: 0.588330\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319237; batch adversarial loss: 0.538098\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327447; batch adversarial loss: 0.612600\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321406; batch adversarial loss: 0.561745\n",
      "epoch 157; iter: 0; batch classifier loss: 0.300798; batch adversarial loss: 0.543858\n",
      "epoch 158; iter: 0; batch classifier loss: 0.357589; batch adversarial loss: 0.544398\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359877; batch adversarial loss: 0.486165\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332433; batch adversarial loss: 0.561520\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410839; batch adversarial loss: 0.597339\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400261; batch adversarial loss: 0.511418\n",
      "epoch 163; iter: 0; batch classifier loss: 0.353153; batch adversarial loss: 0.492960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350334; batch adversarial loss: 0.536270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.380574; batch adversarial loss: 0.568939\n",
      "epoch 166; iter: 0; batch classifier loss: 0.403902; batch adversarial loss: 0.484442\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353342; batch adversarial loss: 0.536589\n",
      "epoch 168; iter: 0; batch classifier loss: 0.413077; batch adversarial loss: 0.537901\n",
      "epoch 169; iter: 0; batch classifier loss: 0.395446; batch adversarial loss: 0.562593\n",
      "epoch 170; iter: 0; batch classifier loss: 0.409194; batch adversarial loss: 0.529360\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394750; batch adversarial loss: 0.570521\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342636; batch adversarial loss: 0.605739\n",
      "epoch 173; iter: 0; batch classifier loss: 0.275949; batch adversarial loss: 0.560539\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394920; batch adversarial loss: 0.535262\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313664; batch adversarial loss: 0.527513\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361777; batch adversarial loss: 0.528742\n",
      "epoch 177; iter: 0; batch classifier loss: 0.325420; batch adversarial loss: 0.519443\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369114; batch adversarial loss: 0.595716\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358019; batch adversarial loss: 0.553445\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389557; batch adversarial loss: 0.561477\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333500; batch adversarial loss: 0.554353\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351311; batch adversarial loss: 0.561646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331959; batch adversarial loss: 0.485051\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382703; batch adversarial loss: 0.579214\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376501; batch adversarial loss: 0.571401\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351322; batch adversarial loss: 0.580737\n",
      "epoch 187; iter: 0; batch classifier loss: 0.352312; batch adversarial loss: 0.545066\n",
      "epoch 188; iter: 0; batch classifier loss: 0.442186; batch adversarial loss: 0.544476\n",
      "epoch 189; iter: 0; batch classifier loss: 0.326981; batch adversarial loss: 0.580499\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361916; batch adversarial loss: 0.563419\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354730; batch adversarial loss: 0.555236\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375342; batch adversarial loss: 0.553974\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383193; batch adversarial loss: 0.544140\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308049; batch adversarial loss: 0.614281\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370160; batch adversarial loss: 0.553913\n",
      "epoch 196; iter: 0; batch classifier loss: 0.297381; batch adversarial loss: 0.570809\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313363; batch adversarial loss: 0.614078\n",
      "epoch 198; iter: 0; batch classifier loss: 0.399943; batch adversarial loss: 0.562986\n",
      "epoch 199; iter: 0; batch classifier loss: 0.346803; batch adversarial loss: 0.518524\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699035; batch adversarial loss: 0.547338\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603007; batch adversarial loss: 0.633717\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585811; batch adversarial loss: 0.667184\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558323; batch adversarial loss: 0.608724\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582844; batch adversarial loss: 0.642950\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594181; batch adversarial loss: 0.634717\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607949; batch adversarial loss: 0.626286\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557555; batch adversarial loss: 0.633347\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532373; batch adversarial loss: 0.600199\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539838; batch adversarial loss: 0.579472\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499314; batch adversarial loss: 0.565629\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502212; batch adversarial loss: 0.609979\n",
      "epoch 12; iter: 0; batch classifier loss: 0.603443; batch adversarial loss: 0.595192\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552818; batch adversarial loss: 0.588708\n",
      "epoch 14; iter: 0; batch classifier loss: 0.550044; batch adversarial loss: 0.581620\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512091; batch adversarial loss: 0.611923\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508506; batch adversarial loss: 0.574599\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451038; batch adversarial loss: 0.569980\n",
      "epoch 18; iter: 0; batch classifier loss: 0.470046; batch adversarial loss: 0.592322\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438464; batch adversarial loss: 0.533493\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510709; batch adversarial loss: 0.574432\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463885; batch adversarial loss: 0.566044\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516326; batch adversarial loss: 0.506127\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461351; batch adversarial loss: 0.595607\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491695; batch adversarial loss: 0.569059\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566629; batch adversarial loss: 0.657283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456728; batch adversarial loss: 0.509843\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484452; batch adversarial loss: 0.562362\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474519; batch adversarial loss: 0.520839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501304; batch adversarial loss: 0.477938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421621; batch adversarial loss: 0.575601\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452092; batch adversarial loss: 0.527166\n",
      "epoch 32; iter: 0; batch classifier loss: 0.386941; batch adversarial loss: 0.602457\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475837; batch adversarial loss: 0.619861\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475408; batch adversarial loss: 0.476328\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461933; batch adversarial loss: 0.502151\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422167; batch adversarial loss: 0.579315\n",
      "epoch 37; iter: 0; batch classifier loss: 0.506712; batch adversarial loss: 0.569385\n",
      "epoch 38; iter: 0; batch classifier loss: 0.413992; batch adversarial loss: 0.464676\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407563; batch adversarial loss: 0.615637\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468042; batch adversarial loss: 0.561176\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460009; batch adversarial loss: 0.529553\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498616; batch adversarial loss: 0.508463\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409445; batch adversarial loss: 0.581508\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446706; batch adversarial loss: 0.510166\n",
      "epoch 45; iter: 0; batch classifier loss: 0.503509; batch adversarial loss: 0.464890\n",
      "epoch 46; iter: 0; batch classifier loss: 0.395722; batch adversarial loss: 0.564553\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472104; batch adversarial loss: 0.534800\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387417; batch adversarial loss: 0.528193\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387371; batch adversarial loss: 0.613583\n",
      "epoch 50; iter: 0; batch classifier loss: 0.375028; batch adversarial loss: 0.499968\n",
      "epoch 51; iter: 0; batch classifier loss: 0.495705; batch adversarial loss: 0.586288\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390810; batch adversarial loss: 0.545271\n",
      "epoch 53; iter: 0; batch classifier loss: 0.494846; batch adversarial loss: 0.512138\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414333; batch adversarial loss: 0.602969\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443423; batch adversarial loss: 0.589931\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421453; batch adversarial loss: 0.499532\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454370; batch adversarial loss: 0.536819\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388918; batch adversarial loss: 0.587733\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414612; batch adversarial loss: 0.596369\n",
      "epoch 60; iter: 0; batch classifier loss: 0.408269; batch adversarial loss: 0.588535\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418230; batch adversarial loss: 0.607412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.332906; batch adversarial loss: 0.541894\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441899; batch adversarial loss: 0.571221\n",
      "epoch 64; iter: 0; batch classifier loss: 0.366723; batch adversarial loss: 0.624905\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364956; batch adversarial loss: 0.589132\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391990; batch adversarial loss: 0.527156\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433812; batch adversarial loss: 0.598164\n",
      "epoch 68; iter: 0; batch classifier loss: 0.358618; batch adversarial loss: 0.570624\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399945; batch adversarial loss: 0.491271\n",
      "epoch 70; iter: 0; batch classifier loss: 0.511373; batch adversarial loss: 0.535197\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402904; batch adversarial loss: 0.589101\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403911; batch adversarial loss: 0.553122\n",
      "epoch 73; iter: 0; batch classifier loss: 0.463789; batch adversarial loss: 0.555231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.459429; batch adversarial loss: 0.571718\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448761; batch adversarial loss: 0.570350\n",
      "epoch 76; iter: 0; batch classifier loss: 0.332012; batch adversarial loss: 0.552534\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399402; batch adversarial loss: 0.560121\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396099; batch adversarial loss: 0.553103\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362202; batch adversarial loss: 0.589275\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401475; batch adversarial loss: 0.570163\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341569; batch adversarial loss: 0.517722\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394897; batch adversarial loss: 0.490220\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413758; batch adversarial loss: 0.546355\n",
      "epoch 84; iter: 0; batch classifier loss: 0.471702; batch adversarial loss: 0.632541\n",
      "epoch 85; iter: 0; batch classifier loss: 0.317260; batch adversarial loss: 0.517682\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408814; batch adversarial loss: 0.518631\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382768; batch adversarial loss: 0.624093\n",
      "epoch 88; iter: 0; batch classifier loss: 0.312709; batch adversarial loss: 0.581144\n",
      "epoch 89; iter: 0; batch classifier loss: 0.290616; batch adversarial loss: 0.536504\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345562; batch adversarial loss: 0.572812\n",
      "epoch 91; iter: 0; batch classifier loss: 0.464821; batch adversarial loss: 0.651887\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411105; batch adversarial loss: 0.535440\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422130; batch adversarial loss: 0.501032\n",
      "epoch 94; iter: 0; batch classifier loss: 0.265722; batch adversarial loss: 0.633165\n",
      "epoch 95; iter: 0; batch classifier loss: 0.385386; batch adversarial loss: 0.535217\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395763; batch adversarial loss: 0.552790\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437423; batch adversarial loss: 0.517322\n",
      "epoch 98; iter: 0; batch classifier loss: 0.345140; batch adversarial loss: 0.552478\n",
      "epoch 99; iter: 0; batch classifier loss: 0.302559; batch adversarial loss: 0.544294\n",
      "epoch 100; iter: 0; batch classifier loss: 0.516057; batch adversarial loss: 0.535327\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382253; batch adversarial loss: 0.563190\n",
      "epoch 102; iter: 0; batch classifier loss: 0.411299; batch adversarial loss: 0.527498\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377062; batch adversarial loss: 0.546025\n",
      "epoch 104; iter: 0; batch classifier loss: 0.309938; batch adversarial loss: 0.597210\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395564; batch adversarial loss: 0.508121\n",
      "epoch 106; iter: 0; batch classifier loss: 0.305722; batch adversarial loss: 0.544635\n",
      "epoch 107; iter: 0; batch classifier loss: 0.395641; batch adversarial loss: 0.552277\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401113; batch adversarial loss: 0.489245\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351490; batch adversarial loss: 0.481375\n",
      "epoch 110; iter: 0; batch classifier loss: 0.372550; batch adversarial loss: 0.492208\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436332; batch adversarial loss: 0.588017\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358496; batch adversarial loss: 0.570724\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363486; batch adversarial loss: 0.465407\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393397; batch adversarial loss: 0.562664\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409884; batch adversarial loss: 0.554738\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402193; batch adversarial loss: 0.500701\n",
      "epoch 117; iter: 0; batch classifier loss: 0.442175; batch adversarial loss: 0.534422\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408270; batch adversarial loss: 0.526524\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338303; batch adversarial loss: 0.562924\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382566; batch adversarial loss: 0.589265\n",
      "epoch 121; iter: 0; batch classifier loss: 0.322209; batch adversarial loss: 0.578456\n",
      "epoch 122; iter: 0; batch classifier loss: 0.414423; batch adversarial loss: 0.694923\n",
      "epoch 123; iter: 0; batch classifier loss: 0.342770; batch adversarial loss: 0.650133\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426195; batch adversarial loss: 0.526668\n",
      "epoch 125; iter: 0; batch classifier loss: 0.493533; batch adversarial loss: 0.571535\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383250; batch adversarial loss: 0.589968\n",
      "epoch 127; iter: 0; batch classifier loss: 0.342679; batch adversarial loss: 0.579558\n",
      "epoch 128; iter: 0; batch classifier loss: 0.388307; batch adversarial loss: 0.581237\n",
      "epoch 129; iter: 0; batch classifier loss: 0.410492; batch adversarial loss: 0.545417\n",
      "epoch 130; iter: 0; batch classifier loss: 0.419537; batch adversarial loss: 0.500985\n",
      "epoch 131; iter: 0; batch classifier loss: 0.325069; batch adversarial loss: 0.590023\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369294; batch adversarial loss: 0.572370\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415743; batch adversarial loss: 0.640553\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357182; batch adversarial loss: 0.616521\n",
      "epoch 135; iter: 0; batch classifier loss: 0.416308; batch adversarial loss: 0.527038\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357366; batch adversarial loss: 0.535080\n",
      "epoch 137; iter: 0; batch classifier loss: 0.417965; batch adversarial loss: 0.587330\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356040; batch adversarial loss: 0.587849\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386962; batch adversarial loss: 0.589216\n",
      "epoch 140; iter: 0; batch classifier loss: 0.421075; batch adversarial loss: 0.578871\n",
      "epoch 141; iter: 0; batch classifier loss: 0.315784; batch adversarial loss: 0.554047\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340356; batch adversarial loss: 0.564510\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361079; batch adversarial loss: 0.456111\n",
      "epoch 144; iter: 0; batch classifier loss: 0.422807; batch adversarial loss: 0.544016\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358142; batch adversarial loss: 0.597568\n",
      "epoch 146; iter: 0; batch classifier loss: 0.436728; batch adversarial loss: 0.578907\n",
      "epoch 147; iter: 0; batch classifier loss: 0.395413; batch adversarial loss: 0.536022\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358598; batch adversarial loss: 0.536087\n",
      "epoch 149; iter: 0; batch classifier loss: 0.272195; batch adversarial loss: 0.561583\n",
      "epoch 150; iter: 0; batch classifier loss: 0.414418; batch adversarial loss: 0.562013\n",
      "epoch 151; iter: 0; batch classifier loss: 0.313226; batch adversarial loss: 0.553616\n",
      "epoch 152; iter: 0; batch classifier loss: 0.404094; batch adversarial loss: 0.483098\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393968; batch adversarial loss: 0.597820\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341802; batch adversarial loss: 0.499860\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356811; batch adversarial loss: 0.535516\n",
      "epoch 156; iter: 0; batch classifier loss: 0.325408; batch adversarial loss: 0.588314\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405125; batch adversarial loss: 0.465528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.345137; batch adversarial loss: 0.640756\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393546; batch adversarial loss: 0.438429\n",
      "epoch 160; iter: 0; batch classifier loss: 0.462400; batch adversarial loss: 0.528515\n",
      "epoch 161; iter: 0; batch classifier loss: 0.352537; batch adversarial loss: 0.552779\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385123; batch adversarial loss: 0.589136\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392055; batch adversarial loss: 0.607215\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346646; batch adversarial loss: 0.553166\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375523; batch adversarial loss: 0.589912\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357507; batch adversarial loss: 0.492064\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363908; batch adversarial loss: 0.589279\n",
      "epoch 168; iter: 0; batch classifier loss: 0.319286; batch adversarial loss: 0.509195\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363680; batch adversarial loss: 0.552722\n",
      "epoch 170; iter: 0; batch classifier loss: 0.422446; batch adversarial loss: 0.500570\n",
      "epoch 171; iter: 0; batch classifier loss: 0.407211; batch adversarial loss: 0.509366\n",
      "epoch 172; iter: 0; batch classifier loss: 0.309117; batch adversarial loss: 0.491058\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347300; batch adversarial loss: 0.499870\n",
      "epoch 174; iter: 0; batch classifier loss: 0.308315; batch adversarial loss: 0.607308\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390147; batch adversarial loss: 0.580711\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336918; batch adversarial loss: 0.535968\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337667; batch adversarial loss: 0.544918\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383585; batch adversarial loss: 0.482296\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386211; batch adversarial loss: 0.536729\n",
      "epoch 180; iter: 0; batch classifier loss: 0.434700; batch adversarial loss: 0.553407\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343353; batch adversarial loss: 0.526966\n",
      "epoch 182; iter: 0; batch classifier loss: 0.412593; batch adversarial loss: 0.677318\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395617; batch adversarial loss: 0.526961\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329159; batch adversarial loss: 0.563014\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364206; batch adversarial loss: 0.500844\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350340; batch adversarial loss: 0.561992\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367461; batch adversarial loss: 0.500548\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371909; batch adversarial loss: 0.562504\n",
      "epoch 189; iter: 0; batch classifier loss: 0.287776; batch adversarial loss: 0.552617\n",
      "epoch 190; iter: 0; batch classifier loss: 0.389826; batch adversarial loss: 0.510233\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321316; batch adversarial loss: 0.554039\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346616; batch adversarial loss: 0.606831\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338125; batch adversarial loss: 0.518058\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365114; batch adversarial loss: 0.553846\n",
      "epoch 195; iter: 0; batch classifier loss: 0.400079; batch adversarial loss: 0.500086\n",
      "epoch 196; iter: 0; batch classifier loss: 0.279588; batch adversarial loss: 0.579952\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377680; batch adversarial loss: 0.447769\n",
      "epoch 198; iter: 0; batch classifier loss: 0.388541; batch adversarial loss: 0.625237\n",
      "epoch 199; iter: 0; batch classifier loss: 0.311654; batch adversarial loss: 0.544712\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728004; batch adversarial loss: 0.682454\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602589; batch adversarial loss: 0.656994\n",
      "epoch 2; iter: 0; batch classifier loss: 0.564348; batch adversarial loss: 0.658924\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588673; batch adversarial loss: 0.617209\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590743; batch adversarial loss: 0.608220\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550931; batch adversarial loss: 0.587299\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552289; batch adversarial loss: 0.561112\n",
      "epoch 7; iter: 0; batch classifier loss: 0.608310; batch adversarial loss: 0.570048\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519207; batch adversarial loss: 0.569313\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553179; batch adversarial loss: 0.632726\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487653; batch adversarial loss: 0.619407\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505294; batch adversarial loss: 0.638447\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504566; batch adversarial loss: 0.628688\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485510; batch adversarial loss: 0.589524\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483411; batch adversarial loss: 0.607419\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505957; batch adversarial loss: 0.559940\n",
      "epoch 16; iter: 0; batch classifier loss: 0.410977; batch adversarial loss: 0.571106\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512216; batch adversarial loss: 0.549040\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541832; batch adversarial loss: 0.556362\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529418; batch adversarial loss: 0.633593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506892; batch adversarial loss: 0.542969\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501224; batch adversarial loss: 0.508356\n",
      "epoch 22; iter: 0; batch classifier loss: 0.554662; batch adversarial loss: 0.568512\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496249; batch adversarial loss: 0.506078\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445567; batch adversarial loss: 0.556506\n",
      "epoch 25; iter: 0; batch classifier loss: 0.448376; batch adversarial loss: 0.561811\n",
      "epoch 26; iter: 0; batch classifier loss: 0.581848; batch adversarial loss: 0.595336\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434494; batch adversarial loss: 0.596158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493520; batch adversarial loss: 0.610099\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432037; batch adversarial loss: 0.524803\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470387; batch adversarial loss: 0.566855\n",
      "epoch 31; iter: 0; batch classifier loss: 0.513662; batch adversarial loss: 0.583517\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410446; batch adversarial loss: 0.582008\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442055; batch adversarial loss: 0.565261\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421516; batch adversarial loss: 0.554042\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475335; batch adversarial loss: 0.514301\n",
      "epoch 36; iter: 0; batch classifier loss: 0.516789; batch adversarial loss: 0.547297\n",
      "epoch 37; iter: 0; batch classifier loss: 0.488414; batch adversarial loss: 0.588418\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428148; batch adversarial loss: 0.569228\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442820; batch adversarial loss: 0.658640\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451888; batch adversarial loss: 0.535343\n",
      "epoch 41; iter: 0; batch classifier loss: 0.387796; batch adversarial loss: 0.515307\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406941; batch adversarial loss: 0.600850\n",
      "epoch 43; iter: 0; batch classifier loss: 0.528727; batch adversarial loss: 0.545844\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452822; batch adversarial loss: 0.595475\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422853; batch adversarial loss: 0.617777\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483428; batch adversarial loss: 0.585651\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443783; batch adversarial loss: 0.532453\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427312; batch adversarial loss: 0.598823\n",
      "epoch 49; iter: 0; batch classifier loss: 0.381503; batch adversarial loss: 0.613369\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416612; batch adversarial loss: 0.584678\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466320; batch adversarial loss: 0.528899\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429605; batch adversarial loss: 0.526449\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420968; batch adversarial loss: 0.525865\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481413; batch adversarial loss: 0.533348\n",
      "epoch 55; iter: 0; batch classifier loss: 0.366678; batch adversarial loss: 0.564173\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398340; batch adversarial loss: 0.514921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.434488; batch adversarial loss: 0.534100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420985; batch adversarial loss: 0.573762\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414879; batch adversarial loss: 0.568414\n",
      "epoch 60; iter: 0; batch classifier loss: 0.512790; batch adversarial loss: 0.637811\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397716; batch adversarial loss: 0.606184\n",
      "epoch 62; iter: 0; batch classifier loss: 0.449157; batch adversarial loss: 0.593205\n",
      "epoch 63; iter: 0; batch classifier loss: 0.365728; batch adversarial loss: 0.502589\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439082; batch adversarial loss: 0.537087\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421773; batch adversarial loss: 0.520223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.468130; batch adversarial loss: 0.608767\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392060; batch adversarial loss: 0.531789\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382398; batch adversarial loss: 0.552786\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383041; batch adversarial loss: 0.552445\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379668; batch adversarial loss: 0.617300\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429806; batch adversarial loss: 0.568248\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447719; batch adversarial loss: 0.497004\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374333; batch adversarial loss: 0.545609\n",
      "epoch 74; iter: 0; batch classifier loss: 0.320527; batch adversarial loss: 0.582082\n",
      "epoch 75; iter: 0; batch classifier loss: 0.444301; batch adversarial loss: 0.537045\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393092; batch adversarial loss: 0.602383\n",
      "epoch 77; iter: 0; batch classifier loss: 0.465228; batch adversarial loss: 0.545100\n",
      "epoch 78; iter: 0; batch classifier loss: 0.353789; batch adversarial loss: 0.573528\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413972; batch adversarial loss: 0.507753\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455015; batch adversarial loss: 0.490027\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391746; batch adversarial loss: 0.549145\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351628; batch adversarial loss: 0.469853\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365325; batch adversarial loss: 0.505655\n",
      "epoch 84; iter: 0; batch classifier loss: 0.470463; batch adversarial loss: 0.519085\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347483; batch adversarial loss: 0.529803\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374205; batch adversarial loss: 0.573004\n",
      "epoch 87; iter: 0; batch classifier loss: 0.341265; batch adversarial loss: 0.580176\n",
      "epoch 88; iter: 0; batch classifier loss: 0.350473; batch adversarial loss: 0.504764\n",
      "epoch 89; iter: 0; batch classifier loss: 0.442906; batch adversarial loss: 0.563505\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378487; batch adversarial loss: 0.509654\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388292; batch adversarial loss: 0.500759\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391865; batch adversarial loss: 0.619522\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352894; batch adversarial loss: 0.534665\n",
      "epoch 94; iter: 0; batch classifier loss: 0.454441; batch adversarial loss: 0.633586\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375331; batch adversarial loss: 0.540391\n",
      "epoch 96; iter: 0; batch classifier loss: 0.363180; batch adversarial loss: 0.593320\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415417; batch adversarial loss: 0.566833\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420390; batch adversarial loss: 0.507411\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365297; batch adversarial loss: 0.463534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.441397; batch adversarial loss: 0.534966\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367968; batch adversarial loss: 0.541607\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355624; batch adversarial loss: 0.569772\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381554; batch adversarial loss: 0.539847\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434771; batch adversarial loss: 0.568843\n",
      "epoch 105; iter: 0; batch classifier loss: 0.459680; batch adversarial loss: 0.506374\n",
      "epoch 106; iter: 0; batch classifier loss: 0.444794; batch adversarial loss: 0.547998\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362638; batch adversarial loss: 0.565551\n",
      "epoch 108; iter: 0; batch classifier loss: 0.430610; batch adversarial loss: 0.472919\n",
      "epoch 109; iter: 0; batch classifier loss: 0.465096; batch adversarial loss: 0.578967\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383483; batch adversarial loss: 0.523281\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380810; batch adversarial loss: 0.555471\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360963; batch adversarial loss: 0.590650\n",
      "epoch 113; iter: 0; batch classifier loss: 0.344716; batch adversarial loss: 0.491468\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381472; batch adversarial loss: 0.578555\n",
      "epoch 115; iter: 0; batch classifier loss: 0.368820; batch adversarial loss: 0.561215\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390354; batch adversarial loss: 0.594112\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337429; batch adversarial loss: 0.536496\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330622; batch adversarial loss: 0.579625\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425983; batch adversarial loss: 0.520406\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361671; batch adversarial loss: 0.577174\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394085; batch adversarial loss: 0.527253\n",
      "epoch 122; iter: 0; batch classifier loss: 0.409072; batch adversarial loss: 0.513081\n",
      "epoch 123; iter: 0; batch classifier loss: 0.408988; batch adversarial loss: 0.517230\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375691; batch adversarial loss: 0.596191\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363362; batch adversarial loss: 0.568177\n",
      "epoch 126; iter: 0; batch classifier loss: 0.415380; batch adversarial loss: 0.604391\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422907; batch adversarial loss: 0.579518\n",
      "epoch 128; iter: 0; batch classifier loss: 0.309356; batch adversarial loss: 0.526789\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329603; batch adversarial loss: 0.552610\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346412; batch adversarial loss: 0.511116\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438119; batch adversarial loss: 0.551768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.274608; batch adversarial loss: 0.561902\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331936; batch adversarial loss: 0.526209\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363330; batch adversarial loss: 0.510724\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411074; batch adversarial loss: 0.607903\n",
      "epoch 136; iter: 0; batch classifier loss: 0.412717; batch adversarial loss: 0.644442\n",
      "epoch 137; iter: 0; batch classifier loss: 0.425691; batch adversarial loss: 0.540378\n",
      "epoch 138; iter: 0; batch classifier loss: 0.467826; batch adversarial loss: 0.617283\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358819; batch adversarial loss: 0.491589\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309604; batch adversarial loss: 0.553781\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422074; batch adversarial loss: 0.555097\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420883; batch adversarial loss: 0.580749\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381728; batch adversarial loss: 0.530698\n",
      "epoch 144; iter: 0; batch classifier loss: 0.374368; batch adversarial loss: 0.544934\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347921; batch adversarial loss: 0.518661\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336197; batch adversarial loss: 0.591063\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377508; batch adversarial loss: 0.597581\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327230; batch adversarial loss: 0.506932\n",
      "epoch 149; iter: 0; batch classifier loss: 0.342837; batch adversarial loss: 0.517266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389829; batch adversarial loss: 0.561466\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365230; batch adversarial loss: 0.560740\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349239; batch adversarial loss: 0.616181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.394054; batch adversarial loss: 0.503272\n",
      "epoch 154; iter: 0; batch classifier loss: 0.437184; batch adversarial loss: 0.552510\n",
      "epoch 155; iter: 0; batch classifier loss: 0.368559; batch adversarial loss: 0.579323\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368365; batch adversarial loss: 0.588571\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330729; batch adversarial loss: 0.613099\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386323; batch adversarial loss: 0.560931\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364898; batch adversarial loss: 0.515232\n",
      "epoch 160; iter: 0; batch classifier loss: 0.310378; batch adversarial loss: 0.556139\n",
      "epoch 161; iter: 0; batch classifier loss: 0.340262; batch adversarial loss: 0.549687\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368110; batch adversarial loss: 0.565594\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384312; batch adversarial loss: 0.624801\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346564; batch adversarial loss: 0.528251\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353373; batch adversarial loss: 0.555395\n",
      "epoch 166; iter: 0; batch classifier loss: 0.396701; batch adversarial loss: 0.551827\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367649; batch adversarial loss: 0.556484\n",
      "epoch 168; iter: 0; batch classifier loss: 0.448887; batch adversarial loss: 0.534115\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370344; batch adversarial loss: 0.580462\n",
      "epoch 170; iter: 0; batch classifier loss: 0.343464; batch adversarial loss: 0.519989\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372838; batch adversarial loss: 0.563189\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372656; batch adversarial loss: 0.598150\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355596; batch adversarial loss: 0.578474\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360112; batch adversarial loss: 0.541673\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352495; batch adversarial loss: 0.572006\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379229; batch adversarial loss: 0.621019\n",
      "epoch 177; iter: 0; batch classifier loss: 0.326046; batch adversarial loss: 0.636347\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360080; batch adversarial loss: 0.518988\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351326; batch adversarial loss: 0.562194\n",
      "epoch 180; iter: 0; batch classifier loss: 0.387815; batch adversarial loss: 0.502982\n",
      "epoch 181; iter: 0; batch classifier loss: 0.429839; batch adversarial loss: 0.546927\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299937; batch adversarial loss: 0.590348\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373150; batch adversarial loss: 0.571165\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351840; batch adversarial loss: 0.569942\n",
      "epoch 185; iter: 0; batch classifier loss: 0.419688; batch adversarial loss: 0.610520\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343965; batch adversarial loss: 0.541795\n",
      "epoch 187; iter: 0; batch classifier loss: 0.381110; batch adversarial loss: 0.546783\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348674; batch adversarial loss: 0.554567\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384381; batch adversarial loss: 0.490635\n",
      "epoch 190; iter: 0; batch classifier loss: 0.378578; batch adversarial loss: 0.660656\n",
      "epoch 191; iter: 0; batch classifier loss: 0.405658; batch adversarial loss: 0.652839\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363997; batch adversarial loss: 0.639502\n",
      "epoch 193; iter: 0; batch classifier loss: 0.334176; batch adversarial loss: 0.543520\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321064; batch adversarial loss: 0.579293\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353470; batch adversarial loss: 0.600497\n",
      "epoch 196; iter: 0; batch classifier loss: 0.414974; batch adversarial loss: 0.527913\n",
      "epoch 197; iter: 0; batch classifier loss: 0.373732; batch adversarial loss: 0.579085\n",
      "epoch 198; iter: 0; batch classifier loss: 0.401774; batch adversarial loss: 0.563089\n",
      "epoch 199; iter: 0; batch classifier loss: 0.373207; batch adversarial loss: 0.622721\n",
      "epoch 0; iter: 0; batch classifier loss: 0.762557; batch adversarial loss: 0.778031\n",
      "epoch 1; iter: 0; batch classifier loss: 0.666250; batch adversarial loss: 0.732381\n",
      "epoch 2; iter: 0; batch classifier loss: 0.739693; batch adversarial loss: 0.674396\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589789; batch adversarial loss: 0.659142\n",
      "epoch 4; iter: 0; batch classifier loss: 0.626586; batch adversarial loss: 0.629887\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592002; batch adversarial loss: 0.614370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544412; batch adversarial loss: 0.622582\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555604; batch adversarial loss: 0.617818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541882; batch adversarial loss: 0.583685\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541316; batch adversarial loss: 0.633073\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537902; batch adversarial loss: 0.582135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495014; batch adversarial loss: 0.560985\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533534; batch adversarial loss: 0.608379\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565810; batch adversarial loss: 0.615364\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539690; batch adversarial loss: 0.625337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.596784; batch adversarial loss: 0.599525\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553693; batch adversarial loss: 0.614104\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501147; batch adversarial loss: 0.663122\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526972; batch adversarial loss: 0.598834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474932; batch adversarial loss: 0.533726\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471887; batch adversarial loss: 0.558795\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471103; batch adversarial loss: 0.588278\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483576; batch adversarial loss: 0.590493\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488360; batch adversarial loss: 0.635431\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440843; batch adversarial loss: 0.594239\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477896; batch adversarial loss: 0.569457\n",
      "epoch 26; iter: 0; batch classifier loss: 0.518845; batch adversarial loss: 0.528931\n",
      "epoch 27; iter: 0; batch classifier loss: 0.385834; batch adversarial loss: 0.511047\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496855; batch adversarial loss: 0.552348\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489379; batch adversarial loss: 0.539483\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524282; batch adversarial loss: 0.534036\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465698; batch adversarial loss: 0.574426\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429984; batch adversarial loss: 0.512539\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426437; batch adversarial loss: 0.507172\n",
      "epoch 34; iter: 0; batch classifier loss: 0.528382; batch adversarial loss: 0.576152\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420397; batch adversarial loss: 0.620726\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461706; batch adversarial loss: 0.596416\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436200; batch adversarial loss: 0.533746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406074; batch adversarial loss: 0.658608\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462119; batch adversarial loss: 0.529964\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435705; batch adversarial loss: 0.580029\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474669; batch adversarial loss: 0.595879\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449510; batch adversarial loss: 0.452478\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451542; batch adversarial loss: 0.621501\n",
      "epoch 44; iter: 0; batch classifier loss: 0.376360; batch adversarial loss: 0.502987\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419647; batch adversarial loss: 0.553868\n",
      "epoch 46; iter: 0; batch classifier loss: 0.375244; batch adversarial loss: 0.638030\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407216; batch adversarial loss: 0.536767\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481095; batch adversarial loss: 0.469070\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454782; batch adversarial loss: 0.528257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.430991; batch adversarial loss: 0.570964\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443741; batch adversarial loss: 0.493033\n",
      "epoch 52; iter: 0; batch classifier loss: 0.489912; batch adversarial loss: 0.623194\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406235; batch adversarial loss: 0.606078\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457398; batch adversarial loss: 0.587517\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411428; batch adversarial loss: 0.623781\n",
      "epoch 56; iter: 0; batch classifier loss: 0.483695; batch adversarial loss: 0.536356\n",
      "epoch 57; iter: 0; batch classifier loss: 0.476409; batch adversarial loss: 0.606539\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398690; batch adversarial loss: 0.579041\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438640; batch adversarial loss: 0.561140\n",
      "epoch 60; iter: 0; batch classifier loss: 0.463056; batch adversarial loss: 0.622692\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403660; batch adversarial loss: 0.570726\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386613; batch adversarial loss: 0.492253\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383820; batch adversarial loss: 0.588828\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406395; batch adversarial loss: 0.580030\n",
      "epoch 65; iter: 0; batch classifier loss: 0.341874; batch adversarial loss: 0.572275\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397455; batch adversarial loss: 0.563424\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434944; batch adversarial loss: 0.528359\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356466; batch adversarial loss: 0.588211\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384900; batch adversarial loss: 0.622682\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437553; batch adversarial loss: 0.509732\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449585; batch adversarial loss: 0.562258\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377043; batch adversarial loss: 0.546137\n",
      "epoch 73; iter: 0; batch classifier loss: 0.458899; batch adversarial loss: 0.544614\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388800; batch adversarial loss: 0.571205\n",
      "epoch 75; iter: 0; batch classifier loss: 0.336140; batch adversarial loss: 0.571765\n",
      "epoch 76; iter: 0; batch classifier loss: 0.476207; batch adversarial loss: 0.589216\n",
      "epoch 77; iter: 0; batch classifier loss: 0.453778; batch adversarial loss: 0.492760\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393016; batch adversarial loss: 0.649680\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408022; batch adversarial loss: 0.570857\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451829; batch adversarial loss: 0.562406\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398385; batch adversarial loss: 0.474637\n",
      "epoch 82; iter: 0; batch classifier loss: 0.462942; batch adversarial loss: 0.622601\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373018; batch adversarial loss: 0.553718\n",
      "epoch 84; iter: 0; batch classifier loss: 0.341894; batch adversarial loss: 0.563110\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351803; batch adversarial loss: 0.501433\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432867; batch adversarial loss: 0.579439\n",
      "epoch 87; iter: 0; batch classifier loss: 0.499281; batch adversarial loss: 0.554154\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341154; batch adversarial loss: 0.553610\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353519; batch adversarial loss: 0.562956\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384401; batch adversarial loss: 0.545925\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427223; batch adversarial loss: 0.553839\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389475; batch adversarial loss: 0.519171\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384864; batch adversarial loss: 0.500766\n",
      "epoch 94; iter: 0; batch classifier loss: 0.337675; batch adversarial loss: 0.527789\n",
      "epoch 95; iter: 0; batch classifier loss: 0.390363; batch adversarial loss: 0.632358\n",
      "epoch 96; iter: 0; batch classifier loss: 0.353984; batch adversarial loss: 0.551937\n",
      "epoch 97; iter: 0; batch classifier loss: 0.438546; batch adversarial loss: 0.562554\n",
      "epoch 98; iter: 0; batch classifier loss: 0.405205; batch adversarial loss: 0.588702\n",
      "epoch 99; iter: 0; batch classifier loss: 0.345747; batch adversarial loss: 0.500538\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348266; batch adversarial loss: 0.580057\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397747; batch adversarial loss: 0.649277\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349471; batch adversarial loss: 0.622504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402547; batch adversarial loss: 0.543238\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363537; batch adversarial loss: 0.580391\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380523; batch adversarial loss: 0.554859\n",
      "epoch 106; iter: 0; batch classifier loss: 0.358980; batch adversarial loss: 0.578040\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403320; batch adversarial loss: 0.535456\n",
      "epoch 108; iter: 0; batch classifier loss: 0.428533; batch adversarial loss: 0.509041\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385901; batch adversarial loss: 0.580651\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383916; batch adversarial loss: 0.483591\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371401; batch adversarial loss: 0.510656\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330636; batch adversarial loss: 0.500690\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339894; batch adversarial loss: 0.519230\n",
      "epoch 114; iter: 0; batch classifier loss: 0.415792; batch adversarial loss: 0.536462\n",
      "epoch 115; iter: 0; batch classifier loss: 0.400398; batch adversarial loss: 0.578418\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373674; batch adversarial loss: 0.536708\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376330; batch adversarial loss: 0.562962\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374958; batch adversarial loss: 0.596904\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347126; batch adversarial loss: 0.632340\n",
      "epoch 120; iter: 0; batch classifier loss: 0.353976; batch adversarial loss: 0.560832\n",
      "epoch 121; iter: 0; batch classifier loss: 0.343123; batch adversarial loss: 0.526929\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367123; batch adversarial loss: 0.570230\n",
      "epoch 123; iter: 0; batch classifier loss: 0.495446; batch adversarial loss: 0.579902\n",
      "epoch 124; iter: 0; batch classifier loss: 0.451958; batch adversarial loss: 0.554046\n",
      "epoch 125; iter: 0; batch classifier loss: 0.333164; batch adversarial loss: 0.632070\n",
      "epoch 126; iter: 0; batch classifier loss: 0.306335; batch adversarial loss: 0.518705\n",
      "epoch 127; iter: 0; batch classifier loss: 0.441540; batch adversarial loss: 0.616210\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345111; batch adversarial loss: 0.545564\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402111; batch adversarial loss: 0.561894\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341649; batch adversarial loss: 0.579443\n",
      "epoch 131; iter: 0; batch classifier loss: 0.384273; batch adversarial loss: 0.510473\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396172; batch adversarial loss: 0.518764\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352466; batch adversarial loss: 0.570115\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376633; batch adversarial loss: 0.527059\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347440; batch adversarial loss: 0.623360\n",
      "epoch 136; iter: 0; batch classifier loss: 0.412097; batch adversarial loss: 0.563119\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351902; batch adversarial loss: 0.544679\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366898; batch adversarial loss: 0.562692\n",
      "epoch 139; iter: 0; batch classifier loss: 0.306447; batch adversarial loss: 0.511203\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329554; batch adversarial loss: 0.562903\n",
      "epoch 141; iter: 0; batch classifier loss: 0.292191; batch adversarial loss: 0.537204\n",
      "epoch 142; iter: 0; batch classifier loss: 0.438225; batch adversarial loss: 0.580441\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354318; batch adversarial loss: 0.606088\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376878; batch adversarial loss: 0.535689\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323146; batch adversarial loss: 0.535797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.457822; batch adversarial loss: 0.624064\n",
      "epoch 147; iter: 0; batch classifier loss: 0.465545; batch adversarial loss: 0.606739\n",
      "epoch 148; iter: 0; batch classifier loss: 0.402327; batch adversarial loss: 0.561080\n",
      "epoch 149; iter: 0; batch classifier loss: 0.381745; batch adversarial loss: 0.640148\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379408; batch adversarial loss: 0.552662\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399227; batch adversarial loss: 0.595602\n",
      "epoch 152; iter: 0; batch classifier loss: 0.358898; batch adversarial loss: 0.639762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.390224; batch adversarial loss: 0.517548\n",
      "epoch 154; iter: 0; batch classifier loss: 0.432048; batch adversarial loss: 0.501448\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353488; batch adversarial loss: 0.526373\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356675; batch adversarial loss: 0.563875\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364651; batch adversarial loss: 0.579489\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435236; batch adversarial loss: 0.562316\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359349; batch adversarial loss: 0.614755\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400415; batch adversarial loss: 0.535447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366287; batch adversarial loss: 0.544665\n",
      "epoch 162; iter: 0; batch classifier loss: 0.455284; batch adversarial loss: 0.493698\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380732; batch adversarial loss: 0.588917\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356061; batch adversarial loss: 0.579826\n",
      "epoch 165; iter: 0; batch classifier loss: 0.286043; batch adversarial loss: 0.510046\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367032; batch adversarial loss: 0.614827\n",
      "epoch 167; iter: 0; batch classifier loss: 0.377187; batch adversarial loss: 0.554011\n",
      "epoch 168; iter: 0; batch classifier loss: 0.383301; batch adversarial loss: 0.526915\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306983; batch adversarial loss: 0.536425\n",
      "epoch 170; iter: 0; batch classifier loss: 0.394766; batch adversarial loss: 0.605395\n",
      "epoch 171; iter: 0; batch classifier loss: 0.426841; batch adversarial loss: 0.578217\n",
      "epoch 172; iter: 0; batch classifier loss: 0.353299; batch adversarial loss: 0.588005\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380563; batch adversarial loss: 0.553518\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366389; batch adversarial loss: 0.570337\n",
      "epoch 175; iter: 0; batch classifier loss: 0.381232; batch adversarial loss: 0.519146\n",
      "epoch 176; iter: 0; batch classifier loss: 0.317423; batch adversarial loss: 0.561454\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383441; batch adversarial loss: 0.483563\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382395; batch adversarial loss: 0.501809\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329701; batch adversarial loss: 0.527296\n",
      "epoch 180; iter: 0; batch classifier loss: 0.328964; batch adversarial loss: 0.510234\n",
      "epoch 181; iter: 0; batch classifier loss: 0.339279; batch adversarial loss: 0.518071\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342545; batch adversarial loss: 0.527628\n",
      "epoch 183; iter: 0; batch classifier loss: 0.440757; batch adversarial loss: 0.613642\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337539; batch adversarial loss: 0.501166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387867; batch adversarial loss: 0.641199\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335295; batch adversarial loss: 0.509191\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335623; batch adversarial loss: 0.580181\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313085; batch adversarial loss: 0.510599\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378582; batch adversarial loss: 0.570990\n",
      "epoch 190; iter: 0; batch classifier loss: 0.304745; batch adversarial loss: 0.526469\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321182; batch adversarial loss: 0.492680\n",
      "epoch 192; iter: 0; batch classifier loss: 0.436118; batch adversarial loss: 0.519036\n",
      "epoch 193; iter: 0; batch classifier loss: 0.430872; batch adversarial loss: 0.537498\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376957; batch adversarial loss: 0.581072\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325012; batch adversarial loss: 0.518956\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338992; batch adversarial loss: 0.588616\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275239; batch adversarial loss: 0.615748\n",
      "epoch 198; iter: 0; batch classifier loss: 0.409758; batch adversarial loss: 0.544425\n",
      "epoch 199; iter: 0; batch classifier loss: 0.470943; batch adversarial loss: 0.615080\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726403; batch adversarial loss: 0.712108\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642125; batch adversarial loss: 0.713708\n",
      "epoch 2; iter: 0; batch classifier loss: 0.685755; batch adversarial loss: 0.673591\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632969; batch adversarial loss: 0.637769\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606488; batch adversarial loss: 0.643527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.471032; batch adversarial loss: 0.610013\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537925; batch adversarial loss: 0.629980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529904; batch adversarial loss: 0.622564\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570007; batch adversarial loss: 0.611492\n",
      "epoch 9; iter: 0; batch classifier loss: 0.608460; batch adversarial loss: 0.579560\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610949; batch adversarial loss: 0.599239\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495753; batch adversarial loss: 0.613653\n",
      "epoch 12; iter: 0; batch classifier loss: 0.615295; batch adversarial loss: 0.612898\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558047; batch adversarial loss: 0.601237\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485923; batch adversarial loss: 0.513756\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528952; batch adversarial loss: 0.555549\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478184; batch adversarial loss: 0.578688\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527796; batch adversarial loss: 0.546727\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508871; batch adversarial loss: 0.557750\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468055; batch adversarial loss: 0.566771\n",
      "epoch 20; iter: 0; batch classifier loss: 0.444233; batch adversarial loss: 0.554620\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477291; batch adversarial loss: 0.596635\n",
      "epoch 22; iter: 0; batch classifier loss: 0.485893; batch adversarial loss: 0.620738\n",
      "epoch 23; iter: 0; batch classifier loss: 0.440257; batch adversarial loss: 0.558974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478067; batch adversarial loss: 0.595391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.448638; batch adversarial loss: 0.606718\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474481; batch adversarial loss: 0.568279\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394177; batch adversarial loss: 0.565627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.531941; batch adversarial loss: 0.542942\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447558; batch adversarial loss: 0.577451\n",
      "epoch 30; iter: 0; batch classifier loss: 0.352127; batch adversarial loss: 0.599776\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494882; batch adversarial loss: 0.504941\n",
      "epoch 32; iter: 0; batch classifier loss: 0.503566; batch adversarial loss: 0.562302\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488821; batch adversarial loss: 0.482680\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448927; batch adversarial loss: 0.595704\n",
      "epoch 35; iter: 0; batch classifier loss: 0.520868; batch adversarial loss: 0.559789\n",
      "epoch 36; iter: 0; batch classifier loss: 0.516155; batch adversarial loss: 0.537781\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381431; batch adversarial loss: 0.536881\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461739; batch adversarial loss: 0.600849\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479987; batch adversarial loss: 0.551992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460215; batch adversarial loss: 0.570946\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433012; batch adversarial loss: 0.581416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.470880; batch adversarial loss: 0.487787\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454252; batch adversarial loss: 0.568311\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492800; batch adversarial loss: 0.582276\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440157; batch adversarial loss: 0.517253\n",
      "epoch 46; iter: 0; batch classifier loss: 0.472015; batch adversarial loss: 0.512122\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422312; batch adversarial loss: 0.571058\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412696; batch adversarial loss: 0.594732\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428009; batch adversarial loss: 0.511719\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414165; batch adversarial loss: 0.543569\n",
      "epoch 51; iter: 0; batch classifier loss: 0.543759; batch adversarial loss: 0.529361\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438234; batch adversarial loss: 0.616699\n",
      "epoch 53; iter: 0; batch classifier loss: 0.328890; batch adversarial loss: 0.564902\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388642; batch adversarial loss: 0.555806\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387833; batch adversarial loss: 0.538983\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448238; batch adversarial loss: 0.515398\n",
      "epoch 57; iter: 0; batch classifier loss: 0.462258; batch adversarial loss: 0.507892\n",
      "epoch 58; iter: 0; batch classifier loss: 0.377264; batch adversarial loss: 0.561123\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412468; batch adversarial loss: 0.541129\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393629; batch adversarial loss: 0.563060\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358977; batch adversarial loss: 0.641513\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376794; batch adversarial loss: 0.552481\n",
      "epoch 63; iter: 0; batch classifier loss: 0.516514; batch adversarial loss: 0.423175\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457425; batch adversarial loss: 0.591634\n",
      "epoch 65; iter: 0; batch classifier loss: 0.340092; batch adversarial loss: 0.498436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382555; batch adversarial loss: 0.591330\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414007; batch adversarial loss: 0.535971\n",
      "epoch 68; iter: 0; batch classifier loss: 0.416657; batch adversarial loss: 0.595944\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382089; batch adversarial loss: 0.624804\n",
      "epoch 70; iter: 0; batch classifier loss: 0.304663; batch adversarial loss: 0.570505\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365421; batch adversarial loss: 0.525352\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422341; batch adversarial loss: 0.604697\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419950; batch adversarial loss: 0.565764\n",
      "epoch 74; iter: 0; batch classifier loss: 0.337319; batch adversarial loss: 0.500600\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354602; batch adversarial loss: 0.508409\n",
      "epoch 76; iter: 0; batch classifier loss: 0.442081; batch adversarial loss: 0.631164\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441234; batch adversarial loss: 0.498990\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368174; batch adversarial loss: 0.502162\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388050; batch adversarial loss: 0.548356\n",
      "epoch 80; iter: 0; batch classifier loss: 0.411990; batch adversarial loss: 0.575042\n",
      "epoch 81; iter: 0; batch classifier loss: 0.362450; batch adversarial loss: 0.625370\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421123; batch adversarial loss: 0.580927\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422750; batch adversarial loss: 0.620725\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404407; batch adversarial loss: 0.551302\n",
      "epoch 85; iter: 0; batch classifier loss: 0.358889; batch adversarial loss: 0.551991\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343417; batch adversarial loss: 0.516605\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389781; batch adversarial loss: 0.453764\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385166; batch adversarial loss: 0.474479\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394204; batch adversarial loss: 0.498989\n",
      "epoch 90; iter: 0; batch classifier loss: 0.479947; batch adversarial loss: 0.569911\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360445; batch adversarial loss: 0.524450\n",
      "epoch 92; iter: 0; batch classifier loss: 0.439674; batch adversarial loss: 0.543563\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394369; batch adversarial loss: 0.521902\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414225; batch adversarial loss: 0.599501\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440017; batch adversarial loss: 0.544449\n",
      "epoch 96; iter: 0; batch classifier loss: 0.476300; batch adversarial loss: 0.482517\n",
      "epoch 97; iter: 0; batch classifier loss: 0.433237; batch adversarial loss: 0.541754\n",
      "epoch 98; iter: 0; batch classifier loss: 0.323931; batch adversarial loss: 0.526299\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359632; batch adversarial loss: 0.513727\n",
      "epoch 100; iter: 0; batch classifier loss: 0.509784; batch adversarial loss: 0.580692\n",
      "epoch 101; iter: 0; batch classifier loss: 0.502335; batch adversarial loss: 0.518458\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427742; batch adversarial loss: 0.529616\n",
      "epoch 103; iter: 0; batch classifier loss: 0.323597; batch adversarial loss: 0.552731\n",
      "epoch 104; iter: 0; batch classifier loss: 0.460832; batch adversarial loss: 0.541508\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417073; batch adversarial loss: 0.510941\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366868; batch adversarial loss: 0.520386\n",
      "epoch 107; iter: 0; batch classifier loss: 0.315393; batch adversarial loss: 0.545859\n",
      "epoch 108; iter: 0; batch classifier loss: 0.443019; batch adversarial loss: 0.618320\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368694; batch adversarial loss: 0.607512\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352207; batch adversarial loss: 0.612598\n",
      "epoch 111; iter: 0; batch classifier loss: 0.292164; batch adversarial loss: 0.518880\n",
      "epoch 112; iter: 0; batch classifier loss: 0.369851; batch adversarial loss: 0.565842\n",
      "epoch 113; iter: 0; batch classifier loss: 0.332433; batch adversarial loss: 0.552655\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358444; batch adversarial loss: 0.518398\n",
      "epoch 115; iter: 0; batch classifier loss: 0.395342; batch adversarial loss: 0.528316\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415903; batch adversarial loss: 0.554835\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368729; batch adversarial loss: 0.526617\n",
      "epoch 118; iter: 0; batch classifier loss: 0.306904; batch adversarial loss: 0.570003\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368046; batch adversarial loss: 0.499959\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378810; batch adversarial loss: 0.517520\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321904; batch adversarial loss: 0.502130\n",
      "epoch 122; iter: 0; batch classifier loss: 0.331634; batch adversarial loss: 0.618238\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378623; batch adversarial loss: 0.552287\n",
      "epoch 124; iter: 0; batch classifier loss: 0.419277; batch adversarial loss: 0.549949\n",
      "epoch 125; iter: 0; batch classifier loss: 0.448347; batch adversarial loss: 0.528565\n",
      "epoch 126; iter: 0; batch classifier loss: 0.397409; batch adversarial loss: 0.487962\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348065; batch adversarial loss: 0.583142\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397722; batch adversarial loss: 0.593760\n",
      "epoch 129; iter: 0; batch classifier loss: 0.484087; batch adversarial loss: 0.520534\n",
      "epoch 130; iter: 0; batch classifier loss: 0.279056; batch adversarial loss: 0.596176\n",
      "epoch 131; iter: 0; batch classifier loss: 0.379957; batch adversarial loss: 0.621083\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388201; batch adversarial loss: 0.471781\n",
      "epoch 133; iter: 0; batch classifier loss: 0.446492; batch adversarial loss: 0.516050\n",
      "epoch 134; iter: 0; batch classifier loss: 0.405345; batch adversarial loss: 0.560915\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376148; batch adversarial loss: 0.570267\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360239; batch adversarial loss: 0.661990\n",
      "epoch 137; iter: 0; batch classifier loss: 0.324965; batch adversarial loss: 0.508794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.352157; batch adversarial loss: 0.543873\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384008; batch adversarial loss: 0.484815\n",
      "epoch 140; iter: 0; batch classifier loss: 0.415045; batch adversarial loss: 0.539090\n",
      "epoch 141; iter: 0; batch classifier loss: 0.315980; batch adversarial loss: 0.516702\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419305; batch adversarial loss: 0.534289\n",
      "epoch 143; iter: 0; batch classifier loss: 0.448209; batch adversarial loss: 0.508986\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354370; batch adversarial loss: 0.546929\n",
      "epoch 145; iter: 0; batch classifier loss: 0.433328; batch adversarial loss: 0.554120\n",
      "epoch 146; iter: 0; batch classifier loss: 0.417232; batch adversarial loss: 0.525283\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360759; batch adversarial loss: 0.562363\n",
      "epoch 148; iter: 0; batch classifier loss: 0.289718; batch adversarial loss: 0.428636\n",
      "epoch 149; iter: 0; batch classifier loss: 0.305365; batch adversarial loss: 0.455599\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382380; batch adversarial loss: 0.545186\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325241; batch adversarial loss: 0.488827\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388237; batch adversarial loss: 0.485006\n",
      "epoch 153; iter: 0; batch classifier loss: 0.311342; batch adversarial loss: 0.599647\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365631; batch adversarial loss: 0.491827\n",
      "epoch 155; iter: 0; batch classifier loss: 0.414892; batch adversarial loss: 0.512508\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344349; batch adversarial loss: 0.544939\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360766; batch adversarial loss: 0.554998\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341416; batch adversarial loss: 0.585270\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360483; batch adversarial loss: 0.575433\n",
      "epoch 160; iter: 0; batch classifier loss: 0.407899; batch adversarial loss: 0.565785\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372608; batch adversarial loss: 0.642488\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351045; batch adversarial loss: 0.605897\n",
      "epoch 163; iter: 0; batch classifier loss: 0.352293; batch adversarial loss: 0.535197\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305744; batch adversarial loss: 0.489963\n",
      "epoch 165; iter: 0; batch classifier loss: 0.314894; batch adversarial loss: 0.524280\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335561; batch adversarial loss: 0.589793\n",
      "epoch 167; iter: 0; batch classifier loss: 0.480986; batch adversarial loss: 0.473776\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370042; batch adversarial loss: 0.480244\n",
      "epoch 169; iter: 0; batch classifier loss: 0.307509; batch adversarial loss: 0.560294\n",
      "epoch 170; iter: 0; batch classifier loss: 0.298706; batch adversarial loss: 0.510086\n",
      "epoch 171; iter: 0; batch classifier loss: 0.398673; batch adversarial loss: 0.591037\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394166; batch adversarial loss: 0.497415\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329774; batch adversarial loss: 0.545606\n",
      "epoch 174; iter: 0; batch classifier loss: 0.315596; batch adversarial loss: 0.584116\n",
      "epoch 175; iter: 0; batch classifier loss: 0.286530; batch adversarial loss: 0.536032\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323889; batch adversarial loss: 0.582588\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336243; batch adversarial loss: 0.588683\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364633; batch adversarial loss: 0.569972\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353593; batch adversarial loss: 0.442238\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369524; batch adversarial loss: 0.514747\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313287; batch adversarial loss: 0.565276\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399103; batch adversarial loss: 0.564667\n",
      "epoch 183; iter: 0; batch classifier loss: 0.312983; batch adversarial loss: 0.514869\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375754; batch adversarial loss: 0.559752\n",
      "epoch 185; iter: 0; batch classifier loss: 0.419212; batch adversarial loss: 0.597190\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359063; batch adversarial loss: 0.615744\n",
      "epoch 187; iter: 0; batch classifier loss: 0.441736; batch adversarial loss: 0.510514\n",
      "epoch 188; iter: 0; batch classifier loss: 0.321397; batch adversarial loss: 0.518800\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346509; batch adversarial loss: 0.590749\n",
      "epoch 190; iter: 0; batch classifier loss: 0.485491; batch adversarial loss: 0.553428\n",
      "epoch 191; iter: 0; batch classifier loss: 0.287747; batch adversarial loss: 0.595448\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352445; batch adversarial loss: 0.650136\n",
      "epoch 193; iter: 0; batch classifier loss: 0.301803; batch adversarial loss: 0.536737\n",
      "epoch 194; iter: 0; batch classifier loss: 0.413405; batch adversarial loss: 0.624823\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319107; batch adversarial loss: 0.526147\n",
      "epoch 196; iter: 0; batch classifier loss: 0.319923; batch adversarial loss: 0.463062\n",
      "epoch 197; iter: 0; batch classifier loss: 0.306544; batch adversarial loss: 0.590277\n",
      "epoch 198; iter: 0; batch classifier loss: 0.427548; batch adversarial loss: 0.552787\n",
      "epoch 199; iter: 0; batch classifier loss: 0.361720; batch adversarial loss: 0.475319\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682315; batch adversarial loss: 0.766919\n",
      "epoch 1; iter: 0; batch classifier loss: 0.697429; batch adversarial loss: 0.809865\n",
      "epoch 2; iter: 0; batch classifier loss: 0.648665; batch adversarial loss: 0.766943\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597111; batch adversarial loss: 0.707870\n",
      "epoch 4; iter: 0; batch classifier loss: 0.484586; batch adversarial loss: 0.675078\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532122; batch adversarial loss: 0.648826\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557229; batch adversarial loss: 0.623985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567635; batch adversarial loss: 0.583566\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513631; batch adversarial loss: 0.600530\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480023; batch adversarial loss: 0.619776\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551744; batch adversarial loss: 0.563600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570087; batch adversarial loss: 0.564621\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503851; batch adversarial loss: 0.590909\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549418; batch adversarial loss: 0.539781\n",
      "epoch 14; iter: 0; batch classifier loss: 0.452918; batch adversarial loss: 0.524168\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542174; batch adversarial loss: 0.557690\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545944; batch adversarial loss: 0.473745\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504777; batch adversarial loss: 0.577218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453241; batch adversarial loss: 0.522585\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551326; batch adversarial loss: 0.555184\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521302; batch adversarial loss: 0.520186\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462028; batch adversarial loss: 0.591495\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454780; batch adversarial loss: 0.580439\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456042; batch adversarial loss: 0.592450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503551; batch adversarial loss: 0.561162\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501687; batch adversarial loss: 0.556924\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510515; batch adversarial loss: 0.580440\n",
      "epoch 27; iter: 0; batch classifier loss: 0.543237; batch adversarial loss: 0.545607\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541439; batch adversarial loss: 0.585051\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490861; batch adversarial loss: 0.526645\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463413; batch adversarial loss: 0.517499\n",
      "epoch 31; iter: 0; batch classifier loss: 0.570718; batch adversarial loss: 0.598851\n",
      "epoch 32; iter: 0; batch classifier loss: 0.542892; batch adversarial loss: 0.507670\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455208; batch adversarial loss: 0.563616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.443500; batch adversarial loss: 0.571082\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479628; batch adversarial loss: 0.579627\n",
      "epoch 36; iter: 0; batch classifier loss: 0.523492; batch adversarial loss: 0.521341\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458998; batch adversarial loss: 0.528989\n",
      "epoch 38; iter: 0; batch classifier loss: 0.518885; batch adversarial loss: 0.528806\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465775; batch adversarial loss: 0.511387\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486310; batch adversarial loss: 0.570785\n",
      "epoch 41; iter: 0; batch classifier loss: 0.511750; batch adversarial loss: 0.605169\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434177; batch adversarial loss: 0.519190\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398598; batch adversarial loss: 0.544986\n",
      "epoch 44; iter: 0; batch classifier loss: 0.416982; batch adversarial loss: 0.536244\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485744; batch adversarial loss: 0.606122\n",
      "epoch 46; iter: 0; batch classifier loss: 0.519380; batch adversarial loss: 0.509525\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399437; batch adversarial loss: 0.615303\n",
      "epoch 48; iter: 0; batch classifier loss: 0.511232; batch adversarial loss: 0.509272\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422966; batch adversarial loss: 0.536469\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459672; batch adversarial loss: 0.633174\n",
      "epoch 51; iter: 0; batch classifier loss: 0.357846; batch adversarial loss: 0.464601\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470716; batch adversarial loss: 0.536391\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404032; batch adversarial loss: 0.588538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392862; batch adversarial loss: 0.501256\n",
      "epoch 55; iter: 0; batch classifier loss: 0.477718; batch adversarial loss: 0.553555\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399788; batch adversarial loss: 0.615155\n",
      "epoch 57; iter: 0; batch classifier loss: 0.419514; batch adversarial loss: 0.535911\n",
      "epoch 58; iter: 0; batch classifier loss: 0.437989; batch adversarial loss: 0.553115\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375757; batch adversarial loss: 0.631196\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411471; batch adversarial loss: 0.614985\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459058; batch adversarial loss: 0.482557\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415488; batch adversarial loss: 0.588499\n",
      "epoch 63; iter: 0; batch classifier loss: 0.487807; batch adversarial loss: 0.553805\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489869; batch adversarial loss: 0.546397\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382568; batch adversarial loss: 0.615889\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396777; batch adversarial loss: 0.518354\n",
      "epoch 67; iter: 0; batch classifier loss: 0.463822; batch adversarial loss: 0.606629\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414218; batch adversarial loss: 0.595848\n",
      "epoch 69; iter: 0; batch classifier loss: 0.362455; batch adversarial loss: 0.527144\n",
      "epoch 70; iter: 0; batch classifier loss: 0.511978; batch adversarial loss: 0.545888\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412469; batch adversarial loss: 0.563548\n",
      "epoch 72; iter: 0; batch classifier loss: 0.463670; batch adversarial loss: 0.590529\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417710; batch adversarial loss: 0.562695\n",
      "epoch 74; iter: 0; batch classifier loss: 0.561308; batch adversarial loss: 0.617050\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416448; batch adversarial loss: 0.607937\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386785; batch adversarial loss: 0.508664\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410313; batch adversarial loss: 0.526273\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448986; batch adversarial loss: 0.553744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399543; batch adversarial loss: 0.527941\n",
      "epoch 80; iter: 0; batch classifier loss: 0.405114; batch adversarial loss: 0.612960\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428411; batch adversarial loss: 0.616949\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406825; batch adversarial loss: 0.544729\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400682; batch adversarial loss: 0.580416\n",
      "epoch 84; iter: 0; batch classifier loss: 0.347301; batch adversarial loss: 0.499392\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423724; batch adversarial loss: 0.509707\n",
      "epoch 86; iter: 0; batch classifier loss: 0.364851; batch adversarial loss: 0.562558\n",
      "epoch 87; iter: 0; batch classifier loss: 0.447685; batch adversarial loss: 0.616387\n",
      "epoch 88; iter: 0; batch classifier loss: 0.347273; batch adversarial loss: 0.544567\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350962; batch adversarial loss: 0.598821\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397397; batch adversarial loss: 0.571164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399178; batch adversarial loss: 0.606655\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405655; batch adversarial loss: 0.562375\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424478; batch adversarial loss: 0.563751\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354854; batch adversarial loss: 0.518180\n",
      "epoch 95; iter: 0; batch classifier loss: 0.479991; batch adversarial loss: 0.589077\n",
      "epoch 96; iter: 0; batch classifier loss: 0.420013; batch adversarial loss: 0.518059\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379837; batch adversarial loss: 0.518731\n",
      "epoch 98; iter: 0; batch classifier loss: 0.427701; batch adversarial loss: 0.543774\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434493; batch adversarial loss: 0.474349\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341271; batch adversarial loss: 0.544234\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364164; batch adversarial loss: 0.571657\n",
      "epoch 102; iter: 0; batch classifier loss: 0.432175; batch adversarial loss: 0.579855\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373596; batch adversarial loss: 0.588338\n",
      "epoch 104; iter: 0; batch classifier loss: 0.381644; batch adversarial loss: 0.553831\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391194; batch adversarial loss: 0.544410\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412834; batch adversarial loss: 0.625192\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351378; batch adversarial loss: 0.526767\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362326; batch adversarial loss: 0.536331\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379570; batch adversarial loss: 0.482432\n",
      "epoch 110; iter: 0; batch classifier loss: 0.345972; batch adversarial loss: 0.517524\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372833; batch adversarial loss: 0.633507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.451057; batch adversarial loss: 0.527742\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353816; batch adversarial loss: 0.544536\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363419; batch adversarial loss: 0.641838\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331171; batch adversarial loss: 0.580548\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359283; batch adversarial loss: 0.527282\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378745; batch adversarial loss: 0.536492\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403048; batch adversarial loss: 0.544888\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374979; batch adversarial loss: 0.509272\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398512; batch adversarial loss: 0.579715\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400613; batch adversarial loss: 0.526506\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372477; batch adversarial loss: 0.571298\n",
      "epoch 123; iter: 0; batch classifier loss: 0.450337; batch adversarial loss: 0.553285\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393556; batch adversarial loss: 0.570894\n",
      "epoch 125; iter: 0; batch classifier loss: 0.331404; batch adversarial loss: 0.527164\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419859; batch adversarial loss: 0.465322\n",
      "epoch 127; iter: 0; batch classifier loss: 0.315421; batch adversarial loss: 0.544394\n",
      "epoch 128; iter: 0; batch classifier loss: 0.384790; batch adversarial loss: 0.554076\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389250; batch adversarial loss: 0.642092\n",
      "epoch 130; iter: 0; batch classifier loss: 0.392648; batch adversarial loss: 0.562823\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367888; batch adversarial loss: 0.500816\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405222; batch adversarial loss: 0.615942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.345502; batch adversarial loss: 0.517930\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368224; batch adversarial loss: 0.570908\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320057; batch adversarial loss: 0.509713\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416568; batch adversarial loss: 0.553860\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369181; batch adversarial loss: 0.517608\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333510; batch adversarial loss: 0.552743\n",
      "epoch 139; iter: 0; batch classifier loss: 0.424479; batch adversarial loss: 0.554024\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413521; batch adversarial loss: 0.473379\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345082; batch adversarial loss: 0.597888\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372045; batch adversarial loss: 0.580020\n",
      "epoch 143; iter: 0; batch classifier loss: 0.331463; batch adversarial loss: 0.553363\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337024; batch adversarial loss: 0.544311\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370199; batch adversarial loss: 0.579865\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377410; batch adversarial loss: 0.527028\n",
      "epoch 147; iter: 0; batch classifier loss: 0.323119; batch adversarial loss: 0.633554\n",
      "epoch 148; iter: 0; batch classifier loss: 0.398607; batch adversarial loss: 0.509555\n",
      "epoch 149; iter: 0; batch classifier loss: 0.325987; batch adversarial loss: 0.596786\n",
      "epoch 150; iter: 0; batch classifier loss: 0.327267; batch adversarial loss: 0.598189\n",
      "epoch 151; iter: 0; batch classifier loss: 0.429728; batch adversarial loss: 0.544959\n",
      "epoch 152; iter: 0; batch classifier loss: 0.409943; batch adversarial loss: 0.615317\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322088; batch adversarial loss: 0.562490\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352404; batch adversarial loss: 0.606089\n",
      "epoch 155; iter: 0; batch classifier loss: 0.431103; batch adversarial loss: 0.615670\n",
      "epoch 156; iter: 0; batch classifier loss: 0.400586; batch adversarial loss: 0.553175\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341048; batch adversarial loss: 0.589084\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397566; batch adversarial loss: 0.553962\n",
      "epoch 159; iter: 0; batch classifier loss: 0.332321; batch adversarial loss: 0.456726\n",
      "epoch 160; iter: 0; batch classifier loss: 0.389948; batch adversarial loss: 0.561788\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392978; batch adversarial loss: 0.580166\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390321; batch adversarial loss: 0.606850\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402564; batch adversarial loss: 0.518319\n",
      "epoch 164; iter: 0; batch classifier loss: 0.294990; batch adversarial loss: 0.526688\n",
      "epoch 165; iter: 0; batch classifier loss: 0.314538; batch adversarial loss: 0.517900\n",
      "epoch 166; iter: 0; batch classifier loss: 0.480183; batch adversarial loss: 0.544766\n",
      "epoch 167; iter: 0; batch classifier loss: 0.338832; batch adversarial loss: 0.571626\n",
      "epoch 168; iter: 0; batch classifier loss: 0.409086; batch adversarial loss: 0.518550\n",
      "epoch 169; iter: 0; batch classifier loss: 0.420015; batch adversarial loss: 0.473725\n",
      "epoch 170; iter: 0; batch classifier loss: 0.334613; batch adversarial loss: 0.651256\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320799; batch adversarial loss: 0.518091\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360530; batch adversarial loss: 0.624506\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370810; batch adversarial loss: 0.562538\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384612; batch adversarial loss: 0.544660\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384231; batch adversarial loss: 0.553356\n",
      "epoch 176; iter: 0; batch classifier loss: 0.406066; batch adversarial loss: 0.535897\n",
      "epoch 177; iter: 0; batch classifier loss: 0.373008; batch adversarial loss: 0.606500\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389059; batch adversarial loss: 0.562731\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351692; batch adversarial loss: 0.614865\n",
      "epoch 180; iter: 0; batch classifier loss: 0.313591; batch adversarial loss: 0.642839\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364565; batch adversarial loss: 0.527431\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336206; batch adversarial loss: 0.491526\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336586; batch adversarial loss: 0.544658\n",
      "epoch 184; iter: 0; batch classifier loss: 0.347307; batch adversarial loss: 0.509570\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331634; batch adversarial loss: 0.552856\n",
      "epoch 186; iter: 0; batch classifier loss: 0.321475; batch adversarial loss: 0.641618\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348989; batch adversarial loss: 0.553207\n",
      "epoch 188; iter: 0; batch classifier loss: 0.333924; batch adversarial loss: 0.579781\n",
      "epoch 189; iter: 0; batch classifier loss: 0.378989; batch adversarial loss: 0.597994\n",
      "epoch 190; iter: 0; batch classifier loss: 0.443232; batch adversarial loss: 0.562737\n",
      "epoch 191; iter: 0; batch classifier loss: 0.333810; batch adversarial loss: 0.580582\n",
      "epoch 192; iter: 0; batch classifier loss: 0.409678; batch adversarial loss: 0.606100\n",
      "epoch 193; iter: 0; batch classifier loss: 0.408349; batch adversarial loss: 0.517982\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384952; batch adversarial loss: 0.615515\n",
      "epoch 195; iter: 0; batch classifier loss: 0.426872; batch adversarial loss: 0.562480\n",
      "epoch 196; iter: 0; batch classifier loss: 0.390638; batch adversarial loss: 0.508476\n",
      "epoch 197; iter: 0; batch classifier loss: 0.346227; batch adversarial loss: 0.526383\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349883; batch adversarial loss: 0.544727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363111; batch adversarial loss: 0.579853\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682478; batch adversarial loss: 0.694327\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596276; batch adversarial loss: 0.653106\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583673; batch adversarial loss: 0.699981\n",
      "epoch 3; iter: 0; batch classifier loss: 0.560176; batch adversarial loss: 0.693685\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557147; batch adversarial loss: 0.706032\n",
      "epoch 5; iter: 0; batch classifier loss: 0.606185; batch adversarial loss: 0.611643\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597387; batch adversarial loss: 0.616602\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509959; batch adversarial loss: 0.684136\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576525; batch adversarial loss: 0.675577\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502842; batch adversarial loss: 0.551709\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509497; batch adversarial loss: 0.604315\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516660; batch adversarial loss: 0.622215\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497659; batch adversarial loss: 0.571375\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500391; batch adversarial loss: 0.616200\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560232; batch adversarial loss: 0.605239\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482586; batch adversarial loss: 0.599668\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467141; batch adversarial loss: 0.533757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505851; batch adversarial loss: 0.623087\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476277; batch adversarial loss: 0.533861\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488818; batch adversarial loss: 0.600580\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485792; batch adversarial loss: 0.580636\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501429; batch adversarial loss: 0.523840\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468379; batch adversarial loss: 0.512798\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464830; batch adversarial loss: 0.526242\n",
      "epoch 24; iter: 0; batch classifier loss: 0.439507; batch adversarial loss: 0.593045\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468962; batch adversarial loss: 0.531221\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457912; batch adversarial loss: 0.537035\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472132; batch adversarial loss: 0.548965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.506414; batch adversarial loss: 0.576291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.452606; batch adversarial loss: 0.586025\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440914; batch adversarial loss: 0.543009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517532; batch adversarial loss: 0.487756\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512606; batch adversarial loss: 0.531561\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518976; batch adversarial loss: 0.570512\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421293; batch adversarial loss: 0.537821\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458422; batch adversarial loss: 0.544719\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478003; batch adversarial loss: 0.559572\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487691; batch adversarial loss: 0.529153\n",
      "epoch 38; iter: 0; batch classifier loss: 0.324211; batch adversarial loss: 0.462052\n",
      "epoch 39; iter: 0; batch classifier loss: 0.379426; batch adversarial loss: 0.547153\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418986; batch adversarial loss: 0.579304\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431101; batch adversarial loss: 0.597584\n",
      "epoch 42; iter: 0; batch classifier loss: 0.539707; batch adversarial loss: 0.527362\n",
      "epoch 43; iter: 0; batch classifier loss: 0.532358; batch adversarial loss: 0.560767\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336117; batch adversarial loss: 0.579646\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466929; batch adversarial loss: 0.570305\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422263; batch adversarial loss: 0.535450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520334; batch adversarial loss: 0.502521\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469387; batch adversarial loss: 0.525537\n",
      "epoch 49; iter: 0; batch classifier loss: 0.517119; batch adversarial loss: 0.568931\n",
      "epoch 50; iter: 0; batch classifier loss: 0.397947; batch adversarial loss: 0.594885\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444323; batch adversarial loss: 0.536064\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380835; batch adversarial loss: 0.564564\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394567; batch adversarial loss: 0.562428\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453022; batch adversarial loss: 0.511005\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425805; batch adversarial loss: 0.552178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447288; batch adversarial loss: 0.625764\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412875; batch adversarial loss: 0.557694\n",
      "epoch 58; iter: 0; batch classifier loss: 0.467531; batch adversarial loss: 0.552872\n",
      "epoch 59; iter: 0; batch classifier loss: 0.341725; batch adversarial loss: 0.556945\n",
      "epoch 60; iter: 0; batch classifier loss: 0.380412; batch adversarial loss: 0.546134\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475098; batch adversarial loss: 0.498842\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386307; batch adversarial loss: 0.658343\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410713; batch adversarial loss: 0.542772\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432181; batch adversarial loss: 0.516079\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367801; batch adversarial loss: 0.565606\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412250; batch adversarial loss: 0.559206\n",
      "epoch 67; iter: 0; batch classifier loss: 0.390348; batch adversarial loss: 0.581352\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407517; batch adversarial loss: 0.576987\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428321; batch adversarial loss: 0.580025\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393904; batch adversarial loss: 0.529707\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408980; batch adversarial loss: 0.479877\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377359; batch adversarial loss: 0.583714\n",
      "epoch 73; iter: 0; batch classifier loss: 0.457640; batch adversarial loss: 0.573895\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432517; batch adversarial loss: 0.605356\n",
      "epoch 75; iter: 0; batch classifier loss: 0.359801; batch adversarial loss: 0.605590\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443870; batch adversarial loss: 0.587228\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417258; batch adversarial loss: 0.515810\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415882; batch adversarial loss: 0.553527\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453377; batch adversarial loss: 0.479533\n",
      "epoch 80; iter: 0; batch classifier loss: 0.486591; batch adversarial loss: 0.563248\n",
      "epoch 81; iter: 0; batch classifier loss: 0.334160; batch adversarial loss: 0.619139\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443693; batch adversarial loss: 0.597932\n",
      "epoch 83; iter: 0; batch classifier loss: 0.424577; batch adversarial loss: 0.473080\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370943; batch adversarial loss: 0.564120\n",
      "epoch 85; iter: 0; batch classifier loss: 0.363924; batch adversarial loss: 0.538705\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391249; batch adversarial loss: 0.545007\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392471; batch adversarial loss: 0.512053\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427654; batch adversarial loss: 0.569131\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386175; batch adversarial loss: 0.519954\n",
      "epoch 90; iter: 0; batch classifier loss: 0.414059; batch adversarial loss: 0.571086\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416404; batch adversarial loss: 0.593145\n",
      "epoch 92; iter: 0; batch classifier loss: 0.475969; batch adversarial loss: 0.645663\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402369; batch adversarial loss: 0.609006\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435641; batch adversarial loss: 0.543891\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399480; batch adversarial loss: 0.482563\n",
      "epoch 96; iter: 0; batch classifier loss: 0.452787; batch adversarial loss: 0.571135\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358816; batch adversarial loss: 0.577940\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371786; batch adversarial loss: 0.499119\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375942; batch adversarial loss: 0.543563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406281; batch adversarial loss: 0.485879\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387847; batch adversarial loss: 0.590064\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414672; batch adversarial loss: 0.496526\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419631; batch adversarial loss: 0.561626\n",
      "epoch 104; iter: 0; batch classifier loss: 0.338375; batch adversarial loss: 0.492272\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360229; batch adversarial loss: 0.546067\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334712; batch adversarial loss: 0.559070\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406488; batch adversarial loss: 0.543610\n",
      "epoch 108; iter: 0; batch classifier loss: 0.419111; batch adversarial loss: 0.590602\n",
      "epoch 109; iter: 0; batch classifier loss: 0.311669; batch adversarial loss: 0.518610\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367713; batch adversarial loss: 0.616767\n",
      "epoch 111; iter: 0; batch classifier loss: 0.378358; batch adversarial loss: 0.582000\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385172; batch adversarial loss: 0.562603\n",
      "epoch 113; iter: 0; batch classifier loss: 0.301794; batch adversarial loss: 0.527357\n",
      "epoch 114; iter: 0; batch classifier loss: 0.445354; batch adversarial loss: 0.581938\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389233; batch adversarial loss: 0.517929\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351037; batch adversarial loss: 0.492387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.352037; batch adversarial loss: 0.550451\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371176; batch adversarial loss: 0.554637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.477406; batch adversarial loss: 0.478997\n",
      "epoch 120; iter: 0; batch classifier loss: 0.409657; batch adversarial loss: 0.553485\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403665; batch adversarial loss: 0.526693\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385752; batch adversarial loss: 0.562729\n",
      "epoch 123; iter: 0; batch classifier loss: 0.345670; batch adversarial loss: 0.578497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.316419; batch adversarial loss: 0.515355\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363259; batch adversarial loss: 0.609361\n",
      "epoch 126; iter: 0; batch classifier loss: 0.356384; batch adversarial loss: 0.616095\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372938; batch adversarial loss: 0.512220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.423579; batch adversarial loss: 0.519958\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339663; batch adversarial loss: 0.465498\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383305; batch adversarial loss: 0.607621\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427696; batch adversarial loss: 0.591292\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346399; batch adversarial loss: 0.587095\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378999; batch adversarial loss: 0.540481\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355511; batch adversarial loss: 0.614609\n",
      "epoch 135; iter: 0; batch classifier loss: 0.323839; batch adversarial loss: 0.505985\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361337; batch adversarial loss: 0.597055\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384026; batch adversarial loss: 0.644533\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351925; batch adversarial loss: 0.546167\n",
      "epoch 139; iter: 0; batch classifier loss: 0.295400; batch adversarial loss: 0.524588\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419626; batch adversarial loss: 0.569829\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358148; batch adversarial loss: 0.500187\n",
      "epoch 142; iter: 0; batch classifier loss: 0.332418; batch adversarial loss: 0.578425\n",
      "epoch 143; iter: 0; batch classifier loss: 0.295649; batch adversarial loss: 0.554189\n",
      "epoch 144; iter: 0; batch classifier loss: 0.259842; batch adversarial loss: 0.639288\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387198; batch adversarial loss: 0.679916\n",
      "epoch 146; iter: 0; batch classifier loss: 0.287997; batch adversarial loss: 0.555367\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410063; batch adversarial loss: 0.556496\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344383; batch adversarial loss: 0.558027\n",
      "epoch 149; iter: 0; batch classifier loss: 0.411722; batch adversarial loss: 0.529606\n",
      "epoch 150; iter: 0; batch classifier loss: 0.297131; batch adversarial loss: 0.577668\n",
      "epoch 151; iter: 0; batch classifier loss: 0.483355; batch adversarial loss: 0.599017\n",
      "epoch 152; iter: 0; batch classifier loss: 0.289501; batch adversarial loss: 0.541618\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384124; batch adversarial loss: 0.477154\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358239; batch adversarial loss: 0.538188\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369327; batch adversarial loss: 0.553558\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.522040\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365939; batch adversarial loss: 0.597948\n",
      "epoch 158; iter: 0; batch classifier loss: 0.317263; batch adversarial loss: 0.587594\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352904; batch adversarial loss: 0.555426\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328610; batch adversarial loss: 0.551528\n",
      "epoch 161; iter: 0; batch classifier loss: 0.471242; batch adversarial loss: 0.504345\n",
      "epoch 162; iter: 0; batch classifier loss: 0.370543; batch adversarial loss: 0.478642\n",
      "epoch 163; iter: 0; batch classifier loss: 0.315996; batch adversarial loss: 0.467753\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398636; batch adversarial loss: 0.553193\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334473; batch adversarial loss: 0.475629\n",
      "epoch 166; iter: 0; batch classifier loss: 0.433906; batch adversarial loss: 0.573701\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416193; batch adversarial loss: 0.488747\n",
      "epoch 168; iter: 0; batch classifier loss: 0.297111; batch adversarial loss: 0.614406\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354347; batch adversarial loss: 0.664919\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412607; batch adversarial loss: 0.519918\n",
      "epoch 171; iter: 0; batch classifier loss: 0.371038; batch adversarial loss: 0.641294\n",
      "epoch 172; iter: 0; batch classifier loss: 0.429375; batch adversarial loss: 0.549373\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369487; batch adversarial loss: 0.544839\n",
      "epoch 174; iter: 0; batch classifier loss: 0.451870; batch adversarial loss: 0.552235\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294291; batch adversarial loss: 0.550636\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373645; batch adversarial loss: 0.556177\n",
      "epoch 177; iter: 0; batch classifier loss: 0.446083; batch adversarial loss: 0.594736\n",
      "epoch 178; iter: 0; batch classifier loss: 0.419093; batch adversarial loss: 0.589891\n",
      "epoch 179; iter: 0; batch classifier loss: 0.388242; batch adversarial loss: 0.453224\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379753; batch adversarial loss: 0.482029\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371117; batch adversarial loss: 0.532295\n",
      "epoch 182; iter: 0; batch classifier loss: 0.433040; batch adversarial loss: 0.565889\n",
      "epoch 183; iter: 0; batch classifier loss: 0.354420; batch adversarial loss: 0.576356\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416705; batch adversarial loss: 0.528073\n",
      "epoch 185; iter: 0; batch classifier loss: 0.395609; batch adversarial loss: 0.562771\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334938; batch adversarial loss: 0.518537\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351484; batch adversarial loss: 0.549024\n",
      "epoch 188; iter: 0; batch classifier loss: 0.294485; batch adversarial loss: 0.578538\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381559; batch adversarial loss: 0.629769\n",
      "epoch 190; iter: 0; batch classifier loss: 0.392056; batch adversarial loss: 0.568192\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386442; batch adversarial loss: 0.512118\n",
      "epoch 192; iter: 0; batch classifier loss: 0.406667; batch adversarial loss: 0.546693\n",
      "epoch 193; iter: 0; batch classifier loss: 0.384315; batch adversarial loss: 0.463555\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380971; batch adversarial loss: 0.558204\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393966; batch adversarial loss: 0.540860\n",
      "epoch 196; iter: 0; batch classifier loss: 0.414956; batch adversarial loss: 0.480484\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317339; batch adversarial loss: 0.540798\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333993; batch adversarial loss: 0.545799\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349232; batch adversarial loss: 0.558976\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690509; batch adversarial loss: 0.769850\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607509; batch adversarial loss: 0.718634\n",
      "epoch 2; iter: 0; batch classifier loss: 0.548371; batch adversarial loss: 0.729972\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544528; batch adversarial loss: 0.694071\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589989; batch adversarial loss: 0.699679\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539588; batch adversarial loss: 0.642525\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585790; batch adversarial loss: 0.623477\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582638; batch adversarial loss: 0.619435\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511135; batch adversarial loss: 0.631874\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499553; batch adversarial loss: 0.588018\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499223; batch adversarial loss: 0.566821\n",
      "epoch 11; iter: 0; batch classifier loss: 0.474308; batch adversarial loss: 0.593668\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521426; batch adversarial loss: 0.535429\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461062; batch adversarial loss: 0.568362\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557042; batch adversarial loss: 0.554956\n",
      "epoch 15; iter: 0; batch classifier loss: 0.557671; batch adversarial loss: 0.556590\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500073; batch adversarial loss: 0.582689\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503087; batch adversarial loss: 0.518943\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475768; batch adversarial loss: 0.487070\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426459; batch adversarial loss: 0.589752\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523461; batch adversarial loss: 0.558496\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544150; batch adversarial loss: 0.595503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474093; batch adversarial loss: 0.561573\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445646; batch adversarial loss: 0.563698\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467876; batch adversarial loss: 0.510800\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471425; batch adversarial loss: 0.513730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.471710; batch adversarial loss: 0.512079\n",
      "epoch 27; iter: 0; batch classifier loss: 0.546751; batch adversarial loss: 0.521930\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479704; batch adversarial loss: 0.560788\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458626; batch adversarial loss: 0.531205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474576; batch adversarial loss: 0.567340\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446603; batch adversarial loss: 0.598326\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454461; batch adversarial loss: 0.543507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426279; batch adversarial loss: 0.533273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455814; batch adversarial loss: 0.544200\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405622; batch adversarial loss: 0.582714\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442320; batch adversarial loss: 0.564050\n",
      "epoch 37; iter: 0; batch classifier loss: 0.515962; batch adversarial loss: 0.512129\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440168; batch adversarial loss: 0.571338\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438531; batch adversarial loss: 0.554806\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404771; batch adversarial loss: 0.510781\n",
      "epoch 41; iter: 0; batch classifier loss: 0.379183; batch adversarial loss: 0.596415\n",
      "epoch 42; iter: 0; batch classifier loss: 0.509276; batch adversarial loss: 0.623652\n",
      "epoch 43; iter: 0; batch classifier loss: 0.528875; batch adversarial loss: 0.544432\n",
      "epoch 44; iter: 0; batch classifier loss: 0.530507; batch adversarial loss: 0.589848\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448052; batch adversarial loss: 0.535663\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419085; batch adversarial loss: 0.615473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430000; batch adversarial loss: 0.492435\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437587; batch adversarial loss: 0.474915\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394602; batch adversarial loss: 0.597429\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434974; batch adversarial loss: 0.509252\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485503; batch adversarial loss: 0.589068\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452070; batch adversarial loss: 0.518123\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404818; batch adversarial loss: 0.535226\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430700; batch adversarial loss: 0.526172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.455253; batch adversarial loss: 0.606957\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468552; batch adversarial loss: 0.579490\n",
      "epoch 57; iter: 0; batch classifier loss: 0.354338; batch adversarial loss: 0.571847\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431862; batch adversarial loss: 0.580014\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413481; batch adversarial loss: 0.509068\n",
      "epoch 60; iter: 0; batch classifier loss: 0.462586; batch adversarial loss: 0.580703\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376414; batch adversarial loss: 0.597937\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398425; batch adversarial loss: 0.552787\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421811; batch adversarial loss: 0.579982\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420483; batch adversarial loss: 0.623761\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374413; batch adversarial loss: 0.652621\n",
      "epoch 66; iter: 0; batch classifier loss: 0.367442; batch adversarial loss: 0.502184\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405462; batch adversarial loss: 0.500249\n",
      "epoch 68; iter: 0; batch classifier loss: 0.463573; batch adversarial loss: 0.598099\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374363; batch adversarial loss: 0.525499\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397673; batch adversarial loss: 0.624142\n",
      "epoch 71; iter: 0; batch classifier loss: 0.397030; batch adversarial loss: 0.527291\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432245; batch adversarial loss: 0.463065\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407679; batch adversarial loss: 0.517065\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448271; batch adversarial loss: 0.563855\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366425; batch adversarial loss: 0.543464\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385281; batch adversarial loss: 0.571408\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382849; batch adversarial loss: 0.560553\n",
      "epoch 78; iter: 0; batch classifier loss: 0.399081; batch adversarial loss: 0.605807\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378945; batch adversarial loss: 0.533041\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380484; batch adversarial loss: 0.513833\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391030; batch adversarial loss: 0.506418\n",
      "epoch 82; iter: 0; batch classifier loss: 0.450055; batch adversarial loss: 0.544304\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365070; batch adversarial loss: 0.506694\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426875; batch adversarial loss: 0.532126\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383384; batch adversarial loss: 0.508439\n",
      "epoch 86; iter: 0; batch classifier loss: 0.441932; batch adversarial loss: 0.593405\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360187; batch adversarial loss: 0.518047\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426249; batch adversarial loss: 0.475444\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429295; batch adversarial loss: 0.634050\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363608; batch adversarial loss: 0.536307\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334303; batch adversarial loss: 0.545596\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373352; batch adversarial loss: 0.494426\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364177; batch adversarial loss: 0.527987\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444402; batch adversarial loss: 0.561245\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407254; batch adversarial loss: 0.519502\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378747; batch adversarial loss: 0.527862\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387352; batch adversarial loss: 0.501213\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420323; batch adversarial loss: 0.580316\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366989; batch adversarial loss: 0.569022\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341273; batch adversarial loss: 0.524399\n",
      "epoch 101; iter: 0; batch classifier loss: 0.378368; batch adversarial loss: 0.604696\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401311; batch adversarial loss: 0.572602\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416021; batch adversarial loss: 0.562911\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354305; batch adversarial loss: 0.571783\n",
      "epoch 105; iter: 0; batch classifier loss: 0.420020; batch adversarial loss: 0.689140\n",
      "epoch 106; iter: 0; batch classifier loss: 0.309661; batch adversarial loss: 0.654354\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381244; batch adversarial loss: 0.507731\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351428; batch adversarial loss: 0.626689\n",
      "epoch 109; iter: 0; batch classifier loss: 0.462766; batch adversarial loss: 0.526979\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357582; batch adversarial loss: 0.544882\n",
      "epoch 111; iter: 0; batch classifier loss: 0.464245; batch adversarial loss: 0.490509\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361247; batch adversarial loss: 0.563581\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353022; batch adversarial loss: 0.491373\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385695; batch adversarial loss: 0.553679\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386779; batch adversarial loss: 0.562541\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412638; batch adversarial loss: 0.572351\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384566; batch adversarial loss: 0.598468\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390718; batch adversarial loss: 0.499848\n",
      "epoch 119; iter: 0; batch classifier loss: 0.427267; batch adversarial loss: 0.481897\n",
      "epoch 120; iter: 0; batch classifier loss: 0.345781; batch adversarial loss: 0.563086\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380098; batch adversarial loss: 0.554040\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352291; batch adversarial loss: 0.545006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.380733; batch adversarial loss: 0.579768\n",
      "epoch 124; iter: 0; batch classifier loss: 0.293713; batch adversarial loss: 0.580696\n",
      "epoch 125; iter: 0; batch classifier loss: 0.425939; batch adversarial loss: 0.499754\n",
      "epoch 126; iter: 0; batch classifier loss: 0.390773; batch adversarial loss: 0.589544\n",
      "epoch 127; iter: 0; batch classifier loss: 0.404982; batch adversarial loss: 0.499808\n",
      "epoch 128; iter: 0; batch classifier loss: 0.427060; batch adversarial loss: 0.606976\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386214; batch adversarial loss: 0.579845\n",
      "epoch 130; iter: 0; batch classifier loss: 0.438533; batch adversarial loss: 0.544866\n",
      "epoch 131; iter: 0; batch classifier loss: 0.462959; batch adversarial loss: 0.473988\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335808; batch adversarial loss: 0.588794\n",
      "epoch 133; iter: 0; batch classifier loss: 0.443270; batch adversarial loss: 0.562679\n",
      "epoch 134; iter: 0; batch classifier loss: 0.340808; batch adversarial loss: 0.527013\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368169; batch adversarial loss: 0.553643\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401429; batch adversarial loss: 0.580153\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357911; batch adversarial loss: 0.571792\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377417; batch adversarial loss: 0.517634\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379942; batch adversarial loss: 0.589408\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387082; batch adversarial loss: 0.562173\n",
      "epoch 141; iter: 0; batch classifier loss: 0.331696; batch adversarial loss: 0.571279\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350341; batch adversarial loss: 0.571507\n",
      "epoch 143; iter: 0; batch classifier loss: 0.302086; batch adversarial loss: 0.508970\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365664; batch adversarial loss: 0.633260\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351378; batch adversarial loss: 0.597914\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359711; batch adversarial loss: 0.545122\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338376; batch adversarial loss: 0.553832\n",
      "epoch 148; iter: 0; batch classifier loss: 0.470352; batch adversarial loss: 0.571258\n",
      "epoch 149; iter: 0; batch classifier loss: 0.407344; batch adversarial loss: 0.526873\n",
      "epoch 150; iter: 0; batch classifier loss: 0.412188; batch adversarial loss: 0.553776\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386130; batch adversarial loss: 0.535602\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375959; batch adversarial loss: 0.509091\n",
      "epoch 153; iter: 0; batch classifier loss: 0.458651; batch adversarial loss: 0.607050\n",
      "epoch 154; iter: 0; batch classifier loss: 0.338977; batch adversarial loss: 0.535355\n",
      "epoch 155; iter: 0; batch classifier loss: 0.372958; batch adversarial loss: 0.571256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352801; batch adversarial loss: 0.509301\n",
      "epoch 157; iter: 0; batch classifier loss: 0.325523; batch adversarial loss: 0.633440\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361739; batch adversarial loss: 0.500206\n",
      "epoch 159; iter: 0; batch classifier loss: 0.315533; batch adversarial loss: 0.580522\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350589; batch adversarial loss: 0.624687\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350086; batch adversarial loss: 0.508037\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356731; batch adversarial loss: 0.589640\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361526; batch adversarial loss: 0.490729\n",
      "epoch 164; iter: 0; batch classifier loss: 0.390396; batch adversarial loss: 0.615543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398163; batch adversarial loss: 0.499680\n",
      "epoch 166; iter: 0; batch classifier loss: 0.261127; batch adversarial loss: 0.517779\n",
      "epoch 167; iter: 0; batch classifier loss: 0.403379; batch adversarial loss: 0.536068\n",
      "epoch 168; iter: 0; batch classifier loss: 0.423118; batch adversarial loss: 0.562339\n",
      "epoch 169; iter: 0; batch classifier loss: 0.418416; batch adversarial loss: 0.589269\n",
      "epoch 170; iter: 0; batch classifier loss: 0.369872; batch adversarial loss: 0.473282\n",
      "epoch 171; iter: 0; batch classifier loss: 0.397347; batch adversarial loss: 0.562600\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350546; batch adversarial loss: 0.597813\n",
      "epoch 173; iter: 0; batch classifier loss: 0.411929; batch adversarial loss: 0.570845\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344705; batch adversarial loss: 0.589481\n",
      "epoch 175; iter: 0; batch classifier loss: 0.355720; batch adversarial loss: 0.544773\n",
      "epoch 176; iter: 0; batch classifier loss: 0.327225; batch adversarial loss: 0.607301\n",
      "epoch 177; iter: 0; batch classifier loss: 0.377720; batch adversarial loss: 0.562513\n",
      "epoch 178; iter: 0; batch classifier loss: 0.275463; batch adversarial loss: 0.580058\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357622; batch adversarial loss: 0.634047\n",
      "epoch 180; iter: 0; batch classifier loss: 0.436495; batch adversarial loss: 0.598339\n",
      "epoch 181; iter: 0; batch classifier loss: 0.297559; batch adversarial loss: 0.589359\n",
      "epoch 182; iter: 0; batch classifier loss: 0.432222; batch adversarial loss: 0.580741\n",
      "epoch 183; iter: 0; batch classifier loss: 0.321897; batch adversarial loss: 0.517928\n",
      "epoch 184; iter: 0; batch classifier loss: 0.317740; batch adversarial loss: 0.526824\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303698; batch adversarial loss: 0.544585\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332595; batch adversarial loss: 0.544128\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357524; batch adversarial loss: 0.481740\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385912; batch adversarial loss: 0.579579\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292044; batch adversarial loss: 0.580362\n",
      "epoch 190; iter: 0; batch classifier loss: 0.345272; batch adversarial loss: 0.490706\n",
      "epoch 191; iter: 0; batch classifier loss: 0.291992; batch adversarial loss: 0.527281\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392760; batch adversarial loss: 0.455036\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348765; batch adversarial loss: 0.580823\n",
      "epoch 194; iter: 0; batch classifier loss: 0.371252; batch adversarial loss: 0.597836\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339986; batch adversarial loss: 0.606601\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310457; batch adversarial loss: 0.588816\n",
      "epoch 197; iter: 0; batch classifier loss: 0.421927; batch adversarial loss: 0.544647\n",
      "epoch 198; iter: 0; batch classifier loss: 0.369621; batch adversarial loss: 0.554066\n",
      "epoch 199; iter: 0; batch classifier loss: 0.324154; batch adversarial loss: 0.588889\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671116; batch adversarial loss: 0.662590\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597963; batch adversarial loss: 0.697540\n",
      "epoch 2; iter: 0; batch classifier loss: 0.535491; batch adversarial loss: 0.673938\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544796; batch adversarial loss: 0.687776\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551165; batch adversarial loss: 0.634848\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574101; batch adversarial loss: 0.610201\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542534; batch adversarial loss: 0.685262\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555114; batch adversarial loss: 0.563087\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531300; batch adversarial loss: 0.574917\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558701; batch adversarial loss: 0.545028\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555337; batch adversarial loss: 0.582194\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532386; batch adversarial loss: 0.533971\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488918; batch adversarial loss: 0.599400\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448545; batch adversarial loss: 0.502462\n",
      "epoch 14; iter: 0; batch classifier loss: 0.658396; batch adversarial loss: 0.513089\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483901; batch adversarial loss: 0.531318\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496051; batch adversarial loss: 0.543206\n",
      "epoch 17; iter: 0; batch classifier loss: 0.440676; batch adversarial loss: 0.607338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.580682; batch adversarial loss: 0.528814\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519119; batch adversarial loss: 0.602627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.491306; batch adversarial loss: 0.579205\n",
      "epoch 21; iter: 0; batch classifier loss: 0.466493; batch adversarial loss: 0.655886\n",
      "epoch 22; iter: 0; batch classifier loss: 0.545553; batch adversarial loss: 0.588300\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474398; batch adversarial loss: 0.537450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528552; batch adversarial loss: 0.597988\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555080; batch adversarial loss: 0.587240\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478352; batch adversarial loss: 0.542831\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448950; batch adversarial loss: 0.582724\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451749; batch adversarial loss: 0.556031\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475254; batch adversarial loss: 0.518312\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436725; batch adversarial loss: 0.593912\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437153; batch adversarial loss: 0.653097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.424525; batch adversarial loss: 0.580397\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450858; batch adversarial loss: 0.463548\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464203; batch adversarial loss: 0.576241\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458167; batch adversarial loss: 0.513262\n",
      "epoch 36; iter: 0; batch classifier loss: 0.506634; batch adversarial loss: 0.596613\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448016; batch adversarial loss: 0.569753\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405034; batch adversarial loss: 0.518899\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453553; batch adversarial loss: 0.589117\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405475; batch adversarial loss: 0.526493\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403355; batch adversarial loss: 0.562223\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499175; batch adversarial loss: 0.490813\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385433; batch adversarial loss: 0.590301\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468109; batch adversarial loss: 0.507955\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425235; batch adversarial loss: 0.544684\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468076; batch adversarial loss: 0.590766\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456469; batch adversarial loss: 0.517883\n",
      "epoch 48; iter: 0; batch classifier loss: 0.488000; batch adversarial loss: 0.480385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404329; batch adversarial loss: 0.599359\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457823; batch adversarial loss: 0.544479\n",
      "epoch 51; iter: 0; batch classifier loss: 0.491785; batch adversarial loss: 0.562820\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440397; batch adversarial loss: 0.562881\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445740; batch adversarial loss: 0.572058\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399487; batch adversarial loss: 0.471145\n",
      "epoch 55; iter: 0; batch classifier loss: 0.502517; batch adversarial loss: 0.581247\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417933; batch adversarial loss: 0.507905\n",
      "epoch 57; iter: 0; batch classifier loss: 0.347833; batch adversarial loss: 0.507846\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414357; batch adversarial loss: 0.544135\n",
      "epoch 59; iter: 0; batch classifier loss: 0.460543; batch adversarial loss: 0.563298\n",
      "epoch 60; iter: 0; batch classifier loss: 0.449858; batch adversarial loss: 0.516549\n",
      "epoch 61; iter: 0; batch classifier loss: 0.367157; batch adversarial loss: 0.516050\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396110; batch adversarial loss: 0.470403\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397171; batch adversarial loss: 0.638186\n",
      "epoch 64; iter: 0; batch classifier loss: 0.400366; batch adversarial loss: 0.488505\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432871; batch adversarial loss: 0.534400\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387313; batch adversarial loss: 0.554128\n",
      "epoch 67; iter: 0; batch classifier loss: 0.464732; batch adversarial loss: 0.516529\n",
      "epoch 68; iter: 0; batch classifier loss: 0.348554; batch adversarial loss: 0.545135\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416334; batch adversarial loss: 0.617855\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380418; batch adversarial loss: 0.562892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.386237; batch adversarial loss: 0.526734\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422207; batch adversarial loss: 0.599660\n",
      "epoch 73; iter: 0; batch classifier loss: 0.449252; batch adversarial loss: 0.543372\n",
      "epoch 74; iter: 0; batch classifier loss: 0.379217; batch adversarial loss: 0.607807\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447567; batch adversarial loss: 0.508030\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439260; batch adversarial loss: 0.525027\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413249; batch adversarial loss: 0.536013\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376838; batch adversarial loss: 0.444302\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399260; batch adversarial loss: 0.535907\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412721; batch adversarial loss: 0.527806\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367419; batch adversarial loss: 0.508633\n",
      "epoch 82; iter: 0; batch classifier loss: 0.452328; batch adversarial loss: 0.525226\n",
      "epoch 83; iter: 0; batch classifier loss: 0.468868; batch adversarial loss: 0.479928\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366157; batch adversarial loss: 0.635404\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383261; batch adversarial loss: 0.572845\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406966; batch adversarial loss: 0.479851\n",
      "epoch 87; iter: 0; batch classifier loss: 0.341817; batch adversarial loss: 0.646110\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408487; batch adversarial loss: 0.573587\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374155; batch adversarial loss: 0.471701\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364106; batch adversarial loss: 0.526399\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454473; batch adversarial loss: 0.478736\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412499; batch adversarial loss: 0.544893\n",
      "epoch 93; iter: 0; batch classifier loss: 0.394889; batch adversarial loss: 0.563520\n",
      "epoch 94; iter: 0; batch classifier loss: 0.506339; batch adversarial loss: 0.516961\n",
      "epoch 95; iter: 0; batch classifier loss: 0.332396; batch adversarial loss: 0.544701\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332606; batch adversarial loss: 0.488739\n",
      "epoch 97; iter: 0; batch classifier loss: 0.436700; batch adversarial loss: 0.573148\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361760; batch adversarial loss: 0.571281\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409807; batch adversarial loss: 0.563461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.342374; batch adversarial loss: 0.563529\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400694; batch adversarial loss: 0.515841\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415044; batch adversarial loss: 0.572881\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372226; batch adversarial loss: 0.544659\n",
      "epoch 104; iter: 0; batch classifier loss: 0.532588; batch adversarial loss: 0.544070\n",
      "epoch 105; iter: 0; batch classifier loss: 0.323995; batch adversarial loss: 0.508108\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355673; batch adversarial loss: 0.562863\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412882; batch adversarial loss: 0.489857\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338170; batch adversarial loss: 0.526980\n",
      "epoch 109; iter: 0; batch classifier loss: 0.494374; batch adversarial loss: 0.581812\n",
      "epoch 110; iter: 0; batch classifier loss: 0.484678; batch adversarial loss: 0.545728\n",
      "epoch 111; iter: 0; batch classifier loss: 0.442380; batch adversarial loss: 0.553320\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361699; batch adversarial loss: 0.608337\n",
      "epoch 113; iter: 0; batch classifier loss: 0.411682; batch adversarial loss: 0.544448\n",
      "epoch 114; iter: 0; batch classifier loss: 0.319035; batch adversarial loss: 0.554232\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418450; batch adversarial loss: 0.498257\n",
      "epoch 116; iter: 0; batch classifier loss: 0.334165; batch adversarial loss: 0.582922\n",
      "epoch 117; iter: 0; batch classifier loss: 0.454648; batch adversarial loss: 0.554266\n",
      "epoch 118; iter: 0; batch classifier loss: 0.332897; batch adversarial loss: 0.535377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.338269; batch adversarial loss: 0.581511\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386885; batch adversarial loss: 0.498108\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380757; batch adversarial loss: 0.572131\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394084; batch adversarial loss: 0.479270\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361698; batch adversarial loss: 0.516046\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329288; batch adversarial loss: 0.553777\n",
      "epoch 125; iter: 0; batch classifier loss: 0.296971; batch adversarial loss: 0.591738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369924; batch adversarial loss: 0.544857\n",
      "epoch 127; iter: 0; batch classifier loss: 0.445697; batch adversarial loss: 0.591685\n",
      "epoch 128; iter: 0; batch classifier loss: 0.400529; batch adversarial loss: 0.609293\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319561; batch adversarial loss: 0.498393\n",
      "epoch 130; iter: 0; batch classifier loss: 0.483419; batch adversarial loss: 0.544236\n",
      "epoch 131; iter: 0; batch classifier loss: 0.433427; batch adversarial loss: 0.582513\n",
      "epoch 132; iter: 0; batch classifier loss: 0.421172; batch adversarial loss: 0.517372\n",
      "epoch 133; iter: 0; batch classifier loss: 0.418966; batch adversarial loss: 0.489347\n",
      "epoch 134; iter: 0; batch classifier loss: 0.352337; batch adversarial loss: 0.506717\n",
      "epoch 135; iter: 0; batch classifier loss: 0.436549; batch adversarial loss: 0.535639\n",
      "epoch 136; iter: 0; batch classifier loss: 0.408664; batch adversarial loss: 0.488604\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332452; batch adversarial loss: 0.562877\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355839; batch adversarial loss: 0.507555\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342327; batch adversarial loss: 0.498916\n",
      "epoch 140; iter: 0; batch classifier loss: 0.370213; batch adversarial loss: 0.581391\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389520; batch adversarial loss: 0.517699\n",
      "epoch 142; iter: 0; batch classifier loss: 0.411257; batch adversarial loss: 0.469778\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371055; batch adversarial loss: 0.545897\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392313; batch adversarial loss: 0.637295\n",
      "epoch 145; iter: 0; batch classifier loss: 0.420265; batch adversarial loss: 0.470656\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349175; batch adversarial loss: 0.553512\n",
      "epoch 147; iter: 0; batch classifier loss: 0.500175; batch adversarial loss: 0.627501\n",
      "epoch 148; iter: 0; batch classifier loss: 0.271870; batch adversarial loss: 0.498381\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378292; batch adversarial loss: 0.627648\n",
      "epoch 150; iter: 0; batch classifier loss: 0.328870; batch adversarial loss: 0.552827\n",
      "epoch 151; iter: 0; batch classifier loss: 0.403890; batch adversarial loss: 0.582016\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326333; batch adversarial loss: 0.553617\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330902; batch adversarial loss: 0.601178\n",
      "epoch 154; iter: 0; batch classifier loss: 0.465776; batch adversarial loss: 0.516237\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387166; batch adversarial loss: 0.629136\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372423; batch adversarial loss: 0.479056\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405285; batch adversarial loss: 0.581803\n",
      "epoch 158; iter: 0; batch classifier loss: 0.429384; batch adversarial loss: 0.609467\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334874; batch adversarial loss: 0.525766\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385352; batch adversarial loss: 0.572281\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356779; batch adversarial loss: 0.582723\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375707; batch adversarial loss: 0.581030\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362075; batch adversarial loss: 0.534523\n",
      "epoch 164; iter: 0; batch classifier loss: 0.276562; batch adversarial loss: 0.516993\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394813; batch adversarial loss: 0.544758\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347552; batch adversarial loss: 0.413881\n",
      "epoch 167; iter: 0; batch classifier loss: 0.455528; batch adversarial loss: 0.499339\n",
      "epoch 168; iter: 0; batch classifier loss: 0.285076; batch adversarial loss: 0.590971\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353991; batch adversarial loss: 0.580981\n",
      "epoch 170; iter: 0; batch classifier loss: 0.323605; batch adversarial loss: 0.517280\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351372; batch adversarial loss: 0.552910\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348377; batch adversarial loss: 0.598748\n",
      "epoch 173; iter: 0; batch classifier loss: 0.447850; batch adversarial loss: 0.580797\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424489; batch adversarial loss: 0.497839\n",
      "epoch 175; iter: 0; batch classifier loss: 0.431529; batch adversarial loss: 0.562979\n",
      "epoch 176; iter: 0; batch classifier loss: 0.323690; batch adversarial loss: 0.479963\n",
      "epoch 177; iter: 0; batch classifier loss: 0.301785; batch adversarial loss: 0.563312\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383886; batch adversarial loss: 0.516955\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334035; batch adversarial loss: 0.554200\n",
      "epoch 180; iter: 0; batch classifier loss: 0.415807; batch adversarial loss: 0.479235\n",
      "epoch 181; iter: 0; batch classifier loss: 0.293108; batch adversarial loss: 0.553532\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349344; batch adversarial loss: 0.535458\n",
      "epoch 183; iter: 0; batch classifier loss: 0.443039; batch adversarial loss: 0.618376\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338119; batch adversarial loss: 0.490309\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365310; batch adversarial loss: 0.534795\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375185; batch adversarial loss: 0.526188\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388849; batch adversarial loss: 0.489168\n",
      "epoch 188; iter: 0; batch classifier loss: 0.282057; batch adversarial loss: 0.563037\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364801; batch adversarial loss: 0.571463\n",
      "epoch 190; iter: 0; batch classifier loss: 0.359699; batch adversarial loss: 0.535784\n",
      "epoch 191; iter: 0; batch classifier loss: 0.402445; batch adversarial loss: 0.534919\n",
      "epoch 192; iter: 0; batch classifier loss: 0.415960; batch adversarial loss: 0.572135\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330590; batch adversarial loss: 0.563256\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336458; batch adversarial loss: 0.590756\n",
      "epoch 195; iter: 0; batch classifier loss: 0.362748; batch adversarial loss: 0.489105\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351759; batch adversarial loss: 0.590794\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318428; batch adversarial loss: 0.618052\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357939; batch adversarial loss: 0.507176\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340234; batch adversarial loss: 0.554217\n",
      "epoch 0; iter: 0; batch classifier loss: 0.806405; batch adversarial loss: 1.311777\n",
      "epoch 1; iter: 0; batch classifier loss: 0.868828; batch adversarial loss: 1.390372\n",
      "epoch 2; iter: 0; batch classifier loss: 0.964698; batch adversarial loss: 1.370624\n",
      "epoch 3; iter: 0; batch classifier loss: 1.028408; batch adversarial loss: 1.282840\n",
      "epoch 4; iter: 0; batch classifier loss: 1.151647; batch adversarial loss: 1.140051\n",
      "epoch 5; iter: 0; batch classifier loss: 0.989418; batch adversarial loss: 1.085048\n",
      "epoch 6; iter: 0; batch classifier loss: 0.832098; batch adversarial loss: 1.003944\n",
      "epoch 7; iter: 0; batch classifier loss: 0.965247; batch adversarial loss: 0.880319\n",
      "epoch 8; iter: 0; batch classifier loss: 0.885465; batch adversarial loss: 0.827276\n",
      "epoch 9; iter: 0; batch classifier loss: 0.736461; batch adversarial loss: 0.762293\n",
      "epoch 10; iter: 0; batch classifier loss: 0.628777; batch adversarial loss: 0.712053\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605246; batch adversarial loss: 0.707920\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548668; batch adversarial loss: 0.625123\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528959; batch adversarial loss: 0.607794\n",
      "epoch 14; iter: 0; batch classifier loss: 0.546521; batch adversarial loss: 0.608678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.487225; batch adversarial loss: 0.593898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488906; batch adversarial loss: 0.563398\n",
      "epoch 17; iter: 0; batch classifier loss: 0.553889; batch adversarial loss: 0.616672\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481075; batch adversarial loss: 0.570654\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499994; batch adversarial loss: 0.594094\n",
      "epoch 20; iter: 0; batch classifier loss: 0.545584; batch adversarial loss: 0.526583\n",
      "epoch 21; iter: 0; batch classifier loss: 0.475181; batch adversarial loss: 0.599170\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493430; batch adversarial loss: 0.531314\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493752; batch adversarial loss: 0.561867\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502585; batch adversarial loss: 0.553741\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443923; batch adversarial loss: 0.528996\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483057; batch adversarial loss: 0.591125\n",
      "epoch 27; iter: 0; batch classifier loss: 0.502769; batch adversarial loss: 0.580714\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515553; batch adversarial loss: 0.518055\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500458; batch adversarial loss: 0.587142\n",
      "epoch 30; iter: 0; batch classifier loss: 0.520880; batch adversarial loss: 0.559073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498634; batch adversarial loss: 0.564583\n",
      "epoch 32; iter: 0; batch classifier loss: 0.483097; batch adversarial loss: 0.590868\n",
      "epoch 33; iter: 0; batch classifier loss: 0.510412; batch adversarial loss: 0.513093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.516702; batch adversarial loss: 0.547355\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452804; batch adversarial loss: 0.543254\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449977; batch adversarial loss: 0.615527\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442776; batch adversarial loss: 0.524443\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450239; batch adversarial loss: 0.539817\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434340; batch adversarial loss: 0.525090\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495611; batch adversarial loss: 0.550419\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428920; batch adversarial loss: 0.554736\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410867; batch adversarial loss: 0.564568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377507; batch adversarial loss: 0.514540\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459619; batch adversarial loss: 0.634506\n",
      "epoch 45; iter: 0; batch classifier loss: 0.510187; batch adversarial loss: 0.586134\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430142; batch adversarial loss: 0.547119\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386505; batch adversarial loss: 0.550950\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427882; batch adversarial loss: 0.497689\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441076; batch adversarial loss: 0.537379\n",
      "epoch 50; iter: 0; batch classifier loss: 0.354996; batch adversarial loss: 0.516082\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409322; batch adversarial loss: 0.604015\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418182; batch adversarial loss: 0.481918\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420791; batch adversarial loss: 0.584296\n",
      "epoch 54; iter: 0; batch classifier loss: 0.387034; batch adversarial loss: 0.571712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.452673; batch adversarial loss: 0.600671\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432895; batch adversarial loss: 0.583853\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402052; batch adversarial loss: 0.572306\n",
      "epoch 58; iter: 0; batch classifier loss: 0.477962; batch adversarial loss: 0.575471\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417233; batch adversarial loss: 0.561663\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433973; batch adversarial loss: 0.564637\n",
      "epoch 61; iter: 0; batch classifier loss: 0.356869; batch adversarial loss: 0.564357\n",
      "epoch 62; iter: 0; batch classifier loss: 0.367926; batch adversarial loss: 0.565712\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421249; batch adversarial loss: 0.563870\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435083; batch adversarial loss: 0.539080\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427591; batch adversarial loss: 0.544729\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408802; batch adversarial loss: 0.578403\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423842; batch adversarial loss: 0.562503\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400743; batch adversarial loss: 0.554486\n",
      "epoch 69; iter: 0; batch classifier loss: 0.326475; batch adversarial loss: 0.518898\n",
      "epoch 70; iter: 0; batch classifier loss: 0.478543; batch adversarial loss: 0.654220\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402057; batch adversarial loss: 0.588449\n",
      "epoch 72; iter: 0; batch classifier loss: 0.453874; batch adversarial loss: 0.562443\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410557; batch adversarial loss: 0.482261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.358900; batch adversarial loss: 0.571923\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382337; batch adversarial loss: 0.561858\n",
      "epoch 76; iter: 0; batch classifier loss: 0.417951; batch adversarial loss: 0.589037\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338542; batch adversarial loss: 0.536753\n",
      "epoch 78; iter: 0; batch classifier loss: 0.346361; batch adversarial loss: 0.490910\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369158; batch adversarial loss: 0.553037\n",
      "epoch 80; iter: 0; batch classifier loss: 0.443675; batch adversarial loss: 0.598387\n",
      "epoch 81; iter: 0; batch classifier loss: 0.320265; batch adversarial loss: 0.563905\n",
      "epoch 82; iter: 0; batch classifier loss: 0.422790; batch adversarial loss: 0.606153\n",
      "epoch 83; iter: 0; batch classifier loss: 0.293653; batch adversarial loss: 0.625035\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438323; batch adversarial loss: 0.624661\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376318; batch adversarial loss: 0.580744\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401157; batch adversarial loss: 0.518657\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377848; batch adversarial loss: 0.605031\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394016; batch adversarial loss: 0.590019\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433682; batch adversarial loss: 0.553433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404044; batch adversarial loss: 0.632623\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412834; batch adversarial loss: 0.490005\n",
      "epoch 92; iter: 0; batch classifier loss: 0.449613; batch adversarial loss: 0.446240\n",
      "epoch 93; iter: 0; batch classifier loss: 0.445207; batch adversarial loss: 0.562959\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384063; batch adversarial loss: 0.560825\n",
      "epoch 95; iter: 0; batch classifier loss: 0.325683; batch adversarial loss: 0.572215\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386014; batch adversarial loss: 0.563188\n",
      "epoch 97; iter: 0; batch classifier loss: 0.387972; batch adversarial loss: 0.578991\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365134; batch adversarial loss: 0.589201\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406565; batch adversarial loss: 0.554288\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357301; batch adversarial loss: 0.573532\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355798; batch adversarial loss: 0.571127\n",
      "epoch 102; iter: 0; batch classifier loss: 0.446507; batch adversarial loss: 0.571012\n",
      "epoch 103; iter: 0; batch classifier loss: 0.451369; batch adversarial loss: 0.608306\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390977; batch adversarial loss: 0.581648\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380136; batch adversarial loss: 0.518885\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382628; batch adversarial loss: 0.615057\n",
      "epoch 107; iter: 0; batch classifier loss: 0.427110; batch adversarial loss: 0.598799\n",
      "epoch 108; iter: 0; batch classifier loss: 0.308756; batch adversarial loss: 0.568824\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385576; batch adversarial loss: 0.607085\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429610; batch adversarial loss: 0.614644\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407322; batch adversarial loss: 0.554481\n",
      "epoch 112; iter: 0; batch classifier loss: 0.340970; batch adversarial loss: 0.582585\n",
      "epoch 113; iter: 0; batch classifier loss: 0.437210; batch adversarial loss: 0.589445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.445835; batch adversarial loss: 0.545517\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445730; batch adversarial loss: 0.597807\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377331; batch adversarial loss: 0.562609\n",
      "epoch 117; iter: 0; batch classifier loss: 0.400043; batch adversarial loss: 0.545117\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389158; batch adversarial loss: 0.590297\n",
      "epoch 119; iter: 0; batch classifier loss: 0.421736; batch adversarial loss: 0.563186\n",
      "epoch 120; iter: 0; batch classifier loss: 0.452365; batch adversarial loss: 0.545103\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358118; batch adversarial loss: 0.490947\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362313; batch adversarial loss: 0.570818\n",
      "epoch 123; iter: 0; batch classifier loss: 0.324605; batch adversarial loss: 0.589090\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375822; batch adversarial loss: 0.529671\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411555; batch adversarial loss: 0.536031\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314542; batch adversarial loss: 0.607472\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333452; batch adversarial loss: 0.545403\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345857; batch adversarial loss: 0.508120\n",
      "epoch 129; iter: 0; batch classifier loss: 0.326124; batch adversarial loss: 0.580370\n",
      "epoch 130; iter: 0; batch classifier loss: 0.318503; batch adversarial loss: 0.570264\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354007; batch adversarial loss: 0.471898\n",
      "epoch 132; iter: 0; batch classifier loss: 0.434766; batch adversarial loss: 0.561910\n",
      "epoch 133; iter: 0; batch classifier loss: 0.328322; batch adversarial loss: 0.580970\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358390; batch adversarial loss: 0.510224\n",
      "epoch 135; iter: 0; batch classifier loss: 0.299842; batch adversarial loss: 0.553626\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410861; batch adversarial loss: 0.507356\n",
      "epoch 137; iter: 0; batch classifier loss: 0.322169; batch adversarial loss: 0.570755\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376654; batch adversarial loss: 0.518064\n",
      "epoch 139; iter: 0; batch classifier loss: 0.353427; batch adversarial loss: 0.579799\n",
      "epoch 140; iter: 0; batch classifier loss: 0.254650; batch adversarial loss: 0.635227\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338068; batch adversarial loss: 0.537172\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367156; batch adversarial loss: 0.581699\n",
      "epoch 143; iter: 0; batch classifier loss: 0.347479; batch adversarial loss: 0.508910\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337200; batch adversarial loss: 0.644157\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333886; batch adversarial loss: 0.517393\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387388; batch adversarial loss: 0.535319\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384063; batch adversarial loss: 0.500166\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311764; batch adversarial loss: 0.624697\n",
      "epoch 149; iter: 0; batch classifier loss: 0.401027; batch adversarial loss: 0.492254\n",
      "epoch 150; iter: 0; batch classifier loss: 0.431040; batch adversarial loss: 0.580563\n",
      "epoch 151; iter: 0; batch classifier loss: 0.268535; batch adversarial loss: 0.570007\n",
      "epoch 152; iter: 0; batch classifier loss: 0.319384; batch adversarial loss: 0.518950\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388545; batch adversarial loss: 0.617365\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316574; batch adversarial loss: 0.543761\n",
      "epoch 155; iter: 0; batch classifier loss: 0.310717; batch adversarial loss: 0.571012\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359880; batch adversarial loss: 0.509491\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333553; batch adversarial loss: 0.605109\n",
      "epoch 158; iter: 0; batch classifier loss: 0.434507; batch adversarial loss: 0.580519\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396191; batch adversarial loss: 0.554054\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364948; batch adversarial loss: 0.517189\n",
      "epoch 161; iter: 0; batch classifier loss: 0.283735; batch adversarial loss: 0.527356\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313268; batch adversarial loss: 0.515978\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321639; batch adversarial loss: 0.525783\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375527; batch adversarial loss: 0.491270\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360150; batch adversarial loss: 0.455601\n",
      "epoch 166; iter: 0; batch classifier loss: 0.308393; batch adversarial loss: 0.553529\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376483; batch adversarial loss: 0.553059\n",
      "epoch 168; iter: 0; batch classifier loss: 0.449263; batch adversarial loss: 0.525514\n",
      "epoch 169; iter: 0; batch classifier loss: 0.429991; batch adversarial loss: 0.578692\n",
      "epoch 170; iter: 0; batch classifier loss: 0.308346; batch adversarial loss: 0.553509\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320281; batch adversarial loss: 0.551878\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376421; batch adversarial loss: 0.498513\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382107; batch adversarial loss: 0.638165\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302635; batch adversarial loss: 0.562013\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331336; batch adversarial loss: 0.499178\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340918; batch adversarial loss: 0.498865\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358637; batch adversarial loss: 0.483080\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360371; batch adversarial loss: 0.535234\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348509; batch adversarial loss: 0.546150\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379334; batch adversarial loss: 0.526710\n",
      "epoch 181; iter: 0; batch classifier loss: 0.409175; batch adversarial loss: 0.499889\n",
      "epoch 182; iter: 0; batch classifier loss: 0.272151; batch adversarial loss: 0.490887\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345768; batch adversarial loss: 0.546764\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336746; batch adversarial loss: 0.516085\n",
      "epoch 185; iter: 0; batch classifier loss: 0.445227; batch adversarial loss: 0.497971\n",
      "epoch 186; iter: 0; batch classifier loss: 0.352413; batch adversarial loss: 0.532796\n",
      "epoch 187; iter: 0; batch classifier loss: 0.297763; batch adversarial loss: 0.555605\n",
      "epoch 188; iter: 0; batch classifier loss: 0.291246; batch adversarial loss: 0.614301\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376859; batch adversarial loss: 0.509598\n",
      "epoch 190; iter: 0; batch classifier loss: 0.271154; batch adversarial loss: 0.449177\n",
      "epoch 191; iter: 0; batch classifier loss: 0.343542; batch adversarial loss: 0.579620\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392220; batch adversarial loss: 0.551793\n",
      "epoch 193; iter: 0; batch classifier loss: 0.241235; batch adversarial loss: 0.524814\n",
      "epoch 194; iter: 0; batch classifier loss: 0.334208; batch adversarial loss: 0.528991\n",
      "epoch 195; iter: 0; batch classifier loss: 0.314345; batch adversarial loss: 0.550726\n",
      "epoch 196; iter: 0; batch classifier loss: 0.367871; batch adversarial loss: 0.489260\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324066; batch adversarial loss: 0.531778\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393302; batch adversarial loss: 0.540712\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342451; batch adversarial loss: 0.537202\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686568; batch adversarial loss: 0.754170\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600711; batch adversarial loss: 0.740625\n",
      "epoch 2; iter: 0; batch classifier loss: 0.536104; batch adversarial loss: 0.693296\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614672; batch adversarial loss: 0.682192\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560207; batch adversarial loss: 0.643456\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531363; batch adversarial loss: 0.635729\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547878; batch adversarial loss: 0.618944\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542399; batch adversarial loss: 0.627524\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572721; batch adversarial loss: 0.610892\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555257; batch adversarial loss: 0.584678\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491270; batch adversarial loss: 0.569463\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520176; batch adversarial loss: 0.579459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.480916; batch adversarial loss: 0.512605\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511910; batch adversarial loss: 0.549236\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503074; batch adversarial loss: 0.537267\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500642; batch adversarial loss: 0.535630\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468445; batch adversarial loss: 0.517053\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492934; batch adversarial loss: 0.561238\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468105; batch adversarial loss: 0.569659\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540310; batch adversarial loss: 0.575611\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530269; batch adversarial loss: 0.670084\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436158; batch adversarial loss: 0.571794\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492747; batch adversarial loss: 0.613114\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442641; batch adversarial loss: 0.532387\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516620; batch adversarial loss: 0.586682\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513388; batch adversarial loss: 0.537872\n",
      "epoch 26; iter: 0; batch classifier loss: 0.503762; batch adversarial loss: 0.572677\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436337; batch adversarial loss: 0.575292\n",
      "epoch 28; iter: 0; batch classifier loss: 0.521161; batch adversarial loss: 0.592680\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437737; batch adversarial loss: 0.589913\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472854; batch adversarial loss: 0.630137\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475466; batch adversarial loss: 0.532337\n",
      "epoch 32; iter: 0; batch classifier loss: 0.561966; batch adversarial loss: 0.564990\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456198; batch adversarial loss: 0.530566\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482483; batch adversarial loss: 0.612104\n",
      "epoch 35; iter: 0; batch classifier loss: 0.516691; batch adversarial loss: 0.488266\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423596; batch adversarial loss: 0.570158\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441507; batch adversarial loss: 0.578779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389377; batch adversarial loss: 0.554054\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478625; batch adversarial loss: 0.623207\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431179; batch adversarial loss: 0.571212\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417874; batch adversarial loss: 0.562469\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441085; batch adversarial loss: 0.517581\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407090; batch adversarial loss: 0.473552\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407622; batch adversarial loss: 0.552283\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479157; batch adversarial loss: 0.544232\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426438; batch adversarial loss: 0.590540\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453994; batch adversarial loss: 0.453758\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455498; batch adversarial loss: 0.525768\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396932; batch adversarial loss: 0.544790\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459191; batch adversarial loss: 0.526018\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436234; batch adversarial loss: 0.581053\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421638; batch adversarial loss: 0.517133\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388699; batch adversarial loss: 0.535590\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421744; batch adversarial loss: 0.554051\n",
      "epoch 55; iter: 0; batch classifier loss: 0.501977; batch adversarial loss: 0.608038\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400115; batch adversarial loss: 0.545185\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395975; batch adversarial loss: 0.517193\n",
      "epoch 58; iter: 0; batch classifier loss: 0.521399; batch adversarial loss: 0.462163\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404594; batch adversarial loss: 0.553728\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367842; batch adversarial loss: 0.517135\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396139; batch adversarial loss: 0.589045\n",
      "epoch 62; iter: 0; batch classifier loss: 0.504774; batch adversarial loss: 0.572379\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378879; batch adversarial loss: 0.489235\n",
      "epoch 64; iter: 0; batch classifier loss: 0.495625; batch adversarial loss: 0.507732\n",
      "epoch 65; iter: 0; batch classifier loss: 0.418114; batch adversarial loss: 0.600034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447982; batch adversarial loss: 0.626937\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430481; batch adversarial loss: 0.488587\n",
      "epoch 68; iter: 0; batch classifier loss: 0.487375; batch adversarial loss: 0.580723\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413332; batch adversarial loss: 0.562444\n",
      "epoch 70; iter: 0; batch classifier loss: 0.491267; batch adversarial loss: 0.564170\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414157; batch adversarial loss: 0.616804\n",
      "epoch 72; iter: 0; batch classifier loss: 0.479080; batch adversarial loss: 0.508194\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430251; batch adversarial loss: 0.544263\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397897; batch adversarial loss: 0.471577\n",
      "epoch 75; iter: 0; batch classifier loss: 0.420206; batch adversarial loss: 0.526971\n",
      "epoch 76; iter: 0; batch classifier loss: 0.450278; batch adversarial loss: 0.625643\n",
      "epoch 77; iter: 0; batch classifier loss: 0.509941; batch adversarial loss: 0.418285\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395252; batch adversarial loss: 0.472196\n",
      "epoch 79; iter: 0; batch classifier loss: 0.478013; batch adversarial loss: 0.480978\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387628; batch adversarial loss: 0.508242\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367852; batch adversarial loss: 0.499092\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457723; batch adversarial loss: 0.580959\n",
      "epoch 83; iter: 0; batch classifier loss: 0.331193; batch adversarial loss: 0.562992\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433624; batch adversarial loss: 0.535275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392771; batch adversarial loss: 0.663332\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440935; batch adversarial loss: 0.480990\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398037; batch adversarial loss: 0.626151\n",
      "epoch 88; iter: 0; batch classifier loss: 0.461383; batch adversarial loss: 0.553556\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373781; batch adversarial loss: 0.526006\n",
      "epoch 90; iter: 0; batch classifier loss: 0.471693; batch adversarial loss: 0.517628\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374052; batch adversarial loss: 0.507817\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417712; batch adversarial loss: 0.553712\n",
      "epoch 93; iter: 0; batch classifier loss: 0.415761; batch adversarial loss: 0.544688\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421381; batch adversarial loss: 0.489034\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427111; batch adversarial loss: 0.544449\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429854; batch adversarial loss: 0.545387\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365850; batch adversarial loss: 0.525390\n",
      "epoch 98; iter: 0; batch classifier loss: 0.343983; batch adversarial loss: 0.469587\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386182; batch adversarial loss: 0.561868\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376618; batch adversarial loss: 0.590700\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396945; batch adversarial loss: 0.444162\n",
      "epoch 102; iter: 0; batch classifier loss: 0.405137; batch adversarial loss: 0.579464\n",
      "epoch 103; iter: 0; batch classifier loss: 0.482114; batch adversarial loss: 0.572823\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428441; batch adversarial loss: 0.536337\n",
      "epoch 105; iter: 0; batch classifier loss: 0.488098; batch adversarial loss: 0.571988\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371701; batch adversarial loss: 0.533055\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404704; batch adversarial loss: 0.564729\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388611; batch adversarial loss: 0.564515\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372786; batch adversarial loss: 0.609684\n",
      "epoch 110; iter: 0; batch classifier loss: 0.420886; batch adversarial loss: 0.526856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.379041; batch adversarial loss: 0.465518\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435682; batch adversarial loss: 0.517756\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370762; batch adversarial loss: 0.516514\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397662; batch adversarial loss: 0.599020\n",
      "epoch 115; iter: 0; batch classifier loss: 0.415751; batch adversarial loss: 0.526699\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417105; batch adversarial loss: 0.500636\n",
      "epoch 117; iter: 0; batch classifier loss: 0.327955; batch adversarial loss: 0.517902\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333679; batch adversarial loss: 0.608874\n",
      "epoch 119; iter: 0; batch classifier loss: 0.419441; batch adversarial loss: 0.535492\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343464; batch adversarial loss: 0.562088\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321276; batch adversarial loss: 0.472278\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397598; batch adversarial loss: 0.562550\n",
      "epoch 123; iter: 0; batch classifier loss: 0.405030; batch adversarial loss: 0.534899\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339134; batch adversarial loss: 0.562027\n",
      "epoch 125; iter: 0; batch classifier loss: 0.450507; batch adversarial loss: 0.535554\n",
      "epoch 126; iter: 0; batch classifier loss: 0.407435; batch adversarial loss: 0.544384\n",
      "epoch 127; iter: 0; batch classifier loss: 0.454449; batch adversarial loss: 0.571172\n",
      "epoch 128; iter: 0; batch classifier loss: 0.378186; batch adversarial loss: 0.553824\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403029; batch adversarial loss: 0.471733\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350592; batch adversarial loss: 0.581511\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359921; batch adversarial loss: 0.517162\n",
      "epoch 132; iter: 0; batch classifier loss: 0.439139; batch adversarial loss: 0.508119\n",
      "epoch 133; iter: 0; batch classifier loss: 0.328678; batch adversarial loss: 0.608160\n",
      "epoch 134; iter: 0; batch classifier loss: 0.319581; batch adversarial loss: 0.536320\n",
      "epoch 135; iter: 0; batch classifier loss: 0.409773; batch adversarial loss: 0.517728\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340484; batch adversarial loss: 0.481103\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375387; batch adversarial loss: 0.517148\n",
      "epoch 138; iter: 0; batch classifier loss: 0.361073; batch adversarial loss: 0.498574\n",
      "epoch 139; iter: 0; batch classifier loss: 0.298688; batch adversarial loss: 0.535602\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349664; batch adversarial loss: 0.517446\n",
      "epoch 141; iter: 0; batch classifier loss: 0.415151; batch adversarial loss: 0.617451\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336313; batch adversarial loss: 0.644395\n",
      "epoch 143; iter: 0; batch classifier loss: 0.421830; batch adversarial loss: 0.562478\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366606; batch adversarial loss: 0.608710\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379367; batch adversarial loss: 0.498593\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357758; batch adversarial loss: 0.636149\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362244; batch adversarial loss: 0.589985\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379608; batch adversarial loss: 0.507686\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365391; batch adversarial loss: 0.489743\n",
      "epoch 150; iter: 0; batch classifier loss: 0.327204; batch adversarial loss: 0.508336\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363088; batch adversarial loss: 0.553225\n",
      "epoch 152; iter: 0; batch classifier loss: 0.314324; batch adversarial loss: 0.544810\n",
      "epoch 153; iter: 0; batch classifier loss: 0.426120; batch adversarial loss: 0.444330\n",
      "epoch 154; iter: 0; batch classifier loss: 0.401175; batch adversarial loss: 0.535542\n",
      "epoch 155; iter: 0; batch classifier loss: 0.432905; batch adversarial loss: 0.580045\n",
      "epoch 156; iter: 0; batch classifier loss: 0.431724; batch adversarial loss: 0.517658\n",
      "epoch 157; iter: 0; batch classifier loss: 0.347504; batch adversarial loss: 0.616296\n",
      "epoch 158; iter: 0; batch classifier loss: 0.440926; batch adversarial loss: 0.572704\n",
      "epoch 159; iter: 0; batch classifier loss: 0.455626; batch adversarial loss: 0.599213\n",
      "epoch 160; iter: 0; batch classifier loss: 0.423563; batch adversarial loss: 0.535156\n",
      "epoch 161; iter: 0; batch classifier loss: 0.305902; batch adversarial loss: 0.408274\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383932; batch adversarial loss: 0.580508\n",
      "epoch 163; iter: 0; batch classifier loss: 0.408388; batch adversarial loss: 0.608978\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333916; batch adversarial loss: 0.563535\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387747; batch adversarial loss: 0.617546\n",
      "epoch 166; iter: 0; batch classifier loss: 0.404274; batch adversarial loss: 0.562482\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371712; batch adversarial loss: 0.444544\n",
      "epoch 168; iter: 0; batch classifier loss: 0.419914; batch adversarial loss: 0.625600\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376811; batch adversarial loss: 0.590015\n",
      "epoch 170; iter: 0; batch classifier loss: 0.316075; batch adversarial loss: 0.499159\n",
      "epoch 171; iter: 0; batch classifier loss: 0.361347; batch adversarial loss: 0.535839\n",
      "epoch 172; iter: 0; batch classifier loss: 0.329350; batch adversarial loss: 0.535986\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356077; batch adversarial loss: 0.599249\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368387; batch adversarial loss: 0.544472\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344587; batch adversarial loss: 0.544535\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370773; batch adversarial loss: 0.590397\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329092; batch adversarial loss: 0.535287\n",
      "epoch 178; iter: 0; batch classifier loss: 0.386101; batch adversarial loss: 0.516772\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395936; batch adversarial loss: 0.681470\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355618; batch adversarial loss: 0.598077\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397514; batch adversarial loss: 0.562096\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404268; batch adversarial loss: 0.543647\n",
      "epoch 183; iter: 0; batch classifier loss: 0.418802; batch adversarial loss: 0.553676\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335850; batch adversarial loss: 0.535357\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362861; batch adversarial loss: 0.508210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357071; batch adversarial loss: 0.508285\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382630; batch adversarial loss: 0.516229\n",
      "epoch 188; iter: 0; batch classifier loss: 0.427369; batch adversarial loss: 0.606508\n",
      "epoch 189; iter: 0; batch classifier loss: 0.325881; batch adversarial loss: 0.472027\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404574; batch adversarial loss: 0.589177\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356638; batch adversarial loss: 0.499095\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396889; batch adversarial loss: 0.544010\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329561; batch adversarial loss: 0.526877\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376141; batch adversarial loss: 0.562906\n",
      "epoch 195; iter: 0; batch classifier loss: 0.457931; batch adversarial loss: 0.535682\n",
      "epoch 196; iter: 0; batch classifier loss: 0.442601; batch adversarial loss: 0.563065\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390685; batch adversarial loss: 0.527314\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378471; batch adversarial loss: 0.553253\n",
      "epoch 199; iter: 0; batch classifier loss: 0.323175; batch adversarial loss: 0.498043\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680871; batch adversarial loss: 0.925885\n",
      "epoch 1; iter: 0; batch classifier loss: 0.803299; batch adversarial loss: 1.222431\n",
      "epoch 2; iter: 0; batch classifier loss: 1.060730; batch adversarial loss: 1.216814\n",
      "epoch 3; iter: 0; batch classifier loss: 1.184679; batch adversarial loss: 1.141809\n",
      "epoch 4; iter: 0; batch classifier loss: 1.149485; batch adversarial loss: 1.017803\n",
      "epoch 5; iter: 0; batch classifier loss: 1.288937; batch adversarial loss: 0.949544\n",
      "epoch 6; iter: 0; batch classifier loss: 1.162316; batch adversarial loss: 0.865021\n",
      "epoch 7; iter: 0; batch classifier loss: 1.149741; batch adversarial loss: 0.805494\n",
      "epoch 8; iter: 0; batch classifier loss: 1.148282; batch adversarial loss: 0.744303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 1.200575; batch adversarial loss: 0.690524\n",
      "epoch 10; iter: 0; batch classifier loss: 0.952146; batch adversarial loss: 0.667842\n",
      "epoch 11; iter: 0; batch classifier loss: 0.791239; batch adversarial loss: 0.659167\n",
      "epoch 12; iter: 0; batch classifier loss: 0.629461; batch adversarial loss: 0.611623\n",
      "epoch 13; iter: 0; batch classifier loss: 0.607217; batch adversarial loss: 0.583621\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568818; batch adversarial loss: 0.552328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498480; batch adversarial loss: 0.557431\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521575; batch adversarial loss: 0.528471\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481544; batch adversarial loss: 0.554204\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465975; batch adversarial loss: 0.563585\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483183; batch adversarial loss: 0.575806\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523998; batch adversarial loss: 0.573432\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525129; batch adversarial loss: 0.558811\n",
      "epoch 22; iter: 0; batch classifier loss: 0.505139; batch adversarial loss: 0.573636\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479452; batch adversarial loss: 0.525700\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481090; batch adversarial loss: 0.566258\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489390; batch adversarial loss: 0.595255\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493137; batch adversarial loss: 0.621469\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501950; batch adversarial loss: 0.564014\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464436; batch adversarial loss: 0.565263\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483481; batch adversarial loss: 0.549938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.409895; batch adversarial loss: 0.581616\n",
      "epoch 31; iter: 0; batch classifier loss: 0.424851; batch adversarial loss: 0.555844\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405404; batch adversarial loss: 0.573333\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456618; batch adversarial loss: 0.535947\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461824; batch adversarial loss: 0.611829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411060; batch adversarial loss: 0.548309\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426300; batch adversarial loss: 0.578488\n",
      "epoch 37; iter: 0; batch classifier loss: 0.506544; batch adversarial loss: 0.570698\n",
      "epoch 38; iter: 0; batch classifier loss: 0.401396; batch adversarial loss: 0.607753\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466088; batch adversarial loss: 0.520530\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501996; batch adversarial loss: 0.518956\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453127; batch adversarial loss: 0.595802\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427843; batch adversarial loss: 0.503641\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413635; batch adversarial loss: 0.581276\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446384; batch adversarial loss: 0.566751\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477416; batch adversarial loss: 0.517122\n",
      "epoch 46; iter: 0; batch classifier loss: 0.338974; batch adversarial loss: 0.524085\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522685; batch adversarial loss: 0.536921\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396425; batch adversarial loss: 0.495785\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448934; batch adversarial loss: 0.491893\n",
      "epoch 50; iter: 0; batch classifier loss: 0.331433; batch adversarial loss: 0.589549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420988; batch adversarial loss: 0.504926\n",
      "epoch 52; iter: 0; batch classifier loss: 0.433646; batch adversarial loss: 0.563577\n",
      "epoch 53; iter: 0; batch classifier loss: 0.495286; batch adversarial loss: 0.526527\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420980; batch adversarial loss: 0.553341\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425090; batch adversarial loss: 0.627683\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431717; batch adversarial loss: 0.519020\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440028; batch adversarial loss: 0.569460\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392410; batch adversarial loss: 0.617693\n",
      "epoch 59; iter: 0; batch classifier loss: 0.350299; batch adversarial loss: 0.580609\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434084; batch adversarial loss: 0.617600\n",
      "epoch 61; iter: 0; batch classifier loss: 0.397749; batch adversarial loss: 0.565555\n",
      "epoch 62; iter: 0; batch classifier loss: 0.424096; batch adversarial loss: 0.488795\n",
      "epoch 63; iter: 0; batch classifier loss: 0.351500; batch adversarial loss: 0.600559\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403592; batch adversarial loss: 0.563206\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409287; batch adversarial loss: 0.559443\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431180; batch adversarial loss: 0.571639\n",
      "epoch 67; iter: 0; batch classifier loss: 0.390961; batch adversarial loss: 0.622041\n",
      "epoch 68; iter: 0; batch classifier loss: 0.446125; batch adversarial loss: 0.526154\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376398; batch adversarial loss: 0.543011\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443563; batch adversarial loss: 0.561868\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389574; batch adversarial loss: 0.545344\n",
      "epoch 72; iter: 0; batch classifier loss: 0.332976; batch adversarial loss: 0.475758\n",
      "epoch 73; iter: 0; batch classifier loss: 0.328958; batch adversarial loss: 0.579708\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430429; batch adversarial loss: 0.620088\n",
      "epoch 75; iter: 0; batch classifier loss: 0.339464; batch adversarial loss: 0.523849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.426811; batch adversarial loss: 0.641716\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429179; batch adversarial loss: 0.602761\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392597; batch adversarial loss: 0.594416\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437160; batch adversarial loss: 0.523442\n",
      "epoch 80; iter: 0; batch classifier loss: 0.357288; batch adversarial loss: 0.565552\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382921; batch adversarial loss: 0.620881\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352731; batch adversarial loss: 0.510815\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395990; batch adversarial loss: 0.512150\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393239; batch adversarial loss: 0.527518\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401045; batch adversarial loss: 0.553429\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350998; batch adversarial loss: 0.593442\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345468; batch adversarial loss: 0.517216\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387755; batch adversarial loss: 0.601863\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365223; batch adversarial loss: 0.511270\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406413; batch adversarial loss: 0.528356\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386750; batch adversarial loss: 0.570307\n",
      "epoch 92; iter: 0; batch classifier loss: 0.343331; batch adversarial loss: 0.592767\n",
      "epoch 93; iter: 0; batch classifier loss: 0.296778; batch adversarial loss: 0.607347\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391235; batch adversarial loss: 0.541402\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442260; batch adversarial loss: 0.579103\n",
      "epoch 96; iter: 0; batch classifier loss: 0.363110; batch adversarial loss: 0.506362\n",
      "epoch 97; iter: 0; batch classifier loss: 0.409355; batch adversarial loss: 0.517960\n",
      "epoch 98; iter: 0; batch classifier loss: 0.332843; batch adversarial loss: 0.461930\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341085; batch adversarial loss: 0.588673\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358923; batch adversarial loss: 0.481629\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377593; batch adversarial loss: 0.598979\n",
      "epoch 102; iter: 0; batch classifier loss: 0.312128; batch adversarial loss: 0.544489\n",
      "epoch 103; iter: 0; batch classifier loss: 0.328426; batch adversarial loss: 0.508474\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385263; batch adversarial loss: 0.599730\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389177; batch adversarial loss: 0.553749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.409374; batch adversarial loss: 0.545874\n",
      "epoch 107; iter: 0; batch classifier loss: 0.359500; batch adversarial loss: 0.562135\n",
      "epoch 108; iter: 0; batch classifier loss: 0.386734; batch adversarial loss: 0.534103\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346742; batch adversarial loss: 0.543563\n",
      "epoch 110; iter: 0; batch classifier loss: 0.315949; batch adversarial loss: 0.534675\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399484; batch adversarial loss: 0.618507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.303133; batch adversarial loss: 0.590930\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351097; batch adversarial loss: 0.534999\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378667; batch adversarial loss: 0.590555\n",
      "epoch 115; iter: 0; batch classifier loss: 0.402300; batch adversarial loss: 0.534995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.352959; batch adversarial loss: 0.507618\n",
      "epoch 117; iter: 0; batch classifier loss: 0.296961; batch adversarial loss: 0.571936\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333277; batch adversarial loss: 0.515401\n",
      "epoch 119; iter: 0; batch classifier loss: 0.362845; batch adversarial loss: 0.533677\n",
      "epoch 120; iter: 0; batch classifier loss: 0.242803; batch adversarial loss: 0.610677\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355086; batch adversarial loss: 0.516280\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418310; batch adversarial loss: 0.589489\n",
      "epoch 123; iter: 0; batch classifier loss: 0.334373; batch adversarial loss: 0.605250\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341834; batch adversarial loss: 0.573366\n",
      "epoch 125; iter: 0; batch classifier loss: 0.315938; batch adversarial loss: 0.624042\n",
      "epoch 126; iter: 0; batch classifier loss: 0.320921; batch adversarial loss: 0.562145\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388718; batch adversarial loss: 0.524987\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322038; batch adversarial loss: 0.507234\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393186; batch adversarial loss: 0.590394\n",
      "epoch 130; iter: 0; batch classifier loss: 0.331741; batch adversarial loss: 0.571150\n",
      "epoch 131; iter: 0; batch classifier loss: 0.298536; batch adversarial loss: 0.528123\n",
      "epoch 132; iter: 0; batch classifier loss: 0.294291; batch adversarial loss: 0.562251\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343448; batch adversarial loss: 0.623206\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341334; batch adversarial loss: 0.598423\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378040; batch adversarial loss: 0.609749\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370811; batch adversarial loss: 0.541787\n",
      "epoch 137; iter: 0; batch classifier loss: 0.299103; batch adversarial loss: 0.532267\n",
      "epoch 138; iter: 0; batch classifier loss: 0.406824; batch adversarial loss: 0.565212\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357239; batch adversarial loss: 0.580183\n",
      "epoch 140; iter: 0; batch classifier loss: 0.303441; batch adversarial loss: 0.625836\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386820; batch adversarial loss: 0.532302\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322264; batch adversarial loss: 0.500022\n",
      "epoch 143; iter: 0; batch classifier loss: 0.283217; batch adversarial loss: 0.543168\n",
      "epoch 144; iter: 0; batch classifier loss: 0.314154; batch adversarial loss: 0.588731\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362134; batch adversarial loss: 0.552801\n",
      "epoch 146; iter: 0; batch classifier loss: 0.287007; batch adversarial loss: 0.522877\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404087; batch adversarial loss: 0.562049\n",
      "epoch 148; iter: 0; batch classifier loss: 0.320216; batch adversarial loss: 0.580655\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329004; batch adversarial loss: 0.545056\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336248; batch adversarial loss: 0.547694\n",
      "epoch 151; iter: 0; batch classifier loss: 0.300907; batch adversarial loss: 0.619986\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320047; batch adversarial loss: 0.514984\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337529; batch adversarial loss: 0.508376\n",
      "epoch 154; iter: 0; batch classifier loss: 0.271824; batch adversarial loss: 0.506870\n",
      "epoch 155; iter: 0; batch classifier loss: 0.329737; batch adversarial loss: 0.552953\n",
      "epoch 156; iter: 0; batch classifier loss: 0.313143; batch adversarial loss: 0.477981\n",
      "epoch 157; iter: 0; batch classifier loss: 0.290374; batch adversarial loss: 0.634219\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364331; batch adversarial loss: 0.508216\n",
      "epoch 159; iter: 0; batch classifier loss: 0.280097; batch adversarial loss: 0.584195\n",
      "epoch 160; iter: 0; batch classifier loss: 0.302979; batch adversarial loss: 0.634899\n",
      "epoch 161; iter: 0; batch classifier loss: 0.288022; batch adversarial loss: 0.551217\n",
      "epoch 162; iter: 0; batch classifier loss: 0.263864; batch adversarial loss: 0.634834\n",
      "epoch 163; iter: 0; batch classifier loss: 0.255511; batch adversarial loss: 0.562290\n",
      "epoch 164; iter: 0; batch classifier loss: 0.301342; batch adversarial loss: 0.510580\n",
      "epoch 165; iter: 0; batch classifier loss: 0.263878; batch adversarial loss: 0.518900\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301895; batch adversarial loss: 0.580244\n",
      "epoch 167; iter: 0; batch classifier loss: 0.284507; batch adversarial loss: 0.526242\n",
      "epoch 168; iter: 0; batch classifier loss: 0.265589; batch adversarial loss: 0.511378\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367357; batch adversarial loss: 0.560450\n",
      "epoch 170; iter: 0; batch classifier loss: 0.283783; batch adversarial loss: 0.480074\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326154; batch adversarial loss: 0.561275\n",
      "epoch 172; iter: 0; batch classifier loss: 0.311947; batch adversarial loss: 0.515235\n",
      "epoch 173; iter: 0; batch classifier loss: 0.358167; batch adversarial loss: 0.543107\n",
      "epoch 174; iter: 0; batch classifier loss: 0.298084; batch adversarial loss: 0.446451\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347489; batch adversarial loss: 0.506011\n",
      "epoch 176; iter: 0; batch classifier loss: 0.293804; batch adversarial loss: 0.498282\n",
      "epoch 177; iter: 0; batch classifier loss: 0.274244; batch adversarial loss: 0.526344\n",
      "epoch 178; iter: 0; batch classifier loss: 0.286511; batch adversarial loss: 0.609207\n",
      "epoch 179; iter: 0; batch classifier loss: 0.361276; batch adversarial loss: 0.494878\n",
      "epoch 180; iter: 0; batch classifier loss: 0.286706; batch adversarial loss: 0.516710\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361348; batch adversarial loss: 0.449650\n",
      "epoch 182; iter: 0; batch classifier loss: 0.328390; batch adversarial loss: 0.581658\n",
      "epoch 183; iter: 0; batch classifier loss: 0.356861; batch adversarial loss: 0.480877\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384713; batch adversarial loss: 0.533813\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281596; batch adversarial loss: 0.498429\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414425; batch adversarial loss: 0.563447\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362559; batch adversarial loss: 0.599574\n",
      "epoch 188; iter: 0; batch classifier loss: 0.278012; batch adversarial loss: 0.571776\n",
      "epoch 189; iter: 0; batch classifier loss: 0.303882; batch adversarial loss: 0.500674\n",
      "epoch 190; iter: 0; batch classifier loss: 0.303689; batch adversarial loss: 0.624293\n",
      "epoch 191; iter: 0; batch classifier loss: 0.297549; batch adversarial loss: 0.515584\n",
      "epoch 192; iter: 0; batch classifier loss: 0.291093; batch adversarial loss: 0.602605\n",
      "epoch 193; iter: 0; batch classifier loss: 0.322726; batch adversarial loss: 0.580713\n",
      "epoch 194; iter: 0; batch classifier loss: 0.292434; batch adversarial loss: 0.589889\n",
      "epoch 195; iter: 0; batch classifier loss: 0.285769; batch adversarial loss: 0.545966\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343045; batch adversarial loss: 0.620156\n",
      "epoch 197; iter: 0; batch classifier loss: 0.262744; batch adversarial loss: 0.551481\n",
      "epoch 198; iter: 0; batch classifier loss: 0.371804; batch adversarial loss: 0.555843\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352013; batch adversarial loss: 0.601759\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697641; batch adversarial loss: 0.718589\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584149; batch adversarial loss: 0.682185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.606763; batch adversarial loss: 0.668860\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626859; batch adversarial loss: 0.651273\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603175; batch adversarial loss: 0.594301\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586773; batch adversarial loss: 0.592948\n",
      "epoch 6; iter: 0; batch classifier loss: 0.495605; batch adversarial loss: 0.570141\n",
      "epoch 7; iter: 0; batch classifier loss: 0.540700; batch adversarial loss: 0.607130\n",
      "epoch 8; iter: 0; batch classifier loss: 0.584680; batch adversarial loss: 0.552769\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525368; batch adversarial loss: 0.540996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551176; batch adversarial loss: 0.541929\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542183; batch adversarial loss: 0.588258\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500382; batch adversarial loss: 0.645678\n",
      "epoch 13; iter: 0; batch classifier loss: 0.614388; batch adversarial loss: 0.569770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542355; batch adversarial loss: 0.552002\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509225; batch adversarial loss: 0.594666\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515422; batch adversarial loss: 0.580771\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467535; batch adversarial loss: 0.586669\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557290; batch adversarial loss: 0.554769\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476432; batch adversarial loss: 0.638707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.409429; batch adversarial loss: 0.576396\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471411; batch adversarial loss: 0.575653\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453689; batch adversarial loss: 0.635453\n",
      "epoch 23; iter: 0; batch classifier loss: 0.560309; batch adversarial loss: 0.543005\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512141; batch adversarial loss: 0.540858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.477244; batch adversarial loss: 0.539713\n",
      "epoch 26; iter: 0; batch classifier loss: 0.454226; batch adversarial loss: 0.565234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440170; batch adversarial loss: 0.526767\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483532; batch adversarial loss: 0.546878\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448508; batch adversarial loss: 0.619645\n",
      "epoch 30; iter: 0; batch classifier loss: 0.587262; batch adversarial loss: 0.587091\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441581; batch adversarial loss: 0.484823\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465464; batch adversarial loss: 0.492338\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347639; batch adversarial loss: 0.484292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429944; batch adversarial loss: 0.572113\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465730; batch adversarial loss: 0.466461\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430980; batch adversarial loss: 0.557853\n",
      "epoch 37; iter: 0; batch classifier loss: 0.509573; batch adversarial loss: 0.554797\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439098; batch adversarial loss: 0.458573\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479727; batch adversarial loss: 0.565906\n",
      "epoch 40; iter: 0; batch classifier loss: 0.385939; batch adversarial loss: 0.527772\n",
      "epoch 41; iter: 0; batch classifier loss: 0.533459; batch adversarial loss: 0.534663\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438670; batch adversarial loss: 0.523753\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391335; batch adversarial loss: 0.565512\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401445; batch adversarial loss: 0.515651\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436142; batch adversarial loss: 0.537464\n",
      "epoch 46; iter: 0; batch classifier loss: 0.494259; batch adversarial loss: 0.575082\n",
      "epoch 47; iter: 0; batch classifier loss: 0.454714; batch adversarial loss: 0.582809\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377732; batch adversarial loss: 0.524036\n",
      "epoch 49; iter: 0; batch classifier loss: 0.453374; batch adversarial loss: 0.506718\n",
      "epoch 50; iter: 0; batch classifier loss: 0.345707; batch adversarial loss: 0.504527\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428861; batch adversarial loss: 0.560622\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455262; batch adversarial loss: 0.550348\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404409; batch adversarial loss: 0.474667\n",
      "epoch 54; iter: 0; batch classifier loss: 0.494445; batch adversarial loss: 0.602612\n",
      "epoch 55; iter: 0; batch classifier loss: 0.541350; batch adversarial loss: 0.480828\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371654; batch adversarial loss: 0.583000\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414779; batch adversarial loss: 0.520932\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444831; batch adversarial loss: 0.514307\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408330; batch adversarial loss: 0.526619\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427729; batch adversarial loss: 0.496415\n",
      "epoch 61; iter: 0; batch classifier loss: 0.530458; batch adversarial loss: 0.462441\n",
      "epoch 62; iter: 0; batch classifier loss: 0.491079; batch adversarial loss: 0.600518\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417375; batch adversarial loss: 0.569055\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404764; batch adversarial loss: 0.584984\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428633; batch adversarial loss: 0.585337\n",
      "epoch 66; iter: 0; batch classifier loss: 0.371518; batch adversarial loss: 0.490591\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433066; batch adversarial loss: 0.563740\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427645; batch adversarial loss: 0.561251\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418667; batch adversarial loss: 0.455094\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467704; batch adversarial loss: 0.501322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365136; batch adversarial loss: 0.543825\n",
      "epoch 72; iter: 0; batch classifier loss: 0.431585; batch adversarial loss: 0.534715\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380577; batch adversarial loss: 0.518607\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374851; batch adversarial loss: 0.628700\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386106; batch adversarial loss: 0.497846\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405670; batch adversarial loss: 0.517740\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415066; batch adversarial loss: 0.537076\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350086; batch adversarial loss: 0.499743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.502876; batch adversarial loss: 0.535749\n",
      "epoch 80; iter: 0; batch classifier loss: 0.311373; batch adversarial loss: 0.563990\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393187; batch adversarial loss: 0.508337\n",
      "epoch 82; iter: 0; batch classifier loss: 0.362072; batch adversarial loss: 0.580575\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398620; batch adversarial loss: 0.545033\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406401; batch adversarial loss: 0.544143\n",
      "epoch 85; iter: 0; batch classifier loss: 0.486614; batch adversarial loss: 0.517052\n",
      "epoch 86; iter: 0; batch classifier loss: 0.366140; batch adversarial loss: 0.654845\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396581; batch adversarial loss: 0.609011\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384960; batch adversarial loss: 0.552975\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369909; batch adversarial loss: 0.571727\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349167; batch adversarial loss: 0.459590\n",
      "epoch 91; iter: 0; batch classifier loss: 0.285078; batch adversarial loss: 0.535868\n",
      "epoch 92; iter: 0; batch classifier loss: 0.422472; batch adversarial loss: 0.517468\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417881; batch adversarial loss: 0.536178\n",
      "epoch 94; iter: 0; batch classifier loss: 0.388134; batch adversarial loss: 0.601069\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381151; batch adversarial loss: 0.581938\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381661; batch adversarial loss: 0.545955\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368560; batch adversarial loss: 0.533999\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389190; batch adversarial loss: 0.572451\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381616; batch adversarial loss: 0.517802\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352562; batch adversarial loss: 0.536432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.335628; batch adversarial loss: 0.534219\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366227; batch adversarial loss: 0.581672\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376376; batch adversarial loss: 0.648710\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421333; batch adversarial loss: 0.507774\n",
      "epoch 105; iter: 0; batch classifier loss: 0.357699; batch adversarial loss: 0.554453\n",
      "epoch 106; iter: 0; batch classifier loss: 0.507734; batch adversarial loss: 0.554036\n",
      "epoch 107; iter: 0; batch classifier loss: 0.292529; batch adversarial loss: 0.544974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403251; batch adversarial loss: 0.498026\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380088; batch adversarial loss: 0.526181\n",
      "epoch 110; iter: 0; batch classifier loss: 0.412791; batch adversarial loss: 0.562556\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387177; batch adversarial loss: 0.591671\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391425; batch adversarial loss: 0.535193\n",
      "epoch 113; iter: 0; batch classifier loss: 0.299493; batch adversarial loss: 0.552523\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365123; batch adversarial loss: 0.534907\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378754; batch adversarial loss: 0.535269\n",
      "epoch 116; iter: 0; batch classifier loss: 0.454084; batch adversarial loss: 0.525753\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393248; batch adversarial loss: 0.562745\n",
      "epoch 118; iter: 0; batch classifier loss: 0.431904; batch adversarial loss: 0.581502\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338232; batch adversarial loss: 0.525126\n",
      "epoch 120; iter: 0; batch classifier loss: 0.332295; batch adversarial loss: 0.516786\n",
      "epoch 121; iter: 0; batch classifier loss: 0.473550; batch adversarial loss: 0.554025\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402393; batch adversarial loss: 0.460283\n",
      "epoch 123; iter: 0; batch classifier loss: 0.393414; batch adversarial loss: 0.572261\n",
      "epoch 124; iter: 0; batch classifier loss: 0.388776; batch adversarial loss: 0.498113\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340831; batch adversarial loss: 0.592459\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424980; batch adversarial loss: 0.543890\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380762; batch adversarial loss: 0.488637\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346040; batch adversarial loss: 0.460999\n",
      "epoch 129; iter: 0; batch classifier loss: 0.408878; batch adversarial loss: 0.516805\n",
      "epoch 130; iter: 0; batch classifier loss: 0.419660; batch adversarial loss: 0.507119\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351101; batch adversarial loss: 0.580377\n",
      "epoch 132; iter: 0; batch classifier loss: 0.415589; batch adversarial loss: 0.470641\n",
      "epoch 133; iter: 0; batch classifier loss: 0.463872; batch adversarial loss: 0.603442\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393060; batch adversarial loss: 0.637598\n",
      "epoch 135; iter: 0; batch classifier loss: 0.438218; batch adversarial loss: 0.639254\n",
      "epoch 136; iter: 0; batch classifier loss: 0.470995; batch adversarial loss: 0.580135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375212; batch adversarial loss: 0.525060\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380547; batch adversarial loss: 0.555787\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373052; batch adversarial loss: 0.592869\n",
      "epoch 140; iter: 0; batch classifier loss: 0.314116; batch adversarial loss: 0.499092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.386538; batch adversarial loss: 0.563897\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356316; batch adversarial loss: 0.538442\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397814; batch adversarial loss: 0.516859\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379236; batch adversarial loss: 0.535823\n",
      "epoch 145; iter: 0; batch classifier loss: 0.468757; batch adversarial loss: 0.462341\n",
      "epoch 146; iter: 0; batch classifier loss: 0.450438; batch adversarial loss: 0.517558\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338022; batch adversarial loss: 0.505312\n",
      "epoch 148; iter: 0; batch classifier loss: 0.422607; batch adversarial loss: 0.553089\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.488815\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344870; batch adversarial loss: 0.468739\n",
      "epoch 151; iter: 0; batch classifier loss: 0.321002; batch adversarial loss: 0.562008\n",
      "epoch 152; iter: 0; batch classifier loss: 0.297934; batch adversarial loss: 0.497520\n",
      "epoch 153; iter: 0; batch classifier loss: 0.339827; batch adversarial loss: 0.534952\n",
      "epoch 154; iter: 0; batch classifier loss: 0.304153; batch adversarial loss: 0.526571\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367521; batch adversarial loss: 0.564332\n",
      "epoch 156; iter: 0; batch classifier loss: 0.326503; batch adversarial loss: 0.533985\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314145; batch adversarial loss: 0.540304\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354002; batch adversarial loss: 0.530787\n",
      "epoch 159; iter: 0; batch classifier loss: 0.329041; batch adversarial loss: 0.565720\n",
      "epoch 160; iter: 0; batch classifier loss: 0.399416; batch adversarial loss: 0.462089\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378781; batch adversarial loss: 0.537523\n",
      "epoch 162; iter: 0; batch classifier loss: 0.415983; batch adversarial loss: 0.599029\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367028; batch adversarial loss: 0.516662\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376811; batch adversarial loss: 0.506684\n",
      "epoch 165; iter: 0; batch classifier loss: 0.341697; batch adversarial loss: 0.572767\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351490; batch adversarial loss: 0.533625\n",
      "epoch 167; iter: 0; batch classifier loss: 0.427933; batch adversarial loss: 0.490123\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327893; batch adversarial loss: 0.483637\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337041; batch adversarial loss: 0.509306\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314859; batch adversarial loss: 0.510348\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359451; batch adversarial loss: 0.518922\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363738; batch adversarial loss: 0.537696\n",
      "epoch 173; iter: 0; batch classifier loss: 0.326696; batch adversarial loss: 0.598535\n",
      "epoch 174; iter: 0; batch classifier loss: 0.315680; batch adversarial loss: 0.526402\n",
      "epoch 175; iter: 0; batch classifier loss: 0.422532; batch adversarial loss: 0.490194\n",
      "epoch 176; iter: 0; batch classifier loss: 0.322979; batch adversarial loss: 0.553804\n",
      "epoch 177; iter: 0; batch classifier loss: 0.320722; batch adversarial loss: 0.517291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.334678; batch adversarial loss: 0.507826\n",
      "epoch 179; iter: 0; batch classifier loss: 0.413605; batch adversarial loss: 0.553074\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388165; batch adversarial loss: 0.544309\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334278; batch adversarial loss: 0.526117\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378119; batch adversarial loss: 0.469829\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388738; batch adversarial loss: 0.479703\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384645; batch adversarial loss: 0.516781\n",
      "epoch 185; iter: 0; batch classifier loss: 0.322114; batch adversarial loss: 0.563713\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311380; batch adversarial loss: 0.665504\n",
      "epoch 187; iter: 0; batch classifier loss: 0.377171; batch adversarial loss: 0.544239\n",
      "epoch 188; iter: 0; batch classifier loss: 0.439246; batch adversarial loss: 0.553259\n",
      "epoch 189; iter: 0; batch classifier loss: 0.383464; batch adversarial loss: 0.451632\n",
      "epoch 190; iter: 0; batch classifier loss: 0.455735; batch adversarial loss: 0.543989\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374279; batch adversarial loss: 0.515943\n",
      "epoch 192; iter: 0; batch classifier loss: 0.442254; batch adversarial loss: 0.590979\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349963; batch adversarial loss: 0.523133\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341693; batch adversarial loss: 0.527798\n",
      "epoch 195; iter: 0; batch classifier loss: 0.379467; batch adversarial loss: 0.525096\n",
      "epoch 196; iter: 0; batch classifier loss: 0.398841; batch adversarial loss: 0.562500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.338635; batch adversarial loss: 0.532862\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336947; batch adversarial loss: 0.515566\n",
      "epoch 199; iter: 0; batch classifier loss: 0.468069; batch adversarial loss: 0.526177\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695654; batch adversarial loss: 0.788079\n",
      "epoch 1; iter: 0; batch classifier loss: 0.743230; batch adversarial loss: 0.791325\n",
      "epoch 2; iter: 0; batch classifier loss: 0.832359; batch adversarial loss: 0.781256\n",
      "epoch 3; iter: 0; batch classifier loss: 0.745419; batch adversarial loss: 0.714996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630439; batch adversarial loss: 0.660901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580633; batch adversarial loss: 0.635590\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544899; batch adversarial loss: 0.622323\n",
      "epoch 7; iter: 0; batch classifier loss: 0.610904; batch adversarial loss: 0.582199\n",
      "epoch 8; iter: 0; batch classifier loss: 0.488715; batch adversarial loss: 0.579774\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548409; batch adversarial loss: 0.582466\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540607; batch adversarial loss: 0.565918\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569501; batch adversarial loss: 0.567791\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481137; batch adversarial loss: 0.588114\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537879; batch adversarial loss: 0.548096\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457670; batch adversarial loss: 0.584173\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433076; batch adversarial loss: 0.575769\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492874; batch adversarial loss: 0.581704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530231; batch adversarial loss: 0.560422\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520426; batch adversarial loss: 0.588123\n",
      "epoch 19; iter: 0; batch classifier loss: 0.494230; batch adversarial loss: 0.494630\n",
      "epoch 20; iter: 0; batch classifier loss: 0.565539; batch adversarial loss: 0.596668\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486525; batch adversarial loss: 0.530646\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469937; batch adversarial loss: 0.552899\n",
      "epoch 23; iter: 0; batch classifier loss: 0.503326; batch adversarial loss: 0.522801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.535569; batch adversarial loss: 0.456590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.447131; batch adversarial loss: 0.577237\n",
      "epoch 26; iter: 0; batch classifier loss: 0.488467; batch adversarial loss: 0.553875\n",
      "epoch 27; iter: 0; batch classifier loss: 0.396123; batch adversarial loss: 0.500776\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434851; batch adversarial loss: 0.579225\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511220; batch adversarial loss: 0.582743\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436516; batch adversarial loss: 0.590913\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449591; batch adversarial loss: 0.492225\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461516; batch adversarial loss: 0.556002\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452737; batch adversarial loss: 0.596769\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426726; batch adversarial loss: 0.513214\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411855; batch adversarial loss: 0.547377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512110; batch adversarial loss: 0.507740\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461162; batch adversarial loss: 0.580504\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405914; batch adversarial loss: 0.550848\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423284; batch adversarial loss: 0.520659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452903; batch adversarial loss: 0.501978\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481280; batch adversarial loss: 0.449398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472300; batch adversarial loss: 0.634925\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467373; batch adversarial loss: 0.537160\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436686; batch adversarial loss: 0.465133\n",
      "epoch 45; iter: 0; batch classifier loss: 0.406298; batch adversarial loss: 0.510200\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462457; batch adversarial loss: 0.526912\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478044; batch adversarial loss: 0.544488\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370301; batch adversarial loss: 0.553644\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447604; batch adversarial loss: 0.580942\n",
      "epoch 50; iter: 0; batch classifier loss: 0.368696; batch adversarial loss: 0.490559\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442243; batch adversarial loss: 0.553372\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446463; batch adversarial loss: 0.580851\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427663; batch adversarial loss: 0.598715\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399299; batch adversarial loss: 0.544237\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468367; batch adversarial loss: 0.553703\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429181; batch adversarial loss: 0.572317\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450189; batch adversarial loss: 0.542969\n",
      "epoch 58; iter: 0; batch classifier loss: 0.385869; batch adversarial loss: 0.572201\n",
      "epoch 59; iter: 0; batch classifier loss: 0.461685; batch adversarial loss: 0.581298\n",
      "epoch 60; iter: 0; batch classifier loss: 0.361436; batch adversarial loss: 0.598641\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412577; batch adversarial loss: 0.653176\n",
      "epoch 62; iter: 0; batch classifier loss: 0.333478; batch adversarial loss: 0.608247\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415785; batch adversarial loss: 0.508443\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381203; batch adversarial loss: 0.565427\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411528; batch adversarial loss: 0.480062\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396183; batch adversarial loss: 0.560290\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400391; batch adversarial loss: 0.525194\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427866; batch adversarial loss: 0.554486\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390667; batch adversarial loss: 0.487485\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421508; batch adversarial loss: 0.543884\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405366; batch adversarial loss: 0.538093\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403194; batch adversarial loss: 0.580798\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374724; batch adversarial loss: 0.507551\n",
      "epoch 74; iter: 0; batch classifier loss: 0.421383; batch adversarial loss: 0.611739\n",
      "epoch 75; iter: 0; batch classifier loss: 0.502660; batch adversarial loss: 0.490736\n",
      "epoch 76; iter: 0; batch classifier loss: 0.389981; batch adversarial loss: 0.506604\n",
      "epoch 77; iter: 0; batch classifier loss: 0.384466; batch adversarial loss: 0.544693\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381326; batch adversarial loss: 0.553519\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404959; batch adversarial loss: 0.579945\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427518; batch adversarial loss: 0.506278\n",
      "epoch 81; iter: 0; batch classifier loss: 0.459275; batch adversarial loss: 0.633860\n",
      "epoch 82; iter: 0; batch classifier loss: 0.474483; batch adversarial loss: 0.470895\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375109; batch adversarial loss: 0.508450\n",
      "epoch 84; iter: 0; batch classifier loss: 0.458945; batch adversarial loss: 0.527148\n",
      "epoch 85; iter: 0; batch classifier loss: 0.414932; batch adversarial loss: 0.506532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377368; batch adversarial loss: 0.514640\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368934; batch adversarial loss: 0.607228\n",
      "epoch 88; iter: 0; batch classifier loss: 0.310679; batch adversarial loss: 0.531800\n",
      "epoch 89; iter: 0; batch classifier loss: 0.431020; batch adversarial loss: 0.524693\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390173; batch adversarial loss: 0.486825\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427225; batch adversarial loss: 0.541328\n",
      "epoch 92; iter: 0; batch classifier loss: 0.332095; batch adversarial loss: 0.608057\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369094; batch adversarial loss: 0.534610\n",
      "epoch 94; iter: 0; batch classifier loss: 0.304941; batch adversarial loss: 0.581984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.474156; batch adversarial loss: 0.518532\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358223; batch adversarial loss: 0.580269\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434098; batch adversarial loss: 0.462959\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361746; batch adversarial loss: 0.517387\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377652; batch adversarial loss: 0.515738\n",
      "epoch 100; iter: 0; batch classifier loss: 0.427401; batch adversarial loss: 0.573156\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405031; batch adversarial loss: 0.599364\n",
      "epoch 102; iter: 0; batch classifier loss: 0.354017; batch adversarial loss: 0.636065\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365600; batch adversarial loss: 0.552148\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377091; batch adversarial loss: 0.553573\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358905; batch adversarial loss: 0.580421\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380285; batch adversarial loss: 0.499810\n",
      "epoch 107; iter: 0; batch classifier loss: 0.359734; batch adversarial loss: 0.518519\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378864; batch adversarial loss: 0.570895\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396927; batch adversarial loss: 0.555384\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358453; batch adversarial loss: 0.535074\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394400; batch adversarial loss: 0.626248\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357811; batch adversarial loss: 0.515627\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363077; batch adversarial loss: 0.554867\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428222; batch adversarial loss: 0.545904\n",
      "epoch 115; iter: 0; batch classifier loss: 0.400128; batch adversarial loss: 0.570522\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328527; batch adversarial loss: 0.507202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375504; batch adversarial loss: 0.592147\n",
      "epoch 118; iter: 0; batch classifier loss: 0.308198; batch adversarial loss: 0.559577\n",
      "epoch 119; iter: 0; batch classifier loss: 0.304807; batch adversarial loss: 0.604606\n",
      "epoch 120; iter: 0; batch classifier loss: 0.424096; batch adversarial loss: 0.523047\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338280; batch adversarial loss: 0.571096\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328659; batch adversarial loss: 0.563812\n",
      "epoch 123; iter: 0; batch classifier loss: 0.427213; batch adversarial loss: 0.626276\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371916; batch adversarial loss: 0.600706\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410849; batch adversarial loss: 0.574599\n",
      "epoch 126; iter: 0; batch classifier loss: 0.413896; batch adversarial loss: 0.608221\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360990; batch adversarial loss: 0.618244\n",
      "epoch 128; iter: 0; batch classifier loss: 0.343500; batch adversarial loss: 0.517710\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347464; batch adversarial loss: 0.568928\n",
      "epoch 130; iter: 0; batch classifier loss: 0.358304; batch adversarial loss: 0.544073\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324931; batch adversarial loss: 0.535380\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369606; batch adversarial loss: 0.479631\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425694; batch adversarial loss: 0.551761\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333445; batch adversarial loss: 0.572087\n",
      "epoch 135; iter: 0; batch classifier loss: 0.344311; batch adversarial loss: 0.481760\n",
      "epoch 136; iter: 0; batch classifier loss: 0.324392; batch adversarial loss: 0.542568\n",
      "epoch 137; iter: 0; batch classifier loss: 0.307889; batch adversarial loss: 0.510659\n",
      "epoch 138; iter: 0; batch classifier loss: 0.343683; batch adversarial loss: 0.480544\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374488; batch adversarial loss: 0.564474\n",
      "epoch 140; iter: 0; batch classifier loss: 0.321431; batch adversarial loss: 0.591844\n",
      "epoch 141; iter: 0; batch classifier loss: 0.370866; batch adversarial loss: 0.470053\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340171; batch adversarial loss: 0.508734\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359671; batch adversarial loss: 0.570374\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381765; batch adversarial loss: 0.506254\n",
      "epoch 145; iter: 0; batch classifier loss: 0.385162; batch adversarial loss: 0.561995\n",
      "epoch 146; iter: 0; batch classifier loss: 0.416708; batch adversarial loss: 0.672227\n",
      "epoch 147; iter: 0; batch classifier loss: 0.325250; batch adversarial loss: 0.618352\n",
      "epoch 148; iter: 0; batch classifier loss: 0.461187; batch adversarial loss: 0.574467\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410371; batch adversarial loss: 0.542729\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356138; batch adversarial loss: 0.546756\n",
      "epoch 151; iter: 0; batch classifier loss: 0.381166; batch adversarial loss: 0.589030\n",
      "epoch 152; iter: 0; batch classifier loss: 0.445450; batch adversarial loss: 0.619704\n",
      "epoch 153; iter: 0; batch classifier loss: 0.320368; batch adversarial loss: 0.506557\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377392; batch adversarial loss: 0.543880\n",
      "epoch 155; iter: 0; batch classifier loss: 0.343644; batch adversarial loss: 0.481698\n",
      "epoch 156; iter: 0; batch classifier loss: 0.415639; batch adversarial loss: 0.516658\n",
      "epoch 157; iter: 0; batch classifier loss: 0.276970; batch adversarial loss: 0.461550\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383053; batch adversarial loss: 0.588814\n",
      "epoch 159; iter: 0; batch classifier loss: 0.386081; batch adversarial loss: 0.543309\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363903; batch adversarial loss: 0.472272\n",
      "epoch 161; iter: 0; batch classifier loss: 0.312899; batch adversarial loss: 0.553111\n",
      "epoch 162; iter: 0; batch classifier loss: 0.340402; batch adversarial loss: 0.546786\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399642; batch adversarial loss: 0.592067\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387495; batch adversarial loss: 0.544552\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369669; batch adversarial loss: 0.581940\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378807; batch adversarial loss: 0.545101\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372680; batch adversarial loss: 0.525707\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353833; batch adversarial loss: 0.600521\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369140; batch adversarial loss: 0.463276\n",
      "epoch 170; iter: 0; batch classifier loss: 0.309716; batch adversarial loss: 0.500172\n",
      "epoch 171; iter: 0; batch classifier loss: 0.406829; batch adversarial loss: 0.544639\n",
      "epoch 172; iter: 0; batch classifier loss: 0.348293; batch adversarial loss: 0.493794\n",
      "epoch 173; iter: 0; batch classifier loss: 0.409984; batch adversarial loss: 0.534839\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377706; batch adversarial loss: 0.628453\n",
      "epoch 175; iter: 0; batch classifier loss: 0.422836; batch adversarial loss: 0.572424\n",
      "epoch 176; iter: 0; batch classifier loss: 0.304379; batch adversarial loss: 0.535352\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338139; batch adversarial loss: 0.471148\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312266; batch adversarial loss: 0.561394\n",
      "epoch 179; iter: 0; batch classifier loss: 0.336874; batch adversarial loss: 0.550278\n",
      "epoch 180; iter: 0; batch classifier loss: 0.302823; batch adversarial loss: 0.469973\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410418; batch adversarial loss: 0.535464\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346269; batch adversarial loss: 0.553357\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342439; batch adversarial loss: 0.582044\n",
      "epoch 184; iter: 0; batch classifier loss: 0.391101; batch adversarial loss: 0.505955\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373071; batch adversarial loss: 0.590375\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383767; batch adversarial loss: 0.538170\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334176; batch adversarial loss: 0.573582\n",
      "epoch 188; iter: 0; batch classifier loss: 0.463976; batch adversarial loss: 0.523834\n",
      "epoch 189; iter: 0; batch classifier loss: 0.408650; batch adversarial loss: 0.480387\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369010; batch adversarial loss: 0.602327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.314754; batch adversarial loss: 0.563045\n",
      "epoch 192; iter: 0; batch classifier loss: 0.274786; batch adversarial loss: 0.496517\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359132; batch adversarial loss: 0.608069\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393548; batch adversarial loss: 0.587433\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398922; batch adversarial loss: 0.590840\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330435; batch adversarial loss: 0.527231\n",
      "epoch 197; iter: 0; batch classifier loss: 0.379015; batch adversarial loss: 0.590992\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393663; batch adversarial loss: 0.507045\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316367; batch adversarial loss: 0.542403\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676923; batch adversarial loss: 0.598370\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594555; batch adversarial loss: 0.659431\n",
      "epoch 2; iter: 0; batch classifier loss: 0.549479; batch adversarial loss: 0.669196\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596085; batch adversarial loss: 0.635216\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557070; batch adversarial loss: 0.589502\n",
      "epoch 5; iter: 0; batch classifier loss: 0.605433; batch adversarial loss: 0.651631\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519470; batch adversarial loss: 0.599703\n",
      "epoch 7; iter: 0; batch classifier loss: 0.672283; batch adversarial loss: 0.623563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568728; batch adversarial loss: 0.587253\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532564; batch adversarial loss: 0.573774\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549311; batch adversarial loss: 0.590354\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607397; batch adversarial loss: 0.563883\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565031; batch adversarial loss: 0.595572\n",
      "epoch 13; iter: 0; batch classifier loss: 0.581354; batch adversarial loss: 0.573060\n",
      "epoch 14; iter: 0; batch classifier loss: 0.570392; batch adversarial loss: 0.560786\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580901; batch adversarial loss: 0.557737\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477916; batch adversarial loss: 0.533645\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516625; batch adversarial loss: 0.566311\n",
      "epoch 18; iter: 0; batch classifier loss: 0.537779; batch adversarial loss: 0.512924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483374; batch adversarial loss: 0.533150\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525721; batch adversarial loss: 0.541283\n",
      "epoch 21; iter: 0; batch classifier loss: 0.441181; batch adversarial loss: 0.589198\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521941; batch adversarial loss: 0.595802\n",
      "epoch 23; iter: 0; batch classifier loss: 0.578630; batch adversarial loss: 0.522010\n",
      "epoch 24; iter: 0; batch classifier loss: 0.437258; batch adversarial loss: 0.587629\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513839; batch adversarial loss: 0.579223\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432238; batch adversarial loss: 0.545181\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445461; batch adversarial loss: 0.519659\n",
      "epoch 28; iter: 0; batch classifier loss: 0.448398; batch adversarial loss: 0.527844\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455857; batch adversarial loss: 0.536032\n",
      "epoch 30; iter: 0; batch classifier loss: 0.562640; batch adversarial loss: 0.525915\n",
      "epoch 31; iter: 0; batch classifier loss: 0.524321; batch adversarial loss: 0.577296\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510063; batch adversarial loss: 0.496660\n",
      "epoch 33; iter: 0; batch classifier loss: 0.449467; batch adversarial loss: 0.505533\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457653; batch adversarial loss: 0.584032\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488538; batch adversarial loss: 0.526700\n",
      "epoch 36; iter: 0; batch classifier loss: 0.416619; batch adversarial loss: 0.468835\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461333; batch adversarial loss: 0.596786\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445161; batch adversarial loss: 0.459618\n",
      "epoch 39; iter: 0; batch classifier loss: 0.374572; batch adversarial loss: 0.518151\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449047; batch adversarial loss: 0.573292\n",
      "epoch 41; iter: 0; batch classifier loss: 0.553874; batch adversarial loss: 0.477213\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474401; batch adversarial loss: 0.554803\n",
      "epoch 43; iter: 0; batch classifier loss: 0.411064; batch adversarial loss: 0.582611\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396196; batch adversarial loss: 0.570083\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421301; batch adversarial loss: 0.591970\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420649; batch adversarial loss: 0.518253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431199; batch adversarial loss: 0.671027\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410764; batch adversarial loss: 0.498489\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393347; batch adversarial loss: 0.569654\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406797; batch adversarial loss: 0.493974\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418647; batch adversarial loss: 0.608914\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382442; batch adversarial loss: 0.541366\n",
      "epoch 53; iter: 0; batch classifier loss: 0.426335; batch adversarial loss: 0.501700\n",
      "epoch 54; iter: 0; batch classifier loss: 0.357870; batch adversarial loss: 0.529562\n",
      "epoch 55; iter: 0; batch classifier loss: 0.359879; batch adversarial loss: 0.607760\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408273; batch adversarial loss: 0.461030\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442993; batch adversarial loss: 0.445382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.413044; batch adversarial loss: 0.586426\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422389; batch adversarial loss: 0.526123\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429811; batch adversarial loss: 0.597994\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385943; batch adversarial loss: 0.496255\n",
      "epoch 62; iter: 0; batch classifier loss: 0.352202; batch adversarial loss: 0.544043\n",
      "epoch 63; iter: 0; batch classifier loss: 0.352524; batch adversarial loss: 0.543851\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423308; batch adversarial loss: 0.574446\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425409; batch adversarial loss: 0.517224\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443966; batch adversarial loss: 0.626456\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425663; batch adversarial loss: 0.524392\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412636; batch adversarial loss: 0.547609\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416642; batch adversarial loss: 0.557549\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410440; batch adversarial loss: 0.600400\n",
      "epoch 71; iter: 0; batch classifier loss: 0.510335; batch adversarial loss: 0.528594\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435424; batch adversarial loss: 0.597076\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422823; batch adversarial loss: 0.534359\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428817; batch adversarial loss: 0.613576\n",
      "epoch 75; iter: 0; batch classifier loss: 0.342031; batch adversarial loss: 0.527224\n",
      "epoch 76; iter: 0; batch classifier loss: 0.481457; batch adversarial loss: 0.578478\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382663; batch adversarial loss: 0.517283\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413451; batch adversarial loss: 0.562390\n",
      "epoch 79; iter: 0; batch classifier loss: 0.458564; batch adversarial loss: 0.514278\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435108; batch adversarial loss: 0.598559\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400902; batch adversarial loss: 0.545094\n",
      "epoch 82; iter: 0; batch classifier loss: 0.428584; batch adversarial loss: 0.540554\n",
      "epoch 83; iter: 0; batch classifier loss: 0.449196; batch adversarial loss: 0.562155\n",
      "epoch 84; iter: 0; batch classifier loss: 0.559791; batch adversarial loss: 0.494999\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367830; batch adversarial loss: 0.595888\n",
      "epoch 86; iter: 0; batch classifier loss: 0.454363; batch adversarial loss: 0.555526\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386451; batch adversarial loss: 0.546918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.442469; batch adversarial loss: 0.571347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.414654; batch adversarial loss: 0.527655\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402439; batch adversarial loss: 0.561832\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433159; batch adversarial loss: 0.484715\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404939; batch adversarial loss: 0.510813\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421931; batch adversarial loss: 0.598144\n",
      "epoch 94; iter: 0; batch classifier loss: 0.398614; batch adversarial loss: 0.537852\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422915; batch adversarial loss: 0.604291\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392470; batch adversarial loss: 0.545919\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456114; batch adversarial loss: 0.515197\n",
      "epoch 98; iter: 0; batch classifier loss: 0.338811; batch adversarial loss: 0.530155\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393324; batch adversarial loss: 0.514830\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409081; batch adversarial loss: 0.544094\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381818; batch adversarial loss: 0.599498\n",
      "epoch 102; iter: 0; batch classifier loss: 0.406295; batch adversarial loss: 0.518573\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384344; batch adversarial loss: 0.443931\n",
      "epoch 104; iter: 0; batch classifier loss: 0.431265; batch adversarial loss: 0.534201\n",
      "epoch 105; iter: 0; batch classifier loss: 0.355030; batch adversarial loss: 0.519067\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417653; batch adversarial loss: 0.577058\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352755; batch adversarial loss: 0.524919\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404842; batch adversarial loss: 0.548236\n",
      "epoch 109; iter: 0; batch classifier loss: 0.469556; batch adversarial loss: 0.546551\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395881; batch adversarial loss: 0.525845\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380094; batch adversarial loss: 0.487513\n",
      "epoch 112; iter: 0; batch classifier loss: 0.345861; batch adversarial loss: 0.531652\n",
      "epoch 113; iter: 0; batch classifier loss: 0.349279; batch adversarial loss: 0.520858\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412976; batch adversarial loss: 0.484921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389842; batch adversarial loss: 0.547890\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351306; batch adversarial loss: 0.576362\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404994; batch adversarial loss: 0.520719\n",
      "epoch 118; iter: 0; batch classifier loss: 0.506160; batch adversarial loss: 0.519742\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414624; batch adversarial loss: 0.580724\n",
      "epoch 120; iter: 0; batch classifier loss: 0.396670; batch adversarial loss: 0.475797\n",
      "epoch 121; iter: 0; batch classifier loss: 0.450120; batch adversarial loss: 0.507867\n",
      "epoch 122; iter: 0; batch classifier loss: 0.461469; batch adversarial loss: 0.618732\n",
      "epoch 123; iter: 0; batch classifier loss: 0.438482; batch adversarial loss: 0.609825\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379637; batch adversarial loss: 0.588198\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377877; batch adversarial loss: 0.498270\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317985; batch adversarial loss: 0.542607\n",
      "epoch 127; iter: 0; batch classifier loss: 0.324363; batch adversarial loss: 0.523408\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369601; batch adversarial loss: 0.541090\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354247; batch adversarial loss: 0.510979\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361390; batch adversarial loss: 0.533767\n",
      "epoch 131; iter: 0; batch classifier loss: 0.432346; batch adversarial loss: 0.523304\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377916; batch adversarial loss: 0.601986\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369610; batch adversarial loss: 0.507558\n",
      "epoch 134; iter: 0; batch classifier loss: 0.335620; batch adversarial loss: 0.545357\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343152; batch adversarial loss: 0.556908\n",
      "epoch 136; iter: 0; batch classifier loss: 0.423380; batch adversarial loss: 0.583246\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399294; batch adversarial loss: 0.614177\n",
      "epoch 138; iter: 0; batch classifier loss: 0.302757; batch adversarial loss: 0.571738\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350008; batch adversarial loss: 0.534860\n",
      "epoch 140; iter: 0; batch classifier loss: 0.438990; batch adversarial loss: 0.456658\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322030; batch adversarial loss: 0.591403\n",
      "epoch 142; iter: 0; batch classifier loss: 0.374839; batch adversarial loss: 0.583013\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359628; batch adversarial loss: 0.461155\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371455; batch adversarial loss: 0.521187\n",
      "epoch 145; iter: 0; batch classifier loss: 0.410273; batch adversarial loss: 0.590323\n",
      "epoch 146; iter: 0; batch classifier loss: 0.336907; batch adversarial loss: 0.453904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362088; batch adversarial loss: 0.506962\n",
      "epoch 148; iter: 0; batch classifier loss: 0.401467; batch adversarial loss: 0.578062\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415490; batch adversarial loss: 0.545108\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354812; batch adversarial loss: 0.584304\n",
      "epoch 151; iter: 0; batch classifier loss: 0.435608; batch adversarial loss: 0.584018\n",
      "epoch 152; iter: 0; batch classifier loss: 0.371935; batch adversarial loss: 0.503514\n",
      "epoch 153; iter: 0; batch classifier loss: 0.310174; batch adversarial loss: 0.606330\n",
      "epoch 154; iter: 0; batch classifier loss: 0.441456; batch adversarial loss: 0.560723\n",
      "epoch 155; iter: 0; batch classifier loss: 0.331756; batch adversarial loss: 0.613248\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350941; batch adversarial loss: 0.494003\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384278; batch adversarial loss: 0.553822\n",
      "epoch 158; iter: 0; batch classifier loss: 0.485208; batch adversarial loss: 0.473681\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387554; batch adversarial loss: 0.524509\n",
      "epoch 160; iter: 0; batch classifier loss: 0.401011; batch adversarial loss: 0.482940\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350166; batch adversarial loss: 0.572183\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412169; batch adversarial loss: 0.581514\n",
      "epoch 163; iter: 0; batch classifier loss: 0.424263; batch adversarial loss: 0.576634\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366031; batch adversarial loss: 0.554042\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360562; batch adversarial loss: 0.506838\n",
      "epoch 166; iter: 0; batch classifier loss: 0.436137; batch adversarial loss: 0.528769\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359575; batch adversarial loss: 0.593038\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376324; batch adversarial loss: 0.579332\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411874; batch adversarial loss: 0.565233\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379191; batch adversarial loss: 0.488462\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375842; batch adversarial loss: 0.607896\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387103; batch adversarial loss: 0.486964\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341134; batch adversarial loss: 0.557985\n",
      "epoch 174; iter: 0; batch classifier loss: 0.317122; batch adversarial loss: 0.511670\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384988; batch adversarial loss: 0.524696\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384309; batch adversarial loss: 0.503461\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380750; batch adversarial loss: 0.450035\n",
      "epoch 178; iter: 0; batch classifier loss: 0.293369; batch adversarial loss: 0.589140\n",
      "epoch 179; iter: 0; batch classifier loss: 0.363964; batch adversarial loss: 0.531198\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351167; batch adversarial loss: 0.545835\n",
      "epoch 181; iter: 0; batch classifier loss: 0.456120; batch adversarial loss: 0.583310\n",
      "epoch 182; iter: 0; batch classifier loss: 0.436132; batch adversarial loss: 0.517731\n",
      "epoch 183; iter: 0; batch classifier loss: 0.454983; batch adversarial loss: 0.638074\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384877; batch adversarial loss: 0.586325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.327633; batch adversarial loss: 0.555009\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326533; batch adversarial loss: 0.499657\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362865; batch adversarial loss: 0.586344\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338230; batch adversarial loss: 0.562102\n",
      "epoch 189; iter: 0; batch classifier loss: 0.403768; batch adversarial loss: 0.542820\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342634; batch adversarial loss: 0.577070\n",
      "epoch 191; iter: 0; batch classifier loss: 0.403615; batch adversarial loss: 0.585892\n",
      "epoch 192; iter: 0; batch classifier loss: 0.451859; batch adversarial loss: 0.581478\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372828; batch adversarial loss: 0.443728\n",
      "epoch 194; iter: 0; batch classifier loss: 0.363507; batch adversarial loss: 0.462343\n",
      "epoch 195; iter: 0; batch classifier loss: 0.419711; batch adversarial loss: 0.484247\n",
      "epoch 196; iter: 0; batch classifier loss: 0.365233; batch adversarial loss: 0.522205\n",
      "epoch 197; iter: 0; batch classifier loss: 0.401662; batch adversarial loss: 0.503116\n",
      "epoch 198; iter: 0; batch classifier loss: 0.425863; batch adversarial loss: 0.548047\n",
      "epoch 199; iter: 0; batch classifier loss: 0.369880; batch adversarial loss: 0.552021\n",
      "epoch 0; iter: 0; batch classifier loss: 0.804001; batch adversarial loss: 0.558647\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592635; batch adversarial loss: 0.608507\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652290; batch adversarial loss: 0.579219\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570292; batch adversarial loss: 0.583702\n",
      "epoch 4; iter: 0; batch classifier loss: 0.592312; batch adversarial loss: 0.643345\n",
      "epoch 5; iter: 0; batch classifier loss: 0.666462; batch adversarial loss: 0.602089\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639937; batch adversarial loss: 0.595908\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604953; batch adversarial loss: 0.587346\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508444; batch adversarial loss: 0.609286\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552115; batch adversarial loss: 0.600683\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472651; batch adversarial loss: 0.558902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556505; batch adversarial loss: 0.567738\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562786; batch adversarial loss: 0.617016\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514206; batch adversarial loss: 0.521628\n",
      "epoch 14; iter: 0; batch classifier loss: 0.632825; batch adversarial loss: 0.566943\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533186; batch adversarial loss: 0.572737\n",
      "epoch 16; iter: 0; batch classifier loss: 0.595572; batch adversarial loss: 0.578672\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522525; batch adversarial loss: 0.640755\n",
      "epoch 18; iter: 0; batch classifier loss: 0.450132; batch adversarial loss: 0.562189\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496401; batch adversarial loss: 0.584369\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429487; batch adversarial loss: 0.515781\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539557; batch adversarial loss: 0.591267\n",
      "epoch 22; iter: 0; batch classifier loss: 0.442926; batch adversarial loss: 0.566061\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467938; batch adversarial loss: 0.525489\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462522; batch adversarial loss: 0.536522\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462015; batch adversarial loss: 0.493035\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471469; batch adversarial loss: 0.505791\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537219; batch adversarial loss: 0.465198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495123; batch adversarial loss: 0.405806\n",
      "epoch 29; iter: 0; batch classifier loss: 0.470227; batch adversarial loss: 0.514410\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438443; batch adversarial loss: 0.547949\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488298; batch adversarial loss: 0.509912\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473321; batch adversarial loss: 0.581289\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443205; batch adversarial loss: 0.535058\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415855; batch adversarial loss: 0.528295\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440306; batch adversarial loss: 0.582403\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430464; batch adversarial loss: 0.480989\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475427; batch adversarial loss: 0.631311\n",
      "epoch 38; iter: 0; batch classifier loss: 0.463788; batch adversarial loss: 0.633144\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405019; batch adversarial loss: 0.543374\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470270; batch adversarial loss: 0.545761\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421033; batch adversarial loss: 0.552775\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418789; batch adversarial loss: 0.517412\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400662; batch adversarial loss: 0.507586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470837; batch adversarial loss: 0.479702\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400163; batch adversarial loss: 0.507166\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467940; batch adversarial loss: 0.516622\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460867; batch adversarial loss: 0.572657\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398421; batch adversarial loss: 0.554130\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487373; batch adversarial loss: 0.582581\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449353; batch adversarial loss: 0.543935\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401227; batch adversarial loss: 0.449878\n",
      "epoch 52; iter: 0; batch classifier loss: 0.374844; batch adversarial loss: 0.554540\n",
      "epoch 53; iter: 0; batch classifier loss: 0.487131; batch adversarial loss: 0.478205\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397744; batch adversarial loss: 0.573302\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402819; batch adversarial loss: 0.573263\n",
      "epoch 56; iter: 0; batch classifier loss: 0.392590; batch adversarial loss: 0.487344\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463075; batch adversarial loss: 0.496731\n",
      "epoch 58; iter: 0; batch classifier loss: 0.478834; batch adversarial loss: 0.506430\n",
      "epoch 59; iter: 0; batch classifier loss: 0.349802; batch adversarial loss: 0.487296\n",
      "epoch 60; iter: 0; batch classifier loss: 0.475313; batch adversarial loss: 0.506366\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404144; batch adversarial loss: 0.602178\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433426; batch adversarial loss: 0.592693\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441762; batch adversarial loss: 0.554153\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429123; batch adversarial loss: 0.458472\n",
      "epoch 65; iter: 0; batch classifier loss: 0.464090; batch adversarial loss: 0.554100\n",
      "epoch 66; iter: 0; batch classifier loss: 0.361005; batch adversarial loss: 0.448865\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384516; batch adversarial loss: 0.630997\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442267; batch adversarial loss: 0.525399\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382478; batch adversarial loss: 0.506077\n",
      "epoch 70; iter: 0; batch classifier loss: 0.375258; batch adversarial loss: 0.535046\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433830; batch adversarial loss: 0.525531\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371877; batch adversarial loss: 0.536120\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409017; batch adversarial loss: 0.495974\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443181; batch adversarial loss: 0.554926\n",
      "epoch 75; iter: 0; batch classifier loss: 0.472825; batch adversarial loss: 0.555452\n",
      "epoch 76; iter: 0; batch classifier loss: 0.449907; batch adversarial loss: 0.495740\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424155; batch adversarial loss: 0.523719\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419131; batch adversarial loss: 0.474795\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416838; batch adversarial loss: 0.522786\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392193; batch adversarial loss: 0.516178\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381090; batch adversarial loss: 0.582882\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418635; batch adversarial loss: 0.516376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.337502; batch adversarial loss: 0.522441\n",
      "epoch 84; iter: 0; batch classifier loss: 0.458512; batch adversarial loss: 0.542140\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365675; batch adversarial loss: 0.554465\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432064; batch adversarial loss: 0.610044\n",
      "epoch 87; iter: 0; batch classifier loss: 0.474986; batch adversarial loss: 0.451519\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433857; batch adversarial loss: 0.497257\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390850; batch adversarial loss: 0.515871\n",
      "epoch 90; iter: 0; batch classifier loss: 0.438009; batch adversarial loss: 0.544262\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428310; batch adversarial loss: 0.535698\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397900; batch adversarial loss: 0.639587\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353797; batch adversarial loss: 0.478187\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372450; batch adversarial loss: 0.553568\n",
      "epoch 95; iter: 0; batch classifier loss: 0.486848; batch adversarial loss: 0.535551\n",
      "epoch 96; iter: 0; batch classifier loss: 0.492961; batch adversarial loss: 0.526040\n",
      "epoch 97; iter: 0; batch classifier loss: 0.447404; batch adversarial loss: 0.544242\n",
      "epoch 98; iter: 0; batch classifier loss: 0.374233; batch adversarial loss: 0.525717\n",
      "epoch 99; iter: 0; batch classifier loss: 0.428524; batch adversarial loss: 0.562982\n",
      "epoch 100; iter: 0; batch classifier loss: 0.328380; batch adversarial loss: 0.534582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.412271; batch adversarial loss: 0.620640\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394345; batch adversarial loss: 0.448464\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384541; batch adversarial loss: 0.515719\n",
      "epoch 104; iter: 0; batch classifier loss: 0.458909; batch adversarial loss: 0.496953\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392276; batch adversarial loss: 0.458042\n",
      "epoch 106; iter: 0; batch classifier loss: 0.315605; batch adversarial loss: 0.439416\n",
      "epoch 107; iter: 0; batch classifier loss: 0.466340; batch adversarial loss: 0.516815\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370843; batch adversarial loss: 0.563531\n",
      "epoch 109; iter: 0; batch classifier loss: 0.391796; batch adversarial loss: 0.602438\n",
      "epoch 110; iter: 0; batch classifier loss: 0.398331; batch adversarial loss: 0.545249\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406731; batch adversarial loss: 0.592853\n",
      "epoch 112; iter: 0; batch classifier loss: 0.363740; batch adversarial loss: 0.506527\n",
      "epoch 113; iter: 0; batch classifier loss: 0.409363; batch adversarial loss: 0.544397\n",
      "epoch 114; iter: 0; batch classifier loss: 0.444545; batch adversarial loss: 0.534645\n",
      "epoch 115; iter: 0; batch classifier loss: 0.437033; batch adversarial loss: 0.620778\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410773; batch adversarial loss: 0.498036\n",
      "epoch 117; iter: 0; batch classifier loss: 0.422223; batch adversarial loss: 0.477571\n",
      "epoch 118; iter: 0; batch classifier loss: 0.404095; batch adversarial loss: 0.602249\n",
      "epoch 119; iter: 0; batch classifier loss: 0.359026; batch adversarial loss: 0.505942\n",
      "epoch 120; iter: 0; batch classifier loss: 0.402631; batch adversarial loss: 0.515975\n",
      "epoch 121; iter: 0; batch classifier loss: 0.333581; batch adversarial loss: 0.535126\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421935; batch adversarial loss: 0.535051\n",
      "epoch 123; iter: 0; batch classifier loss: 0.376830; batch adversarial loss: 0.592607\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377166; batch adversarial loss: 0.581995\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360066; batch adversarial loss: 0.515872\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355668; batch adversarial loss: 0.525424\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382680; batch adversarial loss: 0.584201\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410267; batch adversarial loss: 0.506810\n",
      "epoch 129; iter: 0; batch classifier loss: 0.371146; batch adversarial loss: 0.497029\n",
      "epoch 130; iter: 0; batch classifier loss: 0.404966; batch adversarial loss: 0.516245\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407085; batch adversarial loss: 0.478167\n",
      "epoch 132; iter: 0; batch classifier loss: 0.393260; batch adversarial loss: 0.583015\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346208; batch adversarial loss: 0.573637\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375995; batch adversarial loss: 0.583028\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389871; batch adversarial loss: 0.610857\n",
      "epoch 136; iter: 0; batch classifier loss: 0.399190; batch adversarial loss: 0.564189\n",
      "epoch 137; iter: 0; batch classifier loss: 0.284196; batch adversarial loss: 0.506697\n",
      "epoch 138; iter: 0; batch classifier loss: 0.435699; batch adversarial loss: 0.468032\n",
      "epoch 139; iter: 0; batch classifier loss: 0.489905; batch adversarial loss: 0.524071\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387313; batch adversarial loss: 0.573463\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322337; batch adversarial loss: 0.525586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376990; batch adversarial loss: 0.535098\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405560; batch adversarial loss: 0.563238\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359830; batch adversarial loss: 0.572946\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372412; batch adversarial loss: 0.649944\n",
      "epoch 146; iter: 0; batch classifier loss: 0.397727; batch adversarial loss: 0.563815\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351380; batch adversarial loss: 0.563550\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336118; batch adversarial loss: 0.535409\n",
      "epoch 149; iter: 0; batch classifier loss: 0.455349; batch adversarial loss: 0.580857\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389485; batch adversarial loss: 0.573096\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330241; batch adversarial loss: 0.544647\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384633; batch adversarial loss: 0.535899\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362683; batch adversarial loss: 0.505827\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348783; batch adversarial loss: 0.534771\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340474; batch adversarial loss: 0.544782\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381712; batch adversarial loss: 0.563943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383613; batch adversarial loss: 0.534903\n",
      "epoch 158; iter: 0; batch classifier loss: 0.359551; batch adversarial loss: 0.574406\n",
      "epoch 159; iter: 0; batch classifier loss: 0.357964; batch adversarial loss: 0.564134\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345535; batch adversarial loss: 0.544929\n",
      "epoch 161; iter: 0; batch classifier loss: 0.419503; batch adversarial loss: 0.516781\n",
      "epoch 162; iter: 0; batch classifier loss: 0.438353; batch adversarial loss: 0.516577\n",
      "epoch 163; iter: 0; batch classifier loss: 0.466622; batch adversarial loss: 0.487955\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351766; batch adversarial loss: 0.535023\n",
      "epoch 165; iter: 0; batch classifier loss: 0.421185; batch adversarial loss: 0.488150\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409239; batch adversarial loss: 0.488332\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362088; batch adversarial loss: 0.544763\n",
      "epoch 168; iter: 0; batch classifier loss: 0.454610; batch adversarial loss: 0.572583\n",
      "epoch 169; iter: 0; batch classifier loss: 0.318457; batch adversarial loss: 0.506807\n",
      "epoch 170; iter: 0; batch classifier loss: 0.370093; batch adversarial loss: 0.543601\n",
      "epoch 171; iter: 0; batch classifier loss: 0.452106; batch adversarial loss: 0.602018\n",
      "epoch 172; iter: 0; batch classifier loss: 0.469524; batch adversarial loss: 0.516549\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348740; batch adversarial loss: 0.535343\n",
      "epoch 174; iter: 0; batch classifier loss: 0.464510; batch adversarial loss: 0.496200\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308189; batch adversarial loss: 0.544185\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367429; batch adversarial loss: 0.543693\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333213; batch adversarial loss: 0.562778\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345886; batch adversarial loss: 0.469309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.401790; batch adversarial loss: 0.563170\n",
      "epoch 180; iter: 0; batch classifier loss: 0.330229; batch adversarial loss: 0.497446\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423021; batch adversarial loss: 0.486160\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348608; batch adversarial loss: 0.543957\n",
      "epoch 183; iter: 0; batch classifier loss: 0.369611; batch adversarial loss: 0.410167\n",
      "epoch 184; iter: 0; batch classifier loss: 0.294647; batch adversarial loss: 0.555368\n",
      "epoch 185; iter: 0; batch classifier loss: 0.427679; batch adversarial loss: 0.591521\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383165; batch adversarial loss: 0.544005\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313903; batch adversarial loss: 0.525441\n",
      "epoch 188; iter: 0; batch classifier loss: 0.431773; batch adversarial loss: 0.485520\n",
      "epoch 189; iter: 0; batch classifier loss: 0.420008; batch adversarial loss: 0.622015\n",
      "epoch 190; iter: 0; batch classifier loss: 0.424692; batch adversarial loss: 0.534737\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365700; batch adversarial loss: 0.486745\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388332; batch adversarial loss: 0.554241\n",
      "epoch 193; iter: 0; batch classifier loss: 0.310938; batch adversarial loss: 0.592755\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380757; batch adversarial loss: 0.611572\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290163; batch adversarial loss: 0.592034\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332154; batch adversarial loss: 0.553078\n",
      "epoch 197; iter: 0; batch classifier loss: 0.280423; batch adversarial loss: 0.524460\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387472; batch adversarial loss: 0.476840\n",
      "epoch 199; iter: 0; batch classifier loss: 0.432263; batch adversarial loss: 0.517128\n",
      "epoch 0; iter: 0; batch classifier loss: 0.792102; batch adversarial loss: 0.636978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.611857; batch adversarial loss: 0.653243\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551029; batch adversarial loss: 0.621480\n",
      "epoch 3; iter: 0; batch classifier loss: 0.535671; batch adversarial loss: 0.633964\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588153; batch adversarial loss: 0.667160\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500377; batch adversarial loss: 0.588930\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538490; batch adversarial loss: 0.585567\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588920; batch adversarial loss: 0.602924\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564386; batch adversarial loss: 0.601330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565151; batch adversarial loss: 0.617857\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479372; batch adversarial loss: 0.599752\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582812; batch adversarial loss: 0.551360\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548516; batch adversarial loss: 0.564700\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471408; batch adversarial loss: 0.592785\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498940; batch adversarial loss: 0.573559\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524339; batch adversarial loss: 0.602992\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480567; batch adversarial loss: 0.530375\n",
      "epoch 17; iter: 0; batch classifier loss: 0.447021; batch adversarial loss: 0.566784\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479727; batch adversarial loss: 0.578311\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545110; batch adversarial loss: 0.569110\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553086; batch adversarial loss: 0.604699\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471118; batch adversarial loss: 0.587360\n",
      "epoch 22; iter: 0; batch classifier loss: 0.518804; batch adversarial loss: 0.576167\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444207; batch adversarial loss: 0.505165\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489799; batch adversarial loss: 0.504577\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506730; batch adversarial loss: 0.599058\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483502; batch adversarial loss: 0.541728\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459725; batch adversarial loss: 0.574284\n",
      "epoch 28; iter: 0; batch classifier loss: 0.427985; batch adversarial loss: 0.560593\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494282; batch adversarial loss: 0.557124\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491432; batch adversarial loss: 0.494349\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479104; batch adversarial loss: 0.545390\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500816; batch adversarial loss: 0.554744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494016; batch adversarial loss: 0.562135\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462545; batch adversarial loss: 0.465782\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448430; batch adversarial loss: 0.498615\n",
      "epoch 36; iter: 0; batch classifier loss: 0.511380; batch adversarial loss: 0.615340\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500017; batch adversarial loss: 0.577855\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482125; batch adversarial loss: 0.478887\n",
      "epoch 39; iter: 0; batch classifier loss: 0.398940; batch adversarial loss: 0.500772\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455569; batch adversarial loss: 0.606119\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407135; batch adversarial loss: 0.536229\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409642; batch adversarial loss: 0.527725\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385951; batch adversarial loss: 0.552717\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441985; batch adversarial loss: 0.509640\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402148; batch adversarial loss: 0.615532\n",
      "epoch 46; iter: 0; batch classifier loss: 0.559858; batch adversarial loss: 0.633969\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422917; batch adversarial loss: 0.649770\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408752; batch adversarial loss: 0.483775\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423667; batch adversarial loss: 0.527300\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435914; batch adversarial loss: 0.641010\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445796; batch adversarial loss: 0.625497\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391314; batch adversarial loss: 0.553635\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421251; batch adversarial loss: 0.633933\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447748; batch adversarial loss: 0.544043\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408509; batch adversarial loss: 0.455061\n",
      "epoch 56; iter: 0; batch classifier loss: 0.382689; batch adversarial loss: 0.614236\n",
      "epoch 57; iter: 0; batch classifier loss: 0.342249; batch adversarial loss: 0.518192\n",
      "epoch 58; iter: 0; batch classifier loss: 0.483298; batch adversarial loss: 0.630760\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432966; batch adversarial loss: 0.625275\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393911; batch adversarial loss: 0.573219\n",
      "epoch 61; iter: 0; batch classifier loss: 0.500770; batch adversarial loss: 0.482221\n",
      "epoch 62; iter: 0; batch classifier loss: 0.332243; batch adversarial loss: 0.535737\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400927; batch adversarial loss: 0.580268\n",
      "epoch 64; iter: 0; batch classifier loss: 0.468532; batch adversarial loss: 0.528224\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449798; batch adversarial loss: 0.571657\n",
      "epoch 66; iter: 0; batch classifier loss: 0.362527; batch adversarial loss: 0.536639\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366635; batch adversarial loss: 0.614112\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407226; batch adversarial loss: 0.527666\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404681; batch adversarial loss: 0.464134\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421577; batch adversarial loss: 0.598407\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391345; batch adversarial loss: 0.642865\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381675; batch adversarial loss: 0.597726\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415210; batch adversarial loss: 0.524648\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444452; batch adversarial loss: 0.573522\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449365; batch adversarial loss: 0.541693\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372180; batch adversarial loss: 0.571496\n",
      "epoch 77; iter: 0; batch classifier loss: 0.450199; batch adversarial loss: 0.651736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.372597; batch adversarial loss: 0.590950\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400358; batch adversarial loss: 0.515724\n",
      "epoch 80; iter: 0; batch classifier loss: 0.517157; batch adversarial loss: 0.625760\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413320; batch adversarial loss: 0.510136\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416192; batch adversarial loss: 0.554950\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375018; batch adversarial loss: 0.509957\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380638; batch adversarial loss: 0.608696\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404072; batch adversarial loss: 0.519400\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416762; batch adversarial loss: 0.605575\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412804; batch adversarial loss: 0.475030\n",
      "epoch 88; iter: 0; batch classifier loss: 0.325743; batch adversarial loss: 0.553530\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378022; batch adversarial loss: 0.624623\n",
      "epoch 90; iter: 0; batch classifier loss: 0.437769; batch adversarial loss: 0.518169\n",
      "epoch 91; iter: 0; batch classifier loss: 0.336236; batch adversarial loss: 0.544761\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405797; batch adversarial loss: 0.615615\n",
      "epoch 93; iter: 0; batch classifier loss: 0.437405; batch adversarial loss: 0.588710\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390314; batch adversarial loss: 0.571396\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334019; batch adversarial loss: 0.437835\n",
      "epoch 96; iter: 0; batch classifier loss: 0.379970; batch adversarial loss: 0.535851\n",
      "epoch 97; iter: 0; batch classifier loss: 0.464163; batch adversarial loss: 0.553459\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390086; batch adversarial loss: 0.624582\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412145; batch adversarial loss: 0.553560\n",
      "epoch 100; iter: 0; batch classifier loss: 0.441333; batch adversarial loss: 0.509158\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392846; batch adversarial loss: 0.508710\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389621; batch adversarial loss: 0.571174\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414198; batch adversarial loss: 0.527031\n",
      "epoch 104; iter: 0; batch classifier loss: 0.454413; batch adversarial loss: 0.571304\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398534; batch adversarial loss: 0.580337\n",
      "epoch 106; iter: 0; batch classifier loss: 0.455136; batch adversarial loss: 0.562394\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417256; batch adversarial loss: 0.517899\n",
      "epoch 108; iter: 0; batch classifier loss: 0.321592; batch adversarial loss: 0.473506\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360764; batch adversarial loss: 0.517790\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426597; batch adversarial loss: 0.527273\n",
      "epoch 111; iter: 0; batch classifier loss: 0.437188; batch adversarial loss: 0.589436\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366122; batch adversarial loss: 0.535883\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354443; batch adversarial loss: 0.562006\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405929; batch adversarial loss: 0.571200\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370098; batch adversarial loss: 0.589232\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359485; batch adversarial loss: 0.508970\n",
      "epoch 117; iter: 0; batch classifier loss: 0.420180; batch adversarial loss: 0.598252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406097; batch adversarial loss: 0.526774\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441540; batch adversarial loss: 0.571153\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408825; batch adversarial loss: 0.589327\n",
      "epoch 121; iter: 0; batch classifier loss: 0.387743; batch adversarial loss: 0.500035\n",
      "epoch 122; iter: 0; batch classifier loss: 0.331362; batch adversarial loss: 0.491682\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389655; batch adversarial loss: 0.509040\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322670; batch adversarial loss: 0.553853\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395243; batch adversarial loss: 0.544172\n",
      "epoch 126; iter: 0; batch classifier loss: 0.432578; batch adversarial loss: 0.508444\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333189; batch adversarial loss: 0.580556\n",
      "epoch 128; iter: 0; batch classifier loss: 0.432760; batch adversarial loss: 0.589009\n",
      "epoch 129; iter: 0; batch classifier loss: 0.335960; batch adversarial loss: 0.509611\n",
      "epoch 130; iter: 0; batch classifier loss: 0.274168; batch adversarial loss: 0.545085\n",
      "epoch 131; iter: 0; batch classifier loss: 0.440359; batch adversarial loss: 0.518054\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369990; batch adversarial loss: 0.500517\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302176; batch adversarial loss: 0.553652\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377902; batch adversarial loss: 0.553345\n",
      "epoch 135; iter: 0; batch classifier loss: 0.426394; batch adversarial loss: 0.509228\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383279; batch adversarial loss: 0.562685\n",
      "epoch 137; iter: 0; batch classifier loss: 0.435130; batch adversarial loss: 0.642743\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415281; batch adversarial loss: 0.580448\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367149; batch adversarial loss: 0.562694\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383970; batch adversarial loss: 0.535398\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334688; batch adversarial loss: 0.624122\n",
      "epoch 142; iter: 0; batch classifier loss: 0.421576; batch adversarial loss: 0.491424\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366208; batch adversarial loss: 0.598433\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354456; batch adversarial loss: 0.436998\n",
      "epoch 145; iter: 0; batch classifier loss: 0.396946; batch adversarial loss: 0.580555\n",
      "epoch 146; iter: 0; batch classifier loss: 0.344168; batch adversarial loss: 0.562428\n",
      "epoch 147; iter: 0; batch classifier loss: 0.340405; batch adversarial loss: 0.571680\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357503; batch adversarial loss: 0.597780\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382482; batch adversarial loss: 0.589401\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347443; batch adversarial loss: 0.536096\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376680; batch adversarial loss: 0.562638\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368053; batch adversarial loss: 0.553896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386439; batch adversarial loss: 0.527320\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353651; batch adversarial loss: 0.526727\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401757; batch adversarial loss: 0.580016\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359072; batch adversarial loss: 0.553595\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326503; batch adversarial loss: 0.607088\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425719; batch adversarial loss: 0.509398\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394712; batch adversarial loss: 0.589225\n",
      "epoch 160; iter: 0; batch classifier loss: 0.349969; batch adversarial loss: 0.589339\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397620; batch adversarial loss: 0.473958\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364339; batch adversarial loss: 0.526788\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374638; batch adversarial loss: 0.518096\n",
      "epoch 164; iter: 0; batch classifier loss: 0.390153; batch adversarial loss: 0.571276\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375530; batch adversarial loss: 0.588997\n",
      "epoch 166; iter: 0; batch classifier loss: 0.385741; batch adversarial loss: 0.580573\n",
      "epoch 167; iter: 0; batch classifier loss: 0.389363; batch adversarial loss: 0.544973\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387815; batch adversarial loss: 0.571771\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380033; batch adversarial loss: 0.509393\n",
      "epoch 170; iter: 0; batch classifier loss: 0.381263; batch adversarial loss: 0.571180\n",
      "epoch 171; iter: 0; batch classifier loss: 0.436115; batch adversarial loss: 0.580431\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384952; batch adversarial loss: 0.562755\n",
      "epoch 173; iter: 0; batch classifier loss: 0.380745; batch adversarial loss: 0.490987\n",
      "epoch 174; iter: 0; batch classifier loss: 0.308925; batch adversarial loss: 0.580533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175; iter: 0; batch classifier loss: 0.397698; batch adversarial loss: 0.509033\n",
      "epoch 176; iter: 0; batch classifier loss: 0.279104; batch adversarial loss: 0.509105\n",
      "epoch 177; iter: 0; batch classifier loss: 0.400210; batch adversarial loss: 0.607257\n",
      "epoch 178; iter: 0; batch classifier loss: 0.306585; batch adversarial loss: 0.562581\n",
      "epoch 179; iter: 0; batch classifier loss: 0.418818; batch adversarial loss: 0.615926\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374267; batch adversarial loss: 0.535716\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346924; batch adversarial loss: 0.580160\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341824; batch adversarial loss: 0.526492\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315351; batch adversarial loss: 0.561835\n",
      "epoch 184; iter: 0; batch classifier loss: 0.327718; batch adversarial loss: 0.615784\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349056; batch adversarial loss: 0.562694\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325334; batch adversarial loss: 0.553480\n",
      "epoch 187; iter: 0; batch classifier loss: 0.293224; batch adversarial loss: 0.490988\n",
      "epoch 188; iter: 0; batch classifier loss: 0.394020; batch adversarial loss: 0.544532\n",
      "epoch 189; iter: 0; batch classifier loss: 0.416600; batch adversarial loss: 0.607304\n",
      "epoch 190; iter: 0; batch classifier loss: 0.319491; batch adversarial loss: 0.535824\n",
      "epoch 191; iter: 0; batch classifier loss: 0.405977; batch adversarial loss: 0.500066\n",
      "epoch 192; iter: 0; batch classifier loss: 0.258749; batch adversarial loss: 0.544911\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360421; batch adversarial loss: 0.598598\n",
      "epoch 194; iter: 0; batch classifier loss: 0.314689; batch adversarial loss: 0.580390\n",
      "epoch 195; iter: 0; batch classifier loss: 0.399147; batch adversarial loss: 0.633689\n",
      "epoch 196; iter: 0; batch classifier loss: 0.298066; batch adversarial loss: 0.598184\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326480; batch adversarial loss: 0.625432\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329289; batch adversarial loss: 0.535345\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314192; batch adversarial loss: 0.554109\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649873; batch adversarial loss: 0.673532\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601712; batch adversarial loss: 0.659602\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547140; batch adversarial loss: 0.629720\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615556; batch adversarial loss: 0.633260\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525966; batch adversarial loss: 0.647753\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575823; batch adversarial loss: 0.664295\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494856; batch adversarial loss: 0.602267\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561326; batch adversarial loss: 0.551495\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523927; batch adversarial loss: 0.538680\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535163; batch adversarial loss: 0.525942\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504744; batch adversarial loss: 0.557147\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563599; batch adversarial loss: 0.585097\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478831; batch adversarial loss: 0.599794\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537882; batch adversarial loss: 0.528081\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457243; batch adversarial loss: 0.534688\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497016; batch adversarial loss: 0.513150\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494086; batch adversarial loss: 0.550101\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536402; batch adversarial loss: 0.567143\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464596; batch adversarial loss: 0.619213\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542678; batch adversarial loss: 0.580027\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515073; batch adversarial loss: 0.541020\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480940; batch adversarial loss: 0.529047\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438455; batch adversarial loss: 0.632096\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454762; batch adversarial loss: 0.532864\n",
      "epoch 24; iter: 0; batch classifier loss: 0.437395; batch adversarial loss: 0.500520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457874; batch adversarial loss: 0.453120\n",
      "epoch 26; iter: 0; batch classifier loss: 0.443388; batch adversarial loss: 0.577827\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465064; batch adversarial loss: 0.519070\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494650; batch adversarial loss: 0.581582\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430624; batch adversarial loss: 0.546738\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485287; batch adversarial loss: 0.529654\n",
      "epoch 31; iter: 0; batch classifier loss: 0.359611; batch adversarial loss: 0.550968\n",
      "epoch 32; iter: 0; batch classifier loss: 0.440237; batch adversarial loss: 0.640697\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446104; batch adversarial loss: 0.625731\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457982; batch adversarial loss: 0.574301\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404914; batch adversarial loss: 0.581202\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474689; batch adversarial loss: 0.555048\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481688; batch adversarial loss: 0.520828\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432164; batch adversarial loss: 0.537239\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421666; batch adversarial loss: 0.503216\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450061; batch adversarial loss: 0.520272\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449575; batch adversarial loss: 0.561264\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428147; batch adversarial loss: 0.536717\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435111; batch adversarial loss: 0.560752\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415204; batch adversarial loss: 0.552112\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460203; batch adversarial loss: 0.509150\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467187; batch adversarial loss: 0.580984\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444058; batch adversarial loss: 0.582260\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387006; batch adversarial loss: 0.582033\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388501; batch adversarial loss: 0.544731\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388008; batch adversarial loss: 0.608366\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399052; batch adversarial loss: 0.581183\n",
      "epoch 52; iter: 0; batch classifier loss: 0.388098; batch adversarial loss: 0.562726\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428595; batch adversarial loss: 0.508480\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417472; batch adversarial loss: 0.571914\n",
      "epoch 55; iter: 0; batch classifier loss: 0.352467; batch adversarial loss: 0.535159\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412366; batch adversarial loss: 0.517641\n",
      "epoch 57; iter: 0; batch classifier loss: 0.417573; batch adversarial loss: 0.580551\n",
      "epoch 58; iter: 0; batch classifier loss: 0.503830; batch adversarial loss: 0.518180\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412941; batch adversarial loss: 0.527594\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422751; batch adversarial loss: 0.588365\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420593; batch adversarial loss: 0.481733\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415233; batch adversarial loss: 0.525841\n",
      "epoch 63; iter: 0; batch classifier loss: 0.393456; batch adversarial loss: 0.562909\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449483; batch adversarial loss: 0.606395\n",
      "epoch 65; iter: 0; batch classifier loss: 0.460675; batch adversarial loss: 0.544371\n",
      "epoch 66; iter: 0; batch classifier loss: 0.357373; batch adversarial loss: 0.526434\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436452; batch adversarial loss: 0.571974\n",
      "epoch 68; iter: 0; batch classifier loss: 0.465669; batch adversarial loss: 0.570928\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405585; batch adversarial loss: 0.528816\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417538; batch adversarial loss: 0.563275\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435084; batch adversarial loss: 0.580389\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411535; batch adversarial loss: 0.525989\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367478; batch adversarial loss: 0.472995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.425862; batch adversarial loss: 0.661079\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369085; batch adversarial loss: 0.546025\n",
      "epoch 76; iter: 0; batch classifier loss: 0.511970; batch adversarial loss: 0.526567\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378006; batch adversarial loss: 0.525771\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386914; batch adversarial loss: 0.599160\n",
      "epoch 79; iter: 0; batch classifier loss: 0.368079; batch adversarial loss: 0.562237\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430944; batch adversarial loss: 0.447045\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417833; batch adversarial loss: 0.526086\n",
      "epoch 82; iter: 0; batch classifier loss: 0.461902; batch adversarial loss: 0.535847\n",
      "epoch 83; iter: 0; batch classifier loss: 0.360490; batch adversarial loss: 0.517154\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445769; batch adversarial loss: 0.588554\n",
      "epoch 85; iter: 0; batch classifier loss: 0.329595; batch adversarial loss: 0.580867\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395811; batch adversarial loss: 0.562404\n",
      "epoch 87; iter: 0; batch classifier loss: 0.441807; batch adversarial loss: 0.473466\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414128; batch adversarial loss: 0.545440\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342114; batch adversarial loss: 0.498947\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372925; batch adversarial loss: 0.544762\n",
      "epoch 91; iter: 0; batch classifier loss: 0.570181; batch adversarial loss: 0.561819\n",
      "epoch 92; iter: 0; batch classifier loss: 0.487892; batch adversarial loss: 0.562346\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451980; batch adversarial loss: 0.536066\n",
      "epoch 94; iter: 0; batch classifier loss: 0.437346; batch adversarial loss: 0.508487\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334149; batch adversarial loss: 0.491303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.353753; batch adversarial loss: 0.481555\n",
      "epoch 97; iter: 0; batch classifier loss: 0.458395; batch adversarial loss: 0.581062\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410064; batch adversarial loss: 0.541983\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409031; batch adversarial loss: 0.445895\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420785; batch adversarial loss: 0.546523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.361207; batch adversarial loss: 0.515571\n",
      "epoch 102; iter: 0; batch classifier loss: 0.424302; batch adversarial loss: 0.609340\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402632; batch adversarial loss: 0.633338\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352594; batch adversarial loss: 0.543604\n",
      "epoch 105; iter: 0; batch classifier loss: 0.345201; batch adversarial loss: 0.598089\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357194; batch adversarial loss: 0.500272\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388741; batch adversarial loss: 0.535639\n",
      "epoch 108; iter: 0; batch classifier loss: 0.344093; batch adversarial loss: 0.492248\n",
      "epoch 109; iter: 0; batch classifier loss: 0.444167; batch adversarial loss: 0.571778\n",
      "epoch 110; iter: 0; batch classifier loss: 0.315326; batch adversarial loss: 0.535608\n",
      "epoch 111; iter: 0; batch classifier loss: 0.527837; batch adversarial loss: 0.518716\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368484; batch adversarial loss: 0.507827\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369828; batch adversarial loss: 0.545596\n",
      "epoch 114; iter: 0; batch classifier loss: 0.398636; batch adversarial loss: 0.534668\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412564; batch adversarial loss: 0.527498\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402510; batch adversarial loss: 0.481874\n",
      "epoch 117; iter: 0; batch classifier loss: 0.431732; batch adversarial loss: 0.570743\n",
      "epoch 118; iter: 0; batch classifier loss: 0.320629; batch adversarial loss: 0.552555\n",
      "epoch 119; iter: 0; batch classifier loss: 0.424585; batch adversarial loss: 0.553675\n",
      "epoch 120; iter: 0; batch classifier loss: 0.401383; batch adversarial loss: 0.553192\n",
      "epoch 121; iter: 0; batch classifier loss: 0.420192; batch adversarial loss: 0.536251\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328096; batch adversarial loss: 0.536504\n",
      "epoch 123; iter: 0; batch classifier loss: 0.282131; batch adversarial loss: 0.553171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.366564; batch adversarial loss: 0.588151\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410326; batch adversarial loss: 0.554738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.397825; batch adversarial loss: 0.563509\n",
      "epoch 127; iter: 0; batch classifier loss: 0.406726; batch adversarial loss: 0.536076\n",
      "epoch 128; iter: 0; batch classifier loss: 0.393821; batch adversarial loss: 0.588657\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324429; batch adversarial loss: 0.535701\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348194; batch adversarial loss: 0.527642\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359436; batch adversarial loss: 0.553626\n",
      "epoch 132; iter: 0; batch classifier loss: 0.344793; batch adversarial loss: 0.608636\n",
      "epoch 133; iter: 0; batch classifier loss: 0.464397; batch adversarial loss: 0.518128\n",
      "epoch 134; iter: 0; batch classifier loss: 0.447952; batch adversarial loss: 0.427369\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335357; batch adversarial loss: 0.546317\n",
      "epoch 136; iter: 0; batch classifier loss: 0.374589; batch adversarial loss: 0.570615\n",
      "epoch 137; iter: 0; batch classifier loss: 0.340064; batch adversarial loss: 0.588605\n",
      "epoch 138; iter: 0; batch classifier loss: 0.496465; batch adversarial loss: 0.517944\n",
      "epoch 139; iter: 0; batch classifier loss: 0.412720; batch adversarial loss: 0.542450\n",
      "epoch 140; iter: 0; batch classifier loss: 0.369401; batch adversarial loss: 0.526704\n",
      "epoch 141; iter: 0; batch classifier loss: 0.321597; batch adversarial loss: 0.554586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320098; batch adversarial loss: 0.489648\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345292; batch adversarial loss: 0.589144\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352335; batch adversarial loss: 0.535617\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377564; batch adversarial loss: 0.590318\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325876; batch adversarial loss: 0.527188\n",
      "epoch 147; iter: 0; batch classifier loss: 0.416074; batch adversarial loss: 0.543734\n",
      "epoch 148; iter: 0; batch classifier loss: 0.423565; batch adversarial loss: 0.544396\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402524; batch adversarial loss: 0.588831\n",
      "epoch 150; iter: 0; batch classifier loss: 0.403041; batch adversarial loss: 0.542797\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353383; batch adversarial loss: 0.580343\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353065; batch adversarial loss: 0.527540\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388062; batch adversarial loss: 0.543884\n",
      "epoch 154; iter: 0; batch classifier loss: 0.422096; batch adversarial loss: 0.643091\n",
      "epoch 155; iter: 0; batch classifier loss: 0.299941; batch adversarial loss: 0.535575\n",
      "epoch 156; iter: 0; batch classifier loss: 0.438780; batch adversarial loss: 0.482427\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396082; batch adversarial loss: 0.533203\n",
      "epoch 158; iter: 0; batch classifier loss: 0.396233; batch adversarial loss: 0.635039\n",
      "epoch 159; iter: 0; batch classifier loss: 0.345397; batch adversarial loss: 0.542819\n",
      "epoch 160; iter: 0; batch classifier loss: 0.276036; batch adversarial loss: 0.518743\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399060; batch adversarial loss: 0.569560\n",
      "epoch 162; iter: 0; batch classifier loss: 0.459748; batch adversarial loss: 0.508945\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397234; batch adversarial loss: 0.579818\n",
      "epoch 164; iter: 0; batch classifier loss: 0.325299; batch adversarial loss: 0.607181\n",
      "epoch 165; iter: 0; batch classifier loss: 0.384044; batch adversarial loss: 0.507554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.399563; batch adversarial loss: 0.473776\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319447; batch adversarial loss: 0.554679\n",
      "epoch 168; iter: 0; batch classifier loss: 0.378241; batch adversarial loss: 0.572100\n",
      "epoch 169; iter: 0; batch classifier loss: 0.428028; batch adversarial loss: 0.519700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.294120; batch adversarial loss: 0.536390\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326062; batch adversarial loss: 0.525707\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398293; batch adversarial loss: 0.543754\n",
      "epoch 173; iter: 0; batch classifier loss: 0.393909; batch adversarial loss: 0.581346\n",
      "epoch 174; iter: 0; batch classifier loss: 0.409640; batch adversarial loss: 0.563006\n",
      "epoch 175; iter: 0; batch classifier loss: 0.408664; batch adversarial loss: 0.588275\n",
      "epoch 176; iter: 0; batch classifier loss: 0.405449; batch adversarial loss: 0.435895\n",
      "epoch 177; iter: 0; batch classifier loss: 0.382758; batch adversarial loss: 0.543920\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361575; batch adversarial loss: 0.572119\n",
      "epoch 179; iter: 0; batch classifier loss: 0.328943; batch adversarial loss: 0.581692\n",
      "epoch 180; iter: 0; batch classifier loss: 0.420381; batch adversarial loss: 0.616764\n",
      "epoch 181; iter: 0; batch classifier loss: 0.403004; batch adversarial loss: 0.589765\n",
      "epoch 182; iter: 0; batch classifier loss: 0.385149; batch adversarial loss: 0.617072\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429983; batch adversarial loss: 0.553746\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362384; batch adversarial loss: 0.508652\n",
      "epoch 185; iter: 0; batch classifier loss: 0.298742; batch adversarial loss: 0.470743\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309993; batch adversarial loss: 0.571725\n",
      "epoch 187; iter: 0; batch classifier loss: 0.408932; batch adversarial loss: 0.508151\n",
      "epoch 188; iter: 0; batch classifier loss: 0.420341; batch adversarial loss: 0.589333\n",
      "epoch 189; iter: 0; batch classifier loss: 0.396176; batch adversarial loss: 0.533916\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327098; batch adversarial loss: 0.544227\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372533; batch adversarial loss: 0.561926\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345733; batch adversarial loss: 0.572526\n",
      "epoch 193; iter: 0; batch classifier loss: 0.366816; batch adversarial loss: 0.491960\n",
      "epoch 194; iter: 0; batch classifier loss: 0.335322; batch adversarial loss: 0.545448\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325924; batch adversarial loss: 0.500343\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315093; batch adversarial loss: 0.571838\n",
      "epoch 197; iter: 0; batch classifier loss: 0.378010; batch adversarial loss: 0.669883\n",
      "epoch 198; iter: 0; batch classifier loss: 0.481324; batch adversarial loss: 0.598624\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329820; batch adversarial loss: 0.572061\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748495; batch adversarial loss: 0.628912\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618361; batch adversarial loss: 0.681017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572140; batch adversarial loss: 0.638844\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591419; batch adversarial loss: 0.676865\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557359; batch adversarial loss: 0.627487\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552726; batch adversarial loss: 0.599919\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548157; batch adversarial loss: 0.544757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539400; batch adversarial loss: 0.586693\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541969; batch adversarial loss: 0.603765\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523121; batch adversarial loss: 0.600839\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481995; batch adversarial loss: 0.600287\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544425; batch adversarial loss: 0.555265\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496627; batch adversarial loss: 0.545934\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502660; batch adversarial loss: 0.583441\n",
      "epoch 14; iter: 0; batch classifier loss: 0.468022; batch adversarial loss: 0.479000\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498116; batch adversarial loss: 0.570292\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504923; batch adversarial loss: 0.544577\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474259; batch adversarial loss: 0.577247\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466682; batch adversarial loss: 0.548238\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478922; batch adversarial loss: 0.485849\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472286; batch adversarial loss: 0.587862\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469874; batch adversarial loss: 0.583071\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495315; batch adversarial loss: 0.604618\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457342; batch adversarial loss: 0.609442\n",
      "epoch 24; iter: 0; batch classifier loss: 0.520330; batch adversarial loss: 0.638045\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439984; batch adversarial loss: 0.527863\n",
      "epoch 26; iter: 0; batch classifier loss: 0.547020; batch adversarial loss: 0.576848\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472237; batch adversarial loss: 0.569745\n",
      "epoch 28; iter: 0; batch classifier loss: 0.525738; batch adversarial loss: 0.533975\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461436; batch adversarial loss: 0.633691\n",
      "epoch 30; iter: 0; batch classifier loss: 0.507404; batch adversarial loss: 0.554525\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442491; batch adversarial loss: 0.494272\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509998; batch adversarial loss: 0.580697\n",
      "epoch 33; iter: 0; batch classifier loss: 0.466884; batch adversarial loss: 0.556034\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484451; batch adversarial loss: 0.486136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.538461; batch adversarial loss: 0.534758\n",
      "epoch 36; iter: 0; batch classifier loss: 0.409758; batch adversarial loss: 0.537058\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454453; batch adversarial loss: 0.534749\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440489; batch adversarial loss: 0.527808\n",
      "epoch 39; iter: 0; batch classifier loss: 0.512063; batch adversarial loss: 0.535459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471039; batch adversarial loss: 0.561382\n",
      "epoch 41; iter: 0; batch classifier loss: 0.514526; batch adversarial loss: 0.528012\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390714; batch adversarial loss: 0.491834\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441333; batch adversarial loss: 0.606497\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422661; batch adversarial loss: 0.500858\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506536; batch adversarial loss: 0.597327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.499071; batch adversarial loss: 0.579398\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446543; batch adversarial loss: 0.571719\n",
      "epoch 48; iter: 0; batch classifier loss: 0.353901; batch adversarial loss: 0.517884\n",
      "epoch 49; iter: 0; batch classifier loss: 0.364240; batch adversarial loss: 0.482276\n",
      "epoch 50; iter: 0; batch classifier loss: 0.419630; batch adversarial loss: 0.517566\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392304; batch adversarial loss: 0.545134\n",
      "epoch 52; iter: 0; batch classifier loss: 0.402106; batch adversarial loss: 0.563723\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432076; batch adversarial loss: 0.509243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467168; batch adversarial loss: 0.544530\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426037; batch adversarial loss: 0.544913\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436537; batch adversarial loss: 0.553292\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400544; batch adversarial loss: 0.579636\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442980; batch adversarial loss: 0.622997\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385860; batch adversarial loss: 0.465049\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480230; batch adversarial loss: 0.534871\n",
      "epoch 61; iter: 0; batch classifier loss: 0.343441; batch adversarial loss: 0.517966\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391950; batch adversarial loss: 0.571566\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408725; batch adversarial loss: 0.518726\n",
      "epoch 64; iter: 0; batch classifier loss: 0.461527; batch adversarial loss: 0.526827\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362928; batch adversarial loss: 0.526397\n",
      "epoch 66; iter: 0; batch classifier loss: 0.314748; batch adversarial loss: 0.562696\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408710; batch adversarial loss: 0.472189\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432937; batch adversarial loss: 0.499035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.399637; batch adversarial loss: 0.535379\n",
      "epoch 70; iter: 0; batch classifier loss: 0.334273; batch adversarial loss: 0.608154\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410023; batch adversarial loss: 0.517578\n",
      "epoch 72; iter: 0; batch classifier loss: 0.480920; batch adversarial loss: 0.500135\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391391; batch adversarial loss: 0.571861\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394097; batch adversarial loss: 0.535818\n",
      "epoch 75; iter: 0; batch classifier loss: 0.316456; batch adversarial loss: 0.535421\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410880; batch adversarial loss: 0.571187\n",
      "epoch 77; iter: 0; batch classifier loss: 0.377979; batch adversarial loss: 0.509218\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406997; batch adversarial loss: 0.545178\n",
      "epoch 79; iter: 0; batch classifier loss: 0.305056; batch adversarial loss: 0.589275\n",
      "epoch 80; iter: 0; batch classifier loss: 0.405870; batch adversarial loss: 0.580286\n",
      "epoch 81; iter: 0; batch classifier loss: 0.401115; batch adversarial loss: 0.544538\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416145; batch adversarial loss: 0.571489\n",
      "epoch 83; iter: 0; batch classifier loss: 0.449947; batch adversarial loss: 0.490339\n",
      "epoch 84; iter: 0; batch classifier loss: 0.403419; batch adversarial loss: 0.580127\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366917; batch adversarial loss: 0.562171\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358011; batch adversarial loss: 0.463857\n",
      "epoch 87; iter: 0; batch classifier loss: 0.436898; batch adversarial loss: 0.526597\n",
      "epoch 88; iter: 0; batch classifier loss: 0.337172; batch adversarial loss: 0.535412\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415039; batch adversarial loss: 0.580935\n",
      "epoch 90; iter: 0; batch classifier loss: 0.473737; batch adversarial loss: 0.499767\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395320; batch adversarial loss: 0.535821\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362383; batch adversarial loss: 0.554580\n",
      "epoch 93; iter: 0; batch classifier loss: 0.454520; batch adversarial loss: 0.544140\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425058; batch adversarial loss: 0.607671\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417127; batch adversarial loss: 0.553222\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401100; batch adversarial loss: 0.527188\n",
      "epoch 97; iter: 0; batch classifier loss: 0.367553; batch adversarial loss: 0.482804\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397315; batch adversarial loss: 0.580366\n",
      "epoch 99; iter: 0; batch classifier loss: 0.403863; batch adversarial loss: 0.499606\n",
      "epoch 100; iter: 0; batch classifier loss: 0.316528; batch adversarial loss: 0.499112\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389777; batch adversarial loss: 0.589857\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412234; batch adversarial loss: 0.518330\n",
      "epoch 103; iter: 0; batch classifier loss: 0.442746; batch adversarial loss: 0.598847\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385952; batch adversarial loss: 0.490446\n",
      "epoch 105; iter: 0; batch classifier loss: 0.345173; batch adversarial loss: 0.598389\n",
      "epoch 106; iter: 0; batch classifier loss: 0.445291; batch adversarial loss: 0.527276\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396508; batch adversarial loss: 0.508855\n",
      "epoch 108; iter: 0; batch classifier loss: 0.365015; batch adversarial loss: 0.570992\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410836; batch adversarial loss: 0.580078\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359899; batch adversarial loss: 0.553636\n",
      "epoch 111; iter: 0; batch classifier loss: 0.316758; batch adversarial loss: 0.615636\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410993; batch adversarial loss: 0.562518\n",
      "epoch 113; iter: 0; batch classifier loss: 0.376887; batch adversarial loss: 0.517843\n",
      "epoch 114; iter: 0; batch classifier loss: 0.454688; batch adversarial loss: 0.508281\n",
      "epoch 115; iter: 0; batch classifier loss: 0.314264; batch adversarial loss: 0.553844\n",
      "epoch 116; iter: 0; batch classifier loss: 0.363042; batch adversarial loss: 0.553242\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365653; batch adversarial loss: 0.544545\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333243; batch adversarial loss: 0.562643\n",
      "epoch 119; iter: 0; batch classifier loss: 0.331090; batch adversarial loss: 0.536354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375114; batch adversarial loss: 0.570210\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370336; batch adversarial loss: 0.598281\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372134; batch adversarial loss: 0.562468\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344116; batch adversarial loss: 0.544027\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340205; batch adversarial loss: 0.544776\n",
      "epoch 125; iter: 0; batch classifier loss: 0.368900; batch adversarial loss: 0.597799\n",
      "epoch 126; iter: 0; batch classifier loss: 0.317715; batch adversarial loss: 0.535236\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349616; batch adversarial loss: 0.499450\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411913; batch adversarial loss: 0.535508\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360171; batch adversarial loss: 0.517752\n",
      "epoch 130; iter: 0; batch classifier loss: 0.417098; batch adversarial loss: 0.518427\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340452; batch adversarial loss: 0.589779\n",
      "epoch 132; iter: 0; batch classifier loss: 0.408011; batch adversarial loss: 0.490657\n",
      "epoch 133; iter: 0; batch classifier loss: 0.410870; batch adversarial loss: 0.552719\n",
      "epoch 134; iter: 0; batch classifier loss: 0.409149; batch adversarial loss: 0.445265\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376289; batch adversarial loss: 0.472718\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377766; batch adversarial loss: 0.543059\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347768; batch adversarial loss: 0.473722\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380704; batch adversarial loss: 0.536278\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356698; batch adversarial loss: 0.589209\n",
      "epoch 140; iter: 0; batch classifier loss: 0.409946; batch adversarial loss: 0.580095\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338341; batch adversarial loss: 0.590068\n",
      "epoch 142; iter: 0; batch classifier loss: 0.376118; batch adversarial loss: 0.579896\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352863; batch adversarial loss: 0.580998\n",
      "epoch 144; iter: 0; batch classifier loss: 0.309304; batch adversarial loss: 0.625928\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358725; batch adversarial loss: 0.588346\n",
      "epoch 146; iter: 0; batch classifier loss: 0.327443; batch adversarial loss: 0.508929\n",
      "epoch 147; iter: 0; batch classifier loss: 0.385289; batch adversarial loss: 0.535543\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371275; batch adversarial loss: 0.597556\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337728; batch adversarial loss: 0.580096\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364769; batch adversarial loss: 0.526655\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382314; batch adversarial loss: 0.553963\n",
      "epoch 152; iter: 0; batch classifier loss: 0.274812; batch adversarial loss: 0.599128\n",
      "epoch 153; iter: 0; batch classifier loss: 0.462615; batch adversarial loss: 0.499834\n",
      "epoch 154; iter: 0; batch classifier loss: 0.283734; batch adversarial loss: 0.553200\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342809; batch adversarial loss: 0.509162\n",
      "epoch 156; iter: 0; batch classifier loss: 0.408611; batch adversarial loss: 0.572673\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371109; batch adversarial loss: 0.544618\n",
      "epoch 158; iter: 0; batch classifier loss: 0.304871; batch adversarial loss: 0.552995\n",
      "epoch 159; iter: 0; batch classifier loss: 0.310610; batch adversarial loss: 0.517608\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321978; batch adversarial loss: 0.572744\n",
      "epoch 161; iter: 0; batch classifier loss: 0.321483; batch adversarial loss: 0.499018\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401502; batch adversarial loss: 0.607423\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355605; batch adversarial loss: 0.589004\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350953; batch adversarial loss: 0.571350\n",
      "epoch 165; iter: 0; batch classifier loss: 0.328478; batch adversarial loss: 0.481754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.296966; batch adversarial loss: 0.615312\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360598; batch adversarial loss: 0.580002\n",
      "epoch 168; iter: 0; batch classifier loss: 0.448926; batch adversarial loss: 0.553026\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342448; batch adversarial loss: 0.552653\n",
      "epoch 170; iter: 0; batch classifier loss: 0.317308; batch adversarial loss: 0.571323\n",
      "epoch 171; iter: 0; batch classifier loss: 0.376429; batch adversarial loss: 0.544065\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331362; batch adversarial loss: 0.580348\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344048; batch adversarial loss: 0.562651\n",
      "epoch 174; iter: 0; batch classifier loss: 0.354226; batch adversarial loss: 0.580447\n",
      "epoch 175; iter: 0; batch classifier loss: 0.397640; batch adversarial loss: 0.536000\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367633; batch adversarial loss: 0.589157\n",
      "epoch 177; iter: 0; batch classifier loss: 0.359750; batch adversarial loss: 0.500082\n",
      "epoch 178; iter: 0; batch classifier loss: 0.406517; batch adversarial loss: 0.671274\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350995; batch adversarial loss: 0.589741\n",
      "epoch 180; iter: 0; batch classifier loss: 0.244365; batch adversarial loss: 0.508303\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338376; batch adversarial loss: 0.481426\n",
      "epoch 182; iter: 0; batch classifier loss: 0.358558; batch adversarial loss: 0.588438\n",
      "epoch 183; iter: 0; batch classifier loss: 0.390059; batch adversarial loss: 0.579306\n",
      "epoch 184; iter: 0; batch classifier loss: 0.340619; batch adversarial loss: 0.598754\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303992; batch adversarial loss: 0.616667\n",
      "epoch 186; iter: 0; batch classifier loss: 0.440701; batch adversarial loss: 0.562811\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355161; batch adversarial loss: 0.608522\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383658; batch adversarial loss: 0.580893\n",
      "epoch 189; iter: 0; batch classifier loss: 0.396043; batch adversarial loss: 0.607401\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401965; batch adversarial loss: 0.571138\n",
      "epoch 191; iter: 0; batch classifier loss: 0.315252; batch adversarial loss: 0.536579\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330160; batch adversarial loss: 0.499762\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388742; batch adversarial loss: 0.545059\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322721; batch adversarial loss: 0.499029\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349700; batch adversarial loss: 0.570399\n",
      "epoch 196; iter: 0; batch classifier loss: 0.273876; batch adversarial loss: 0.625001\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393428; batch adversarial loss: 0.492373\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358112; batch adversarial loss: 0.553539\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362109; batch adversarial loss: 0.526930\n",
      "epoch 0; iter: 0; batch classifier loss: 0.742797; batch adversarial loss: 0.925745\n",
      "epoch 1; iter: 0; batch classifier loss: 0.827946; batch adversarial loss: 1.091670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.974725; batch adversarial loss: 1.047467\n",
      "epoch 3; iter: 0; batch classifier loss: 1.085638; batch adversarial loss: 0.968498\n",
      "epoch 4; iter: 0; batch classifier loss: 1.038838; batch adversarial loss: 0.892522\n",
      "epoch 5; iter: 0; batch classifier loss: 1.249523; batch adversarial loss: 0.826814\n",
      "epoch 6; iter: 0; batch classifier loss: 1.074045; batch adversarial loss: 0.756838\n",
      "epoch 7; iter: 0; batch classifier loss: 0.917516; batch adversarial loss: 0.718145\n",
      "epoch 8; iter: 0; batch classifier loss: 0.935499; batch adversarial loss: 0.694627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.916369; batch adversarial loss: 0.654608\n",
      "epoch 10; iter: 0; batch classifier loss: 0.827463; batch adversarial loss: 0.612987\n",
      "epoch 11; iter: 0; batch classifier loss: 0.623366; batch adversarial loss: 0.546195\n",
      "epoch 12; iter: 0; batch classifier loss: 0.607475; batch adversarial loss: 0.616355\n",
      "epoch 13; iter: 0; batch classifier loss: 0.615053; batch adversarial loss: 0.551644\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566452; batch adversarial loss: 0.511117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543630; batch adversarial loss: 0.511052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.612754; batch adversarial loss: 0.603838\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533328; batch adversarial loss: 0.528385\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542713; batch adversarial loss: 0.515504\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518027; batch adversarial loss: 0.564008\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500655; batch adversarial loss: 0.524876\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533484; batch adversarial loss: 0.538916\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549489; batch adversarial loss: 0.488585\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521104; batch adversarial loss: 0.587106\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514067; batch adversarial loss: 0.571942\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512656; batch adversarial loss: 0.517988\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508267; batch adversarial loss: 0.509990\n",
      "epoch 27; iter: 0; batch classifier loss: 0.515671; batch adversarial loss: 0.528033\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483993; batch adversarial loss: 0.561218\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508626; batch adversarial loss: 0.573113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463860; batch adversarial loss: 0.548524\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421456; batch adversarial loss: 0.534619\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477224; batch adversarial loss: 0.580872\n",
      "epoch 33; iter: 0; batch classifier loss: 0.517106; batch adversarial loss: 0.563287\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485353; batch adversarial loss: 0.531141\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416741; batch adversarial loss: 0.555870\n",
      "epoch 36; iter: 0; batch classifier loss: 0.518040; batch adversarial loss: 0.568420\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483491; batch adversarial loss: 0.551087\n",
      "epoch 38; iter: 0; batch classifier loss: 0.430609; batch adversarial loss: 0.608727\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478514; batch adversarial loss: 0.610057\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429891; batch adversarial loss: 0.543156\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474174; batch adversarial loss: 0.514339\n",
      "epoch 42; iter: 0; batch classifier loss: 0.522647; batch adversarial loss: 0.547934\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482607; batch adversarial loss: 0.537078\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437110; batch adversarial loss: 0.531846\n",
      "epoch 45; iter: 0; batch classifier loss: 0.511294; batch adversarial loss: 0.577448\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448522; batch adversarial loss: 0.598142\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428077; batch adversarial loss: 0.581882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470587; batch adversarial loss: 0.546500\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406650; batch adversarial loss: 0.572234\n",
      "epoch 50; iter: 0; batch classifier loss: 0.492950; batch adversarial loss: 0.548543\n",
      "epoch 51; iter: 0; batch classifier loss: 0.478822; batch adversarial loss: 0.579750\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458383; batch adversarial loss: 0.522237\n",
      "epoch 53; iter: 0; batch classifier loss: 0.489452; batch adversarial loss: 0.572241\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398561; batch adversarial loss: 0.537042\n",
      "epoch 55; iter: 0; batch classifier loss: 0.395940; batch adversarial loss: 0.570951\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395110; batch adversarial loss: 0.553433\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392955; batch adversarial loss: 0.552029\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411847; batch adversarial loss: 0.535598\n",
      "epoch 59; iter: 0; batch classifier loss: 0.470474; batch adversarial loss: 0.501613\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481393; batch adversarial loss: 0.586195\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408935; batch adversarial loss: 0.572994\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421050; batch adversarial loss: 0.516456\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381450; batch adversarial loss: 0.570028\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424339; batch adversarial loss: 0.551618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.421367; batch adversarial loss: 0.536485\n",
      "epoch 66; iter: 0; batch classifier loss: 0.363927; batch adversarial loss: 0.579859\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388347; batch adversarial loss: 0.585585\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342114; batch adversarial loss: 0.544792\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382114; batch adversarial loss: 0.611992\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427368; batch adversarial loss: 0.560593\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399486; batch adversarial loss: 0.595401\n",
      "epoch 72; iter: 0; batch classifier loss: 0.423524; batch adversarial loss: 0.580748\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366066; batch adversarial loss: 0.545040\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382926; batch adversarial loss: 0.562537\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405309; batch adversarial loss: 0.560928\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391851; batch adversarial loss: 0.518269\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395182; batch adversarial loss: 0.499566\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417136; batch adversarial loss: 0.499712\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392717; batch adversarial loss: 0.490723\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430212; batch adversarial loss: 0.535447\n",
      "epoch 81; iter: 0; batch classifier loss: 0.380047; batch adversarial loss: 0.588051\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409288; batch adversarial loss: 0.578268\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391926; batch adversarial loss: 0.612129\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388673; batch adversarial loss: 0.551898\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410210; batch adversarial loss: 0.526276\n",
      "epoch 86; iter: 0; batch classifier loss: 0.460649; batch adversarial loss: 0.475444\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364556; batch adversarial loss: 0.570668\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428818; batch adversarial loss: 0.565748\n",
      "epoch 89; iter: 0; batch classifier loss: 0.417635; batch adversarial loss: 0.535629\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344028; batch adversarial loss: 0.534184\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385937; batch adversarial loss: 0.455380\n",
      "epoch 92; iter: 0; batch classifier loss: 0.419789; batch adversarial loss: 0.563125\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393716; batch adversarial loss: 0.572208\n",
      "epoch 94; iter: 0; batch classifier loss: 0.398218; batch adversarial loss: 0.502100\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359656; batch adversarial loss: 0.534163\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398007; batch adversarial loss: 0.544238\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379304; batch adversarial loss: 0.545528\n",
      "epoch 98; iter: 0; batch classifier loss: 0.448124; batch adversarial loss: 0.560520\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377339; batch adversarial loss: 0.551007\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410739; batch adversarial loss: 0.530420\n",
      "epoch 101; iter: 0; batch classifier loss: 0.373213; batch adversarial loss: 0.553045\n",
      "epoch 102; iter: 0; batch classifier loss: 0.337266; batch adversarial loss: 0.525089\n",
      "epoch 103; iter: 0; batch classifier loss: 0.448391; batch adversarial loss: 0.614015\n",
      "epoch 104; iter: 0; batch classifier loss: 0.314573; batch adversarial loss: 0.565485\n",
      "epoch 105; iter: 0; batch classifier loss: 0.374786; batch adversarial loss: 0.622206\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369850; batch adversarial loss: 0.544863\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346365; batch adversarial loss: 0.546784\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371364; batch adversarial loss: 0.498864\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423500; batch adversarial loss: 0.582208\n",
      "epoch 110; iter: 0; batch classifier loss: 0.374963; batch adversarial loss: 0.492573\n",
      "epoch 111; iter: 0; batch classifier loss: 0.404347; batch adversarial loss: 0.652739\n",
      "epoch 112; iter: 0; batch classifier loss: 0.317243; batch adversarial loss: 0.561488\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362179; batch adversarial loss: 0.481869\n",
      "epoch 114; iter: 0; batch classifier loss: 0.282785; batch adversarial loss: 0.572452\n",
      "epoch 115; iter: 0; batch classifier loss: 0.318711; batch adversarial loss: 0.609912\n",
      "epoch 116; iter: 0; batch classifier loss: 0.326712; batch adversarial loss: 0.567143\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342278; batch adversarial loss: 0.526496\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361008; batch adversarial loss: 0.486440\n",
      "epoch 119; iter: 0; batch classifier loss: 0.325976; batch adversarial loss: 0.647079\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366091; batch adversarial loss: 0.564654\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360643; batch adversarial loss: 0.551646\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373024; batch adversarial loss: 0.596132\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350981; batch adversarial loss: 0.524432\n",
      "epoch 124; iter: 0; batch classifier loss: 0.358122; batch adversarial loss: 0.516492\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386284; batch adversarial loss: 0.541857\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363380; batch adversarial loss: 0.580246\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329141; batch adversarial loss: 0.530049\n",
      "epoch 128; iter: 0; batch classifier loss: 0.334996; batch adversarial loss: 0.526138\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324927; batch adversarial loss: 0.565998\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359510; batch adversarial loss: 0.545123\n",
      "epoch 131; iter: 0; batch classifier loss: 0.376580; batch adversarial loss: 0.576430\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320839; batch adversarial loss: 0.546682\n",
      "epoch 133; iter: 0; batch classifier loss: 0.345954; batch adversarial loss: 0.667499\n",
      "epoch 134; iter: 0; batch classifier loss: 0.430181; batch adversarial loss: 0.504492\n",
      "epoch 135; iter: 0; batch classifier loss: 0.425995; batch adversarial loss: 0.561663\n",
      "epoch 136; iter: 0; batch classifier loss: 0.305861; batch adversarial loss: 0.525190\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413638; batch adversarial loss: 0.594706\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322270; batch adversarial loss: 0.601668\n",
      "epoch 139; iter: 0; batch classifier loss: 0.362387; batch adversarial loss: 0.490772\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387120; batch adversarial loss: 0.491073\n",
      "epoch 141; iter: 0; batch classifier loss: 0.287799; batch adversarial loss: 0.513802\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324700; batch adversarial loss: 0.583386\n",
      "epoch 143; iter: 0; batch classifier loss: 0.445857; batch adversarial loss: 0.520350\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339837; batch adversarial loss: 0.560257\n",
      "epoch 145; iter: 0; batch classifier loss: 0.315112; batch adversarial loss: 0.621629\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394941; batch adversarial loss: 0.559995\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403456; batch adversarial loss: 0.545650\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375068; batch adversarial loss: 0.582244\n",
      "epoch 149; iter: 0; batch classifier loss: 0.277172; batch adversarial loss: 0.554727\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317767; batch adversarial loss: 0.539039\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356359; batch adversarial loss: 0.595712\n",
      "epoch 152; iter: 0; batch classifier loss: 0.367404; batch adversarial loss: 0.657351\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321369; batch adversarial loss: 0.562344\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316589; batch adversarial loss: 0.645059\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360390; batch adversarial loss: 0.610096\n",
      "epoch 156; iter: 0; batch classifier loss: 0.420871; batch adversarial loss: 0.516794\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369823; batch adversarial loss: 0.509508\n",
      "epoch 158; iter: 0; batch classifier loss: 0.300510; batch adversarial loss: 0.587582\n",
      "epoch 159; iter: 0; batch classifier loss: 0.359666; batch adversarial loss: 0.605088\n",
      "epoch 160; iter: 0; batch classifier loss: 0.362526; batch adversarial loss: 0.586129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.300981; batch adversarial loss: 0.572365\n",
      "epoch 162; iter: 0; batch classifier loss: 0.309702; batch adversarial loss: 0.615950\n",
      "epoch 163; iter: 0; batch classifier loss: 0.283779; batch adversarial loss: 0.522520\n",
      "epoch 164; iter: 0; batch classifier loss: 0.294922; batch adversarial loss: 0.460829\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319900; batch adversarial loss: 0.549912\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319052; batch adversarial loss: 0.594118\n",
      "epoch 167; iter: 0; batch classifier loss: 0.305754; batch adversarial loss: 0.535083\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370806; batch adversarial loss: 0.544041\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362532; batch adversarial loss: 0.610035\n",
      "epoch 170; iter: 0; batch classifier loss: 0.392330; batch adversarial loss: 0.570122\n",
      "epoch 171; iter: 0; batch classifier loss: 0.300169; batch adversarial loss: 0.587193\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364400; batch adversarial loss: 0.614707\n",
      "epoch 173; iter: 0; batch classifier loss: 0.304292; batch adversarial loss: 0.648692\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302820; batch adversarial loss: 0.560092\n",
      "epoch 175; iter: 0; batch classifier loss: 0.424619; batch adversarial loss: 0.535377\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320748; batch adversarial loss: 0.523945\n",
      "epoch 177; iter: 0; batch classifier loss: 0.287245; batch adversarial loss: 0.554946\n",
      "epoch 178; iter: 0; batch classifier loss: 0.299606; batch adversarial loss: 0.497354\n",
      "epoch 179; iter: 0; batch classifier loss: 0.299938; batch adversarial loss: 0.471417\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351041; batch adversarial loss: 0.614406\n",
      "epoch 181; iter: 0; batch classifier loss: 0.355748; batch adversarial loss: 0.523369\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320064; batch adversarial loss: 0.535691\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324941; batch adversarial loss: 0.582769\n",
      "epoch 184; iter: 0; batch classifier loss: 0.311851; batch adversarial loss: 0.671076\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357031; batch adversarial loss: 0.440583\n",
      "epoch 186; iter: 0; batch classifier loss: 0.305501; batch adversarial loss: 0.570335\n",
      "epoch 187; iter: 0; batch classifier loss: 0.298783; batch adversarial loss: 0.516888\n",
      "epoch 188; iter: 0; batch classifier loss: 0.275040; batch adversarial loss: 0.508560\n",
      "epoch 189; iter: 0; batch classifier loss: 0.399324; batch adversarial loss: 0.493699\n",
      "epoch 190; iter: 0; batch classifier loss: 0.300411; batch adversarial loss: 0.535845\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374768; batch adversarial loss: 0.555049\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404978; batch adversarial loss: 0.582911\n",
      "epoch 193; iter: 0; batch classifier loss: 0.285787; batch adversarial loss: 0.575186\n",
      "epoch 194; iter: 0; batch classifier loss: 0.451447; batch adversarial loss: 0.466333\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328935; batch adversarial loss: 0.471180\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373886; batch adversarial loss: 0.562946\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324955; batch adversarial loss: 0.610073\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362674; batch adversarial loss: 0.546072\n",
      "epoch 199; iter: 0; batch classifier loss: 0.341025; batch adversarial loss: 0.591118\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667821; batch adversarial loss: 0.608921\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643186; batch adversarial loss: 0.662941\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580750; batch adversarial loss: 0.646743\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576842; batch adversarial loss: 0.671007\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610435; batch adversarial loss: 0.632207\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549099; batch adversarial loss: 0.617337\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527597; batch adversarial loss: 0.636957\n",
      "epoch 7; iter: 0; batch classifier loss: 0.647018; batch adversarial loss: 0.652886\n",
      "epoch 8; iter: 0; batch classifier loss: 0.608912; batch adversarial loss: 0.634348\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528762; batch adversarial loss: 0.587371\n",
      "epoch 10; iter: 0; batch classifier loss: 0.453078; batch adversarial loss: 0.619249\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564193; batch adversarial loss: 0.602619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567328; batch adversarial loss: 0.572330\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556435; batch adversarial loss: 0.614525\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558219; batch adversarial loss: 0.486703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528424; batch adversarial loss: 0.524311\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526629; batch adversarial loss: 0.562307\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494665; batch adversarial loss: 0.548249\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486745; batch adversarial loss: 0.553990\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527741; batch adversarial loss: 0.598863\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468145; batch adversarial loss: 0.668778\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424404; batch adversarial loss: 0.559137\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472922; batch adversarial loss: 0.479400\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450780; batch adversarial loss: 0.569464\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509248; batch adversarial loss: 0.575463\n",
      "epoch 25; iter: 0; batch classifier loss: 0.425073; batch adversarial loss: 0.504223\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504677; batch adversarial loss: 0.523711\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510776; batch adversarial loss: 0.546349\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488449; batch adversarial loss: 0.635046\n",
      "epoch 29; iter: 0; batch classifier loss: 0.516877; batch adversarial loss: 0.443948\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457546; batch adversarial loss: 0.489756\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484639; batch adversarial loss: 0.524750\n",
      "epoch 32; iter: 0; batch classifier loss: 0.387623; batch adversarial loss: 0.501572\n",
      "epoch 33; iter: 0; batch classifier loss: 0.411431; batch adversarial loss: 0.628504\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457074; batch adversarial loss: 0.554431\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478692; batch adversarial loss: 0.521641\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452669; batch adversarial loss: 0.541583\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444794; batch adversarial loss: 0.557408\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496954; batch adversarial loss: 0.535855\n",
      "epoch 39; iter: 0; batch classifier loss: 0.488746; batch adversarial loss: 0.564515\n",
      "epoch 40; iter: 0; batch classifier loss: 0.387918; batch adversarial loss: 0.553620\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397367; batch adversarial loss: 0.556931\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462347; batch adversarial loss: 0.542076\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408008; batch adversarial loss: 0.555222\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488399; batch adversarial loss: 0.563846\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448291; batch adversarial loss: 0.546305\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425934; batch adversarial loss: 0.505933\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415168; batch adversarial loss: 0.553839\n",
      "epoch 48; iter: 0; batch classifier loss: 0.490216; batch adversarial loss: 0.527853\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437574; batch adversarial loss: 0.542122\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453745; batch adversarial loss: 0.471279\n",
      "epoch 51; iter: 0; batch classifier loss: 0.467976; batch adversarial loss: 0.445129\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434617; batch adversarial loss: 0.527259\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446608; batch adversarial loss: 0.553006\n",
      "epoch 54; iter: 0; batch classifier loss: 0.340022; batch adversarial loss: 0.535838\n",
      "epoch 55; iter: 0; batch classifier loss: 0.418109; batch adversarial loss: 0.554210\n",
      "epoch 56; iter: 0; batch classifier loss: 0.362188; batch adversarial loss: 0.605657\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398220; batch adversarial loss: 0.592462\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388491; batch adversarial loss: 0.521467\n",
      "epoch 59; iter: 0; batch classifier loss: 0.472901; batch adversarial loss: 0.553692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.413024; batch adversarial loss: 0.583244\n",
      "epoch 61; iter: 0; batch classifier loss: 0.401918; batch adversarial loss: 0.545501\n",
      "epoch 62; iter: 0; batch classifier loss: 0.520837; batch adversarial loss: 0.500507\n",
      "epoch 63; iter: 0; batch classifier loss: 0.455044; batch adversarial loss: 0.582271\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385765; batch adversarial loss: 0.515982\n",
      "epoch 65; iter: 0; batch classifier loss: 0.405620; batch adversarial loss: 0.626106\n",
      "epoch 66; iter: 0; batch classifier loss: 0.467229; batch adversarial loss: 0.527200\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399889; batch adversarial loss: 0.516971\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397512; batch adversarial loss: 0.498638\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436459; batch adversarial loss: 0.516927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380882; batch adversarial loss: 0.517414\n",
      "epoch 71; iter: 0; batch classifier loss: 0.361676; batch adversarial loss: 0.508604\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391569; batch adversarial loss: 0.480426\n",
      "epoch 73; iter: 0; batch classifier loss: 0.477644; batch adversarial loss: 0.469216\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378650; batch adversarial loss: 0.560437\n",
      "epoch 75; iter: 0; batch classifier loss: 0.449219; batch adversarial loss: 0.518013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461424; batch adversarial loss: 0.538948\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398688; batch adversarial loss: 0.554589\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354055; batch adversarial loss: 0.524287\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440007; batch adversarial loss: 0.562960\n",
      "epoch 80; iter: 0; batch classifier loss: 0.336127; batch adversarial loss: 0.553650\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404410; batch adversarial loss: 0.529327\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377754; batch adversarial loss: 0.470698\n",
      "epoch 83; iter: 0; batch classifier loss: 0.357544; batch adversarial loss: 0.562489\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368331; batch adversarial loss: 0.666209\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385613; batch adversarial loss: 0.485119\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387132; batch adversarial loss: 0.432536\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391531; batch adversarial loss: 0.626158\n",
      "epoch 88; iter: 0; batch classifier loss: 0.480705; batch adversarial loss: 0.559708\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386898; batch adversarial loss: 0.564390\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383088; batch adversarial loss: 0.527595\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421323; batch adversarial loss: 0.594593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393637; batch adversarial loss: 0.523218\n",
      "epoch 93; iter: 0; batch classifier loss: 0.313066; batch adversarial loss: 0.632806\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364287; batch adversarial loss: 0.492300\n",
      "epoch 95; iter: 0; batch classifier loss: 0.386737; batch adversarial loss: 0.532757\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422423; batch adversarial loss: 0.511662\n",
      "epoch 97; iter: 0; batch classifier loss: 0.450905; batch adversarial loss: 0.565365\n",
      "epoch 98; iter: 0; batch classifier loss: 0.457600; batch adversarial loss: 0.588445\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412167; batch adversarial loss: 0.526218\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406467; batch adversarial loss: 0.580301\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387521; batch adversarial loss: 0.545746\n",
      "epoch 102; iter: 0; batch classifier loss: 0.412384; batch adversarial loss: 0.561879\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409081; batch adversarial loss: 0.481402\n",
      "epoch 104; iter: 0; batch classifier loss: 0.345902; batch adversarial loss: 0.509127\n",
      "epoch 105; iter: 0; batch classifier loss: 0.419497; batch adversarial loss: 0.579203\n",
      "epoch 106; iter: 0; batch classifier loss: 0.423821; batch adversarial loss: 0.563043\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421031; batch adversarial loss: 0.589049\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334550; batch adversarial loss: 0.490337\n",
      "epoch 109; iter: 0; batch classifier loss: 0.451657; batch adversarial loss: 0.545061\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339107; batch adversarial loss: 0.535583\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416731; batch adversarial loss: 0.535695\n",
      "epoch 112; iter: 0; batch classifier loss: 0.319346; batch adversarial loss: 0.579980\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368955; batch adversarial loss: 0.570516\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377060; batch adversarial loss: 0.617977\n",
      "epoch 115; iter: 0; batch classifier loss: 0.369242; batch adversarial loss: 0.598165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.337436; batch adversarial loss: 0.580595\n",
      "epoch 117; iter: 0; batch classifier loss: 0.409923; batch adversarial loss: 0.517178\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392116; batch adversarial loss: 0.572245\n",
      "epoch 119; iter: 0; batch classifier loss: 0.497586; batch adversarial loss: 0.563763\n",
      "epoch 120; iter: 0; batch classifier loss: 0.457701; batch adversarial loss: 0.526939\n",
      "epoch 121; iter: 0; batch classifier loss: 0.459297; batch adversarial loss: 0.463254\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421762; batch adversarial loss: 0.590927\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378626; batch adversarial loss: 0.526927\n",
      "epoch 124; iter: 0; batch classifier loss: 0.409985; batch adversarial loss: 0.571381\n",
      "epoch 125; iter: 0; batch classifier loss: 0.347615; batch adversarial loss: 0.500186\n",
      "epoch 126; iter: 0; batch classifier loss: 0.433352; batch adversarial loss: 0.516682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341856; batch adversarial loss: 0.628229\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344184; batch adversarial loss: 0.526930\n",
      "epoch 129; iter: 0; batch classifier loss: 0.415500; batch adversarial loss: 0.591260\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391343; batch adversarial loss: 0.553681\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400856; batch adversarial loss: 0.598704\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343675; batch adversarial loss: 0.517741\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376843; batch adversarial loss: 0.544115\n",
      "epoch 134; iter: 0; batch classifier loss: 0.412384; batch adversarial loss: 0.526026\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395479; batch adversarial loss: 0.507721\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368200; batch adversarial loss: 0.499979\n",
      "epoch 137; iter: 0; batch classifier loss: 0.311675; batch adversarial loss: 0.589799\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360694; batch adversarial loss: 0.497505\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344507; batch adversarial loss: 0.590748\n",
      "epoch 140; iter: 0; batch classifier loss: 0.336250; batch adversarial loss: 0.542360\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349041; batch adversarial loss: 0.481221\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351346; batch adversarial loss: 0.535575\n",
      "epoch 143; iter: 0; batch classifier loss: 0.474187; batch adversarial loss: 0.598100\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382033; batch adversarial loss: 0.443760\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407875; batch adversarial loss: 0.562971\n",
      "epoch 146; iter: 0; batch classifier loss: 0.370270; batch adversarial loss: 0.608379\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408710; batch adversarial loss: 0.544968\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358490; batch adversarial loss: 0.588739\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379117; batch adversarial loss: 0.516652\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340921; batch adversarial loss: 0.526693\n",
      "epoch 151; iter: 0; batch classifier loss: 0.298130; batch adversarial loss: 0.607936\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383613; batch adversarial loss: 0.525962\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370046; batch adversarial loss: 0.526269\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379983; batch adversarial loss: 0.498418\n",
      "epoch 155; iter: 0; batch classifier loss: 0.435404; batch adversarial loss: 0.635319\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372287; batch adversarial loss: 0.544559\n",
      "epoch 157; iter: 0; batch classifier loss: 0.359285; batch adversarial loss: 0.580186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.416667; batch adversarial loss: 0.599432\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366244; batch adversarial loss: 0.490463\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384684; batch adversarial loss: 0.663642\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401444; batch adversarial loss: 0.544390\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286395; batch adversarial loss: 0.525618\n",
      "epoch 163; iter: 0; batch classifier loss: 0.398285; batch adversarial loss: 0.581886\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339381; batch adversarial loss: 0.544971\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388166; batch adversarial loss: 0.543709\n",
      "epoch 166; iter: 0; batch classifier loss: 0.313054; batch adversarial loss: 0.442620\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319183; batch adversarial loss: 0.590437\n",
      "epoch 168; iter: 0; batch classifier loss: 0.368527; batch adversarial loss: 0.450252\n",
      "epoch 169; iter: 0; batch classifier loss: 0.435618; batch adversarial loss: 0.591350\n",
      "epoch 170; iter: 0; batch classifier loss: 0.253866; batch adversarial loss: 0.607829\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380987; batch adversarial loss: 0.516819\n",
      "epoch 172; iter: 0; batch classifier loss: 0.356840; batch adversarial loss: 0.506972\n",
      "epoch 173; iter: 0; batch classifier loss: 0.421711; batch adversarial loss: 0.618573\n",
      "epoch 174; iter: 0; batch classifier loss: 0.412532; batch adversarial loss: 0.580850\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308138; batch adversarial loss: 0.444621\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408445; batch adversarial loss: 0.506953\n",
      "epoch 177; iter: 0; batch classifier loss: 0.353226; batch adversarial loss: 0.564689\n",
      "epoch 178; iter: 0; batch classifier loss: 0.412349; batch adversarial loss: 0.562841\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337443; batch adversarial loss: 0.634895\n",
      "epoch 180; iter: 0; batch classifier loss: 0.326102; batch adversarial loss: 0.544886\n",
      "epoch 181; iter: 0; batch classifier loss: 0.414818; batch adversarial loss: 0.499246\n",
      "epoch 182; iter: 0; batch classifier loss: 0.290507; batch adversarial loss: 0.527332\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409993; batch adversarial loss: 0.652012\n",
      "epoch 184; iter: 0; batch classifier loss: 0.326248; batch adversarial loss: 0.499372\n",
      "epoch 185; iter: 0; batch classifier loss: 0.424777; batch adversarial loss: 0.571297\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355865; batch adversarial loss: 0.435423\n",
      "epoch 187; iter: 0; batch classifier loss: 0.453113; batch adversarial loss: 0.616674\n",
      "epoch 188; iter: 0; batch classifier loss: 0.295536; batch adversarial loss: 0.553185\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345827; batch adversarial loss: 0.526506\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339041; batch adversarial loss: 0.508487\n",
      "epoch 191; iter: 0; batch classifier loss: 0.361823; batch adversarial loss: 0.552436\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314146; batch adversarial loss: 0.546641\n",
      "epoch 193; iter: 0; batch classifier loss: 0.349598; batch adversarial loss: 0.488373\n",
      "epoch 194; iter: 0; batch classifier loss: 0.370601; batch adversarial loss: 0.480414\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381899; batch adversarial loss: 0.571506\n",
      "epoch 196; iter: 0; batch classifier loss: 0.382621; batch adversarial loss: 0.543717\n",
      "epoch 197; iter: 0; batch classifier loss: 0.421899; batch adversarial loss: 0.517028\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343335; batch adversarial loss: 0.515368\n",
      "epoch 199; iter: 0; batch classifier loss: 0.341371; batch adversarial loss: 0.526375\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747902; batch adversarial loss: 0.526861\n",
      "epoch 1; iter: 0; batch classifier loss: 0.541662; batch adversarial loss: 0.650962\n",
      "epoch 2; iter: 0; batch classifier loss: 0.518387; batch adversarial loss: 0.623416\n",
      "epoch 3; iter: 0; batch classifier loss: 0.684188; batch adversarial loss: 0.663794\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557665; batch adversarial loss: 0.697298\n",
      "epoch 5; iter: 0; batch classifier loss: 0.661500; batch adversarial loss: 0.702817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550482; batch adversarial loss: 0.665371\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548887; batch adversarial loss: 0.643205\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587518; batch adversarial loss: 0.588154\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555629; batch adversarial loss: 0.607977\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509505; batch adversarial loss: 0.592665\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551166; batch adversarial loss: 0.574482\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560313; batch adversarial loss: 0.595994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536829; batch adversarial loss: 0.520668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534129; batch adversarial loss: 0.588403\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530808; batch adversarial loss: 0.589987\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542737; batch adversarial loss: 0.580934\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525015; batch adversarial loss: 0.533158\n",
      "epoch 18; iter: 0; batch classifier loss: 0.575596; batch adversarial loss: 0.552732\n",
      "epoch 19; iter: 0; batch classifier loss: 0.547847; batch adversarial loss: 0.578845\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483836; batch adversarial loss: 0.549625\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452436; batch adversarial loss: 0.571011\n",
      "epoch 22; iter: 0; batch classifier loss: 0.537882; batch adversarial loss: 0.487876\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500046; batch adversarial loss: 0.629787\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463530; batch adversarial loss: 0.460605\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452771; batch adversarial loss: 0.546951\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511325; batch adversarial loss: 0.595747\n",
      "epoch 27; iter: 0; batch classifier loss: 0.522146; batch adversarial loss: 0.571080\n",
      "epoch 28; iter: 0; batch classifier loss: 0.522577; batch adversarial loss: 0.614185\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493529; batch adversarial loss: 0.579440\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502725; batch adversarial loss: 0.537614\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507919; batch adversarial loss: 0.605340\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429330; batch adversarial loss: 0.579641\n",
      "epoch 33; iter: 0; batch classifier loss: 0.378239; batch adversarial loss: 0.562274\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483403; batch adversarial loss: 0.501708\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435518; batch adversarial loss: 0.544880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512176; batch adversarial loss: 0.605505\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467346; batch adversarial loss: 0.527021\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437855; batch adversarial loss: 0.561298\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429651; batch adversarial loss: 0.484247\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443220; batch adversarial loss: 0.500658\n",
      "epoch 41; iter: 0; batch classifier loss: 0.516530; batch adversarial loss: 0.595787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475909; batch adversarial loss: 0.528295\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427904; batch adversarial loss: 0.552880\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396434; batch adversarial loss: 0.588881\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451295; batch adversarial loss: 0.571647\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458098; batch adversarial loss: 0.562799\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377184; batch adversarial loss: 0.491900\n",
      "epoch 48; iter: 0; batch classifier loss: 0.494353; batch adversarial loss: 0.544442\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393492; batch adversarial loss: 0.519172\n",
      "epoch 50; iter: 0; batch classifier loss: 0.484482; batch adversarial loss: 0.512710\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434411; batch adversarial loss: 0.500823\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449883; batch adversarial loss: 0.491518\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461857; batch adversarial loss: 0.553546\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392927; batch adversarial loss: 0.563295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55; iter: 0; batch classifier loss: 0.394530; batch adversarial loss: 0.508552\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411688; batch adversarial loss: 0.598099\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450627; batch adversarial loss: 0.579987\n",
      "epoch 58; iter: 0; batch classifier loss: 0.501425; batch adversarial loss: 0.588047\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421287; batch adversarial loss: 0.553279\n",
      "epoch 60; iter: 0; batch classifier loss: 0.421670; batch adversarial loss: 0.536013\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394245; batch adversarial loss: 0.533530\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426447; batch adversarial loss: 0.629480\n",
      "epoch 63; iter: 0; batch classifier loss: 0.467695; batch adversarial loss: 0.536331\n",
      "epoch 64; iter: 0; batch classifier loss: 0.415626; batch adversarial loss: 0.569989\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448635; batch adversarial loss: 0.517000\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377829; batch adversarial loss: 0.473042\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428222; batch adversarial loss: 0.499862\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418593; batch adversarial loss: 0.544733\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407187; batch adversarial loss: 0.500139\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443996; batch adversarial loss: 0.536988\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449353; batch adversarial loss: 0.544953\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372754; batch adversarial loss: 0.590507\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401438; batch adversarial loss: 0.498937\n",
      "epoch 74; iter: 0; batch classifier loss: 0.473514; batch adversarial loss: 0.553586\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423452; batch adversarial loss: 0.562581\n",
      "epoch 76; iter: 0; batch classifier loss: 0.467468; batch adversarial loss: 0.526370\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421704; batch adversarial loss: 0.562521\n",
      "epoch 78; iter: 0; batch classifier loss: 0.388966; batch adversarial loss: 0.517804\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367254; batch adversarial loss: 0.588213\n",
      "epoch 80; iter: 0; batch classifier loss: 0.434338; batch adversarial loss: 0.509773\n",
      "epoch 81; iter: 0; batch classifier loss: 0.477890; batch adversarial loss: 0.580056\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398225; batch adversarial loss: 0.544986\n",
      "epoch 83; iter: 0; batch classifier loss: 0.390891; batch adversarial loss: 0.544169\n",
      "epoch 84; iter: 0; batch classifier loss: 0.321345; batch adversarial loss: 0.537715\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411990; batch adversarial loss: 0.510005\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390942; batch adversarial loss: 0.624380\n",
      "epoch 87; iter: 0; batch classifier loss: 0.453146; batch adversarial loss: 0.517948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.447771; batch adversarial loss: 0.534043\n",
      "epoch 89; iter: 0; batch classifier loss: 0.464660; batch adversarial loss: 0.585377\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403157; batch adversarial loss: 0.577622\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455295; batch adversarial loss: 0.586644\n",
      "epoch 92; iter: 0; batch classifier loss: 0.452659; batch adversarial loss: 0.595730\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375112; batch adversarial loss: 0.580960\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449319; batch adversarial loss: 0.567873\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446698; batch adversarial loss: 0.564498\n",
      "epoch 96; iter: 0; batch classifier loss: 0.436937; batch adversarial loss: 0.456168\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336824; batch adversarial loss: 0.562362\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387776; batch adversarial loss: 0.590012\n",
      "epoch 99; iter: 0; batch classifier loss: 0.411482; batch adversarial loss: 0.517326\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375715; batch adversarial loss: 0.490936\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363204; batch adversarial loss: 0.517987\n",
      "epoch 102; iter: 0; batch classifier loss: 0.455119; batch adversarial loss: 0.509057\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366764; batch adversarial loss: 0.526785\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428119; batch adversarial loss: 0.589099\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343061; batch adversarial loss: 0.527080\n",
      "epoch 106; iter: 0; batch classifier loss: 0.344787; batch adversarial loss: 0.553043\n",
      "epoch 107; iter: 0; batch classifier loss: 0.415218; batch adversarial loss: 0.562665\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370254; batch adversarial loss: 0.571625\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360938; batch adversarial loss: 0.562317\n",
      "epoch 110; iter: 0; batch classifier loss: 0.335419; batch adversarial loss: 0.586294\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389710; batch adversarial loss: 0.554602\n",
      "epoch 112; iter: 0; batch classifier loss: 0.426328; batch adversarial loss: 0.580317\n",
      "epoch 113; iter: 0; batch classifier loss: 0.423946; batch adversarial loss: 0.602340\n",
      "epoch 114; iter: 0; batch classifier loss: 0.385029; batch adversarial loss: 0.526104\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354472; batch adversarial loss: 0.631367\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438823; batch adversarial loss: 0.551496\n",
      "epoch 117; iter: 0; batch classifier loss: 0.477221; batch adversarial loss: 0.557198\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367152; batch adversarial loss: 0.535086\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431407; batch adversarial loss: 0.499178\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379983; batch adversarial loss: 0.506909\n",
      "epoch 121; iter: 0; batch classifier loss: 0.284378; batch adversarial loss: 0.499910\n",
      "epoch 122; iter: 0; batch classifier loss: 0.432147; batch adversarial loss: 0.562637\n",
      "epoch 123; iter: 0; batch classifier loss: 0.442746; batch adversarial loss: 0.535571\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405212; batch adversarial loss: 0.596284\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370938; batch adversarial loss: 0.537739\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323376; batch adversarial loss: 0.518164\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340965; batch adversarial loss: 0.508290\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346461; batch adversarial loss: 0.535922\n",
      "epoch 129; iter: 0; batch classifier loss: 0.435423; batch adversarial loss: 0.578820\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383849; batch adversarial loss: 0.615651\n",
      "epoch 131; iter: 0; batch classifier loss: 0.397355; batch adversarial loss: 0.552897\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402407; batch adversarial loss: 0.526937\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402515; batch adversarial loss: 0.527079\n",
      "epoch 134; iter: 0; batch classifier loss: 0.450445; batch adversarial loss: 0.552536\n",
      "epoch 135; iter: 0; batch classifier loss: 0.342333; batch adversarial loss: 0.598581\n",
      "epoch 136; iter: 0; batch classifier loss: 0.350886; batch adversarial loss: 0.535097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374977; batch adversarial loss: 0.588970\n",
      "epoch 138; iter: 0; batch classifier loss: 0.424708; batch adversarial loss: 0.526716\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366280; batch adversarial loss: 0.562127\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390097; batch adversarial loss: 0.501857\n",
      "epoch 141; iter: 0; batch classifier loss: 0.389474; batch adversarial loss: 0.562896\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405766; batch adversarial loss: 0.641215\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377954; batch adversarial loss: 0.624015\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366398; batch adversarial loss: 0.563003\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387984; batch adversarial loss: 0.580307\n",
      "epoch 146; iter: 0; batch classifier loss: 0.465291; batch adversarial loss: 0.668821\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390136; batch adversarial loss: 0.553512\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351097; batch adversarial loss: 0.553654\n",
      "epoch 149; iter: 0; batch classifier loss: 0.298030; batch adversarial loss: 0.614296\n",
      "epoch 150; iter: 0; batch classifier loss: 0.328647; batch adversarial loss: 0.536979\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373431; batch adversarial loss: 0.669944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.350588; batch adversarial loss: 0.571080\n",
      "epoch 153; iter: 0; batch classifier loss: 0.436169; batch adversarial loss: 0.545368\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397677; batch adversarial loss: 0.553355\n",
      "epoch 155; iter: 0; batch classifier loss: 0.448997; batch adversarial loss: 0.536875\n",
      "epoch 156; iter: 0; batch classifier loss: 0.388624; batch adversarial loss: 0.588493\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381053; batch adversarial loss: 0.528497\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341100; batch adversarial loss: 0.649920\n",
      "epoch 159; iter: 0; batch classifier loss: 0.351562; batch adversarial loss: 0.561147\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363575; batch adversarial loss: 0.563623\n",
      "epoch 161; iter: 0; batch classifier loss: 0.402974; batch adversarial loss: 0.656358\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369808; batch adversarial loss: 0.624946\n",
      "epoch 163; iter: 0; batch classifier loss: 0.404273; batch adversarial loss: 0.510114\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330878; batch adversarial loss: 0.526367\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399513; batch adversarial loss: 0.553028\n",
      "epoch 166; iter: 0; batch classifier loss: 0.401992; batch adversarial loss: 0.526106\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393314; batch adversarial loss: 0.483869\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401195; batch adversarial loss: 0.598260\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356969; batch adversarial loss: 0.526722\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336685; batch adversarial loss: 0.615179\n",
      "epoch 171; iter: 0; batch classifier loss: 0.260020; batch adversarial loss: 0.596076\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372950; batch adversarial loss: 0.607044\n",
      "epoch 173; iter: 0; batch classifier loss: 0.326117; batch adversarial loss: 0.565114\n",
      "epoch 174; iter: 0; batch classifier loss: 0.288990; batch adversarial loss: 0.527559\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352004; batch adversarial loss: 0.534223\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384547; batch adversarial loss: 0.590055\n",
      "epoch 177; iter: 0; batch classifier loss: 0.423086; batch adversarial loss: 0.560639\n",
      "epoch 178; iter: 0; batch classifier loss: 0.484401; batch adversarial loss: 0.527652\n",
      "epoch 179; iter: 0; batch classifier loss: 0.393921; batch adversarial loss: 0.579434\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375191; batch adversarial loss: 0.510951\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382744; batch adversarial loss: 0.551579\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331828; batch adversarial loss: 0.546560\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372886; batch adversarial loss: 0.561689\n",
      "epoch 184; iter: 0; batch classifier loss: 0.381233; batch adversarial loss: 0.552651\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349461; batch adversarial loss: 0.545065\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356639; batch adversarial loss: 0.606127\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322919; batch adversarial loss: 0.571710\n",
      "epoch 188; iter: 0; batch classifier loss: 0.382032; batch adversarial loss: 0.545353\n",
      "epoch 189; iter: 0; batch classifier loss: 0.435227; batch adversarial loss: 0.538359\n",
      "epoch 190; iter: 0; batch classifier loss: 0.454489; batch adversarial loss: 0.527897\n",
      "epoch 191; iter: 0; batch classifier loss: 0.296866; batch adversarial loss: 0.535640\n",
      "epoch 192; iter: 0; batch classifier loss: 0.379114; batch adversarial loss: 0.526587\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388813; batch adversarial loss: 0.555188\n",
      "epoch 194; iter: 0; batch classifier loss: 0.317676; batch adversarial loss: 0.518797\n",
      "epoch 195; iter: 0; batch classifier loss: 0.349404; batch adversarial loss: 0.533049\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372160; batch adversarial loss: 0.621243\n",
      "epoch 197; iter: 0; batch classifier loss: 0.305187; batch adversarial loss: 0.526236\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338582; batch adversarial loss: 0.562154\n",
      "epoch 199; iter: 0; batch classifier loss: 0.224863; batch adversarial loss: 0.527992\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734893; batch adversarial loss: 0.890136\n",
      "epoch 1; iter: 0; batch classifier loss: 0.653693; batch adversarial loss: 0.949008\n",
      "epoch 2; iter: 0; batch classifier loss: 0.670406; batch adversarial loss: 0.839165\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551194; batch adversarial loss: 0.781978\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496250; batch adversarial loss: 0.761433\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582842; batch adversarial loss: 0.694530\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596240; batch adversarial loss: 0.673042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612890; batch adversarial loss: 0.651323\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545550; batch adversarial loss: 0.649713\n",
      "epoch 9; iter: 0; batch classifier loss: 0.603671; batch adversarial loss: 0.609078\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570742; batch adversarial loss: 0.624654\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540959; batch adversarial loss: 0.649752\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518517; batch adversarial loss: 0.649119\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483038; batch adversarial loss: 0.601589\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518362; batch adversarial loss: 0.617325\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584091; batch adversarial loss: 0.572900\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518485; batch adversarial loss: 0.545242\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541361; batch adversarial loss: 0.575599\n",
      "epoch 18; iter: 0; batch classifier loss: 0.445743; batch adversarial loss: 0.621655\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468772; batch adversarial loss: 0.617633\n",
      "epoch 20; iter: 0; batch classifier loss: 0.499788; batch adversarial loss: 0.605526\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487559; batch adversarial loss: 0.613591\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491326; batch adversarial loss: 0.578896\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511468; batch adversarial loss: 0.615810\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517480; batch adversarial loss: 0.579837\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522342; batch adversarial loss: 0.619384\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506817; batch adversarial loss: 0.587663\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449332; batch adversarial loss: 0.637672\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496518; batch adversarial loss: 0.646523\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475659; batch adversarial loss: 0.532152\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443535; batch adversarial loss: 0.538777\n",
      "epoch 31; iter: 0; batch classifier loss: 0.519954; batch adversarial loss: 0.527296\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430053; batch adversarial loss: 0.540606\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467142; batch adversarial loss: 0.540860\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491979; batch adversarial loss: 0.586718\n",
      "epoch 35; iter: 0; batch classifier loss: 0.536695; batch adversarial loss: 0.556529\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418332; batch adversarial loss: 0.533329\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456012; batch adversarial loss: 0.541825\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452009; batch adversarial loss: 0.503220\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403034; batch adversarial loss: 0.494683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507672; batch adversarial loss: 0.515227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436379; batch adversarial loss: 0.548088\n",
      "epoch 42; iter: 0; batch classifier loss: 0.404706; batch adversarial loss: 0.570174\n",
      "epoch 43; iter: 0; batch classifier loss: 0.577894; batch adversarial loss: 0.575705\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336773; batch adversarial loss: 0.538247\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471585; batch adversarial loss: 0.653342\n",
      "epoch 46; iter: 0; batch classifier loss: 0.506245; batch adversarial loss: 0.590682\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461337; batch adversarial loss: 0.484276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.412716; batch adversarial loss: 0.493120\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415331; batch adversarial loss: 0.536464\n",
      "epoch 50; iter: 0; batch classifier loss: 0.373769; batch adversarial loss: 0.563551\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469884; batch adversarial loss: 0.632068\n",
      "epoch 52; iter: 0; batch classifier loss: 0.518869; batch adversarial loss: 0.579802\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396477; batch adversarial loss: 0.465949\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406377; batch adversarial loss: 0.571366\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431289; batch adversarial loss: 0.491805\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451068; batch adversarial loss: 0.527096\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402665; batch adversarial loss: 0.553655\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419297; batch adversarial loss: 0.492876\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433995; batch adversarial loss: 0.553343\n",
      "epoch 60; iter: 0; batch classifier loss: 0.474273; batch adversarial loss: 0.553097\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395754; batch adversarial loss: 0.694228\n",
      "epoch 62; iter: 0; batch classifier loss: 0.412327; batch adversarial loss: 0.545937\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460375; batch adversarial loss: 0.588759\n",
      "epoch 64; iter: 0; batch classifier loss: 0.444644; batch adversarial loss: 0.669034\n",
      "epoch 65; iter: 0; batch classifier loss: 0.555816; batch adversarial loss: 0.579431\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387972; batch adversarial loss: 0.598231\n",
      "epoch 67; iter: 0; batch classifier loss: 0.433803; batch adversarial loss: 0.545594\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376878; batch adversarial loss: 0.510487\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426562; batch adversarial loss: 0.606121\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403531; batch adversarial loss: 0.525795\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435542; batch adversarial loss: 0.543994\n",
      "epoch 72; iter: 0; batch classifier loss: 0.348481; batch adversarial loss: 0.562761\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427025; batch adversarial loss: 0.557035\n",
      "epoch 74; iter: 0; batch classifier loss: 0.440648; batch adversarial loss: 0.642029\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386817; batch adversarial loss: 0.483513\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470460; batch adversarial loss: 0.600968\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414636; batch adversarial loss: 0.473222\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389084; batch adversarial loss: 0.562887\n",
      "epoch 79; iter: 0; batch classifier loss: 0.456564; batch adversarial loss: 0.599601\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422223; batch adversarial loss: 0.571923\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398082; batch adversarial loss: 0.652177\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367920; batch adversarial loss: 0.580237\n",
      "epoch 83; iter: 0; batch classifier loss: 0.570356; batch adversarial loss: 0.640263\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376007; batch adversarial loss: 0.554067\n",
      "epoch 85; iter: 0; batch classifier loss: 0.418038; batch adversarial loss: 0.587468\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398966; batch adversarial loss: 0.531532\n",
      "epoch 87; iter: 0; batch classifier loss: 0.358412; batch adversarial loss: 0.561072\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378341; batch adversarial loss: 0.570881\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399623; batch adversarial loss: 0.578597\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371512; batch adversarial loss: 0.489962\n",
      "epoch 91; iter: 0; batch classifier loss: 0.394371; batch adversarial loss: 0.547957\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379341; batch adversarial loss: 0.608279\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433540; batch adversarial loss: 0.540548\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446883; batch adversarial loss: 0.605679\n",
      "epoch 95; iter: 0; batch classifier loss: 0.438591; batch adversarial loss: 0.588818\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396353; batch adversarial loss: 0.568834\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399772; batch adversarial loss: 0.578277\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434747; batch adversarial loss: 0.502811\n",
      "epoch 99; iter: 0; batch classifier loss: 0.445872; batch adversarial loss: 0.562196\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364409; batch adversarial loss: 0.578341\n",
      "epoch 101; iter: 0; batch classifier loss: 0.427377; batch adversarial loss: 0.499280\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402119; batch adversarial loss: 0.518528\n",
      "epoch 103; iter: 0; batch classifier loss: 0.453852; batch adversarial loss: 0.550603\n",
      "epoch 104; iter: 0; batch classifier loss: 0.396316; batch adversarial loss: 0.510442\n",
      "epoch 105; iter: 0; batch classifier loss: 0.393878; batch adversarial loss: 0.481404\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345493; batch adversarial loss: 0.524285\n",
      "epoch 107; iter: 0; batch classifier loss: 0.453779; batch adversarial loss: 0.597394\n",
      "epoch 108; iter: 0; batch classifier loss: 0.479696; batch adversarial loss: 0.572930\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374757; batch adversarial loss: 0.590371\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408983; batch adversarial loss: 0.552446\n",
      "epoch 111; iter: 0; batch classifier loss: 0.376926; batch adversarial loss: 0.529944\n",
      "epoch 112; iter: 0; batch classifier loss: 0.431373; batch adversarial loss: 0.509937\n",
      "epoch 113; iter: 0; batch classifier loss: 0.496223; batch adversarial loss: 0.651681\n",
      "epoch 114; iter: 0; batch classifier loss: 0.430820; batch adversarial loss: 0.543816\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370025; batch adversarial loss: 0.500246\n",
      "epoch 116; iter: 0; batch classifier loss: 0.459220; batch adversarial loss: 0.651784\n",
      "epoch 117; iter: 0; batch classifier loss: 0.332788; batch adversarial loss: 0.534593\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375522; batch adversarial loss: 0.623417\n",
      "epoch 119; iter: 0; batch classifier loss: 0.411736; batch adversarial loss: 0.551645\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349536; batch adversarial loss: 0.579945\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390324; batch adversarial loss: 0.598420\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385649; batch adversarial loss: 0.526850\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377063; batch adversarial loss: 0.515884\n",
      "epoch 124; iter: 0; batch classifier loss: 0.483122; batch adversarial loss: 0.556712\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393816; batch adversarial loss: 0.562281\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353660; batch adversarial loss: 0.570736\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379683; batch adversarial loss: 0.601992\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376639; batch adversarial loss: 0.515514\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364568; batch adversarial loss: 0.563356\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394783; batch adversarial loss: 0.647950\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391937; batch adversarial loss: 0.509655\n",
      "epoch 132; iter: 0; batch classifier loss: 0.358031; batch adversarial loss: 0.518274\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362507; batch adversarial loss: 0.574253\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337595; batch adversarial loss: 0.650534\n",
      "epoch 135; iter: 0; batch classifier loss: 0.403446; batch adversarial loss: 0.488588\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410002; batch adversarial loss: 0.569877\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343506; batch adversarial loss: 0.615780\n",
      "epoch 138; iter: 0; batch classifier loss: 0.397599; batch adversarial loss: 0.483630\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375883; batch adversarial loss: 0.534168\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344289; batch adversarial loss: 0.533772\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359795; batch adversarial loss: 0.518620\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362581; batch adversarial loss: 0.570317\n",
      "epoch 143; iter: 0; batch classifier loss: 0.356382; batch adversarial loss: 0.570934\n",
      "epoch 144; iter: 0; batch classifier loss: 0.417154; batch adversarial loss: 0.554899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.317484; batch adversarial loss: 0.572374\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379702; batch adversarial loss: 0.579278\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355379; batch adversarial loss: 0.491897\n",
      "epoch 148; iter: 0; batch classifier loss: 0.402439; batch adversarial loss: 0.555248\n",
      "epoch 149; iter: 0; batch classifier loss: 0.284039; batch adversarial loss: 0.616502\n",
      "epoch 150; iter: 0; batch classifier loss: 0.380299; batch adversarial loss: 0.550050\n",
      "epoch 151; iter: 0; batch classifier loss: 0.414953; batch adversarial loss: 0.519036\n",
      "epoch 152; iter: 0; batch classifier loss: 0.437611; batch adversarial loss: 0.607328\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393203; batch adversarial loss: 0.580513\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354822; batch adversarial loss: 0.571655\n",
      "epoch 155; iter: 0; batch classifier loss: 0.449309; batch adversarial loss: 0.580229\n",
      "epoch 156; iter: 0; batch classifier loss: 0.438344; batch adversarial loss: 0.599723\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406018; batch adversarial loss: 0.545288\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403807; batch adversarial loss: 0.589031\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396168; batch adversarial loss: 0.579800\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343598; batch adversarial loss: 0.511222\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351313; batch adversarial loss: 0.546703\n",
      "epoch 162; iter: 0; batch classifier loss: 0.396942; batch adversarial loss: 0.652382\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385458; batch adversarial loss: 0.569386\n",
      "epoch 164; iter: 0; batch classifier loss: 0.369572; batch adversarial loss: 0.589864\n",
      "epoch 165; iter: 0; batch classifier loss: 0.420769; batch adversarial loss: 0.562489\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409035; batch adversarial loss: 0.580545\n",
      "epoch 167; iter: 0; batch classifier loss: 0.304943; batch adversarial loss: 0.527147\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358822; batch adversarial loss: 0.493167\n",
      "epoch 169; iter: 0; batch classifier loss: 0.374425; batch adversarial loss: 0.517917\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397434; batch adversarial loss: 0.554297\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325775; batch adversarial loss: 0.526656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.385940; batch adversarial loss: 0.527553\n",
      "epoch 173; iter: 0; batch classifier loss: 0.394480; batch adversarial loss: 0.580389\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349139; batch adversarial loss: 0.587791\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416033; batch adversarial loss: 0.652294\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332170; batch adversarial loss: 0.572718\n",
      "epoch 177; iter: 0; batch classifier loss: 0.331861; batch adversarial loss: 0.554447\n",
      "epoch 178; iter: 0; batch classifier loss: 0.351384; batch adversarial loss: 0.615089\n",
      "epoch 179; iter: 0; batch classifier loss: 0.325271; batch adversarial loss: 0.490733\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322379; batch adversarial loss: 0.606125\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397494; batch adversarial loss: 0.541655\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365266; batch adversarial loss: 0.562585\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367836; batch adversarial loss: 0.516279\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389952; batch adversarial loss: 0.517362\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423174; batch adversarial loss: 0.531368\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332205; batch adversarial loss: 0.583013\n",
      "epoch 187; iter: 0; batch classifier loss: 0.445140; batch adversarial loss: 0.500383\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377877; batch adversarial loss: 0.583032\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320715; batch adversarial loss: 0.570954\n",
      "epoch 190; iter: 0; batch classifier loss: 0.411503; batch adversarial loss: 0.553366\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378032; batch adversarial loss: 0.544644\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334760; batch adversarial loss: 0.611838\n",
      "epoch 193; iter: 0; batch classifier loss: 0.306765; batch adversarial loss: 0.553102\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399879; batch adversarial loss: 0.518450\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365146; batch adversarial loss: 0.642353\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357353; batch adversarial loss: 0.507986\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335527; batch adversarial loss: 0.579347\n",
      "epoch 198; iter: 0; batch classifier loss: 0.420439; batch adversarial loss: 0.520178\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347503; batch adversarial loss: 0.482077\n",
      "epoch 0; iter: 0; batch classifier loss: 0.749237; batch adversarial loss: 0.647689\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649005; batch adversarial loss: 0.640873\n",
      "epoch 2; iter: 0; batch classifier loss: 0.598854; batch adversarial loss: 0.634079\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589890; batch adversarial loss: 0.644088\n",
      "epoch 4; iter: 0; batch classifier loss: 0.629004; batch adversarial loss: 0.599634\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573730; batch adversarial loss: 0.605302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536593; batch adversarial loss: 0.538613\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553517; batch adversarial loss: 0.654351\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519796; batch adversarial loss: 0.570948\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545292; batch adversarial loss: 0.622188\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539437; batch adversarial loss: 0.597181\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571261; batch adversarial loss: 0.553885\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540935; batch adversarial loss: 0.581773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564244; batch adversarial loss: 0.556253\n",
      "epoch 14; iter: 0; batch classifier loss: 0.561848; batch adversarial loss: 0.539603\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562527; batch adversarial loss: 0.531234\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476081; batch adversarial loss: 0.578883\n",
      "epoch 17; iter: 0; batch classifier loss: 0.553919; batch adversarial loss: 0.513399\n",
      "epoch 18; iter: 0; batch classifier loss: 0.497498; batch adversarial loss: 0.605879\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557481; batch adversarial loss: 0.538198\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486591; batch adversarial loss: 0.567606\n",
      "epoch 21; iter: 0; batch classifier loss: 0.442324; batch adversarial loss: 0.621113\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519011; batch adversarial loss: 0.549704\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489617; batch adversarial loss: 0.554861\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454170; batch adversarial loss: 0.534904\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455585; batch adversarial loss: 0.562204\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478235; batch adversarial loss: 0.557131\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462009; batch adversarial loss: 0.538641\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479273; batch adversarial loss: 0.580389\n",
      "epoch 29; iter: 0; batch classifier loss: 0.420836; batch adversarial loss: 0.540989\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417535; batch adversarial loss: 0.596661\n",
      "epoch 31; iter: 0; batch classifier loss: 0.434740; batch adversarial loss: 0.553427\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452823; batch adversarial loss: 0.488472\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441382; batch adversarial loss: 0.517475\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463163; batch adversarial loss: 0.510658\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449201; batch adversarial loss: 0.566058\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436711; batch adversarial loss: 0.525853\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395905; batch adversarial loss: 0.553269\n",
      "epoch 38; iter: 0; batch classifier loss: 0.485163; batch adversarial loss: 0.562803\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410919; batch adversarial loss: 0.595835\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493632; batch adversarial loss: 0.546036\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454271; batch adversarial loss: 0.518545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.388763; batch adversarial loss: 0.569111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386313; batch adversarial loss: 0.518297\n",
      "epoch 44; iter: 0; batch classifier loss: 0.453799; batch adversarial loss: 0.511931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453967; batch adversarial loss: 0.605218\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422112; batch adversarial loss: 0.568283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463900; batch adversarial loss: 0.591535\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423927; batch adversarial loss: 0.572477\n",
      "epoch 49; iter: 0; batch classifier loss: 0.494306; batch adversarial loss: 0.543718\n",
      "epoch 50; iter: 0; batch classifier loss: 0.444942; batch adversarial loss: 0.544891\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433663; batch adversarial loss: 0.545962\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429461; batch adversarial loss: 0.570687\n",
      "epoch 53; iter: 0; batch classifier loss: 0.387729; batch adversarial loss: 0.510414\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464049; batch adversarial loss: 0.578698\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428820; batch adversarial loss: 0.579314\n",
      "epoch 56; iter: 0; batch classifier loss: 0.373284; batch adversarial loss: 0.552619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390492; batch adversarial loss: 0.518925\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441717; batch adversarial loss: 0.642295\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418483; batch adversarial loss: 0.562229\n",
      "epoch 60; iter: 0; batch classifier loss: 0.468841; batch adversarial loss: 0.605391\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379441; batch adversarial loss: 0.518998\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443424; batch adversarial loss: 0.615508\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432626; batch adversarial loss: 0.631419\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398273; batch adversarial loss: 0.509234\n",
      "epoch 65; iter: 0; batch classifier loss: 0.489829; batch adversarial loss: 0.543885\n",
      "epoch 66; iter: 0; batch classifier loss: 0.348656; batch adversarial loss: 0.517250\n",
      "epoch 67; iter: 0; batch classifier loss: 0.468350; batch adversarial loss: 0.579893\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404735; batch adversarial loss: 0.560869\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393268; batch adversarial loss: 0.562332\n",
      "epoch 70; iter: 0; batch classifier loss: 0.394532; batch adversarial loss: 0.607372\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420991; batch adversarial loss: 0.571845\n",
      "epoch 72; iter: 0; batch classifier loss: 0.497150; batch adversarial loss: 0.498938\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402588; batch adversarial loss: 0.613999\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427672; batch adversarial loss: 0.559427\n",
      "epoch 75; iter: 0; batch classifier loss: 0.365610; batch adversarial loss: 0.529106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383462; batch adversarial loss: 0.599457\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394475; batch adversarial loss: 0.571332\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400070; batch adversarial loss: 0.546135\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399945; batch adversarial loss: 0.566224\n",
      "epoch 80; iter: 0; batch classifier loss: 0.309639; batch adversarial loss: 0.559889\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427221; batch adversarial loss: 0.551807\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353540; batch adversarial loss: 0.539491\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423459; batch adversarial loss: 0.449023\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378892; batch adversarial loss: 0.536611\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344942; batch adversarial loss: 0.574292\n",
      "epoch 86; iter: 0; batch classifier loss: 0.461196; batch adversarial loss: 0.597495\n",
      "epoch 87; iter: 0; batch classifier loss: 0.414836; batch adversarial loss: 0.562375\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427726; batch adversarial loss: 0.691826\n",
      "epoch 89; iter: 0; batch classifier loss: 0.333212; batch adversarial loss: 0.536735\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411380; batch adversarial loss: 0.587913\n",
      "epoch 91; iter: 0; batch classifier loss: 0.378180; batch adversarial loss: 0.588952\n",
      "epoch 92; iter: 0; batch classifier loss: 0.465796; batch adversarial loss: 0.501022\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400028; batch adversarial loss: 0.543719\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422259; batch adversarial loss: 0.509596\n",
      "epoch 95; iter: 0; batch classifier loss: 0.487642; batch adversarial loss: 0.555978\n",
      "epoch 96; iter: 0; batch classifier loss: 0.339290; batch adversarial loss: 0.508069\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425848; batch adversarial loss: 0.546592\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393373; batch adversarial loss: 0.535583\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344613; batch adversarial loss: 0.535933\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388577; batch adversarial loss: 0.606185\n",
      "epoch 101; iter: 0; batch classifier loss: 0.492391; batch adversarial loss: 0.569356\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415492; batch adversarial loss: 0.536329\n",
      "epoch 103; iter: 0; batch classifier loss: 0.440433; batch adversarial loss: 0.551193\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387620; batch adversarial loss: 0.599369\n",
      "epoch 105; iter: 0; batch classifier loss: 0.458832; batch adversarial loss: 0.586185\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374878; batch adversarial loss: 0.581826\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354982; batch adversarial loss: 0.545761\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390859; batch adversarial loss: 0.537996\n",
      "epoch 109; iter: 0; batch classifier loss: 0.437058; batch adversarial loss: 0.537228\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346243; batch adversarial loss: 0.545502\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379857; batch adversarial loss: 0.492365\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368576; batch adversarial loss: 0.491729\n",
      "epoch 113; iter: 0; batch classifier loss: 0.447147; batch adversarial loss: 0.544432\n",
      "epoch 114; iter: 0; batch classifier loss: 0.433365; batch adversarial loss: 0.456840\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387823; batch adversarial loss: 0.544187\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365471; batch adversarial loss: 0.586154\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340074; batch adversarial loss: 0.576753\n",
      "epoch 118; iter: 0; batch classifier loss: 0.282259; batch adversarial loss: 0.578994\n",
      "epoch 119; iter: 0; batch classifier loss: 0.481460; batch adversarial loss: 0.534117\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346004; batch adversarial loss: 0.571520\n",
      "epoch 121; iter: 0; batch classifier loss: 0.435095; batch adversarial loss: 0.530458\n",
      "epoch 122; iter: 0; batch classifier loss: 0.334721; batch adversarial loss: 0.528355\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396728; batch adversarial loss: 0.598078\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354205; batch adversarial loss: 0.519560\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375831; batch adversarial loss: 0.587958\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400733; batch adversarial loss: 0.502253\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377690; batch adversarial loss: 0.553853\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375727; batch adversarial loss: 0.545485\n",
      "epoch 129; iter: 0; batch classifier loss: 0.452672; batch adversarial loss: 0.588219\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377256; batch adversarial loss: 0.570925\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438738; batch adversarial loss: 0.554093\n",
      "epoch 132; iter: 0; batch classifier loss: 0.429794; batch adversarial loss: 0.482828\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399810; batch adversarial loss: 0.473438\n",
      "epoch 134; iter: 0; batch classifier loss: 0.526600; batch adversarial loss: 0.587964\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372657; batch adversarial loss: 0.508537\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372234; batch adversarial loss: 0.623739\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368311; batch adversarial loss: 0.589086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.360190; batch adversarial loss: 0.552119\n",
      "epoch 139; iter: 0; batch classifier loss: 0.382220; batch adversarial loss: 0.511167\n",
      "epoch 140; iter: 0; batch classifier loss: 0.330139; batch adversarial loss: 0.475590\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326670; batch adversarial loss: 0.546934\n",
      "epoch 142; iter: 0; batch classifier loss: 0.423550; batch adversarial loss: 0.542836\n",
      "epoch 143; iter: 0; batch classifier loss: 0.319139; batch adversarial loss: 0.572277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349717; batch adversarial loss: 0.518924\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373056; batch adversarial loss: 0.607013\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353876; batch adversarial loss: 0.520540\n",
      "epoch 147; iter: 0; batch classifier loss: 0.315071; batch adversarial loss: 0.518304\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332687; batch adversarial loss: 0.535351\n",
      "epoch 149; iter: 0; batch classifier loss: 0.354322; batch adversarial loss: 0.589034\n",
      "epoch 150; iter: 0; batch classifier loss: 0.435253; batch adversarial loss: 0.545284\n",
      "epoch 151; iter: 0; batch classifier loss: 0.343715; batch adversarial loss: 0.553756\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376651; batch adversarial loss: 0.570269\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400928; batch adversarial loss: 0.553542\n",
      "epoch 154; iter: 0; batch classifier loss: 0.368990; batch adversarial loss: 0.579075\n",
      "epoch 155; iter: 0; batch classifier loss: 0.315577; batch adversarial loss: 0.527431\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392198; batch adversarial loss: 0.518972\n",
      "epoch 157; iter: 0; batch classifier loss: 0.305487; batch adversarial loss: 0.588138\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361546; batch adversarial loss: 0.561480\n",
      "epoch 159; iter: 0; batch classifier loss: 0.350407; batch adversarial loss: 0.554722\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328438; batch adversarial loss: 0.508845\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376926; batch adversarial loss: 0.499369\n",
      "epoch 162; iter: 0; batch classifier loss: 0.478322; batch adversarial loss: 0.570739\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341546; batch adversarial loss: 0.499981\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336271; batch adversarial loss: 0.590296\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351592; batch adversarial loss: 0.544193\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325643; batch adversarial loss: 0.517902\n",
      "epoch 167; iter: 0; batch classifier loss: 0.321373; batch adversarial loss: 0.544692\n",
      "epoch 168; iter: 0; batch classifier loss: 0.449248; batch adversarial loss: 0.562184\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407017; batch adversarial loss: 0.635697\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385151; batch adversarial loss: 0.588508\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332959; batch adversarial loss: 0.597453\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346959; batch adversarial loss: 0.536232\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392603; batch adversarial loss: 0.634135\n",
      "epoch 174; iter: 0; batch classifier loss: 0.418366; batch adversarial loss: 0.544409\n",
      "epoch 175; iter: 0; batch classifier loss: 0.406430; batch adversarial loss: 0.472741\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367987; batch adversarial loss: 0.528087\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351472; batch adversarial loss: 0.508314\n",
      "epoch 178; iter: 0; batch classifier loss: 0.410002; batch adversarial loss: 0.535792\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330097; batch adversarial loss: 0.500634\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363616; batch adversarial loss: 0.466749\n",
      "epoch 181; iter: 0; batch classifier loss: 0.378890; batch adversarial loss: 0.562554\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327050; batch adversarial loss: 0.527112\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429361; batch adversarial loss: 0.509386\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397201; batch adversarial loss: 0.519085\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320126; batch adversarial loss: 0.622889\n",
      "epoch 186; iter: 0; batch classifier loss: 0.374516; batch adversarial loss: 0.605238\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341069; batch adversarial loss: 0.614330\n",
      "epoch 188; iter: 0; batch classifier loss: 0.296006; batch adversarial loss: 0.579655\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362039; batch adversarial loss: 0.518488\n",
      "epoch 190; iter: 0; batch classifier loss: 0.425908; batch adversarial loss: 0.571266\n",
      "epoch 191; iter: 0; batch classifier loss: 0.311331; batch adversarial loss: 0.571483\n",
      "epoch 192; iter: 0; batch classifier loss: 0.380885; batch adversarial loss: 0.667955\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300587; batch adversarial loss: 0.580671\n",
      "epoch 194; iter: 0; batch classifier loss: 0.421969; batch adversarial loss: 0.623890\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387337; batch adversarial loss: 0.553743\n",
      "epoch 196; iter: 0; batch classifier loss: 0.293180; batch adversarial loss: 0.527236\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349014; batch adversarial loss: 0.606679\n",
      "epoch 198; iter: 0; batch classifier loss: 0.309118; batch adversarial loss: 0.544077\n",
      "epoch 199; iter: 0; batch classifier loss: 0.390516; batch adversarial loss: 0.597721\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703375; batch adversarial loss: 0.619779\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556265; batch adversarial loss: 0.693072\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586949; batch adversarial loss: 0.588182\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563495; batch adversarial loss: 0.615799\n",
      "epoch 4; iter: 0; batch classifier loss: 0.484410; batch adversarial loss: 0.650554\n",
      "epoch 5; iter: 0; batch classifier loss: 0.652381; batch adversarial loss: 0.632804\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555061; batch adversarial loss: 0.544847\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536948; batch adversarial loss: 0.530054\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546828; batch adversarial loss: 0.511298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517031; batch adversarial loss: 0.548042\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570640; batch adversarial loss: 0.561015\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480735; batch adversarial loss: 0.582754\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513253; batch adversarial loss: 0.597547\n",
      "epoch 13; iter: 0; batch classifier loss: 0.459118; batch adversarial loss: 0.569515\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493900; batch adversarial loss: 0.584527\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497403; batch adversarial loss: 0.524480\n",
      "epoch 16; iter: 0; batch classifier loss: 0.444386; batch adversarial loss: 0.525673\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500425; batch adversarial loss: 0.613282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495640; batch adversarial loss: 0.615298\n",
      "epoch 19; iter: 0; batch classifier loss: 0.607397; batch adversarial loss: 0.538158\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449154; batch adversarial loss: 0.521665\n",
      "epoch 21; iter: 0; batch classifier loss: 0.437660; batch adversarial loss: 0.586437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.550998; batch adversarial loss: 0.527466\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495102; batch adversarial loss: 0.527100\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457556; batch adversarial loss: 0.508388\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517963; batch adversarial loss: 0.530712\n",
      "epoch 26; iter: 0; batch classifier loss: 0.454175; batch adversarial loss: 0.475551\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481234; batch adversarial loss: 0.531178\n",
      "epoch 28; iter: 0; batch classifier loss: 0.348430; batch adversarial loss: 0.517103\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521982; batch adversarial loss: 0.581286\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449236; batch adversarial loss: 0.569865\n",
      "epoch 31; iter: 0; batch classifier loss: 0.457765; batch adversarial loss: 0.497666\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446696; batch adversarial loss: 0.496547\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509675; batch adversarial loss: 0.460269\n",
      "epoch 34; iter: 0; batch classifier loss: 0.504527; batch adversarial loss: 0.512302\n",
      "epoch 35; iter: 0; batch classifier loss: 0.525314; batch adversarial loss: 0.564859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.482800; batch adversarial loss: 0.585851\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471115; batch adversarial loss: 0.490211\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414408; batch adversarial loss: 0.573104\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401270; batch adversarial loss: 0.572098\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443536; batch adversarial loss: 0.479632\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466112; batch adversarial loss: 0.555653\n",
      "epoch 42; iter: 0; batch classifier loss: 0.491334; batch adversarial loss: 0.535548\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381987; batch adversarial loss: 0.527504\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394585; batch adversarial loss: 0.516764\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441320; batch adversarial loss: 0.536949\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444197; batch adversarial loss: 0.563259\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424638; batch adversarial loss: 0.527168\n",
      "epoch 48; iter: 0; batch classifier loss: 0.526670; batch adversarial loss: 0.569880\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417111; batch adversarial loss: 0.526726\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403116; batch adversarial loss: 0.506441\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422284; batch adversarial loss: 0.487985\n",
      "epoch 52; iter: 0; batch classifier loss: 0.494392; batch adversarial loss: 0.535185\n",
      "epoch 53; iter: 0; batch classifier loss: 0.482225; batch adversarial loss: 0.522723\n",
      "epoch 54; iter: 0; batch classifier loss: 0.358322; batch adversarial loss: 0.619584\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454639; batch adversarial loss: 0.525871\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425602; batch adversarial loss: 0.619225\n",
      "epoch 57; iter: 0; batch classifier loss: 0.378364; batch adversarial loss: 0.508251\n",
      "epoch 58; iter: 0; batch classifier loss: 0.363850; batch adversarial loss: 0.534959\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440341; batch adversarial loss: 0.579642\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395409; batch adversarial loss: 0.423195\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385249; batch adversarial loss: 0.450742\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429767; batch adversarial loss: 0.488135\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407015; batch adversarial loss: 0.554343\n",
      "epoch 64; iter: 0; batch classifier loss: 0.343693; batch adversarial loss: 0.525188\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386159; batch adversarial loss: 0.498758\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445450; batch adversarial loss: 0.535084\n",
      "epoch 67; iter: 0; batch classifier loss: 0.387439; batch adversarial loss: 0.480199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415454; batch adversarial loss: 0.580106\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457380; batch adversarial loss: 0.554363\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364018; batch adversarial loss: 0.517920\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377233; batch adversarial loss: 0.563683\n",
      "epoch 72; iter: 0; batch classifier loss: 0.459720; batch adversarial loss: 0.462035\n",
      "epoch 73; iter: 0; batch classifier loss: 0.346406; batch adversarial loss: 0.563258\n",
      "epoch 74; iter: 0; batch classifier loss: 0.467272; batch adversarial loss: 0.518094\n",
      "epoch 75; iter: 0; batch classifier loss: 0.424323; batch adversarial loss: 0.526311\n",
      "epoch 76; iter: 0; batch classifier loss: 0.345086; batch adversarial loss: 0.635804\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441744; batch adversarial loss: 0.617964\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341372; batch adversarial loss: 0.516766\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385426; batch adversarial loss: 0.507631\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349849; batch adversarial loss: 0.461396\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427930; batch adversarial loss: 0.516815\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403598; batch adversarial loss: 0.526085\n",
      "epoch 83; iter: 0; batch classifier loss: 0.474446; batch adversarial loss: 0.516501\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401052; batch adversarial loss: 0.526609\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441179; batch adversarial loss: 0.516854\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410098; batch adversarial loss: 0.543479\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391689; batch adversarial loss: 0.560902\n",
      "epoch 88; iter: 0; batch classifier loss: 0.342678; batch adversarial loss: 0.534005\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393485; batch adversarial loss: 0.564369\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444584; batch adversarial loss: 0.621112\n",
      "epoch 91; iter: 0; batch classifier loss: 0.470479; batch adversarial loss: 0.516902\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366639; batch adversarial loss: 0.572614\n",
      "epoch 93; iter: 0; batch classifier loss: 0.438424; batch adversarial loss: 0.564395\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423682; batch adversarial loss: 0.517518\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394678; batch adversarial loss: 0.526101\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375176; batch adversarial loss: 0.497853\n",
      "epoch 97; iter: 0; batch classifier loss: 0.490150; batch adversarial loss: 0.432177\n",
      "epoch 98; iter: 0; batch classifier loss: 0.460937; batch adversarial loss: 0.562584\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377078; batch adversarial loss: 0.497434\n",
      "epoch 100; iter: 0; batch classifier loss: 0.426585; batch adversarial loss: 0.582207\n",
      "epoch 101; iter: 0; batch classifier loss: 0.338538; batch adversarial loss: 0.553721\n",
      "epoch 102; iter: 0; batch classifier loss: 0.487346; batch adversarial loss: 0.488825\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383456; batch adversarial loss: 0.535038\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349094; batch adversarial loss: 0.517189\n",
      "epoch 105; iter: 0; batch classifier loss: 0.421420; batch adversarial loss: 0.599127\n",
      "epoch 106; iter: 0; batch classifier loss: 0.446804; batch adversarial loss: 0.610319\n",
      "epoch 107; iter: 0; batch classifier loss: 0.438926; batch adversarial loss: 0.518107\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332631; batch adversarial loss: 0.533585\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363602; batch adversarial loss: 0.554526\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394342; batch adversarial loss: 0.524758\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385021; batch adversarial loss: 0.581511\n",
      "epoch 112; iter: 0; batch classifier loss: 0.346441; batch adversarial loss: 0.581625\n",
      "epoch 113; iter: 0; batch classifier loss: 0.491706; batch adversarial loss: 0.544256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.339186; batch adversarial loss: 0.506694\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342150; batch adversarial loss: 0.553724\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401923; batch adversarial loss: 0.563774\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365347; batch adversarial loss: 0.535232\n",
      "epoch 118; iter: 0; batch classifier loss: 0.408777; batch adversarial loss: 0.516231\n",
      "epoch 119; iter: 0; batch classifier loss: 0.320614; batch adversarial loss: 0.525893\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370941; batch adversarial loss: 0.572588\n",
      "epoch 121; iter: 0; batch classifier loss: 0.424091; batch adversarial loss: 0.525799\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359001; batch adversarial loss: 0.525744\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369986; batch adversarial loss: 0.637238\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408460; batch adversarial loss: 0.507378\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437429; batch adversarial loss: 0.590880\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361551; batch adversarial loss: 0.563146\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372744; batch adversarial loss: 0.479654\n",
      "epoch 128; iter: 0; batch classifier loss: 0.335768; batch adversarial loss: 0.516762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.363451; batch adversarial loss: 0.553650\n",
      "epoch 130; iter: 0; batch classifier loss: 0.449612; batch adversarial loss: 0.581514\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414636; batch adversarial loss: 0.525907\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390678; batch adversarial loss: 0.525837\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426626; batch adversarial loss: 0.535260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.343468; batch adversarial loss: 0.581345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.459902; batch adversarial loss: 0.544087\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346386; batch adversarial loss: 0.563395\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305213; batch adversarial loss: 0.572359\n",
      "epoch 138; iter: 0; batch classifier loss: 0.375349; batch adversarial loss: 0.507678\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369787; batch adversarial loss: 0.618453\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383515; batch adversarial loss: 0.498417\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369377; batch adversarial loss: 0.488974\n",
      "epoch 142; iter: 0; batch classifier loss: 0.463431; batch adversarial loss: 0.572237\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373696; batch adversarial loss: 0.535073\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339086; batch adversarial loss: 0.544189\n",
      "epoch 145; iter: 0; batch classifier loss: 0.467802; batch adversarial loss: 0.508505\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361014; batch adversarial loss: 0.563036\n",
      "epoch 147; iter: 0; batch classifier loss: 0.320875; batch adversarial loss: 0.507816\n",
      "epoch 148; iter: 0; batch classifier loss: 0.446948; batch adversarial loss: 0.571433\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370753; batch adversarial loss: 0.516504\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336862; batch adversarial loss: 0.460541\n",
      "epoch 151; iter: 0; batch classifier loss: 0.327377; batch adversarial loss: 0.609716\n",
      "epoch 152; iter: 0; batch classifier loss: 0.422876; batch adversarial loss: 0.590443\n",
      "epoch 153; iter: 0; batch classifier loss: 0.415212; batch adversarial loss: 0.535432\n",
      "epoch 154; iter: 0; batch classifier loss: 0.407178; batch adversarial loss: 0.572461\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330011; batch adversarial loss: 0.572028\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351500; batch adversarial loss: 0.554145\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313129; batch adversarial loss: 0.619353\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384199; batch adversarial loss: 0.516862\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415882; batch adversarial loss: 0.497496\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341801; batch adversarial loss: 0.544467\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342148; batch adversarial loss: 0.517208\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311303; batch adversarial loss: 0.591123\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392075; batch adversarial loss: 0.470224\n",
      "epoch 164; iter: 0; batch classifier loss: 0.428393; batch adversarial loss: 0.525911\n",
      "epoch 165; iter: 0; batch classifier loss: 0.332727; batch adversarial loss: 0.562990\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384978; batch adversarial loss: 0.618794\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346339; batch adversarial loss: 0.553866\n",
      "epoch 168; iter: 0; batch classifier loss: 0.390395; batch adversarial loss: 0.526008\n",
      "epoch 169; iter: 0; batch classifier loss: 0.323129; batch adversarial loss: 0.525836\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315230; batch adversarial loss: 0.554315\n",
      "epoch 171; iter: 0; batch classifier loss: 0.388628; batch adversarial loss: 0.562060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349294; batch adversarial loss: 0.562804\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339683; batch adversarial loss: 0.498197\n",
      "epoch 174; iter: 0; batch classifier loss: 0.461242; batch adversarial loss: 0.589039\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360422; batch adversarial loss: 0.635427\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382343; batch adversarial loss: 0.518678\n",
      "epoch 177; iter: 0; batch classifier loss: 0.331630; batch adversarial loss: 0.636694\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316683; batch adversarial loss: 0.600545\n",
      "epoch 179; iter: 0; batch classifier loss: 0.385002; batch adversarial loss: 0.562593\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346891; batch adversarial loss: 0.497630\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397929; batch adversarial loss: 0.542984\n",
      "epoch 182; iter: 0; batch classifier loss: 0.472113; batch adversarial loss: 0.562111\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357445; batch adversarial loss: 0.471090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357650; batch adversarial loss: 0.527262\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339232; batch adversarial loss: 0.543538\n",
      "epoch 186; iter: 0; batch classifier loss: 0.379037; batch adversarial loss: 0.610705\n",
      "epoch 187; iter: 0; batch classifier loss: 0.440203; batch adversarial loss: 0.552991\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362683; batch adversarial loss: 0.553306\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292583; batch adversarial loss: 0.478650\n",
      "epoch 190; iter: 0; batch classifier loss: 0.301427; batch adversarial loss: 0.506848\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381598; batch adversarial loss: 0.581538\n",
      "epoch 192; iter: 0; batch classifier loss: 0.324580; batch adversarial loss: 0.563646\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373301; batch adversarial loss: 0.627653\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407405; batch adversarial loss: 0.498101\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312093; batch adversarial loss: 0.544597\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330532; batch adversarial loss: 0.600783\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317722; batch adversarial loss: 0.488793\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355510; batch adversarial loss: 0.535002\n",
      "epoch 199; iter: 0; batch classifier loss: 0.291908; batch adversarial loss: 0.488421\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717077; batch adversarial loss: 0.654112\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583911; batch adversarial loss: 0.638630\n",
      "epoch 2; iter: 0; batch classifier loss: 0.545008; batch adversarial loss: 0.639438\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573534; batch adversarial loss: 0.605273\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519448; batch adversarial loss: 0.590391\n",
      "epoch 5; iter: 0; batch classifier loss: 0.525461; batch adversarial loss: 0.641027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536274; batch adversarial loss: 0.595510\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545248; batch adversarial loss: 0.585109\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508996; batch adversarial loss: 0.608131\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495398; batch adversarial loss: 0.580899\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581792; batch adversarial loss: 0.638864\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582552; batch adversarial loss: 0.606810\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503651; batch adversarial loss: 0.601932\n",
      "epoch 13; iter: 0; batch classifier loss: 0.581488; batch adversarial loss: 0.592215\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543512; batch adversarial loss: 0.548247\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494876; batch adversarial loss: 0.627117\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448596; batch adversarial loss: 0.607654\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568524; batch adversarial loss: 0.585568\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501422; batch adversarial loss: 0.531036\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519140; batch adversarial loss: 0.481963\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517891; batch adversarial loss: 0.548418\n",
      "epoch 21; iter: 0; batch classifier loss: 0.571866; batch adversarial loss: 0.561881\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467075; batch adversarial loss: 0.543317\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489110; batch adversarial loss: 0.561230\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452402; batch adversarial loss: 0.602120\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437378; batch adversarial loss: 0.564099\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441217; batch adversarial loss: 0.491589\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470817; batch adversarial loss: 0.529981\n",
      "epoch 28; iter: 0; batch classifier loss: 0.379110; batch adversarial loss: 0.595926\n",
      "epoch 29; iter: 0; batch classifier loss: 0.499746; batch adversarial loss: 0.538417\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428833; batch adversarial loss: 0.580431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.381406; batch adversarial loss: 0.563212\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450756; batch adversarial loss: 0.604844\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417119; batch adversarial loss: 0.571481\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501339; batch adversarial loss: 0.514871\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440781; batch adversarial loss: 0.596151\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424647; batch adversarial loss: 0.586995\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463165; batch adversarial loss: 0.528466\n",
      "epoch 38; iter: 0; batch classifier loss: 0.396200; batch adversarial loss: 0.637955\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457430; batch adversarial loss: 0.553874\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432584; batch adversarial loss: 0.570637\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436650; batch adversarial loss: 0.596138\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481917; batch adversarial loss: 0.621078\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446936; batch adversarial loss: 0.546048\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520745; batch adversarial loss: 0.579898\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473642; batch adversarial loss: 0.537140\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424513; batch adversarial loss: 0.535710\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479138; batch adversarial loss: 0.536112\n",
      "epoch 48; iter: 0; batch classifier loss: 0.463652; batch adversarial loss: 0.604862\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428007; batch adversarial loss: 0.613151\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404887; batch adversarial loss: 0.528080\n",
      "epoch 51; iter: 0; batch classifier loss: 0.410933; batch adversarial loss: 0.612012\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414922; batch adversarial loss: 0.578825\n",
      "epoch 53; iter: 0; batch classifier loss: 0.497257; batch adversarial loss: 0.510789\n",
      "epoch 54; iter: 0; batch classifier loss: 0.367344; batch adversarial loss: 0.571116\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434400; batch adversarial loss: 0.604510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385112; batch adversarial loss: 0.502832\n",
      "epoch 57; iter: 0; batch classifier loss: 0.479227; batch adversarial loss: 0.526778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423132; batch adversarial loss: 0.568865\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385186; batch adversarial loss: 0.551569\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385668; batch adversarial loss: 0.553630\n",
      "epoch 61; iter: 0; batch classifier loss: 0.453621; batch adversarial loss: 0.520501\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405939; batch adversarial loss: 0.562683\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397465; batch adversarial loss: 0.606463\n",
      "epoch 64; iter: 0; batch classifier loss: 0.335690; batch adversarial loss: 0.574037\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435205; batch adversarial loss: 0.509555\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408613; batch adversarial loss: 0.562553\n",
      "epoch 67; iter: 0; batch classifier loss: 0.415904; batch adversarial loss: 0.614572\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405918; batch adversarial loss: 0.528164\n",
      "epoch 69; iter: 0; batch classifier loss: 0.390702; batch adversarial loss: 0.587731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433524; batch adversarial loss: 0.511088\n",
      "epoch 71; iter: 0; batch classifier loss: 0.447167; batch adversarial loss: 0.597119\n",
      "epoch 72; iter: 0; batch classifier loss: 0.396078; batch adversarial loss: 0.520179\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439234; batch adversarial loss: 0.528285\n",
      "epoch 74; iter: 0; batch classifier loss: 0.495389; batch adversarial loss: 0.569976\n",
      "epoch 75; iter: 0; batch classifier loss: 0.461069; batch adversarial loss: 0.587523\n",
      "epoch 76; iter: 0; batch classifier loss: 0.446119; batch adversarial loss: 0.543926\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386909; batch adversarial loss: 0.606051\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457994; batch adversarial loss: 0.553171\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381332; batch adversarial loss: 0.477091\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395240; batch adversarial loss: 0.535444\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389772; batch adversarial loss: 0.595870\n",
      "epoch 82; iter: 0; batch classifier loss: 0.460865; batch adversarial loss: 0.553011\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396997; batch adversarial loss: 0.611150\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376339; batch adversarial loss: 0.578971\n",
      "epoch 85; iter: 0; batch classifier loss: 0.483767; batch adversarial loss: 0.550782\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420366; batch adversarial loss: 0.503401\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368418; batch adversarial loss: 0.606605\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460845; batch adversarial loss: 0.587925\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425014; batch adversarial loss: 0.552019\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404761; batch adversarial loss: 0.498371\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439216; batch adversarial loss: 0.625611\n",
      "epoch 92; iter: 0; batch classifier loss: 0.338223; batch adversarial loss: 0.545971\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447034; batch adversarial loss: 0.656467\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336771; batch adversarial loss: 0.580458\n",
      "epoch 95; iter: 0; batch classifier loss: 0.448632; batch adversarial loss: 0.561983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396924; batch adversarial loss: 0.492842\n",
      "epoch 97; iter: 0; batch classifier loss: 0.347799; batch adversarial loss: 0.659227\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373910; batch adversarial loss: 0.552526\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384288; batch adversarial loss: 0.536404\n",
      "epoch 100; iter: 0; batch classifier loss: 0.445937; batch adversarial loss: 0.560688\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394949; batch adversarial loss: 0.527455\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418053; batch adversarial loss: 0.597396\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376646; batch adversarial loss: 0.630120\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420240; batch adversarial loss: 0.632075\n",
      "epoch 105; iter: 0; batch classifier loss: 0.347478; batch adversarial loss: 0.571525\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371933; batch adversarial loss: 0.519676\n",
      "epoch 107; iter: 0; batch classifier loss: 0.418292; batch adversarial loss: 0.536466\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408968; batch adversarial loss: 0.529796\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369700; batch adversarial loss: 0.545002\n",
      "epoch 110; iter: 0; batch classifier loss: 0.406509; batch adversarial loss: 0.580815\n",
      "epoch 111; iter: 0; batch classifier loss: 0.322887; batch adversarial loss: 0.586823\n",
      "epoch 112; iter: 0; batch classifier loss: 0.325412; batch adversarial loss: 0.633070\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374261; batch adversarial loss: 0.493763\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390109; batch adversarial loss: 0.563985\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374171; batch adversarial loss: 0.588196\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361644; batch adversarial loss: 0.553301\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388312; batch adversarial loss: 0.579434\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354893; batch adversarial loss: 0.538449\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369000; batch adversarial loss: 0.535447\n",
      "epoch 120; iter: 0; batch classifier loss: 0.318871; batch adversarial loss: 0.504014\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381949; batch adversarial loss: 0.544592\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404469; batch adversarial loss: 0.605134\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366449; batch adversarial loss: 0.560754\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381036; batch adversarial loss: 0.524927\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387742; batch adversarial loss: 0.576030\n",
      "epoch 126; iter: 0; batch classifier loss: 0.452570; batch adversarial loss: 0.553457\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350316; batch adversarial loss: 0.603101\n",
      "epoch 128; iter: 0; batch classifier loss: 0.393139; batch adversarial loss: 0.589410\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402935; batch adversarial loss: 0.570441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.339611; batch adversarial loss: 0.470090\n",
      "epoch 131; iter: 0; batch classifier loss: 0.410456; batch adversarial loss: 0.606547\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343116; batch adversarial loss: 0.606312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.323175; batch adversarial loss: 0.511587\n",
      "epoch 134; iter: 0; batch classifier loss: 0.330569; batch adversarial loss: 0.649165\n",
      "epoch 135; iter: 0; batch classifier loss: 0.332232; batch adversarial loss: 0.467008\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368422; batch adversarial loss: 0.537243\n",
      "epoch 137; iter: 0; batch classifier loss: 0.459578; batch adversarial loss: 0.569928\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376060; batch adversarial loss: 0.624037\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403558; batch adversarial loss: 0.613918\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371235; batch adversarial loss: 0.551542\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400657; batch adversarial loss: 0.545140\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419178; batch adversarial loss: 0.590373\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380054; batch adversarial loss: 0.656005\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356949; batch adversarial loss: 0.561446\n",
      "epoch 145; iter: 0; batch classifier loss: 0.499568; batch adversarial loss: 0.572337\n",
      "epoch 146; iter: 0; batch classifier loss: 0.462500; batch adversarial loss: 0.569120\n",
      "epoch 147; iter: 0; batch classifier loss: 0.401692; batch adversarial loss: 0.544367\n",
      "epoch 148; iter: 0; batch classifier loss: 0.321157; batch adversarial loss: 0.595833\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347916; batch adversarial loss: 0.543899\n",
      "epoch 150; iter: 0; batch classifier loss: 0.448727; batch adversarial loss: 0.493679\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323792; batch adversarial loss: 0.596687\n",
      "epoch 152; iter: 0; batch classifier loss: 0.430757; batch adversarial loss: 0.530703\n",
      "epoch 153; iter: 0; batch classifier loss: 0.359004; batch adversarial loss: 0.582901\n",
      "epoch 154; iter: 0; batch classifier loss: 0.345282; batch adversarial loss: 0.579314\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419630; batch adversarial loss: 0.589444\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327647; batch adversarial loss: 0.555816\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404256; batch adversarial loss: 0.571547\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386028; batch adversarial loss: 0.554996\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376346; batch adversarial loss: 0.579072\n",
      "epoch 160; iter: 0; batch classifier loss: 0.363066; batch adversarial loss: 0.528359\n",
      "epoch 161; iter: 0; batch classifier loss: 0.400200; batch adversarial loss: 0.579405\n",
      "epoch 162; iter: 0; batch classifier loss: 0.402157; batch adversarial loss: 0.511337\n",
      "epoch 163; iter: 0; batch classifier loss: 0.294905; batch adversarial loss: 0.536717\n",
      "epoch 164; iter: 0; batch classifier loss: 0.318036; batch adversarial loss: 0.590874\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374395; batch adversarial loss: 0.515907\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368408; batch adversarial loss: 0.581101\n",
      "epoch 167; iter: 0; batch classifier loss: 0.414392; batch adversarial loss: 0.587221\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375422; batch adversarial loss: 0.580486\n",
      "epoch 169; iter: 0; batch classifier loss: 0.296691; batch adversarial loss: 0.510833\n",
      "epoch 170; iter: 0; batch classifier loss: 0.377097; batch adversarial loss: 0.581199\n",
      "epoch 171; iter: 0; batch classifier loss: 0.325182; batch adversarial loss: 0.552527\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344571; batch adversarial loss: 0.568868\n",
      "epoch 173; iter: 0; batch classifier loss: 0.435570; batch adversarial loss: 0.611211\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404558; batch adversarial loss: 0.604399\n",
      "epoch 175; iter: 0; batch classifier loss: 0.398830; batch adversarial loss: 0.553883\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297625; batch adversarial loss: 0.510910\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315943; batch adversarial loss: 0.570355\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309149; batch adversarial loss: 0.603691\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402224; batch adversarial loss: 0.580902\n",
      "epoch 180; iter: 0; batch classifier loss: 0.341774; batch adversarial loss: 0.535172\n",
      "epoch 181; iter: 0; batch classifier loss: 0.326060; batch adversarial loss: 0.528380\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314141; batch adversarial loss: 0.510071\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344158; batch adversarial loss: 0.586293\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416240; batch adversarial loss: 0.528039\n",
      "epoch 185; iter: 0; batch classifier loss: 0.470488; batch adversarial loss: 0.597890\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414005; batch adversarial loss: 0.578766\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375658; batch adversarial loss: 0.535933\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379036; batch adversarial loss: 0.500939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.461229; batch adversarial loss: 0.597016\n",
      "epoch 190; iter: 0; batch classifier loss: 0.308743; batch adversarial loss: 0.580550\n",
      "epoch 191; iter: 0; batch classifier loss: 0.406632; batch adversarial loss: 0.512418\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345923; batch adversarial loss: 0.537418\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318253; batch adversarial loss: 0.614426\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312469; batch adversarial loss: 0.459505\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346329; batch adversarial loss: 0.580219\n",
      "epoch 196; iter: 0; batch classifier loss: 0.363418; batch adversarial loss: 0.571679\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366780; batch adversarial loss: 0.561194\n",
      "epoch 198; iter: 0; batch classifier loss: 0.470116; batch adversarial loss: 0.585473\n",
      "epoch 199; iter: 0; batch classifier loss: 0.406846; batch adversarial loss: 0.579441\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682913; batch adversarial loss: 0.809221\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704354; batch adversarial loss: 0.883866\n",
      "epoch 2; iter: 0; batch classifier loss: 0.837282; batch adversarial loss: 0.826540\n",
      "epoch 3; iter: 0; batch classifier loss: 0.832565; batch adversarial loss: 0.758617\n",
      "epoch 4; iter: 0; batch classifier loss: 0.661090; batch adversarial loss: 0.693727\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594496; batch adversarial loss: 0.656172\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484200; batch adversarial loss: 0.635308\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526600; batch adversarial loss: 0.640420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539614; batch adversarial loss: 0.620157\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514642; batch adversarial loss: 0.580309\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535937; batch adversarial loss: 0.633781\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525409; batch adversarial loss: 0.592956\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546864; batch adversarial loss: 0.555687\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493288; batch adversarial loss: 0.612076\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571871; batch adversarial loss: 0.584797\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500829; batch adversarial loss: 0.589672\n",
      "epoch 16; iter: 0; batch classifier loss: 0.462878; batch adversarial loss: 0.545881\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497760; batch adversarial loss: 0.523257\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534723; batch adversarial loss: 0.573022\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523149; batch adversarial loss: 0.556243\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501761; batch adversarial loss: 0.574026\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490279; batch adversarial loss: 0.509358\n",
      "epoch 22; iter: 0; batch classifier loss: 0.600535; batch adversarial loss: 0.605170\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486781; batch adversarial loss: 0.539882\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469211; batch adversarial loss: 0.500769\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489418; batch adversarial loss: 0.632920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.482988; batch adversarial loss: 0.524748\n",
      "epoch 27; iter: 0; batch classifier loss: 0.552163; batch adversarial loss: 0.531037\n",
      "epoch 28; iter: 0; batch classifier loss: 0.562746; batch adversarial loss: 0.591454\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439736; batch adversarial loss: 0.568252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.412856; batch adversarial loss: 0.596805\n",
      "epoch 31; iter: 0; batch classifier loss: 0.551156; batch adversarial loss: 0.582250\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467161; batch adversarial loss: 0.538760\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406623; batch adversarial loss: 0.622781\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459474; batch adversarial loss: 0.503010\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466426; batch adversarial loss: 0.570918\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407650; batch adversarial loss: 0.535881\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430068; batch adversarial loss: 0.581924\n",
      "epoch 38; iter: 0; batch classifier loss: 0.543802; batch adversarial loss: 0.486754\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438607; batch adversarial loss: 0.504412\n",
      "epoch 40; iter: 0; batch classifier loss: 0.363020; batch adversarial loss: 0.571799\n",
      "epoch 41; iter: 0; batch classifier loss: 0.520412; batch adversarial loss: 0.613075\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450839; batch adversarial loss: 0.587441\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401534; batch adversarial loss: 0.587874\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424376; batch adversarial loss: 0.597949\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454128; batch adversarial loss: 0.562137\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500478; batch adversarial loss: 0.483332\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425353; batch adversarial loss: 0.572072\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466686; batch adversarial loss: 0.545248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468848; batch adversarial loss: 0.641928\n",
      "epoch 50; iter: 0; batch classifier loss: 0.408712; batch adversarial loss: 0.500363\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426614; batch adversarial loss: 0.615195\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475672; batch adversarial loss: 0.604496\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443668; batch adversarial loss: 0.535579\n",
      "epoch 54; iter: 0; batch classifier loss: 0.382188; batch adversarial loss: 0.605806\n",
      "epoch 55; iter: 0; batch classifier loss: 0.332605; batch adversarial loss: 0.639518\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454631; batch adversarial loss: 0.526713\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441509; batch adversarial loss: 0.571495\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417757; batch adversarial loss: 0.527439\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410819; batch adversarial loss: 0.563388\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402357; batch adversarial loss: 0.581880\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395474; batch adversarial loss: 0.588711\n",
      "epoch 62; iter: 0; batch classifier loss: 0.410769; batch adversarial loss: 0.483960\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422280; batch adversarial loss: 0.520815\n",
      "epoch 64; iter: 0; batch classifier loss: 0.355156; batch adversarial loss: 0.598718\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417717; batch adversarial loss: 0.559345\n",
      "epoch 66; iter: 0; batch classifier loss: 0.467705; batch adversarial loss: 0.520856\n",
      "epoch 67; iter: 0; batch classifier loss: 0.502029; batch adversarial loss: 0.571548\n",
      "epoch 68; iter: 0; batch classifier loss: 0.466296; batch adversarial loss: 0.533275\n",
      "epoch 69; iter: 0; batch classifier loss: 0.380296; batch adversarial loss: 0.589278\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368297; batch adversarial loss: 0.550003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394690; batch adversarial loss: 0.597199\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397144; batch adversarial loss: 0.510139\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384460; batch adversarial loss: 0.535645\n",
      "epoch 74; iter: 0; batch classifier loss: 0.455327; batch adversarial loss: 0.526276\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441750; batch adversarial loss: 0.553243\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335049; batch adversarial loss: 0.528097\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379060; batch adversarial loss: 0.631741\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413050; batch adversarial loss: 0.526745\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380212; batch adversarial loss: 0.623432\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398834; batch adversarial loss: 0.572330\n",
      "epoch 81; iter: 0; batch classifier loss: 0.313378; batch adversarial loss: 0.569385\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390704; batch adversarial loss: 0.527388\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411404; batch adversarial loss: 0.635077\n",
      "epoch 84; iter: 0; batch classifier loss: 0.460274; batch adversarial loss: 0.579772\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397883; batch adversarial loss: 0.571598\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371003; batch adversarial loss: 0.536950\n",
      "epoch 87; iter: 0; batch classifier loss: 0.331451; batch adversarial loss: 0.563154\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425116; batch adversarial loss: 0.560704\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378074; batch adversarial loss: 0.587027\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418804; batch adversarial loss: 0.552576\n",
      "epoch 91; iter: 0; batch classifier loss: 0.371280; batch adversarial loss: 0.620092\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379741; batch adversarial loss: 0.533773\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407441; batch adversarial loss: 0.594846\n",
      "epoch 94; iter: 0; batch classifier loss: 0.315883; batch adversarial loss: 0.546002\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350191; batch adversarial loss: 0.597302\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387422; batch adversarial loss: 0.627444\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375185; batch adversarial loss: 0.581189\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339090; batch adversarial loss: 0.597188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.331977; batch adversarial loss: 0.553246\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381965; batch adversarial loss: 0.517393\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426865; batch adversarial loss: 0.438227\n",
      "epoch 102; iter: 0; batch classifier loss: 0.300706; batch adversarial loss: 0.528808\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398662; batch adversarial loss: 0.578480\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341845; batch adversarial loss: 0.543549\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380608; batch adversarial loss: 0.571472\n",
      "epoch 106; iter: 0; batch classifier loss: 0.312574; batch adversarial loss: 0.568492\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377402; batch adversarial loss: 0.535697\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392204; batch adversarial loss: 0.446206\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360747; batch adversarial loss: 0.517273\n",
      "epoch 110; iter: 0; batch classifier loss: 0.322615; batch adversarial loss: 0.491720\n",
      "epoch 111; iter: 0; batch classifier loss: 0.449125; batch adversarial loss: 0.552294\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378125; batch adversarial loss: 0.491154\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406575; batch adversarial loss: 0.555571\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382870; batch adversarial loss: 0.595307\n",
      "epoch 115; iter: 0; batch classifier loss: 0.311935; batch adversarial loss: 0.588173\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370520; batch adversarial loss: 0.563457\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377655; batch adversarial loss: 0.559804\n",
      "epoch 118; iter: 0; batch classifier loss: 0.441181; batch adversarial loss: 0.594934\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374012; batch adversarial loss: 0.536203\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436777; batch adversarial loss: 0.505734\n",
      "epoch 121; iter: 0; batch classifier loss: 0.415657; batch adversarial loss: 0.526874\n",
      "epoch 122; iter: 0; batch classifier loss: 0.420640; batch adversarial loss: 0.597940\n",
      "epoch 123; iter: 0; batch classifier loss: 0.320557; batch adversarial loss: 0.536554\n",
      "epoch 124; iter: 0; batch classifier loss: 0.297286; batch adversarial loss: 0.615176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.426475; batch adversarial loss: 0.543268\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401219; batch adversarial loss: 0.560347\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340287; batch adversarial loss: 0.555708\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329282; batch adversarial loss: 0.596818\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368503; batch adversarial loss: 0.578992\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370127; batch adversarial loss: 0.592755\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374115; batch adversarial loss: 0.526414\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319087; batch adversarial loss: 0.552373\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343388; batch adversarial loss: 0.454036\n",
      "epoch 134; iter: 0; batch classifier loss: 0.454164; batch adversarial loss: 0.573212\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413440; batch adversarial loss: 0.508234\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377674; batch adversarial loss: 0.615127\n",
      "epoch 137; iter: 0; batch classifier loss: 0.431327; batch adversarial loss: 0.518074\n",
      "epoch 138; iter: 0; batch classifier loss: 0.429754; batch adversarial loss: 0.545838\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356746; batch adversarial loss: 0.553793\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399832; batch adversarial loss: 0.525578\n",
      "epoch 141; iter: 0; batch classifier loss: 0.340716; batch adversarial loss: 0.492189\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368738; batch adversarial loss: 0.606346\n",
      "epoch 143; iter: 0; batch classifier loss: 0.353255; batch adversarial loss: 0.526615\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350714; batch adversarial loss: 0.599805\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375114; batch adversarial loss: 0.575070\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395573; batch adversarial loss: 0.556427\n",
      "epoch 147; iter: 0; batch classifier loss: 0.356916; batch adversarial loss: 0.554855\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332614; batch adversarial loss: 0.605748\n",
      "epoch 149; iter: 0; batch classifier loss: 0.351860; batch adversarial loss: 0.542518\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370174; batch adversarial loss: 0.510634\n",
      "epoch 151; iter: 0; batch classifier loss: 0.400957; batch adversarial loss: 0.554090\n",
      "epoch 152; iter: 0; batch classifier loss: 0.305165; batch adversarial loss: 0.556661\n",
      "epoch 153; iter: 0; batch classifier loss: 0.452701; batch adversarial loss: 0.549059\n",
      "epoch 154; iter: 0; batch classifier loss: 0.315836; batch adversarial loss: 0.598390\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339468; batch adversarial loss: 0.613898\n",
      "epoch 156; iter: 0; batch classifier loss: 0.422286; batch adversarial loss: 0.447003\n",
      "epoch 157; iter: 0; batch classifier loss: 0.410155; batch adversarial loss: 0.650667\n",
      "epoch 158; iter: 0; batch classifier loss: 0.371878; batch adversarial loss: 0.512725\n",
      "epoch 159; iter: 0; batch classifier loss: 0.431094; batch adversarial loss: 0.551400\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352944; batch adversarial loss: 0.554899\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345449; batch adversarial loss: 0.544778\n",
      "epoch 162; iter: 0; batch classifier loss: 0.385807; batch adversarial loss: 0.490674\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391528; batch adversarial loss: 0.608734\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395949; batch adversarial loss: 0.507664\n",
      "epoch 165; iter: 0; batch classifier loss: 0.296169; batch adversarial loss: 0.580032\n",
      "epoch 166; iter: 0; batch classifier loss: 0.300754; batch adversarial loss: 0.500422\n",
      "epoch 167; iter: 0; batch classifier loss: 0.419764; batch adversarial loss: 0.508201\n",
      "epoch 168; iter: 0; batch classifier loss: 0.455553; batch adversarial loss: 0.605528\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314801; batch adversarial loss: 0.534790\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349788; batch adversarial loss: 0.624682\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351226; batch adversarial loss: 0.535626\n",
      "epoch 172; iter: 0; batch classifier loss: 0.399958; batch adversarial loss: 0.537078\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386514; batch adversarial loss: 0.482648\n",
      "epoch 174; iter: 0; batch classifier loss: 0.342184; batch adversarial loss: 0.526568\n",
      "epoch 175; iter: 0; batch classifier loss: 0.295800; batch adversarial loss: 0.463706\n",
      "epoch 176; iter: 0; batch classifier loss: 0.402065; batch adversarial loss: 0.510411\n",
      "epoch 177; iter: 0; batch classifier loss: 0.418620; batch adversarial loss: 0.476488\n",
      "epoch 178; iter: 0; batch classifier loss: 0.296971; batch adversarial loss: 0.532851\n",
      "epoch 179; iter: 0; batch classifier loss: 0.304916; batch adversarial loss: 0.499451\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400450; batch adversarial loss: 0.606204\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364259; batch adversarial loss: 0.537245\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402825; batch adversarial loss: 0.502400\n",
      "epoch 183; iter: 0; batch classifier loss: 0.439879; batch adversarial loss: 0.546280\n",
      "epoch 184; iter: 0; batch classifier loss: 0.398159; batch adversarial loss: 0.541371\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361063; batch adversarial loss: 0.518544\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368383; batch adversarial loss: 0.549588\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350622; batch adversarial loss: 0.481882\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404610; batch adversarial loss: 0.555003\n",
      "epoch 189; iter: 0; batch classifier loss: 0.438391; batch adversarial loss: 0.510226\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375579; batch adversarial loss: 0.507874\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321275; batch adversarial loss: 0.546124\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338050; batch adversarial loss: 0.590653\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320109; batch adversarial loss: 0.644156\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354644; batch adversarial loss: 0.589009\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319333; batch adversarial loss: 0.525175\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357686; batch adversarial loss: 0.508877\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360630; batch adversarial loss: 0.614931\n",
      "epoch 198; iter: 0; batch classifier loss: 0.337680; batch adversarial loss: 0.538748\n",
      "epoch 199; iter: 0; batch classifier loss: 0.336772; batch adversarial loss: 0.525272\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686720; batch adversarial loss: 0.574346\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592074; batch adversarial loss: 0.637021\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609877; batch adversarial loss: 0.686761\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582557; batch adversarial loss: 0.704024\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553587; batch adversarial loss: 0.672868\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581975; batch adversarial loss: 0.749631\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612922; batch adversarial loss: 0.657519\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632124; batch adversarial loss: 0.628967\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515258; batch adversarial loss: 0.636320\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492648; batch adversarial loss: 0.596747\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553002; batch adversarial loss: 0.569130\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549567; batch adversarial loss: 0.580310\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555034; batch adversarial loss: 0.579037\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494654; batch adversarial loss: 0.553390\n",
      "epoch 14; iter: 0; batch classifier loss: 0.582928; batch adversarial loss: 0.590967\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555255; batch adversarial loss: 0.630455\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487526; batch adversarial loss: 0.557049\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469654; batch adversarial loss: 0.514195\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484532; batch adversarial loss: 0.554745\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471049; batch adversarial loss: 0.632810\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530458; batch adversarial loss: 0.535393\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486616; batch adversarial loss: 0.610500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.590099; batch adversarial loss: 0.619396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.450321; batch adversarial loss: 0.610865\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495608; batch adversarial loss: 0.540629\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503583; batch adversarial loss: 0.563959\n",
      "epoch 26; iter: 0; batch classifier loss: 0.535695; batch adversarial loss: 0.512762\n",
      "epoch 27; iter: 0; batch classifier loss: 0.532518; batch adversarial loss: 0.569808\n",
      "epoch 28; iter: 0; batch classifier loss: 0.395881; batch adversarial loss: 0.569587\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482805; batch adversarial loss: 0.545267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448584; batch adversarial loss: 0.500488\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480701; batch adversarial loss: 0.519373\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432463; batch adversarial loss: 0.469708\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425093; batch adversarial loss: 0.502612\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499918; batch adversarial loss: 0.467406\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447270; batch adversarial loss: 0.569776\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397135; batch adversarial loss: 0.554965\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427088; batch adversarial loss: 0.527644\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458707; batch adversarial loss: 0.522253\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454607; batch adversarial loss: 0.535266\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492245; batch adversarial loss: 0.586106\n",
      "epoch 41; iter: 0; batch classifier loss: 0.490181; batch adversarial loss: 0.536067\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457397; batch adversarial loss: 0.570526\n",
      "epoch 43; iter: 0; batch classifier loss: 0.498544; batch adversarial loss: 0.621816\n",
      "epoch 44; iter: 0; batch classifier loss: 0.514804; batch adversarial loss: 0.550922\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443831; batch adversarial loss: 0.544910\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443971; batch adversarial loss: 0.543606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479284; batch adversarial loss: 0.519679\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509621; batch adversarial loss: 0.549791\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444207; batch adversarial loss: 0.499456\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449333; batch adversarial loss: 0.597562\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446405; batch adversarial loss: 0.509988\n",
      "epoch 52; iter: 0; batch classifier loss: 0.484983; batch adversarial loss: 0.604358\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454426; batch adversarial loss: 0.594665\n",
      "epoch 54; iter: 0; batch classifier loss: 0.444001; batch adversarial loss: 0.569669\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411582; batch adversarial loss: 0.617607\n",
      "epoch 56; iter: 0; batch classifier loss: 0.459093; batch adversarial loss: 0.528503\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411643; batch adversarial loss: 0.544965\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418895; batch adversarial loss: 0.582667\n",
      "epoch 59; iter: 0; batch classifier loss: 0.354067; batch adversarial loss: 0.538004\n",
      "epoch 60; iter: 0; batch classifier loss: 0.350124; batch adversarial loss: 0.629931\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380439; batch adversarial loss: 0.521681\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415873; batch adversarial loss: 0.563011\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423018; batch adversarial loss: 0.571497\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450014; batch adversarial loss: 0.629931\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417860; batch adversarial loss: 0.552987\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374927; batch adversarial loss: 0.545312\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429703; batch adversarial loss: 0.492998\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421299; batch adversarial loss: 0.510305\n",
      "epoch 69; iter: 0; batch classifier loss: 0.466061; batch adversarial loss: 0.544840\n",
      "epoch 70; iter: 0; batch classifier loss: 0.351726; batch adversarial loss: 0.501078\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463560; batch adversarial loss: 0.528637\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376522; batch adversarial loss: 0.553892\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423860; batch adversarial loss: 0.560260\n",
      "epoch 74; iter: 0; batch classifier loss: 0.453368; batch adversarial loss: 0.544426\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430552; batch adversarial loss: 0.589034\n",
      "epoch 76; iter: 0; batch classifier loss: 0.320781; batch adversarial loss: 0.562269\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400626; batch adversarial loss: 0.528923\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409123; batch adversarial loss: 0.571750\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428129; batch adversarial loss: 0.493830\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420774; batch adversarial loss: 0.605884\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390562; batch adversarial loss: 0.587074\n",
      "epoch 82; iter: 0; batch classifier loss: 0.357438; batch adversarial loss: 0.510680\n",
      "epoch 83; iter: 0; batch classifier loss: 0.435115; batch adversarial loss: 0.546929\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362591; batch adversarial loss: 0.595353\n",
      "epoch 85; iter: 0; batch classifier loss: 0.439000; batch adversarial loss: 0.570188\n",
      "epoch 86; iter: 0; batch classifier loss: 0.465749; batch adversarial loss: 0.545088\n",
      "epoch 87; iter: 0; batch classifier loss: 0.355778; batch adversarial loss: 0.563275\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378093; batch adversarial loss: 0.544750\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452238; batch adversarial loss: 0.570869\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444339; batch adversarial loss: 0.510025\n",
      "epoch 91; iter: 0; batch classifier loss: 0.262682; batch adversarial loss: 0.527358\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351434; batch adversarial loss: 0.561867\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393511; batch adversarial loss: 0.552708\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392648; batch adversarial loss: 0.500622\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402134; batch adversarial loss: 0.588545\n",
      "epoch 96; iter: 0; batch classifier loss: 0.409372; batch adversarial loss: 0.563522\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439914; batch adversarial loss: 0.449482\n",
      "epoch 98; iter: 0; batch classifier loss: 0.473064; batch adversarial loss: 0.614221\n",
      "epoch 99; iter: 0; batch classifier loss: 0.386519; batch adversarial loss: 0.563156\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358585; batch adversarial loss: 0.535616\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360867; batch adversarial loss: 0.534316\n",
      "epoch 102; iter: 0; batch classifier loss: 0.396729; batch adversarial loss: 0.537161\n",
      "epoch 103; iter: 0; batch classifier loss: 0.453224; batch adversarial loss: 0.596631\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352598; batch adversarial loss: 0.491926\n",
      "epoch 105; iter: 0; batch classifier loss: 0.450228; batch adversarial loss: 0.588389\n",
      "epoch 106; iter: 0; batch classifier loss: 0.429159; batch adversarial loss: 0.569913\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348988; batch adversarial loss: 0.544487\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381823; batch adversarial loss: 0.493162\n",
      "epoch 109; iter: 0; batch classifier loss: 0.393237; batch adversarial loss: 0.579201\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399404; batch adversarial loss: 0.622201\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381881; batch adversarial loss: 0.518273\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356332; batch adversarial loss: 0.518573\n",
      "epoch 113; iter: 0; batch classifier loss: 0.448613; batch adversarial loss: 0.570914\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383732; batch adversarial loss: 0.579220\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357236; batch adversarial loss: 0.596626\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370193; batch adversarial loss: 0.606668\n",
      "epoch 117; iter: 0; batch classifier loss: 0.419300; batch adversarial loss: 0.589092\n",
      "epoch 118; iter: 0; batch classifier loss: 0.375542; batch adversarial loss: 0.518715\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347233; batch adversarial loss: 0.571877\n",
      "epoch 120; iter: 0; batch classifier loss: 0.368063; batch adversarial loss: 0.569998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121; iter: 0; batch classifier loss: 0.301800; batch adversarial loss: 0.607265\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359124; batch adversarial loss: 0.640820\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343793; batch adversarial loss: 0.595998\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342167; batch adversarial loss: 0.535818\n",
      "epoch 125; iter: 0; batch classifier loss: 0.432681; batch adversarial loss: 0.570872\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345133; batch adversarial loss: 0.544253\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390241; batch adversarial loss: 0.528409\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365076; batch adversarial loss: 0.490983\n",
      "epoch 129; iter: 0; batch classifier loss: 0.517427; batch adversarial loss: 0.536630\n",
      "epoch 130; iter: 0; batch classifier loss: 0.294638; batch adversarial loss: 0.561821\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396114; batch adversarial loss: 0.519542\n",
      "epoch 132; iter: 0; batch classifier loss: 0.420454; batch adversarial loss: 0.605369\n",
      "epoch 133; iter: 0; batch classifier loss: 0.419875; batch adversarial loss: 0.570439\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354040; batch adversarial loss: 0.552564\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364369; batch adversarial loss: 0.458197\n",
      "epoch 136; iter: 0; batch classifier loss: 0.382914; batch adversarial loss: 0.545452\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369650; batch adversarial loss: 0.578915\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344188; batch adversarial loss: 0.518668\n",
      "epoch 139; iter: 0; batch classifier loss: 0.382890; batch adversarial loss: 0.553666\n",
      "epoch 140; iter: 0; batch classifier loss: 0.433063; batch adversarial loss: 0.545145\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383348; batch adversarial loss: 0.587881\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347234; batch adversarial loss: 0.517879\n",
      "epoch 143; iter: 0; batch classifier loss: 0.446501; batch adversarial loss: 0.553738\n",
      "epoch 144; iter: 0; batch classifier loss: 0.359817; batch adversarial loss: 0.621672\n",
      "epoch 145; iter: 0; batch classifier loss: 0.425928; batch adversarial loss: 0.604956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371672; batch adversarial loss: 0.544873\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364623; batch adversarial loss: 0.544874\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279618; batch adversarial loss: 0.596936\n",
      "epoch 149; iter: 0; batch classifier loss: 0.386044; batch adversarial loss: 0.528563\n",
      "epoch 150; iter: 0; batch classifier loss: 0.319914; batch adversarial loss: 0.589746\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365511; batch adversarial loss: 0.544921\n",
      "epoch 152; iter: 0; batch classifier loss: 0.448580; batch adversarial loss: 0.502218\n",
      "epoch 153; iter: 0; batch classifier loss: 0.408632; batch adversarial loss: 0.535697\n",
      "epoch 154; iter: 0; batch classifier loss: 0.330784; batch adversarial loss: 0.587651\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362670; batch adversarial loss: 0.500502\n",
      "epoch 156; iter: 0; batch classifier loss: 0.302378; batch adversarial loss: 0.571683\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365810; batch adversarial loss: 0.552663\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341145; batch adversarial loss: 0.553466\n",
      "epoch 159; iter: 0; batch classifier loss: 0.431195; batch adversarial loss: 0.580594\n",
      "epoch 160; iter: 0; batch classifier loss: 0.385400; batch adversarial loss: 0.642057\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355648; batch adversarial loss: 0.605887\n",
      "epoch 162; iter: 0; batch classifier loss: 0.288278; batch adversarial loss: 0.595202\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358705; batch adversarial loss: 0.528429\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387364; batch adversarial loss: 0.640564\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408860; batch adversarial loss: 0.552381\n",
      "epoch 166; iter: 0; batch classifier loss: 0.446802; batch adversarial loss: 0.527415\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380414; batch adversarial loss: 0.526010\n",
      "epoch 168; iter: 0; batch classifier loss: 0.451684; batch adversarial loss: 0.641394\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379698; batch adversarial loss: 0.571206\n",
      "epoch 170; iter: 0; batch classifier loss: 0.312036; batch adversarial loss: 0.544204\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420969; batch adversarial loss: 0.553932\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363699; batch adversarial loss: 0.536250\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339178; batch adversarial loss: 0.511513\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334361; batch adversarial loss: 0.554211\n",
      "epoch 175; iter: 0; batch classifier loss: 0.384248; batch adversarial loss: 0.579726\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400896; batch adversarial loss: 0.588193\n",
      "epoch 177; iter: 0; batch classifier loss: 0.437060; batch adversarial loss: 0.598399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.348921; batch adversarial loss: 0.562173\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354330; batch adversarial loss: 0.572530\n",
      "epoch 180; iter: 0; batch classifier loss: 0.368515; batch adversarial loss: 0.519923\n",
      "epoch 181; iter: 0; batch classifier loss: 0.405771; batch adversarial loss: 0.536270\n",
      "epoch 182; iter: 0; batch classifier loss: 0.386939; batch adversarial loss: 0.588253\n",
      "epoch 183; iter: 0; batch classifier loss: 0.308204; batch adversarial loss: 0.544545\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362278; batch adversarial loss: 0.536550\n",
      "epoch 185; iter: 0; batch classifier loss: 0.435731; batch adversarial loss: 0.569389\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356273; batch adversarial loss: 0.526908\n",
      "epoch 187; iter: 0; batch classifier loss: 0.440822; batch adversarial loss: 0.544321\n",
      "epoch 188; iter: 0; batch classifier loss: 0.308004; batch adversarial loss: 0.553010\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297760; batch adversarial loss: 0.587906\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395035; batch adversarial loss: 0.554110\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314660; batch adversarial loss: 0.612993\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315029; batch adversarial loss: 0.483408\n",
      "epoch 193; iter: 0; batch classifier loss: 0.366882; batch adversarial loss: 0.484513\n",
      "epoch 194; iter: 0; batch classifier loss: 0.315629; batch adversarial loss: 0.570492\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365192; batch adversarial loss: 0.596771\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374566; batch adversarial loss: 0.544907\n",
      "epoch 197; iter: 0; batch classifier loss: 0.385932; batch adversarial loss: 0.510304\n",
      "epoch 198; iter: 0; batch classifier loss: 0.401880; batch adversarial loss: 0.580119\n",
      "epoch 199; iter: 0; batch classifier loss: 0.330023; batch adversarial loss: 0.571260\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727966; batch adversarial loss: 0.778521\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621353; batch adversarial loss: 0.733285\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614560; batch adversarial loss: 0.702190\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614745; batch adversarial loss: 0.668538\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598451; batch adversarial loss: 0.643365\n",
      "epoch 5; iter: 0; batch classifier loss: 0.604452; batch adversarial loss: 0.622164\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515246; batch adversarial loss: 0.634704\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536540; batch adversarial loss: 0.597626\n",
      "epoch 8; iter: 0; batch classifier loss: 0.470019; batch adversarial loss: 0.589865\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536336; batch adversarial loss: 0.600570\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502837; batch adversarial loss: 0.581014\n",
      "epoch 11; iter: 0; batch classifier loss: 0.609751; batch adversarial loss: 0.621722\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575525; batch adversarial loss: 0.555665\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524260; batch adversarial loss: 0.558155\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495325; batch adversarial loss: 0.564132\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534301; batch adversarial loss: 0.560205\n",
      "epoch 16; iter: 0; batch classifier loss: 0.582395; batch adversarial loss: 0.594633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.568232; batch adversarial loss: 0.659310\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514125; batch adversarial loss: 0.530223\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550522; batch adversarial loss: 0.606442\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539374; batch adversarial loss: 0.561894\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514327; batch adversarial loss: 0.569531\n",
      "epoch 22; iter: 0; batch classifier loss: 0.545364; batch adversarial loss: 0.578391\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539920; batch adversarial loss: 0.560881\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492044; batch adversarial loss: 0.616672\n",
      "epoch 25; iter: 0; batch classifier loss: 0.514190; batch adversarial loss: 0.543641\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504885; batch adversarial loss: 0.527217\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459826; batch adversarial loss: 0.541418\n",
      "epoch 28; iter: 0; batch classifier loss: 0.511182; batch adversarial loss: 0.602254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505369; batch adversarial loss: 0.634918\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462136; batch adversarial loss: 0.595259\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495580; batch adversarial loss: 0.570785\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490760; batch adversarial loss: 0.530259\n",
      "epoch 33; iter: 0; batch classifier loss: 0.403135; batch adversarial loss: 0.512857\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426908; batch adversarial loss: 0.545391\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457348; batch adversarial loss: 0.529124\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498064; batch adversarial loss: 0.587803\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462736; batch adversarial loss: 0.596609\n",
      "epoch 38; iter: 0; batch classifier loss: 0.388784; batch adversarial loss: 0.520066\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437308; batch adversarial loss: 0.553752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428497; batch adversarial loss: 0.536811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428610; batch adversarial loss: 0.605760\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457576; batch adversarial loss: 0.553961\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422101; batch adversarial loss: 0.476087\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448797; batch adversarial loss: 0.537107\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404308; batch adversarial loss: 0.553944\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447801; batch adversarial loss: 0.562384\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446597; batch adversarial loss: 0.545462\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469147; batch adversarial loss: 0.535429\n",
      "epoch 49; iter: 0; batch classifier loss: 0.512976; batch adversarial loss: 0.553644\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493858; batch adversarial loss: 0.579813\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429916; batch adversarial loss: 0.544832\n",
      "epoch 52; iter: 0; batch classifier loss: 0.394189; batch adversarial loss: 0.571330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.484373; batch adversarial loss: 0.518767\n",
      "epoch 54; iter: 0; batch classifier loss: 0.372159; batch adversarial loss: 0.517650\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433277; batch adversarial loss: 0.554236\n",
      "epoch 56; iter: 0; batch classifier loss: 0.351906; batch adversarial loss: 0.562019\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410374; batch adversarial loss: 0.509649\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458995; batch adversarial loss: 0.552913\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431393; batch adversarial loss: 0.607053\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416290; batch adversarial loss: 0.570231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413377; batch adversarial loss: 0.545038\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429561; batch adversarial loss: 0.588203\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420783; batch adversarial loss: 0.597131\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411319; batch adversarial loss: 0.631955\n",
      "epoch 65; iter: 0; batch classifier loss: 0.470389; batch adversarial loss: 0.482839\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377325; batch adversarial loss: 0.561943\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340823; batch adversarial loss: 0.570533\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442815; batch adversarial loss: 0.527205\n",
      "epoch 69; iter: 0; batch classifier loss: 0.462044; batch adversarial loss: 0.552257\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377498; batch adversarial loss: 0.509537\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358421; batch adversarial loss: 0.511446\n",
      "epoch 72; iter: 0; batch classifier loss: 0.480050; batch adversarial loss: 0.598132\n",
      "epoch 73; iter: 0; batch classifier loss: 0.443776; batch adversarial loss: 0.648539\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422743; batch adversarial loss: 0.659599\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407024; batch adversarial loss: 0.597640\n",
      "epoch 76; iter: 0; batch classifier loss: 0.311229; batch adversarial loss: 0.570874\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360437; batch adversarial loss: 0.535111\n",
      "epoch 78; iter: 0; batch classifier loss: 0.433636; batch adversarial loss: 0.519088\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404378; batch adversarial loss: 0.577357\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442291; batch adversarial loss: 0.544401\n",
      "epoch 81; iter: 0; batch classifier loss: 0.425036; batch adversarial loss: 0.536294\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385649; batch adversarial loss: 0.541664\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326551; batch adversarial loss: 0.519254\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353379; batch adversarial loss: 0.681100\n",
      "epoch 85; iter: 0; batch classifier loss: 0.336826; batch adversarial loss: 0.525759\n",
      "epoch 86; iter: 0; batch classifier loss: 0.338122; batch adversarial loss: 0.568331\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363155; batch adversarial loss: 0.615403\n",
      "epoch 88; iter: 0; batch classifier loss: 0.346820; batch adversarial loss: 0.520052\n",
      "epoch 89; iter: 0; batch classifier loss: 0.445636; batch adversarial loss: 0.553309\n",
      "epoch 90; iter: 0; batch classifier loss: 0.465802; batch adversarial loss: 0.622194\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400093; batch adversarial loss: 0.511050\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348361; batch adversarial loss: 0.614033\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386273; batch adversarial loss: 0.485486\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449212; batch adversarial loss: 0.510401\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394529; batch adversarial loss: 0.516104\n",
      "epoch 96; iter: 0; batch classifier loss: 0.339304; batch adversarial loss: 0.571096\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425084; batch adversarial loss: 0.544587\n",
      "epoch 98; iter: 0; batch classifier loss: 0.271073; batch adversarial loss: 0.545954\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369199; batch adversarial loss: 0.500546\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361609; batch adversarial loss: 0.571238\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434102; batch adversarial loss: 0.562366\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366790; batch adversarial loss: 0.518504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.319432; batch adversarial loss: 0.535346\n",
      "epoch 104; iter: 0; batch classifier loss: 0.410502; batch adversarial loss: 0.561924\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365879; batch adversarial loss: 0.589409\n",
      "epoch 106; iter: 0; batch classifier loss: 0.334764; batch adversarial loss: 0.537842\n",
      "epoch 107; iter: 0; batch classifier loss: 0.332574; batch adversarial loss: 0.491159\n",
      "epoch 108; iter: 0; batch classifier loss: 0.449682; batch adversarial loss: 0.623532\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422076; batch adversarial loss: 0.507999\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381701; batch adversarial loss: 0.535486\n",
      "epoch 111; iter: 0; batch classifier loss: 0.370363; batch adversarial loss: 0.542683\n",
      "epoch 112; iter: 0; batch classifier loss: 0.401095; batch adversarial loss: 0.517858\n",
      "epoch 113; iter: 0; batch classifier loss: 0.420168; batch adversarial loss: 0.624310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.351841; batch adversarial loss: 0.475632\n",
      "epoch 115; iter: 0; batch classifier loss: 0.376117; batch adversarial loss: 0.572946\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361126; batch adversarial loss: 0.612205\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406669; batch adversarial loss: 0.545008\n",
      "epoch 118; iter: 0; batch classifier loss: 0.460923; batch adversarial loss: 0.528081\n",
      "epoch 119; iter: 0; batch classifier loss: 0.426866; batch adversarial loss: 0.568502\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375202; batch adversarial loss: 0.526914\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369032; batch adversarial loss: 0.482672\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373102; batch adversarial loss: 0.519719\n",
      "epoch 123; iter: 0; batch classifier loss: 0.330682; batch adversarial loss: 0.622630\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368989; batch adversarial loss: 0.665725\n",
      "epoch 125; iter: 0; batch classifier loss: 0.422975; batch adversarial loss: 0.569587\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391707; batch adversarial loss: 0.554931\n",
      "epoch 127; iter: 0; batch classifier loss: 0.403176; batch adversarial loss: 0.570110\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409320; batch adversarial loss: 0.489567\n",
      "epoch 129; iter: 0; batch classifier loss: 0.344659; batch adversarial loss: 0.534905\n",
      "epoch 130; iter: 0; batch classifier loss: 0.435881; batch adversarial loss: 0.526340\n",
      "epoch 131; iter: 0; batch classifier loss: 0.387474; batch adversarial loss: 0.520018\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320278; batch adversarial loss: 0.597733\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386131; batch adversarial loss: 0.554681\n",
      "epoch 134; iter: 0; batch classifier loss: 0.306060; batch adversarial loss: 0.467489\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308748; batch adversarial loss: 0.544451\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410598; batch adversarial loss: 0.544515\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403176; batch adversarial loss: 0.519361\n",
      "epoch 138; iter: 0; batch classifier loss: 0.418233; batch adversarial loss: 0.518070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.271458; batch adversarial loss: 0.560517\n",
      "epoch 140; iter: 0; batch classifier loss: 0.285318; batch adversarial loss: 0.545726\n",
      "epoch 141; iter: 0; batch classifier loss: 0.466962; batch adversarial loss: 0.581202\n",
      "epoch 142; iter: 0; batch classifier loss: 0.440570; batch adversarial loss: 0.482475\n",
      "epoch 143; iter: 0; batch classifier loss: 0.415892; batch adversarial loss: 0.499970\n",
      "epoch 144; iter: 0; batch classifier loss: 0.429891; batch adversarial loss: 0.596689\n",
      "epoch 145; iter: 0; batch classifier loss: 0.372997; batch adversarial loss: 0.574470\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388119; batch adversarial loss: 0.561277\n",
      "epoch 147; iter: 0; batch classifier loss: 0.323619; batch adversarial loss: 0.569573\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303231; batch adversarial loss: 0.518788\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317719; batch adversarial loss: 0.569576\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394429; batch adversarial loss: 0.560808\n",
      "epoch 151; iter: 0; batch classifier loss: 0.287899; batch adversarial loss: 0.535144\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383434; batch adversarial loss: 0.501135\n",
      "epoch 153; iter: 0; batch classifier loss: 0.292547; batch adversarial loss: 0.518437\n",
      "epoch 154; iter: 0; batch classifier loss: 0.355468; batch adversarial loss: 0.606996\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379019; batch adversarial loss: 0.552796\n",
      "epoch 156; iter: 0; batch classifier loss: 0.305846; batch adversarial loss: 0.605694\n",
      "epoch 157; iter: 0; batch classifier loss: 0.413181; batch adversarial loss: 0.560512\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425449; batch adversarial loss: 0.485369\n",
      "epoch 159; iter: 0; batch classifier loss: 0.386096; batch adversarial loss: 0.595641\n",
      "epoch 160; iter: 0; batch classifier loss: 0.324683; batch adversarial loss: 0.499084\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314755; batch adversarial loss: 0.489075\n",
      "epoch 162; iter: 0; batch classifier loss: 0.300776; batch adversarial loss: 0.578480\n",
      "epoch 163; iter: 0; batch classifier loss: 0.271411; batch adversarial loss: 0.572393\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358473; batch adversarial loss: 0.517306\n",
      "epoch 165; iter: 0; batch classifier loss: 0.414405; batch adversarial loss: 0.537740\n",
      "epoch 166; iter: 0; batch classifier loss: 0.345674; batch adversarial loss: 0.606310\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335983; batch adversarial loss: 0.466633\n",
      "epoch 168; iter: 0; batch classifier loss: 0.442783; batch adversarial loss: 0.569499\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304685; batch adversarial loss: 0.580124\n",
      "epoch 170; iter: 0; batch classifier loss: 0.320670; batch adversarial loss: 0.578768\n",
      "epoch 171; iter: 0; batch classifier loss: 0.323884; batch adversarial loss: 0.526784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.320731; batch adversarial loss: 0.494831\n",
      "epoch 173; iter: 0; batch classifier loss: 0.310909; batch adversarial loss: 0.604665\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390192; batch adversarial loss: 0.535650\n",
      "epoch 175; iter: 0; batch classifier loss: 0.300119; batch adversarial loss: 0.572090\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353384; batch adversarial loss: 0.553086\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316978; batch adversarial loss: 0.510262\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307974; batch adversarial loss: 0.570729\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339112; batch adversarial loss: 0.525613\n",
      "epoch 180; iter: 0; batch classifier loss: 0.275854; batch adversarial loss: 0.588323\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353572; batch adversarial loss: 0.528119\n",
      "epoch 182; iter: 0; batch classifier loss: 0.423799; batch adversarial loss: 0.484299\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353890; batch adversarial loss: 0.527646\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357482; batch adversarial loss: 0.544536\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311104; batch adversarial loss: 0.517771\n",
      "epoch 186; iter: 0; batch classifier loss: 0.441626; batch adversarial loss: 0.604942\n",
      "epoch 187; iter: 0; batch classifier loss: 0.449001; batch adversarial loss: 0.569054\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353250; batch adversarial loss: 0.578016\n",
      "epoch 189; iter: 0; batch classifier loss: 0.349565; batch adversarial loss: 0.551135\n",
      "epoch 190; iter: 0; batch classifier loss: 0.302811; batch adversarial loss: 0.564197\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306377; batch adversarial loss: 0.543643\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345193; batch adversarial loss: 0.612357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370967; batch adversarial loss: 0.577739\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354175; batch adversarial loss: 0.640626\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312826; batch adversarial loss: 0.510398\n",
      "epoch 196; iter: 0; batch classifier loss: 0.250302; batch adversarial loss: 0.579720\n",
      "epoch 197; iter: 0; batch classifier loss: 0.306763; batch adversarial loss: 0.552240\n",
      "epoch 198; iter: 0; batch classifier loss: 0.412060; batch adversarial loss: 0.465908\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334380; batch adversarial loss: 0.535685\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743062; batch adversarial loss: 0.685616\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595656; batch adversarial loss: 0.671335\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562264; batch adversarial loss: 0.625741\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549674; batch adversarial loss: 0.629654\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612471; batch adversarial loss: 0.619700\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582648; batch adversarial loss: 0.624480\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496153; batch adversarial loss: 0.579951\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530960; batch adversarial loss: 0.546542\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574932; batch adversarial loss: 0.619610\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513036; batch adversarial loss: 0.648097\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592421; batch adversarial loss: 0.659983\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527902; batch adversarial loss: 0.643755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.550669; batch adversarial loss: 0.594187\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496487; batch adversarial loss: 0.576724\n",
      "epoch 14; iter: 0; batch classifier loss: 0.598476; batch adversarial loss: 0.611560\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522990; batch adversarial loss: 0.649779\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519018; batch adversarial loss: 0.629793\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520411; batch adversarial loss: 0.575268\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518648; batch adversarial loss: 0.583591\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501109; batch adversarial loss: 0.542565\n",
      "epoch 20; iter: 0; batch classifier loss: 0.536558; batch adversarial loss: 0.552252\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516850; batch adversarial loss: 0.571510\n",
      "epoch 22; iter: 0; batch classifier loss: 0.527089; batch adversarial loss: 0.570815\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466712; batch adversarial loss: 0.537812\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507126; batch adversarial loss: 0.550160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533893; batch adversarial loss: 0.488787\n",
      "epoch 26; iter: 0; batch classifier loss: 0.421930; batch adversarial loss: 0.602327\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474392; batch adversarial loss: 0.539573\n",
      "epoch 28; iter: 0; batch classifier loss: 0.415377; batch adversarial loss: 0.522802\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451527; batch adversarial loss: 0.546447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490586; batch adversarial loss: 0.562467\n",
      "epoch 31; iter: 0; batch classifier loss: 0.529021; batch adversarial loss: 0.571029\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429185; batch adversarial loss: 0.528720\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441897; batch adversarial loss: 0.519452\n",
      "epoch 34; iter: 0; batch classifier loss: 0.375050; batch adversarial loss: 0.605209\n",
      "epoch 35; iter: 0; batch classifier loss: 0.557047; batch adversarial loss: 0.545215\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424984; batch adversarial loss: 0.562304\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429961; batch adversarial loss: 0.484513\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457170; batch adversarial loss: 0.562426\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474666; batch adversarial loss: 0.588607\n",
      "epoch 40; iter: 0; batch classifier loss: 0.375162; batch adversarial loss: 0.483770\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431339; batch adversarial loss: 0.500583\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433166; batch adversarial loss: 0.571102\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397986; batch adversarial loss: 0.500828\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438106; batch adversarial loss: 0.509959\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440454; batch adversarial loss: 0.588689\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503766; batch adversarial loss: 0.553798\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425620; batch adversarial loss: 0.587878\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411136; batch adversarial loss: 0.553325\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431919; batch adversarial loss: 0.562709\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427660; batch adversarial loss: 0.553044\n",
      "epoch 51; iter: 0; batch classifier loss: 0.480457; batch adversarial loss: 0.545499\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410881; batch adversarial loss: 0.500822\n",
      "epoch 53; iter: 0; batch classifier loss: 0.368368; batch adversarial loss: 0.536020\n",
      "epoch 54; iter: 0; batch classifier loss: 0.485741; batch adversarial loss: 0.561192\n",
      "epoch 55; iter: 0; batch classifier loss: 0.374701; batch adversarial loss: 0.580915\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420044; batch adversarial loss: 0.535809\n",
      "epoch 57; iter: 0; batch classifier loss: 0.427905; batch adversarial loss: 0.553326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.491035; batch adversarial loss: 0.552764\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374164; batch adversarial loss: 0.561851\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481888; batch adversarial loss: 0.455879\n",
      "epoch 61; iter: 0; batch classifier loss: 0.385840; batch adversarial loss: 0.544096\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382644; batch adversarial loss: 0.499677\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436736; batch adversarial loss: 0.544082\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420599; batch adversarial loss: 0.519176\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457933; batch adversarial loss: 0.527763\n",
      "epoch 66; iter: 0; batch classifier loss: 0.537372; batch adversarial loss: 0.517886\n",
      "epoch 67; iter: 0; batch classifier loss: 0.485552; batch adversarial loss: 0.544272\n",
      "epoch 68; iter: 0; batch classifier loss: 0.453956; batch adversarial loss: 0.597831\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393086; batch adversarial loss: 0.535925\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420444; batch adversarial loss: 0.536179\n",
      "epoch 71; iter: 0; batch classifier loss: 0.503971; batch adversarial loss: 0.571391\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427596; batch adversarial loss: 0.509467\n",
      "epoch 73; iter: 0; batch classifier loss: 0.319681; batch adversarial loss: 0.564178\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378013; batch adversarial loss: 0.490207\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386133; batch adversarial loss: 0.573423\n",
      "epoch 76; iter: 0; batch classifier loss: 0.329557; batch adversarial loss: 0.543940\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407486; batch adversarial loss: 0.571082\n",
      "epoch 78; iter: 0; batch classifier loss: 0.339938; batch adversarial loss: 0.563483\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382391; batch adversarial loss: 0.500933\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437347; batch adversarial loss: 0.490843\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445862; batch adversarial loss: 0.561403\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381583; batch adversarial loss: 0.579708\n",
      "epoch 83; iter: 0; batch classifier loss: 0.433050; batch adversarial loss: 0.580240\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409341; batch adversarial loss: 0.464939\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397857; batch adversarial loss: 0.535165\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391556; batch adversarial loss: 0.553364\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402306; batch adversarial loss: 0.536445\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363174; batch adversarial loss: 0.527787\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407549; batch adversarial loss: 0.561534\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387960; batch adversarial loss: 0.536487\n",
      "epoch 91; iter: 0; batch classifier loss: 0.343678; batch adversarial loss: 0.634316\n",
      "epoch 92; iter: 0; batch classifier loss: 0.457273; batch adversarial loss: 0.589726\n",
      "epoch 93; iter: 0; batch classifier loss: 0.468439; batch adversarial loss: 0.545124\n",
      "epoch 94; iter: 0; batch classifier loss: 0.334097; batch adversarial loss: 0.545136\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428993; batch adversarial loss: 0.546264\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361814; batch adversarial loss: 0.555563\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393381; batch adversarial loss: 0.492209\n",
      "epoch 98; iter: 0; batch classifier loss: 0.393835; batch adversarial loss: 0.481962\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446873; batch adversarial loss: 0.553920\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349349; batch adversarial loss: 0.525641\n",
      "epoch 101; iter: 0; batch classifier loss: 0.354601; batch adversarial loss: 0.561022\n",
      "epoch 102; iter: 0; batch classifier loss: 0.420755; batch adversarial loss: 0.545747\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374279; batch adversarial loss: 0.501501\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391709; batch adversarial loss: 0.598312\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378270; batch adversarial loss: 0.554354\n",
      "epoch 106; iter: 0; batch classifier loss: 0.418015; batch adversarial loss: 0.516106\n",
      "epoch 107; iter: 0; batch classifier loss: 0.412696; batch adversarial loss: 0.606816\n",
      "epoch 108; iter: 0; batch classifier loss: 0.282373; batch adversarial loss: 0.517206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109; iter: 0; batch classifier loss: 0.396346; batch adversarial loss: 0.590252\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357311; batch adversarial loss: 0.517820\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353712; batch adversarial loss: 0.482536\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366434; batch adversarial loss: 0.563328\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401084; batch adversarial loss: 0.528882\n",
      "epoch 114; iter: 0; batch classifier loss: 0.409657; batch adversarial loss: 0.483229\n",
      "epoch 115; iter: 0; batch classifier loss: 0.385979; batch adversarial loss: 0.490598\n",
      "epoch 116; iter: 0; batch classifier loss: 0.332902; batch adversarial loss: 0.553438\n",
      "epoch 117; iter: 0; batch classifier loss: 0.375034; batch adversarial loss: 0.535669\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333875; batch adversarial loss: 0.546087\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369019; batch adversarial loss: 0.571717\n",
      "epoch 120; iter: 0; batch classifier loss: 0.454847; batch adversarial loss: 0.462879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412942; batch adversarial loss: 0.500628\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368430; batch adversarial loss: 0.553445\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414207; batch adversarial loss: 0.554960\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359194; batch adversarial loss: 0.551762\n",
      "epoch 125; iter: 0; batch classifier loss: 0.331413; batch adversarial loss: 0.572850\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392710; batch adversarial loss: 0.544171\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344997; batch adversarial loss: 0.535142\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362115; batch adversarial loss: 0.517160\n",
      "epoch 129; iter: 0; batch classifier loss: 0.459684; batch adversarial loss: 0.570726\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380408; batch adversarial loss: 0.590808\n",
      "epoch 131; iter: 0; batch classifier loss: 0.315977; batch adversarial loss: 0.652543\n",
      "epoch 132; iter: 0; batch classifier loss: 0.434574; batch adversarial loss: 0.570718\n",
      "epoch 133; iter: 0; batch classifier loss: 0.456001; batch adversarial loss: 0.527286\n",
      "epoch 134; iter: 0; batch classifier loss: 0.349685; batch adversarial loss: 0.525989\n",
      "epoch 135; iter: 0; batch classifier loss: 0.444391; batch adversarial loss: 0.489413\n",
      "epoch 136; iter: 0; batch classifier loss: 0.414456; batch adversarial loss: 0.554851\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414378; batch adversarial loss: 0.535025\n",
      "epoch 138; iter: 0; batch classifier loss: 0.440450; batch adversarial loss: 0.544149\n",
      "epoch 139; iter: 0; batch classifier loss: 0.323388; batch adversarial loss: 0.614365\n",
      "epoch 140; iter: 0; batch classifier loss: 0.445597; batch adversarial loss: 0.545390\n",
      "epoch 141; iter: 0; batch classifier loss: 0.306626; batch adversarial loss: 0.570872\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369438; batch adversarial loss: 0.520158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350570; batch adversarial loss: 0.563110\n",
      "epoch 144; iter: 0; batch classifier loss: 0.302014; batch adversarial loss: 0.498641\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366962; batch adversarial loss: 0.595561\n",
      "epoch 146; iter: 0; batch classifier loss: 0.372440; batch adversarial loss: 0.565752\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312659; batch adversarial loss: 0.643133\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279825; batch adversarial loss: 0.499007\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388491; batch adversarial loss: 0.510257\n",
      "epoch 150; iter: 0; batch classifier loss: 0.346276; batch adversarial loss: 0.543609\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344682; batch adversarial loss: 0.561835\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333943; batch adversarial loss: 0.615579\n",
      "epoch 153; iter: 0; batch classifier loss: 0.450650; batch adversarial loss: 0.579789\n",
      "epoch 154; iter: 0; batch classifier loss: 0.335142; batch adversarial loss: 0.587521\n",
      "epoch 155; iter: 0; batch classifier loss: 0.423449; batch adversarial loss: 0.562769\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376798; batch adversarial loss: 0.527366\n",
      "epoch 157; iter: 0; batch classifier loss: 0.395942; batch adversarial loss: 0.561246\n",
      "epoch 158; iter: 0; batch classifier loss: 0.411765; batch adversarial loss: 0.516701\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346295; batch adversarial loss: 0.544530\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368202; batch adversarial loss: 0.597222\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354924; batch adversarial loss: 0.534788\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366223; batch adversarial loss: 0.573778\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321945; batch adversarial loss: 0.641449\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374029; batch adversarial loss: 0.569425\n",
      "epoch 165; iter: 0; batch classifier loss: 0.364547; batch adversarial loss: 0.587507\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358901; batch adversarial loss: 0.518076\n",
      "epoch 167; iter: 0; batch classifier loss: 0.307173; batch adversarial loss: 0.489616\n",
      "epoch 168; iter: 0; batch classifier loss: 0.368954; batch adversarial loss: 0.492861\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330302; batch adversarial loss: 0.550426\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386633; batch adversarial loss: 0.545296\n",
      "epoch 171; iter: 0; batch classifier loss: 0.367630; batch adversarial loss: 0.560927\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317412; batch adversarial loss: 0.535701\n",
      "epoch 173; iter: 0; batch classifier loss: 0.409473; batch adversarial loss: 0.501122\n",
      "epoch 174; iter: 0; batch classifier loss: 0.406265; batch adversarial loss: 0.446692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.383519; batch adversarial loss: 0.535729\n",
      "epoch 176; iter: 0; batch classifier loss: 0.357699; batch adversarial loss: 0.528495\n",
      "epoch 177; iter: 0; batch classifier loss: 0.421605; batch adversarial loss: 0.535541\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357178; batch adversarial loss: 0.624971\n",
      "epoch 179; iter: 0; batch classifier loss: 0.295078; batch adversarial loss: 0.581439\n",
      "epoch 180; iter: 0; batch classifier loss: 0.425049; batch adversarial loss: 0.535707\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345323; batch adversarial loss: 0.650926\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367564; batch adversarial loss: 0.571583\n",
      "epoch 183; iter: 0; batch classifier loss: 0.290562; batch adversarial loss: 0.507430\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329209; batch adversarial loss: 0.463681\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384332; batch adversarial loss: 0.544580\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373080; batch adversarial loss: 0.641877\n",
      "epoch 187; iter: 0; batch classifier loss: 0.263282; batch adversarial loss: 0.642148\n",
      "epoch 188; iter: 0; batch classifier loss: 0.450562; batch adversarial loss: 0.541774\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343513; batch adversarial loss: 0.561858\n",
      "epoch 190; iter: 0; batch classifier loss: 0.392174; batch adversarial loss: 0.632489\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346966; batch adversarial loss: 0.544661\n",
      "epoch 192; iter: 0; batch classifier loss: 0.433273; batch adversarial loss: 0.564642\n",
      "epoch 193; iter: 0; batch classifier loss: 0.454884; batch adversarial loss: 0.608096\n",
      "epoch 194; iter: 0; batch classifier loss: 0.367712; batch adversarial loss: 0.564528\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361094; batch adversarial loss: 0.591113\n",
      "epoch 196; iter: 0; batch classifier loss: 0.298856; batch adversarial loss: 0.577657\n",
      "epoch 197; iter: 0; batch classifier loss: 0.308399; batch adversarial loss: 0.560922\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343531; batch adversarial loss: 0.544856\n",
      "epoch 199; iter: 0; batch classifier loss: 0.403953; batch adversarial loss: 0.588902\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723006; batch adversarial loss: 0.521261\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573689; batch adversarial loss: 0.716027\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613454; batch adversarial loss: 0.670453\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583847; batch adversarial loss: 0.765863\n",
      "epoch 4; iter: 0; batch classifier loss: 0.648406; batch adversarial loss: 0.607797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.552190; batch adversarial loss: 0.748975\n",
      "epoch 6; iter: 0; batch classifier loss: 0.649913; batch adversarial loss: 0.617023\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586006; batch adversarial loss: 0.599104\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451742; batch adversarial loss: 0.643244\n",
      "epoch 9; iter: 0; batch classifier loss: 0.642666; batch adversarial loss: 0.604451\n",
      "epoch 10; iter: 0; batch classifier loss: 0.637606; batch adversarial loss: 0.520085\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532487; batch adversarial loss: 0.591531\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511456; batch adversarial loss: 0.537724\n",
      "epoch 13; iter: 0; batch classifier loss: 0.619258; batch adversarial loss: 0.562154\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501525; batch adversarial loss: 0.577760\n",
      "epoch 15; iter: 0; batch classifier loss: 0.614302; batch adversarial loss: 0.578664\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554430; batch adversarial loss: 0.567386\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468512; batch adversarial loss: 0.547558\n",
      "epoch 18; iter: 0; batch classifier loss: 0.580147; batch adversarial loss: 0.499076\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514706; batch adversarial loss: 0.544301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513966; batch adversarial loss: 0.495337\n",
      "epoch 21; iter: 0; batch classifier loss: 0.561178; batch adversarial loss: 0.544039\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459872; batch adversarial loss: 0.514721\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508424; batch adversarial loss: 0.543381\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422665; batch adversarial loss: 0.505772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.447125; batch adversarial loss: 0.537433\n",
      "epoch 26; iter: 0; batch classifier loss: 0.411067; batch adversarial loss: 0.602715\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501867; batch adversarial loss: 0.561243\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404102; batch adversarial loss: 0.496507\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419276; batch adversarial loss: 0.526497\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436058; batch adversarial loss: 0.536071\n",
      "epoch 31; iter: 0; batch classifier loss: 0.509293; batch adversarial loss: 0.533949\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449197; batch adversarial loss: 0.546816\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497294; batch adversarial loss: 0.600657\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484026; batch adversarial loss: 0.484898\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481887; batch adversarial loss: 0.582673\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353418; batch adversarial loss: 0.496650\n",
      "epoch 37; iter: 0; batch classifier loss: 0.411529; batch adversarial loss: 0.508777\n",
      "epoch 38; iter: 0; batch classifier loss: 0.335483; batch adversarial loss: 0.623922\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404934; batch adversarial loss: 0.535182\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457612; batch adversarial loss: 0.544425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473375; batch adversarial loss: 0.573912\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496929; batch adversarial loss: 0.554684\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425506; batch adversarial loss: 0.555442\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484931; batch adversarial loss: 0.583091\n",
      "epoch 45; iter: 0; batch classifier loss: 0.388625; batch adversarial loss: 0.524571\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443345; batch adversarial loss: 0.515156\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404446; batch adversarial loss: 0.600555\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451669; batch adversarial loss: 0.473003\n",
      "epoch 49; iter: 0; batch classifier loss: 0.491428; batch adversarial loss: 0.546939\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435462; batch adversarial loss: 0.462945\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442048; batch adversarial loss: 0.475524\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386915; batch adversarial loss: 0.526969\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393632; batch adversarial loss: 0.526561\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440680; batch adversarial loss: 0.531853\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393729; batch adversarial loss: 0.540949\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428401; batch adversarial loss: 0.498970\n",
      "epoch 57; iter: 0; batch classifier loss: 0.388439; batch adversarial loss: 0.506470\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418966; batch adversarial loss: 0.552201\n",
      "epoch 59; iter: 0; batch classifier loss: 0.463381; batch adversarial loss: 0.549014\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382443; batch adversarial loss: 0.479853\n",
      "epoch 61; iter: 0; batch classifier loss: 0.434312; batch adversarial loss: 0.490563\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432191; batch adversarial loss: 0.617679\n",
      "epoch 63; iter: 0; batch classifier loss: 0.354762; batch adversarial loss: 0.460580\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354394; batch adversarial loss: 0.560726\n",
      "epoch 65; iter: 0; batch classifier loss: 0.439136; batch adversarial loss: 0.601382\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423247; batch adversarial loss: 0.536871\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405991; batch adversarial loss: 0.597370\n",
      "epoch 68; iter: 0; batch classifier loss: 0.532992; batch adversarial loss: 0.496627\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422095; batch adversarial loss: 0.518637\n",
      "epoch 70; iter: 0; batch classifier loss: 0.457060; batch adversarial loss: 0.552909\n",
      "epoch 71; iter: 0; batch classifier loss: 0.302131; batch adversarial loss: 0.485343\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430338; batch adversarial loss: 0.542413\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388273; batch adversarial loss: 0.535508\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424959; batch adversarial loss: 0.578876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.443552; batch adversarial loss: 0.627600\n",
      "epoch 76; iter: 0; batch classifier loss: 0.403539; batch adversarial loss: 0.510333\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360929; batch adversarial loss: 0.610426\n",
      "epoch 78; iter: 0; batch classifier loss: 0.468917; batch adversarial loss: 0.563931\n",
      "epoch 79; iter: 0; batch classifier loss: 0.431173; batch adversarial loss: 0.566192\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384561; batch adversarial loss: 0.592093\n",
      "epoch 81; iter: 0; batch classifier loss: 0.347514; batch adversarial loss: 0.555445\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419842; batch adversarial loss: 0.572251\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341693; batch adversarial loss: 0.535689\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381565; batch adversarial loss: 0.560095\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376513; batch adversarial loss: 0.557402\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387972; batch adversarial loss: 0.567324\n",
      "epoch 87; iter: 0; batch classifier loss: 0.336073; batch adversarial loss: 0.496526\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415369; batch adversarial loss: 0.531761\n",
      "epoch 89; iter: 0; batch classifier loss: 0.491749; batch adversarial loss: 0.579854\n",
      "epoch 90; iter: 0; batch classifier loss: 0.419645; batch adversarial loss: 0.582306\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455605; batch adversarial loss: 0.517846\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364873; batch adversarial loss: 0.528946\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367781; batch adversarial loss: 0.577331\n",
      "epoch 94; iter: 0; batch classifier loss: 0.470553; batch adversarial loss: 0.480440\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451052; batch adversarial loss: 0.496543\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403488; batch adversarial loss: 0.586401\n",
      "epoch 97; iter: 0; batch classifier loss: 0.424315; batch adversarial loss: 0.578604\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386564; batch adversarial loss: 0.555580\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364950; batch adversarial loss: 0.517269\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410447; batch adversarial loss: 0.546305\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430685; batch adversarial loss: 0.563031\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388217; batch adversarial loss: 0.580246\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397576; batch adversarial loss: 0.562896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.367030; batch adversarial loss: 0.566237\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362125; batch adversarial loss: 0.551020\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397517; batch adversarial loss: 0.590303\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354310; batch adversarial loss: 0.571688\n",
      "epoch 108; iter: 0; batch classifier loss: 0.365612; batch adversarial loss: 0.518768\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375969; batch adversarial loss: 0.517560\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349291; batch adversarial loss: 0.490462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353746; batch adversarial loss: 0.550586\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365110; batch adversarial loss: 0.546437\n",
      "epoch 113; iter: 0; batch classifier loss: 0.401955; batch adversarial loss: 0.556938\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364542; batch adversarial loss: 0.557005\n",
      "epoch 115; iter: 0; batch classifier loss: 0.496403; batch adversarial loss: 0.558961\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379485; batch adversarial loss: 0.604532\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408320; batch adversarial loss: 0.489006\n",
      "epoch 118; iter: 0; batch classifier loss: 0.325554; batch adversarial loss: 0.495448\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350477; batch adversarial loss: 0.635569\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364535; batch adversarial loss: 0.556973\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350737; batch adversarial loss: 0.494031\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383171; batch adversarial loss: 0.549668\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368295; batch adversarial loss: 0.530683\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395073; batch adversarial loss: 0.611918\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332007; batch adversarial loss: 0.537800\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438473; batch adversarial loss: 0.532704\n",
      "epoch 127; iter: 0; batch classifier loss: 0.349255; batch adversarial loss: 0.546308\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329172; batch adversarial loss: 0.581027\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428347; batch adversarial loss: 0.479250\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390762; batch adversarial loss: 0.577522\n",
      "epoch 131; iter: 0; batch classifier loss: 0.268007; batch adversarial loss: 0.541269\n",
      "epoch 132; iter: 0; batch classifier loss: 0.329053; batch adversarial loss: 0.451686\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391806; batch adversarial loss: 0.481231\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415120; batch adversarial loss: 0.629665\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364832; batch adversarial loss: 0.527381\n",
      "epoch 136; iter: 0; batch classifier loss: 0.427265; batch adversarial loss: 0.548880\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350569; batch adversarial loss: 0.524827\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338148; batch adversarial loss: 0.563191\n",
      "epoch 139; iter: 0; batch classifier loss: 0.476326; batch adversarial loss: 0.551852\n",
      "epoch 140; iter: 0; batch classifier loss: 0.398782; batch adversarial loss: 0.535105\n",
      "epoch 141; iter: 0; batch classifier loss: 0.431132; batch adversarial loss: 0.554034\n",
      "epoch 142; iter: 0; batch classifier loss: 0.504260; batch adversarial loss: 0.609675\n",
      "epoch 143; iter: 0; batch classifier loss: 0.468713; batch adversarial loss: 0.574722\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348680; batch adversarial loss: 0.554381\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374018; batch adversarial loss: 0.595423\n",
      "epoch 146; iter: 0; batch classifier loss: 0.408615; batch adversarial loss: 0.551047\n",
      "epoch 147; iter: 0; batch classifier loss: 0.425408; batch adversarial loss: 0.591447\n",
      "epoch 148; iter: 0; batch classifier loss: 0.402439; batch adversarial loss: 0.469485\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413154; batch adversarial loss: 0.485501\n",
      "epoch 150; iter: 0; batch classifier loss: 0.285031; batch adversarial loss: 0.523148\n",
      "epoch 151; iter: 0; batch classifier loss: 0.427942; batch adversarial loss: 0.571646\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356978; batch adversarial loss: 0.581402\n",
      "epoch 153; iter: 0; batch classifier loss: 0.407038; batch adversarial loss: 0.502255\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365732; batch adversarial loss: 0.469377\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397218; batch adversarial loss: 0.565529\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348014; batch adversarial loss: 0.507472\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315248; batch adversarial loss: 0.510613\n",
      "epoch 158; iter: 0; batch classifier loss: 0.293478; batch adversarial loss: 0.557715\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407860; batch adversarial loss: 0.543216\n",
      "epoch 160; iter: 0; batch classifier loss: 0.403342; batch adversarial loss: 0.543711\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358677; batch adversarial loss: 0.559939\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353789; batch adversarial loss: 0.563389\n",
      "epoch 163; iter: 0; batch classifier loss: 0.256540; batch adversarial loss: 0.510327\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377009; batch adversarial loss: 0.545801\n",
      "epoch 165; iter: 0; batch classifier loss: 0.365826; batch adversarial loss: 0.577821\n",
      "epoch 166; iter: 0; batch classifier loss: 0.387874; batch adversarial loss: 0.513865\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407240; batch adversarial loss: 0.600662\n",
      "epoch 168; iter: 0; batch classifier loss: 0.315610; batch adversarial loss: 0.526597\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352111; batch adversarial loss: 0.623723\n",
      "epoch 170; iter: 0; batch classifier loss: 0.285455; batch adversarial loss: 0.516056\n",
      "epoch 171; iter: 0; batch classifier loss: 0.279409; batch adversarial loss: 0.500724\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369129; batch adversarial loss: 0.530151\n",
      "epoch 173; iter: 0; batch classifier loss: 0.400326; batch adversarial loss: 0.520894\n",
      "epoch 174; iter: 0; batch classifier loss: 0.303013; batch adversarial loss: 0.524708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316038; batch adversarial loss: 0.531380\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366146; batch adversarial loss: 0.525151\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312185; batch adversarial loss: 0.544802\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368225; batch adversarial loss: 0.622384\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333183; batch adversarial loss: 0.502089\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331104; batch adversarial loss: 0.574940\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334226; batch adversarial loss: 0.479619\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314269; batch adversarial loss: 0.546751\n",
      "epoch 183; iter: 0; batch classifier loss: 0.300641; batch adversarial loss: 0.620250\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336146; batch adversarial loss: 0.513534\n",
      "epoch 185; iter: 0; batch classifier loss: 0.324787; batch adversarial loss: 0.453120\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377771; batch adversarial loss: 0.552636\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371393; batch adversarial loss: 0.492387\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314786; batch adversarial loss: 0.507883\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385654; batch adversarial loss: 0.527136\n",
      "epoch 190; iter: 0; batch classifier loss: 0.245495; batch adversarial loss: 0.497390\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362505; batch adversarial loss: 0.636159\n",
      "epoch 192; iter: 0; batch classifier loss: 0.421574; batch adversarial loss: 0.574558\n",
      "epoch 193; iter: 0; batch classifier loss: 0.358611; batch adversarial loss: 0.563091\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336487; batch adversarial loss: 0.576950\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346442; batch adversarial loss: 0.549253\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353012; batch adversarial loss: 0.542704\n",
      "epoch 197; iter: 0; batch classifier loss: 0.389645; batch adversarial loss: 0.468828\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350052; batch adversarial loss: 0.514423\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380917; batch adversarial loss: 0.465720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.734549; batch adversarial loss: 0.619309\n",
      "epoch 1; iter: 0; batch classifier loss: 0.730001; batch adversarial loss: 0.670241\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649650; batch adversarial loss: 0.641334\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652800; batch adversarial loss: 0.660402\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601509; batch adversarial loss: 0.674077\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576673; batch adversarial loss: 0.681356\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518131; batch adversarial loss: 0.626692\n",
      "epoch 7; iter: 0; batch classifier loss: 0.608582; batch adversarial loss: 0.659135\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544365; batch adversarial loss: 0.632842\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542960; batch adversarial loss: 0.624801\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531450; batch adversarial loss: 0.574321\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552924; batch adversarial loss: 0.571897\n",
      "epoch 12; iter: 0; batch classifier loss: 0.541437; batch adversarial loss: 0.597174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538846; batch adversarial loss: 0.649709\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502741; batch adversarial loss: 0.614121\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526264; batch adversarial loss: 0.495058\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506586; batch adversarial loss: 0.460392\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557852; batch adversarial loss: 0.546282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.495209; batch adversarial loss: 0.588602\n",
      "epoch 19; iter: 0; batch classifier loss: 0.552254; batch adversarial loss: 0.532817\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525509; batch adversarial loss: 0.580923\n",
      "epoch 21; iter: 0; batch classifier loss: 0.463541; batch adversarial loss: 0.520333\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493552; batch adversarial loss: 0.522941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507413; batch adversarial loss: 0.607200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524499; batch adversarial loss: 0.589176\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471056; batch adversarial loss: 0.605455\n",
      "epoch 26; iter: 0; batch classifier loss: 0.528582; batch adversarial loss: 0.565259\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446773; batch adversarial loss: 0.563635\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507064; batch adversarial loss: 0.504516\n",
      "epoch 29; iter: 0; batch classifier loss: 0.417542; batch adversarial loss: 0.562450\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476406; batch adversarial loss: 0.492883\n",
      "epoch 31; iter: 0; batch classifier loss: 0.478680; batch adversarial loss: 0.519576\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470207; batch adversarial loss: 0.527173\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464547; batch adversarial loss: 0.544539\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392858; batch adversarial loss: 0.527373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469423; batch adversarial loss: 0.545360\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481329; batch adversarial loss: 0.580814\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480424; batch adversarial loss: 0.570743\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458981; batch adversarial loss: 0.554073\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455980; batch adversarial loss: 0.580369\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442849; batch adversarial loss: 0.481369\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416644; batch adversarial loss: 0.499612\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420323; batch adversarial loss: 0.597708\n",
      "epoch 43; iter: 0; batch classifier loss: 0.529338; batch adversarial loss: 0.525516\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439028; batch adversarial loss: 0.580450\n",
      "epoch 45; iter: 0; batch classifier loss: 0.450343; batch adversarial loss: 0.507004\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469941; batch adversarial loss: 0.488915\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450650; batch adversarial loss: 0.547289\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456178; batch adversarial loss: 0.527839\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396832; batch adversarial loss: 0.515474\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427981; batch adversarial loss: 0.553468\n",
      "epoch 51; iter: 0; batch classifier loss: 0.359601; batch adversarial loss: 0.502305\n",
      "epoch 52; iter: 0; batch classifier loss: 0.496259; batch adversarial loss: 0.536988\n",
      "epoch 53; iter: 0; batch classifier loss: 0.372046; batch adversarial loss: 0.570887\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462561; batch adversarial loss: 0.624840\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426432; batch adversarial loss: 0.536288\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439600; batch adversarial loss: 0.535499\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429898; batch adversarial loss: 0.490336\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426584; batch adversarial loss: 0.571378\n",
      "epoch 59; iter: 0; batch classifier loss: 0.493434; batch adversarial loss: 0.608168\n",
      "epoch 60; iter: 0; batch classifier loss: 0.492932; batch adversarial loss: 0.499717\n",
      "epoch 61; iter: 0; batch classifier loss: 0.360236; batch adversarial loss: 0.606980\n",
      "epoch 62; iter: 0; batch classifier loss: 0.431434; batch adversarial loss: 0.579728\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387618; batch adversarial loss: 0.561692\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374085; batch adversarial loss: 0.499911\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410928; batch adversarial loss: 0.481498\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419873; batch adversarial loss: 0.589105\n",
      "epoch 67; iter: 0; batch classifier loss: 0.375312; batch adversarial loss: 0.517505\n",
      "epoch 68; iter: 0; batch classifier loss: 0.362158; batch adversarial loss: 0.580783\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392464; batch adversarial loss: 0.517444\n",
      "epoch 70; iter: 0; batch classifier loss: 0.498576; batch adversarial loss: 0.553554\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410341; batch adversarial loss: 0.562515\n",
      "epoch 72; iter: 0; batch classifier loss: 0.447468; batch adversarial loss: 0.553573\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379789; batch adversarial loss: 0.535288\n",
      "epoch 74; iter: 0; batch classifier loss: 0.341895; batch adversarial loss: 0.590392\n",
      "epoch 75; iter: 0; batch classifier loss: 0.338908; batch adversarial loss: 0.544465\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367402; batch adversarial loss: 0.553449\n",
      "epoch 77; iter: 0; batch classifier loss: 0.475698; batch adversarial loss: 0.499358\n",
      "epoch 78; iter: 0; batch classifier loss: 0.485006; batch adversarial loss: 0.499645\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439064; batch adversarial loss: 0.535392\n",
      "epoch 80; iter: 0; batch classifier loss: 0.479473; batch adversarial loss: 0.508451\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406379; batch adversarial loss: 0.589779\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420773; batch adversarial loss: 0.554063\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369486; batch adversarial loss: 0.544925\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398043; batch adversarial loss: 0.543566\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423871; batch adversarial loss: 0.535229\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391234; batch adversarial loss: 0.680713\n",
      "epoch 87; iter: 0; batch classifier loss: 0.315966; batch adversarial loss: 0.625762\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345008; batch adversarial loss: 0.634793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.439134; batch adversarial loss: 0.517309\n",
      "epoch 90; iter: 0; batch classifier loss: 0.338636; batch adversarial loss: 0.553247\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419415; batch adversarial loss: 0.571987\n",
      "epoch 92; iter: 0; batch classifier loss: 0.324166; batch adversarial loss: 0.544314\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380179; batch adversarial loss: 0.580683\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430027; batch adversarial loss: 0.571696\n",
      "epoch 95; iter: 0; batch classifier loss: 0.437528; batch adversarial loss: 0.599213\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366433; batch adversarial loss: 0.535579\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392913; batch adversarial loss: 0.535087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.381872; batch adversarial loss: 0.617243\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376746; batch adversarial loss: 0.598659\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416799; batch adversarial loss: 0.542668\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382024; batch adversarial loss: 0.473430\n",
      "epoch 102; iter: 0; batch classifier loss: 0.465346; batch adversarial loss: 0.553866\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378281; batch adversarial loss: 0.598720\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446793; batch adversarial loss: 0.508720\n",
      "epoch 105; iter: 0; batch classifier loss: 0.444345; batch adversarial loss: 0.580074\n",
      "epoch 106; iter: 0; batch classifier loss: 0.422263; batch adversarial loss: 0.499247\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406867; batch adversarial loss: 0.599180\n",
      "epoch 108; iter: 0; batch classifier loss: 0.320227; batch adversarial loss: 0.525551\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386700; batch adversarial loss: 0.671558\n",
      "epoch 110; iter: 0; batch classifier loss: 0.396867; batch adversarial loss: 0.518299\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382680; batch adversarial loss: 0.552811\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394420; batch adversarial loss: 0.500940\n",
      "epoch 113; iter: 0; batch classifier loss: 0.310630; batch adversarial loss: 0.572514\n",
      "epoch 114; iter: 0; batch classifier loss: 0.298236; batch adversarial loss: 0.606198\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383439; batch adversarial loss: 0.590948\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377000; batch adversarial loss: 0.463197\n",
      "epoch 117; iter: 0; batch classifier loss: 0.343665; batch adversarial loss: 0.543200\n",
      "epoch 118; iter: 0; batch classifier loss: 0.383859; batch adversarial loss: 0.561249\n",
      "epoch 119; iter: 0; batch classifier loss: 0.349478; batch adversarial loss: 0.453176\n",
      "epoch 120; iter: 0; batch classifier loss: 0.347908; batch adversarial loss: 0.618236\n",
      "epoch 121; iter: 0; batch classifier loss: 0.399170; batch adversarial loss: 0.553094\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352969; batch adversarial loss: 0.555031\n",
      "epoch 123; iter: 0; batch classifier loss: 0.450406; batch adversarial loss: 0.572805\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410858; batch adversarial loss: 0.636255\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376468; batch adversarial loss: 0.517069\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347010; batch adversarial loss: 0.498664\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370735; batch adversarial loss: 0.599169\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404252; batch adversarial loss: 0.608716\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361678; batch adversarial loss: 0.526796\n",
      "epoch 130; iter: 0; batch classifier loss: 0.415749; batch adversarial loss: 0.544708\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414901; batch adversarial loss: 0.544119\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347634; batch adversarial loss: 0.445041\n",
      "epoch 133; iter: 0; batch classifier loss: 0.310670; batch adversarial loss: 0.500137\n",
      "epoch 134; iter: 0; batch classifier loss: 0.394736; batch adversarial loss: 0.526513\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362349; batch adversarial loss: 0.598952\n",
      "epoch 136; iter: 0; batch classifier loss: 0.367767; batch adversarial loss: 0.515800\n",
      "epoch 137; iter: 0; batch classifier loss: 0.425520; batch adversarial loss: 0.634884\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346468; batch adversarial loss: 0.616377\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379755; batch adversarial loss: 0.569899\n",
      "epoch 140; iter: 0; batch classifier loss: 0.369868; batch adversarial loss: 0.614856\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343293; batch adversarial loss: 0.562541\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367569; batch adversarial loss: 0.536872\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381744; batch adversarial loss: 0.573546\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350787; batch adversarial loss: 0.599512\n",
      "epoch 145; iter: 0; batch classifier loss: 0.484300; batch adversarial loss: 0.581133\n",
      "epoch 146; iter: 0; batch classifier loss: 0.403207; batch adversarial loss: 0.590519\n",
      "epoch 147; iter: 0; batch classifier loss: 0.406704; batch adversarial loss: 0.571871\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373421; batch adversarial loss: 0.598796\n",
      "epoch 149; iter: 0; batch classifier loss: 0.378872; batch adversarial loss: 0.490663\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336466; batch adversarial loss: 0.534473\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334655; batch adversarial loss: 0.569749\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405200; batch adversarial loss: 0.516141\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344826; batch adversarial loss: 0.534498\n",
      "epoch 154; iter: 0; batch classifier loss: 0.272975; batch adversarial loss: 0.563439\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419165; batch adversarial loss: 0.532890\n",
      "epoch 156; iter: 0; batch classifier loss: 0.417875; batch adversarial loss: 0.573293\n",
      "epoch 157; iter: 0; batch classifier loss: 0.317651; batch adversarial loss: 0.581481\n",
      "epoch 158; iter: 0; batch classifier loss: 0.379980; batch adversarial loss: 0.561610\n",
      "epoch 159; iter: 0; batch classifier loss: 0.464777; batch adversarial loss: 0.590094\n",
      "epoch 160; iter: 0; batch classifier loss: 0.338413; batch adversarial loss: 0.544689\n",
      "epoch 161; iter: 0; batch classifier loss: 0.261130; batch adversarial loss: 0.570618\n",
      "epoch 162; iter: 0; batch classifier loss: 0.316048; batch adversarial loss: 0.571110\n",
      "epoch 163; iter: 0; batch classifier loss: 0.304712; batch adversarial loss: 0.527418\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409022; batch adversarial loss: 0.489828\n",
      "epoch 165; iter: 0; batch classifier loss: 0.328872; batch adversarial loss: 0.544630\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350895; batch adversarial loss: 0.517048\n",
      "epoch 167; iter: 0; batch classifier loss: 0.454712; batch adversarial loss: 0.571381\n",
      "epoch 168; iter: 0; batch classifier loss: 0.314010; batch adversarial loss: 0.462365\n",
      "epoch 169; iter: 0; batch classifier loss: 0.451096; batch adversarial loss: 0.580891\n",
      "epoch 170; iter: 0; batch classifier loss: 0.378997; batch adversarial loss: 0.489767\n",
      "epoch 171; iter: 0; batch classifier loss: 0.286007; batch adversarial loss: 0.571836\n",
      "epoch 172; iter: 0; batch classifier loss: 0.290958; batch adversarial loss: 0.644016\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354617; batch adversarial loss: 0.544410\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380397; batch adversarial loss: 0.599229\n",
      "epoch 175; iter: 0; batch classifier loss: 0.419939; batch adversarial loss: 0.580834\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353096; batch adversarial loss: 0.580979\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318089; batch adversarial loss: 0.553670\n",
      "epoch 178; iter: 0; batch classifier loss: 0.463219; batch adversarial loss: 0.562594\n",
      "epoch 179; iter: 0; batch classifier loss: 0.342457; batch adversarial loss: 0.472652\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362665; batch adversarial loss: 0.613815\n",
      "epoch 181; iter: 0; batch classifier loss: 0.425143; batch adversarial loss: 0.650158\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377729; batch adversarial loss: 0.491801\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332931; batch adversarial loss: 0.624967\n",
      "epoch 184; iter: 0; batch classifier loss: 0.467406; batch adversarial loss: 0.570760\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.489447\n",
      "epoch 186; iter: 0; batch classifier loss: 0.302211; batch adversarial loss: 0.598661\n",
      "epoch 187; iter: 0; batch classifier loss: 0.351607; batch adversarial loss: 0.545156\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387531; batch adversarial loss: 0.490136\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311371; batch adversarial loss: 0.562398\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306411; batch adversarial loss: 0.571929\n",
      "epoch 191; iter: 0; batch classifier loss: 0.299336; batch adversarial loss: 0.535571\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315670; batch adversarial loss: 0.517056\n",
      "epoch 193; iter: 0; batch classifier loss: 0.430625; batch adversarial loss: 0.526367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.313412; batch adversarial loss: 0.644805\n",
      "epoch 195; iter: 0; batch classifier loss: 0.278640; batch adversarial loss: 0.581133\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343855; batch adversarial loss: 0.590478\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315691; batch adversarial loss: 0.608200\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338412; batch adversarial loss: 0.607781\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331953; batch adversarial loss: 0.553279\n",
      "epoch 0; iter: 0; batch classifier loss: 0.815784; batch adversarial loss: 0.705954\n",
      "epoch 1; iter: 0; batch classifier loss: 0.654389; batch adversarial loss: 0.677831\n",
      "epoch 2; iter: 0; batch classifier loss: 0.629273; batch adversarial loss: 0.656431\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586906; batch adversarial loss: 0.615821\n",
      "epoch 4; iter: 0; batch classifier loss: 0.527868; batch adversarial loss: 0.624142\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528090; batch adversarial loss: 0.576069\n",
      "epoch 6; iter: 0; batch classifier loss: 0.500536; batch adversarial loss: 0.600848\n",
      "epoch 7; iter: 0; batch classifier loss: 0.479972; batch adversarial loss: 0.570242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511601; batch adversarial loss: 0.579817\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503365; batch adversarial loss: 0.620337\n",
      "epoch 10; iter: 0; batch classifier loss: 0.459287; batch adversarial loss: 0.565307\n",
      "epoch 11; iter: 0; batch classifier loss: 0.497908; batch adversarial loss: 0.659134\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469699; batch adversarial loss: 0.531891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574489; batch adversarial loss: 0.513704\n",
      "epoch 14; iter: 0; batch classifier loss: 0.581592; batch adversarial loss: 0.621977\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468648; batch adversarial loss: 0.529986\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543911; batch adversarial loss: 0.591274\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521116; batch adversarial loss: 0.571051\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492306; batch adversarial loss: 0.514245\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526462; batch adversarial loss: 0.578488\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454796; batch adversarial loss: 0.552916\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431160; batch adversarial loss: 0.521226\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458995; batch adversarial loss: 0.533340\n",
      "epoch 23; iter: 0; batch classifier loss: 0.536175; batch adversarial loss: 0.577214\n",
      "epoch 24; iter: 0; batch classifier loss: 0.373038; batch adversarial loss: 0.534981\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501904; batch adversarial loss: 0.548089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505070; batch adversarial loss: 0.555587\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484368; batch adversarial loss: 0.480793\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464816; batch adversarial loss: 0.546311\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449185; batch adversarial loss: 0.457324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428380; batch adversarial loss: 0.544301\n",
      "epoch 31; iter: 0; batch classifier loss: 0.526944; batch adversarial loss: 0.528449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473683; batch adversarial loss: 0.510080\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503409; batch adversarial loss: 0.529168\n",
      "epoch 34; iter: 0; batch classifier loss: 0.405406; batch adversarial loss: 0.509843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432292; batch adversarial loss: 0.579866\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445269; batch adversarial loss: 0.544762\n",
      "epoch 37; iter: 0; batch classifier loss: 0.353792; batch adversarial loss: 0.570827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418343; batch adversarial loss: 0.534548\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462847; batch adversarial loss: 0.463434\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458378; batch adversarial loss: 0.536570\n",
      "epoch 41; iter: 0; batch classifier loss: 0.442071; batch adversarial loss: 0.615768\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461018; batch adversarial loss: 0.508621\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439457; batch adversarial loss: 0.481585\n",
      "epoch 44; iter: 0; batch classifier loss: 0.340335; batch adversarial loss: 0.508451\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384009; batch adversarial loss: 0.535023\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419048; batch adversarial loss: 0.599875\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348947; batch adversarial loss: 0.582432\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451534; batch adversarial loss: 0.488113\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417584; batch adversarial loss: 0.508444\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451686; batch adversarial loss: 0.597893\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462590; batch adversarial loss: 0.524179\n",
      "epoch 52; iter: 0; batch classifier loss: 0.384888; batch adversarial loss: 0.641070\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432868; batch adversarial loss: 0.656450\n",
      "epoch 54; iter: 0; batch classifier loss: 0.378823; batch adversarial loss: 0.453699\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416595; batch adversarial loss: 0.517996\n",
      "epoch 56; iter: 0; batch classifier loss: 0.376061; batch adversarial loss: 0.570787\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410764; batch adversarial loss: 0.588984\n",
      "epoch 58; iter: 0; batch classifier loss: 0.476990; batch adversarial loss: 0.529431\n",
      "epoch 59; iter: 0; batch classifier loss: 0.421233; batch adversarial loss: 0.554307\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370928; batch adversarial loss: 0.600048\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409834; batch adversarial loss: 0.536208\n",
      "epoch 62; iter: 0; batch classifier loss: 0.469407; batch adversarial loss: 0.456438\n",
      "epoch 63; iter: 0; batch classifier loss: 0.453046; batch adversarial loss: 0.416105\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363007; batch adversarial loss: 0.555060\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391139; batch adversarial loss: 0.585496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389672; batch adversarial loss: 0.540535\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363377; batch adversarial loss: 0.458787\n",
      "epoch 68; iter: 0; batch classifier loss: 0.370968; batch adversarial loss: 0.561470\n",
      "epoch 69; iter: 0; batch classifier loss: 0.517528; batch adversarial loss: 0.587483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398033; batch adversarial loss: 0.523710\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449730; batch adversarial loss: 0.529763\n",
      "epoch 72; iter: 0; batch classifier loss: 0.441600; batch adversarial loss: 0.611249\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378414; batch adversarial loss: 0.526751\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435394; batch adversarial loss: 0.544964\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360787; batch adversarial loss: 0.559839\n",
      "epoch 76; iter: 0; batch classifier loss: 0.433710; batch adversarial loss: 0.530501\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441868; batch adversarial loss: 0.452917\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406852; batch adversarial loss: 0.546834\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375577; batch adversarial loss: 0.494980\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412764; batch adversarial loss: 0.530773\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431815; batch adversarial loss: 0.496122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.387525; batch adversarial loss: 0.517555\n",
      "epoch 83; iter: 0; batch classifier loss: 0.354210; batch adversarial loss: 0.619393\n",
      "epoch 84; iter: 0; batch classifier loss: 0.467266; batch adversarial loss: 0.486632\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380733; batch adversarial loss: 0.563265\n",
      "epoch 86; iter: 0; batch classifier loss: 0.480379; batch adversarial loss: 0.488925\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365697; batch adversarial loss: 0.497828\n",
      "epoch 88; iter: 0; batch classifier loss: 0.409883; batch adversarial loss: 0.600836\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329106; batch adversarial loss: 0.535586\n",
      "epoch 90; iter: 0; batch classifier loss: 0.284756; batch adversarial loss: 0.534272\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377180; batch adversarial loss: 0.535604\n",
      "epoch 92; iter: 0; batch classifier loss: 0.439426; batch adversarial loss: 0.477379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.302050; batch adversarial loss: 0.590711\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433081; batch adversarial loss: 0.495422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.336169; batch adversarial loss: 0.482285\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345014; batch adversarial loss: 0.493184\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363335; batch adversarial loss: 0.530967\n",
      "epoch 98; iter: 0; batch classifier loss: 0.437722; batch adversarial loss: 0.570116\n",
      "epoch 99; iter: 0; batch classifier loss: 0.478848; batch adversarial loss: 0.497461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.295354; batch adversarial loss: 0.517524\n",
      "epoch 101; iter: 0; batch classifier loss: 0.361473; batch adversarial loss: 0.523563\n",
      "epoch 102; iter: 0; batch classifier loss: 0.325931; batch adversarial loss: 0.487896\n",
      "epoch 103; iter: 0; batch classifier loss: 0.342722; batch adversarial loss: 0.559829\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399758; batch adversarial loss: 0.576061\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408378; batch adversarial loss: 0.538212\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377701; batch adversarial loss: 0.629444\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362397; batch adversarial loss: 0.545663\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387210; batch adversarial loss: 0.606577\n",
      "epoch 109; iter: 0; batch classifier loss: 0.334428; batch adversarial loss: 0.642402\n",
      "epoch 110; iter: 0; batch classifier loss: 0.364284; batch adversarial loss: 0.561526\n",
      "epoch 111; iter: 0; batch classifier loss: 0.311123; batch adversarial loss: 0.544210\n",
      "epoch 112; iter: 0; batch classifier loss: 0.399369; batch adversarial loss: 0.449747\n",
      "epoch 113; iter: 0; batch classifier loss: 0.318213; batch adversarial loss: 0.498230\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376124; batch adversarial loss: 0.463000\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405901; batch adversarial loss: 0.507898\n",
      "epoch 116; iter: 0; batch classifier loss: 0.396909; batch adversarial loss: 0.548651\n",
      "epoch 117; iter: 0; batch classifier loss: 0.403794; batch adversarial loss: 0.530481\n",
      "epoch 118; iter: 0; batch classifier loss: 0.419650; batch adversarial loss: 0.557826\n",
      "epoch 119; iter: 0; batch classifier loss: 0.504116; batch adversarial loss: 0.555818\n",
      "epoch 120; iter: 0; batch classifier loss: 0.425644; batch adversarial loss: 0.551690\n",
      "epoch 121; iter: 0; batch classifier loss: 0.323933; batch adversarial loss: 0.581644\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391755; batch adversarial loss: 0.537086\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401637; batch adversarial loss: 0.470919\n",
      "epoch 124; iter: 0; batch classifier loss: 0.402854; batch adversarial loss: 0.482104\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386650; batch adversarial loss: 0.524037\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401766; batch adversarial loss: 0.486897\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379472; batch adversarial loss: 0.581074\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370599; batch adversarial loss: 0.531671\n",
      "epoch 129; iter: 0; batch classifier loss: 0.457016; batch adversarial loss: 0.496316\n",
      "epoch 130; iter: 0; batch classifier loss: 0.457715; batch adversarial loss: 0.590345\n",
      "epoch 131; iter: 0; batch classifier loss: 0.491330; batch adversarial loss: 0.610793\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376225; batch adversarial loss: 0.508654\n",
      "epoch 133; iter: 0; batch classifier loss: 0.441162; batch adversarial loss: 0.513894\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400327; batch adversarial loss: 0.496480\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399855; batch adversarial loss: 0.503280\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375610; batch adversarial loss: 0.588572\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401553; batch adversarial loss: 0.480926\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367720; batch adversarial loss: 0.543424\n",
      "epoch 139; iter: 0; batch classifier loss: 0.425170; batch adversarial loss: 0.575001\n",
      "epoch 140; iter: 0; batch classifier loss: 0.415886; batch adversarial loss: 0.539239\n",
      "epoch 141; iter: 0; batch classifier loss: 0.301532; batch adversarial loss: 0.516856\n",
      "epoch 142; iter: 0; batch classifier loss: 0.309510; batch adversarial loss: 0.469110\n",
      "epoch 143; iter: 0; batch classifier loss: 0.421270; batch adversarial loss: 0.456792\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415604; batch adversarial loss: 0.543949\n",
      "epoch 145; iter: 0; batch classifier loss: 0.343239; batch adversarial loss: 0.550254\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334133; batch adversarial loss: 0.550041\n",
      "epoch 147; iter: 0; batch classifier loss: 0.313671; batch adversarial loss: 0.460778\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343398; batch adversarial loss: 0.513903\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363443; batch adversarial loss: 0.556215\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394015; batch adversarial loss: 0.532300\n",
      "epoch 151; iter: 0; batch classifier loss: 0.273463; batch adversarial loss: 0.503546\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370681; batch adversarial loss: 0.560399\n",
      "epoch 153; iter: 0; batch classifier loss: 0.305505; batch adversarial loss: 0.582040\n",
      "epoch 154; iter: 0; batch classifier loss: 0.427030; batch adversarial loss: 0.540923\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379119; batch adversarial loss: 0.497034\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334466; batch adversarial loss: 0.538504\n",
      "epoch 157; iter: 0; batch classifier loss: 0.282191; batch adversarial loss: 0.498228\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354002; batch adversarial loss: 0.520347\n",
      "epoch 159; iter: 0; batch classifier loss: 0.275697; batch adversarial loss: 0.573282\n",
      "epoch 160; iter: 0; batch classifier loss: 0.486283; batch adversarial loss: 0.469757\n",
      "epoch 161; iter: 0; batch classifier loss: 0.295001; batch adversarial loss: 0.533014\n",
      "epoch 162; iter: 0; batch classifier loss: 0.302906; batch adversarial loss: 0.543621\n",
      "epoch 163; iter: 0; batch classifier loss: 0.284166; batch adversarial loss: 0.534847\n",
      "epoch 164; iter: 0; batch classifier loss: 0.416285; batch adversarial loss: 0.456552\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371780; batch adversarial loss: 0.566622\n",
      "epoch 166; iter: 0; batch classifier loss: 0.453765; batch adversarial loss: 0.533350\n",
      "epoch 167; iter: 0; batch classifier loss: 0.286390; batch adversarial loss: 0.580846\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367003; batch adversarial loss: 0.508358\n",
      "epoch 169; iter: 0; batch classifier loss: 0.450201; batch adversarial loss: 0.585749\n",
      "epoch 170; iter: 0; batch classifier loss: 0.415848; batch adversarial loss: 0.527983\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366174; batch adversarial loss: 0.528964\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402938; batch adversarial loss: 0.455715\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403867; batch adversarial loss: 0.549211\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361394; batch adversarial loss: 0.529326\n",
      "epoch 175; iter: 0; batch classifier loss: 0.396198; batch adversarial loss: 0.610101\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396306; batch adversarial loss: 0.590950\n",
      "epoch 177; iter: 0; batch classifier loss: 0.272346; batch adversarial loss: 0.523204\n",
      "epoch 178; iter: 0; batch classifier loss: 0.310245; batch adversarial loss: 0.535388\n",
      "epoch 179; iter: 0; batch classifier loss: 0.363768; batch adversarial loss: 0.487309\n",
      "epoch 180; iter: 0; batch classifier loss: 0.470485; batch adversarial loss: 0.534961\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400808; batch adversarial loss: 0.570313\n",
      "epoch 182; iter: 0; batch classifier loss: 0.337134; batch adversarial loss: 0.630298\n",
      "epoch 183; iter: 0; batch classifier loss: 0.361458; batch adversarial loss: 0.507993\n",
      "epoch 184; iter: 0; batch classifier loss: 0.320349; batch adversarial loss: 0.535954\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377008; batch adversarial loss: 0.447563\n",
      "epoch 186; iter: 0; batch classifier loss: 0.346981; batch adversarial loss: 0.572970\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356117; batch adversarial loss: 0.543307\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423367; batch adversarial loss: 0.505076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.382724; batch adversarial loss: 0.553084\n",
      "epoch 190; iter: 0; batch classifier loss: 0.287822; batch adversarial loss: 0.559881\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323746; batch adversarial loss: 0.582844\n",
      "epoch 192; iter: 0; batch classifier loss: 0.355776; batch adversarial loss: 0.542687\n",
      "epoch 193; iter: 0; batch classifier loss: 0.419565; batch adversarial loss: 0.589516\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351455; batch adversarial loss: 0.527354\n",
      "epoch 195; iter: 0; batch classifier loss: 0.356194; batch adversarial loss: 0.537782\n",
      "epoch 196; iter: 0; batch classifier loss: 0.284161; batch adversarial loss: 0.546070\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357909; batch adversarial loss: 0.468471\n",
      "epoch 198; iter: 0; batch classifier loss: 0.421895; batch adversarial loss: 0.442164\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338606; batch adversarial loss: 0.564628\n",
      "epoch 0; iter: 0; batch classifier loss: 0.800874; batch adversarial loss: 0.672902\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603689; batch adversarial loss: 0.632862\n",
      "epoch 2; iter: 0; batch classifier loss: 0.523963; batch adversarial loss: 0.645397\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537605; batch adversarial loss: 0.617467\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564988; batch adversarial loss: 0.619498\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489061; batch adversarial loss: 0.594030\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577615; batch adversarial loss: 0.589273\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516041; batch adversarial loss: 0.557935\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598346; batch adversarial loss: 0.583251\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504299; batch adversarial loss: 0.618564\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533997; batch adversarial loss: 0.587045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523275; batch adversarial loss: 0.644435\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562348; batch adversarial loss: 0.597218\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461036; batch adversarial loss: 0.563037\n",
      "epoch 14; iter: 0; batch classifier loss: 0.582555; batch adversarial loss: 0.598515\n",
      "epoch 15; iter: 0; batch classifier loss: 0.605219; batch adversarial loss: 0.625484\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454634; batch adversarial loss: 0.564263\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510603; batch adversarial loss: 0.553226\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533235; batch adversarial loss: 0.545723\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464371; batch adversarial loss: 0.551760\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496906; batch adversarial loss: 0.593626\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526225; batch adversarial loss: 0.554758\n",
      "epoch 22; iter: 0; batch classifier loss: 0.518287; batch adversarial loss: 0.467560\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473078; batch adversarial loss: 0.482869\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514358; batch adversarial loss: 0.522602\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491083; batch adversarial loss: 0.552515\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466075; batch adversarial loss: 0.603806\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485603; batch adversarial loss: 0.572902\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432924; batch adversarial loss: 0.592114\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444014; batch adversarial loss: 0.556284\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467654; batch adversarial loss: 0.542521\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455519; batch adversarial loss: 0.581588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468569; batch adversarial loss: 0.526671\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471758; batch adversarial loss: 0.596246\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461158; batch adversarial loss: 0.493465\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460436; batch adversarial loss: 0.554386\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445870; batch adversarial loss: 0.528382\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483952; batch adversarial loss: 0.466894\n",
      "epoch 38; iter: 0; batch classifier loss: 0.511808; batch adversarial loss: 0.580504\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490282; batch adversarial loss: 0.579956\n",
      "epoch 40; iter: 0; batch classifier loss: 0.376363; batch adversarial loss: 0.545577\n",
      "epoch 41; iter: 0; batch classifier loss: 0.513174; batch adversarial loss: 0.535490\n",
      "epoch 42; iter: 0; batch classifier loss: 0.480979; batch adversarial loss: 0.519237\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463062; batch adversarial loss: 0.561221\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469832; batch adversarial loss: 0.519427\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435360; batch adversarial loss: 0.531256\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503141; batch adversarial loss: 0.484751\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459125; batch adversarial loss: 0.595566\n",
      "epoch 48; iter: 0; batch classifier loss: 0.441470; batch adversarial loss: 0.499905\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392509; batch adversarial loss: 0.571616\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453690; batch adversarial loss: 0.563270\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424549; batch adversarial loss: 0.564345\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410063; batch adversarial loss: 0.525702\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427017; batch adversarial loss: 0.579490\n",
      "epoch 54; iter: 0; batch classifier loss: 0.491477; batch adversarial loss: 0.580919\n",
      "epoch 55; iter: 0; batch classifier loss: 0.408380; batch adversarial loss: 0.546331\n",
      "epoch 56; iter: 0; batch classifier loss: 0.483298; batch adversarial loss: 0.598369\n",
      "epoch 57; iter: 0; batch classifier loss: 0.501480; batch adversarial loss: 0.599705\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419581; batch adversarial loss: 0.562920\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420885; batch adversarial loss: 0.572145\n",
      "epoch 60; iter: 0; batch classifier loss: 0.359560; batch adversarial loss: 0.535526\n",
      "epoch 61; iter: 0; batch classifier loss: 0.528979; batch adversarial loss: 0.535262\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382080; batch adversarial loss: 0.498774\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438985; batch adversarial loss: 0.526832\n",
      "epoch 64; iter: 0; batch classifier loss: 0.492477; batch adversarial loss: 0.508191\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425879; batch adversarial loss: 0.543834\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382053; batch adversarial loss: 0.643916\n",
      "epoch 67; iter: 0; batch classifier loss: 0.450859; batch adversarial loss: 0.586767\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382390; batch adversarial loss: 0.605324\n",
      "epoch 69; iter: 0; batch classifier loss: 0.391747; batch adversarial loss: 0.562488\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420138; batch adversarial loss: 0.556877\n",
      "epoch 71; iter: 0; batch classifier loss: 0.326528; batch adversarial loss: 0.551579\n",
      "epoch 72; iter: 0; batch classifier loss: 0.341027; batch adversarial loss: 0.552232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428118; batch adversarial loss: 0.508694\n",
      "epoch 74; iter: 0; batch classifier loss: 0.466416; batch adversarial loss: 0.586754\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385644; batch adversarial loss: 0.507692\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392585; batch adversarial loss: 0.473560\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412205; batch adversarial loss: 0.536835\n",
      "epoch 78; iter: 0; batch classifier loss: 0.343679; batch adversarial loss: 0.562492\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353095; batch adversarial loss: 0.526043\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383185; batch adversarial loss: 0.547399\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408491; batch adversarial loss: 0.509863\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443613; batch adversarial loss: 0.607570\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341452; batch adversarial loss: 0.516196\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374120; batch adversarial loss: 0.571219\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423365; batch adversarial loss: 0.581854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.319790; batch adversarial loss: 0.605499\n",
      "epoch 87; iter: 0; batch classifier loss: 0.389497; batch adversarial loss: 0.527605\n",
      "epoch 88; iter: 0; batch classifier loss: 0.453472; batch adversarial loss: 0.563702\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429246; batch adversarial loss: 0.481562\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351651; batch adversarial loss: 0.538743\n",
      "epoch 91; iter: 0; batch classifier loss: 0.401457; batch adversarial loss: 0.534907\n",
      "epoch 92; iter: 0; batch classifier loss: 0.416341; batch adversarial loss: 0.622964\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393886; batch adversarial loss: 0.589381\n",
      "epoch 94; iter: 0; batch classifier loss: 0.361685; batch adversarial loss: 0.608697\n",
      "epoch 95; iter: 0; batch classifier loss: 0.352927; batch adversarial loss: 0.587024\n",
      "epoch 96; iter: 0; batch classifier loss: 0.360432; batch adversarial loss: 0.526601\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338129; batch adversarial loss: 0.633974\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368599; batch adversarial loss: 0.537520\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406093; batch adversarial loss: 0.554603\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401411; batch adversarial loss: 0.534800\n",
      "epoch 101; iter: 0; batch classifier loss: 0.345810; batch adversarial loss: 0.545153\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437063; batch adversarial loss: 0.578514\n",
      "epoch 103; iter: 0; batch classifier loss: 0.357317; batch adversarial loss: 0.607500\n",
      "epoch 104; iter: 0; batch classifier loss: 0.426665; batch adversarial loss: 0.515478\n",
      "epoch 105; iter: 0; batch classifier loss: 0.474483; batch adversarial loss: 0.680542\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371662; batch adversarial loss: 0.523834\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402352; batch adversarial loss: 0.604688\n",
      "epoch 108; iter: 0; batch classifier loss: 0.392594; batch adversarial loss: 0.526325\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344809; batch adversarial loss: 0.580163\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357810; batch adversarial loss: 0.532184\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353723; batch adversarial loss: 0.545038\n",
      "epoch 112; iter: 0; batch classifier loss: 0.400333; batch adversarial loss: 0.606065\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357695; batch adversarial loss: 0.529932\n",
      "epoch 114; iter: 0; batch classifier loss: 0.308433; batch adversarial loss: 0.507666\n",
      "epoch 115; iter: 0; batch classifier loss: 0.357582; batch adversarial loss: 0.607446\n",
      "epoch 116; iter: 0; batch classifier loss: 0.445613; batch adversarial loss: 0.594234\n",
      "epoch 117; iter: 0; batch classifier loss: 0.458374; batch adversarial loss: 0.624309\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357912; batch adversarial loss: 0.517333\n",
      "epoch 119; iter: 0; batch classifier loss: 0.440144; batch adversarial loss: 0.615073\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369066; batch adversarial loss: 0.553512\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395264; batch adversarial loss: 0.593023\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376607; batch adversarial loss: 0.586134\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384719; batch adversarial loss: 0.564610\n",
      "epoch 124; iter: 0; batch classifier loss: 0.371047; batch adversarial loss: 0.552764\n",
      "epoch 125; iter: 0; batch classifier loss: 0.455523; batch adversarial loss: 0.504848\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387426; batch adversarial loss: 0.689665\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378664; batch adversarial loss: 0.470022\n",
      "epoch 128; iter: 0; batch classifier loss: 0.402530; batch adversarial loss: 0.539564\n",
      "epoch 129; iter: 0; batch classifier loss: 0.428924; batch adversarial loss: 0.582210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363233; batch adversarial loss: 0.529804\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345864; batch adversarial loss: 0.575371\n",
      "epoch 132; iter: 0; batch classifier loss: 0.356553; batch adversarial loss: 0.574057\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344458; batch adversarial loss: 0.559768\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369297; batch adversarial loss: 0.525316\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361232; batch adversarial loss: 0.541996\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387965; batch adversarial loss: 0.536657\n",
      "epoch 137; iter: 0; batch classifier loss: 0.364699; batch adversarial loss: 0.545258\n",
      "epoch 138; iter: 0; batch classifier loss: 0.431496; batch adversarial loss: 0.546891\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341880; batch adversarial loss: 0.657579\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327487; batch adversarial loss: 0.590365\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434643; batch adversarial loss: 0.554633\n",
      "epoch 142; iter: 0; batch classifier loss: 0.445994; batch adversarial loss: 0.618043\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394473; batch adversarial loss: 0.509489\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398450; batch adversarial loss: 0.506202\n",
      "epoch 145; iter: 0; batch classifier loss: 0.420578; batch adversarial loss: 0.676220\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410442; batch adversarial loss: 0.579034\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334408; batch adversarial loss: 0.563661\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350233; batch adversarial loss: 0.507957\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329979; batch adversarial loss: 0.538851\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349911; batch adversarial loss: 0.506001\n",
      "epoch 151; iter: 0; batch classifier loss: 0.416405; batch adversarial loss: 0.576962\n",
      "epoch 152; iter: 0; batch classifier loss: 0.397009; batch adversarial loss: 0.580454\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386229; batch adversarial loss: 0.553334\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412747; batch adversarial loss: 0.572102\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367615; batch adversarial loss: 0.626169\n",
      "epoch 156; iter: 0; batch classifier loss: 0.301102; batch adversarial loss: 0.503089\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350391; batch adversarial loss: 0.583874\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356088; batch adversarial loss: 0.567461\n",
      "epoch 159; iter: 0; batch classifier loss: 0.417577; batch adversarial loss: 0.520087\n",
      "epoch 160; iter: 0; batch classifier loss: 0.403947; batch adversarial loss: 0.614698\n",
      "epoch 161; iter: 0; batch classifier loss: 0.436099; batch adversarial loss: 0.558404\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328835; batch adversarial loss: 0.525749\n",
      "epoch 163; iter: 0; batch classifier loss: 0.283323; batch adversarial loss: 0.506313\n",
      "epoch 164; iter: 0; batch classifier loss: 0.464766; batch adversarial loss: 0.511040\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385929; batch adversarial loss: 0.536129\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350604; batch adversarial loss: 0.635439\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342816; batch adversarial loss: 0.510164\n",
      "epoch 168; iter: 0; batch classifier loss: 0.285857; batch adversarial loss: 0.561408\n",
      "epoch 169; iter: 0; batch classifier loss: 0.407140; batch adversarial loss: 0.499457\n",
      "epoch 170; iter: 0; batch classifier loss: 0.339208; batch adversarial loss: 0.530764\n",
      "epoch 171; iter: 0; batch classifier loss: 0.379943; batch adversarial loss: 0.464570\n",
      "epoch 172; iter: 0; batch classifier loss: 0.427007; batch adversarial loss: 0.566300\n",
      "epoch 173; iter: 0; batch classifier loss: 0.408513; batch adversarial loss: 0.601149\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395888; batch adversarial loss: 0.582278\n",
      "epoch 175; iter: 0; batch classifier loss: 0.283237; batch adversarial loss: 0.571101\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356737; batch adversarial loss: 0.617579\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321542; batch adversarial loss: 0.596024\n",
      "epoch 178; iter: 0; batch classifier loss: 0.392571; batch adversarial loss: 0.581804\n",
      "epoch 179; iter: 0; batch classifier loss: 0.314720; batch adversarial loss: 0.587849\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390395; batch adversarial loss: 0.456103\n",
      "epoch 181; iter: 0; batch classifier loss: 0.410401; batch adversarial loss: 0.535454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.329569; batch adversarial loss: 0.640400\n",
      "epoch 183; iter: 0; batch classifier loss: 0.420528; batch adversarial loss: 0.491042\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328179; batch adversarial loss: 0.511125\n",
      "epoch 185; iter: 0; batch classifier loss: 0.443535; batch adversarial loss: 0.549947\n",
      "epoch 186; iter: 0; batch classifier loss: 0.413070; batch adversarial loss: 0.608730\n",
      "epoch 187; iter: 0; batch classifier loss: 0.383275; batch adversarial loss: 0.483799\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346699; batch adversarial loss: 0.535826\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370839; batch adversarial loss: 0.598302\n",
      "epoch 190; iter: 0; batch classifier loss: 0.400139; batch adversarial loss: 0.538418\n",
      "epoch 191; iter: 0; batch classifier loss: 0.375716; batch adversarial loss: 0.527423\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362433; batch adversarial loss: 0.550486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.467167; batch adversarial loss: 0.590508\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362536; batch adversarial loss: 0.607336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.402619; batch adversarial loss: 0.586730\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326147; batch adversarial loss: 0.525212\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315278; batch adversarial loss: 0.574336\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390743; batch adversarial loss: 0.569182\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367606; batch adversarial loss: 0.491270\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698377; batch adversarial loss: 0.736457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647879; batch adversarial loss: 0.671933\n",
      "epoch 2; iter: 0; batch classifier loss: 0.555954; batch adversarial loss: 0.641547\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610975; batch adversarial loss: 0.619436\n",
      "epoch 4; iter: 0; batch classifier loss: 0.516799; batch adversarial loss: 0.621376\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553779; batch adversarial loss: 0.606300\n",
      "epoch 6; iter: 0; batch classifier loss: 0.566991; batch adversarial loss: 0.611224\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523851; batch adversarial loss: 0.570796\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573541; batch adversarial loss: 0.594709\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506513; batch adversarial loss: 0.603314\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460623; batch adversarial loss: 0.583728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538994; batch adversarial loss: 0.602634\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551834; batch adversarial loss: 0.587819\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550641; batch adversarial loss: 0.536308\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521354; batch adversarial loss: 0.573264\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541742; batch adversarial loss: 0.493803\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529634; batch adversarial loss: 0.550605\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486800; batch adversarial loss: 0.542878\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492971; batch adversarial loss: 0.545709\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542267; batch adversarial loss: 0.583453\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441397; batch adversarial loss: 0.472219\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499563; batch adversarial loss: 0.510435\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471971; batch adversarial loss: 0.504525\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457542; batch adversarial loss: 0.524364\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448918; batch adversarial loss: 0.519016\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475828; batch adversarial loss: 0.511907\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505612; batch adversarial loss: 0.612013\n",
      "epoch 27; iter: 0; batch classifier loss: 0.519868; batch adversarial loss: 0.516938\n",
      "epoch 28; iter: 0; batch classifier loss: 0.447090; batch adversarial loss: 0.536825\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479454; batch adversarial loss: 0.662568\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425345; batch adversarial loss: 0.555141\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499260; batch adversarial loss: 0.676308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.411720; batch adversarial loss: 0.527728\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448111; batch adversarial loss: 0.583270\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480957; batch adversarial loss: 0.529228\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488627; batch adversarial loss: 0.579477\n",
      "epoch 36; iter: 0; batch classifier loss: 0.565797; batch adversarial loss: 0.563951\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459569; batch adversarial loss: 0.501549\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467860; batch adversarial loss: 0.563144\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504473; batch adversarial loss: 0.597934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396609; batch adversarial loss: 0.509133\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428393; batch adversarial loss: 0.518373\n",
      "epoch 42; iter: 0; batch classifier loss: 0.363943; batch adversarial loss: 0.510578\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442334; batch adversarial loss: 0.508682\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492013; batch adversarial loss: 0.526484\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464228; batch adversarial loss: 0.553845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423097; batch adversarial loss: 0.571444\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409461; batch adversarial loss: 0.517574\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430198; batch adversarial loss: 0.553579\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430972; batch adversarial loss: 0.489615\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400773; batch adversarial loss: 0.526333\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433177; batch adversarial loss: 0.544536\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400542; batch adversarial loss: 0.626556\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402166; batch adversarial loss: 0.581033\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409050; batch adversarial loss: 0.599302\n",
      "epoch 55; iter: 0; batch classifier loss: 0.506996; batch adversarial loss: 0.535129\n",
      "epoch 56; iter: 0; batch classifier loss: 0.476701; batch adversarial loss: 0.516974\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405236; batch adversarial loss: 0.590257\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384516; batch adversarial loss: 0.581097\n",
      "epoch 59; iter: 0; batch classifier loss: 0.423857; batch adversarial loss: 0.572447\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398655; batch adversarial loss: 0.461701\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429009; batch adversarial loss: 0.562362\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446109; batch adversarial loss: 0.572057\n",
      "epoch 63; iter: 0; batch classifier loss: 0.437900; batch adversarial loss: 0.525225\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442083; batch adversarial loss: 0.526179\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389476; batch adversarial loss: 0.526070\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418870; batch adversarial loss: 0.562678\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423011; batch adversarial loss: 0.489199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434585; batch adversarial loss: 0.553196\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420111; batch adversarial loss: 0.572316\n",
      "epoch 70; iter: 0; batch classifier loss: 0.491592; batch adversarial loss: 0.507958\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365954; batch adversarial loss: 0.608622\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382338; batch adversarial loss: 0.516639\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425855; batch adversarial loss: 0.581471\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408790; batch adversarial loss: 0.488473\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360866; batch adversarial loss: 0.553845\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454119; batch adversarial loss: 0.470799\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388604; batch adversarial loss: 0.635608\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395570; batch adversarial loss: 0.534480\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397953; batch adversarial loss: 0.525959\n",
      "epoch 80; iter: 0; batch classifier loss: 0.469049; batch adversarial loss: 0.479111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.377422; batch adversarial loss: 0.589973\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415600; batch adversarial loss: 0.608708\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365185; batch adversarial loss: 0.526388\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356592; batch adversarial loss: 0.517096\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362847; batch adversarial loss: 0.562576\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401053; batch adversarial loss: 0.526351\n",
      "epoch 87; iter: 0; batch classifier loss: 0.491026; batch adversarial loss: 0.461009\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430072; batch adversarial loss: 0.489856\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374427; batch adversarial loss: 0.554208\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444347; batch adversarial loss: 0.498714\n",
      "epoch 91; iter: 0; batch classifier loss: 0.430344; batch adversarial loss: 0.499221\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434998; batch adversarial loss: 0.526067\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368804; batch adversarial loss: 0.508419\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336008; batch adversarial loss: 0.524808\n",
      "epoch 95; iter: 0; batch classifier loss: 0.468546; batch adversarial loss: 0.581657\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355596; batch adversarial loss: 0.544312\n",
      "epoch 97; iter: 0; batch classifier loss: 0.408493; batch adversarial loss: 0.534801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367826; batch adversarial loss: 0.507323\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395099; batch adversarial loss: 0.497942\n",
      "epoch 100; iter: 0; batch classifier loss: 0.344396; batch adversarial loss: 0.618080\n",
      "epoch 101; iter: 0; batch classifier loss: 0.462061; batch adversarial loss: 0.453218\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372298; batch adversarial loss: 0.534959\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379115; batch adversarial loss: 0.535068\n",
      "epoch 104; iter: 0; batch classifier loss: 0.448331; batch adversarial loss: 0.590799\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424004; batch adversarial loss: 0.517443\n",
      "epoch 106; iter: 0; batch classifier loss: 0.321779; batch adversarial loss: 0.507268\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356000; batch adversarial loss: 0.535422\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367233; batch adversarial loss: 0.553000\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381736; batch adversarial loss: 0.627592\n",
      "epoch 110; iter: 0; batch classifier loss: 0.410279; batch adversarial loss: 0.581565\n",
      "epoch 111; iter: 0; batch classifier loss: 0.340221; batch adversarial loss: 0.461472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.377790; batch adversarial loss: 0.507288\n",
      "epoch 113; iter: 0; batch classifier loss: 0.359884; batch adversarial loss: 0.536494\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389532; batch adversarial loss: 0.470716\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326151; batch adversarial loss: 0.507068\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343360; batch adversarial loss: 0.535987\n",
      "epoch 117; iter: 0; batch classifier loss: 0.440507; batch adversarial loss: 0.553421\n",
      "epoch 118; iter: 0; batch classifier loss: 0.397138; batch adversarial loss: 0.553959\n",
      "epoch 119; iter: 0; batch classifier loss: 0.336601; batch adversarial loss: 0.554072\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378605; batch adversarial loss: 0.545246\n",
      "epoch 121; iter: 0; batch classifier loss: 0.318636; batch adversarial loss: 0.526277\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351152; batch adversarial loss: 0.582448\n",
      "epoch 123; iter: 0; batch classifier loss: 0.452118; batch adversarial loss: 0.526579\n",
      "epoch 124; iter: 0; batch classifier loss: 0.362073; batch adversarial loss: 0.589119\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412355; batch adversarial loss: 0.562750\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380766; batch adversarial loss: 0.682484\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407581; batch adversarial loss: 0.572780\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362860; batch adversarial loss: 0.543978\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391968; batch adversarial loss: 0.544356\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354824; batch adversarial loss: 0.554877\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372420; batch adversarial loss: 0.536584\n",
      "epoch 132; iter: 0; batch classifier loss: 0.418119; batch adversarial loss: 0.552576\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395621; batch adversarial loss: 0.562479\n",
      "epoch 134; iter: 0; batch classifier loss: 0.299490; batch adversarial loss: 0.610433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320150; batch adversarial loss: 0.498666\n",
      "epoch 136; iter: 0; batch classifier loss: 0.335539; batch adversarial loss: 0.599004\n",
      "epoch 137; iter: 0; batch classifier loss: 0.295609; batch adversarial loss: 0.526106\n",
      "epoch 138; iter: 0; batch classifier loss: 0.429971; batch adversarial loss: 0.599502\n",
      "epoch 139; iter: 0; batch classifier loss: 0.345869; batch adversarial loss: 0.579308\n",
      "epoch 140; iter: 0; batch classifier loss: 0.414759; batch adversarial loss: 0.515508\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380403; batch adversarial loss: 0.498479\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383175; batch adversarial loss: 0.544355\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408327; batch adversarial loss: 0.534422\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409453; batch adversarial loss: 0.487154\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362760; batch adversarial loss: 0.553535\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367865; batch adversarial loss: 0.536200\n",
      "epoch 147; iter: 0; batch classifier loss: 0.445094; batch adversarial loss: 0.544184\n",
      "epoch 148; iter: 0; batch classifier loss: 0.428528; batch adversarial loss: 0.508357\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368850; batch adversarial loss: 0.591473\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334457; batch adversarial loss: 0.563713\n",
      "epoch 151; iter: 0; batch classifier loss: 0.449095; batch adversarial loss: 0.490425\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370327; batch adversarial loss: 0.517655\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355747; batch adversarial loss: 0.609354\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369945; batch adversarial loss: 0.536493\n",
      "epoch 155; iter: 0; batch classifier loss: 0.309348; batch adversarial loss: 0.590011\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377431; batch adversarial loss: 0.527063\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379240; batch adversarial loss: 0.608725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387639; batch adversarial loss: 0.498263\n",
      "epoch 159; iter: 0; batch classifier loss: 0.337576; batch adversarial loss: 0.608335\n",
      "epoch 160; iter: 0; batch classifier loss: 0.418829; batch adversarial loss: 0.628074\n",
      "epoch 161; iter: 0; batch classifier loss: 0.382692; batch adversarial loss: 0.525975\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397670; batch adversarial loss: 0.582126\n",
      "epoch 163; iter: 0; batch classifier loss: 0.391994; batch adversarial loss: 0.553171\n",
      "epoch 164; iter: 0; batch classifier loss: 0.439409; batch adversarial loss: 0.590855\n",
      "epoch 165; iter: 0; batch classifier loss: 0.316976; batch adversarial loss: 0.518014\n",
      "epoch 166; iter: 0; batch classifier loss: 0.381300; batch adversarial loss: 0.498502\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371960; batch adversarial loss: 0.424591\n",
      "epoch 168; iter: 0; batch classifier loss: 0.346095; batch adversarial loss: 0.517137\n",
      "epoch 169; iter: 0; batch classifier loss: 0.421173; batch adversarial loss: 0.478482\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362975; batch adversarial loss: 0.570545\n",
      "epoch 171; iter: 0; batch classifier loss: 0.310215; batch adversarial loss: 0.435141\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368836; batch adversarial loss: 0.525419\n",
      "epoch 173; iter: 0; batch classifier loss: 0.353319; batch adversarial loss: 0.525006\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326731; batch adversarial loss: 0.508295\n",
      "epoch 175; iter: 0; batch classifier loss: 0.442373; batch adversarial loss: 0.572251\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368207; batch adversarial loss: 0.453652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.382080; batch adversarial loss: 0.555182\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361288; batch adversarial loss: 0.499142\n",
      "epoch 179; iter: 0; batch classifier loss: 0.359690; batch adversarial loss: 0.590093\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337763; batch adversarial loss: 0.543845\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420223; batch adversarial loss: 0.534242\n",
      "epoch 182; iter: 0; batch classifier loss: 0.328374; batch adversarial loss: 0.582085\n",
      "epoch 183; iter: 0; batch classifier loss: 0.347032; batch adversarial loss: 0.525908\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346260; batch adversarial loss: 0.526209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.309636; batch adversarial loss: 0.507808\n",
      "epoch 186; iter: 0; batch classifier loss: 0.369276; batch adversarial loss: 0.508501\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346793; batch adversarial loss: 0.535668\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302694; batch adversarial loss: 0.553084\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365375; batch adversarial loss: 0.516112\n",
      "epoch 190; iter: 0; batch classifier loss: 0.355481; batch adversarial loss: 0.572449\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360809; batch adversarial loss: 0.536513\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361266; batch adversarial loss: 0.597948\n",
      "epoch 193; iter: 0; batch classifier loss: 0.385761; batch adversarial loss: 0.570889\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403972; batch adversarial loss: 0.563003\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338887; batch adversarial loss: 0.554087\n",
      "epoch 196; iter: 0; batch classifier loss: 0.307549; batch adversarial loss: 0.526164\n",
      "epoch 197; iter: 0; batch classifier loss: 0.323017; batch adversarial loss: 0.526779\n",
      "epoch 198; iter: 0; batch classifier loss: 0.464892; batch adversarial loss: 0.619050\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397987; batch adversarial loss: 0.515829\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676111; batch adversarial loss: 0.924738\n",
      "epoch 1; iter: 0; batch classifier loss: 0.871588; batch adversarial loss: 1.139977\n",
      "epoch 2; iter: 0; batch classifier loss: 1.103161; batch adversarial loss: 1.143332\n",
      "epoch 3; iter: 0; batch classifier loss: 0.998029; batch adversarial loss: 1.038760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.943512; batch adversarial loss: 0.891457\n",
      "epoch 5; iter: 0; batch classifier loss: 0.879230; batch adversarial loss: 0.846730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.926599; batch adversarial loss: 0.830990\n",
      "epoch 7; iter: 0; batch classifier loss: 0.764928; batch adversarial loss: 0.754528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.755433; batch adversarial loss: 0.702799\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627123; batch adversarial loss: 0.633548\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511663; batch adversarial loss: 0.594011\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548146; batch adversarial loss: 0.610449\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562494; batch adversarial loss: 0.627053\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486060; batch adversarial loss: 0.607303\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471512; batch adversarial loss: 0.565928\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508766; batch adversarial loss: 0.617316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561829; batch adversarial loss: 0.573243\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451058; batch adversarial loss: 0.552337\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487278; batch adversarial loss: 0.581207\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451543; batch adversarial loss: 0.535722\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492048; batch adversarial loss: 0.597053\n",
      "epoch 21; iter: 0; batch classifier loss: 0.613099; batch adversarial loss: 0.573344\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555310; batch adversarial loss: 0.567460\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470589; batch adversarial loss: 0.568933\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509088; batch adversarial loss: 0.534167\n",
      "epoch 25; iter: 0; batch classifier loss: 0.498753; batch adversarial loss: 0.529610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.538997; batch adversarial loss: 0.577559\n",
      "epoch 27; iter: 0; batch classifier loss: 0.512397; batch adversarial loss: 0.555416\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440324; batch adversarial loss: 0.471263\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488300; batch adversarial loss: 0.666934\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453111; batch adversarial loss: 0.604607\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432988; batch adversarial loss: 0.558606\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479903; batch adversarial loss: 0.592392\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463672; batch adversarial loss: 0.598680\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456043; batch adversarial loss: 0.545162\n",
      "epoch 35; iter: 0; batch classifier loss: 0.505149; batch adversarial loss: 0.567893\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470151; batch adversarial loss: 0.586552\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432299; batch adversarial loss: 0.629083\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450984; batch adversarial loss: 0.510139\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500381; batch adversarial loss: 0.542273\n",
      "epoch 40; iter: 0; batch classifier loss: 0.508940; batch adversarial loss: 0.618470\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434501; batch adversarial loss: 0.506751\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464106; batch adversarial loss: 0.547881\n",
      "epoch 43; iter: 0; batch classifier loss: 0.508333; batch adversarial loss: 0.592829\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409299; batch adversarial loss: 0.586816\n",
      "epoch 45; iter: 0; batch classifier loss: 0.530899; batch adversarial loss: 0.656700\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425351; batch adversarial loss: 0.595168\n",
      "epoch 47; iter: 0; batch classifier loss: 0.538000; batch adversarial loss: 0.588761\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455724; batch adversarial loss: 0.539472\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371239; batch adversarial loss: 0.520740\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390385; batch adversarial loss: 0.626882\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466554; batch adversarial loss: 0.579524\n",
      "epoch 52; iter: 0; batch classifier loss: 0.396293; batch adversarial loss: 0.573075\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466712; batch adversarial loss: 0.518953\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452393; batch adversarial loss: 0.502378\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437140; batch adversarial loss: 0.503872\n",
      "epoch 56; iter: 0; batch classifier loss: 0.454149; batch adversarial loss: 0.554153\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472801; batch adversarial loss: 0.573249\n",
      "epoch 58; iter: 0; batch classifier loss: 0.482125; batch adversarial loss: 0.582925\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444795; batch adversarial loss: 0.563771\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377566; batch adversarial loss: 0.571844\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439331; batch adversarial loss: 0.555485\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439072; batch adversarial loss: 0.587585\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401282; batch adversarial loss: 0.493468\n",
      "epoch 64; iter: 0; batch classifier loss: 0.459394; batch adversarial loss: 0.589970\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364616; batch adversarial loss: 0.552197\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452219; batch adversarial loss: 0.614709\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363521; batch adversarial loss: 0.493881\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434778; batch adversarial loss: 0.536331\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368084; batch adversarial loss: 0.571573\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464593; batch adversarial loss: 0.545632\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423853; batch adversarial loss: 0.579189\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382282; batch adversarial loss: 0.640812\n",
      "epoch 73; iter: 0; batch classifier loss: 0.505799; batch adversarial loss: 0.544536\n",
      "epoch 74; iter: 0; batch classifier loss: 0.455620; batch adversarial loss: 0.571310\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405285; batch adversarial loss: 0.545050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.434850; batch adversarial loss: 0.579837\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416099; batch adversarial loss: 0.467180\n",
      "epoch 78; iter: 0; batch classifier loss: 0.313713; batch adversarial loss: 0.570877\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393564; batch adversarial loss: 0.570567\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380842; batch adversarial loss: 0.518749\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404562; batch adversarial loss: 0.545130\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389185; batch adversarial loss: 0.588205\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394152; batch adversarial loss: 0.597010\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390868; batch adversarial loss: 0.579631\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341347; batch adversarial loss: 0.622675\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356621; batch adversarial loss: 0.588872\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390554; batch adversarial loss: 0.578783\n",
      "epoch 88; iter: 0; batch classifier loss: 0.462987; batch adversarial loss: 0.517968\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379176; batch adversarial loss: 0.570364\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415089; batch adversarial loss: 0.631677\n",
      "epoch 91; iter: 0; batch classifier loss: 0.317057; batch adversarial loss: 0.484411\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381051; batch adversarial loss: 0.534990\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447467; batch adversarial loss: 0.527684\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434610; batch adversarial loss: 0.518524\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400487; batch adversarial loss: 0.552000\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387750; batch adversarial loss: 0.537661\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415979; batch adversarial loss: 0.622615\n",
      "epoch 98; iter: 0; batch classifier loss: 0.349243; batch adversarial loss: 0.579618\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399137; batch adversarial loss: 0.544613\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403520; batch adversarial loss: 0.519165\n",
      "epoch 101; iter: 0; batch classifier loss: 0.345254; batch adversarial loss: 0.535762\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374527; batch adversarial loss: 0.711036\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376899; batch adversarial loss: 0.491565\n",
      "epoch 104; iter: 0; batch classifier loss: 0.410527; batch adversarial loss: 0.528847\n",
      "epoch 105; iter: 0; batch classifier loss: 0.380118; batch adversarial loss: 0.605340\n",
      "epoch 106; iter: 0; batch classifier loss: 0.368600; batch adversarial loss: 0.493336\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371603; batch adversarial loss: 0.624784\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366592; batch adversarial loss: 0.511404\n",
      "epoch 109; iter: 0; batch classifier loss: 0.334805; batch adversarial loss: 0.552561\n",
      "epoch 110; iter: 0; batch classifier loss: 0.353013; batch adversarial loss: 0.598061\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398813; batch adversarial loss: 0.585469\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375173; batch adversarial loss: 0.580412\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400950; batch adversarial loss: 0.572425\n",
      "epoch 114; iter: 0; batch classifier loss: 0.336375; batch adversarial loss: 0.569724\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388760; batch adversarial loss: 0.458104\n",
      "epoch 116; iter: 0; batch classifier loss: 0.433611; batch adversarial loss: 0.536408\n",
      "epoch 117; iter: 0; batch classifier loss: 0.347099; batch adversarial loss: 0.560682\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347902; batch adversarial loss: 0.519240\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378411; batch adversarial loss: 0.475492\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354307; batch adversarial loss: 0.536513\n",
      "epoch 121; iter: 0; batch classifier loss: 0.424950; batch adversarial loss: 0.603310\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373867; batch adversarial loss: 0.579241\n",
      "epoch 123; iter: 0; batch classifier loss: 0.368257; batch adversarial loss: 0.572457\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326037; batch adversarial loss: 0.527050\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437865; batch adversarial loss: 0.605892\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380762; batch adversarial loss: 0.598264\n",
      "epoch 127; iter: 0; batch classifier loss: 0.294618; batch adversarial loss: 0.536277\n",
      "epoch 128; iter: 0; batch classifier loss: 0.346235; batch adversarial loss: 0.552121\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355870; batch adversarial loss: 0.474735\n",
      "epoch 130; iter: 0; batch classifier loss: 0.412656; batch adversarial loss: 0.554146\n",
      "epoch 131; iter: 0; batch classifier loss: 0.346144; batch adversarial loss: 0.563062\n",
      "epoch 132; iter: 0; batch classifier loss: 0.311674; batch adversarial loss: 0.490463\n",
      "epoch 133; iter: 0; batch classifier loss: 0.311364; batch adversarial loss: 0.546560\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364324; batch adversarial loss: 0.623279\n",
      "epoch 135; iter: 0; batch classifier loss: 0.362410; batch adversarial loss: 0.537392\n",
      "epoch 136; iter: 0; batch classifier loss: 0.420899; batch adversarial loss: 0.552495\n",
      "epoch 137; iter: 0; batch classifier loss: 0.341531; batch adversarial loss: 0.560459\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356711; batch adversarial loss: 0.571373\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355719; batch adversarial loss: 0.482885\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352023; batch adversarial loss: 0.625623\n",
      "epoch 141; iter: 0; batch classifier loss: 0.403787; batch adversarial loss: 0.535998\n",
      "epoch 142; iter: 0; batch classifier loss: 0.315922; batch adversarial loss: 0.563365\n",
      "epoch 143; iter: 0; batch classifier loss: 0.286738; batch adversarial loss: 0.554060\n",
      "epoch 144; iter: 0; batch classifier loss: 0.432851; batch adversarial loss: 0.597504\n",
      "epoch 145; iter: 0; batch classifier loss: 0.266566; batch adversarial loss: 0.568939\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379224; batch adversarial loss: 0.562490\n",
      "epoch 147; iter: 0; batch classifier loss: 0.317956; batch adversarial loss: 0.570704\n",
      "epoch 148; iter: 0; batch classifier loss: 0.411198; batch adversarial loss: 0.613493\n",
      "epoch 149; iter: 0; batch classifier loss: 0.449905; batch adversarial loss: 0.545890\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350615; batch adversarial loss: 0.527744\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350323; batch adversarial loss: 0.555607\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349492; batch adversarial loss: 0.590958\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388615; batch adversarial loss: 0.573788\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390028; batch adversarial loss: 0.553274\n",
      "epoch 155; iter: 0; batch classifier loss: 0.345340; batch adversarial loss: 0.572062\n",
      "epoch 156; iter: 0; batch classifier loss: 0.409590; batch adversarial loss: 0.553606\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309726; batch adversarial loss: 0.587550\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343886; batch adversarial loss: 0.534214\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361369; batch adversarial loss: 0.509863\n",
      "epoch 160; iter: 0; batch classifier loss: 0.467672; batch adversarial loss: 0.560695\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343809; batch adversarial loss: 0.551963\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371501; batch adversarial loss: 0.527445\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344012; batch adversarial loss: 0.502012\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392970; batch adversarial loss: 0.474355\n",
      "epoch 165; iter: 0; batch classifier loss: 0.408684; batch adversarial loss: 0.516206\n",
      "epoch 166; iter: 0; batch classifier loss: 0.338216; batch adversarial loss: 0.588576\n",
      "epoch 167; iter: 0; batch classifier loss: 0.389318; batch adversarial loss: 0.573912\n",
      "epoch 168; iter: 0; batch classifier loss: 0.360374; batch adversarial loss: 0.551040\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354673; batch adversarial loss: 0.555130\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346799; batch adversarial loss: 0.568631\n",
      "epoch 171; iter: 0; batch classifier loss: 0.397392; batch adversarial loss: 0.604670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.344460; batch adversarial loss: 0.534631\n",
      "epoch 173; iter: 0; batch classifier loss: 0.394027; batch adversarial loss: 0.596677\n",
      "epoch 174; iter: 0; batch classifier loss: 0.400621; batch adversarial loss: 0.517369\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369545; batch adversarial loss: 0.517162\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397343; batch adversarial loss: 0.553120\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330560; batch adversarial loss: 0.544279\n",
      "epoch 178; iter: 0; batch classifier loss: 0.338548; batch adversarial loss: 0.553121\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346004; batch adversarial loss: 0.560874\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318076; batch adversarial loss: 0.571478\n",
      "epoch 181; iter: 0; batch classifier loss: 0.335526; batch adversarial loss: 0.476132\n",
      "epoch 182; iter: 0; batch classifier loss: 0.326140; batch adversarial loss: 0.530747\n",
      "epoch 183; iter: 0; batch classifier loss: 0.437597; batch adversarial loss: 0.527272\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371023; batch adversarial loss: 0.525861\n",
      "epoch 185; iter: 0; batch classifier loss: 0.278059; batch adversarial loss: 0.534861\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315943; batch adversarial loss: 0.595075\n",
      "epoch 187; iter: 0; batch classifier loss: 0.399729; batch adversarial loss: 0.561552\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423336; batch adversarial loss: 0.551937\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339896; batch adversarial loss: 0.578871\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383824; batch adversarial loss: 0.535792\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337835; batch adversarial loss: 0.569574\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317897; batch adversarial loss: 0.526150\n",
      "epoch 193; iter: 0; batch classifier loss: 0.282746; batch adversarial loss: 0.563824\n",
      "epoch 194; iter: 0; batch classifier loss: 0.287183; batch adversarial loss: 0.641427\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311100; batch adversarial loss: 0.579998\n",
      "epoch 196; iter: 0; batch classifier loss: 0.286126; batch adversarial loss: 0.552097\n",
      "epoch 197; iter: 0; batch classifier loss: 0.297751; batch adversarial loss: 0.545612\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376796; batch adversarial loss: 0.572031\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316386; batch adversarial loss: 0.544652\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735270; batch adversarial loss: 0.728456\n",
      "epoch 1; iter: 0; batch classifier loss: 0.661567; batch adversarial loss: 0.694068\n",
      "epoch 2; iter: 0; batch classifier loss: 0.584088; batch adversarial loss: 0.664326\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568981; batch adversarial loss: 0.625787\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573365; batch adversarial loss: 0.669563\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515246; batch adversarial loss: 0.616139\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571527; batch adversarial loss: 0.647067\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566791; batch adversarial loss: 0.606609\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576066; batch adversarial loss: 0.567269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504029; batch adversarial loss: 0.639987\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484579; batch adversarial loss: 0.616352\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498682; batch adversarial loss: 0.544582\n",
      "epoch 12; iter: 0; batch classifier loss: 0.616273; batch adversarial loss: 0.554885\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474469; batch adversarial loss: 0.607683\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508976; batch adversarial loss: 0.604662\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575609; batch adversarial loss: 0.546721\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547727; batch adversarial loss: 0.530100\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537758; batch adversarial loss: 0.587395\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496309; batch adversarial loss: 0.588624\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495881; batch adversarial loss: 0.531995\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519394; batch adversarial loss: 0.561446\n",
      "epoch 21; iter: 0; batch classifier loss: 0.553563; batch adversarial loss: 0.562563\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465096; batch adversarial loss: 0.541934\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511658; batch adversarial loss: 0.583036\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507145; batch adversarial loss: 0.613734\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503126; batch adversarial loss: 0.584706\n",
      "epoch 26; iter: 0; batch classifier loss: 0.534602; batch adversarial loss: 0.591910\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493862; batch adversarial loss: 0.633597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429654; batch adversarial loss: 0.587530\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433354; batch adversarial loss: 0.606368\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402721; batch adversarial loss: 0.541474\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498075; batch adversarial loss: 0.637162\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438227; batch adversarial loss: 0.489554\n",
      "epoch 33; iter: 0; batch classifier loss: 0.581731; batch adversarial loss: 0.560885\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449109; batch adversarial loss: 0.480845\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499496; batch adversarial loss: 0.589228\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471619; batch adversarial loss: 0.495975\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406936; batch adversarial loss: 0.555888\n",
      "epoch 38; iter: 0; batch classifier loss: 0.456228; batch adversarial loss: 0.474066\n",
      "epoch 39; iter: 0; batch classifier loss: 0.539700; batch adversarial loss: 0.554174\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404136; batch adversarial loss: 0.602555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.405398; batch adversarial loss: 0.610581\n",
      "epoch 42; iter: 0; batch classifier loss: 0.397041; batch adversarial loss: 0.555002\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469597; batch adversarial loss: 0.487923\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421375; batch adversarial loss: 0.537293\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440608; batch adversarial loss: 0.526900\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401630; batch adversarial loss: 0.599726\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432469; batch adversarial loss: 0.561830\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455561; batch adversarial loss: 0.572336\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455597; batch adversarial loss: 0.531399\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402860; batch adversarial loss: 0.547770\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490667; batch adversarial loss: 0.604642\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463571; batch adversarial loss: 0.511596\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433216; batch adversarial loss: 0.573411\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442440; batch adversarial loss: 0.580894\n",
      "epoch 55; iter: 0; batch classifier loss: 0.373663; batch adversarial loss: 0.579799\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430438; batch adversarial loss: 0.510418\n",
      "epoch 57; iter: 0; batch classifier loss: 0.381613; batch adversarial loss: 0.580723\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452542; batch adversarial loss: 0.491640\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399965; batch adversarial loss: 0.492574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389911; batch adversarial loss: 0.517596\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409653; batch adversarial loss: 0.588677\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440420; batch adversarial loss: 0.519123\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375252; batch adversarial loss: 0.545019\n",
      "epoch 64; iter: 0; batch classifier loss: 0.357847; batch adversarial loss: 0.664257\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413587; batch adversarial loss: 0.553220\n",
      "epoch 66; iter: 0; batch classifier loss: 0.373751; batch adversarial loss: 0.551836\n",
      "epoch 67; iter: 0; batch classifier loss: 0.365733; batch adversarial loss: 0.690066\n",
      "epoch 68; iter: 0; batch classifier loss: 0.494552; batch adversarial loss: 0.517504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.401246; batch adversarial loss: 0.550405\n",
      "epoch 70; iter: 0; batch classifier loss: 0.367912; batch adversarial loss: 0.579326\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403738; batch adversarial loss: 0.660020\n",
      "epoch 72; iter: 0; batch classifier loss: 0.469507; batch adversarial loss: 0.622165\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420810; batch adversarial loss: 0.597626\n",
      "epoch 74; iter: 0; batch classifier loss: 0.485659; batch adversarial loss: 0.542922\n",
      "epoch 75; iter: 0; batch classifier loss: 0.450820; batch adversarial loss: 0.510938\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371136; batch adversarial loss: 0.491959\n",
      "epoch 77; iter: 0; batch classifier loss: 0.393672; batch adversarial loss: 0.524174\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467639; batch adversarial loss: 0.647253\n",
      "epoch 79; iter: 0; batch classifier loss: 0.325075; batch adversarial loss: 0.620515\n",
      "epoch 80; iter: 0; batch classifier loss: 0.319913; batch adversarial loss: 0.541457\n",
      "epoch 81; iter: 0; batch classifier loss: 0.334308; batch adversarial loss: 0.528394\n",
      "epoch 82; iter: 0; batch classifier loss: 0.399520; batch adversarial loss: 0.551896\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361668; batch adversarial loss: 0.510796\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366711; batch adversarial loss: 0.572057\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395350; batch adversarial loss: 0.609397\n",
      "epoch 86; iter: 0; batch classifier loss: 0.472820; batch adversarial loss: 0.519676\n",
      "epoch 87; iter: 0; batch classifier loss: 0.379456; batch adversarial loss: 0.626346\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402785; batch adversarial loss: 0.518677\n",
      "epoch 89; iter: 0; batch classifier loss: 0.475021; batch adversarial loss: 0.582504\n",
      "epoch 90; iter: 0; batch classifier loss: 0.343364; batch adversarial loss: 0.634176\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407900; batch adversarial loss: 0.571950\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354152; batch adversarial loss: 0.633544\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379934; batch adversarial loss: 0.588932\n",
      "epoch 94; iter: 0; batch classifier loss: 0.451524; batch adversarial loss: 0.589418\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402322; batch adversarial loss: 0.554155\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354103; batch adversarial loss: 0.553124\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402980; batch adversarial loss: 0.527799\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398442; batch adversarial loss: 0.623928\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375962; batch adversarial loss: 0.519913\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377319; batch adversarial loss: 0.528613\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370809; batch adversarial loss: 0.570963\n",
      "epoch 102; iter: 0; batch classifier loss: 0.423989; batch adversarial loss: 0.571851\n",
      "epoch 103; iter: 0; batch classifier loss: 0.457983; batch adversarial loss: 0.614919\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408655; batch adversarial loss: 0.501161\n",
      "epoch 105; iter: 0; batch classifier loss: 0.451087; batch adversarial loss: 0.581986\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349723; batch adversarial loss: 0.571639\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400271; batch adversarial loss: 0.561339\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422118; batch adversarial loss: 0.483060\n",
      "epoch 109; iter: 0; batch classifier loss: 0.343352; batch adversarial loss: 0.520379\n",
      "epoch 110; iter: 0; batch classifier loss: 0.438976; batch adversarial loss: 0.562486\n",
      "epoch 111; iter: 0; batch classifier loss: 0.420109; batch adversarial loss: 0.605102\n",
      "epoch 112; iter: 0; batch classifier loss: 0.357491; batch adversarial loss: 0.534344\n",
      "epoch 113; iter: 0; batch classifier loss: 0.366558; batch adversarial loss: 0.613032\n",
      "epoch 114; iter: 0; batch classifier loss: 0.425115; batch adversarial loss: 0.500122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.351959; batch adversarial loss: 0.571053\n",
      "epoch 116; iter: 0; batch classifier loss: 0.453755; batch adversarial loss: 0.517844\n",
      "epoch 117; iter: 0; batch classifier loss: 0.475238; batch adversarial loss: 0.550932\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410591; batch adversarial loss: 0.587714\n",
      "epoch 119; iter: 0; batch classifier loss: 0.445012; batch adversarial loss: 0.620341\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378725; batch adversarial loss: 0.603568\n",
      "epoch 121; iter: 0; batch classifier loss: 0.512409; batch adversarial loss: 0.558906\n",
      "epoch 122; iter: 0; batch classifier loss: 0.462298; batch adversarial loss: 0.542271\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414773; batch adversarial loss: 0.501676\n",
      "epoch 124; iter: 0; batch classifier loss: 0.439680; batch adversarial loss: 0.640939\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365998; batch adversarial loss: 0.589387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387268; batch adversarial loss: 0.545648\n",
      "epoch 127; iter: 0; batch classifier loss: 0.473367; batch adversarial loss: 0.560634\n",
      "epoch 128; iter: 0; batch classifier loss: 0.348381; batch adversarial loss: 0.492402\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348057; batch adversarial loss: 0.543609\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370932; batch adversarial loss: 0.536171\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347607; batch adversarial loss: 0.492608\n",
      "epoch 132; iter: 0; batch classifier loss: 0.321641; batch adversarial loss: 0.606629\n",
      "epoch 133; iter: 0; batch classifier loss: 0.333125; batch adversarial loss: 0.579031\n",
      "epoch 134; iter: 0; batch classifier loss: 0.345962; batch adversarial loss: 0.624820\n",
      "epoch 135; iter: 0; batch classifier loss: 0.453242; batch adversarial loss: 0.552893\n",
      "epoch 136; iter: 0; batch classifier loss: 0.293356; batch adversarial loss: 0.579413\n",
      "epoch 137; iter: 0; batch classifier loss: 0.409624; batch adversarial loss: 0.540181\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350939; batch adversarial loss: 0.588730\n",
      "epoch 139; iter: 0; batch classifier loss: 0.323771; batch adversarial loss: 0.535800\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341564; batch adversarial loss: 0.561571\n",
      "epoch 141; iter: 0; batch classifier loss: 0.331916; batch adversarial loss: 0.473866\n",
      "epoch 142; iter: 0; batch classifier loss: 0.304639; batch adversarial loss: 0.648823\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385814; batch adversarial loss: 0.571015\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409461; batch adversarial loss: 0.614342\n",
      "epoch 145; iter: 0; batch classifier loss: 0.389756; batch adversarial loss: 0.553410\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405928; batch adversarial loss: 0.553786\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346729; batch adversarial loss: 0.606241\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367120; batch adversarial loss: 0.509704\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335018; batch adversarial loss: 0.579591\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370211; batch adversarial loss: 0.596341\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373138; batch adversarial loss: 0.562181\n",
      "epoch 152; iter: 0; batch classifier loss: 0.404155; batch adversarial loss: 0.512678\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331197; batch adversarial loss: 0.560546\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394205; batch adversarial loss: 0.569315\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373331; batch adversarial loss: 0.544881\n",
      "epoch 156; iter: 0; batch classifier loss: 0.288028; batch adversarial loss: 0.590403\n",
      "epoch 157; iter: 0; batch classifier loss: 0.435502; batch adversarial loss: 0.632478\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376408; batch adversarial loss: 0.563584\n",
      "epoch 159; iter: 0; batch classifier loss: 0.404189; batch adversarial loss: 0.553933\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384112; batch adversarial loss: 0.551216\n",
      "epoch 161; iter: 0; batch classifier loss: 0.261966; batch adversarial loss: 0.544629\n",
      "epoch 162; iter: 0; batch classifier loss: 0.403426; batch adversarial loss: 0.534653\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339406; batch adversarial loss: 0.571008\n",
      "epoch 164; iter: 0; batch classifier loss: 0.338147; batch adversarial loss: 0.528027\n",
      "epoch 165; iter: 0; batch classifier loss: 0.412718; batch adversarial loss: 0.552940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.401051; batch adversarial loss: 0.536386\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343702; batch adversarial loss: 0.527151\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338771; batch adversarial loss: 0.535576\n",
      "epoch 169; iter: 0; batch classifier loss: 0.442942; batch adversarial loss: 0.579382\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398434; batch adversarial loss: 0.476112\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338084; batch adversarial loss: 0.623832\n",
      "epoch 172; iter: 0; batch classifier loss: 0.272955; batch adversarial loss: 0.596793\n",
      "epoch 173; iter: 0; batch classifier loss: 0.338496; batch adversarial loss: 0.510098\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343425; batch adversarial loss: 0.571117\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372865; batch adversarial loss: 0.494881\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340529; batch adversarial loss: 0.535723\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392808; batch adversarial loss: 0.571012\n",
      "epoch 178; iter: 0; batch classifier loss: 0.326630; batch adversarial loss: 0.528369\n",
      "epoch 179; iter: 0; batch classifier loss: 0.299488; batch adversarial loss: 0.535708\n",
      "epoch 180; iter: 0; batch classifier loss: 0.377503; batch adversarial loss: 0.588057\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348406; batch adversarial loss: 0.569765\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318997; batch adversarial loss: 0.546453\n",
      "epoch 183; iter: 0; batch classifier loss: 0.360115; batch adversarial loss: 0.561686\n",
      "epoch 184; iter: 0; batch classifier loss: 0.353579; batch adversarial loss: 0.660113\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281265; batch adversarial loss: 0.561016\n",
      "epoch 186; iter: 0; batch classifier loss: 0.360387; batch adversarial loss: 0.510186\n",
      "epoch 187; iter: 0; batch classifier loss: 0.316664; batch adversarial loss: 0.561413\n",
      "epoch 188; iter: 0; batch classifier loss: 0.350297; batch adversarial loss: 0.527175\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321000; batch adversarial loss: 0.579220\n",
      "epoch 190; iter: 0; batch classifier loss: 0.299608; batch adversarial loss: 0.605482\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373299; batch adversarial loss: 0.568237\n",
      "epoch 192; iter: 0; batch classifier loss: 0.262461; batch adversarial loss: 0.587994\n",
      "epoch 193; iter: 0; batch classifier loss: 0.358137; batch adversarial loss: 0.630090\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343710; batch adversarial loss: 0.613629\n",
      "epoch 195; iter: 0; batch classifier loss: 0.254598; batch adversarial loss: 0.498766\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336101; batch adversarial loss: 0.589122\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332240; batch adversarial loss: 0.569040\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370213; batch adversarial loss: 0.554683\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345826; batch adversarial loss: 0.555274\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685118; batch adversarial loss: 0.624406\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584083; batch adversarial loss: 0.645675\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596268; batch adversarial loss: 0.647159\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590889; batch adversarial loss: 0.658329\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561534; batch adversarial loss: 0.686740\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602213; batch adversarial loss: 0.692152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508960; batch adversarial loss: 0.626505\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562001; batch adversarial loss: 0.548445\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517043; batch adversarial loss: 0.601901\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556750; batch adversarial loss: 0.532917\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504223; batch adversarial loss: 0.666328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.484291; batch adversarial loss: 0.572831\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516578; batch adversarial loss: 0.592661\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539030; batch adversarial loss: 0.590475\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461158; batch adversarial loss: 0.545205\n",
      "epoch 15; iter: 0; batch classifier loss: 0.619057; batch adversarial loss: 0.557478\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469226; batch adversarial loss: 0.631420\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466822; batch adversarial loss: 0.589494\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442513; batch adversarial loss: 0.548212\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508726; batch adversarial loss: 0.572861\n",
      "epoch 20; iter: 0; batch classifier loss: 0.537382; batch adversarial loss: 0.520244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485648; batch adversarial loss: 0.493258\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469399; batch adversarial loss: 0.532834\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484371; batch adversarial loss: 0.564450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468257; batch adversarial loss: 0.515988\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454673; batch adversarial loss: 0.538949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424361; batch adversarial loss: 0.489312\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450666; batch adversarial loss: 0.535062\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463603; batch adversarial loss: 0.606683\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474011; batch adversarial loss: 0.522174\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452473; batch adversarial loss: 0.565775\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480928; batch adversarial loss: 0.525971\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472175; batch adversarial loss: 0.486896\n",
      "epoch 33; iter: 0; batch classifier loss: 0.493498; batch adversarial loss: 0.513309\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466248; batch adversarial loss: 0.484190\n",
      "epoch 35; iter: 0; batch classifier loss: 0.505887; batch adversarial loss: 0.530357\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452161; batch adversarial loss: 0.628183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442599; batch adversarial loss: 0.563233\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399130; batch adversarial loss: 0.527805\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386406; batch adversarial loss: 0.614931\n",
      "epoch 40; iter: 0; batch classifier loss: 0.379214; batch adversarial loss: 0.537037\n",
      "epoch 41; iter: 0; batch classifier loss: 0.522264; batch adversarial loss: 0.553373\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414609; batch adversarial loss: 0.580630\n",
      "epoch 43; iter: 0; batch classifier loss: 0.561328; batch adversarial loss: 0.598281\n",
      "epoch 44; iter: 0; batch classifier loss: 0.361338; batch adversarial loss: 0.500556\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518921; batch adversarial loss: 0.555169\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458157; batch adversarial loss: 0.536200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.481217; batch adversarial loss: 0.499577\n",
      "epoch 48; iter: 0; batch classifier loss: 0.497958; batch adversarial loss: 0.607094\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417419; batch adversarial loss: 0.517863\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498954; batch adversarial loss: 0.562203\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421952; batch adversarial loss: 0.553341\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382432; batch adversarial loss: 0.543657\n",
      "epoch 53; iter: 0; batch classifier loss: 0.484981; batch adversarial loss: 0.535190\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451176; batch adversarial loss: 0.572519\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427612; batch adversarial loss: 0.553072\n",
      "epoch 56; iter: 0; batch classifier loss: 0.481632; batch adversarial loss: 0.617530\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441311; batch adversarial loss: 0.617442\n",
      "epoch 58; iter: 0; batch classifier loss: 0.485201; batch adversarial loss: 0.553666\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462313; batch adversarial loss: 0.544075\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424829; batch adversarial loss: 0.480547\n",
      "epoch 61; iter: 0; batch classifier loss: 0.416546; batch adversarial loss: 0.562495\n",
      "epoch 62; iter: 0; batch classifier loss: 0.455981; batch adversarial loss: 0.517470\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430071; batch adversarial loss: 0.651562\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406028; batch adversarial loss: 0.527195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.464096; batch adversarial loss: 0.455857\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410917; batch adversarial loss: 0.465433\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434051; batch adversarial loss: 0.508541\n",
      "epoch 68; iter: 0; batch classifier loss: 0.372879; batch adversarial loss: 0.590306\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426137; batch adversarial loss: 0.492200\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352437; batch adversarial loss: 0.545147\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414903; batch adversarial loss: 0.462774\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455648; batch adversarial loss: 0.656251\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404340; batch adversarial loss: 0.582310\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384910; batch adversarial loss: 0.516626\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366080; batch adversarial loss: 0.571980\n",
      "epoch 76; iter: 0; batch classifier loss: 0.431444; batch adversarial loss: 0.599672\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406379; batch adversarial loss: 0.554489\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359909; batch adversarial loss: 0.526573\n",
      "epoch 79; iter: 0; batch classifier loss: 0.480143; batch adversarial loss: 0.525804\n",
      "epoch 80; iter: 0; batch classifier loss: 0.483344; batch adversarial loss: 0.507507\n",
      "epoch 81; iter: 0; batch classifier loss: 0.364822; batch adversarial loss: 0.552673\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391942; batch adversarial loss: 0.526027\n",
      "epoch 83; iter: 0; batch classifier loss: 0.352533; batch adversarial loss: 0.562599\n",
      "epoch 84; iter: 0; batch classifier loss: 0.567878; batch adversarial loss: 0.572284\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399598; batch adversarial loss: 0.572165\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435967; batch adversarial loss: 0.599052\n",
      "epoch 87; iter: 0; batch classifier loss: 0.325068; batch adversarial loss: 0.544142\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357574; batch adversarial loss: 0.571576\n",
      "epoch 89; iter: 0; batch classifier loss: 0.416147; batch adversarial loss: 0.535676\n",
      "epoch 90; iter: 0; batch classifier loss: 0.406137; batch adversarial loss: 0.637192\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385205; batch adversarial loss: 0.525414\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390712; batch adversarial loss: 0.553365\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418960; batch adversarial loss: 0.581340\n",
      "epoch 94; iter: 0; batch classifier loss: 0.326760; batch adversarial loss: 0.544273\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397761; batch adversarial loss: 0.509180\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377126; batch adversarial loss: 0.598545\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400385; batch adversarial loss: 0.553007\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391716; batch adversarial loss: 0.499537\n",
      "epoch 99; iter: 0; batch classifier loss: 0.375846; batch adversarial loss: 0.607726\n",
      "epoch 100; iter: 0; batch classifier loss: 0.463502; batch adversarial loss: 0.517063\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406247; batch adversarial loss: 0.571423\n",
      "epoch 102; iter: 0; batch classifier loss: 0.425294; batch adversarial loss: 0.536171\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396916; batch adversarial loss: 0.544304\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384845; batch adversarial loss: 0.535925\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372311; batch adversarial loss: 0.499450\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396366; batch adversarial loss: 0.526870\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345140; batch adversarial loss: 0.498668\n",
      "epoch 108; iter: 0; batch classifier loss: 0.446456; batch adversarial loss: 0.544222\n",
      "epoch 109; iter: 0; batch classifier loss: 0.422251; batch adversarial loss: 0.553564\n",
      "epoch 110; iter: 0; batch classifier loss: 0.309070; batch adversarial loss: 0.526268\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335643; batch adversarial loss: 0.499480\n",
      "epoch 112; iter: 0; batch classifier loss: 0.454572; batch adversarial loss: 0.535258\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378624; batch adversarial loss: 0.509049\n",
      "epoch 114; iter: 0; batch classifier loss: 0.408972; batch adversarial loss: 0.535491\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401788; batch adversarial loss: 0.589404\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370353; batch adversarial loss: 0.517576\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429486; batch adversarial loss: 0.617478\n",
      "epoch 118; iter: 0; batch classifier loss: 0.365942; batch adversarial loss: 0.489959\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368776; batch adversarial loss: 0.526567\n",
      "epoch 120; iter: 0; batch classifier loss: 0.407411; batch adversarial loss: 0.571990\n",
      "epoch 121; iter: 0; batch classifier loss: 0.408399; batch adversarial loss: 0.526385\n",
      "epoch 122; iter: 0; batch classifier loss: 0.499731; batch adversarial loss: 0.517371\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385014; batch adversarial loss: 0.535646\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426993; batch adversarial loss: 0.589991\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349241; batch adversarial loss: 0.490236\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382566; batch adversarial loss: 0.590235\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423488; batch adversarial loss: 0.508372\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322689; batch adversarial loss: 0.490603\n",
      "epoch 129; iter: 0; batch classifier loss: 0.383091; batch adversarial loss: 0.517267\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395036; batch adversarial loss: 0.508435\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353855; batch adversarial loss: 0.589632\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392355; batch adversarial loss: 0.590144\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360004; batch adversarial loss: 0.499197\n",
      "epoch 134; iter: 0; batch classifier loss: 0.412299; batch adversarial loss: 0.599010\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375648; batch adversarial loss: 0.707190\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354518; batch adversarial loss: 0.626430\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396901; batch adversarial loss: 0.562628\n",
      "epoch 138; iter: 0; batch classifier loss: 0.467282; batch adversarial loss: 0.598852\n",
      "epoch 139; iter: 0; batch classifier loss: 0.339625; batch adversarial loss: 0.572025\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350485; batch adversarial loss: 0.535420\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364889; batch adversarial loss: 0.581162\n",
      "epoch 142; iter: 0; batch classifier loss: 0.473673; batch adversarial loss: 0.625929\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397268; batch adversarial loss: 0.526528\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341075; batch adversarial loss: 0.590032\n",
      "epoch 145; iter: 0; batch classifier loss: 0.330564; batch adversarial loss: 0.653367\n",
      "epoch 146; iter: 0; batch classifier loss: 0.316905; batch adversarial loss: 0.554100\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404837; batch adversarial loss: 0.535267\n",
      "epoch 148; iter: 0; batch classifier loss: 0.372967; batch adversarial loss: 0.589671\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315365; batch adversarial loss: 0.535441\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325008; batch adversarial loss: 0.634724\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374963; batch adversarial loss: 0.553677\n",
      "epoch 152; iter: 0; batch classifier loss: 0.312470; batch adversarial loss: 0.490152\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379949; batch adversarial loss: 0.535621\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391521; batch adversarial loss: 0.535408\n",
      "epoch 155; iter: 0; batch classifier loss: 0.301575; batch adversarial loss: 0.517375\n",
      "epoch 156; iter: 0; batch classifier loss: 0.418391; batch adversarial loss: 0.544458\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369196; batch adversarial loss: 0.490080\n",
      "epoch 158; iter: 0; batch classifier loss: 0.311329; batch adversarial loss: 0.553629\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373559; batch adversarial loss: 0.598892\n",
      "epoch 160; iter: 0; batch classifier loss: 0.438526; batch adversarial loss: 0.544551\n",
      "epoch 161; iter: 0; batch classifier loss: 0.419847; batch adversarial loss: 0.608130\n",
      "epoch 162; iter: 0; batch classifier loss: 0.379213; batch adversarial loss: 0.544611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 163; iter: 0; batch classifier loss: 0.360734; batch adversarial loss: 0.589902\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305717; batch adversarial loss: 0.544700\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356264; batch adversarial loss: 0.580859\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358364; batch adversarial loss: 0.526255\n",
      "epoch 167; iter: 0; batch classifier loss: 0.489874; batch adversarial loss: 0.526372\n",
      "epoch 168; iter: 0; batch classifier loss: 0.479914; batch adversarial loss: 0.481029\n",
      "epoch 169; iter: 0; batch classifier loss: 0.410309; batch adversarial loss: 0.590224\n",
      "epoch 170; iter: 0; batch classifier loss: 0.389203; batch adversarial loss: 0.535493\n",
      "epoch 171; iter: 0; batch classifier loss: 0.368832; batch adversarial loss: 0.499061\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331164; batch adversarial loss: 0.526553\n",
      "epoch 173; iter: 0; batch classifier loss: 0.368143; batch adversarial loss: 0.490335\n",
      "epoch 174; iter: 0; batch classifier loss: 0.416356; batch adversarial loss: 0.508042\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385940; batch adversarial loss: 0.535833\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374001; batch adversarial loss: 0.581074\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364363; batch adversarial loss: 0.526687\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323735; batch adversarial loss: 0.481470\n",
      "epoch 179; iter: 0; batch classifier loss: 0.360978; batch adversarial loss: 0.526057\n",
      "epoch 180; iter: 0; batch classifier loss: 0.372110; batch adversarial loss: 0.562552\n",
      "epoch 181; iter: 0; batch classifier loss: 0.318614; batch adversarial loss: 0.572419\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313290; batch adversarial loss: 0.535417\n",
      "epoch 183; iter: 0; batch classifier loss: 0.348803; batch adversarial loss: 0.635779\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371569; batch adversarial loss: 0.544334\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347269; batch adversarial loss: 0.499270\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338541; batch adversarial loss: 0.553476\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305965; batch adversarial loss: 0.508348\n",
      "epoch 188; iter: 0; batch classifier loss: 0.418833; batch adversarial loss: 0.553540\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404832; batch adversarial loss: 0.562363\n",
      "epoch 190; iter: 0; batch classifier loss: 0.301746; batch adversarial loss: 0.526327\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360618; batch adversarial loss: 0.544559\n",
      "epoch 192; iter: 0; batch classifier loss: 0.386891; batch adversarial loss: 0.463119\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398774; batch adversarial loss: 0.499222\n",
      "epoch 194; iter: 0; batch classifier loss: 0.420341; batch adversarial loss: 0.644111\n",
      "epoch 195; iter: 0; batch classifier loss: 0.411686; batch adversarial loss: 0.553865\n",
      "epoch 196; iter: 0; batch classifier loss: 0.371234; batch adversarial loss: 0.517788\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394097; batch adversarial loss: 0.535588\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321615; batch adversarial loss: 0.462868\n",
      "epoch 199; iter: 0; batch classifier loss: 0.328621; batch adversarial loss: 0.462734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688184; batch adversarial loss: 0.852940\n",
      "epoch 1; iter: 0; batch classifier loss: 0.674820; batch adversarial loss: 0.958586\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652923; batch adversarial loss: 0.845979\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579050; batch adversarial loss: 0.806761\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538410; batch adversarial loss: 0.709119\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516773; batch adversarial loss: 0.705560\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539442; batch adversarial loss: 0.656087\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536184; batch adversarial loss: 0.678114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539312; batch adversarial loss: 0.629432\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578980; batch adversarial loss: 0.633756\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488061; batch adversarial loss: 0.620079\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529376; batch adversarial loss: 0.583126\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540461; batch adversarial loss: 0.567877\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518454; batch adversarial loss: 0.603099\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571111; batch adversarial loss: 0.559482\n",
      "epoch 15; iter: 0; batch classifier loss: 0.532878; batch adversarial loss: 0.573905\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478937; batch adversarial loss: 0.572576\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546677; batch adversarial loss: 0.577455\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478233; batch adversarial loss: 0.568854\n",
      "epoch 19; iter: 0; batch classifier loss: 0.552544; batch adversarial loss: 0.538464\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500752; batch adversarial loss: 0.541718\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489053; batch adversarial loss: 0.582116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.426858; batch adversarial loss: 0.523550\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450504; batch adversarial loss: 0.579146\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465312; batch adversarial loss: 0.590512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465724; batch adversarial loss: 0.563566\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498070; batch adversarial loss: 0.540079\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484602; batch adversarial loss: 0.623391\n",
      "epoch 28; iter: 0; batch classifier loss: 0.502759; batch adversarial loss: 0.571460\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474038; batch adversarial loss: 0.513651\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488902; batch adversarial loss: 0.518819\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452229; batch adversarial loss: 0.501585\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498457; batch adversarial loss: 0.509212\n",
      "epoch 33; iter: 0; batch classifier loss: 0.506074; batch adversarial loss: 0.551328\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451610; batch adversarial loss: 0.532994\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465855; batch adversarial loss: 0.580552\n",
      "epoch 36; iter: 0; batch classifier loss: 0.516925; batch adversarial loss: 0.495948\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486591; batch adversarial loss: 0.497615\n",
      "epoch 38; iter: 0; batch classifier loss: 0.439539; batch adversarial loss: 0.539841\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421107; batch adversarial loss: 0.545729\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424763; batch adversarial loss: 0.589057\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421313; batch adversarial loss: 0.557003\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476837; batch adversarial loss: 0.542666\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397054; batch adversarial loss: 0.603937\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454736; batch adversarial loss: 0.463335\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436461; batch adversarial loss: 0.514148\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516072; batch adversarial loss: 0.499270\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433881; batch adversarial loss: 0.635906\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418267; batch adversarial loss: 0.601551\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444914; batch adversarial loss: 0.541617\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414513; batch adversarial loss: 0.525034\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428573; batch adversarial loss: 0.481241\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444433; batch adversarial loss: 0.543021\n",
      "epoch 53; iter: 0; batch classifier loss: 0.426675; batch adversarial loss: 0.515675\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462329; batch adversarial loss: 0.524266\n",
      "epoch 55; iter: 0; batch classifier loss: 0.381843; batch adversarial loss: 0.526161\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409114; batch adversarial loss: 0.497992\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436173; batch adversarial loss: 0.479673\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395524; batch adversarial loss: 0.571895\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446773; batch adversarial loss: 0.478040\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443015; batch adversarial loss: 0.592169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61; iter: 0; batch classifier loss: 0.489691; batch adversarial loss: 0.581969\n",
      "epoch 62; iter: 0; batch classifier loss: 0.452843; batch adversarial loss: 0.525936\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390662; batch adversarial loss: 0.496391\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372501; batch adversarial loss: 0.572822\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437273; batch adversarial loss: 0.487970\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409502; batch adversarial loss: 0.590515\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394261; batch adversarial loss: 0.507016\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381720; batch adversarial loss: 0.525384\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418549; batch adversarial loss: 0.572805\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444712; batch adversarial loss: 0.506767\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370707; batch adversarial loss: 0.535091\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390269; batch adversarial loss: 0.506824\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441142; batch adversarial loss: 0.572568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364679; batch adversarial loss: 0.563292\n",
      "epoch 75; iter: 0; batch classifier loss: 0.419230; batch adversarial loss: 0.544603\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418558; batch adversarial loss: 0.497520\n",
      "epoch 77; iter: 0; batch classifier loss: 0.347818; batch adversarial loss: 0.554043\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406424; batch adversarial loss: 0.535298\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376072; batch adversarial loss: 0.507583\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406820; batch adversarial loss: 0.507209\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389477; batch adversarial loss: 0.517804\n",
      "epoch 82; iter: 0; batch classifier loss: 0.524175; batch adversarial loss: 0.525616\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381900; batch adversarial loss: 0.468610\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398778; batch adversarial loss: 0.571865\n",
      "epoch 85; iter: 0; batch classifier loss: 0.440821; batch adversarial loss: 0.544891\n",
      "epoch 86; iter: 0; batch classifier loss: 0.404284; batch adversarial loss: 0.535665\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400021; batch adversarial loss: 0.579812\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429725; batch adversarial loss: 0.499652\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406190; batch adversarial loss: 0.602023\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428515; batch adversarial loss: 0.470067\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408054; batch adversarial loss: 0.508779\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408919; batch adversarial loss: 0.525891\n",
      "epoch 93; iter: 0; batch classifier loss: 0.350718; batch adversarial loss: 0.593304\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421890; batch adversarial loss: 0.498414\n",
      "epoch 95; iter: 0; batch classifier loss: 0.405340; batch adversarial loss: 0.542574\n",
      "epoch 96; iter: 0; batch classifier loss: 0.345354; batch adversarial loss: 0.545123\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319816; batch adversarial loss: 0.572957\n",
      "epoch 98; iter: 0; batch classifier loss: 0.424679; batch adversarial loss: 0.574020\n",
      "epoch 99; iter: 0; batch classifier loss: 0.353488; batch adversarial loss: 0.441386\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387300; batch adversarial loss: 0.479025\n",
      "epoch 101; iter: 0; batch classifier loss: 0.337523; batch adversarial loss: 0.535739\n",
      "epoch 102; iter: 0; batch classifier loss: 0.478231; batch adversarial loss: 0.620275\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427828; batch adversarial loss: 0.508184\n",
      "epoch 104; iter: 0; batch classifier loss: 0.404128; batch adversarial loss: 0.573427\n",
      "epoch 105; iter: 0; batch classifier loss: 0.415803; batch adversarial loss: 0.516355\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370993; batch adversarial loss: 0.544711\n",
      "epoch 107; iter: 0; batch classifier loss: 0.415027; batch adversarial loss: 0.563763\n",
      "epoch 108; iter: 0; batch classifier loss: 0.361480; batch adversarial loss: 0.534676\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410084; batch adversarial loss: 0.516748\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386283; batch adversarial loss: 0.499143\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412468; batch adversarial loss: 0.497552\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347584; batch adversarial loss: 0.583086\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407651; batch adversarial loss: 0.461351\n",
      "epoch 114; iter: 0; batch classifier loss: 0.434482; batch adversarial loss: 0.517074\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412316; batch adversarial loss: 0.525599\n",
      "epoch 116; iter: 0; batch classifier loss: 0.320671; batch adversarial loss: 0.516679\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351746; batch adversarial loss: 0.592311\n",
      "epoch 118; iter: 0; batch classifier loss: 0.457818; batch adversarial loss: 0.612205\n",
      "epoch 119; iter: 0; batch classifier loss: 0.430014; batch adversarial loss: 0.553964\n",
      "epoch 120; iter: 0; batch classifier loss: 0.420222; batch adversarial loss: 0.534684\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358235; batch adversarial loss: 0.479078\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387068; batch adversarial loss: 0.602223\n",
      "epoch 123; iter: 0; batch classifier loss: 0.424301; batch adversarial loss: 0.495481\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345427; batch adversarial loss: 0.563879\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393668; batch adversarial loss: 0.544306\n",
      "epoch 126; iter: 0; batch classifier loss: 0.421764; batch adversarial loss: 0.565242\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380055; batch adversarial loss: 0.564011\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344039; batch adversarial loss: 0.508126\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388606; batch adversarial loss: 0.487708\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384666; batch adversarial loss: 0.582623\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392271; batch adversarial loss: 0.461717\n",
      "epoch 132; iter: 0; batch classifier loss: 0.351901; batch adversarial loss: 0.522361\n",
      "epoch 133; iter: 0; batch classifier loss: 0.382408; batch adversarial loss: 0.524460\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326950; batch adversarial loss: 0.545159\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366423; batch adversarial loss: 0.554265\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416018; batch adversarial loss: 0.599349\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413800; batch adversarial loss: 0.499600\n",
      "epoch 138; iter: 0; batch classifier loss: 0.437883; batch adversarial loss: 0.553292\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326113; batch adversarial loss: 0.535542\n",
      "epoch 140; iter: 0; batch classifier loss: 0.382772; batch adversarial loss: 0.526081\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434665; batch adversarial loss: 0.499663\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372956; batch adversarial loss: 0.631996\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334587; batch adversarial loss: 0.564998\n",
      "epoch 144; iter: 0; batch classifier loss: 0.388934; batch adversarial loss: 0.574287\n",
      "epoch 145; iter: 0; batch classifier loss: 0.336169; batch adversarial loss: 0.573498\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337548; batch adversarial loss: 0.563829\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338117; batch adversarial loss: 0.601285\n",
      "epoch 148; iter: 0; batch classifier loss: 0.375708; batch adversarial loss: 0.487424\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384515; batch adversarial loss: 0.525171\n",
      "epoch 150; iter: 0; batch classifier loss: 0.401953; batch adversarial loss: 0.497410\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347428; batch adversarial loss: 0.526314\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377497; batch adversarial loss: 0.554485\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334180; batch adversarial loss: 0.535999\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325569; batch adversarial loss: 0.525636\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336310; batch adversarial loss: 0.516951\n",
      "epoch 156; iter: 0; batch classifier loss: 0.412231; batch adversarial loss: 0.544580\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411848; batch adversarial loss: 0.515689\n",
      "epoch 158; iter: 0; batch classifier loss: 0.389375; batch adversarial loss: 0.554015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.442578; batch adversarial loss: 0.582598\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398027; batch adversarial loss: 0.572143\n",
      "epoch 161; iter: 0; batch classifier loss: 0.326689; batch adversarial loss: 0.619822\n",
      "epoch 162; iter: 0; batch classifier loss: 0.272860; batch adversarial loss: 0.572776\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403126; batch adversarial loss: 0.478794\n",
      "epoch 164; iter: 0; batch classifier loss: 0.297832; batch adversarial loss: 0.563022\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369341; batch adversarial loss: 0.553728\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370164; batch adversarial loss: 0.516403\n",
      "epoch 167; iter: 0; batch classifier loss: 0.336246; batch adversarial loss: 0.497311\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343740; batch adversarial loss: 0.620399\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320359; batch adversarial loss: 0.525732\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322764; batch adversarial loss: 0.582244\n",
      "epoch 171; iter: 0; batch classifier loss: 0.361394; batch adversarial loss: 0.544487\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378370; batch adversarial loss: 0.609930\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346691; batch adversarial loss: 0.572205\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324094; batch adversarial loss: 0.581015\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366517; batch adversarial loss: 0.572912\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360564; batch adversarial loss: 0.515773\n",
      "epoch 177; iter: 0; batch classifier loss: 0.304256; batch adversarial loss: 0.554413\n",
      "epoch 178; iter: 0; batch classifier loss: 0.325433; batch adversarial loss: 0.488733\n",
      "epoch 179; iter: 0; batch classifier loss: 0.419248; batch adversarial loss: 0.562187\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359190; batch adversarial loss: 0.534859\n",
      "epoch 181; iter: 0; batch classifier loss: 0.294567; batch adversarial loss: 0.573454\n",
      "epoch 182; iter: 0; batch classifier loss: 0.397603; batch adversarial loss: 0.545555\n",
      "epoch 183; iter: 0; batch classifier loss: 0.280939; batch adversarial loss: 0.526856\n",
      "epoch 184; iter: 0; batch classifier loss: 0.426285; batch adversarial loss: 0.553811\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308218; batch adversarial loss: 0.590996\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324620; batch adversarial loss: 0.582873\n",
      "epoch 187; iter: 0; batch classifier loss: 0.397312; batch adversarial loss: 0.563832\n",
      "epoch 188; iter: 0; batch classifier loss: 0.296887; batch adversarial loss: 0.610029\n",
      "epoch 189; iter: 0; batch classifier loss: 0.384728; batch adversarial loss: 0.508418\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347110; batch adversarial loss: 0.536073\n",
      "epoch 191; iter: 0; batch classifier loss: 0.462878; batch adversarial loss: 0.488143\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385813; batch adversarial loss: 0.524885\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344251; batch adversarial loss: 0.525250\n",
      "epoch 194; iter: 0; batch classifier loss: 0.388442; batch adversarial loss: 0.612259\n",
      "epoch 195; iter: 0; batch classifier loss: 0.367473; batch adversarial loss: 0.571135\n",
      "epoch 196; iter: 0; batch classifier loss: 0.315105; batch adversarial loss: 0.584703\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351163; batch adversarial loss: 0.544394\n",
      "epoch 198; iter: 0; batch classifier loss: 0.444035; batch adversarial loss: 0.476989\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362567; batch adversarial loss: 0.544022\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663323; batch adversarial loss: 0.679809\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582889; batch adversarial loss: 0.650487\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611084; batch adversarial loss: 0.627994\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531545; batch adversarial loss: 0.628948\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551561; batch adversarial loss: 0.606422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578646; batch adversarial loss: 0.605768\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565056; batch adversarial loss: 0.621504\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490503; batch adversarial loss: 0.635184\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497470; batch adversarial loss: 0.581982\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531721; batch adversarial loss: 0.560125\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554801; batch adversarial loss: 0.578870\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611382; batch adversarial loss: 0.559153\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505652; batch adversarial loss: 0.567242\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532429; batch adversarial loss: 0.611992\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480039; batch adversarial loss: 0.584177\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540220; batch adversarial loss: 0.640092\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448361; batch adversarial loss: 0.594173\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541786; batch adversarial loss: 0.494066\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522943; batch adversarial loss: 0.642920\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455573; batch adversarial loss: 0.615283\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447254; batch adversarial loss: 0.572006\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513620; batch adversarial loss: 0.499713\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437180; batch adversarial loss: 0.581569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491656; batch adversarial loss: 0.572871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.473369; batch adversarial loss: 0.503645\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521802; batch adversarial loss: 0.478544\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466204; batch adversarial loss: 0.547774\n",
      "epoch 27; iter: 0; batch classifier loss: 0.502397; batch adversarial loss: 0.538932\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512364; batch adversarial loss: 0.570841\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457633; batch adversarial loss: 0.512803\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462347; batch adversarial loss: 0.536851\n",
      "epoch 31; iter: 0; batch classifier loss: 0.487484; batch adversarial loss: 0.553888\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449474; batch adversarial loss: 0.528192\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459298; batch adversarial loss: 0.579811\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431656; batch adversarial loss: 0.518780\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432704; batch adversarial loss: 0.570794\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434458; batch adversarial loss: 0.571908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448865; batch adversarial loss: 0.526657\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488713; batch adversarial loss: 0.607300\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499221; batch adversarial loss: 0.491464\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425859; batch adversarial loss: 0.526923\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422600; batch adversarial loss: 0.597705\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462691; batch adversarial loss: 0.570056\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421606; batch adversarial loss: 0.519731\n",
      "epoch 44; iter: 0; batch classifier loss: 0.510378; batch adversarial loss: 0.542913\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467680; batch adversarial loss: 0.561282\n",
      "epoch 46; iter: 0; batch classifier loss: 0.501956; batch adversarial loss: 0.553604\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486845; batch adversarial loss: 0.534489\n",
      "epoch 48; iter: 0; batch classifier loss: 0.330949; batch adversarial loss: 0.552626\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475373; batch adversarial loss: 0.626239\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442250; batch adversarial loss: 0.472685\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401698; batch adversarial loss: 0.518741\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426319; batch adversarial loss: 0.525930\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405034; batch adversarial loss: 0.527199\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414673; batch adversarial loss: 0.547909\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441254; batch adversarial loss: 0.603334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.460908; batch adversarial loss: 0.583045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.451589; batch adversarial loss: 0.499366\n",
      "epoch 58; iter: 0; batch classifier loss: 0.331639; batch adversarial loss: 0.572547\n",
      "epoch 59; iter: 0; batch classifier loss: 0.494437; batch adversarial loss: 0.499624\n",
      "epoch 60; iter: 0; batch classifier loss: 0.479224; batch adversarial loss: 0.564983\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413697; batch adversarial loss: 0.587308\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389303; batch adversarial loss: 0.537218\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399910; batch adversarial loss: 0.463200\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404330; batch adversarial loss: 0.533270\n",
      "epoch 65; iter: 0; batch classifier loss: 0.333292; batch adversarial loss: 0.532114\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396979; batch adversarial loss: 0.534440\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380634; batch adversarial loss: 0.557984\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439883; batch adversarial loss: 0.540078\n",
      "epoch 69; iter: 0; batch classifier loss: 0.474955; batch adversarial loss: 0.544595\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443020; batch adversarial loss: 0.581262\n",
      "epoch 71; iter: 0; batch classifier loss: 0.363937; batch adversarial loss: 0.565086\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371496; batch adversarial loss: 0.499157\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371102; batch adversarial loss: 0.523689\n",
      "epoch 74; iter: 0; batch classifier loss: 0.428765; batch adversarial loss: 0.599600\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425566; batch adversarial loss: 0.554312\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411139; batch adversarial loss: 0.549412\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383233; batch adversarial loss: 0.543698\n",
      "epoch 78; iter: 0; batch classifier loss: 0.414017; batch adversarial loss: 0.559147\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398004; batch adversarial loss: 0.544300\n",
      "epoch 80; iter: 0; batch classifier loss: 0.321261; batch adversarial loss: 0.507957\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410982; batch adversarial loss: 0.554688\n",
      "epoch 82; iter: 0; batch classifier loss: 0.341827; batch adversarial loss: 0.644908\n",
      "epoch 83; iter: 0; batch classifier loss: 0.464212; batch adversarial loss: 0.561784\n",
      "epoch 84; iter: 0; batch classifier loss: 0.485461; batch adversarial loss: 0.514076\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387105; batch adversarial loss: 0.539436\n",
      "epoch 86; iter: 0; batch classifier loss: 0.388381; batch adversarial loss: 0.497445\n",
      "epoch 87; iter: 0; batch classifier loss: 0.481173; batch adversarial loss: 0.561468\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441845; batch adversarial loss: 0.542680\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401139; batch adversarial loss: 0.545054\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395159; batch adversarial loss: 0.598153\n",
      "epoch 91; iter: 0; batch classifier loss: 0.453878; batch adversarial loss: 0.525609\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.600870\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393852; batch adversarial loss: 0.575176\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414453; batch adversarial loss: 0.453618\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392347; batch adversarial loss: 0.545892\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381117; batch adversarial loss: 0.518335\n",
      "epoch 97; iter: 0; batch classifier loss: 0.322400; batch adversarial loss: 0.518300\n",
      "epoch 98; iter: 0; batch classifier loss: 0.430166; batch adversarial loss: 0.472472\n",
      "epoch 99; iter: 0; batch classifier loss: 0.450386; batch adversarial loss: 0.560648\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418957; batch adversarial loss: 0.517780\n",
      "epoch 101; iter: 0; batch classifier loss: 0.431126; batch adversarial loss: 0.537005\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437882; batch adversarial loss: 0.445338\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373135; batch adversarial loss: 0.606369\n",
      "epoch 104; iter: 0; batch classifier loss: 0.451697; batch adversarial loss: 0.527204\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384830; batch adversarial loss: 0.564786\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393388; batch adversarial loss: 0.561122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374581; batch adversarial loss: 0.545644\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384621; batch adversarial loss: 0.541508\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377568; batch adversarial loss: 0.596240\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401305; batch adversarial loss: 0.600133\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391869; batch adversarial loss: 0.537009\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410893; batch adversarial loss: 0.562168\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351161; batch adversarial loss: 0.565258\n",
      "epoch 114; iter: 0; batch classifier loss: 0.439841; batch adversarial loss: 0.560439\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410274; batch adversarial loss: 0.581716\n",
      "epoch 116; iter: 0; batch classifier loss: 0.399498; batch adversarial loss: 0.517918\n",
      "epoch 117; iter: 0; batch classifier loss: 0.502604; batch adversarial loss: 0.506933\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370202; batch adversarial loss: 0.546904\n",
      "epoch 119; iter: 0; batch classifier loss: 0.360931; batch adversarial loss: 0.566284\n",
      "epoch 120; iter: 0; batch classifier loss: 0.309866; batch adversarial loss: 0.593760\n",
      "epoch 121; iter: 0; batch classifier loss: 0.332863; batch adversarial loss: 0.609285\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398341; batch adversarial loss: 0.581399\n",
      "epoch 123; iter: 0; batch classifier loss: 0.426649; batch adversarial loss: 0.532434\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341380; batch adversarial loss: 0.556570\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386407; batch adversarial loss: 0.473403\n",
      "epoch 126; iter: 0; batch classifier loss: 0.334484; batch adversarial loss: 0.551563\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407723; batch adversarial loss: 0.491175\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368086; batch adversarial loss: 0.611876\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361417; batch adversarial loss: 0.545799\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394143; batch adversarial loss: 0.541895\n",
      "epoch 131; iter: 0; batch classifier loss: 0.500098; batch adversarial loss: 0.595442\n",
      "epoch 132; iter: 0; batch classifier loss: 0.345944; batch adversarial loss: 0.565468\n",
      "epoch 133; iter: 0; batch classifier loss: 0.358057; batch adversarial loss: 0.552611\n",
      "epoch 134; iter: 0; batch classifier loss: 0.318783; batch adversarial loss: 0.543929\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387146; batch adversarial loss: 0.533435\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421425; batch adversarial loss: 0.541850\n",
      "epoch 137; iter: 0; batch classifier loss: 0.429371; batch adversarial loss: 0.490616\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350600; batch adversarial loss: 0.446359\n",
      "epoch 139; iter: 0; batch classifier loss: 0.404662; batch adversarial loss: 0.588698\n",
      "epoch 140; iter: 0; batch classifier loss: 0.331563; batch adversarial loss: 0.549151\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361766; batch adversarial loss: 0.617967\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392705; batch adversarial loss: 0.466107\n",
      "epoch 143; iter: 0; batch classifier loss: 0.498572; batch adversarial loss: 0.536776\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347707; batch adversarial loss: 0.605485\n",
      "epoch 145; iter: 0; batch classifier loss: 0.428635; batch adversarial loss: 0.605409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371757; batch adversarial loss: 0.610676\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369967; batch adversarial loss: 0.603872\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378670; batch adversarial loss: 0.537181\n",
      "epoch 149; iter: 0; batch classifier loss: 0.393579; batch adversarial loss: 0.594813\n",
      "epoch 150; iter: 0; batch classifier loss: 0.379799; batch adversarial loss: 0.484002\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348824; batch adversarial loss: 0.559421\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388261; batch adversarial loss: 0.550480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.570854\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397627; batch adversarial loss: 0.534278\n",
      "epoch 155; iter: 0; batch classifier loss: 0.409071; batch adversarial loss: 0.500769\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348667; batch adversarial loss: 0.561400\n",
      "epoch 157; iter: 0; batch classifier loss: 0.364250; batch adversarial loss: 0.559960\n",
      "epoch 158; iter: 0; batch classifier loss: 0.370510; batch adversarial loss: 0.497140\n",
      "epoch 159; iter: 0; batch classifier loss: 0.457515; batch adversarial loss: 0.553388\n",
      "epoch 160; iter: 0; batch classifier loss: 0.405766; batch adversarial loss: 0.515143\n",
      "epoch 161; iter: 0; batch classifier loss: 0.353669; batch adversarial loss: 0.568077\n",
      "epoch 162; iter: 0; batch classifier loss: 0.454399; batch adversarial loss: 0.509145\n",
      "epoch 163; iter: 0; batch classifier loss: 0.307395; batch adversarial loss: 0.502139\n",
      "epoch 164; iter: 0; batch classifier loss: 0.379081; batch adversarial loss: 0.519211\n",
      "epoch 165; iter: 0; batch classifier loss: 0.403319; batch adversarial loss: 0.566123\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333006; batch adversarial loss: 0.550583\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332696; batch adversarial loss: 0.466993\n",
      "epoch 168; iter: 0; batch classifier loss: 0.417648; batch adversarial loss: 0.568913\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334303; batch adversarial loss: 0.641225\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299312; batch adversarial loss: 0.601330\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382861; batch adversarial loss: 0.509006\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397647; batch adversarial loss: 0.622882\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372010; batch adversarial loss: 0.774378\n",
      "epoch 174; iter: 0; batch classifier loss: 0.464071; batch adversarial loss: 0.622851\n",
      "epoch 175; iter: 0; batch classifier loss: 0.443272; batch adversarial loss: 0.527318\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340660; batch adversarial loss: 0.472484\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337960; batch adversarial loss: 0.596545\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316830; batch adversarial loss: 0.586289\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378960; batch adversarial loss: 0.528596\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381376; batch adversarial loss: 0.560901\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374900; batch adversarial loss: 0.525869\n",
      "epoch 182; iter: 0; batch classifier loss: 0.455252; batch adversarial loss: 0.538875\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338176; batch adversarial loss: 0.590173\n",
      "epoch 184; iter: 0; batch classifier loss: 0.413805; batch adversarial loss: 0.525642\n",
      "epoch 185; iter: 0; batch classifier loss: 0.318812; batch adversarial loss: 0.555957\n",
      "epoch 186; iter: 0; batch classifier loss: 0.386575; batch adversarial loss: 0.451909\n",
      "epoch 187; iter: 0; batch classifier loss: 0.317581; batch adversarial loss: 0.520308\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378481; batch adversarial loss: 0.563253\n",
      "epoch 189; iter: 0; batch classifier loss: 0.389384; batch adversarial loss: 0.555020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.433777; batch adversarial loss: 0.498075\n",
      "epoch 191; iter: 0; batch classifier loss: 0.347172; batch adversarial loss: 0.529321\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373392; batch adversarial loss: 0.545088\n",
      "epoch 193; iter: 0; batch classifier loss: 0.302264; batch adversarial loss: 0.467158\n",
      "epoch 194; iter: 0; batch classifier loss: 0.458075; batch adversarial loss: 0.609042\n",
      "epoch 195; iter: 0; batch classifier loss: 0.326948; batch adversarial loss: 0.578983\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341956; batch adversarial loss: 0.583683\n",
      "epoch 197; iter: 0; batch classifier loss: 0.408963; batch adversarial loss: 0.631007\n",
      "epoch 198; iter: 0; batch classifier loss: 0.415963; batch adversarial loss: 0.555404\n",
      "epoch 199; iter: 0; batch classifier loss: 0.453771; batch adversarial loss: 0.480506\n",
      "epoch 0; iter: 0; batch classifier loss: 0.821659; batch adversarial loss: 1.028108\n",
      "epoch 1; iter: 0; batch classifier loss: 0.876344; batch adversarial loss: 1.051109\n",
      "epoch 2; iter: 0; batch classifier loss: 1.057120; batch adversarial loss: 1.052415\n",
      "epoch 3; iter: 0; batch classifier loss: 0.997778; batch adversarial loss: 0.938684\n",
      "epoch 4; iter: 0; batch classifier loss: 1.146204; batch adversarial loss: 0.881442\n",
      "epoch 5; iter: 0; batch classifier loss: 1.084436; batch adversarial loss: 0.809403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.975519; batch adversarial loss: 0.722573\n",
      "epoch 7; iter: 0; batch classifier loss: 0.942782; batch adversarial loss: 0.671076\n",
      "epoch 8; iter: 0; batch classifier loss: 0.799114; batch adversarial loss: 0.639184\n",
      "epoch 9; iter: 0; batch classifier loss: 0.639156; batch adversarial loss: 0.585922\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533650; batch adversarial loss: 0.622564\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519166; batch adversarial loss: 0.588169\n",
      "epoch 12; iter: 0; batch classifier loss: 0.524610; batch adversarial loss: 0.570906\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485515; batch adversarial loss: 0.581196\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579673; batch adversarial loss: 0.541573\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535392; batch adversarial loss: 0.604147\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480028; batch adversarial loss: 0.620120\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544614; batch adversarial loss: 0.589712\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555035; batch adversarial loss: 0.552023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507876; batch adversarial loss: 0.559145\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470045; batch adversarial loss: 0.571442\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541588; batch adversarial loss: 0.556575\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459904; batch adversarial loss: 0.555921\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484289; batch adversarial loss: 0.567125\n",
      "epoch 24; iter: 0; batch classifier loss: 0.537031; batch adversarial loss: 0.520025\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523659; batch adversarial loss: 0.527470\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506087; batch adversarial loss: 0.515895\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450021; batch adversarial loss: 0.515904\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523059; batch adversarial loss: 0.556044\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509572; batch adversarial loss: 0.557065\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449089; batch adversarial loss: 0.552746\n",
      "epoch 31; iter: 0; batch classifier loss: 0.490117; batch adversarial loss: 0.605960\n",
      "epoch 32; iter: 0; batch classifier loss: 0.424800; batch adversarial loss: 0.559494\n",
      "epoch 33; iter: 0; batch classifier loss: 0.410905; batch adversarial loss: 0.498422\n",
      "epoch 34; iter: 0; batch classifier loss: 0.541000; batch adversarial loss: 0.513783\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423202; batch adversarial loss: 0.535047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455979; batch adversarial loss: 0.503877\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456845; batch adversarial loss: 0.591598\n",
      "epoch 38; iter: 0; batch classifier loss: 0.493522; batch adversarial loss: 0.491394\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497376; batch adversarial loss: 0.525567\n",
      "epoch 40; iter: 0; batch classifier loss: 0.489336; batch adversarial loss: 0.527426\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419601; batch adversarial loss: 0.621945\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484137; batch adversarial loss: 0.531146\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477153; batch adversarial loss: 0.518659\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456097; batch adversarial loss: 0.505431\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441513; batch adversarial loss: 0.493184\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408765; batch adversarial loss: 0.611271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424018; batch adversarial loss: 0.552826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442456; batch adversarial loss: 0.509874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 0; batch classifier loss: 0.403546; batch adversarial loss: 0.509081\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403116; batch adversarial loss: 0.581701\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458606; batch adversarial loss: 0.545809\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466320; batch adversarial loss: 0.543819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388607; batch adversarial loss: 0.472120\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486559; batch adversarial loss: 0.580906\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465598; batch adversarial loss: 0.553355\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451111; batch adversarial loss: 0.644631\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409616; batch adversarial loss: 0.637974\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445451; batch adversarial loss: 0.573463\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419631; batch adversarial loss: 0.532818\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376648; batch adversarial loss: 0.554696\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395538; batch adversarial loss: 0.601022\n",
      "epoch 62; iter: 0; batch classifier loss: 0.411844; batch adversarial loss: 0.545933\n",
      "epoch 63; iter: 0; batch classifier loss: 0.485047; batch adversarial loss: 0.526461\n",
      "epoch 64; iter: 0; batch classifier loss: 0.492977; batch adversarial loss: 0.488839\n",
      "epoch 65; iter: 0; batch classifier loss: 0.518995; batch adversarial loss: 0.580904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437112; batch adversarial loss: 0.588957\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435885; batch adversarial loss: 0.515398\n",
      "epoch 68; iter: 0; batch classifier loss: 0.354035; batch adversarial loss: 0.624789\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405999; batch adversarial loss: 0.491205\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423636; batch adversarial loss: 0.551604\n",
      "epoch 71; iter: 0; batch classifier loss: 0.462216; batch adversarial loss: 0.547809\n",
      "epoch 72; iter: 0; batch classifier loss: 0.527125; batch adversarial loss: 0.599440\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379524; batch adversarial loss: 0.554161\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436150; batch adversarial loss: 0.581311\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415819; batch adversarial loss: 0.563720\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394141; batch adversarial loss: 0.618041\n",
      "epoch 77; iter: 0; batch classifier loss: 0.357011; batch adversarial loss: 0.568688\n",
      "epoch 78; iter: 0; batch classifier loss: 0.413423; batch adversarial loss: 0.571373\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385877; batch adversarial loss: 0.633126\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399905; batch adversarial loss: 0.579910\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426528; batch adversarial loss: 0.590444\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405062; batch adversarial loss: 0.572391\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365611; batch adversarial loss: 0.543448\n",
      "epoch 84; iter: 0; batch classifier loss: 0.476247; batch adversarial loss: 0.505629\n",
      "epoch 85; iter: 0; batch classifier loss: 0.335609; batch adversarial loss: 0.631886\n",
      "epoch 86; iter: 0; batch classifier loss: 0.455062; batch adversarial loss: 0.546516\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421156; batch adversarial loss: 0.564021\n",
      "epoch 88; iter: 0; batch classifier loss: 0.304167; batch adversarial loss: 0.513778\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407975; batch adversarial loss: 0.524177\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345047; batch adversarial loss: 0.544773\n",
      "epoch 91; iter: 0; batch classifier loss: 0.355790; batch adversarial loss: 0.534038\n",
      "epoch 92; iter: 0; batch classifier loss: 0.352866; batch adversarial loss: 0.563375\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325381; batch adversarial loss: 0.479971\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415790; batch adversarial loss: 0.515971\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381434; batch adversarial loss: 0.620641\n",
      "epoch 96; iter: 0; batch classifier loss: 0.357885; batch adversarial loss: 0.538108\n",
      "epoch 97; iter: 0; batch classifier loss: 0.330402; batch adversarial loss: 0.451111\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369318; batch adversarial loss: 0.470782\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312486; batch adversarial loss: 0.555113\n",
      "epoch 100; iter: 0; batch classifier loss: 0.333925; batch adversarial loss: 0.635292\n",
      "epoch 101; iter: 0; batch classifier loss: 0.287137; batch adversarial loss: 0.516899\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415871; batch adversarial loss: 0.576827\n",
      "epoch 103; iter: 0; batch classifier loss: 0.363557; batch adversarial loss: 0.555581\n",
      "epoch 104; iter: 0; batch classifier loss: 0.450060; batch adversarial loss: 0.525780\n",
      "epoch 105; iter: 0; batch classifier loss: 0.464555; batch adversarial loss: 0.568174\n",
      "epoch 106; iter: 0; batch classifier loss: 0.368797; batch adversarial loss: 0.657982\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375675; batch adversarial loss: 0.691479\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378219; batch adversarial loss: 0.607387\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367807; batch adversarial loss: 0.528725\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357862; batch adversarial loss: 0.517523\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408399; batch adversarial loss: 0.579721\n",
      "epoch 112; iter: 0; batch classifier loss: 0.352499; batch adversarial loss: 0.534176\n",
      "epoch 113; iter: 0; batch classifier loss: 0.420116; batch adversarial loss: 0.500547\n",
      "epoch 114; iter: 0; batch classifier loss: 0.261579; batch adversarial loss: 0.532761\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390865; batch adversarial loss: 0.506317\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323260; batch adversarial loss: 0.518070\n",
      "epoch 117; iter: 0; batch classifier loss: 0.341863; batch adversarial loss: 0.486505\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330339; batch adversarial loss: 0.441908\n",
      "epoch 119; iter: 0; batch classifier loss: 0.314430; batch adversarial loss: 0.492929\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369109; batch adversarial loss: 0.638245\n",
      "epoch 121; iter: 0; batch classifier loss: 0.415638; batch adversarial loss: 0.561678\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352031; batch adversarial loss: 0.471302\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369939; batch adversarial loss: 0.532718\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398806; batch adversarial loss: 0.545317\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334944; batch adversarial loss: 0.535549\n",
      "epoch 126; iter: 0; batch classifier loss: 0.325150; batch adversarial loss: 0.487952\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396461; batch adversarial loss: 0.539715\n",
      "epoch 128; iter: 0; batch classifier loss: 0.306891; batch adversarial loss: 0.556695\n",
      "epoch 129; iter: 0; batch classifier loss: 0.383973; batch adversarial loss: 0.563558\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378910; batch adversarial loss: 0.519547\n",
      "epoch 131; iter: 0; batch classifier loss: 0.312979; batch adversarial loss: 0.534804\n",
      "epoch 132; iter: 0; batch classifier loss: 0.436149; batch adversarial loss: 0.558753\n",
      "epoch 133; iter: 0; batch classifier loss: 0.318634; batch adversarial loss: 0.552807\n",
      "epoch 134; iter: 0; batch classifier loss: 0.411885; batch adversarial loss: 0.509881\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350175; batch adversarial loss: 0.612080\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338603; batch adversarial loss: 0.597794\n",
      "epoch 137; iter: 0; batch classifier loss: 0.304240; batch adversarial loss: 0.573924\n",
      "epoch 138; iter: 0; batch classifier loss: 0.348549; batch adversarial loss: 0.537772\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361236; batch adversarial loss: 0.514521\n",
      "epoch 140; iter: 0; batch classifier loss: 0.324497; batch adversarial loss: 0.575562\n",
      "epoch 141; iter: 0; batch classifier loss: 0.312482; batch adversarial loss: 0.628798\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372200; batch adversarial loss: 0.521513\n",
      "epoch 143; iter: 0; batch classifier loss: 0.316870; batch adversarial loss: 0.543913\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424725; batch adversarial loss: 0.611546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.369134; batch adversarial loss: 0.543928\n",
      "epoch 146; iter: 0; batch classifier loss: 0.417689; batch adversarial loss: 0.524068\n",
      "epoch 147; iter: 0; batch classifier loss: 0.429328; batch adversarial loss: 0.574858\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342007; batch adversarial loss: 0.570909\n",
      "epoch 149; iter: 0; batch classifier loss: 0.407679; batch adversarial loss: 0.594180\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413633; batch adversarial loss: 0.577644\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347593; batch adversarial loss: 0.506499\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370714; batch adversarial loss: 0.550758\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357230; batch adversarial loss: 0.582836\n",
      "epoch 154; iter: 0; batch classifier loss: 0.409898; batch adversarial loss: 0.562165\n",
      "epoch 155; iter: 0; batch classifier loss: 0.439440; batch adversarial loss: 0.562149\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337641; batch adversarial loss: 0.506772\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319851; batch adversarial loss: 0.646899\n",
      "epoch 158; iter: 0; batch classifier loss: 0.418404; batch adversarial loss: 0.592564\n",
      "epoch 159; iter: 0; batch classifier loss: 0.386595; batch adversarial loss: 0.563506\n",
      "epoch 160; iter: 0; batch classifier loss: 0.301807; batch adversarial loss: 0.593376\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393910; batch adversarial loss: 0.526914\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286576; batch adversarial loss: 0.646721\n",
      "epoch 163; iter: 0; batch classifier loss: 0.432593; batch adversarial loss: 0.540036\n",
      "epoch 164; iter: 0; batch classifier loss: 0.349650; batch adversarial loss: 0.602207\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393243; batch adversarial loss: 0.485864\n",
      "epoch 166; iter: 0; batch classifier loss: 0.303610; batch adversarial loss: 0.573093\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324941; batch adversarial loss: 0.525909\n",
      "epoch 168; iter: 0; batch classifier loss: 0.310222; batch adversarial loss: 0.537468\n",
      "epoch 169; iter: 0; batch classifier loss: 0.378796; batch adversarial loss: 0.491365\n",
      "epoch 170; iter: 0; batch classifier loss: 0.356106; batch adversarial loss: 0.559631\n",
      "epoch 171; iter: 0; batch classifier loss: 0.371365; batch adversarial loss: 0.596629\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355734; batch adversarial loss: 0.574752\n",
      "epoch 173; iter: 0; batch classifier loss: 0.426110; batch adversarial loss: 0.526575\n",
      "epoch 174; iter: 0; batch classifier loss: 0.423313; batch adversarial loss: 0.670249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329420; batch adversarial loss: 0.544377\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346752; batch adversarial loss: 0.583137\n",
      "epoch 177; iter: 0; batch classifier loss: 0.308615; batch adversarial loss: 0.534737\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343095; batch adversarial loss: 0.488119\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374403; batch adversarial loss: 0.558467\n",
      "epoch 180; iter: 0; batch classifier loss: 0.247808; batch adversarial loss: 0.558309\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319527; batch adversarial loss: 0.554169\n",
      "epoch 182; iter: 0; batch classifier loss: 0.409729; batch adversarial loss: 0.450735\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372108; batch adversarial loss: 0.552575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.493807; batch adversarial loss: 0.488077\n",
      "epoch 185; iter: 0; batch classifier loss: 0.450639; batch adversarial loss: 0.501393\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334627; batch adversarial loss: 0.491478\n",
      "epoch 187; iter: 0; batch classifier loss: 0.309095; batch adversarial loss: 0.540469\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392688; batch adversarial loss: 0.551375\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354364; batch adversarial loss: 0.543254\n",
      "epoch 190; iter: 0; batch classifier loss: 0.344269; batch adversarial loss: 0.572511\n",
      "epoch 191; iter: 0; batch classifier loss: 0.303513; batch adversarial loss: 0.563252\n",
      "epoch 192; iter: 0; batch classifier loss: 0.311431; batch adversarial loss: 0.510723\n",
      "epoch 193; iter: 0; batch classifier loss: 0.334536; batch adversarial loss: 0.579513\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332723; batch adversarial loss: 0.579639\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319615; batch adversarial loss: 0.554116\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314903; batch adversarial loss: 0.461109\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335061; batch adversarial loss: 0.571232\n",
      "epoch 198; iter: 0; batch classifier loss: 0.281610; batch adversarial loss: 0.608903\n",
      "epoch 199; iter: 0; batch classifier loss: 0.362648; batch adversarial loss: 0.461980\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672263; batch adversarial loss: 0.667516\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622594; batch adversarial loss: 0.645712\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612191; batch adversarial loss: 0.641952\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541050; batch adversarial loss: 0.636946\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558721; batch adversarial loss: 0.631348\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555439; batch adversarial loss: 0.623107\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641411; batch adversarial loss: 0.665229\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561394; batch adversarial loss: 0.633077\n",
      "epoch 8; iter: 0; batch classifier loss: 0.632233; batch adversarial loss: 0.551354\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518517; batch adversarial loss: 0.613704\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577854; batch adversarial loss: 0.654941\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543413; batch adversarial loss: 0.589400\n",
      "epoch 12; iter: 0; batch classifier loss: 0.583771; batch adversarial loss: 0.624933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556064; batch adversarial loss: 0.625634\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558028; batch adversarial loss: 0.552714\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493760; batch adversarial loss: 0.521645\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520885; batch adversarial loss: 0.610352\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488690; batch adversarial loss: 0.556469\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522964; batch adversarial loss: 0.557882\n",
      "epoch 19; iter: 0; batch classifier loss: 0.418365; batch adversarial loss: 0.552640\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530271; batch adversarial loss: 0.540818\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513441; batch adversarial loss: 0.569694\n",
      "epoch 22; iter: 0; batch classifier loss: 0.564221; batch adversarial loss: 0.506494\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513343; batch adversarial loss: 0.565484\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515337; batch adversarial loss: 0.559557\n",
      "epoch 25; iter: 0; batch classifier loss: 0.569010; batch adversarial loss: 0.580218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.364152; batch adversarial loss: 0.564677\n",
      "epoch 27; iter: 0; batch classifier loss: 0.496136; batch adversarial loss: 0.489486\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496804; batch adversarial loss: 0.546859\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471197; batch adversarial loss: 0.496975\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480224; batch adversarial loss: 0.561903\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438063; batch adversarial loss: 0.549267\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448074; batch adversarial loss: 0.518959\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478944; batch adversarial loss: 0.648077\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390352; batch adversarial loss: 0.578286\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488657; batch adversarial loss: 0.603978\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472111; batch adversarial loss: 0.578927\n",
      "epoch 37; iter: 0; batch classifier loss: 0.492472; batch adversarial loss: 0.606051\n",
      "epoch 38; iter: 0; batch classifier loss: 0.501280; batch adversarial loss: 0.561959\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473931; batch adversarial loss: 0.526947\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422337; batch adversarial loss: 0.612787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.441709; batch adversarial loss: 0.634812\n",
      "epoch 42; iter: 0; batch classifier loss: 0.509878; batch adversarial loss: 0.440278\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398470; batch adversarial loss: 0.517180\n",
      "epoch 44; iter: 0; batch classifier loss: 0.521538; batch adversarial loss: 0.537526\n",
      "epoch 45; iter: 0; batch classifier loss: 0.529205; batch adversarial loss: 0.481532\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426164; batch adversarial loss: 0.572564\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451741; batch adversarial loss: 0.465278\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387978; batch adversarial loss: 0.605473\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427542; batch adversarial loss: 0.482873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.496814; batch adversarial loss: 0.552920\n",
      "epoch 51; iter: 0; batch classifier loss: 0.533478; batch adversarial loss: 0.545222\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435378; batch adversarial loss: 0.571127\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388460; batch adversarial loss: 0.587792\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453708; batch adversarial loss: 0.582828\n",
      "epoch 55; iter: 0; batch classifier loss: 0.338836; batch adversarial loss: 0.551800\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398274; batch adversarial loss: 0.568816\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422616; batch adversarial loss: 0.536003\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466528; batch adversarial loss: 0.626060\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428136; batch adversarial loss: 0.621265\n",
      "epoch 60; iter: 0; batch classifier loss: 0.494983; batch adversarial loss: 0.627972\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441441; batch adversarial loss: 0.569315\n",
      "epoch 62; iter: 0; batch classifier loss: 0.494052; batch adversarial loss: 0.608730\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454739; batch adversarial loss: 0.597570\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454025; batch adversarial loss: 0.482834\n",
      "epoch 65; iter: 0; batch classifier loss: 0.476302; batch adversarial loss: 0.555240\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411904; batch adversarial loss: 0.563162\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447507; batch adversarial loss: 0.515172\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405369; batch adversarial loss: 0.564395\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439165; batch adversarial loss: 0.543619\n",
      "epoch 70; iter: 0; batch classifier loss: 0.373907; batch adversarial loss: 0.533008\n",
      "epoch 71; iter: 0; batch classifier loss: 0.467564; batch adversarial loss: 0.551017\n",
      "epoch 72; iter: 0; batch classifier loss: 0.461880; batch adversarial loss: 0.551362\n",
      "epoch 73; iter: 0; batch classifier loss: 0.476717; batch adversarial loss: 0.544666\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356299; batch adversarial loss: 0.550878\n",
      "epoch 75; iter: 0; batch classifier loss: 0.473642; batch adversarial loss: 0.578340\n",
      "epoch 76; iter: 0; batch classifier loss: 0.414984; batch adversarial loss: 0.630067\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437872; batch adversarial loss: 0.587908\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397391; batch adversarial loss: 0.594252\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401218; batch adversarial loss: 0.544769\n",
      "epoch 80; iter: 0; batch classifier loss: 0.477983; batch adversarial loss: 0.583922\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405675; batch adversarial loss: 0.566815\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447444; batch adversarial loss: 0.583396\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429037; batch adversarial loss: 0.596750\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409423; batch adversarial loss: 0.583097\n",
      "epoch 85; iter: 0; batch classifier loss: 0.464210; batch adversarial loss: 0.463415\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427644; batch adversarial loss: 0.526473\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370051; batch adversarial loss: 0.579097\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408347; batch adversarial loss: 0.572106\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410464; batch adversarial loss: 0.499507\n",
      "epoch 90; iter: 0; batch classifier loss: 0.437991; batch adversarial loss: 0.560745\n",
      "epoch 91; iter: 0; batch classifier loss: 0.455139; batch adversarial loss: 0.578924\n",
      "epoch 92; iter: 0; batch classifier loss: 0.438030; batch adversarial loss: 0.617346\n",
      "epoch 93; iter: 0; batch classifier loss: 0.485947; batch adversarial loss: 0.563215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449737; batch adversarial loss: 0.517325\n",
      "epoch 95; iter: 0; batch classifier loss: 0.369593; batch adversarial loss: 0.602342\n",
      "epoch 96; iter: 0; batch classifier loss: 0.455918; batch adversarial loss: 0.545294\n",
      "epoch 97; iter: 0; batch classifier loss: 0.360521; batch adversarial loss: 0.553535\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434605; batch adversarial loss: 0.587499\n",
      "epoch 99; iter: 0; batch classifier loss: 0.420643; batch adversarial loss: 0.573120\n",
      "epoch 100; iter: 0; batch classifier loss: 0.447150; batch adversarial loss: 0.553227\n",
      "epoch 101; iter: 0; batch classifier loss: 0.351602; batch adversarial loss: 0.577458\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377648; batch adversarial loss: 0.611158\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408637; batch adversarial loss: 0.543744\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383484; batch adversarial loss: 0.517035\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362508; batch adversarial loss: 0.515019\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432707; batch adversarial loss: 0.590472\n",
      "epoch 107; iter: 0; batch classifier loss: 0.393867; batch adversarial loss: 0.511432\n",
      "epoch 108; iter: 0; batch classifier loss: 0.302683; batch adversarial loss: 0.528772\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368731; batch adversarial loss: 0.455159\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379898; batch adversarial loss: 0.560245\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375594; batch adversarial loss: 0.506536\n",
      "epoch 112; iter: 0; batch classifier loss: 0.501132; batch adversarial loss: 0.494786\n",
      "epoch 113; iter: 0; batch classifier loss: 0.427690; batch adversarial loss: 0.572454\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360784; batch adversarial loss: 0.485194\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412399; batch adversarial loss: 0.581463\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423677; batch adversarial loss: 0.552654\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369299; batch adversarial loss: 0.570431\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361808; batch adversarial loss: 0.613288\n",
      "epoch 119; iter: 0; batch classifier loss: 0.441384; batch adversarial loss: 0.608438\n",
      "epoch 120; iter: 0; batch classifier loss: 0.435410; batch adversarial loss: 0.615609\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400166; batch adversarial loss: 0.601546\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415126; batch adversarial loss: 0.448479\n",
      "epoch 123; iter: 0; batch classifier loss: 0.456787; batch adversarial loss: 0.509055\n",
      "epoch 124; iter: 0; batch classifier loss: 0.401738; batch adversarial loss: 0.639335\n",
      "epoch 125; iter: 0; batch classifier loss: 0.318456; batch adversarial loss: 0.528462\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330435; batch adversarial loss: 0.572792\n",
      "epoch 127; iter: 0; batch classifier loss: 0.481296; batch adversarial loss: 0.582581\n",
      "epoch 128; iter: 0; batch classifier loss: 0.393764; batch adversarial loss: 0.577628\n",
      "epoch 129; iter: 0; batch classifier loss: 0.315120; batch adversarial loss: 0.505977\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322383; batch adversarial loss: 0.552404\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388730; batch adversarial loss: 0.542118\n",
      "epoch 132; iter: 0; batch classifier loss: 0.464796; batch adversarial loss: 0.510252\n",
      "epoch 133; iter: 0; batch classifier loss: 0.406790; batch adversarial loss: 0.581501\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350157; batch adversarial loss: 0.552272\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381557; batch adversarial loss: 0.588124\n",
      "epoch 136; iter: 0; batch classifier loss: 0.400218; batch adversarial loss: 0.583930\n",
      "epoch 137; iter: 0; batch classifier loss: 0.398974; batch adversarial loss: 0.602550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.372286; batch adversarial loss: 0.587011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.388427; batch adversarial loss: 0.597019\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377507; batch adversarial loss: 0.553306\n",
      "epoch 141; iter: 0; batch classifier loss: 0.300362; batch adversarial loss: 0.631004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417523; batch adversarial loss: 0.604324\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382275; batch adversarial loss: 0.508536\n",
      "epoch 144; iter: 0; batch classifier loss: 0.383173; batch adversarial loss: 0.525533\n",
      "epoch 145; iter: 0; batch classifier loss: 0.468948; batch adversarial loss: 0.527907\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383005; batch adversarial loss: 0.547203\n",
      "epoch 147; iter: 0; batch classifier loss: 0.416712; batch adversarial loss: 0.508903\n",
      "epoch 148; iter: 0; batch classifier loss: 0.479348; batch adversarial loss: 0.501500\n",
      "epoch 149; iter: 0; batch classifier loss: 0.414633; batch adversarial loss: 0.572436\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362220; batch adversarial loss: 0.463036\n",
      "epoch 151; iter: 0; batch classifier loss: 0.433796; batch adversarial loss: 0.561809\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336133; batch adversarial loss: 0.563304\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334493; batch adversarial loss: 0.468423\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364114; batch adversarial loss: 0.582836\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350970; batch adversarial loss: 0.565026\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377030; batch adversarial loss: 0.606165\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371301; batch adversarial loss: 0.585229\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368970; batch adversarial loss: 0.530749\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323583; batch adversarial loss: 0.582164\n",
      "epoch 160; iter: 0; batch classifier loss: 0.437828; batch adversarial loss: 0.478070\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387864; batch adversarial loss: 0.559495\n",
      "epoch 162; iter: 0; batch classifier loss: 0.505837; batch adversarial loss: 0.595784\n",
      "epoch 163; iter: 0; batch classifier loss: 0.358652; batch adversarial loss: 0.522381\n",
      "epoch 164; iter: 0; batch classifier loss: 0.440627; batch adversarial loss: 0.551757\n",
      "epoch 165; iter: 0; batch classifier loss: 0.319819; batch adversarial loss: 0.534490\n",
      "epoch 166; iter: 0; batch classifier loss: 0.459758; batch adversarial loss: 0.624873\n",
      "epoch 167; iter: 0; batch classifier loss: 0.428476; batch adversarial loss: 0.499317\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401488; batch adversarial loss: 0.546773\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341993; batch adversarial loss: 0.658842\n",
      "epoch 170; iter: 0; batch classifier loss: 0.536684; batch adversarial loss: 0.589746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340535; batch adversarial loss: 0.615589\n",
      "epoch 172; iter: 0; batch classifier loss: 0.448702; batch adversarial loss: 0.448626\n",
      "epoch 173; iter: 0; batch classifier loss: 0.359293; batch adversarial loss: 0.618700\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336875; batch adversarial loss: 0.558319\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416420; batch adversarial loss: 0.580925\n",
      "epoch 176; iter: 0; batch classifier loss: 0.423481; batch adversarial loss: 0.526695\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361703; batch adversarial loss: 0.557559\n",
      "epoch 178; iter: 0; batch classifier loss: 0.429304; batch adversarial loss: 0.581521\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395500; batch adversarial loss: 0.560968\n",
      "epoch 180; iter: 0; batch classifier loss: 0.418861; batch adversarial loss: 0.541981\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361998; batch adversarial loss: 0.575026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.380493; batch adversarial loss: 0.605001\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346505; batch adversarial loss: 0.543211\n",
      "epoch 184; iter: 0; batch classifier loss: 0.303870; batch adversarial loss: 0.576503\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378545; batch adversarial loss: 0.561366\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340441; batch adversarial loss: 0.562763\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367867; batch adversarial loss: 0.465478\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374185; batch adversarial loss: 0.521750\n",
      "epoch 189; iter: 0; batch classifier loss: 0.345766; batch adversarial loss: 0.484046\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407274; batch adversarial loss: 0.553839\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339434; batch adversarial loss: 0.626706\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359391; batch adversarial loss: 0.596709\n",
      "epoch 193; iter: 0; batch classifier loss: 0.407646; batch adversarial loss: 0.526547\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393730; batch adversarial loss: 0.520068\n",
      "epoch 195; iter: 0; batch classifier loss: 0.425471; batch adversarial loss: 0.556789\n",
      "epoch 196; iter: 0; batch classifier loss: 0.448870; batch adversarial loss: 0.598565\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307934; batch adversarial loss: 0.558237\n",
      "epoch 198; iter: 0; batch classifier loss: 0.407133; batch adversarial loss: 0.570607\n",
      "epoch 199; iter: 0; batch classifier loss: 0.406394; batch adversarial loss: 0.559284\n",
      "epoch 0; iter: 0; batch classifier loss: 0.746994; batch adversarial loss: 0.784735\n",
      "epoch 1; iter: 0; batch classifier loss: 0.700494; batch adversarial loss: 0.789622\n",
      "epoch 2; iter: 0; batch classifier loss: 0.879547; batch adversarial loss: 0.749808\n",
      "epoch 3; iter: 0; batch classifier loss: 0.910219; batch adversarial loss: 0.685811\n",
      "epoch 4; iter: 0; batch classifier loss: 0.654290; batch adversarial loss: 0.624952\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532580; batch adversarial loss: 0.616197\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544754; batch adversarial loss: 0.625318\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549009; batch adversarial loss: 0.619807\n",
      "epoch 8; iter: 0; batch classifier loss: 0.603375; batch adversarial loss: 0.575933\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541906; batch adversarial loss: 0.588135\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511193; batch adversarial loss: 0.593238\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481743; batch adversarial loss: 0.531493\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455106; batch adversarial loss: 0.558295\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439537; batch adversarial loss: 0.591123\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462979; batch adversarial loss: 0.561097\n",
      "epoch 15; iter: 0; batch classifier loss: 0.426404; batch adversarial loss: 0.534382\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520998; batch adversarial loss: 0.524251\n",
      "epoch 17; iter: 0; batch classifier loss: 0.583894; batch adversarial loss: 0.517442\n",
      "epoch 18; iter: 0; batch classifier loss: 0.575678; batch adversarial loss: 0.563977\n",
      "epoch 19; iter: 0; batch classifier loss: 0.571145; batch adversarial loss: 0.570963\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520782; batch adversarial loss: 0.536693\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501471; batch adversarial loss: 0.569149\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477342; batch adversarial loss: 0.563227\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530427; batch adversarial loss: 0.540892\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459632; batch adversarial loss: 0.573738\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438424; batch adversarial loss: 0.488065\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461756; batch adversarial loss: 0.593231\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447181; batch adversarial loss: 0.558214\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441850; batch adversarial loss: 0.535978\n",
      "epoch 29; iter: 0; batch classifier loss: 0.499233; batch adversarial loss: 0.548357\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438852; batch adversarial loss: 0.479290\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414915; batch adversarial loss: 0.530805\n",
      "epoch 32; iter: 0; batch classifier loss: 0.530880; batch adversarial loss: 0.543750\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426546; batch adversarial loss: 0.552550\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485813; batch adversarial loss: 0.518839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.462762; batch adversarial loss: 0.474910\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403939; batch adversarial loss: 0.623046\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477077; batch adversarial loss: 0.577909\n",
      "epoch 38; iter: 0; batch classifier loss: 0.483737; batch adversarial loss: 0.477983\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468552; batch adversarial loss: 0.532218\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450970; batch adversarial loss: 0.457547\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403048; batch adversarial loss: 0.406353\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489022; batch adversarial loss: 0.536669\n",
      "epoch 43; iter: 0; batch classifier loss: 0.405124; batch adversarial loss: 0.567381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435576; batch adversarial loss: 0.523670\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400628; batch adversarial loss: 0.534919\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409585; batch adversarial loss: 0.466426\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457992; batch adversarial loss: 0.623099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482704; batch adversarial loss: 0.508809\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369745; batch adversarial loss: 0.514378\n",
      "epoch 50; iter: 0; batch classifier loss: 0.494357; batch adversarial loss: 0.431587\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424469; batch adversarial loss: 0.592473\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400932; batch adversarial loss: 0.545028\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466690; batch adversarial loss: 0.515004\n",
      "epoch 54; iter: 0; batch classifier loss: 0.373429; batch adversarial loss: 0.535245\n",
      "epoch 55; iter: 0; batch classifier loss: 0.511540; batch adversarial loss: 0.497310\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384024; batch adversarial loss: 0.487788\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387569; batch adversarial loss: 0.515685\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460002; batch adversarial loss: 0.565496\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426233; batch adversarial loss: 0.525358\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396483; batch adversarial loss: 0.629562\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423753; batch adversarial loss: 0.553926\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441575; batch adversarial loss: 0.544657\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386605; batch adversarial loss: 0.572746\n",
      "epoch 64; iter: 0; batch classifier loss: 0.349015; batch adversarial loss: 0.564260\n",
      "epoch 65; iter: 0; batch classifier loss: 0.458360; batch adversarial loss: 0.620246\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423067; batch adversarial loss: 0.554138\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360972; batch adversarial loss: 0.563547\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413928; batch adversarial loss: 0.581990\n",
      "epoch 69; iter: 0; batch classifier loss: 0.453943; batch adversarial loss: 0.524485\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455434; batch adversarial loss: 0.554315\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365608; batch adversarial loss: 0.525212\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381597; batch adversarial loss: 0.478053\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425818; batch adversarial loss: 0.544379\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401679; batch adversarial loss: 0.564071\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416642; batch adversarial loss: 0.544849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.425072; batch adversarial loss: 0.545296\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413414; batch adversarial loss: 0.611194\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404378; batch adversarial loss: 0.439798\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355423; batch adversarial loss: 0.562171\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366486; batch adversarial loss: 0.514183\n",
      "epoch 81; iter: 0; batch classifier loss: 0.374744; batch adversarial loss: 0.526012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377903; batch adversarial loss: 0.526246\n",
      "epoch 83; iter: 0; batch classifier loss: 0.475312; batch adversarial loss: 0.545209\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352872; batch adversarial loss: 0.487687\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342993; batch adversarial loss: 0.515810\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431487; batch adversarial loss: 0.573545\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368317; batch adversarial loss: 0.478251\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414582; batch adversarial loss: 0.506961\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433581; batch adversarial loss: 0.535694\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369249; batch adversarial loss: 0.611029\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374066; batch adversarial loss: 0.516661\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399398; batch adversarial loss: 0.391831\n",
      "epoch 93; iter: 0; batch classifier loss: 0.335602; batch adversarial loss: 0.534825\n",
      "epoch 94; iter: 0; batch classifier loss: 0.400315; batch adversarial loss: 0.438098\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426054; batch adversarial loss: 0.534888\n",
      "epoch 96; iter: 0; batch classifier loss: 0.302889; batch adversarial loss: 0.545122\n",
      "epoch 97; iter: 0; batch classifier loss: 0.286487; batch adversarial loss: 0.488189\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438382; batch adversarial loss: 0.506458\n",
      "epoch 99; iter: 0; batch classifier loss: 0.315868; batch adversarial loss: 0.535092\n",
      "epoch 100; iter: 0; batch classifier loss: 0.309886; batch adversarial loss: 0.544225\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403163; batch adversarial loss: 0.535094\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394513; batch adversarial loss: 0.516600\n",
      "epoch 103; iter: 0; batch classifier loss: 0.336840; batch adversarial loss: 0.515840\n",
      "epoch 104; iter: 0; batch classifier loss: 0.432153; batch adversarial loss: 0.554079\n",
      "epoch 105; iter: 0; batch classifier loss: 0.430278; batch adversarial loss: 0.554479\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331030; batch adversarial loss: 0.593003\n",
      "epoch 107; iter: 0; batch classifier loss: 0.334701; batch adversarial loss: 0.524873\n",
      "epoch 108; iter: 0; batch classifier loss: 0.442330; batch adversarial loss: 0.506059\n",
      "epoch 109; iter: 0; batch classifier loss: 0.431532; batch adversarial loss: 0.506285\n",
      "epoch 110; iter: 0; batch classifier loss: 0.390763; batch adversarial loss: 0.515326\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368875; batch adversarial loss: 0.612098\n",
      "epoch 112; iter: 0; batch classifier loss: 0.335379; batch adversarial loss: 0.496309\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374991; batch adversarial loss: 0.611549\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346316; batch adversarial loss: 0.573512\n",
      "epoch 115; iter: 0; batch classifier loss: 0.378780; batch adversarial loss: 0.496319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361158; batch adversarial loss: 0.477864\n",
      "epoch 117; iter: 0; batch classifier loss: 0.293710; batch adversarial loss: 0.515669\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330395; batch adversarial loss: 0.516012\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350793; batch adversarial loss: 0.535622\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343967; batch adversarial loss: 0.515696\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383392; batch adversarial loss: 0.545166\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360689; batch adversarial loss: 0.544850\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346362; batch adversarial loss: 0.612071\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345738; batch adversarial loss: 0.535077\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367526; batch adversarial loss: 0.572642\n",
      "epoch 126; iter: 0; batch classifier loss: 0.331316; batch adversarial loss: 0.526604\n",
      "epoch 127; iter: 0; batch classifier loss: 0.309177; batch adversarial loss: 0.506414\n",
      "epoch 128; iter: 0; batch classifier loss: 0.450791; batch adversarial loss: 0.535282\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342638; batch adversarial loss: 0.621847\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357759; batch adversarial loss: 0.632047\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375754; batch adversarial loss: 0.544749\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347545; batch adversarial loss: 0.515857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.314127; batch adversarial loss: 0.525295\n",
      "epoch 134; iter: 0; batch classifier loss: 0.331499; batch adversarial loss: 0.553939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.379161; batch adversarial loss: 0.554641\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343207; batch adversarial loss: 0.611478\n",
      "epoch 137; iter: 0; batch classifier loss: 0.416566; batch adversarial loss: 0.592486\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365556; batch adversarial loss: 0.476920\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393067; batch adversarial loss: 0.535200\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329688; batch adversarial loss: 0.506389\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344821; batch adversarial loss: 0.545164\n",
      "epoch 142; iter: 0; batch classifier loss: 0.399378; batch adversarial loss: 0.457972\n",
      "epoch 143; iter: 0; batch classifier loss: 0.334563; batch adversarial loss: 0.544674\n",
      "epoch 144; iter: 0; batch classifier loss: 0.425143; batch adversarial loss: 0.640895\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341027; batch adversarial loss: 0.497629\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346881; batch adversarial loss: 0.467653\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334483; batch adversarial loss: 0.573682\n",
      "epoch 148; iter: 0; batch classifier loss: 0.350283; batch adversarial loss: 0.477378\n",
      "epoch 149; iter: 0; batch classifier loss: 0.409975; batch adversarial loss: 0.458642\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353736; batch adversarial loss: 0.526194\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349641; batch adversarial loss: 0.573208\n",
      "epoch 152; iter: 0; batch classifier loss: 0.287046; batch adversarial loss: 0.515962\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385395; batch adversarial loss: 0.429830\n",
      "epoch 154; iter: 0; batch classifier loss: 0.461642; batch adversarial loss: 0.535548\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433521; batch adversarial loss: 0.458106\n",
      "epoch 156; iter: 0; batch classifier loss: 0.390277; batch adversarial loss: 0.535389\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.668191\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363831; batch adversarial loss: 0.496253\n",
      "epoch 159; iter: 0; batch classifier loss: 0.326027; batch adversarial loss: 0.525604\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373395; batch adversarial loss: 0.497054\n",
      "epoch 161; iter: 0; batch classifier loss: 0.338217; batch adversarial loss: 0.573197\n",
      "epoch 162; iter: 0; batch classifier loss: 0.278555; batch adversarial loss: 0.477395\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374490; batch adversarial loss: 0.497478\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363496; batch adversarial loss: 0.525066\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324972; batch adversarial loss: 0.602443\n",
      "epoch 166; iter: 0; batch classifier loss: 0.407704; batch adversarial loss: 0.524746\n",
      "epoch 167; iter: 0; batch classifier loss: 0.331646; batch adversarial loss: 0.621040\n",
      "epoch 168; iter: 0; batch classifier loss: 0.325371; batch adversarial loss: 0.564260\n",
      "epoch 169; iter: 0; batch classifier loss: 0.382446; batch adversarial loss: 0.506903\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351352; batch adversarial loss: 0.516889\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389688; batch adversarial loss: 0.582755\n",
      "epoch 172; iter: 0; batch classifier loss: 0.327976; batch adversarial loss: 0.592552\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382511; batch adversarial loss: 0.525376\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349266; batch adversarial loss: 0.486611\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330915; batch adversarial loss: 0.554647\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361116; batch adversarial loss: 0.544077\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389367; batch adversarial loss: 0.534279\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376154; batch adversarial loss: 0.525498\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279687; batch adversarial loss: 0.458015\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318514; batch adversarial loss: 0.544516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313825; batch adversarial loss: 0.467498\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404725; batch adversarial loss: 0.496318\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350387; batch adversarial loss: 0.563565\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343417; batch adversarial loss: 0.534901\n",
      "epoch 185; iter: 0; batch classifier loss: 0.276315; batch adversarial loss: 0.496978\n",
      "epoch 186; iter: 0; batch classifier loss: 0.388468; batch adversarial loss: 0.458117\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375003; batch adversarial loss: 0.573305\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362346; batch adversarial loss: 0.583336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382849; batch adversarial loss: 0.496994\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352187; batch adversarial loss: 0.544282\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355642; batch adversarial loss: 0.486451\n",
      "epoch 192; iter: 0; batch classifier loss: 0.350270; batch adversarial loss: 0.543933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373095; batch adversarial loss: 0.603160\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369865; batch adversarial loss: 0.430060\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335803; batch adversarial loss: 0.534550\n",
      "epoch 196; iter: 0; batch classifier loss: 0.375077; batch adversarial loss: 0.554589\n",
      "epoch 197; iter: 0; batch classifier loss: 0.431465; batch adversarial loss: 0.544141\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347636; batch adversarial loss: 0.593146\n",
      "epoch 199; iter: 0; batch classifier loss: 0.284850; batch adversarial loss: 0.592394\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698864; batch adversarial loss: 0.800828\n",
      "epoch 1; iter: 0; batch classifier loss: 0.748758; batch adversarial loss: 0.826216\n",
      "epoch 2; iter: 0; batch classifier loss: 0.867559; batch adversarial loss: 0.784212\n",
      "epoch 3; iter: 0; batch classifier loss: 0.838355; batch adversarial loss: 0.711113\n",
      "epoch 4; iter: 0; batch classifier loss: 0.920518; batch adversarial loss: 0.683994\n",
      "epoch 5; iter: 0; batch classifier loss: 0.622925; batch adversarial loss: 0.624303\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609540; batch adversarial loss: 0.618097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565003; batch adversarial loss: 0.602773\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525218; batch adversarial loss: 0.588426\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546277; batch adversarial loss: 0.579142\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517317; batch adversarial loss: 0.646338\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570239; batch adversarial loss: 0.587036\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498990; batch adversarial loss: 0.566391\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445904; batch adversarial loss: 0.562977\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461912; batch adversarial loss: 0.557880\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505186; batch adversarial loss: 0.576075\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454624; batch adversarial loss: 0.543465\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507531; batch adversarial loss: 0.587553\n",
      "epoch 18; iter: 0; batch classifier loss: 0.558992; batch adversarial loss: 0.570051\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513551; batch adversarial loss: 0.554816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.566954; batch adversarial loss: 0.565942\n",
      "epoch 21; iter: 0; batch classifier loss: 0.604059; batch adversarial loss: 0.553262\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502673; batch adversarial loss: 0.541583\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493196; batch adversarial loss: 0.563389\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433046; batch adversarial loss: 0.574701\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434353; batch adversarial loss: 0.516873\n",
      "epoch 26; iter: 0; batch classifier loss: 0.447719; batch adversarial loss: 0.579444\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441422; batch adversarial loss: 0.509437\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472256; batch adversarial loss: 0.598166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.475367; batch adversarial loss: 0.517223\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464483; batch adversarial loss: 0.637213\n",
      "epoch 31; iter: 0; batch classifier loss: 0.382168; batch adversarial loss: 0.560893\n",
      "epoch 32; iter: 0; batch classifier loss: 0.503400; batch adversarial loss: 0.582058\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440116; batch adversarial loss: 0.576585\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450063; batch adversarial loss: 0.676664\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479807; batch adversarial loss: 0.532302\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456832; batch adversarial loss: 0.531310\n",
      "epoch 37; iter: 0; batch classifier loss: 0.419931; batch adversarial loss: 0.582190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424820; batch adversarial loss: 0.565740\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497290; batch adversarial loss: 0.519273\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444988; batch adversarial loss: 0.544404\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459261; batch adversarial loss: 0.586345\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428587; batch adversarial loss: 0.552282\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453621; batch adversarial loss: 0.546407\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462155; batch adversarial loss: 0.498454\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427573; batch adversarial loss: 0.518177\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459640; batch adversarial loss: 0.603237\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434148; batch adversarial loss: 0.555939\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385382; batch adversarial loss: 0.520231\n",
      "epoch 49; iter: 0; batch classifier loss: 0.374170; batch adversarial loss: 0.527893\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421645; batch adversarial loss: 0.554920\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482938; batch adversarial loss: 0.545338\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419204; batch adversarial loss: 0.632767\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401972; batch adversarial loss: 0.614742\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404031; batch adversarial loss: 0.563873\n",
      "epoch 55; iter: 0; batch classifier loss: 0.366103; batch adversarial loss: 0.529145\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409046; batch adversarial loss: 0.519168\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396432; batch adversarial loss: 0.536405\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411962; batch adversarial loss: 0.536487\n",
      "epoch 59; iter: 0; batch classifier loss: 0.474305; batch adversarial loss: 0.536252\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418961; batch adversarial loss: 0.466286\n",
      "epoch 61; iter: 0; batch classifier loss: 0.431944; batch adversarial loss: 0.483423\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465069; batch adversarial loss: 0.517558\n",
      "epoch 63; iter: 0; batch classifier loss: 0.342441; batch adversarial loss: 0.553835\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416665; batch adversarial loss: 0.553977\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438097; batch adversarial loss: 0.607372\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377488; batch adversarial loss: 0.545248\n",
      "epoch 67; iter: 0; batch classifier loss: 0.339715; batch adversarial loss: 0.571388\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375686; batch adversarial loss: 0.527584\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403328; batch adversarial loss: 0.589426\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465841; batch adversarial loss: 0.616082\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425728; batch adversarial loss: 0.527034\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400216; batch adversarial loss: 0.598280\n",
      "epoch 73; iter: 0; batch classifier loss: 0.363796; batch adversarial loss: 0.526792\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447525; batch adversarial loss: 0.482187\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391353; batch adversarial loss: 0.535605\n",
      "epoch 76; iter: 0; batch classifier loss: 0.410793; batch adversarial loss: 0.580051\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400013; batch adversarial loss: 0.509132\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371184; batch adversarial loss: 0.509121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401118; batch adversarial loss: 0.500265\n",
      "epoch 80; iter: 0; batch classifier loss: 0.422476; batch adversarial loss: 0.579328\n",
      "epoch 81; iter: 0; batch classifier loss: 0.472867; batch adversarial loss: 0.580081\n",
      "epoch 82; iter: 0; batch classifier loss: 0.340753; batch adversarial loss: 0.562403\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376613; batch adversarial loss: 0.527681\n",
      "epoch 84; iter: 0; batch classifier loss: 0.397874; batch adversarial loss: 0.588865\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369157; batch adversarial loss: 0.588992\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357247; batch adversarial loss: 0.500510\n",
      "epoch 87; iter: 0; batch classifier loss: 0.327414; batch adversarial loss: 0.526736\n",
      "epoch 88; iter: 0; batch classifier loss: 0.343908; batch adversarial loss: 0.544471\n",
      "epoch 89; iter: 0; batch classifier loss: 0.323213; batch adversarial loss: 0.544531\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359168; batch adversarial loss: 0.526815\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411189; batch adversarial loss: 0.509105\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399345; batch adversarial loss: 0.615936\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427477; batch adversarial loss: 0.607226\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356648; batch adversarial loss: 0.580601\n",
      "epoch 95; iter: 0; batch classifier loss: 0.295780; batch adversarial loss: 0.500217\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407954; batch adversarial loss: 0.562735\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455187; batch adversarial loss: 0.615685\n",
      "epoch 98; iter: 0; batch classifier loss: 0.342918; batch adversarial loss: 0.597996\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364754; batch adversarial loss: 0.597242\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350939; batch adversarial loss: 0.616180\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399554; batch adversarial loss: 0.553618\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335221; batch adversarial loss: 0.545095\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374763; batch adversarial loss: 0.465437\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389891; batch adversarial loss: 0.598107\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407570; batch adversarial loss: 0.580088\n",
      "epoch 106; iter: 0; batch classifier loss: 0.326783; batch adversarial loss: 0.561348\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421500; batch adversarial loss: 0.544821\n",
      "epoch 108; iter: 0; batch classifier loss: 0.455902; batch adversarial loss: 0.508940\n",
      "epoch 109; iter: 0; batch classifier loss: 0.446359; batch adversarial loss: 0.659597\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388735; batch adversarial loss: 0.544951\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361650; batch adversarial loss: 0.526216\n",
      "epoch 112; iter: 0; batch classifier loss: 0.431762; batch adversarial loss: 0.544157\n",
      "epoch 113; iter: 0; batch classifier loss: 0.375530; batch adversarial loss: 0.500922\n",
      "epoch 114; iter: 0; batch classifier loss: 0.336776; batch adversarial loss: 0.545379\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396815; batch adversarial loss: 0.562191\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384812; batch adversarial loss: 0.552961\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374923; batch adversarial loss: 0.500232\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345224; batch adversarial loss: 0.527683\n",
      "epoch 119; iter: 0; batch classifier loss: 0.440918; batch adversarial loss: 0.553789\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375379; batch adversarial loss: 0.589151\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348442; batch adversarial loss: 0.561621\n",
      "epoch 122; iter: 0; batch classifier loss: 0.317582; batch adversarial loss: 0.536146\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353402; batch adversarial loss: 0.589429\n",
      "epoch 124; iter: 0; batch classifier loss: 0.429154; batch adversarial loss: 0.482659\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360214; batch adversarial loss: 0.561817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.378573; batch adversarial loss: 0.562935\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356733; batch adversarial loss: 0.589476\n",
      "epoch 128; iter: 0; batch classifier loss: 0.304672; batch adversarial loss: 0.580223\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338222; batch adversarial loss: 0.571431\n",
      "epoch 130; iter: 0; batch classifier loss: 0.369909; batch adversarial loss: 0.570405\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352803; batch adversarial loss: 0.535488\n",
      "epoch 132; iter: 0; batch classifier loss: 0.337414; batch adversarial loss: 0.536767\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370181; batch adversarial loss: 0.552907\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341926; batch adversarial loss: 0.527025\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387635; batch adversarial loss: 0.572017\n",
      "epoch 136; iter: 0; batch classifier loss: 0.325498; batch adversarial loss: 0.553543\n",
      "epoch 137; iter: 0; batch classifier loss: 0.336119; batch adversarial loss: 0.553019\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318113; batch adversarial loss: 0.571611\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338802; batch adversarial loss: 0.571293\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354764; batch adversarial loss: 0.500301\n",
      "epoch 141; iter: 0; batch classifier loss: 0.306210; batch adversarial loss: 0.500291\n",
      "epoch 142; iter: 0; batch classifier loss: 0.317602; batch adversarial loss: 0.633235\n",
      "epoch 143; iter: 0; batch classifier loss: 0.294395; batch adversarial loss: 0.597927\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352261; batch adversarial loss: 0.579105\n",
      "epoch 145; iter: 0; batch classifier loss: 0.465260; batch adversarial loss: 0.579683\n",
      "epoch 146; iter: 0; batch classifier loss: 0.306903; batch adversarial loss: 0.571976\n",
      "epoch 147; iter: 0; batch classifier loss: 0.326691; batch adversarial loss: 0.553931\n",
      "epoch 148; iter: 0; batch classifier loss: 0.292522; batch adversarial loss: 0.499747\n",
      "epoch 149; iter: 0; batch classifier loss: 0.357232; batch adversarial loss: 0.571006\n",
      "epoch 150; iter: 0; batch classifier loss: 0.428870; batch adversarial loss: 0.553975\n",
      "epoch 151; iter: 0; batch classifier loss: 0.344342; batch adversarial loss: 0.562957\n",
      "epoch 152; iter: 0; batch classifier loss: 0.327518; batch adversarial loss: 0.543749\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363426; batch adversarial loss: 0.491140\n",
      "epoch 154; iter: 0; batch classifier loss: 0.300662; batch adversarial loss: 0.562485\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408456; batch adversarial loss: 0.518029\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371884; batch adversarial loss: 0.588997\n",
      "epoch 157; iter: 0; batch classifier loss: 0.322807; batch adversarial loss: 0.535975\n",
      "epoch 158; iter: 0; batch classifier loss: 0.277225; batch adversarial loss: 0.580805\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388869; batch adversarial loss: 0.526693\n",
      "epoch 160; iter: 0; batch classifier loss: 0.427834; batch adversarial loss: 0.572047\n",
      "epoch 161; iter: 0; batch classifier loss: 0.296684; batch adversarial loss: 0.545305\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312052; batch adversarial loss: 0.605258\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382771; batch adversarial loss: 0.643955\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381008; batch adversarial loss: 0.535199\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326209; batch adversarial loss: 0.580783\n",
      "epoch 166; iter: 0; batch classifier loss: 0.312939; batch adversarial loss: 0.536181\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366204; batch adversarial loss: 0.588743\n",
      "epoch 168; iter: 0; batch classifier loss: 0.311940; batch adversarial loss: 0.499541\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408901; batch adversarial loss: 0.579890\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336034; batch adversarial loss: 0.491394\n",
      "epoch 171; iter: 0; batch classifier loss: 0.246786; batch adversarial loss: 0.518094\n",
      "epoch 172; iter: 0; batch classifier loss: 0.339266; batch adversarial loss: 0.597116\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414031; batch adversarial loss: 0.554212\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318637; batch adversarial loss: 0.553403\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336358; batch adversarial loss: 0.554307\n",
      "epoch 176; iter: 0; batch classifier loss: 0.317488; batch adversarial loss: 0.561277\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392298; batch adversarial loss: 0.509766\n",
      "epoch 178; iter: 0; batch classifier loss: 0.300902; batch adversarial loss: 0.544403\n",
      "epoch 179; iter: 0; batch classifier loss: 0.313053; batch adversarial loss: 0.642609\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343324; batch adversarial loss: 0.561260\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384943; batch adversarial loss: 0.561712\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364855; batch adversarial loss: 0.527863\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336720; batch adversarial loss: 0.580294\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363345; batch adversarial loss: 0.579434\n",
      "epoch 185; iter: 0; batch classifier loss: 0.298745; batch adversarial loss: 0.510128\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327253; batch adversarial loss: 0.579380\n",
      "epoch 187; iter: 0; batch classifier loss: 0.312372; batch adversarial loss: 0.605576\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383527; batch adversarial loss: 0.543778\n",
      "epoch 189; iter: 0; batch classifier loss: 0.293158; batch adversarial loss: 0.579895\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347535; batch adversarial loss: 0.581362\n",
      "epoch 191; iter: 0; batch classifier loss: 0.319762; batch adversarial loss: 0.571657\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349160; batch adversarial loss: 0.509175\n",
      "epoch 193; iter: 0; batch classifier loss: 0.291537; batch adversarial loss: 0.536566\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347427; batch adversarial loss: 0.562255\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347363; batch adversarial loss: 0.571705\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332690; batch adversarial loss: 0.535731\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366302; batch adversarial loss: 0.572395\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360985; batch adversarial loss: 0.526408\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315786; batch adversarial loss: 0.525699\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685673; batch adversarial loss: 0.590169\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597805; batch adversarial loss: 0.615878\n",
      "epoch 2; iter: 0; batch classifier loss: 0.545147; batch adversarial loss: 0.637734\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576190; batch adversarial loss: 0.638747\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588769; batch adversarial loss: 0.628258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.653088; batch adversarial loss: 0.550615\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508072; batch adversarial loss: 0.616095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469293; batch adversarial loss: 0.574320\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610879; batch adversarial loss: 0.596212\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579503; batch adversarial loss: 0.602802\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553126; batch adversarial loss: 0.608219\n",
      "epoch 11; iter: 0; batch classifier loss: 0.619292; batch adversarial loss: 0.580821\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536978; batch adversarial loss: 0.559006\n",
      "epoch 13; iter: 0; batch classifier loss: 0.444023; batch adversarial loss: 0.534357\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472942; batch adversarial loss: 0.555735\n",
      "epoch 15; iter: 0; batch classifier loss: 0.590161; batch adversarial loss: 0.525158\n",
      "epoch 16; iter: 0; batch classifier loss: 0.535918; batch adversarial loss: 0.627846\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483636; batch adversarial loss: 0.530059\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498319; batch adversarial loss: 0.598341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518464; batch adversarial loss: 0.530691\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518809; batch adversarial loss: 0.585268\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459006; batch adversarial loss: 0.523445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512492; batch adversarial loss: 0.569730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.403936; batch adversarial loss: 0.535626\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527034; batch adversarial loss: 0.588027\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446503; batch adversarial loss: 0.575625\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472729; batch adversarial loss: 0.533255\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434579; batch adversarial loss: 0.514304\n",
      "epoch 28; iter: 0; batch classifier loss: 0.522849; batch adversarial loss: 0.462998\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483607; batch adversarial loss: 0.608135\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504308; batch adversarial loss: 0.512242\n",
      "epoch 31; iter: 0; batch classifier loss: 0.573340; batch adversarial loss: 0.595637\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470399; batch adversarial loss: 0.560055\n",
      "epoch 33; iter: 0; batch classifier loss: 0.535251; batch adversarial loss: 0.517264\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422276; batch adversarial loss: 0.589746\n",
      "epoch 35; iter: 0; batch classifier loss: 0.439820; batch adversarial loss: 0.571811\n",
      "epoch 36; iter: 0; batch classifier loss: 0.538936; batch adversarial loss: 0.562139\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460658; batch adversarial loss: 0.511548\n",
      "epoch 38; iter: 0; batch classifier loss: 0.393049; batch adversarial loss: 0.587986\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482910; batch adversarial loss: 0.571198\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431354; batch adversarial loss: 0.509672\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423305; batch adversarial loss: 0.491787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.558333; batch adversarial loss: 0.544775\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394571; batch adversarial loss: 0.499899\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395681; batch adversarial loss: 0.544603\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455688; batch adversarial loss: 0.446033\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419540; batch adversarial loss: 0.562631\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421554; batch adversarial loss: 0.553632\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467266; batch adversarial loss: 0.553513\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409866; batch adversarial loss: 0.535445\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470971; batch adversarial loss: 0.498993\n",
      "epoch 51; iter: 0; batch classifier loss: 0.419013; batch adversarial loss: 0.599154\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460582; batch adversarial loss: 0.654273\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439850; batch adversarial loss: 0.608271\n",
      "epoch 54; iter: 0; batch classifier loss: 0.498517; batch adversarial loss: 0.653350\n",
      "epoch 55; iter: 0; batch classifier loss: 0.399892; batch adversarial loss: 0.517343\n",
      "epoch 56; iter: 0; batch classifier loss: 0.464417; batch adversarial loss: 0.526078\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379714; batch adversarial loss: 0.554011\n",
      "epoch 58; iter: 0; batch classifier loss: 0.406574; batch adversarial loss: 0.581223\n",
      "epoch 59; iter: 0; batch classifier loss: 0.481730; batch adversarial loss: 0.498925\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423273; batch adversarial loss: 0.553728\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407907; batch adversarial loss: 0.436334\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380934; batch adversarial loss: 0.490359\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387282; batch adversarial loss: 0.526154\n",
      "epoch 64; iter: 0; batch classifier loss: 0.492679; batch adversarial loss: 0.572904\n",
      "epoch 65; iter: 0; batch classifier loss: 0.459358; batch adversarial loss: 0.634746\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377031; batch adversarial loss: 0.653423\n",
      "epoch 67; iter: 0; batch classifier loss: 0.470779; batch adversarial loss: 0.508218\n",
      "epoch 68; iter: 0; batch classifier loss: 0.429788; batch adversarial loss: 0.535994\n",
      "epoch 69; iter: 0; batch classifier loss: 0.345516; batch adversarial loss: 0.571220\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458799; batch adversarial loss: 0.516428\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392164; batch adversarial loss: 0.526522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399312; batch adversarial loss: 0.598789\n",
      "epoch 73; iter: 0; batch classifier loss: 0.312239; batch adversarial loss: 0.554361\n",
      "epoch 74; iter: 0; batch classifier loss: 0.459342; batch adversarial loss: 0.571755\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397036; batch adversarial loss: 0.507563\n",
      "epoch 76; iter: 0; batch classifier loss: 0.428470; batch adversarial loss: 0.534470\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387387; batch adversarial loss: 0.526062\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429246; batch adversarial loss: 0.535964\n",
      "epoch 79; iter: 0; batch classifier loss: 0.335749; batch adversarial loss: 0.580963\n",
      "epoch 80; iter: 0; batch classifier loss: 0.413814; batch adversarial loss: 0.544750\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372209; batch adversarial loss: 0.562637\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401938; batch adversarial loss: 0.544437\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404817; batch adversarial loss: 0.554051\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382740; batch adversarial loss: 0.490613\n",
      "epoch 85; iter: 0; batch classifier loss: 0.359897; batch adversarial loss: 0.553624\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377043; batch adversarial loss: 0.562069\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410217; batch adversarial loss: 0.553994\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382356; batch adversarial loss: 0.552930\n",
      "epoch 89; iter: 0; batch classifier loss: 0.458197; batch adversarial loss: 0.535914\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397805; batch adversarial loss: 0.489537\n",
      "epoch 91; iter: 0; batch classifier loss: 0.454298; batch adversarial loss: 0.571933\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370777; batch adversarial loss: 0.580178\n",
      "epoch 93; iter: 0; batch classifier loss: 0.411780; batch adversarial loss: 0.480402\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348723; batch adversarial loss: 0.690578\n",
      "epoch 95; iter: 0; batch classifier loss: 0.379281; batch adversarial loss: 0.616926\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418403; batch adversarial loss: 0.543253\n",
      "epoch 97; iter: 0; batch classifier loss: 0.474265; batch adversarial loss: 0.581295\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372851; batch adversarial loss: 0.579429\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434739; batch adversarial loss: 0.578418\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392680; batch adversarial loss: 0.571479\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396387; batch adversarial loss: 0.508638\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388423; batch adversarial loss: 0.590477\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373412; batch adversarial loss: 0.599507\n",
      "epoch 104; iter: 0; batch classifier loss: 0.406474; batch adversarial loss: 0.535187\n",
      "epoch 105; iter: 0; batch classifier loss: 0.494969; batch adversarial loss: 0.491443\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373082; batch adversarial loss: 0.544756\n",
      "epoch 107; iter: 0; batch classifier loss: 0.425445; batch adversarial loss: 0.569443\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385965; batch adversarial loss: 0.517889\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357705; batch adversarial loss: 0.597733\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427026; batch adversarial loss: 0.499119\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398543; batch adversarial loss: 0.536384\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336507; batch adversarial loss: 0.518381\n",
      "epoch 113; iter: 0; batch classifier loss: 0.480902; batch adversarial loss: 0.526057\n",
      "epoch 114; iter: 0; batch classifier loss: 0.402973; batch adversarial loss: 0.524710\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388952; batch adversarial loss: 0.618268\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391880; batch adversarial loss: 0.580463\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326394; batch adversarial loss: 0.561347\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373626; batch adversarial loss: 0.617588\n",
      "epoch 119; iter: 0; batch classifier loss: 0.413075; batch adversarial loss: 0.471811\n",
      "epoch 120; iter: 0; batch classifier loss: 0.432526; batch adversarial loss: 0.571942\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341495; batch adversarial loss: 0.561538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.309723; batch adversarial loss: 0.472169\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380065; batch adversarial loss: 0.599892\n",
      "epoch 124; iter: 0; batch classifier loss: 0.426949; batch adversarial loss: 0.543025\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412566; batch adversarial loss: 0.535686\n",
      "epoch 126; iter: 0; batch classifier loss: 0.433272; batch adversarial loss: 0.615627\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347187; batch adversarial loss: 0.507906\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355511; batch adversarial loss: 0.508810\n",
      "epoch 129; iter: 0; batch classifier loss: 0.405844; batch adversarial loss: 0.500878\n",
      "epoch 130; iter: 0; batch classifier loss: 0.347935; batch adversarial loss: 0.607246\n",
      "epoch 131; iter: 0; batch classifier loss: 0.461307; batch adversarial loss: 0.543925\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392158; batch adversarial loss: 0.552752\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379966; batch adversarial loss: 0.653568\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329690; batch adversarial loss: 0.589454\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399865; batch adversarial loss: 0.518616\n",
      "epoch 136; iter: 0; batch classifier loss: 0.436660; batch adversarial loss: 0.526515\n",
      "epoch 137; iter: 0; batch classifier loss: 0.421873; batch adversarial loss: 0.481407\n",
      "epoch 138; iter: 0; batch classifier loss: 0.288769; batch adversarial loss: 0.570874\n",
      "epoch 139; iter: 0; batch classifier loss: 0.432138; batch adversarial loss: 0.507885\n",
      "epoch 140; iter: 0; batch classifier loss: 0.425309; batch adversarial loss: 0.536769\n",
      "epoch 141; iter: 0; batch classifier loss: 0.382066; batch adversarial loss: 0.581153\n",
      "epoch 142; iter: 0; batch classifier loss: 0.450437; batch adversarial loss: 0.572133\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373171; batch adversarial loss: 0.581196\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336082; batch adversarial loss: 0.506778\n",
      "epoch 145; iter: 0; batch classifier loss: 0.427905; batch adversarial loss: 0.579835\n",
      "epoch 146; iter: 0; batch classifier loss: 0.338803; batch adversarial loss: 0.517495\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410506; batch adversarial loss: 0.552598\n",
      "epoch 148; iter: 0; batch classifier loss: 0.288897; batch adversarial loss: 0.563152\n",
      "epoch 149; iter: 0; batch classifier loss: 0.422369; batch adversarial loss: 0.471866\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345530; batch adversarial loss: 0.488702\n",
      "epoch 151; iter: 0; batch classifier loss: 0.433448; batch adversarial loss: 0.499258\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369263; batch adversarial loss: 0.580935\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400532; batch adversarial loss: 0.480588\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424696; batch adversarial loss: 0.508660\n",
      "epoch 155; iter: 0; batch classifier loss: 0.516603; batch adversarial loss: 0.452951\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370967; batch adversarial loss: 0.608655\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369039; batch adversarial loss: 0.517650\n",
      "epoch 158; iter: 0; batch classifier loss: 0.440919; batch adversarial loss: 0.542826\n",
      "epoch 159; iter: 0; batch classifier loss: 0.438962; batch adversarial loss: 0.528094\n",
      "epoch 160; iter: 0; batch classifier loss: 0.343743; batch adversarial loss: 0.507591\n",
      "epoch 161; iter: 0; batch classifier loss: 0.328646; batch adversarial loss: 0.499727\n",
      "epoch 162; iter: 0; batch classifier loss: 0.295578; batch adversarial loss: 0.480204\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338220; batch adversarial loss: 0.518627\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377237; batch adversarial loss: 0.506922\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379492; batch adversarial loss: 0.461967\n",
      "epoch 166; iter: 0; batch classifier loss: 0.444516; batch adversarial loss: 0.579716\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395878; batch adversarial loss: 0.581083\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351090; batch adversarial loss: 0.571571\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411265; batch adversarial loss: 0.608701\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354092; batch adversarial loss: 0.589177\n",
      "epoch 171; iter: 0; batch classifier loss: 0.286248; batch adversarial loss: 0.525639\n",
      "epoch 172; iter: 0; batch classifier loss: 0.443859; batch adversarial loss: 0.627734\n",
      "epoch 173; iter: 0; batch classifier loss: 0.385711; batch adversarial loss: 0.499089\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358031; batch adversarial loss: 0.489497\n",
      "epoch 175; iter: 0; batch classifier loss: 0.353602; batch adversarial loss: 0.507967\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361736; batch adversarial loss: 0.562872\n",
      "epoch 177; iter: 0; batch classifier loss: 0.294508; batch adversarial loss: 0.526133\n",
      "epoch 178; iter: 0; batch classifier loss: 0.503575; batch adversarial loss: 0.516143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421088; batch adversarial loss: 0.562352\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307127; batch adversarial loss: 0.526442\n",
      "epoch 181; iter: 0; batch classifier loss: 0.289902; batch adversarial loss: 0.563700\n",
      "epoch 182; iter: 0; batch classifier loss: 0.311062; batch adversarial loss: 0.579739\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396080; batch adversarial loss: 0.598297\n",
      "epoch 184; iter: 0; batch classifier loss: 0.442313; batch adversarial loss: 0.525853\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348769; batch adversarial loss: 0.525837\n",
      "epoch 186; iter: 0; batch classifier loss: 0.305133; batch adversarial loss: 0.526348\n",
      "epoch 187; iter: 0; batch classifier loss: 0.349165; batch adversarial loss: 0.498842\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363795; batch adversarial loss: 0.489304\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395020; batch adversarial loss: 0.516945\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336098; batch adversarial loss: 0.553915\n",
      "epoch 191; iter: 0; batch classifier loss: 0.458401; batch adversarial loss: 0.589308\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369321; batch adversarial loss: 0.489566\n",
      "epoch 193; iter: 0; batch classifier loss: 0.309919; batch adversarial loss: 0.518616\n",
      "epoch 194; iter: 0; batch classifier loss: 0.386363; batch adversarial loss: 0.635669\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319568; batch adversarial loss: 0.481665\n",
      "epoch 196; iter: 0; batch classifier loss: 0.455016; batch adversarial loss: 0.589041\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319483; batch adversarial loss: 0.571445\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334772; batch adversarial loss: 0.599596\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337816; batch adversarial loss: 0.544998\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7792382",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37b30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d582f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2022e6",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ef4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9d8ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce645e6",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c753065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae20855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd6985",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ac27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b2eda6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2af6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
